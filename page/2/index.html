<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://example.com">
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div> 
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/123.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/categories">分类</a></li>
	        
			</ul>
		</nav>
		<nav>
			总文章数 51
		</nav>		
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
		        
					<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
		        
					<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>



    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/123.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
			        
						<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
			        
						<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/categories">分类</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-腾讯云EMR离线数仓" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/01/%E8%85%BE%E8%AE%AF%E4%BA%91EMR%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93/">腾讯云EMR离线数仓</a>
    </h1>
  

        
        <a href="/2023/11/01/%E8%85%BE%E8%AE%AF%E4%BA%91EMR%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93/" class="archive-article-date">
  	<time datetime="2023-11-01T06:05:31.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-11-01</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>基于腾讯云EMR搭建离线数据仓库（需求及架构设计）</p>
</blockquote>
<h1 id="第一章-序言"><a href="#第一章-序言" class="headerlink" title="第一章 序言"></a>第一章 序言</h1><h2 id="1-1-目标"><a href="#1-1-目标" class="headerlink" title="1.1 目标"></a>1.1 目标</h2><p>在生产环境中，我们的数据来源于java后台，我们要从业务库中将这些数据采集到大数据集群中，这样才能做分析处理。</p>
<p>按照数仓建模理论搭建一个完整的数据仓库。包括：需求分析、架构设计、数据存储、建模、计算、输出、展示等所有流程。</p>
<h2 id="1-2-数据仓库概念"><a href="#1-2-数据仓库概念" class="headerlink" title="1.2 数据仓库概念"></a>1.2 数据仓库概念</h2><p><img src="Snipaste_2023-11-02_21-09-44.png" alt="Snipaste_2023-11-02_21-09-44"></p>
<p>ODS：原始数据层</p>
<p>DWD：明细数据层</p>
<p>DWS：汇总数据层</p>
<p>ADS：数据应用层</p>
<p>Oozie：定时调度</p>
<h1 id="第二章-项目需求及架构设计"><a href="#第二章-项目需求及架构设计" class="headerlink" title="第二章 项目需求及架构设计"></a>第二章 项目需求及架构设计</h1><h2 id="2-1-项目需求分析"><a href="#2-1-项目需求分析" class="headerlink" title="2.1 项目需求分析"></a>2.1 项目需求分析</h2><img src="Snipaste_2023-11-02_21-16-10.png" alt="Snipaste_2023-11-02_21-16-10" style="zoom:50%;">

<h2 id="2-2-项目框架"><a href="#2-2-项目框架" class="headerlink" title="2.2 项目框架"></a>2.2 项目框架</h2><h3 id="2-2-1-技术选型"><a href="#2-2-1-技术选型" class="headerlink" title="2.2.1 技术选型"></a>2.2.1 技术选型</h3><img src="Snipaste_2023-11-02_21-16-43.png" alt="Snipaste_2023-11-02_21-16-43" style="zoom:50%;">

<h3 id="2-2-2-系统数据流程设计"><a href="#2-2-2-系统数据流程设计" class="headerlink" title="2.2.2 系统数据流程设计"></a>2.2.2 系统数据流程设计</h3><img src="Snipaste_2023-11-02_21-17-15.png" alt="Snipaste_2023-11-02_21-17-15" style="zoom:50%;">

<h3 id="2-2-3-框架版本选择"><a href="#2-2-3-框架版本选择" class="headerlink" title="2.2.3 框架版本选择"></a>2.2.3 框架版本选择</h3><img src="Snipaste_2023-11-02_21-40-23.png" alt="Snipaste_2023-11-02_21-40-23" style="zoom:43%;">

<img src="Snipaste_2023-11-02_21-41-39.png" alt="Snipaste_2023-11-02_21-41-39" style="zoom:43%;">

<h3 id="2-2-4-服务器选型"><a href="#2-2-4-服务器选型" class="headerlink" title="2.2.4 服务器选型"></a>2.2.4 服务器选型</h3><img src="Snipaste_2023-11-02_21-42-52.png" alt="Snipaste_2023-11-02_21-42-52" style="zoom:43%;">

<h3 id="2-2-5-集群规模"><a href="#2-2-5-集群规模" class="headerlink" title="2.2.5 集群规模"></a>2.2.5 集群规模</h3><img src="Snipaste_2023-11-02_21-45-48.png" alt="Snipaste_2023-11-02_21-45-48" style="zoom:50%;">

<h3 id="2-2-6-集群资源规划设计"><a href="#2-2-6-集群资源规划设计" class="headerlink" title="2.2.6 集群资源规划设计"></a>2.2.6 集群资源规划设计</h3><p>在企业中通常会搭建一套生产集群和一套测试集群。生产集群运行生产任务，测试集群用于上线前代码编写和测试。</p>
<img src="Snipaste_2023-11-02_21-51-20.png" alt="Snipaste_2023-11-02_21-51-20" style="zoom:50%;">

<h1 id="第三章-电商业务简介"><a href="#第三章-电商业务简介" class="headerlink" title="第三章 电商业务简介"></a>第三章 电商业务简介</h1><h2 id="3-1-电商业务流程"><a href="#3-1-电商业务流程" class="headerlink" title="3.1 电商业务流程"></a>3.1 电商业务流程</h2><p>电商的业务流程可以以一个普通用户的浏览足迹为例进行说明，用户点开电商首页开始浏览，可能会通过分类查询也可能通过全文搜索寻找自己中意的商品，这些商品无疑都是存储在后台的管理系统中的。</p>
<p>当用户寻找到自己中意的商品，可能会想要购买，将商品添加到购物车后发现需要登录，登录后对商品进行结算，这时候购物车的管理和商品订单信息的生成都会对业务数据库产生影响，会生成相应的订单数据和支付数据。</p>
<p>订单正式生成之后，还会对订单进行跟踪处理，直到订单全部完成。</p>
<p>电商的主要业务流程包括用户前台浏览商品时的商品详情的管理，用户商品加入购物车进行支付时用户个人中心&amp;支付服务的管理，用户支付完成后订单后台服务的管理，这些流程涉及到了十几个甚至几十个业务数据表，甚至更多。</p>
<h2 id="3-2-电商常识"><a href="#3-2-电商常识" class="headerlink" title="3.2 电商常识"></a>3.2 电商常识</h2><h3 id="3-2-1-SKU和SPU"><a href="#3-2-1-SKU和SPU" class="headerlink" title="3.2.1 SKU和SPU"></a>3.2.1 SKU和SPU</h3><p>SKU&#x3D;Stock Keeping Unit（库存量基本单位）。现在已经被引申为<strong>产品统一编号</strong>的简称，每种产品均对应有唯一的SKU号。</p>
<p> SPU（Standard Product Unit）：是<strong>商品信息聚合的最小单位</strong>，是一组可复用、易检索的标准化信息集合。</p>
<p>例如：iPhoneX手机就是SPU。一台银色、128G内存的、支持联通网络的iPhoneX，就是SKU。</p>
<p><img src="%E5%9B%BE%E7%89%871.png" alt="图片1"></p>
<p>SPU表示一类商品。同一SPU的商品可以共用商品图片、海报、销售属性等。</p>
<h1 id="第四章-选购腾讯云EMR"><a href="#第四章-选购腾讯云EMR" class="headerlink" title="第四章 选购腾讯云EMR"></a>第四章 选购腾讯云EMR</h1><h2 id="4-1-注册腾讯云账户"><a href="#4-1-注册腾讯云账户" class="headerlink" title="4.1 注册腾讯云账户"></a>4.1 注册腾讯云账户</h2><h2 id="4-2-购买弹性MapReduce"><a href="#4-2-购买弹性MapReduce" class="headerlink" title="4.2 购买弹性MapReduce"></a>4.2 购买弹性MapReduce</h2><p><img src="Snipaste_2023-11-05_21-23-35.png" alt="Snipaste_2023-11-05_21-23-35"></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">项目</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/11/01/%E8%85%BE%E8%AE%AF%E4%BA%91EMR%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-kafka框架学习笔记" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/20/kafka%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">kafka框架学习笔记</a>
    </h1>
  

        
        <a href="/2023/10/20/kafka%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2023-10-20T13:37:36.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-10-20</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Kafka概述"><a href="#第一章-Kafka概述" class="headerlink" title="第一章 Kafka概述"></a>第一章 Kafka概述</h1><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h2><p><img src="Snipaste_2023-10-23_12-21-51.png" alt="Snipaste_2023-10-23_12-21-51"></p>
<h2 id="1-2-消息队列"><a href="#1-2-消息队列" class="headerlink" title="1.2 消息队列"></a>1.2 消息队列</h2><p>目 前企 业中比 较常 见的 消息 队列产 品主 要有 Kafka、ActiveMQ 、RabbitMQ 、RocketMQ 等。</p>
<p>在<strong>大数据</strong>场景主要采用 <strong>Kafka</strong> 作为消息队列。在 JavaEE 开发中主要采用 ActiveMQ、RabbitMQ、RocketMQ。</p>
<h3 id="1-2-1-传统消息队列的应用场景"><a href="#1-2-1-传统消息队列的应用场景" class="headerlink" title="1.2.1 传统消息队列的应用场景"></a>1.2.1 传统消息队列的应用场景</h3><p>传统的消息队列的主要应用场景包括：<strong>缓存&#x2F;消峰</strong>、<strong>解耦</strong>和<strong>异步通信</strong></p>
<img src="Snipaste_2023-10-23_12-28-55.png" alt="Snipaste_2023-10-23_12-28-55" style="zoom:43%;">

<img src="Snipaste_2023-10-23_12-29-14.png" alt="Snipaste_2023-10-23_12-29-14" style="zoom:43%;">

<img src="Snipaste_2023-10-23_12-31-49.png" alt="Snipaste_2023-10-23_12-31-49" style="zoom:43%;">

<h3 id="1-2-2-消息队列的两种模式"><a href="#1-2-2-消息队列的两种模式" class="headerlink" title="1.2.2 消息队列的两种模式"></a>1.2.2 消息队列的两种模式</h3><p>（1）点对点模式</p>
<img src="Snipaste_2023-10-23_12-39-38.png" alt="Snipaste_2023-10-23_12-39-38" style="zoom:50%;">

<p>（2）发布&#x2F;订阅模式</p>
<img src="Snipaste_2023-10-23_12-40-01.png" alt="Snipaste_2023-10-23_12-40-01" style="zoom:50%;">

<h2 id="1-3-Kafka基础架构"><a href="#1-3-Kafka基础架构" class="headerlink" title="1.3 Kafka基础架构"></a>1.3 Kafka基础架构</h2><p><img src="Snipaste_2023-10-23_13-10-47.png" alt="Snipaste_2023-10-23_13-10-47"></p>
<p>（1）Producer：消息生产者，就是向 Kafka broker 发消息的客户端。</p>
<p>（2）Consumer：消息消费者，向 Kafka broker 取消息的客户端。</p>
<p>（3）Consumer Group（CG）：消费者组，由多个 consumer 组成。<strong>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。</strong>所有的消费者都属于某个消费者组，即<strong>消费者组是逻辑上的一个订阅者</strong>。</p>
<p>也就是说：一个分区如果被两个消费者消费，那么这两个消费者必定不在同一个组；</p>
<p>（4）Broker：一台Kafka服务器就是一个broker。一个集群由多个 broker （kafka）组成。一个broker （kafka）可以容纳多个 topic。</p>
<p>（5）Topic：可以理解为一个队列，<strong>生产者和消费者面向的都是一个</strong> <strong>topic</strong>。</p>
<p>（6）Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，<strong>一个</strong> <strong>topic</strong> <strong>可以分为多个</strong> <strong>partition</strong>，每个 partition 是一个有序的队列</p>
<p>（7）Replica：副本。一个 topic 的每个分区都有若干个副本，一个 <strong>Leader</strong> 和若干个<strong>Follower</strong></p>
<p>（8）Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。</p>
<p>（9）Follower：每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。</p>
<h1 id="第二章-Kafka快速入门"><a href="#第二章-Kafka快速入门" class="headerlink" title="第二章 Kafka快速入门"></a>第二章 Kafka快速入门</h1><h2 id="2-1-安装部署"><a href="#2-1-安装部署" class="headerlink" title="2.1 安装部署"></a>2.1 安装部署</h2><h3 id="2-1-1-集群规划"><a href="#2-1-1-集群规划" class="headerlink" title="2.1.1 集群规划"></a>2.1.1 集群规划</h3><p><img src="Snipaste_2023-10-23_13-33-36.png" alt="Snipaste_2023-10-23_13-33-36"></p>
<h3 id="2-1-2-集群部署"><a href="#2-1-2-集群部署" class="headerlink" title="2.1.2 集群部署"></a>2.1.2 集群部署</h3><p>（0）将kafka的安装包拖拽到&#x2F;opt&#x2F;software&#x2F;</p>
<p>（1）解压安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>（2）修改解压后的文件名称</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mv kafka_2.12-3.0.0/ kafka</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 8</span><br><span class="line">drwxr-xr-x.  2 root root   99 10月 10 13:38 data</span><br><span class="line">drwxr-xr-x.  4 root root   76 10月 21 20:31 datas</span><br><span class="line">drwxr-xr-x. 12 root root  272 10月 21 17:08 flume</span><br><span class="line">-rw-r--r--.  1 root root    9 10月 22 14:08 group.log</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 12 root root  243 10月  8 13:38 hive</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br><span class="line">drwxr-xr-x   7 root root  105 9月   9 2021 kafka       # 在这里</span><br><span class="line">drwxr-xr-x.  8 root root  160 10月 19 12:57 zookeeper-3.5.7</span><br></pre></td></tr></table></figure>

<p>（3）进入到&#x2F;opt&#x2F;module&#x2F;kafka 目录，修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# cd config/</span><br><span class="line">[root@hadoop102 config]# vim server.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">broker 的全局唯一编号，不能重复，只能是数字。</span></span><br><span class="line">broker.id=0</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">处理网络请求的线程数量</span></span><br><span class="line">num.network.threads=3</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">用来处理磁盘 IO 的线程数量</span></span><br><span class="line">num.io.threads=8</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">发送套接字的缓冲区大小</span></span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">接收套接字的缓冲区大小</span></span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">请求套接字的缓冲区大小</span></span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">kafka 运行日志(数据)存放的路径，路径不需要提前创建，kafka 自动帮你创建，可以配置多个磁盘路径，路径与路径之间可以用<span class="string">&quot;，&quot;</span>分隔</span></span><br><span class="line">log.dirs=/opt/module/kafka/datas</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">topic 在当前 broker 上的分区个数</span></span><br><span class="line">num.partitions=1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">用来恢复和清理 data 下数据的线程数量</span></span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">每个 topic 创建时的副本数，默认时 1 个副本</span></span><br><span class="line">offsets.topic.replication.factor=1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">segment 文件保留的最长时间，超时将被删除</span></span><br><span class="line">log.retention.hours=168</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">每个 segment 文件的大小，默认最大 1G</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查过期数据的时间，默认 5 分钟检查一次是否数据过期</span></span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置连接 Zookeeper 集群地址（在 zk 根目录下创建/kafka，方便管理）</span></span><br><span class="line">zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka</span><br></pre></td></tr></table></figure>

<p>（4）分发安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# xsync kafka/</span><br></pre></td></tr></table></figure>

<p>（5）分别在hadoop103和hadoop104上修改配置文件&#x2F;opt&#x2F;module&#x2F;kafka&#x2F;config&#x2F;server.properties中的 broker.id&#x3D;1、broker.id&#x3D;2</p>
<p><strong>注：broker.id 不得重复，整个集群中唯一。</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 module]#  vim kafka/config/server.properties</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The <span class="built_in">id</span> of the broker. This must be <span class="built_in">set</span> to a unique <span class="built_in">integer</span> <span class="keyword">for</span></span> </span><br><span class="line">each broker.</span><br><span class="line">broker.id=1</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 module]# vim kafka/config/server.properties</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The <span class="built_in">id</span> of the broker. This must be <span class="built_in">set</span> to a unique <span class="built_in">integer</span> <span class="keyword">for</span></span> </span><br><span class="line">each broker.</span><br><span class="line">broker.id=2</span><br></pre></td></tr></table></figure>

<p>（6）配置环境变量</p>
<p>在&#x2F;etc&#x2F;profile.d&#x2F;my_env.sh 文件中增加 kafka 环境变量配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">KAFKA_HOME</span></span><br><span class="line">export KAFKA_HOME=/opt/module/kafka</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure>

<p>刷新新一下环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# source /etc/profile</span><br></pre></td></tr></table></figure>

<p>分发环境变量文件到其他节点，并 source。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 profile.d]# xsync my_env.sh</span><br><span class="line"></span><br><span class="line">[root@hadoop103 ~]# source /etc/profile</span><br><span class="line">[root@hadoop104 module]# source /etc/profile</span><br></pre></td></tr></table></figure>

<p>（7）启动集群</p>
<p>必须先启动Zookeeper集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 profile.d]# zk.sh start</span><br><span class="line"></span><br><span class="line">[root@hadoop102 profile.d]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">4788 QuorumPeerMain</span><br><span class="line">4863 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">4449 Jps</span><br><span class="line">4377 QuorumPeerMain</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">4336 QuorumPeerMain</span><br><span class="line">4401 Jps</span><br></pre></td></tr></table></figure>

<p>然后依次在102，103，104节点上启动kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line">[root@hadoop103 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line">[root@hadoop104 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动成功</span></span><br><span class="line">[root@hadoop102 kafka]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">5392 Jps</span><br><span class="line">4788 QuorumPeerMain</span><br><span class="line">5252 Kafka</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">4949 Jps</span><br><span class="line">4840 Kafka</span><br><span class="line">4377 QuorumPeerMain</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">4336 QuorumPeerMain</span><br><span class="line">4896 Jps</span><br><span class="line">4807 Kafka</span><br></pre></td></tr></table></figure>

<p>（8）关闭集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-server-stop.sh </span><br><span class="line">[root@hadoop103 kafka]# bin/kafka-server-stop.sh </span><br><span class="line">[root@hadoop104 kafka]# bin/kafka-server-stop.sh</span><br><span class="line"></span><br><span class="line">[root@hadoop102 kafka]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">5553 Jps</span><br><span class="line">4788 QuorumPeerMain</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">5121 Jps</span><br><span class="line">4377 QuorumPeerMain</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">4336 QuorumPeerMain</span><br><span class="line">5093 Jps</span><br></pre></td></tr></table></figure>

<h3 id="2-1-3-集群启停脚本"><a href="#2-1-3-集群启停脚本" class="headerlink" title="2.1.3 集群启停脚本"></a>2.1.3 集群启停脚本</h3><p>（1）在&#x2F;bin 目录下创建文件 kf.sh 脚本文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# vim kf.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">     for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">     do</span><br><span class="line">         echo &quot; --------启动 $i Kafka-------&quot;</span><br><span class="line">         ssh $i &quot;/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties&quot;</span><br><span class="line">     done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">     for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">     do</span><br><span class="line">         echo &quot; --------停止 $i Kafka-------&quot;</span><br><span class="line">         ssh $i &quot;/opt/module/kafka/bin/kafka-server-stop.sh &quot;</span><br><span class="line">     done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>（2）添加执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# chmod 777 kf.sh</span><br></pre></td></tr></table></figure>

<p>（3）启动集群命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# kf.sh start</span><br><span class="line"> --------启动 hadoop102 Kafka-------</span><br><span class="line"> --------启动 hadoop103 Kafka-------</span><br><span class="line"> --------启动 hadoop104 Kafka-------</span><br><span class="line">[root@hadoop102 bin]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">4788 QuorumPeerMain</span><br><span class="line">6004 Kafka</span><br><span class="line">6100 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">5554 Kafka</span><br><span class="line">4377 QuorumPeerMain</span><br><span class="line">5647 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">4336 QuorumPeerMain</span><br><span class="line">5623 Jps</span><br><span class="line">5535 Kafka</span><br></pre></td></tr></table></figure>

<p><strong>注意zookeeper和kafa集群的启停顺序：</strong></p>
<p>停止 Kafka 集群时，一定要等 Kafka 所有节点进程全部停止后再停止 Zookeeper集群。因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止，Kafka 集群就没有办法再获取停止进程的信息，只能手动杀死 Kafka 进程了。</p>
<p>①zookeeper启动     zk.sh start</p>
<p>②kafka启动            kf.sh start</p>
<p>③kafka停止            kf.sh stop</p>
<p>④zookeeper停止    zk.sh stop</p>
<h2 id="2-2-Kafka命令行操作"><a href="#2-2-Kafka命令行操作" class="headerlink" title="2.2 Kafka命令行操作"></a>2.2 Kafka命令行操作</h2><img src="Snipaste_2023-10-23_14-24-00.png" alt="Snipaste_2023-10-23_14-24-00" style="zoom:50%;">

<h3 id="2-2-1-主题命令行操作"><a href="#2-2-1-主题命令行操作" class="headerlink" title="2.2.1 主题命令行操作"></a>2.2.1 主题命令行操作</h3><p>（1）查看操作主题命令参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-23_14-52-01.png" alt="Snipaste_2023-10-23_14-52-01" style="zoom:43%;">

<p>（2）查看当前服务器中的所有 topic（当前为空）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --list</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（3）创建first topic</p>
<p>topic名称为first，分区数为1，分区副本为3</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --topic first --partitions 1 --replication-factor 3</span><br><span class="line">Created topic first.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看副本</span></span><br><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --list</span><br><span class="line">first</span><br></pre></td></tr></table></figure>

<p>（4）查看first主题的详情</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic first</span><br><span class="line">Topic: first	TopicId: VV7ddVy4SKyTQauf1IHvag	PartitionCount: 1	ReplicationFactor: 3	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: first	Partition: 0	Leader: 2	Replicas: 2,1,0	Isr: 2,1,0</span><br></pre></td></tr></table></figure>

<p>（5）修改分区数（注意：分区数只能增加，不能减少）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --topic first --alter --partitions 3</span><br></pre></td></tr></table></figure>

<p>（6）再次查看详情</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic first</span><br><span class="line">Topic: first	TopicId: VV7ddVy4SKyTQauf1IHvag	PartitionCount: 3	ReplicationFactor: 3	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: first	Partition: 0	Leader: 2	Replicas: 2,1,0	Isr: 2,1,0</span><br><span class="line">	Topic: first	Partition: 1	Leader: 0	Replicas: 0,1,2	Isr: 0,1,2</span><br><span class="line">	Topic: first	Partition: 2	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-生产者命令行操作"><a href="#2-2-2-生产者命令行操作" class="headerlink" title="2.2.2 生产者命令行操作"></a>2.2.2 生产者命令行操作</h3><p>（1）查看操作生产者命令参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-producer.sh</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-23_15-12-51.png" alt="Snipaste_2023-10-23_15-12-51" style="zoom:43%;">

<p>（2）发送消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic first</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hello</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">atguigu</span></span><br></pre></td></tr></table></figure>

<h3 id="2-2-3-消费者命令行操作"><a href="#2-2-3-消费者命令行操作" class="headerlink" title="2.2.3 消费者命令行操作"></a>2.2.3 消费者命令行操作</h3><p>（1）查看操作消费者命令参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-23_15-18-16.png" alt="Snipaste_2023-10-23_15-18-16" style="zoom:43%;">

<p>（2）消费数据</p>
<p>消费 first 主题中的数据（只是增量数据，历史数据不显示）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first </span><br></pre></td></tr></table></figure>

<p>把主题中所有的数据都读取出来（包括历史数据）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --from-beginning</span><br><span class="line">hello</span><br><span class="line">atguigu</span><br></pre></td></tr></table></figure>

<p><strong>此时在生产者端输入一条数据，消费者端就能在对应的topic下收到一条数据。</strong></p>
<h1 id="第三章-Kafka的生产者"><a href="#第三章-Kafka的生产者" class="headerlink" title="第三章 Kafka的生产者"></a>第三章 Kafka的生产者</h1><h2 id="3-1-生产者消息发送流程"><a href="#3-1-生产者消息发送流程" class="headerlink" title="3.1 生产者消息发送流程"></a>3.1 生产者消息发送流程</h2><h3 id="3-1-1-发送原理"><a href="#3-1-1-发送原理" class="headerlink" title="3.1.1 发送原理"></a>3.1.1 发送原理</h3><p>在消息发送的过程中，涉及到了<strong>两个线程——****main</strong> <strong>线程和</strong> <strong>Sender</strong> <strong>线程</strong>。在 main 线程中创建了<strong>一个双端队列</strong> <strong>RecordAccumulator</strong>。main 线程将消息发送给 RecordAccumulator，Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka Broker。</p>
<p><img src="Snipaste_2023-10-23_15-38-44.png" alt="Snipaste_2023-10-23_15-38-44"></p>
<h3 id="3-1-2-生产者重要参数列表"><a href="#3-1-2-生产者重要参数列表" class="headerlink" title="3.1.2 生产者重要参数列表"></a>3.1.2 生产者重要参数列表</h3><table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>bootstrap.servers</td>
<td>生产者连接集群所需的 broker 地址清单 。 例 如hadoop102:9092,hadoop103:9092,hadoop104:9092，可以设置 1 个或者多个，中间用逗号隔开。注意这里并非需要所有的 broker 地址，因为生产者从给定的 broker里查找到其他 broker 信息</td>
</tr>
<tr>
<td>key.serializer 和 value.serializer</td>
<td>指定发送消息的 key 和 value 的序列化类型。一定要写全类名</td>
</tr>
<tr>
<td>buffer.memory</td>
<td>RecordAccumulator 缓冲区总大小，默认 32m</td>
</tr>
<tr>
<td>batch.size</td>
<td>缓冲区一批数据最大值，默认 16k。适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加</td>
</tr>
<tr>
<td>linger.ms</td>
<td>如果数据迟迟未达到 batch.size，sender 等待 linger.time之后就会发送数据。单位 ms，默认值是 0ms，表示没有延迟。生产环境建议该值大小为 5-100ms 之间</td>
</tr>
<tr>
<td>acks</td>
<td>0：生产者发送过来的数据，不需要等数据落盘应答<br>1：生产者发送过来的数据，Leader 收到数据后应答<br>-1（all）：生产者发送过来的数据，Leader+和 isr 队列里面的所有节点收齐数据后应答。默认值是-1，-1 和all 是等价的。</td>
</tr>
<tr>
<td>max.in.flight.requests.per.connection</td>
<td>允许最多没有返回 ack 的次数，默认为 5，开启幂等性要保证该值是 1-5 的数字</td>
</tr>
<tr>
<td>retries</td>
<td>当消息发送出现错误的时候，系统会重发消息。retries表示重试次数。默认是 int 最大值，2147483647。如果设置了重试，还想保证消息的有序性，需要设置MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION&#x3D;1否则在重试此失败消息的时候，其他的消息可能发送成功了</td>
</tr>
<tr>
<td>retry.backoff.ms</td>
<td>两次重试之间的时间间隔，默认是 100ms</td>
</tr>
<tr>
<td>enable.idempotence</td>
<td>是否开启幂等性，默认 true，开启幂等性</td>
</tr>
<tr>
<td>compression.type</td>
<td>生产者发送的所有数据的压缩方式。默认是 none，也就是不压缩。支持压缩类型：none、gzip、snappy、lz4 和 zstd。</td>
</tr>
</tbody></table>
<h2 id="3-2-异步发送API"><a href="#3-2-异步发送API" class="headerlink" title="3.2 异步发送API"></a>3.2 异步发送API</h2><h3 id="3-2-1-普通异步发送"><a href="#3-2-1-普通异步发送" class="headerlink" title="3.2.1 普通异步发送"></a>3.2.1 普通异步发送</h3><p>（1）需求：创建 Kafka 生产者，采用异步的方式发送到 Kafka Broker，也就是从kafka Producer到RecordAccumulator实现异步发送。</p>
<p>（2）代码编写</p>
<p>①创建maven工程kafka</p>
<p>②导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>③创建包名：com.atguigu.kafka.producer</p>
<p>④编写不带回调函数的 API 代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定key-value序列化类型</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用 send 方法,发送消息，不带回调信息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="string">&quot;atguigu &quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        往first主题中发送：</span></span><br><span class="line"><span class="comment">        atguigu0</span></span><br><span class="line"><span class="comment">        atguigu1</span></span><br><span class="line"><span class="comment">        atguigu2</span></span><br><span class="line"><span class="comment">        atguigu3</span></span><br><span class="line"><span class="comment">        atguigu4</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<p>在102上开启kafka消费者，运行java代码，观察hadoop102上的kafka消费者能否接收到消息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first </span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 4</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-带回调函数的异步发送"><a href="#3-2-2-带回调函数的异步发送" class="headerlink" title="3.2.2 带回调函数的异步发送"></a>3.2.2 带回调函数的异步发送</h3><p>回调函数会在 producer 收到 ack 时调用，为异步调用，该方法有两个参数，分别是元数据信息（RecordMetadata）和异常信息（Exception），如果 Exception 为 null，说明消息发送成功，如果 Exception 不为 null，说明消息发送失败。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallback</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定key-value序列化类型</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用 send 方法,发送消息，带回调信息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="string">&quot;atguigu &quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="comment">// 该方法在 Producer 收到 ack 时调用，为异步调用</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        <span class="comment">// 没有异常,输出信息到控制台</span></span><br><span class="line">                        System.out.println(<span class="string">&quot; 主题： &quot;</span> +</span><br><span class="line">                                metadata.topic() + <span class="string">&quot;-&gt;&quot;</span> + <span class="string">&quot;分区：&quot;</span> + metadata.partition());</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 出现异常打印</span></span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            <span class="comment">// 延迟一会会看到数据发往不同分区</span></span><br><span class="line">            Thread.sleep(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        往first主题中发送：</span></span><br><span class="line"><span class="comment">        atguigu0</span></span><br><span class="line"><span class="comment">        atguigu1</span></span><br><span class="line"><span class="comment">        atguigu2</span></span><br><span class="line"><span class="comment">        atguigu3</span></span><br><span class="line"><span class="comment">        atguigu4</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<p>①在hadoop102上开启kafka消费者</p>
<p>②在IDEA中执行代码，观察102控制台是否收到消息，因为异步发送且设定了延迟，所以数据不一定按顺序到达消费者端</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first </span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 4</span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 2</span><br></pre></td></tr></table></figure>

<p>③在IDEA控制台观察回调信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：2</span><br><span class="line">主题： first-&gt;分区：2</span><br><span class="line">主题： first-&gt;分区：2</span><br></pre></td></tr></table></figure>

<h2 id="3-3-同步发送API"><a href="#3-3-同步发送API" class="headerlink" title="3.3 同步发送API"></a>3.3 同步发送API</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerSync</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定key-value序列化类型</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用 send.get()方法,发送消息，采用的就是同步发送</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="string">&quot;atguigu &quot;</span> + i)).get();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        往first主题中发送：</span></span><br><span class="line"><span class="comment">        atguigu0</span></span><br><span class="line"><span class="comment">        atguigu1</span></span><br><span class="line"><span class="comment">        atguigu2</span></span><br><span class="line"><span class="comment">        atguigu3</span></span><br><span class="line"><span class="comment">        atguigu4</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<p>在102上开启kafka消费者，运行java代码，观察hadoop102上的kafka消费者能否接收到消息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first </span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 4</span><br></pre></td></tr></table></figure>

<h2 id="3-4-生产者分区"><a href="#3-4-生产者分区" class="headerlink" title="3.4 生产者分区"></a>3.4 生产者分区</h2><h3 id="3-4-1-分区好处"><a href="#3-4-1-分区好处" class="headerlink" title="3.4.1 分区好处"></a>3.4.1 分区好处</h3><p>（1）<strong>便于合理使用存储资源</strong>，每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一块一块数据存储在多台Broker上。合理控制分区的任务，可以实现负载均衡的效果。</p>
<p>（2）<strong>提高并行度</strong>，生产者可以以分区为单位发送数据；消费者可以以分区为单位进行消费数据。</p>
<img src="Snipaste_2023-10-23_19-58-33.png" alt="Snipaste_2023-10-23_19-58-33" style="zoom:43%;">

<h3 id="3-4-2-生产者发送消息的分区策略"><a href="#3-4-2-生产者发送消息的分区策略" class="headerlink" title="3.4.2 生产者发送消息的分区策略"></a>3.4.2 生产者发送消息的分区策略</h3><p>（1）默认的分区器DefaultPartitioner</p>
<img src="Snipaste_2023-10-23_20-07-52.png" alt="Snipaste_2023-10-23_20-07-52" style="zoom:50%;">

<p><img src="Snipaste_2023-10-23_20-11-26.png" alt="Snipaste_2023-10-23_20-11-26"></p>
<p>（2）案例1：</p>
<p>将数据发往指定 partition 的情况下，例如，将所有数据发往分区 1 中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallbackPartitions</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定key-value序列化类型</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用 send 方法,发送消息，带回调信息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            <span class="comment">// 指定数据发送到 1 号分区，key 为空</span></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="number">1</span>, <span class="string">&quot;&quot;</span>, <span class="string">&quot;atguigu &quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="comment">// 该方法在 Producer 收到 ack 时调用，为异步调用</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        <span class="comment">// 没有异常,输出信息到控制台</span></span><br><span class="line">                        System.out.println(<span class="string">&quot; 主题： &quot;</span> +</span><br><span class="line">                                metadata.topic() + <span class="string">&quot;-&gt;&quot;</span> + <span class="string">&quot;分区：&quot;</span> + metadata.partition());</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 出现异常打印</span></span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            <span class="comment">// 延迟一会会看到数据发往不同分区</span></span><br><span class="line"><span class="comment">//            Thread.sleep(2);</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        往first主题中发送：</span></span><br><span class="line"><span class="comment">        atguigu0</span></span><br><span class="line"><span class="comment">        atguigu1</span></span><br><span class="line"><span class="comment">        atguigu2</span></span><br><span class="line"><span class="comment">        atguigu3</span></span><br><span class="line"><span class="comment">        atguigu4</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<p>在hadoop102上开启kafka消费者并观察其控制台：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first </span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 4</span><br></pre></td></tr></table></figure>

<p>在IDEA控制台观察回调信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题： first-&gt;分区：1</span><br><span class="line">主题： first-&gt;分区：1</span><br><span class="line">主题： first-&gt;分区：1</span><br><span class="line">主题： first-&gt;分区：1</span><br><span class="line">主题： first-&gt;分区：1</span><br></pre></td></tr></table></figure>

<p>（3）案例2：</p>
<p>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallback</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定key-value序列化类型</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用 send 方法,发送消息，带回调信息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            <span class="comment">// 依次指定 key 值为 a,b,f ，数据 key 的 hash 值与 3 个分区求余，分别发往 1、2、0</span></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;a&quot;</span>,<span class="string">&quot;atguigu &quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="comment">// 该方法在 Producer 收到 ack 时调用，为异步调用</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        <span class="comment">// 没有异常,输出信息到控制台</span></span><br><span class="line">                        System.out.println(<span class="string">&quot; 主题： &quot;</span> +</span><br><span class="line">                                metadata.topic() + <span class="string">&quot;-&gt;&quot;</span> + <span class="string">&quot;分区：&quot;</span> + metadata.partition());</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 出现异常打印</span></span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            <span class="comment">// 延迟一会会看到数据发往不同分区</span></span><br><span class="line">            Thread.sleep(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        往first主题中发送：</span></span><br><span class="line"><span class="comment">        atguigu0</span></span><br><span class="line"><span class="comment">        atguigu1</span></span><br><span class="line"><span class="comment">        atguigu2</span></span><br><span class="line"><span class="comment">        atguigu3</span></span><br><span class="line"><span class="comment">        atguigu4</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<p>①key&#x3D;”a”时，在控制台查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题：first-&gt;分区：1</span><br><span class="line">主题：first-&gt;分区：1</span><br><span class="line">主题：first-&gt;分区：1</span><br><span class="line">主题：first-&gt;分区：1</span><br><span class="line">主题：first-&gt;分区：1</span><br></pre></td></tr></table></figure>

<p>②key&#x3D;”b”时，在控制台查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题：first-&gt;分区：2</span><br><span class="line">主题：first-&gt;分区：2</span><br><span class="line">主题：first-&gt;分区：2</span><br><span class="line">主题：first-&gt;分区：2</span><br><span class="line">主题：first-&gt;分区：2</span><br></pre></td></tr></table></figure>

<p>③key&#x3D;”f”时，在控制台查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题：first-&gt;分区：0</span><br><span class="line">主题：first-&gt;分区：0</span><br><span class="line">主题：first-&gt;分区：0</span><br><span class="line">主题：first-&gt;分区：0</span><br><span class="line">主题：first-&gt;分区：0</span><br></pre></td></tr></table></figure>

<h3 id="3-4-3-自定义分区器"><a href="#3-4-3-自定义分区器" class="headerlink" title="3.4.3 自定义分区器"></a>3.4.3 自定义分区器</h3><p>如果研发人员可以根据企业需求，自己重新实现分区器。</p>
<p>（1）需求</p>
<p>例如我们实现一个分区器实现，发送过来的数据中如果包含 atguigu，就发往 0 号分区，不包含 atguigu，就发往 1 号分区。</p>
<p>（2）实现步骤</p>
<p>编写MyPartitioner类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 返回信息对应的分区</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic 主题</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key 消息的 key</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> keyBytes 消息的 key 序列化后的字节数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value 消息的 value</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> valueBytes 消息的 value 序列化后的字节数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cluster 集群元数据可以查看分区信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取消息</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">msgValue</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建 partition</span></span><br><span class="line">        <span class="type">int</span> partition;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断消息是否包含 atguigu</span></span><br><span class="line">        <span class="keyword">if</span> (msgValue.contains(<span class="string">&quot;atguigu&quot;</span>))&#123;</span><br><span class="line">            partition = <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            partition = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 返回分区号</span></span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 关闭资源</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 配置方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用分区器的方法，在生产者的配置中添加分区器参数</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallbackPartitions</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定key-value序列化类型</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//添加自定义分区器</span></span><br><span class="line">        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,<span class="string">&quot;com.atguigu.kafka.producer.MyPartitioner&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用 send 方法,发送消息，带回调信息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;atguigu &quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="comment">// 该方法在 Producer 收到 ack 时调用，为异步调用</span></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        <span class="comment">// 没有异常,输出信息到控制台</span></span><br><span class="line">                        System.out.println(<span class="string">&quot; 主题： &quot;</span> +</span><br><span class="line">                                metadata.topic() + <span class="string">&quot;-&gt;&quot;</span> + <span class="string">&quot;分区：&quot;</span> + metadata.partition());</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 出现异常打印</span></span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            <span class="comment">// 延迟一会会看到数据发往不同分区</span></span><br><span class="line"><span class="comment">//            Thread.sleep(2);</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        往first主题中发送：</span></span><br><span class="line"><span class="comment">        atguigu0</span></span><br><span class="line"><span class="comment">        atguigu1</span></span><br><span class="line"><span class="comment">        atguigu2</span></span><br><span class="line"><span class="comment">        atguigu3</span></span><br><span class="line"><span class="comment">        atguigu4</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<p>在hadoop102上开启kafka消费者，在IDEA控制台观察回调信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br></pre></td></tr></table></figure>

<h2 id="3-5-生产经验——生产者如何提高吞吐量"><a href="#3-5-生产经验——生产者如何提高吞吐量" class="headerlink" title="3.5 生产经验——生产者如何提高吞吐量"></a>3.5 生产经验——生产者如何提高吞吐量</h2><img src="Snipaste_2023-10-23_21-08-48.png" alt="Snipaste_2023-10-23_21-08-48" style="zoom: 50%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerParameters</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// key,value 序列化（必须）：key.serializer，value.serializer</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//以上4个是必须配置的</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// batch.size：批次大小，默认 16K</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// linger.ms：等待时间，默认 0</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RecordAccumulator：缓冲区大小，默认 32M：buffer.memory</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// compression.type：压缩，默认 none，可配置值 gzip、snappy、lz4 和 zstd</span></span><br><span class="line">        properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG,<span class="string">&quot;snappy&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用 send 方法,发送消息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="string">&quot;atguigu &quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<p>在hadoop102上开启kafka消费者，在IDEA中执行java代码，观察hadoop102控制台中是否收到消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first</span><br><span class="line">atguigu 0</span><br><span class="line">atguigu 1</span><br><span class="line">atguigu 2</span><br><span class="line">atguigu 3</span><br><span class="line">atguigu 4</span><br></pre></td></tr></table></figure>

<h2 id="3-6-生产经验——数据可靠性"><a href="#3-6-生产经验——数据可靠性" class="headerlink" title="3.6 生产经验——数据可靠性"></a>3.6 生产经验——数据可靠性</h2><p>（0）回顾</p>
<p><img src="Snipaste_2023-10-23_15-38-44.png" alt="Snipaste_2023-10-23_15-38-44"></p>
<p>（1）ack应答原理</p>
<p><img src="Snipaste_2023-10-23_21-24-39.png" alt="Snipaste_2023-10-23_21-24-39"></p>
<p><img src="Snipaste_2023-10-23_21-25-48.png" alt="Snipaste_2023-10-23_21-25-48"></p>
<p><img src="Snipaste_2023-10-23_21-28-28.png" alt="Snipaste_2023-10-23_21-28-28"></p>
<p>（2）代码配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerAck</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定key-value序列化类型</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置 acks</span></span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG, <span class="string">&quot;all&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 重试次数 retries，默认是 int 最大值，2147483647</span></span><br><span class="line">        properties.put(ProducerConfig.RETRIES_CONFIG, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 调用 send 方法,发送消息，不带回调信息</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="string">&quot;atguigu &quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        往first主题中发送：</span></span><br><span class="line"><span class="comment">        atguigu0</span></span><br><span class="line"><span class="comment">        atguigu1</span></span><br><span class="line"><span class="comment">        atguigu2</span></span><br><span class="line"><span class="comment">        atguigu3</span></span><br><span class="line"><span class="comment">        atguigu4</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-7-生产经验——数据去重"><a href="#3-7-生产经验——数据去重" class="headerlink" title="3.7 生产经验——数据去重"></a>3.7 生产经验——数据去重</h2><h3 id="3-7-1-数据传递语义"><a href="#3-7-1-数据传递语义" class="headerlink" title="3.7.1 数据传递语义"></a>3.7.1 数据传递语义</h3><p><img src="Snipaste_2023-10-23_21-38-00.png" alt="Snipaste_2023-10-23_21-38-00"></p>
<h3 id="3-7-2-幂等性"><a href="#3-7-2-幂等性" class="headerlink" title="3.7.2 幂等性"></a>3.7.2 幂等性</h3><p>（1）幂等性原理</p>
<p><img src="Snipaste_2023-10-23_21-41-19.png" alt="Snipaste_2023-10-23_21-41-19"></p>
<p>（2）如何使用幂等性</p>
<p>开启参数 <strong>enable.idempotence</strong> 默认为 true，false 关闭</p>
<h3 id="3-7-3-生产者事务"><a href="#3-7-3-生产者事务" class="headerlink" title="3.7.3 生产者事务"></a>3.7.3 生产者事务</h3><p>（1）kafka事务原理</p>
<p><img src="Snipaste_2023-10-23_21-43-04.png" alt="Snipaste_2023-10-23_21-43-04"></p>
<p>（2）kafaka的事务一共有如下5个API</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1 初始化事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">initTransactions</span><span class="params">()</span>;</span><br><span class="line"><span class="comment">// 2 开启事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br><span class="line"><span class="comment">// 3 在事务内提交已经消费的偏移量（主要用于消费者）</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets,String consumerGroupId)</span> <span class="keyword">throws</span> </span><br><span class="line">ProducerFencedException;</span><br><span class="line"><span class="comment">// 4 提交事务</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">commitTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br><span class="line"><span class="comment">// 5 放弃事务（类似于回滚事务的操作）</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">abortTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br></pre></td></tr></table></figure>

<p>（3）代码实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerTransactions</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 创建 kafka 生产者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 给 kafka 配置对象添加配置信息：bootstrap.servers</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定key-value序列化类型</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置事务 id（必须），事务 id 任意起名</span></span><br><span class="line">        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, <span class="string">&quot;transaction_id_0&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 kafka 生产者对象</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 初始化事务</span></span><br><span class="line">        kafkaProducer.initTransactions();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 开启事务</span></span><br><span class="line">        kafkaProducer.beginTransaction();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 4. 调用 send 方法,发送消息，不带回调信息</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">                kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="string">&quot;atguigu &quot;</span> + i));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 提交事务</span></span><br><span class="line">            kafkaProducer.commitTransaction();</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            <span class="comment">// 终止事务</span></span><br><span class="line">            kafkaProducer.abortTransaction();</span><br><span class="line">        &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 5. 关闭资源</span></span><br><span class="line">            kafkaProducer.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>102的控制台成功收到消息。</p>
<h2 id="3-8-生产经验——数据乱序"><a href="#3-8-生产经验——数据乱序" class="headerlink" title="3.8 生产经验——数据乱序"></a>3.8 生产经验——数据乱序</h2><p><img src="Snipaste_2023-10-23_21-58-03.png" alt="Snipaste_2023-10-23_21-58-03"></p>
<p><img src="Snipaste_2023-10-23_21-58-32.png" alt="Snipaste_2023-10-23_21-58-32"></p>
<p><strong>max.in.flight.requests.per.connection</strong>就是上图Request的个数，如果没有开启幂等性，设置为1说明缓存只有一个请求，只有该请求成功成功ack之后才能处理下一个请求，所以强制保证了请求按顺序到达，数据也是按顺序提交给消费者的。</p>
<p>如果开启了幂等性，幂等性中有SeqNumber，它是单调递增的，集群收到的数据如果SeqNumber非单调递增，它会在服务端重新排序，保证单调递增再传递，所以这也保证了数据的按序传递。而为什么<strong>max.in.flight.requests.per.connection</strong>最大设置成5，是因为启用幂等性后最多在kafka集群缓存生产者发送的5个request，也就是保证了最近5个request数据一定有序，超过5个就不保证了。</p>
<h1 id="第四章-Kafka-Broker"><a href="#第四章-Kafka-Broker" class="headerlink" title="第四章 Kafka Broker"></a>第四章 Kafka Broker</h1><h2 id="4-1-Kafka-Broker工作流程"><a href="#4-1-Kafka-Broker工作流程" class="headerlink" title="4.1 Kafka Broker工作流程"></a>4.1 Kafka Broker工作流程</h2><h3 id="4-1-1-Zookeeper存储的Kafka信息"><a href="#4-1-1-Zookeeper存储的Kafka信息" class="headerlink" title="4.1.1 Zookeeper存储的Kafka信息"></a>4.1.1 Zookeeper存储的Kafka信息</h3><p>（1）启动 Zookeeper 客户端</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/zookeeper-3.5.7/</span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# bin/zkCli.sh</span><br></pre></td></tr></table></figure>

<p>（2）通过 ls 命令可以查看 kafka 相关信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /kafka</span><br><span class="line">[admin, brokers, cluster, config, consumers, controller, controller_epoch, feature, isr_change_notification, latest_producer_id_block, log_dir_event_notification]</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 4] ls /kafka/brokers/ids</span><br><span class="line">[0, 1, 2]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以上0，1，2表示brokerid，分别代表hadoop102,hadoop103,hadoop104</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-24_12-42-44.png" alt="Snipaste_2023-10-24_12-42-44"></p>
<p>也可以使用prettyZoo更方便地查看Zookeeper的节点信息：</p>
<img src="Snipaste_2023-10-24_12-30-53.png" alt="Snipaste_2023-10-24_12-30-53" style="zoom: 33%;">

<img src="Snipaste_2023-10-24_12-33-09.png" alt="Snipaste_2023-10-24_12-33-09" style="zoom:43%;">

<img src="Snipaste_2023-10-24_12-37-56.png" alt="Snipaste_2023-10-24_12-37-56" style="zoom: 40%;">

<img src="Snipaste_2023-10-24_12-42-13.png" alt="Snipaste_2023-10-24_12-42-13" style="zoom:40%;">

<h3 id="4-1-2-Kafka-Broker总体工作流程"><a href="#4-1-2-Kafka-Broker总体工作流程" class="headerlink" title="4.1.2 Kafka Broker总体工作流程"></a>4.1.2 Kafka Broker总体工作流程</h3><p><img src="Snipaste_2023-10-24_12-50-24.png" alt="Snipaste_2023-10-24_12-50-24"></p>
<p>（1）模拟Kafka上下线，Zookeeper中数据变化</p>
<p>①目前看&#x2F;kafka&#x2F;brokers&#x2F;ids 路径上的节点：</p>
<img src="Snipaste_2023-10-24_12-53-35.png" alt="Snipaste_2023-10-24_12-53-35" style="zoom:43%;">

<p>②查看&#x2F;kafka&#x2F;controller 路径上的数据：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;brokerid&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1698120266977&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>③查看&#x2F;kafka&#x2F;brokers&#x2F;topics&#x2F;first&#x2F;partitions&#x2F;0&#x2F;state 路径上的数据：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;controller_epoch&quot;</span> <span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;leader&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;leader_epoch&quot;</span> <span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;isr&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">0</span><span class="punctuation">,</span> <span class="number">1</span> <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>④停止 hadoop104 上的 kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 kafka]# bin/kafka-server-stop.sh</span><br><span class="line">[root@hadoop104 kafka]# jps</span><br><span class="line">3856 Jps</span><br><span class="line">2737 QuorumPeerMain</span><br></pre></td></tr></table></figure>

<p>⑤再次查看&#x2F;kafka&#x2F;brokers&#x2F;ids 路径上的节点（Hadoop04对应ids&#x3D;2，已经没了）</p>
<img src="Snipaste_2023-10-24_12-57-31.png" alt="Snipaste_2023-10-24_12-57-31" style="zoom:43%;">

<p>⑥再次查看&#x2F;kafka&#x2F;controller 路径上的数据</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;brokerid&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1698120266977&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>⑦再次查看&#x2F;kafka&#x2F;brokers&#x2F;topics&#x2F;first&#x2F;partitions&#x2F;0&#x2F;state 路径上的数据。此时leader已经变成1了</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;controller_epoch&quot;</span> <span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;leader&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;leader_epoch&quot;</span> <span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;isr&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="number">0</span><span class="punctuation">,</span> <span class="number">1</span> <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>⑧启动hadoop104上的Kafka，再次观察①②③步骤中的内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 kafka]# bin/kafka-server-start.sh -daemon ./config/server.properties</span><br><span class="line">[root@hadoop104 kafka]# jps</span><br><span class="line">2737 QuorumPeerMain</span><br><span class="line">4273 Kafka</span><br><span class="line">4361 Jps</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-24_12-53-35.png" alt="Snipaste_2023-10-24_12-53-35" style="zoom:43%;">

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;brokerid&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1698120266977&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;controller_epoch&quot;</span> <span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;leader&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;leader_epoch&quot;</span> <span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;isr&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="number">0</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span> <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-1-3-Broker重要参数"><a href="#4-1-3-Broker重要参数" class="headerlink" title="4.1.3 Broker重要参数"></a>4.1.3 Broker重要参数</h3><table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>replica.lag.time.max.ms</td>
<td>ISR 中，如果 Follower 长时间未向 Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。该时间阈值，默认 30s。</td>
</tr>
<tr>
<td>auto.leader.rebalance.enable</td>
<td>默认是 true。 自动 Leader Partition 平衡。</td>
</tr>
<tr>
<td>leader.imbalance.per.broker.percentage</td>
<td>默认是 10%。每个 broker 允许的不平衡的 leader的比率。如果每个 broker 超过了这个值，控制器会触发 leader 的平衡。</td>
</tr>
<tr>
<td>leader.imbalance.check.interval.seconds</td>
<td>默认值 300 秒。检查 leader 负载是否平衡的间隔时间。</td>
</tr>
<tr>
<td>log.segment.bytes</td>
<td>Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分 成块的大小，默认值 1G。</td>
</tr>
<tr>
<td>log.index.interval.bytes</td>
<td>默认 4kb，kafka 里面每当写入了 4kb 大小的日志（.log），然后就往 index 文件里面记录一个索引。</td>
</tr>
<tr>
<td>log.retention.hours</td>
<td>Kafka 中数据保存的时间，默认 7 天。</td>
</tr>
<tr>
<td>log.retention.minutes</td>
<td>Kafka 中数据保存的时间，分钟级别，默认关闭。</td>
</tr>
<tr>
<td>log.retention.ms</td>
<td>Kafka 中数据保存的时间，毫秒级别，默认关闭。</td>
</tr>
<tr>
<td>log.retention.check.interval.ms</td>
<td>检查数据是否保存超时的间隔，默认是 5 分钟。</td>
</tr>
<tr>
<td>log.retention.bytes</td>
<td>默认等于-1，表示无穷大。超过设置的所有日志总大小，删除最早的 segment。</td>
</tr>
<tr>
<td>log.cleanup.policy</td>
<td>默认是 delete，表示所有数据启用删除策略；如果设置值为 compact，表示所有数据启用压缩策略</td>
</tr>
<tr>
<td>num.io.threads</td>
<td>默认是 8。负责写磁盘的线程数。整个参数值要占总核数的 50%。</td>
</tr>
<tr>
<td>num.replica.fetchers</td>
<td>副本拉取线程数，这个参数占总核数的 50%的 1&#x2F;3</td>
</tr>
<tr>
<td>num.network.threads</td>
<td>默认是 3。数据传输线程数，这个参数占总核数的50%的 2&#x2F;3 。</td>
</tr>
<tr>
<td>log.flush.interval.messages</td>
<td>强制页缓存刷写到磁盘的条数，默认是 long 的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。</td>
</tr>
<tr>
<td>log.flush.interval.ms</td>
<td>每隔多久，刷数据到磁盘，默认是 null。一般不建议修改，交给系统自己管理。</td>
</tr>
</tbody></table>
<h2 id="4-2-生产经验——节点服役和退役"><a href="#4-2-生产经验——节点服役和退役" class="headerlink" title="4.2 生产经验——节点服役和退役"></a>4.2 生产经验——节点服役和退役</h2><h3 id="4-2-1-服役新节点"><a href="#4-2-1-服役新节点" class="headerlink" title="4.2.1 服役新节点"></a>4.2.1 服役新节点</h3><p>（1）新节点准备</p>
<p>①关机hadoop104，右键执行克隆操作</p>
<p>②开启hadoop105，并修改IP地址</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">IP地址</span></span><br><span class="line">IPADDR=192.168.255.105</span><br></pre></td></tr></table></figure>

<p>③在hadoop105上，修改主机名称为hadoop105</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 ~]# vim /etc/hostname</span><br><span class="line">hadoop105</span><br></pre></td></tr></table></figure>

<p>④重启104，105</p>
<p>⑤删除 hadoop105 中 kafka 下的 datas 和 logs。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 kafka]# rm -rf datas/* logs/*</span><br></pre></td></tr></table></figure>

<p>⑥修改hadoop105中kafka的broker.id 为 3</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 config]# vim server.properties</span><br></pre></td></tr></table></figure>

<p>⑦启动102，103，104上的kafka集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 zookeeper-3.5.7]# zk.sh start</span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# kf.sh start</span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">5032 Kafka</span><br><span class="line">4618 QuorumPeerMain</span><br><span class="line">5131 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">4977 Jps</span><br><span class="line">4469 QuorumPeerMain</span><br><span class="line">4861 Kafka</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">3345 Jps</span><br><span class="line">2852 QuorumPeerMain</span><br><span class="line">3239 Kafka</span><br></pre></td></tr></table></figure>

<p>⑧单独启动105中的kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line">[root@hadoop105 kafka]# jps</span><br><span class="line">3187 Jps</span><br><span class="line">3102 Kafka</span><br></pre></td></tr></table></figure>

<p>（2）执行负载均衡操作</p>
<p>①创建一个要均衡的主题</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# vim topics-to-move.json</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">     <span class="attr">&quot;topics&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">     	<span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span> <span class="string">&quot;first&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>②生成一个负载均衡的计划：【–broker-list “0,1,2,3”】</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --topics-to-move-json-file topics-to-move.json --broker-list &quot;0,1,2,3&quot; --generate</span><br><span class="line">Current partition replica assignment</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[2,1,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,2,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,3,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1,0,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[2,1,3],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p>③创建副本存储计划（所有副本存储在 broker0、broker1、broker2、broker3 中）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]#  vim increase-replication-factor.json</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;first&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;log_dirs&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;first&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="number">0</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;log_dirs&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;first&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;log_dirs&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>④执行副本存储计划。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[2,1,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,2,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignments for first-0,first-1,first-2</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>⑤验证副本存储计划</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition first-0 is complete.</span><br><span class="line">Reassignment of partition first-1 is complete.</span><br><span class="line">Reassignment of partition first-2 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 0,1,2,3</span><br><span class="line">Clearing topic-level throttles on topic first</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --topic first --describe</span><br><span class="line">Topic: first	TopicId: VV7ddVy4SKyTQauf1IHvag	PartitionCount: 3	ReplicationFactor: Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: first	Partition: 0	Leader: 1	Replicas: 0,3,1	Isr: 1,0,3</span><br><span class="line">	Topic: first	Partition: 1	Leader: 1	Replicas: 1,0,2	Isr: 1,2,0</span><br><span class="line">	Topic: first	Partition: 2	Leader: 1	Replicas: 2,1,3	Isr: 1,2,3</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-退役旧节点"><a href="#4-2-2-退役旧节点" class="headerlink" title="4.2.2 退役旧节点"></a>4.2.2 退役旧节点</h3><p>（1）执行负载均衡操作</p>
<p>①创建一个要均衡的主题</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# vim topics-to-move.json</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">     <span class="attr">&quot;topics&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">     	<span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span> <span class="string">&quot;first&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>②创建执行计划：【–broker-list “0,1,2”】</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --topics-to-move-json-file topics-to-move.json --broker-list &quot;0,1,2&quot; --generate</span><br><span class="line">Current partition replica assignment</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,3,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1,0,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[2,1,3],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1,2,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[2,0,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p>③创建副本存储计划（所有副本存储在 broker0、broker1、broker2 中）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]#  vim increase-replication-factor.json</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;first&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;log_dirs&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;first&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">,</span><span class="number">0</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;log_dirs&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;first&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">2</span><span class="punctuation">,</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;log_dirs&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">,</span><span class="string">&quot;any&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>④执行副本存储计划。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,3,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1,0,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;first&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[2,1,3],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignments for first-0,first-1,first-2</span><br></pre></td></tr></table></figure>

<p>⑤验证副本存储计划</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition first-0 is complete.</span><br><span class="line">Reassignment of partition first-1 is complete.</span><br><span class="line">Reassignment of partition first-2 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 0,1,2,3</span><br><span class="line">Clearing topic-level throttles on topic first</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --topic first --describe</span><br><span class="line">Topic: first	TopicId: VV7ddVy4SKyTQauf1IHvag	PartitionCount: 3	ReplicationFactor: Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: first	Partition: 0	Leader: 1	Replicas: 0,1,2	Isr: 1,0,2</span><br><span class="line">	Topic: first	Partition: 1	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0</span><br><span class="line">	Topic: first	Partition: 2	Leader: 1	Replicas: 2,0,1	Isr: 1,2,0</span><br></pre></td></tr></table></figure>

<p>（2）在105上执行停止命令，退役105节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 kafka]# bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>

<h2 id="4-3-Kafka副本"><a href="#4-3-Kafka副本" class="headerlink" title="4.3 Kafka副本"></a>4.3 Kafka副本</h2><h3 id="4-3-1-副本基本信息"><a href="#4-3-1-副本基本信息" class="headerlink" title="4.3.1 副本基本信息"></a>4.3.1 副本基本信息</h3><ul>
<li><p>Kafka 副本作用：提高数据可靠性</p>
</li>
<li><p>Kafka 默认副本 1 个，生产环境一般配置为 2 个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率</p>
</li>
<li><p>Kafka 中副本分为：Leader 和 Follower。Kafka 生产者只会把数据发往 Leader，然后 Follower 找 Leader 进行同步数据</p>
</li>
<li><p>Kafka 分区中的所有副本统称为 AR（Assigned Repllicas）。</p>
<p>AR &#x3D; ISR + OSR</p>
<p><strong>ISR</strong>，表示和 Leader 保持同步的 Follower 集合。如果 Follower 长时间未向 Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。该时间阈值由 <strong>replica.lag.time.max.ms</strong>参数设定，默认 30s。Leader 发生故障之后，就会从 ISR 中选举新的 Leader</p>
<p><strong>OSR</strong>，表示 Follower 与 Leader 副本同步时，延迟过多的副本</p>
</li>
</ul>
<h3 id="4-3-2-Leader选举流程"><a href="#4-3-2-Leader选举流程" class="headerlink" title="4.3.2 Leader选举流程"></a>4.3.2 Leader选举流程</h3><p>Kafka 集群中有一个 broker 的 Controller 会被选举为 Controller Leader，负责管理集群broker 的上下线，所有 topic 的分区副本分配和 Leader 选举等工作。</p>
<p>Controller 的信息同步工作是依赖于 Zookeeper 的。</p>
<p><img src="Snipaste_2023-10-24_15-14-44.png" alt="Snipaste_2023-10-24_15-14-44"></p>
<p>（1）创建创建一个新的 topic  atguigu1，4 个分区，4 个副本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --topic atguigu1 --partitions 4 --replication-factor 4</span><br><span class="line">Created topic atguigu1.</span><br></pre></td></tr></table></figure>

<p>（2）查看Leader分布情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic atguigu1</span><br><span class="line">Topic: atguigu1	TopicId: orp06E3cQHGvR4FFHYcjJg	PartitionCount: 4	ReplicationFactor: Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: atguigu1	Partition: 0	Leader: 1	Replicas: 1,2,3,0	Isr: 1,2,3,0</span><br><span class="line">	Topic: atguigu1	Partition: 1	Leader: 0	Replicas: 0,3,1,2	Isr: 0,3,1,2</span><br><span class="line">	Topic: atguigu1	Partition: 2	Leader: 2	Replicas: 2,1,0,3	Isr: 2,1,0,3</span><br><span class="line">	Topic: atguigu1	Partition: 3	Leader: 3	Replicas: 3,0,2,1	Isr: 3,0,2,1</span><br></pre></td></tr></table></figure>

<p>我们发现：在3分区中，Leader为3，如果停掉hadoop105的进程，那么Leader应该变为0（按照Replicas顺序）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Topic: atguigu1	Partition: 3	Leader: 3	Replicas: 3,0,2,1	Isr: 3,0,2,1</span><br></pre></td></tr></table></figure>

<p>（3）停止掉hadoop105的kafka进程，并查看Leader分区情况，和预想的一致</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 kafka]# bin/kafka-server-stop.sh</span><br><span class="line"></span><br><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic atguigu1</span><br><span class="line">Topic: atguigu1	TopicId: orp06E3cQHGvR4FFHYcjJg	PartitionCount: 4	ReplicationFactor: 4	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: atguigu1	Partition: 0	Leader: 1	Replicas: 1,2,3,0	Isr: 1,2,0</span><br><span class="line">	Topic: atguigu1	Partition: 1	Leader: 0	Replicas: 0,3,1,2	Isr: 0,1,2</span><br><span class="line">	Topic: atguigu1	Partition: 2	Leader: 2	Replicas: 2,1,0,3	Isr: 2,1,0</span><br><span class="line">	Topic: atguigu1	Partition: 3	Leader: 0	Replicas: 3,0,2,1	Isr: 0,2,1</span><br></pre></td></tr></table></figure>

<p>我们发现：在2分区中，Leader为2，如果停掉hadoop104的进程，那么Leader应该变为1（按照Replicas顺序）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Topic: atguigu1	Partition: 2	Leader: 2	Replicas: 2,1,0,3	Isr: 2,1,0</span><br></pre></td></tr></table></figure>

<p>（4）停止掉 hadoop104 的 kafka 进程，并查看 Leader 分区情况，和预想的一致</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[rootu@hadoop104 kafka]# bin/kafka-server-stop.sh</span><br><span class="line"></span><br><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic atguigu1</span><br><span class="line">Topic: atguigu1	TopicId: orp06E3cQHGvR4FFHYcjJg	PartitionCount: 4	ReplicationFactor: 4	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: atguigu1	Partition: 0	Leader: 1	Replicas: 1,2,3,0	Isr: 1,0</span><br><span class="line">	Topic: atguigu1	Partition: 1	Leader: 0	Replicas: 0,3,1,2	Isr: 0,1</span><br><span class="line">	Topic: atguigu1	Partition: 2	Leader: 1	Replicas: 2,1,0,3	Isr: 1,0</span><br><span class="line">	Topic: atguigu1	Partition: 3	Leader: 0	Replicas: 3,0,2,1	Isr: 0,1</span><br></pre></td></tr></table></figure>

<p>（5）启动 hadoop105 的 kafka 进程，并查看 Leader 分区情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop105 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line"></span><br><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic atguigu1</span><br><span class="line">Topic: atguigu1	TopicId: orp06E3cQHGvR4FFHYcjJg	PartitionCount: 4	ReplicationFactor: 4	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: atguigu1	Partition: 0	Leader: 1	Replicas: 1,2,3,0	Isr: 1,0,3</span><br><span class="line">	Topic: atguigu1	Partition: 1	Leader: 0	Replicas: 0,3,1,2	Isr: 0,1,3</span><br><span class="line">	Topic: atguigu1	Partition: 2	Leader: 1	Replicas: 2,1,0,3	Isr: 1,0,3</span><br><span class="line">	Topic: atguigu1	Partition: 3	Leader: 0	Replicas: 3,0,2,1	Isr: 0,1,3</span><br></pre></td></tr></table></figure>

<p>（6）启动 hadoop104 的 kafka 进程，并查看 Leader 分区情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 kafka]# bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line"></span><br><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic atguigu1</span><br><span class="line">Topic: atguigu1	TopicId: orp06E3cQHGvR4FFHYcjJg	PartitionCount: 4	ReplicationFactor: 4	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: atguigu1	Partition: 0	Leader: 1	Replicas: 1,2,3,0	Isr: 1,0,3,2</span><br><span class="line">	Topic: atguigu1	Partition: 1	Leader: 0	Replicas: 0,3,1,2	Isr: 0,1,3,2</span><br><span class="line">	Topic: atguigu1	Partition: 2	Leader: 1	Replicas: 2,1,0,3	Isr: 1,0,3,2</span><br><span class="line">	Topic: atguigu1	Partition: 3	Leader: 0	Replicas: 3,0,2,1	Isr: 0,1,3,2</span><br></pre></td></tr></table></figure>

<p>我们发现：在0分区中，Leader为1，如果停掉hadoop103的进程，那么Leader应该变为2（按照Replicas顺序）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Topic: atguigu1	Partition: 0	Leader: 1	Replicas: 1,2,3,0	Isr: 1,0,3,2</span><br></pre></td></tr></table></figure>

<p>我们发现：在2分区中，Leader为1，如果停掉hadoop103的进程，那么Leader应该变为2（按照Replicas顺序）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Topic: atguigu1	Partition: 2	Leader: 1	Replicas: 2,1,0,3	Isr: 1,0,3,2</span><br></pre></td></tr></table></figure>

<p>（7）停止掉 hadoop103 的 kafka 进程，并查看 Leader 分区情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 kafka]# bin/kafka-server-stop.sh</span><br><span class="line"></span><br><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic atguigu1</span><br><span class="line">Topic: atguigu1	TopicId: orp06E3cQHGvR4FFHYcjJg	PartitionCount: 4	ReplicationFactor: 4	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: atguigu1	Partition: 0	Leader: 2	Replicas: 1,2,3,0	Isr: 0,3,2</span><br><span class="line">	Topic: atguigu1	Partition: 1	Leader: 0	Replicas: 0,3,1,2	Isr: 0,3,2</span><br><span class="line">	Topic: atguigu1	Partition: 2	Leader: 2	Replicas: 2,1,0,3	Isr: 0,3,2</span><br><span class="line">	Topic: atguigu1	Partition: 3	Leader: 3	Replicas: 3,0,2,1	Isr: 0,3,2</span><br></pre></td></tr></table></figure>

<h3 id="4-3-3-Leader和Follower故障处理细节"><a href="#4-3-3-Leader和Follower故障处理细节" class="headerlink" title="4.3.3 Leader和Follower故障处理细节"></a>4.3.3 Leader和Follower故障处理细节</h3><p>Leader是先收到数据的，其余Follower对Leader中的数据进行拉取，所以Follower中的数据在某一时刻可能比Leader中要少</p>
<img src="Snipaste_2023-10-24_15-53-26.png" alt="Snipaste_2023-10-24_15-53-26" style="zoom: 67%;">

<p>（1）Follower故障处理细节：</p>
<p>①当Follower没出现故障时，Leader和Follower们的LEO和HW：</p>
<img src="webwxgetmsgimg (3).jpg" alt="webwxgetmsgimg (3)" style="zoom: 25%;">

<p>②当Follower发生故障后会被踢出ISR：</p>
<img src="webwxgetmsgimg.jpg" alt="webwxgetmsgimg" style="zoom: 25%;">

<p>③这个期间Leader和Follower继续接收数据，LEO和HW也不断更新：</p>
<img src="webwxgetmsgimg (1).jpg" alt="webwxgetmsgimg (1)" style="zoom:25%;">

<p>④待该Follower恢复后，Follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向Leader进行同步。</p>
<img src="webwxgetmsgimg (2).jpg" alt="webwxgetmsgimg (2)" style="zoom:25%;">

<p>⑤等该Follower的LEO大于等于该Partition的HW，即Follower追上Leader之后，就可以重新加入ISR了。 </p>
<img src="webwxgetmsgimg (4).jpg" alt="webwxgetmsgimg (4)" style="zoom:25%;">

<p>（2）Leader故障处理细节</p>
<p>①当Leader没出现故障时，Leader和Follower们的LEO和HW：</p>
<img src="webwxgetmsgimg (3).jpg" alt="webwxgetmsgimg (3)" style="zoom:25%;">

<p>②Leader发生故障之后，会从ISR中选出一个新的Leader</p>
<img src="webwxgetmsgimg (5).jpg" alt="webwxgetmsgimg (5)" style="zoom:25%;">

<img src="webwxgetmsgimg (6).jpg" alt="webwxgetmsgimg (6)" style="zoom:25%;">

<p>③为保证多个副本之间的数据一致性，其余的Follower会先将各自的log文件高于HW的部分截掉，然后从新的Leader同步数据</p>
<img src="webwxgetmsgimg (7).jpg" alt="webwxgetmsgimg (7)" style="zoom:25%;">

<p><strong>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p>
<h3 id="4-3-4-分区副本分配"><a href="#4-3-4-分区副本分配" class="headerlink" title="4.3.4 分区副本分配"></a>4.3.4 分区副本分配</h3><p>如果 kafka 服务器只有 4 个节点，那么设置 kafka 的分区数大于服务器台数，在 kafka底层如何分配存储副本呢？</p>
<p>（1）创建16个分区，3个副本</p>
<p>①创建一个新的topic，名称为second</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 16 --replication-factor 3 --topic second</span><br><span class="line">Created topic second.</span><br></pre></td></tr></table></figure>

<p>②查看分区和副本情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic second</span><br><span class="line">Topic: second	TopicId: ENu4i6cnTIKB4cEs8Caskw	PartitionCount: 16	ReplicationFactor: 3	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: second	Partition: 0	Leader: 1	Replicas: 1,0,2	Isr: 1,0,2</span><br><span class="line">	Topic: second	Partition: 1	Leader: 0	Replicas: 0,2,3	Isr: 0,2,3</span><br><span class="line">	Topic: second	Partition: 2	Leader: 2	Replicas: 2,3,1	Isr: 2,3,1</span><br><span class="line">	Topic: second	Partition: 3	Leader: 3	Replicas: 3,1,0	Isr: 3,1,0</span><br><span class="line">	Topic: second	Partition: 4	Leader: 1	Replicas: 1,2,3	Isr: 1,2,3</span><br><span class="line">	Topic: second	Partition: 5	Leader: 0	Replicas: 0,3,1	Isr: 0,3,1</span><br><span class="line">	Topic: second	Partition: 6	Leader: 2	Replicas: 2,1,0	Isr: 2,1,0</span><br><span class="line">	Topic: second	Partition: 7	Leader: 3	Replicas: 3,0,2	Isr: 3,0,2</span><br><span class="line">	Topic: second	Partition: 8	Leader: 1	Replicas: 1,3,0	Isr: 1,3,0</span><br><span class="line">	Topic: second	Partition: 9	Leader: 0	Replicas: 0,1,2	Isr: 0,1,2</span><br><span class="line">	Topic: second	Partition: 10	Leader: 2	Replicas: 2,0,3	Isr: 2,0,3</span><br><span class="line">	Topic: second	Partition: 11	Leader: 3	Replicas: 3,2,1	Isr: 3,2,1</span><br><span class="line">	Topic: second	Partition: 12	Leader: 1	Replicas: 1,0,2	Isr: 1,0,2</span><br><span class="line">	Topic: second	Partition: 13	Leader: 0	Replicas: 0,2,3	Isr: 0,2,3</span><br><span class="line">	Topic: second	Partition: 14	Leader: 2	Replicas: 2,3,1	Isr: 2,3,1</span><br><span class="line">	Topic: second	Partition: 15	Leader: 3	Replicas: 3,1,0	Isr: 3,1,0</span><br></pre></td></tr></table></figure>

<p>这个图，broker0~3代表的是hadoop102-105服务器（或者说kafka集群），横向每一行代表一个分区，一共16行，就代表16个分区。</p>
<img src="Snipaste_2023-10-24_21-07-22.png" alt="Snipaste_2023-10-24_21-07-22" style="zoom:50%;">



<h3 id="4-3-5-生产经验——手动调整分区副本存储"><a href="#4-3-5-生产经验——手动调整分区副本存储" class="headerlink" title="4.3.5 生产经验——手动调整分区副本存储"></a>4.3.5 生产经验——手动调整分区副本存储</h3><img src="Snipaste_2023-10-24_21-13-39.png" alt="Snipaste_2023-10-24_21-13-39" style="zoom:50%;">

<p>步骤：</p>
<p>（1）创建一个新的 topic，名称为 three</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 4 --replication-factor 2 --topic three</span><br><span class="line">Created topic three.</span><br></pre></td></tr></table></figure>

<p>（2）查看分区副本存储情况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic three</span><br><span class="line">Topic: three	TopicId: CeDwRMeHQQCkTeD5H1x9Zw	PartitionCount: 4	ReplicationFactor: 2	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: three	Partition: 0	Leader: 3	Replicas: 3,1	Isr: 3,1</span><br><span class="line">	Topic: three	Partition: 1	Leader: 1	Replicas: 1,0	Isr: 1,0</span><br><span class="line">	Topic: three	Partition: 2	Leader: 0	Replicas: 0,2	Isr: 0,2</span><br><span class="line">	Topic: three	Partition: 3	Leader: 2	Replicas: 2,3	Isr: 2,3</span><br></pre></td></tr></table></figure>

<p>（3）创建副本存储计划（所有副本都指定存储在 broker0、broker1 中）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# vim increase-replication-factor.json</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;three&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                  <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;three&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                  <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;three&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="number">0</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                  <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;three&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">1</span><span class="punctuation">,</span><span class="number">0</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>（4）执行副本存储计划</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[rootu@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[3,1],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1,0],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[0,2],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;three&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[2,3],&quot;log_dirs&quot;:[&quot;any&quot;,&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignments for three-0,three-1,three-2,three-3</span><br></pre></td></tr></table></figure>

<p>（5）验证副本存储计划</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --verify</span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition three-0 is complete.</span><br><span class="line">Reassignment of partition three-1 is complete.</span><br><span class="line">Reassignment of partition three-2 is complete.</span><br><span class="line">Reassignment of partition three-3 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 0,1,2,3</span><br><span class="line">Clearing topic-level throttles on topic three</span><br></pre></td></tr></table></figure>

<p>（6）查看分区副本存储情况。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic three</span><br><span class="line">Topic: three	TopicId: CeDwRMeHQQCkTeD5H1x9Zw	PartitionCount: 4	ReplicationFactor: 2	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: three	Partition: 0	Leader: 0	Replicas: 0,1	Isr: 1,0</span><br><span class="line">	Topic: three	Partition: 1	Leader: 1	Replicas: 0,1	Isr: 1,0</span><br><span class="line">	Topic: three	Partition: 2	Leader: 0	Replicas: 1,0	Isr: 0,1</span><br><span class="line">	Topic: three	Partition: 3	Leader: 1	Replicas: 1,0	Isr: 1,0</span><br></pre></td></tr></table></figure>

<h3 id="4-3-6-生产经验——Leader-Partition负载平衡"><a href="#4-3-6-生产经验——Leader-Partition负载平衡" class="headerlink" title="4.3.6 生产经验——Leader Partition负载平衡"></a>4.3.6 生产经验——Leader Partition负载平衡</h3><p><img src="Snipaste_2023-10-25_16-10-37.png" alt="Snipaste_2023-10-25_16-10-37"></p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>auto.leader.rebalance.enable</td>
<td>默认是 true。 自动 Leader Partition 平衡。生产环境中，leader 重选举的代价比较大，可能会带来性能影响，建议设置为 false 关闭</td>
</tr>
<tr>
<td>leader.imbalance.per.broker.percentage</td>
<td>默认是 10%。每个 broker 允许的不平衡的 leader的比率。如果每个 broker 超过了这个值，控制器会触发 leader 的平衡</td>
</tr>
<tr>
<td>leader.imbalance.check.interval.seconds</td>
<td>默认值 300 秒。检查 leader 负载是否平衡的间隔时间</td>
</tr>
</tbody></table>
<h3 id="4-3-7-生产经验——增加副本因子"><a href="#4-3-7-生产经验——增加副本因子" class="headerlink" title="4.3.7 生产经验——增加副本因子"></a>4.3.7 生产经验——增加副本因子</h3><p>在生产环境当中，由于某个主题的重要等级需要提升，我们考虑<strong>增加副本</strong>。副本数的增加需要先制定计划，然后根据计划执行</p>
<p>（1）创建topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 3 --replication-factor 1 --topic four</span><br><span class="line">Created topic four.</span><br></pre></td></tr></table></figure>

<p>（2）手动增加副本存储</p>
<p>①创建副本存储计划（所有副本都指定存储在 broker0、broker1、broker2 中）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# vim increase-replication-factor.json</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;four&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                           <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;four&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                           <span class="punctuation">&#123;</span><span class="attr">&quot;topic&quot;</span><span class="punctuation">:</span><span class="string">&quot;four&quot;</span><span class="punctuation">,</span><span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;replicas&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="number">0</span><span class="punctuation">,</span><span class="number">1</span><span class="punctuation">,</span><span class="number">2</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>②执行副本存储计划</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1],&quot;log_dirs&quot;:[&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0],&quot;log_dirs&quot;:[&quot;any&quot;]&#125;,&#123;&quot;topic&quot;:&quot;four&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[2],&quot;log_dirs&quot;:[&quot;any&quot;]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignments for four-0,four-1,four-2</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe --topic four</span><br><span class="line">Topic: four	TopicId: DMmey5uUSL6J5ue3twq3Yw	PartitionCount: 3	ReplicationFactor: 3	Configs: segment.bytes=1073741824</span><br><span class="line">	Topic: four	Partition: 0	Leader: 1	Replicas: 0,1,2	Isr: 1,0,2</span><br><span class="line">	Topic: four	Partition: 1	Leader: 0	Replicas: 0,1,2	Isr: 0,1,2</span><br><span class="line">	Topic: four	Partition: 2	Leader: 2	Replicas: 0,1,2	Isr: 2,1,0</span><br></pre></td></tr></table></figure>

<h2 id="4-4-文件存储"><a href="#4-4-文件存储" class="headerlink" title="4.4 文件存储"></a>4.4 文件存储</h2><h3 id="4-4-1-文件存储机制"><a href="#4-4-1-文件存储机制" class="headerlink" title="4.4.1 文件存储机制"></a>4.4.1 文件存储机制</h3><p>（1）Topicc数据的存储机制</p>
<p><img src="Snipaste_2023-10-25_21-36-21.png" alt="Snipaste_2023-10-25_21-36-21"></p>
<p>（2）Topic数据到底存储在什么位置？</p>
<p>①启动生产者，并发送消息（之前发过了）</p>
<p>②查看 hadoop102（或者 hadoop103、hadoop104）的&#x2F;opt&#x2F;module&#x2F;kafka&#x2F;datas&#x2F;first-1（first-0、first-2）路径上的文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# cd first-0</span><br><span class="line">[root@hadoop102 first-0]# ll</span><br><span class="line">总用量 20</span><br><span class="line">-rw-r--r-- 1 root root 10485760 10月 25 16:21 00000000000000000000.index</span><br><span class="line">-rw-r--r-- 1 root root     1126 10月 23 21:14 00000000000000000000.log</span><br><span class="line">-rw-r--r-- 1 root root 10485756 10月 25 16:21 00000000000000000000.timeindex</span><br><span class="line">-rw-r--r-- 1 root root       10 10月 23 21:51 00000000000000000032.snapshot</span><br><span class="line">-rw-r--r-- 1 root root       14 10月 25 16:21 leader-epoch-checkpoint</span><br><span class="line">-rw-r--r-- 1 root root       43 10月 23 15:04 partition.metadata</span><br></pre></td></tr></table></figure>

<p>③直接查看日志，发现是乱码</p>
<p>④通过工具查看 index 和 log 信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 first-0]# kafka-run-class.sh kafka.tools.DumpLogSegments --files ./00000000000000000000.index</span><br><span class="line">Dumping ./00000000000000000000.index</span><br><span class="line">offset: 0 position: 0</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 first-0]# kafka-run-class.sh kafka.tools.DumpLogSegments --files ./00000000000000000000.log</span><br><span class="line">Dumping ./00000000000000000000.log</span><br><span class="line">Starting offset: 0</span><br><span class="line">baseOffset: 0 lastOffset: 4 count: 5 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1698048686162 size: 141 magic: 2 compresscodec: none crc: 1451661340 isvalid: true</span><br><span class="line">baseOffset: 5 lastOffset: 6 count: 2 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 141 CreateTime: 1698049194013 size: 93 magic: 2 compresscodec: none crc: 2165397900 isvalid: true</span><br><span class="line">baseOffset: 7 lastOffset: 8 count: 2 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 234 CreateTime: 1698063818922 size: 95 magic: 2 compresscodec: none crc: 3599054527 isvalid: true</span><br><span class="line">baseOffset: 9 lastOffset: 9 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 329 CreateTime: 1698063818925 size: 78 magic: 2 compresscodec: none crc: 1140168620 isvalid: true</span><br><span class="line">baseOffset: 10 lastOffset: 10 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 407 CreateTime: 1698063818929 size: 78 magic: 2 compresscodec: none crc: 2810004441 isvalid: true</span><br><span class="line">baseOffset: 11 lastOffset: 11 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 485 CreateTime: 1698063818933 size: 78 magic: 2 compresscodec: none crc: 2525659745 isvalid: true</span><br><span class="line">baseOffset: 12 lastOffset: 16 count: 5 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 563 CreateTime: 1698065665463 size: 141 magic: 2 compresscodec: none crc: 962796909 isvalid: true</span><br><span class="line">baseOffset: 17 lastOffset: 21 count: 5 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 704 CreateTime: 1698067107691 size: 141 magic: 2 compresscodec: snappy crc: 1908828542 isvalid: true</span><br><span class="line">baseOffset: 22 lastOffset: 26 count: 5 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 845 CreateTime: 1698067116133 size: 140 magic: 2 compresscodec: snappy crc: 980480848 isvalid: true</span><br><span class="line">baseOffset: 27 lastOffset: 31 count: 5 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 985 CreateTime: 1698068119235 size: 141 magic: 2 compresscodec: none crc: 2727579545 isvalid: true</span><br></pre></td></tr></table></figure>

<p>（3）index文件和log文件详解</p>
<p><img src="Snipaste_2023-10-25_22-00-46.png" alt="Snipaste_2023-10-25_22-00-46"></p>
<p>说明：日志存储参数配置</p>
<img src="Snipaste_2023-10-25_22-02-02.png" alt="Snipaste_2023-10-25_22-02-02" style="zoom: 50%;">

<h3 id="4-4-2-文件清理策略"><a href="#4-4-2-文件清理策略" class="headerlink" title="4.4.2 文件清理策略"></a>4.4.2 文件清理策略</h3><p>Kafka 中默认的日志保存时间为 7 天，可以通过调整如下参数修改保存时间。</p>
<ul>
<li>log.retention.hours，最低优先级小时，默认 7 天。</li>
<li>log.retention.minutes，分钟。</li>
<li>log.retention.ms，最高优先级毫秒。</li>
<li>log.retention.check.interval.ms，负责设置检查周期，默认 5 分钟。</li>
</ul>
<p>那么日志一旦超过了设置的时间，怎么处理呢？</p>
<p>Kafka 中提供的日志清理策略有 delete 和 compact 两种。</p>
<p><strong>（1）delete 日志删除：将过期数据删除</strong></p>
<p>log.cleanup.policy &#x3D; delete 所有数据启用删除策略</p>
<p>①基于时间：默认打开。以 segment 中所有记录中的最大时间戳作为该文件时间戳</p>
<p>②基于大小：默认关闭。超过设置的所有日志总大小，删除最早的 segment。log.retention.bytes，默认等于-1，表示无穷大</p>
<img src="Snipaste_2023-10-26_14-41-42.png" alt="Snipaste_2023-10-26_14-41-42" style="zoom: 50%;">

<p><strong>（2）compact 日志压缩（用的少）</strong></p>
<img src="Snipaste_2023-10-26_14-42-31.png" alt="Snipaste_2023-10-26_14-42-31" style="zoom:50%;">

<h2 id="4-5-高效读写数据（高频面试题，必会）"><a href="#4-5-高效读写数据（高频面试题，必会）" class="headerlink" title="4.5 高效读写数据（高频面试题，必会）"></a>4.5 高效读写数据（高频面试题，必会）</h2><p>（1）kafka本身是分布式集群，可以采用分区技术，并行度高</p>
<p>（2）读数据采用稀疏索引，可以快速定位要消费的数据</p>
<p>（3）顺序写磁盘</p>
<img src="Snipaste_2023-10-26_14-49-11.png" alt="Snipaste_2023-10-26_14-49-11" style="zoom:50%;">

<p>（4）页缓存+零拷贝技术</p>
<img src="Snipaste_2023-10-26_14-53-55.png" alt="Snipaste_2023-10-26_14-53-55" style="zoom: 50%;">

<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>log.flush.interval.messages</td>
<td>强制页缓存刷写到磁盘的条数，默认是 long 的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。</td>
</tr>
<tr>
<td>log.flush.interval.ms</td>
<td>每隔多久，刷数据到磁盘，默认是 null。一般不建议修改，交给系统自己管理。</td>
</tr>
</tbody></table>
<h1 id="第五章-Kafka消费者"><a href="#第五章-Kafka消费者" class="headerlink" title="第五章 Kafka消费者"></a>第五章 Kafka消费者</h1><h2 id="5-1-kafka消费方式"><a href="#5-1-kafka消费方式" class="headerlink" title="5.1 kafka消费方式"></a>5.1 kafka消费方式</h2><img src="Snipaste_2023-10-26_15-29-33.png" alt="Snipaste_2023-10-26_15-29-33" style="zoom:50%;">

<h2 id="5-2-kafka消费者工作流程"><a href="#5-2-kafka消费者工作流程" class="headerlink" title="5.2 kafka消费者工作流程"></a>5.2 kafka消费者工作流程</h2><h3 id="5-2-1-消费者总体工作流程"><a href="#5-2-1-消费者总体工作流程" class="headerlink" title="5.2.1 消费者总体工作流程"></a>5.2.1 消费者总体工作流程</h3><img src="Snipaste_2023-10-26_15-37-22.png" alt="Snipaste_2023-10-26_15-37-22" style="zoom:50%;">

<p>可以一对一，多对一（无条件），如果一对多，对应的消费者一定是分属于不同消费者组的</p>
<h3 id="5-2-2-消费者组原理"><a href="#5-2-2-消费者组原理" class="headerlink" title="5.2.2 消费者组原理"></a>5.2.2 消费者组原理</h3><p>可以一对一，多对一（无条件）</p>
<img src="Snipaste_2023-10-26_15-43-19.png" alt="Snipaste_2023-10-26_15-43-19" style="zoom:50%;">

<p>如果一对多，对应的消费者一定是分属于不同的消费者组的</p>
<img src="Snipaste_2023-10-26_15-44-51.png" alt="Snipaste_2023-10-26_15-44-51" style="zoom:50%;">

<img src="webwxgetmsgimg (8).jpg" alt="webwxgetmsgimg (8)" style="zoom:50%;">

<img src="webwxgetmsgimg (9).jpg" alt="webwxgetmsgimg (9)" style="zoom:50%;">

<p>这里面的消费计划就是消费者组中的各个消费者拉取Partition分区的方案，谁拉取0号分区，谁拉取1号分区，谁拉取2号分区</p>
<img src="webwxgetmsgimg (10).jpg" alt="webwxgetmsgimg (10)" style="zoom:50%;">

<p>再平衡就是其中某个消费者挂了之后，该消费者组内的其余消费者重新分配消费方案</p>
<p><img src="Snipaste_2023-10-26_16-13-12.png" alt="Snipaste_2023-10-26_16-13-12"></p>
<h3 id="5-2-3-消费者重要参数"><a href="#5-2-3-消费者重要参数" class="headerlink" title="5.2.3 消费者重要参数"></a>5.2.3 消费者重要参数</h3><table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>bootstrap.servers</td>
<td>向 Kafka 集群建立初始连接用到的 host&#x2F;port 列表。</td>
</tr>
<tr>
<td>key.deserializer 和value.deserializer</td>
<td>指定接收消息的 key 和 value 的反序列化类型。一定要写全类名。</td>
</tr>
<tr>
<td>group.id</td>
<td>标记消费者所属的消费者组。</td>
</tr>
<tr>
<td>enable.auto.commit</td>
<td>默认值为 true，消费者会自动周期性地向服务器提交偏移量</td>
</tr>
<tr>
<td>auto.commit.interval.ms</td>
<td>如果设置了 enable.auto.commit 的值为 true， 则该值定义了消费者偏移量向 Kafka 提交的频率，默认 5s。</td>
</tr>
<tr>
<td>auto.offset.reset</td>
<td>当 Kafka 中没有初始偏移量或当前偏移量在服务器中不存在（如，数据被删除了），该如何处理？ earliest：自动重置偏移量到最早的偏移量。 latest：默认，自动重置偏移量为最新的偏移量。 none：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常。 anything：向消费者抛异常。</td>
</tr>
<tr>
<td>offsets.topic.num.partitions</td>
<td>__consumer_offsets 的分区数，默认是 50 个分区。</td>
</tr>
<tr>
<td>heartbeat.interval.ms</td>
<td>Kafka 消费者和 coordinator 之间的心跳时间，默认 3s。该条目的值必须小于 session.timeout.ms ，也不应该高于session.timeout.ms 的 1&#x2F;3。</td>
</tr>
<tr>
<td>session.timeout.ms</td>
<td>Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。超过该值，该消费者被移除，消费者组执行再平衡</td>
</tr>
<tr>
<td>max.poll.interval.ms</td>
<td>消费者处理消息的最大时长，默认是 5 分钟。超过该值，该消费者被移除，消费者组执行再平衡。</td>
</tr>
<tr>
<td>fetch.min.bytes</td>
<td>默认 1 个字节。消费者获取服务器端一批消息最小的字节数</td>
</tr>
<tr>
<td>fetch.max.wait.ms</td>
<td>默认 500ms。如果没有从服务器端获取到一批数据的最小字节数。该时间到，仍然会返回数据。</td>
</tr>
<tr>
<td>fetch.max.bytes</td>
<td>默认 Default: 52428800（50 m）。消费者获取服务器端一批消息最大的字节数。如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是一个绝对最大值。一批次的大小受 message.max.bytes （brokerconfig）or max.message.bytes （topic config）影响</td>
</tr>
<tr>
<td>max.poll.records</td>
<td>一次 poll 拉取数据返回消息的最大条数，默认是 500 条。</td>
</tr>
</tbody></table>
<h3 id="5-3-消费者API"><a href="#5-3-消费者API" class="headerlink" title="5.3 消费者API"></a>5.3 消费者API</h3><h3 id="5-3-1-独立消费者案例（订阅主题）"><a href="#5-3-1-独立消费者案例（订阅主题）" class="headerlink" title="5.3.1 独立消费者案例（订阅主题）"></a>5.3.1 独立消费者案例（订阅主题）</h3><p>（1）需求：创建一个独立消费者，消费 first 主题（所有分区）中数据</p>
<img src="Snipaste_2023-10-26_16-21-19.png" alt="Snipaste_2023-10-26_16-21-19" style="zoom:50%;">

<p><strong>注意：</strong>在消费者 API 代码中必须配置消费者组 id。命令行启动消费者不填写消费者组id 会被自动填写随机的消费者组 id。</p>
<p>（2）实现步骤：</p>
<p>①创建包名：com.atguigu.kafka.consumer</p>
<p>②编写代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.创建消费者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.给消费者配置对象添加参数</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置反序列化 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置消费者组（组名任意起名） 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题的所有分区（可以消费多个主题）</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 拉取数据打印</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印消费到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）测试</p>
<p>①在IDEA中执行消费者程序</p>
<p>②创建kafka生产者，并输入数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 --topic first</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hello</span></span><br></pre></td></tr></table></figure>

<p>③在IDEA的控制台观察到接收到的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 26, offset = 32, CreateTime = 1698322534687, serialized key size = -1, serialized value size = 5, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hello)</span><br></pre></td></tr></table></figure>

<h3 id="5-3-2-独立消费者案例（订阅分区）"><a href="#5-3-2-独立消费者案例（订阅分区）" class="headerlink" title="5.3.2 独立消费者案例（订阅分区）"></a>5.3.2 独立消费者案例（订阅分区）</h3><p>（1）需求：创建一个独立消费者，消费first主题0号分区的数据</p>
<img src="Snipaste_2023-10-26_21-02-00.png" alt="Snipaste_2023-10-26_21-02-00" style="zoom:50%;">

<p>（2）代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerPartition</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置反序列化 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置消费者组（必须），名字可以任意起</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 消费某个主题的某个分区数据</span></span><br><span class="line">        ArrayList&lt;TopicPartition&gt; topicPartitions = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topicPartitions.add(<span class="keyword">new</span> <span class="title class_">TopicPartition</span>(<span class="string">&quot;first&quot;</span>, <span class="number">0</span>));</span><br><span class="line">        kafkaConsumer.assign(topicPartitions);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)&#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）测试</p>
<p>①在IDEA中执行消费者程序</p>
<p>②在 IDEA 中执行生产者程序 CustomProducerCallbackPartitions()，往first主题的分区0发送五条数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br><span class="line">主题： first-&gt;分区：0</span><br></pre></td></tr></table></figure>

<p>③可以看到收到的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 26, offset = 33, CreateTime = 1698326266217, serialized key size = 0, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu 0)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 26, offset = 34, CreateTime = 1698326266217, serialized key size = 0, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu 1)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 26, offset = 35, CreateTime = 1698326266217, serialized key size = 0, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu 2)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 26, offset = 36, CreateTime = 1698326266217, serialized key size = 0, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu 3)</span><br><span class="line">ConsumerRecord(topic = first, partition = 0, leaderEpoch = 26, offset = 37, CreateTime = 1698326266217, serialized key size = 0, serialized value size = 9, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = atguigu 4)</span><br></pre></td></tr></table></figure>

<h3 id="5-3-3-消费者组案例"><a href="#5-3-3-消费者组案例" class="headerlink" title="5.3.3 消费者组案例"></a>5.3.3 消费者组案例</h3><p>（1）需求：测试同一个主题的分区数据，只能由一个消费者组中的一个消费</p>
<img src="Snipaste_2023-10-26_21-21-56.png" alt="Snipaste_2023-10-26_21-21-56" style="zoom:50%;">

<p>（2）实操</p>
<p>①复制两份 CustomConsumer代码，分别命名为 CustomConsumer1和 CustomConsumer2，在IDEA中同时启动，这三个消费者同属于一个消费者组</p>
<p>②启动代码中的生产者发送消息，可以看到每个消费者只能收到特定某个分区的数据</p>
<p><img src="Snipaste_2023-10-26_21-35-37.png" alt="Snipaste_2023-10-26_21-35-37"></p>
<p><img src="Snipaste_2023-10-26_21-35-54.png" alt="Snipaste_2023-10-26_21-35-54"></p>
<p><img src="Snipaste_2023-10-26_21-36-09.png" alt="Snipaste_2023-10-26_21-36-09"></p>
<h2 id="5-4-生产经验——分区的分配以及再平衡"><a href="#5-4-生产经验——分区的分配以及再平衡" class="headerlink" title="5.4 生产经验——分区的分配以及再平衡"></a>5.4 生产经验——分区的分配以及再平衡</h2><p><img src="Snipaste_2023-10-28_12-43-01.png" alt="Snipaste_2023-10-28_12-43-01"></p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>heartbeat.interval.ms</td>
<td>Kafka 消费者和 coordinator 之间的心跳时间，默认 3s。该条目的值必须小于 session.timeout.ms，也不应该高于session.timeout.ms 的 1&#x2F;3。</td>
</tr>
<tr>
<td>session.timeout.ms</td>
<td>Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。超过该值，该消费者被移除，消费者组执行再平衡。</td>
</tr>
<tr>
<td>max.poll.interval.ms</td>
<td>消费者处理消息的最大时长，默认是 5 分钟。超过该值，该消费者被移除，消费者组执行再平衡。</td>
</tr>
<tr>
<td>partition.assignment.strategy</td>
<td>消费者分区分配策略 ， 默认策略是Range + CooperativeSticky。Kafka 可以同时使用多个分区分配策略。可以选择的策略包括 ： Range 、 RoundRobin 、 Sticky 、CooperativeSticky</td>
</tr>
</tbody></table>
<h3 id="5-4-1-Range以及再平衡"><a href="#5-4-1-Range以及再平衡" class="headerlink" title="5.4.1 Range以及再平衡"></a>5.4.1 Range以及再平衡</h3><p>（1）Range分区策略原理</p>
<p><img src="Snipaste_2023-10-28_12-54-44.png" alt="Snipaste_2023-10-28_12-54-44"></p>
<p>（2）Range分区分配策略案例</p>
<p>①修改主题 first 为 7 个分区</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --alter --topic first --partitions 7</span><br></pre></td></tr></table></figure>

<p>注意：分区数可以增加，但是不能减少</p>
<p>②构建CustomConsumer，CustomConsumer1，CustomConsumer2为一个消费者组，组名为“test”，同时启动3个消费者</p>
<p>③启动 CustomProducer 生产者，发送 500 条消息，随机发送到不同的分区</p>
<p>说明：Kafka 默认的分区分配策略就是 Range + CooperativeSticky，所以不需要修改策略。</p>
<p>④观看 3 个消费者分别消费哪些分区的数据。</p>
<p><img src="Snipaste_2023-10-28_13-02-02.png" alt="Snipaste_2023-10-28_13-02-02"></p>
<p><img src="Snipaste_2023-10-28_13-02-23.png" alt="Snipaste_2023-10-28_13-02-23"></p>
<p><img src="Snipaste_2023-10-28_13-02-44.png" alt="Snipaste_2023-10-28_13-02-44"></p>
<p>（3）Range分区分配再平衡案例</p>
<p>①停止掉0号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。</p>
<p>1 号消费者：消费到 3、4 号分区数据。</p>
<p>2 号消费者：消费到 5、6 号分区数据。</p>
<p>0 号消费者的任务<strong>会整体被分配</strong>到 1 号消费者或者 2 号消费者。</p>
<p>说明：0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p>
<p>②再次重新发送消息观看结果（45s 以后）。</p>
<p>1 号消费者：消费到 0、1、2、3 号分区数据。</p>
<p>2 号消费者：消费到 4、5、6 号分区数据。</p>
<p>说明：消费者 0 已经被踢出消费者组，所以重新按照 range 方式分配。</p>
<p><img src="Snipaste_2023-10-28_13-11-39.png" alt="Snipaste_2023-10-28_13-11-39"></p>
<p><img src="Snipaste_2023-10-28_13-12-05.png" alt="Snipaste_2023-10-28_13-12-05"></p>
<h3 id="5-4-2-RoundRobin以及再平衡"><a href="#5-4-2-RoundRobin以及再平衡" class="headerlink" title="5.4.2 RoundRobin以及再平衡"></a>5.4.2 RoundRobin以及再平衡</h3><p>（1）RoundRobin分区策略原理</p>
<p><img src="Snipaste_2023-10-28_19-09-50.png" alt="Snipaste_2023-10-28_19-09-50"></p>
<p>（2）RoundRobin分区分配策略案例</p>
<p>依次在 CustomConsumer、CustomConsumer1、CustomConsumer2 三个消费者代码中修改分区分配策略为 RoundRobin</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 修改分区分配策略</span></span><br><span class="line">        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">&quot;org.apache.kafka.clients.consumer.RoundRobinAssignor&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>重启 3 个消费者，重复发送消息的步骤，观看分区结果</p>
<p><img src="Snipaste_2023-10-28_19-14-32.png" alt="Snipaste_2023-10-28_19-14-32"></p>
<p><img src="Snipaste_2023-10-28_19-14-56.png" alt="Snipaste_2023-10-28_19-14-56"></p>
<p><img src="Snipaste_2023-10-28_19-15-16.png" alt="Snipaste_2023-10-28_19-15-16"></p>
<p>（3）RoundRobin分区分配再平衡案例</p>
<p>①停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。</p>
<p>1 号消费者：消费到 2、5 号分区数据</p>
<p>2 号消费者：消费到 4、1 号分区数据</p>
<p>0 号消费者的任务会按照 RoundRobin 的方式，把数据轮询分成 0 、6 和 3 号分区数据，分别由 1 号消费者或者 2 号消费者消费。**(也就是0号分区和6号分区给某个消费者，3号分区给某个消费者)**</p>
<p>说明：0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p>
<p>②再次重新发送消息观看结果（45s 以后）</p>
<p>1 号消费者：消费到 0、2、4、6 号分区数据</p>
<p>2 号消费者：消费到 1、3、5 号分区数据</p>
<p>说明：消费者 0 已经被踢出消费者组，所以重新按照 RoundRobin 方式分配。</p>
<p><img src="Snipaste_2023-10-28_19-22-24.png" alt="Snipaste_2023-10-28_19-22-24"></p>
<p><img src="Snipaste_2023-10-28_19-22-51.png" alt="Snipaste_2023-10-28_19-22-51"></p>
<h3 id="5-4-3-Sticky以及再平衡"><a href="#5-4-3-Sticky以及再平衡" class="headerlink" title="5.4.3 Sticky以及再平衡"></a>5.4.3 Sticky以及再平衡</h3><p>（1）<strong>粘性分区定义：</strong>可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。</p>
<p>粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，首先会尽量均衡的放置分区到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分区不变化。</p>
<p>（2）①修改分区分配策略为粘性</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 修改分区分配策略</span></span><br><span class="line">properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class="string">&quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>②发送数据，可以看到会尽量保持分区的个数近似划分分区。3：2：2</p>
<p><img src="Snipaste_2023-10-28_19-30-36.png" alt="Snipaste_2023-10-28_19-30-36"></p>
<p><img src="Snipaste_2023-10-28_19-30-51.png" alt="Snipaste_2023-10-28_19-30-51"></p>
<p><img src="Snipaste_2023-10-28_19-31-07.png" alt="Snipaste_2023-10-28_19-31-07"></p>
<p>（3）<strong>Sticky</strong> <strong>分区分配再平衡案例</strong></p>
<p>①停止掉 0 号消费者，快速重新发送消息观看结果（45s 以内，越快越好）。</p>
<p>1 号消费者：消费到 4、5 号分区数据。</p>
<p>2 号消费者：消费到 3、6 号分区数据。</p>
<p>0 号消费者的任务会按照粘性规则，尽可能均衡的随机将0，1，2 号分区分成两份数据，分别由 1 号消费者或者 2 号消费者消费。</p>
<p>说明：0 号消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p>
<p>②再次重新发送消息观看结果（45s 以后）。</p>
<p>1 号消费者：消费到 0、2、4、5 号分区数据。</p>
<p>2 号消费者：消费到 1、3、6 号分区数据。</p>
<p>说明：消费者 0 已经被踢出消费者组，所以重新按照粘性方式分配。</p>
<p><img src="Snipaste_2023-10-28_19-38-30.png" alt="Snipaste_2023-10-28_19-38-30"></p>
<p><img src="Snipaste_2023-10-28_19-38-48.png" alt="Snipaste_2023-10-28_19-38-48"></p>
<h2 id="5-5-offset位移"><a href="#5-5-offset位移" class="headerlink" title="5.5 offset位移"></a>5.5 offset位移</h2><h3 id="5-5-1-offset的默认维护位置"><a href="#5-5-1-offset的默认维护位置" class="headerlink" title="5.5.1 offset的默认维护位置"></a>5.5.1 offset的默认维护位置</h3><img src="Snipaste_2023-10-30_12-28-14.png" alt="Snipaste_2023-10-30_12-28-14" style="zoom:50%;">

<p>__consumer_offsets 主题里面采用 key 和 value 的方式存储数据。key 是 group.id+topic+分区号，value 就是当前 offset 的值。每隔一段时间，kafka 内部会对这个 topic 进行compact，也就是每个 group.id+topic+分区号就保留最新数据</p>
<p>（1）消费offset案例</p>
<p>①思想：__consumer_offsets 为 Kafka 中的 topic，那就可以通过消费者进行消费。</p>
<p>②在配置文件 config&#x2F;consumer.properties 中添加配置 exclude.internal.topics&#x3D;false，默认是 true，表示不能消费系统主题。为了查看该系统主题数据，所以该参数修改为 false。</p>
<p>③采用命令行方式，创建一个新的 topic</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --create --topic atguigu --partitions 2 --replication-factor 2</span><br></pre></td></tr></table></figure>

<p>④启动生产者往 atguigu 生产数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-producer.sh --topic atguigu --bootstrap-server hadoop102:9092</span><br></pre></td></tr></table></figure>

<p>⑤启动消费者消费 atguigu 数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 kafka]# bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic atguigu --group test</span><br></pre></td></tr></table></figure>

<p>注意：指定消费者组名称，更好观察数据存储位置（key 是 group.id+topic+分区号）。</p>
<p>⑥查看消费者消费主题__consumer_offsets。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# bin/kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server hadoop102:9092 --consumer.config config/consumer.properties --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --from-beginning</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[test,atguigu,1]::OffsetAndMetadata(offset=2, leaderEpoch=Optional[0], metadata=, commitTimestamp=1698641012931, expireTimestamp=None)</span><br><span class="line">[test,atguigu,0]::OffsetAndMetadata(offset=2, leaderEpoch=Optional[0], metadata=, commitTimestamp=1698641012931, expireTimestamp=None)</span><br></pre></td></tr></table></figure>

<h3 id="5-5-2-自动提交offset"><a href="#5-5-2-自动提交offset" class="headerlink" title="5.5.2 自动提交offset"></a>5.5.2 自动提交offset</h3><img src="Snipaste_2023-10-30_12-53-15.png" alt="Snipaste_2023-10-30_12-53-15" style="zoom:50%;">

<img src="Snipaste_2023-10-30_12-53-35.png" alt="Snipaste_2023-10-30_12-53-35" style="zoom:50%;">

<p>（1）消费者自动提交offset</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerAutoOffset</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.创建消费者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.给消费者配置对象添加参数</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置反序列化 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置消费者组（组名任意起名） 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 是否自动提交 offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">true</span>);</span><br><span class="line">        <span class="comment">// 提交 offset 的时间周期 1000ms，默认 5s</span></span><br><span class="line">        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line"><span class="comment">//        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, &quot;org.apache.kafka.clients.consumer.RoundRobinAssignor&quot;);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line"><span class="comment">//        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, &quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;);</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题的所有分区（可以消费多个主题）</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 拉取数据打印</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印消费到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-5-3-手动提交offset"><a href="#5-5-3-手动提交offset" class="headerlink" title="5.5.3 手动提交offset"></a>5.5.3 手动提交offset</h3><p><img src="Snipaste_2023-10-30_13-10-41.png" alt="Snipaste_2023-10-30_13-10-41"></p>
<p>（1）同步提交offset</p>
<p>由于同步提交 offset 有失败重试机制，故更加可靠，但是由于一直等待提交结果，提交的效率比较低。以下为同步提交 offset 的示例。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerByHandSync</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.创建消费者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.给消费者配置对象添加参数</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置反序列化 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置消费者组（组名任意起名） 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 是否自动提交 offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line"><span class="comment">//        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, &quot;org.apache.kafka.clients.consumer.RoundRobinAssignor&quot;);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line"><span class="comment">//        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, &quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题的所有分区（可以消费多个主题）</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 拉取数据打印</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印消费到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 同步提交 offset</span></span><br><span class="line">            kafkaConsumer.commitSync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）异步提交pffset</p>
<p>虽然同步提交 offset 更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响。因此更多的情况下，会选用异步提交 offset 的方式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerByHandAsync</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.创建消费者的配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.给消费者配置对象添加参数</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置反序列化 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 配置消费者组（组名任意起名） 必须</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 是否自动提交 offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line"><span class="comment">//        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, &quot;org.apache.kafka.clients.consumer.RoundRobinAssignor&quot;);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 修改分区分配策略</span></span><br><span class="line"><span class="comment">//        properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, &quot;org.apache.kafka.clients.consumer.StickyAssignor&quot;);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消费者对象</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;String, String&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅要消费的主题的所有分区（可以消费多个主题）</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 拉取数据打印</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 设置 1s 中消费一批数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 打印消费到的数据</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 异步提交 offset</span></span><br><span class="line">            kafkaConsumer.commitAsync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-5-4-指定Pffset消费"><a href="#5-5-4-指定Pffset消费" class="headerlink" title="5.5.4 指定Pffset消费"></a>5.5.4 指定Pffset消费</h3><p>auto.offset.reset &#x3D; earliest | latest | none 默认是 latest。</p>
<p>当 Kafka 中没有初始偏移量（消费者组第一次消费）或服务器上不再存在当前偏移量时（例如该数据已被删除），该怎么办？</p>
<p>（1）earliest：自动将偏移量重置为最早的偏移量，–from-beginning。</p>
<p>（2）latest（默认值）：自动将偏移量重置为最新偏移量</p>
<p>（3）none：如果未找到消费者组的先前偏移量，则向消费者抛出异常。</p>
<img src="Snipaste_2023-10-30_13-39-43.png" alt="Snipaste_2023-10-30_13-39-43" style="zoom:50%;">

<p>（4）任意指定 offset 位移开始消费</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerSeek</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0 配置信息</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 连接</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// key value 反序列化</span></span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test3&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 订阅一个主题</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定位置进行消费</span></span><br><span class="line">        Set&lt;TopicPartition&gt; assignment= <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line">            kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费）</span></span><br><span class="line">            assignment = kafkaConsumer.assignment();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 遍历所有分区，并指定 offset 从 1700 的位置开始消费</span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition tp: assignment) &#123;</span><br><span class="line">            kafkaConsumer.seek(tp, <span class="number">1700</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 消费该主题数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意：每次执行完，需要修改消费者组名</p>
<h3 id="5-5-5-指定时间消费"><a href="#5-5-5-指定时间消费" class="headerlink" title="5.5.5 指定时间消费"></a>5.5.5 指定时间消费</h3><p>需求：在生产环境中，会遇到最近消费的几个小时数据异常，想重新按照时间消费。例如要求按照时间消费前一天的数据，怎么处理？</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerSeekTime</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 0 配置信息</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        <span class="comment">// 连接</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// key value 反序列化</span></span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test4&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 创建一个消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 订阅一个主题</span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>);</span><br><span class="line">        kafkaConsumer.subscribe(topics);</span><br><span class="line"></span><br><span class="line">        Set&lt;TopicPartition&gt; assignment= <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123;</span><br><span class="line">            kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费）</span></span><br><span class="line">            assignment = kafkaConsumer.assignment();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        HashMap&lt;TopicPartition, Long&gt; timestampToSearch = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="comment">// 封装集合存储，每个分区对应一天前的数据</span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class="line">            timestampToSearch.put(topicPartition, System.currentTimeMillis() - <span class="number">1</span> * <span class="number">24</span> * <span class="number">3600</span> * <span class="number">1000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 获取从 1 天前开始消费的每个分区的 offset</span></span><br><span class="line">        Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = kafkaConsumer.offsetsForTimes(timestampToSearch);</span><br><span class="line">        <span class="comment">// 遍历每个分区，对每个分区设置消费时间。</span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class="line">            <span class="type">OffsetAndTimestamp</span> <span class="variable">offsetAndTimestamp</span> <span class="operator">=</span> offsets.get(topicPartition);</span><br><span class="line">            <span class="comment">// 根据时间指定开始消费的位置</span></span><br><span class="line">            <span class="keyword">if</span> (offsetAndTimestamp != <span class="literal">null</span>)&#123;</span><br><span class="line">                kafkaConsumer.seek(topicPartition, offsetAndTimestamp.offset());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 消费该主题数据</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                System.out.println(consumerRecord);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-5-6-漏消费和重复消费"><a href="#5-5-6-漏消费和重复消费" class="headerlink" title="5.5.6 漏消费和重复消费"></a>5.5.6 漏消费和重复消费</h3><p><strong>重复消费：</strong>已经消费了数据，但是 offset 没提交。消费快，offset提交慢</p>
<p><strong>漏消费：</strong>先提交 offset 后消费，有可能会造成数据的漏消费。消费慢，offset提交快</p>
<img src="Snipaste_2023-10-30_14-11-06.png" alt="Snipaste_2023-10-30_14-11-06" style="zoom:50%;">

<h2 id="5-6-消费者事务"><a href="#5-6-消费者事务" class="headerlink" title="5.6 消费者事务"></a>5.6 消费者事务</h2><img src="Snipaste_2023-10-30_14-23-01.png" alt="Snipaste_2023-10-30_14-23-01" style="zoom:50%;">

<h2 id="5-7-生产经验——数据积压（消费者如何提高吞吐量）"><a href="#5-7-生产经验——数据积压（消费者如何提高吞吐量）" class="headerlink" title="5.7 生产经验——数据积压（消费者如何提高吞吐量）"></a>5.7 生产经验——数据积压（消费者如何提高吞吐量）</h2><p><img src="Snipaste_2023-10-30_14-25-03.png" alt="Snipaste_2023-10-30_14-25-03"></p>
<img src="webwxgetmsgimg (11).jpg" alt="webwxgetmsgimg (11)" style="zoom:33%;">

<img src="Snipaste_2023-10-30_14-36-56.png" alt="Snipaste_2023-10-30_14-36-56" style="zoom:50%;">

<h1 id="第六章-Kafka-Eagle监控"><a href="#第六章-Kafka-Eagle监控" class="headerlink" title="第六章 Kafka-Eagle监控"></a>第六章 Kafka-Eagle监控</h1><p>Kafka-Eagle 框架可以监控 Kafka 集群的整体运行情况，在生产环境中经常使用。</p>
<h2 id="6-1-MySQL环境准备"><a href="#6-1-MySQL环境准备" class="headerlink" title="6.1 MySQL环境准备"></a>6.1 MySQL环境准备</h2><p>之前Hive框架学习笔记中有</p>
<h2 id="6-2-Kafka环境准备"><a href="#6-2-Kafka环境准备" class="headerlink" title="6.2 Kafka环境准备"></a>6.2 Kafka环境准备</h2><p>（1）关闭Kafka集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# kf.sh stop</span><br></pre></td></tr></table></figure>

<p>（2）修改&#x2F;opt&#x2F;module&#x2F;kafka&#x2F;bin&#x2F;kafka-sever-start.sh命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka]# vim bin/kafka-server-start.sh</span><br></pre></td></tr></table></figure>

<p>修改为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then</span><br><span class="line"> 	export KAFKA_HEAP_OPTS=&quot;-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70&quot;</span><br><span class="line"> 	export JMX_PORT=&quot;9999&quot;</span><br><span class="line"><span class="meta prompt_"> 	#</span><span class="language-bash"><span class="built_in">export</span> KAFKA_HEAP_OPTS=<span class="string">&quot;-Xmx1G -Xms1G&quot;</span></span></span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p>（3）分发到其他节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# xsync kafka-server-start.sh</span><br></pre></td></tr></table></figure>

<p>（4）启动Kafka集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# kf.sh start</span><br></pre></td></tr></table></figure>

<h2 id="6-3-Kafka-Eagle安装"><a href="#6-3-Kafka-Eagle安装" class="headerlink" title="6.3 Kafka-Eagle安装"></a>6.3 Kafka-Eagle安装</h2><p>（1）上传压缩包到集群&#x2F;opt&#x2F;software目录</p>
<p>（2）解压到本地</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf kafka-eagle-bin-2.0.8.tar.gz</span><br></pre></td></tr></table></figure>

<p>（3）进入刚才解压的目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka-eagle-bin-2.0.8]# ll</span><br><span class="line">总用量 79164</span><br><span class="line">-rw-rw-r-- 1 root root 81062577 10月 13 2021 efak-web-2.0.8-bin.tar.gz</span><br></pre></td></tr></table></figure>

<p>（4）将efak-web-2.0.8-bin.tar.gz解压到&#x2F;opt&#x2F;module</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka-eagle-bin-2.0.8]# tar -zxvf efak-web-2.0.8-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>（5）修改名称</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mv efak-web-2.0.8/ efak</span><br></pre></td></tr></table></figure>

<p>（6）修改配置文件&#x2F;opt&#x2F;module&#x2F;efak&#x2F;conf&#x2F;system-config.properties</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim system-config.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">multi zookeeper &amp; kafka cluster list</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Settings prefixed with <span class="string">&#x27;kafka.eagle.&#x27;</span> will be deprecated, use <span class="string">&#x27;efak.&#x27;</span></span> </span><br><span class="line">instead</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">efak.zk.cluster.alias=cluster1</span><br><span class="line">cluster1.zk.list=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">zookeeper <span class="built_in">enable</span> acl</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">cluster1.zk.acl.enable=false</span><br><span class="line">cluster1.zk.acl.schema=digest</span><br><span class="line">cluster1.zk.acl.username=test</span><br><span class="line">cluster1.zk.acl.password=test123</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">broker size online list</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">cluster1.efak.broker.size=20</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">zk client thread <span class="built_in">limit</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">kafka.zk.limit.size=32</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">EFAK webui port</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">efak.webui.port=8048</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka jmx acl and ssl authenticate</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">cluster1.efak.jmx.acl=false</span><br><span class="line">cluster1.efak.jmx.user=keadmin</span><br><span class="line">cluster1.efak.jmx.password=keadmin123</span><br><span class="line">cluster1.efak.jmx.ssl=false</span><br><span class="line">cluster1.efak.jmx.truststore.location=/data/ssl/certificates/kafka.truststor</span><br><span class="line">e</span><br><span class="line">cluster1.efak.jmx.truststore.password=ke123456</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka offset storage</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">offset 保存在 kafka</span></span><br><span class="line">cluster1.efak.offset.storage=kafka</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka jmx uri</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">cluster1.efak.jmx.uri=service:jmx:rmi:///jndi/rmi://%s/jmxrmi</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka metrics, 15 days by default</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">efak.metrics.charts=true</span><br><span class="line">efak.metrics.retain=15</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka sql topic records max</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">efak.sql.topic.records.max=5000</span><br><span class="line">efak.sql.topic.preview.records.max=10</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">delete kafka topic token</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">efak.topic.token=keadmin</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka sasl authenticate</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">cluster1.efak.sasl.enable=false</span><br><span class="line">cluster1.efak.sasl.protocol=SASL_PLAINTEXT</span><br><span class="line">cluster1.efak.sasl.mechanism=SCRAM-SHA-256</span><br><span class="line">cluster1.efak.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramL</span><br><span class="line">oginModule required username=&quot;kafka&quot; password=&quot;kafka-eagle&quot;;</span><br><span class="line">cluster1.efak.sasl.client.id=</span><br><span class="line">cluster1.efak.blacklist.topics=</span><br><span class="line">cluster1.efak.sasl.cgroup.enable=false</span><br><span class="line">cluster1.efak.sasl.cgroup.topics=</span><br><span class="line">cluster2.efak.sasl.enable=false</span><br><span class="line">cluster2.efak.sasl.protocol=SASL_PLAINTEXT</span><br><span class="line">cluster2.efak.sasl.mechanism=PLAIN</span><br><span class="line">cluster2.efak.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainL</span><br><span class="line">oginModule required username=&quot;kafka&quot; password=&quot;kafka-eagle&quot;;</span><br><span class="line">cluster2.efak.sasl.client.id=</span><br><span class="line">cluster2.efak.blacklist.topics=</span><br><span class="line">cluster2.efak.sasl.cgroup.enable=false</span><br><span class="line">cluster2.efak.sasl.cgroup.topics=</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka ssl authenticate</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line">cluster3.efak.ssl.enable=false</span><br><span class="line">cluster3.efak.ssl.protocol=SSL</span><br><span class="line">cluster3.efak.ssl.truststore.location=</span><br><span class="line">cluster3.efak.ssl.truststore.password=</span><br><span class="line">cluster3.efak.ssl.keystore.location=</span><br><span class="line">cluster3.efak.ssl.keystore.password=</span><br><span class="line">cluster3.efak.ssl.key.password=</span><br><span class="line">cluster3.efak.ssl.endpoint.identification.algorithm=https</span><br><span class="line">cluster3.efak.blacklist.topics=</span><br><span class="line">cluster3.efak.ssl.cgroup.enable=false</span><br><span class="line">cluster3.efak.ssl.cgroup.topics=</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka sqlite jdbc driver address</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置 mysql 连接</span></span><br><span class="line">efak.driver=com.mysql.jdbc.Driver</span><br><span class="line">efak.url=jdbc:mysql://hadoop102:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull</span><br><span class="line">efak.username=root</span><br><span class="line">efak.password=wy****1*****18</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafka mysql jdbc driver address</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">#####################################</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">efak.driver=com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">efak.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=<span class="literal">true</span>&amp;characterEncoding=U</span></span><br><span class="line">TF-8&amp;zeroDateTimeBehavior=convertToNull</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">efak.username=root</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">efak.password=123456</span></span><br></pre></td></tr></table></figure>

<p>（7）添加环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kafkaEFAK</span></span><br><span class="line">export KE_HOME=/opt/module/efak</span><br><span class="line">export PATH=$PATH:$KE_HOME/bin</span><br><span class="line"></span><br><span class="line">[root@hadoop102 conf]# source /etc/profile</span><br></pre></td></tr></table></figure>

<p>（8）启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 efak]# bin/ke.sh start</span><br><span class="line"></span><br><span class="line">[2023-10-30 15:34:55] INFO: [Job done!]</span><br><span class="line">Welcome to</span><br><span class="line">    ______    ______    ___     __ __</span><br><span class="line">   / ____/   / ____/   /   |   / //_/</span><br><span class="line">  / __/     / /_      / /| |  / ,&lt;   </span><br><span class="line"> / /___    / __/     / ___ | / /| |  </span><br><span class="line">/_____/   /_/       /_/  |_|/_/ |_|  </span><br><span class="line">( Eagle For Apache Kafka® )</span><br><span class="line"></span><br><span class="line">Version 2.0.8 -- Copyright 2016-2021</span><br><span class="line">*******************************************************************</span><br><span class="line">* EFAK Service has started success.</span><br><span class="line">* Welcome, Now you can visit &#x27;http://192.168.255.102:8048&#x27;</span><br><span class="line">* Account:admin ,Password:123456</span><br><span class="line">*******************************************************************</span><br><span class="line">* &lt;Usage&gt; ke.sh [start|status|stop|restart|stats] &lt;/Usage&gt;</span><br><span class="line">* &lt;Usage&gt; https://www.kafka-eagle.org/ &lt;/Usage&gt;</span><br><span class="line">*******************************************************************</span><br></pre></td></tr></table></figure>

<p>说明：如果停止 efak，执行命令。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 efak]# bin/ke.sh stop</span><br></pre></td></tr></table></figure>

<h2 id="6-4-Kafka-Eagle页面操作"><a href="#6-4-Kafka-Eagle页面操作" class="headerlink" title="6.4 Kafka-Eagle页面操作"></a>6.4 Kafka-Eagle页面操作</h2><p>（1）<strong>登录页面查看监控数据</strong></p>
<p><a target="_blank" rel="noopener" href="http://192.168.255.102:8048/">http://192.168.255.102:8048</a></p>
<p>Account:admin ,Password:123456</p>
<p><img src="Snipaste_2023-10-30_15-37-45.png" alt="Snipaste_2023-10-30_15-37-45"></p>
<p>查看BROKERS详情</p>
<p><img src="Snipaste_2023-10-30_15-39-12.png" alt="Snipaste_2023-10-30_15-39-12"></p>
<p><img src="Snipaste_2023-10-30_15-39-54.png" alt="Snipaste_2023-10-30_15-39-54"></p>
<p>查看TOPICS详情</p>
<p><img src="Snipaste_2023-10-30_15-40-53.png" alt="Snipaste_2023-10-30_15-40-53"></p>
<p><img src="Snipaste_2023-10-30_15-41-21.png" alt="Snipaste_2023-10-30_15-41-21"></p>
<p>查看ZOOKEEPERS详情</p>
<p><img src="Snipaste_2023-10-30_15-42-12.png" alt="Snipaste_2023-10-30_15-42-12"></p>
<p>查看CONSUMERGROUPS详情</p>
<p><img src="Snipaste_2023-10-30_15-43-13.png" alt="Snipaste_2023-10-30_15-43-13"></p>
<p>大屏展示：</p>
<p><img src="Snipaste_2023-10-30_15-46-35.png" alt="Snipaste_2023-10-30_15-46-35"></p>
<h1 id="第七章-Kafka-Kraft模式"><a href="#第七章-Kafka-Kraft模式" class="headerlink" title="第七章 Kafka-Kraft模式"></a>第七章 Kafka-Kraft模式</h1><h2 id="7-1-Kafka-Kraft架构"><a href="#7-1-Kafka-Kraft架构" class="headerlink" title="7.1 Kafka-Kraft架构"></a>7.1 Kafka-Kraft架构</h2><img src="Snipaste_2023-10-30_15-54-00.png" alt="Snipaste_2023-10-30_15-54-00" style="zoom:50%;">

<p>左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由controller 进行 Kafka 集群管理。右图为 kraft 模式架构（实验性），不再依赖 zookeeper 集群，而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进行 Kafka 集群管理。</p>
<p>这样做的好处有以下几个：</p>
<ul>
<li>Kafka 不再依赖外部框架，而是能够独立运行；</li>
<li>controller 管理集群时，不再需要从 zookeeper 中先读取数据，集群性能上升；</li>
<li>由于不依赖 zookeeper，集群扩展时不再受到 zookeeper 读写能力限制；</li>
<li>controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。</li>
</ul>
<h2 id="7-2-Kafka-Kraft集群部署"><a href="#7-2-Kafka-Kraft集群部署" class="headerlink" title="7.2 Kafka-Kraft集群部署"></a>7.2 Kafka-Kraft集群部署</h2><p>（0）关闭kafka集群和zookeeper集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# kf.sh stop</span><br><span class="line">[root@hadoop102 module]# zk.sh stop</span><br></pre></td></tr></table></figure>

<p>（1）再次解压一份 kafka 安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>（2）重命名为kafka2</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mv kafka_2.12-3.0.0/ kafka2</span><br></pre></td></tr></table></figure>

<p>（3）在 hadoop102 上修改&#x2F;opt&#x2F;module&#x2F;kafka2&#x2F;config&#x2F;kraft&#x2F;server.properties 配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# cd kafka2/config/kraft/</span><br><span class="line">[root@hadoop102 kraft]# vim server.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">kafka 的角色（controller 相当于主机、broker 节点相当于从机，主机类似 zk 功能）</span></span><br><span class="line">process.roles=broker, controller</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">节点 ID</span></span><br><span class="line">node.id=2</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">controller 服务协议别名</span></span><br><span class="line">controller.listener.names=CONTROLLER</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">全 Controller 列表</span></span><br><span class="line">controller.quorum.voters=2@hadoop102:9093,3@hadoop103:9093,4@hadoop104:9093</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">不同服务器绑定的端口</span></span><br><span class="line">listeners=PLAINTEXT://:9092,CONTROLLER://:9093</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">broker 服务协议别名</span></span><br><span class="line">inter.broker.listener.name=PLAINTEXT</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">broker 对外暴露的地址</span></span><br><span class="line">advertised.Listeners=PLAINTEXT://hadoop102:9092</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">协议别名到安全协议的映射</span></span><br><span class="line">listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLA</span><br><span class="line">INTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">kafka 数据存储目录</span></span><br><span class="line">log.dirs=/opt/module/kafka2/data</span><br></pre></td></tr></table></figure>

<p>（4）分发kafka2</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# xsync kafka2/</span><br></pre></td></tr></table></figure>

<ul>
<li>在 hadoop103 和 hadoop104 上 需 要 对 node.id 相应改变 ， 值 需 要 和controller.quorum.voters 对应。</li>
<li>在 hadoop103 和 hadoop104 上需要 根据各自的主机名称，修改相应的advertised.Listeners 地址。</li>
</ul>
<p>（5）初始化集群数据目录</p>
<p>①首先生成存储目录唯一ID</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka2]# bin/kafka-storage.sh random-uuid</span><br><span class="line">fmWatWf3SPe8m3ghz_RndA</span><br></pre></td></tr></table></figure>

<p>②用该 ID 格式化 kafka 存储目录（三台节点）。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[rootu@hadoop102 kafka2]# bin/kafka-storage.sh format -t fmWatWf3SPe8m3ghz_RndA -c /opt/module/kafka2/config/kraft/server.properties</span><br><span class="line">[root@hadoop103 kafka2]# bin/kafka-storage.sh format -t fmWatWf3SPe8m3ghz_RndA -c /opt/module/kafka2/config/kraft/server.properties</span><br><span class="line">[root@hadoop104 kafka2]# bin/kafka-storage.sh format -t fmWatWf3SPe8m3ghz_RndA -c /opt/module/kafka2/config/kraft/server.properties</span><br></pre></td></tr></table></figure>

<p>（6）启动kafka集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka2]# bin/kafka-server-start.sh -daemon config/kraft/server.properties</span><br><span class="line">[root@hadoop103 kafka2]# bin/kafka-server-start.sh -daemon config/kraft/server.properties</span><br><span class="line">[root@hadoop104 kafka2]# bin/kafka-server-start.sh -daemon config/kraft/server.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka2]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">16945 Kafka</span><br><span class="line">17080 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">8121 Kafka</span><br><span class="line">8234 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">8192 Jps</span><br><span class="line">8087 Kafka</span><br></pre></td></tr></table></figure>

<p>（7）关闭kafka集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 kafka2]# bin/kafka-server-stop.sh</span><br><span class="line">[root@hadoop103 kafka2]# bin/kafka-server-stop.sh</span><br><span class="line">[root@hadoop104 kafka2]# bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>

<h2 id="7-3-Kafka-Kraft集群启停脚本"><a href="#7-3-Kafka-Kraft集群启停脚本" class="headerlink" title="7.3 Kafka-Kraft集群启停脚本"></a>7.3 Kafka-Kraft集群启停脚本</h2><p>（1）~&#x2F;bin 目录下创建文件 kf2.sh 脚本文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# vim kf2.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">     for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">     do</span><br><span class="line">         echo &quot; --------启动 $i Kafka2-------&quot;</span><br><span class="line">         ssh $i &quot;/opt/module/kafka2/bin/kafka-server-start.sh -daemon /opt/module/kafka2/config/kraft/server.properties&quot;</span><br><span class="line">     done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">     for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">     do</span><br><span class="line">         echo &quot; --------停止 $i Kafka2-------&quot;</span><br><span class="line">         ssh $i &quot;/opt/module/kafka2/bin/kafka-server-stop.sh &quot;</span><br><span class="line">     done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>（2）添加执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# chmod 777 kf2.sh</span><br></pre></td></tr></table></figure>

<p>（3）集群启动和停止</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# kf2.sh start</span><br><span class="line">[root@hadoop102 bin]# kf2.sh stop</span><br></pre></td></tr></table></figure>


      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/10/20/kafka%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-flume框架学习笔记" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/20/flume%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">flume框架学习笔记</a>
    </h1>
  

        
        <a href="/2023/10/20/flume%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2023-10-20T06:31:48.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-10-20</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Flume概述"><a href="#第一章-Flume概述" class="headerlink" title="第一章 Flume概述"></a>第一章 Flume概述</h1><h2 id="1-1-Flume定义"><a href="#1-1-Flume定义" class="headerlink" title="1.1 Flume定义"></a>1.1 Flume定义</h2><p>Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume 基于流式架构，灵活简单。</p>
<img src="Snipaste_2023-10-20_15-24-23.png" alt="Snipaste_2023-10-20_15-24-23" style="zoom:43%;">

<h2 id="1-2-Flume基础框架"><a href="#1-2-Flume基础框架" class="headerlink" title="1.2 Flume基础框架"></a>1.2 Flume基础框架</h2><img src="Snipaste_2023-10-20_15-37-57.png" alt="Snipaste_2023-10-20_15-37-57" style="zoom:43%;">

<p>Flume整体上是<strong>Source-Channel-Sink</strong>的三层架构。</p>
<p>Flume以<strong>Agent</strong>为最小独立运行单元，一个Agent就是一个JVM，它以事件event的形式将数据从源头送至目的，单个Agent由Source、Channel、Sink三大组件组成。</p>
<h3 id="1-2-1-Source"><a href="#1-2-1-Source" class="headerlink" title="1.2.1 Source"></a>1.2.1 Source</h3><p>Source 是<strong>负责接收数据到 Flume Agent 的组件</strong>。Source 组件可以处理各种类型、各种格式的日志数据，包括 avro、thrift、exec、jms、spooling directory、netcat、taildir、sequence generator、syslog、http、legacy。</p>
<h3 id="1-2-2-Sink"><a href="#1-2-2-Sink" class="headerlink" title="1.2.2 Sink"></a>1.2.2 Sink</h3><p>Sink <strong>不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个 Flume Agent</strong>。</p>
<p>Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。</p>
<h3 id="1-2-3-Channel"><a href="#1-2-3-Channel" class="headerlink" title="1.2.3 Channel"></a>1.2.3 Channel</h3><p>Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在<strong>不同的速率</strong>上。Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个Sink 的读取操作。</p>
<p>Flume 自带两种 Channel：<strong>Memory Channel</strong> 和 <strong>File Channel</strong>。</p>
<p>Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适用。如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。</p>
<p>File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。</p>
<h3 id="1-2-4-Event"><a href="#1-2-4-Event" class="headerlink" title="1.2.4 Event"></a>1.2.4 Event</h3><p>传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。Event 由 <strong>Header</strong> 和 <strong>Body</strong> 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构，报头Header容纳的k-v信息是为了给数据增加标识，用于跟踪发送事件的优先级和重要性，用户可以通过拦截器进行修改。Body 用来存放该条数据，形式为字节数组。</p>
<img src="Snipaste_2023-10-20_15-57-12.png" alt="Snipaste_2023-10-20_15-57-12" style="zoom:43%;">

<h1 id="第二章-Flume入门"><a href="#第二章-Flume入门" class="headerlink" title="第二章 Flume入门"></a>第二章 Flume入门</h1><h2 id="2-1-Flume安装部署"><a href="#2-1-Flume安装部署" class="headerlink" title="2.1 Flume安装部署"></a>2.1 Flume安装部署</h2><h3 id="2-1-1-安装地址"><a href="#2-1-1-安装地址" class="headerlink" title="2.1.1 安装地址"></a>2.1.1 安装地址</h3><h3 id="2-1-2-安装部署"><a href="#2-1-2-安装部署" class="headerlink" title="2.1.2 安装部署"></a>2.1.2 安装部署</h3><p>（1）将 apache-flume-1.9.0-bin.tar.gz 上传到 linux 的&#x2F;opt&#x2F;software 目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 1540044</span><br><span class="line">-rw-r--r--. 1 root root  67938106 8月  13 2021 apache-flume-1.9.0-bin.tar.gz   # 在这里</span><br><span class="line">-rw-r--r--. 1 root root 356079876 12月  2 2022 apache-hive-3.1.3-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root   9311744 5月  20 2021 apache-zookeeper-3.5.7-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 609556480 12月  2 2022 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line">-rw-r--r--. 1 root root    985600 12月  2 2022 mysql-connector-java-5.1.37.jar</span><br><span class="line">drwxr-xr-x. 2 root root      4096 10月  7 15:30 mysql_lib</span><br></pre></td></tr></table></figure>

<p>（2）解压 apache-flume-1.9.0-bin.tar.gz 到&#x2F;opt&#x2F;module&#x2F;目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/</span><br><span class="line">[root@hadoop102 software]# cd /opt/module/</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x.  7 root root  187 10月 20 16:04 apache-flume-1.9.0-bin  # 在这里</span><br><span class="line">drwxr-xr-x.  2 root root   99 10月 10 13:38 data</span><br><span class="line">drwxr-xr-x.  3 root root   62 10月  9 13:35 datas</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 12 root root  243 10月  8 13:38 hive</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br><span class="line">drwxr-xr-x.  8 root root  160 10月 19 12:57 zookeeper-3.5.7</span><br></pre></td></tr></table></figure>

<p>（3）修改 apache-flume-1.9.0-bin 的名称为 flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mv /opt/module/apache-flume-1.9.0-bin/ /opt/module/flume</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x.  2 root root   99 10月 10 13:38 data</span><br><span class="line">drwxr-xr-x.  3 root root   62 10月  9 13:35 datas</span><br><span class="line">drwxr-xr-x.  7 root root  187 10月 20 16:04 flume    # 在这里</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 12 root root  243 10月  8 13:38 hive</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br><span class="line">drwxr-xr-x.  8 root root  160 10月 19 12:57 zookeeper-3.5.7</span><br></pre></td></tr></table></figure>

<p>（4）将 lib 文件夹下的 guava-11.0.2.jar 删除以兼容 Hadoop 3.1.3</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# rm /opt/module/flume/lib/guava-11.0.2.jar </span><br><span class="line">rm：是否删除普通文件 &quot;/opt/module/flume/lib/guava-11.0.2.jar&quot;？y</span><br></pre></td></tr></table></figure>

<p>（5）将flume&#x2F;conf目录下的flume-env.sh.template文件名称修改为flume-env.sh，并配置flume-env.sh文件，在配置文件中增加JAVA_HOME路径；并修改内存最大为4G</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# cp flume-env.sh.template flume-env.sh</span><br><span class="line">[root@hadoop102 conf]# vim flume-env.sh</span><br><span class="line"></span><br><span class="line">export JAVA_OPTS=&quot;-Xms100m -Xmx4000m -Dcom.sun.management.jmxremote&quot;</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>（6）修改logs目录，并打印到控制台一份（学习测试用）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim log4j.properties </span><br><span class="line"></span><br><span class="line">flume.root.logger=INFO,LOGFILE,console</span><br><span class="line">flume.log.dir=/opt/module/flume/logs # 原来是./logs</span><br></pre></td></tr></table></figure>

<p>（7）将配置好的flume文件分发到集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# xsync flume/</span><br></pre></td></tr></table></figure>

<h2 id="2-2-Flume入门案例"><a href="#2-2-Flume入门案例" class="headerlink" title="2.2 Flume入门案例"></a>2.2 Flume入门案例</h2><h3 id="2-2-1-监控端口数据官方案例"><a href="#2-2-1-监控端口数据官方案例" class="headerlink" title="2.2.1 监控端口数据官方案例"></a>2.2.1 监控端口数据官方案例</h3><p>需求：使用 Flume 监听一个端口，收集该端口数据，并打印到控制台。</p>
<p>分析：</p>
<p><img src="Snipaste_2023-10-20_16-15-53.png" alt="Snipaste_2023-10-20_16-15-53"></p>
<p>步骤：</p>
<p>（0）安装netcat工具：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# yum install -y nc</span><br></pre></td></tr></table></figure>

<p>（1）测试一下netcat</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在hadoop102上开启端口号为9999的nc服务端</span></span><br><span class="line">[root@hadoop102 flume]# nc -lk 9999</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在hadoop102的另一个窗口上开启端口号为9999的nc客户端</span></span><br><span class="line">[root@hadoop102 ~]# nc localhost 999</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在服务端输入数据在客户端就可以接收到，当然在客户端输入数据在服务端也可以接收到</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-20_16-28-12.png" alt="Snipaste_2023-10-20_16-28-12"></p>
<p><img src="Snipaste_2023-10-20_16-29-40.png" alt="Snipaste_2023-10-20_16-29-40"></p>
<p>（2）判断 44444 端口是否被占用</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]#  netstat -nlp | grep 44444</span><br><span class="line">[root@hadoop102 flume]# </span><br></pre></td></tr></table></figure>

<p>（3）在 flume 目录下创建 job 文件夹并进入 job 文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# mkdir job</span><br><span class="line">[root@hadoop102 flume]#  cd job/</span><br></pre></td></tr></table></figure>

<p>（4）在 job 文件夹下创建 Flume Agent 配置文件 flume-netcat-logger.conf。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]#  vim flume-netcat-logger.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent   	<span class="comment"># a1:表示agent的名称</span></span></span><br><span class="line">a1.sources = r1   	# r1表示a1的Source的名称</span><br><span class="line">a1.sinks = k1     	# k1表示a1的Sink的名称</span><br><span class="line">a1.channels = c1  	# c1表示a1的Channel的名称</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat		# 表示a1的输入源类型为netcat端口类型</span><br><span class="line">a1.sources.r1.bind = localhost     # 表示a1的监听的主机</span><br><span class="line">a1.sources.r1.port = 44444         # 表示a1的监听的端口号</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger         # 表示a1的输出目的地是控制台logger类型</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory      # 表示a1的channel类型是memory内存型</span><br><span class="line">a1.channels.c1.capacity = 1000    # 表示a1的channel总容量1000个event</span><br><span class="line">a1.channels.c1.transactionCapacity = 100      # 表示a1的channel传输时收集到了100条event以后再去提交事务</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1     # 表示将r1和c1连接起来</span><br><span class="line">a1.sinks.k1.channel = c1        # 表示将k1和c1连接起来</span><br></pre></td></tr></table></figure>

<p>（5）先开启flume监听端口（开启服务端）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">参数说明：</span><br><span class="line">-c：表示配置文件存储在 conf/目录</span><br><span class="line">--n：表示给 agent 起名为 a1</span><br><span class="line">-f：flume 本次启动读取的配置文件是在 job 文件夹下的 flume-telnet.conf文件。</span><br><span class="line">-Dflume.root.logger=INFO,console ：-D 表示 flume 运行时动态修改 flume.root.logger参数属性值，并将控制台日志打印级别设置为 INFO 级别。日志级别包括:log、info、warn、error。console表示将结果输出到控制台</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-20_21-15-51.png" alt="Snipaste_2023-10-20_21-15-51"></p>
<p>（6）在开启客户端（都是在hadoop102上）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]#  nc localhost 44444</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（7）使用netcat工具向本机的44444端口发送内容，并在flume监听页面观察接受数据情况</p>
<p><img src="Snipaste_2023-10-20_21-21-02.png" alt="Snipaste_2023-10-20_21-21-02"></p>
<h3 id="2-2-2-实时监控单个追加文件"><a href="#2-2-2-实时监控单个追加文件" class="headerlink" title="2.2.2 实时监控单个追加文件"></a>2.2.2 实时监控单个追加文件</h3><p>需求：实时监控Hive日志，并上传到HDFS中</p>
<p>分析：</p>
<p><img src="Snipaste_2023-10-21_15-01-39.png" alt="Snipaste_2023-10-21_15-01-39"></p>
<p>步骤：</p>
<p>（1）检查&#x2F;etc&#x2F;profile.d&#x2F;my_env.sh 文件，确认 Hadoop 和 Java 环境变量配置正确</p>
<p>（2）创建 flume-file-hdfs.conf 文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 profile.d]# cd /opt/module/flume/job/</span><br><span class="line">[root@hadoop102 job]# vim flume-file-hdfs.conf</span><br></pre></td></tr></table></figure>

<p>注：要想读取 Linux 系统中的文件，就得按照 Linux 命令的规则执行命令。由于 Hive日志在 Linux 系统中所以读取文件的类型选择：exec 即 execute 执行的意思。表示执行Linux 命令来读取文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a2.sources = r2</span><br><span class="line">a2.sinks = k2</span><br><span class="line">a2.channels = c2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义<span class="built_in">source</span>类型为<span class="built_in">exec</span>可执行命令的</span></span><br><span class="line">a2.sources.r2.type = exec</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看文件末端10行的命令</span></span><br><span class="line">a2.sources.r2.command = tail -F /opt/module/hive/logs/hive.log</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a2.sinks.k2.type = hdfs</span><br><span class="line">a2.sinks.k2.hdfs.path = hdfs://hadoop102:8020/flume/%Y%m%d/%H</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传文件的前缀</span></span><br><span class="line">a2.sinks.k2.hdfs.filePrefix = logs-</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否按照时间滚动文件夹</span></span><br><span class="line">a2.sinks.k2.hdfs.round = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多少时间单位创建一个新的文件夹</span></span><br><span class="line">a2.sinks.k2.hdfs.roundValue = 1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重新定义时间单位</span></span><br><span class="line">a2.sinks.k2.hdfs.roundUnit = hour</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否使用本地时间戳</span></span><br><span class="line">a2.sinks.k2.hdfs.useLocalTimeStamp = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">积攒多少个 Event 才 flush 到 HDFS 一次</span></span><br><span class="line">a2.sinks.k2.hdfs.batchSize = 100</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置文件类型，可支持压缩</span></span><br><span class="line">a2.sinks.k2.hdfs.fileType = DataStream</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多久生成一个新的文件，生产环境中一般配3600</span></span><br><span class="line">a2.sinks.k2.hdfs.rollInterval = 30</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置每个文件的滚动大小</span></span><br><span class="line">a2.sinks.k2.hdfs.rollSize = 134217700</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件的滚动与 Event 数量无关</span></span><br><span class="line">a2.sinks.k2.hdfs.rollCount = 0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a2.channels.c2.type = memory</span><br><span class="line">a2.channels.c2.capacity = 1000</span><br><span class="line">a2.channels.c2.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a2.sources.r2.channels = c2</span><br><span class="line">a2.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure>

<p>（3）运行flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a2 -f job/flume-file-hdfs.conf</span><br></pre></td></tr></table></figure>

<p>可以看到flume文件已经在HDFS上创建了：</p>
<img src="Snipaste_2023-10-21_16-00-33.png" alt="Snipaste_2023-10-21_16-00-33" style="zoom:43%;">

<p>（4）开启hadoop集群和hive服务</p>
<p>（5）在hive上随便执行一个语句，查看HDFS上的日志更新</p>
<img src="Snipaste_2023-10-21_16-05-08.png" alt="Snipaste_2023-10-21_16-05-08" style="zoom:43%;">

<h3 id="2-2-3-实时监控目录下多个新文件"><a href="#2-2-3-实时监控目录下多个新文件" class="headerlink" title="2.2.3 实时监控目录下多个新文件"></a>2.2.3 实时监控目录下多个新文件</h3><p>需求：使用Flume监听整个目录的文件，并上传至HDFS</p>
<p>分析：</p>
<p><img src="Snipaste_2023-10-21_16-10-48.png" alt="Snipaste_2023-10-21_16-10-48"></p>
<p>5 解释：.COMPLETED结尾表示已经上传，.tmp结尾表示还没有上传</p>
<p>步骤：</p>
<p>（1）创建配置文件flume-dir-hdfs.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# vim flume-dir-hdfs.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">a3.sources = r3</span><br><span class="line">a3.sinks = k3</span><br><span class="line">a3.channels = c3</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a3.sources.r3.type = spooldir</span><br><span class="line">a3.sources.r3.spoolDir = /opt/module/flume/upload</span><br><span class="line">a3.sources.r3.fileSuffix = .COMPLETED</span><br><span class="line">a3.sources.r3.fileHeader = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">忽略所有以.tmp 结尾的文件，不上传</span></span><br><span class="line">a3.sources.r3.ignorePattern = ([^ ]*\.tmp)</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a3.sinks.k3.type = hdfs</span><br><span class="line">a3.sinks.k3.hdfs.path = hdfs://hadoop102:8020/flume/upload/%Y%m%d/%H</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传文件的前缀</span></span><br><span class="line">a3.sinks.k3.hdfs.filePrefix = upload-</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否按照时间滚动文件夹</span></span><br><span class="line">a3.sinks.k3.hdfs.round = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多少时间单位创建一个新的文件夹</span></span><br><span class="line">a3.sinks.k3.hdfs.roundValue = 1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重新定义时间单位</span></span><br><span class="line">a3.sinks.k3.hdfs.roundUnit = hour</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否使用本地时间戳</span></span><br><span class="line">a3.sinks.k3.hdfs.useLocalTimeStamp = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">积攒多少个 Event 才 flush 到 HDFS 一次</span></span><br><span class="line">a3.sinks.k3.hdfs.batchSize = 100</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置文件类型，可支持压缩</span></span><br><span class="line">a3.sinks.k3.hdfs.fileType = DataStream</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多久生成一个新的文件</span></span><br><span class="line">a3.sinks.k3.hdfs.rollInterval = 20</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置每个文件的滚动大小大概是 128M</span></span><br><span class="line">a3.sinks.k3.hdfs.rollSize = 134217700</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件的滚动与 Event 数量无关</span></span><br><span class="line">a3.sinks.k3.hdfs.rollCount = 0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a3.channels.c3.type = memory</span><br><span class="line">a3.channels.c3.capacity = 1000</span><br><span class="line">a3.channels.c3.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a3.sources.r3.channels = c3</span><br><span class="line">a3.sinks.k3.channel = c3</span><br></pre></td></tr></table></figure>

<p>（2）在&#x2F;opt&#x2F;module&#x2F;flume 目录下创建 upload 文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]#  mkdir upload</span><br></pre></td></tr></table></figure>

<p>（3）启动监控文件夹命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a3 -f job/flume-dir-hdfs.conf</span><br></pre></td></tr></table></figure>

<p>（4）向 upload 文件夹中添加文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 upload]# touch atguigu.txt</span><br><span class="line">[root@hadoop102 upload]# touch atguigu.tmp</span><br><span class="line">[root@hadoop102 upload]# touch atguigu.log</span><br><span class="line">[root@hadoop102 upload]# ll</span><br><span class="line">总用量 0</span><br><span class="line">-rw-r--r--. 1 root root 0 10月 21 16:32 atguigu.log.COMPLETED</span><br><span class="line">-rw-r--r--. 1 root root 0 10月 21 16:31 atguigu.tmp</span><br><span class="line">-rw-r--r--. 1 root root 0 10月 21 16:29 atguigu.txt.COMPLETED</span><br></pre></td></tr></table></figure>

<p>可以发现.tmp结尾的文件是没有被上传至HDFS中的：</p>
<img src="Snipaste_2023-10-21_16-33-46.png" alt="Snipaste_2023-10-21_16-33-46" style="zoom:43%;">

<h3 id="2-2-4-实时监控目录下的多个追加文件"><a href="#2-2-4-实时监控目录下的多个追加文件" class="headerlink" title="2.2.4 实时监控目录下的多个追加文件"></a>2.2.4 实时监控目录下的多个追加文件</h3><p>Exec source 适用于监控一个实时追加的文件，不能实现断点续传；Spooldir Source适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步；而 <strong>Taildir Source</strong>适合用于监听多个实时追加的文件，并且能够实现断点续传。</p>
<p>Spooldir Source：监控同一目录的不同文件</p>
<p>Taildir Source：监控不同目录的不同文件</p>
<p>需求：使用Flume监听整个目录的实时追加文件，并上传至HDFS</p>
<p>分析：</p>
<p><img src="Snipaste_2023-10-21_16-51-57.png" alt="Snipaste_2023-10-21_16-51-57"></p>
<p>步骤：</p>
<p>（1）创建配置文件 flume-taildir-hdfs.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# vim flume-taildir-hdfs.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">a3.sources = r3</span><br><span class="line">a3.sinks = k3</span><br><span class="line">a3.channels = c3</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a3.sources.r3.type = TAILDIR</span><br><span class="line">a3.sources.r3.positionFile = /opt/module/flume/tail_dir.json</span><br><span class="line">a3.sources.r3.filegroups = f1 f2</span><br><span class="line">a3.sources.r3.filegroups.f1 = /opt/module/flume/files/.*file.*</span><br><span class="line">a3.sources.r3.filegroups.f2 = /opt/module/flume/files2/.*log.*</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a3.sinks.k3.type = hdfs</span><br><span class="line">a3.sinks.k3.hdfs.path = hdfs://hadoop102:8020/flume/upload2/%Y%m%d/%H</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传文件的前缀</span></span><br><span class="line">a3.sinks.k3.hdfs.filePrefix = upload-</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否按照时间滚动文件夹</span></span><br><span class="line">a3.sinks.k3.hdfs.round = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多少时间单位创建一个新的文件夹</span></span><br><span class="line">a3.sinks.k3.hdfs.roundValue = 1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重新定义时间单位</span></span><br><span class="line">a3.sinks.k3.hdfs.roundUnit = hour</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否使用本地时间戳</span></span><br><span class="line">a3.sinks.k3.hdfs.useLocalTimeStamp = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">积攒多少个 Event 才 flush 到 HDFS 一次</span></span><br><span class="line">a3.sinks.k3.hdfs.batchSize = 100</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置文件类型，可支持压缩</span></span><br><span class="line">a3.sinks.k3.hdfs.fileType = DataStream</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多久生成一个新的文件</span></span><br><span class="line">a3.sinks.k3.hdfs.rollInterval = 20</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置每个文件的滚动大小大概是 128M</span></span><br><span class="line">a3.sinks.k3.hdfs.rollSize = 134217700</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件的滚动与 Event 数量无关</span></span><br><span class="line">a3.sinks.k3.hdfs.rollCount = 0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a3.channels.c3.type = memory</span><br><span class="line">a3.channels.c3.capacity = 1000</span><br><span class="line">a3.channels.c3.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a3.sources.r3.channels = c3</span><br><span class="line">a3.sinks.k3.channel = c3</span><br></pre></td></tr></table></figure>

<p>（2）在&#x2F;opt&#x2F;module&#x2F;flume 目录下创建 files 文件夹和files2文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# mkdir files</span><br><span class="line">[root@hadoop102 flume]# mkdir files2</span><br></pre></td></tr></table></figure>

<p>（3）启动监控文件夹命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a3 -f job/flume-taildir-hdfs.conf</span><br></pre></td></tr></table></figure>

<p>（4）向 files 文件夹中追加内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# cd files</span><br><span class="line">[root@hadoop102 files]# touch file1.txt</span><br><span class="line">[root@hadoop102 files]# echo hello &gt;&gt; file1.txt</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-21_17-11-45.png" alt="Snipaste_2023-10-21_17-11-45" style="zoom:43%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">继续追加</span></span><br><span class="line">[root@hadoop102 files]# echo atguigu &gt;&gt; file1.txt</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-21_17-13-49.png" alt="Snipaste_2023-10-21_17-13-49" style="zoom:43%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">向 files2 文件夹中追加内容</span></span><br><span class="line">[root@hadoop102 files2]# touch log.txt</span><br><span class="line">[root@hadoop102 files2]# echo hello2 &gt;&gt; log.txt </span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-21_17-16-24.png" alt="Snipaste_2023-10-21_17-16-24" style="zoom:43%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">继续追加</span></span><br><span class="line">[root@hadoop102 files2]# echo atguigu2 &gt;&gt; log.txt</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-21_17-18-01.png" alt="Snipaste_2023-10-21_17-18-01" style="zoom:43%;">

<p>Taildir Source 维护了一个 json 格式的 position File，其会定期的往 position File中更新每个文件读取到的最新的位置，因此能够实现断点续传。Position File 的格式如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;inode&quot;</span><span class="punctuation">:</span><span class="number">104996452</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;pos&quot;</span><span class="punctuation">:</span><span class="number">14</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;file&quot;</span><span class="punctuation">:</span><span class="string">&quot;/opt/module/flume/files/file1.txt&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;inode&quot;</span><span class="punctuation">:</span><span class="number">3349704</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;pos&quot;</span><span class="punctuation">:</span><span class="number">16</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;file&quot;</span><span class="punctuation">:</span><span class="string">&quot;/opt/module/flume/files2/log.txt&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>注：Linux 中储存文件元数据的区域就叫做 inode，每个 inode 都有一个号码，操作系统用 inode 号码来识别不同的文件，Unix&#x2F;Linux 系统内部不使用文件名，而使用 inode 号码来识别文件。</p>
<h1 id="第三章-Flume进阶"><a href="#第三章-Flume进阶" class="headerlink" title="第三章 Flume进阶"></a>第三章 Flume进阶</h1><h2 id="3-1-Flume事务"><a href="#3-1-Flume事务" class="headerlink" title="3.1 Flume事务"></a>3.1 Flume事务</h2><p><img src="Snipaste_2023-10-21_19-47-32.png" alt="Snipaste_2023-10-21_19-47-32"></p>
<h2 id="3-2-Flume-Agent内部原理"><a href="#3-2-Flume-Agent内部原理" class="headerlink" title="3.2 Flume Agent内部原理"></a>3.2 Flume Agent内部原理</h2><p><img src="Snipaste_2023-10-21_19-52-06.png" alt="Snipaste_2023-10-21_19-52-06"></p>
<p>重要组件：</p>
<p>（1）Channel Selector</p>
<p>ChannelSelector 的作用就是选出 Event 将要被发往哪个 Channel。其共有两种类型，分别是 Replicating（复制）和 Multiplexing（多路复用）。</p>
<p>ReplicatingSelector 会将同一个 Event发往所有的 Channel，Multiplexing 会根据相应的原则，将不同的 Event 发往不同的 Channel。</p>
<p>（2）Sink Processor</p>
<p>SinkProcessor共有三种类型，分 别 是 DefaultSinkProcessor 、LoadBalancingSinkProcessor 和 FailoverSinkProcessor。</p>
<p>DefaultSinkProcessor 对 应 的 是 单 个 的 Sink ，LoadBalancingSinkProcessor 和FailoverSinkProcessor 对应的是 Sink Group，LoadBalancingSinkProcessor 可以实现负载均衡的功能，FailoverSinkProcessor 可以错误恢复的功能。</p>
<h2 id="3-3-Flume拓扑结构"><a href="#3-3-Flume拓扑结构" class="headerlink" title="3.3 Flume拓扑结构"></a>3.3 Flume拓扑结构</h2><h3 id="3-3-1-简单串联"><a href="#3-3-1-简单串联" class="headerlink" title="3.3.1 简单串联"></a>3.3.1 简单串联</h3><img src="Snipaste_2023-10-21_20-05-52.png" alt="Snipaste_2023-10-21_20-05-52" style="zoom:43%;">

<p>这种模式是将多个 flume 顺序连接起来了，从最初的 source 开始到最终 sink 传送的目的存储系统。此模式不建议桥接过多的 flume 数量， flume 数量过多不仅会影响传输速率，而且一旦传输过程中某个节点 flume 宕机，会影响整个传输系统。</p>
<h3 id="3-3-2-复制和多路复用"><a href="#3-3-2-复制和多路复用" class="headerlink" title="3.3.2 复制和多路复用"></a>3.3.2 复制和多路复用</h3><img src="Snipaste_2023-10-21_20-06-34.png" alt="Snipaste_2023-10-21_20-06-34" style="zoom:43%;">

<p>Flume 支持将事件流向一个或者多个目的地。这种模式可以将相同数据复制到多个channel 中，或者将不同数据分发到不同的 channel 中，sink 可以选择传送到不同的目的地。</p>
<h3 id="3-3-3-负载均衡和故障转移"><a href="#3-3-3-负载均衡和故障转移" class="headerlink" title="3.3.3 负载均衡和故障转移"></a>3.3.3 负载均衡和故障转移</h3><img src="Snipaste_2023-10-21_20-07-50.png" alt="Snipaste_2023-10-21_20-07-50" style="zoom:43%;">

<p>Flume支持使用将多个sink逻辑上分到一个sink组，sink组配合不同的SinkProcessor可以实现负载均衡和错误恢复的功能。</p>
<h3 id="3-3-4-聚合"><a href="#3-3-4-聚合" class="headerlink" title="3.3.4 聚合"></a>3.3.4 聚合</h3><img src="Snipaste_2023-10-21_20-31-49.png" alt="Snipaste_2023-10-21_20-31-49" style="zoom:43%;">

<p>这种模式是我们最常见的，也非常实用，日常 web 应用通常分布在上百个服务器，大者甚至上千个、上万个服务器。产生的日志，处理起来也非常麻烦。用 flume 的这种组合方式能很好的解决这一问题，每台服务器部署一个 flume 采集日志，传送到一个集中收集日志的flume，再由此 flume 上传到 hdfs、hive、hbase 等，进行日志分析。</p>
<h2 id="3-4-Flume企业开发案例"><a href="#3-4-Flume企业开发案例" class="headerlink" title="3.4 Flume企业开发案例"></a>3.4 Flume企业开发案例</h2><h3 id="3-4-1-复制"><a href="#3-4-1-复制" class="headerlink" title="3.4.1 复制"></a>3.4.1 复制</h3><p>（1）需求</p>
<p>使用 Flume-1 监控文件变动，Flume-1 将变动内容传递给 Flume-2，Flume-2 负责存储到 HDFS。同时 Flume-1 将变动内容传递给 Flume-3，Flume-3 负责输出到 Local FileSystem。</p>
<p>（2）分析</p>
<p><img src="Snipaste_2023-10-21_20-45-59.png" alt="Snipaste_2023-10-21_20-45-59"></p>
<p>（3）实现步骤：</p>
<p>①在&#x2F;opt&#x2F;module&#x2F;flume&#x2F;job 目录下创建 group1 文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# mkdir group1</span><br><span class="line">[root@hadoop102 job]# cd group1/</span><br></pre></td></tr></table></figure>

<p>在&#x2F;opt&#x2F;module&#x2F;datas&#x2F;目录下创建 flume3 文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# mkdir flume3</span><br></pre></td></tr></table></figure>

<p>②创建 flume-file-flume.conf</p>
<p>配置 1 个接收日志文件的 source 和两个 channel、两个 sink，分别输送给 flume-flumehdfs 和 flume-flume-dir。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group1]# vim flume-file-flume.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将数据流复制给所有 channel</span></span><br><span class="line">a1.sources.r1.selector.type = replicating</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /opt/module/hive/logs/hive.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sink 端的 avro 是一个数据发送者</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop102</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop102</span><br><span class="line">a1.sinks.k2.port = 4142</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line">a1.channels.c2.type = memory</span><br><span class="line">a1.channels.c2.capacity = 1000</span><br><span class="line">a1.channels.c2.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure>

<p>③创建 flume-flume-hdfs.conf</p>
<p>配置上级 Flume 输出的 Source，输出是到 HDFS 的 Sink。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group1]# vim flume-flume-hdfs.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a2.sources = r1</span><br><span class="line">a2.sinks = k1</span><br><span class="line">a2.channels = c1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">source</span> 端的 avro 是一个数据接收服务</span></span><br><span class="line">a2.sources.r1.type = avro</span><br><span class="line">a2.sources.r1.bind = hadoop102</span><br><span class="line">a2.sources.r1.port = 4141</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a2.sinks.k1.type = hdfs</span><br><span class="line">a2.sinks.k1.hdfs.path = hdfs://hadoop102:8020/flume2/%Y%m%d/%H</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传文件的前缀</span></span><br><span class="line">a2.sinks.k1.hdfs.filePrefix = flume2-</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否按照时间滚动文件夹</span></span><br><span class="line">a2.sinks.k1.hdfs.round = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多少时间单位创建一个新的文件夹</span></span><br><span class="line">a2.sinks.k1.hdfs.roundValue = 1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">重新定义时间单位</span></span><br><span class="line">a2.sinks.k1.hdfs.roundUnit = hour</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">是否使用本地时间戳</span></span><br><span class="line">a2.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">积攒多少个 Event 才 flush 到 HDFS 一次</span></span><br><span class="line">a2.sinks.k1.hdfs.batchSize = 100</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置文件类型，可支持压缩</span></span><br><span class="line">a2.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">多久生成一个新的文件</span></span><br><span class="line">a2.sinks.k1.hdfs.rollInterval = 30</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置每个文件的滚动大小大概是 128M</span></span><br><span class="line">a2.sinks.k1.hdfs.rollSize = 134217700</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件的滚动与 Event 数量无关</span></span><br><span class="line">a2.sinks.k1.hdfs.rollCount = 0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a2.channels.c1.type = memory</span><br><span class="line">a2.channels.c1.capacity = 1000</span><br><span class="line">a2.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a2.sources.r1.channels = c1</span><br><span class="line">a2.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>④创建 flume-flume-dir.conf</p>
<p>配置上级 Flume 输出的 Source，输出是到本地目录的 Sink。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group1]# vim flume-flume-dir.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a3.sources = r1</span><br><span class="line">a3.sinks = k1</span><br><span class="line">a3.channels = c2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a3.sources.r1.type = avro</span><br><span class="line">a3.sources.r1.bind = hadoop102</span><br><span class="line">a3.sources.r1.port = 4142</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a3.sinks.k1.type = file_roll</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">提示：输出的本地目录必须是已经存在的目录，如果该目录不存在，并不会创建新的目录</span></span><br><span class="line">a3.sinks.k1.sink.directory = /opt/module/datas/flume3</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a3.channels.c2.type = memory</span><br><span class="line">a3.channels.c2.capacity = 1000</span><br><span class="line">a3.channels.c2.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a3.sources.r1.channels = c2</span><br><span class="line">a3.sinks.k1.channel = c2</span><br></pre></td></tr></table></figure>

<p>⑤执行配置文件</p>
<p>分别启动对应的 flume 进程：flume-flume-dir，flume-flume-hdfs，flume-file-flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a3 -f job/group1/flume-flume-dir.conf</span><br><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a2 -f job/group1/flume-flume-hdfs.conf</span><br><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/group1/flume-file-flume.conf</span><br></pre></td></tr></table></figure>

<p>⑥启动HDFS和Hive，检查Web端</p>
<p><img src="Snipaste_2023-10-21_21-28-01.png" alt="Snipaste_2023-10-21_21-28-01"></p>
<p>⑦检查&#x2F;opt&#x2F;module&#x2F;datas&#x2F;flume3 目录中数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume3]# ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 root root    0 10月 21 20:51 1697892687504-1</span><br><span class="line">-rw-r--r--. 1 root root 1546 10月 21 20:52 1697892687504-2</span><br><span class="line">-rw-r--r--. 1 root root    0 10月 21 20:52 1697892687504-3</span><br><span class="line">-rw-r--r--. 1 root root    0 10月 21 20:53 1697892687504-4</span><br><span class="line">-rw-r--r--. 1 root root    0 10月 21 20:53 1697892687504-5</span><br><span class="line">-rw-r--r--. 1 root root    0 10月 21 20:53 1697892687504-6</span><br><span class="line">-rw-r--r--. 1 root root    0 10月 21 20:54 1697892687504-7</span><br><span class="line">-rw-r--r--. 1 root root    0 10月 21 20:55 1697892687504-8</span><br><span class="line">-rw-r--r--. 1 root root    0 10月 21 20:55 1697892687504-9</span><br></pre></td></tr></table></figure>

<h3 id="3-4-2-故障转移"><a href="#3-4-2-故障转移" class="headerlink" title="3.4.2 故障转移"></a>3.4.2 故障转移</h3><p>需求：</p>
<p>使用 Flume1 监控一个端口，其 sink 组中的 sink 分别对接 Flume2 和 Flume3，采用FailoverSinkProcessor，实现故障转移的功能。</p>
<p>分析：</p>
<img src="Snipaste_2023-10-21_21-34-27.png" alt="Snipaste_2023-10-21_21-34-27">

<p>步骤：</p>
<p>（1）准备工作：</p>
<p>在&#x2F;opt&#x2F;module&#x2F;flume&#x2F;job 目录下创建 group2 文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# mkdir group2</span><br><span class="line">[root@hadoop102 job]# cd group2/</span><br></pre></td></tr></table></figure>

<p>（2）创建 flume-netcat-flume.conf</p>
<p>配置 1 个 netcat source 和 1 个 channel、1 个 sink group（2 个 sink），分别输送给flume-flume-console1 和 flume-flume-console2。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group2]# vim flume-netcat-flume.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line">a1.sinkgroups.g1.processor.type = failover</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k1 = 5</span><br><span class="line">a1.sinkgroups.g1.processor.priority.k2 = 10</span><br><span class="line">a1.sinkgroups.g1.processor.maxpenalty = 10000</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop102</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop102</span><br><span class="line">a1.sinks.k2.port = 4142</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c1</span><br></pre></td></tr></table></figure>

<p>（3）创建 flume-flume-console1.conf</p>
<p>配置上级 Flume 输出的 Source，输出是到本地控制台。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group2]# vim flume-flume-console1.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a2.sources = r1</span><br><span class="line">a2.sinks = k1</span><br><span class="line">a2.channels = c1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a2.sources.r1.type = avro</span><br><span class="line">a2.sources.r1.bind = hadoop102</span><br><span class="line">a2.sources.r1.port = 4141</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a2.sinks.k1.type = logger</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a2.channels.c1.type = memory</span><br><span class="line">a2.channels.c1.capacity = 1000</span><br><span class="line">a2.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a2.sources.r1.channels = c1</span><br><span class="line">a2.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>（4）创建 flume-flume-console2.conf</p>
<p>配置上级 Flume 输出的 Source，输出是到本地控制台。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group2]# vim flume-flume-console2.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a3.sources = r1</span><br><span class="line">a3.sinks = k1</span><br><span class="line">a3.channels = c2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a3.sources.r1.type = avro</span><br><span class="line">a3.sources.r1.bind = hadoop102</span><br><span class="line">a3.sources.r1.port = 4142</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a3.sinks.k1.type = logger</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a3.channels.c2.type = memory</span><br><span class="line">a3.channels.c2.capacity = 1000</span><br><span class="line">a3.channels.c2.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a3.sources.r1.channels = c2</span><br><span class="line">a3.sinks.k1.channel = c2</span><br></pre></td></tr></table></figure>

<p>（5）执行配置文件</p>
<p>分别开启对应配置文件：flume-flume-console2，flume-flume-console1，flume-netcat-flume。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a3 -f job/group2/flume-flume-console2.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a2 -f job/group2/flume-flume-console1.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/group2/flume-netcat-flume.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>（6）使用netcat工具向本机的44444端口发送内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# nc localhost 44444</span><br><span class="line">hello</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>由于console2（Flume3）的优先级高，可以在其服务端看到控制台打印的日志：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2023-10-21 21:23:43,601 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F                                  hello &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（7）将console2（Flume3）的服务停掉，再使用netcat工具发送内容，此时故障转移，可以在console1（Flume2）上看到控制台打印的日志：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2023-10-21 21:28:43,122 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 77 79 68                                        wyh &#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-4-2-负载均衡"><a href="#3-4-2-负载均衡" class="headerlink" title="3.4.2+ 负载均衡"></a>3.4.2+ 负载均衡</h3><p>（1）将group2中的flume-netcat-flume.conf配置文件复制一份，并重命名为flume-netcat-flume2.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group2]# cp flume-netcat-flume.conf flume-netcat-flume2.conf</span><br></pre></td></tr></table></figure>

<p>（2）修改flume-netcat-flume2.conf配置文件中的内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group2]# vim flume-netcat-flume2.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinkgroups = g1</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line">a1.sinkgroups.g1.processor.type = load_balance</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop102</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop102</span><br><span class="line">a1.sinks.k2.port = 4142</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c1</span><br></pre></td></tr></table></figure>

<p>（3）执行配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a3 -f job/group2/flume-flume-console2.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a2 -f job/group2/flume-flume-console1.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/group2/flume-netcat-flume2.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>（4）使用netcat工具向本机的44444端口发送内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# nc localhost 44444</span><br><span class="line">hello    # flume3端输出日志</span><br><span class="line">OK</span><br><span class="line">atguigu  # flume2端输出日志</span><br><span class="line">OK</span><br><span class="line">123      # flume2端输出日志</span><br><span class="line">OK</span><br><span class="line">alibaba   # flume3端输出日志</span><br><span class="line">OK</span><br><span class="line">djkdjkdj   # flume2端输出日志</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>flume3端：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 12:48:59,423 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F                                  hello &#125;</span><br><span class="line">2023-10-22 12:51:14,806 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 6C 69 62 61 62 61                            alibaba &#125;</span><br></pre></td></tr></table></figure>

<p>flume2端：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 12:50:14,710 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75                            atguigu &#125;</span><br><span class="line">2023-10-22 12:50:36,750 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 31 32 33                                        123 &#125;</span><br><span class="line">2023-10-22 12:51:39,836 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 64 6A 6B 64 6A 6B 64 6A                         djkdjkdj &#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-4-3-聚合"><a href="#3-4-3-聚合" class="headerlink" title="3.4.3 聚合"></a>3.4.3 聚合</h3><p>需求：</p>
<p>hadoop102 上的 Flume-1 监控文件&#x2F;opt&#x2F;module&#x2F;group.log，</p>
<p>hadoop103 上的 Flume-2 监控某一个端口的数据流，</p>
<p>Flume-1 与 Flume-2 将数据发送给 hadoop104 上的 Flume-3，Flume-3 将最终数据打印到控制台。</p>
<p>分析：</p>
<p><img src="Snipaste_2023-10-22_13-10-01.png" alt="Snipaste_2023-10-22_13-10-01"></p>
<p>步骤：</p>
<p>（1）准备工作</p>
<p>分发Flume</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# xsync flume</span><br></pre></td></tr></table></figure>

<p>在 hadoop102、hadoop103 以及 hadoop104 的&#x2F;opt&#x2F;module&#x2F;flume&#x2F;job 目录下创建一个group3 文件夹。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# mkdir group3</span><br><span class="line">[root@hadoop103 job]# mkdir group3</span><br><span class="line">[root@hadoop104 job]# mkdir group3</span><br></pre></td></tr></table></figure>

<p>在&#x2F;opt&#x2F;module&#x2F;上创建文件group.log</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# vim group.log</span><br></pre></td></tr></table></figure>

<p>（2）创建 flume1-logger-flume.conf</p>
<p>配置 Source 用于监控 group.log 文件，配置 Sink 输出数据到下一级 Flume。</p>
<p>在 hadoop102 上编辑配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 group3]# vim flume1-logger-flume.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /opt/module/group.log</span><br><span class="line">a1.sources.r1.shell = /bin/bash -c</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop104</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>（3）创建 flume2-netcat-flume.conf</p>
<p>配置 Source 监控端口 44444 数据流，配置 Sink 数据到下一级 Flume：</p>
<p>在 hadoop103 上编辑配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 group3]# vim flume2-netcat-flume.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a2.sources = r1</span><br><span class="line">a2.sinks = k1</span><br><span class="line">a2.channels = c1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a2.sources.r1.type = netcat</span><br><span class="line">a2.sources.r1.bind = hadoop103</span><br><span class="line">a2.sources.r1.port = 44444</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a2.sinks.k1.type = avro</span><br><span class="line">a2.sinks.k1.hostname = hadoop104</span><br><span class="line">a2.sinks.k1.port = 4141</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a2.channels.c1.type = memory</span><br><span class="line">a2.channels.c1.capacity = 1000</span><br><span class="line">a2.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a2.sources.r1.channels = c1</span><br><span class="line">a2.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>（4）创建 flume3-flume-logger.conf</p>
<p>配置 source 用于接收 flume1 与 flume2 发送过来的数据流，最终合并后 sink 到控制台。</p>
<p>在 hadoop104 上编辑配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 group3]# vim flume3-flume-logger.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a3.sources = r1</span><br><span class="line">a3.sinks = k1</span><br><span class="line">a3.channels = c1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a3.sources.r1.type = avro</span><br><span class="line">a3.sources.r1.bind = hadoop104</span><br><span class="line">a3.sources.r1.port = 4141</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a3.sinks.k1.type = logger</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the channel</span></span><br><span class="line">a3.channels.c1.type = memory</span><br><span class="line">a3.channels.c1.capacity = 1000</span><br><span class="line">a3.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a3.sources.r1.channels = c1</span><br><span class="line">a3.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>（5）执行配置文件</p>
<p>分别开启对应配置文件：flume3-flume-logger.conf，flume2-netcat-flume.conf，flume1-logger-flume.conf。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 flume]# bin/flume-ng agent -c conf/ -n a3 -f job/group3/flume3-flume-logger.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">[root@hadoop103 flume]# bin/flume-ng agent -c conf/ -n a2 -f job/group3/flume2-netcat-flume.conf</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/group3/flume1-logger-flume.conf</span><br></pre></td></tr></table></figure>

<p>（6）在hadoop103开启44444端口，并传输数据hello</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 ~]# nc hadoop103 44444</span><br><span class="line">hello</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>此时可以在hadoop104上看到由控制台输出打印的日志：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 14:05:59,473 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F                                  hello &#125;</span><br></pre></td></tr></table></figure>

<p>（7）在hadoop102端的&#x2F;opt&#x2F;module&#x2F;group.log中追加内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# echo &#x27;hello222&#x27; &gt;&gt; group.log</span><br></pre></td></tr></table></figure>

<p>此时也可以在hadoop104上看到由控制台输出打印的日志：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 14:08:35,734 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F 32 32 32                         hello222 &#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-5-自定义拦截器（Interceptor）——多路复用（常用）"><a href="#3-5-自定义拦截器（Interceptor）——多路复用（常用）" class="headerlink" title="3.5 自定义拦截器（Interceptor）——多路复用（常用）"></a>3.5 自定义拦截器（Interceptor）——多路复用（常用）</h2><p>需求：</p>
<p>使用 Flume 采集服务器本地日志，需要按照日志<strong>类型的不同</strong>，将不同种类的日志发往不同的分析系统。</p>
<p>分析：</p>
<p>在实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要发送到不同的分析系统。此时会用到 Flume 拓扑结构中的 Multiplexing（多路复用） 结构，Multiplexing的原理是，根据 event 中 Header 的某个 key 的值，将不同的 event 发送到不同的 Channel中，所以我们需要自定义一个 Interceptor，为不同类型的 event 的 Header 中的 key 赋予不同的值。</p>
<p>在该案例中，我们以端口数据模拟日志，以是否包含”atguigu”模拟不同类型的日志，我们需要自定义 interceptor 区分数据中是否包含”atguigu”，将其分别发往不同的分析系统（Channel）。</p>
<p><img src="Snipaste_2023-10-22_14-20-56.png" alt="Snipaste_2023-10-22_14-20-56"></p>
<p>步骤：</p>
<p>（1）创建一个maven项目，并引入以下依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flume<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flume-ng-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）定义TypeInterceptor类并实现Interceptor接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TypeInterceptor</span> <span class="keyword">implements</span> <span class="title class_">Interceptor</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//声明一个存放事件的集合</span></span><br><span class="line">    <span class="keyword">private</span> List&lt;Event&gt; addHeaderEvents;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">//初始化存放事件的集合</span></span><br><span class="line">        addHeaderEvents = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//单个事件拦截</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Event <span class="title function_">intercept</span><span class="params">(Event event)</span> &#123;</span><br><span class="line">        <span class="comment">//1.获取事件中的头信息</span></span><br><span class="line">        Map&lt;String, String&gt; headers = event.getHeaders();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.获取事件中的 body 信息</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">body</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(event.getBody());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.根据 body 中是否有&quot;atguigu&quot;来决定添加怎样的头信息</span></span><br><span class="line">        <span class="keyword">if</span> (body.contains(<span class="string">&quot;atguigu&quot;</span>)) &#123;</span><br><span class="line">            <span class="comment">//4.添加头信息</span></span><br><span class="line">            headers.put(<span class="string">&quot;type&quot;</span>, <span class="string">&quot;first&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//4.添加头信息</span></span><br><span class="line">            headers.put(<span class="string">&quot;type&quot;</span>, <span class="string">&quot;second&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> event;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//批量事件拦截</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> List&lt;Event&gt; <span class="title function_">intercept</span><span class="params">(List&lt;Event&gt; events)</span> &#123;</span><br><span class="line">        <span class="comment">//1.清空集合</span></span><br><span class="line">        addHeaderEvents.clear();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.遍历 events</span></span><br><span class="line">        <span class="keyword">for</span> (Event event : events) &#123;</span><br><span class="line">            <span class="comment">//3.给每一个事件添加头信息</span></span><br><span class="line">            addHeaderEvents.add(intercept(event));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.返回结果</span></span><br><span class="line">        <span class="keyword">return</span> addHeaderEvents;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建一个静态内部类Builder，帮助我们构建拦截器对象</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Builder</span> <span class="keyword">implements</span> <span class="title class_">Interceptor</span>.Builder&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> Interceptor <span class="title function_">build</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">TypeInterceptor</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）将该程序打成jar包，将jar包放到opt&#x2F;module&#x2F;flume&#x2F;lib&#x2F;下</p>
<p><img src="Snipaste_2023-10-22_14-53-38.png" alt="Snipaste_2023-10-22_14-53-38"></p>
<p>（4）编辑 flume 配置文件</p>
<p>为 hadoop102 上的 Flume1 配置 1 个 netcat source，1 个 sink group（2 个 avro sink），并配置相应的 ChannelSelector 和 interceptor。为 hadoop103 上的 Flume2 配置一个 avro source 和一个 logger sink。为 hadoop104 上的 Flume3 配置一个 avro source 和一个 logger sink。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# mkdir group4</span><br><span class="line">[root@hadoop102 job]# cd group4/</span><br><span class="line">[root@hadoop102 group4]# vim flume1.conf</span><br><span class="line">[root@hadoop102 group4]# vim flume2.conf</span><br><span class="line">[root@hadoop102 group4]# vim flume3.conf</span><br></pre></td></tr></table></figure>

<p>分别编写配置文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">flume1</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type = com.atguigu.interceptor.TypeInterceptor$Builder</span><br><span class="line">a1.sources.r1.selector.type = multiplexing</span><br><span class="line">a1.sources.r1.selector.header = type</span><br><span class="line">a1.sources.r1.selector.mapping.first = c1</span><br><span class="line">a1.sources.r1.selector.mapping.second = c2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = hadoop103</span><br><span class="line">a1.sinks.k1.port = 4141</span><br><span class="line">a1.sinks.k2.type=avro</span><br><span class="line">a1.sinks.k2.hostname = hadoop104</span><br><span class="line">a1.sinks.k2.port = 4242</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c2.type = memory</span><br><span class="line">a1.channels.c2.capacity = 1000</span><br><span class="line">a1.channels.c2.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">flume2</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = hadoop103</span><br><span class="line">a1.sources.r1.port = 4141</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">flume3</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = hadoop104</span><br><span class="line">a1.sources.r1.port = 4242</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sources.r1.channels = c1</span><br></pre></td></tr></table></figure>

<p>编写完配置文件后，分发给hadoop103和hadoop104</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# xsync group4/</span><br></pre></td></tr></table></figure>

<p>（5）分别在hadoop103，hadoop104 ，hadoop102上启动 flume 进程，注意先后顺序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/group4/flume2.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">[root@hadoop104 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/group4/flume3.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/group4/flume1.conf </span><br></pre></td></tr></table></figure>

<p>（6）在 hadoop102 使用 netcat 向 localhost:44444 发送字母和数字</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# nc localhost 44444</span><br><span class="line">atguiguaaa   # 在hadoop103上打印日志</span><br><span class="line">OK</span><br><span class="line">wyh        # 在hadoop104上打印日志</span><br><span class="line">OK</span><br><span class="line">666atguigu555   # 在hadoop103上打印日志</span><br><span class="line">OK</span><br><span class="line">alibaba      # 在hadoop104上打印日志</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>在hadoop103端：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 15:23:14,731 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;type=first&#125; body: 61 74 67 75 69 67 75 61 61 61                   atguiguaaa &#125;</span><br><span class="line">2023-10-22 15:27:20,998 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;type=first&#125; body: 36 36 36 61 74 67 75 69 67 75 35 35 35          666atguigu555 &#125;</span><br></pre></td></tr></table></figure>

<p>在hadoop104端：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 15:26:24,479 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;type=second&#125; body: 77 79 68                                        wyh &#125;</span><br><span class="line">2023-10-22 15:27:56,606 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;type=second&#125; body: 61 6C 69 62 61 62 61                            alibaba &#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-6-自定义Source（较少使用）"><a href="#3-6-自定义Source（较少使用）" class="headerlink" title="3.6 自定义Source（较少使用）"></a>3.6 自定义Source（较少使用）</h2><p>（1）介绍</p>
<p>Source 是负责接收数据到 Flume Agent 的组件。Source 组件可以处理各种类型、各种格式的日志数据，包括 avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy。官方提供的 source 类型已经很多，但是有时候并不能满足实际开发当中的需求，此时我们就需要根据实际需求自定义某些 source。</p>
<p>根据官方说明自定义MySource 需要继承 AbstractSource 类并实现 Configurable 和 PollableSource 接口。</p>
<img src="Snipaste_2023-10-22_15-42-23.png" alt="Snipaste_2023-10-22_15-42-23" style="zoom:50%;">

<p>（2）需求：</p>
<p>使用 flume 接收数据，并给每条数据添加前缀，输出到控制台。前缀可从 flume 配置文件中配置</p>
<img src="Snipaste_2023-10-22_15-51-12.png" alt="Snipaste_2023-10-22_15-51-12" style="zoom:50%;">

<p>（3）分析</p>
<img src="Snipaste_2023-10-22_15-52-29.png" alt="Snipaste_2023-10-22_15-52-29" style="zoom:50%;">

<p>（4）编码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySource</span> <span class="keyword">extends</span> <span class="title class_">AbstractSource</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span>, PollableSource &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//定义配置文件将来要读取的字段</span></span><br><span class="line">    <span class="keyword">private</span> Long delay;</span><br><span class="line">    <span class="keyword">private</span> String field;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//初始化配置信息</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">        delay = context.getLong(<span class="string">&quot;delay&quot;</span>);</span><br><span class="line">        field = context.getString(<span class="string">&quot;field&quot;</span>, <span class="string">&quot;Hello!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//创建事件头信息</span></span><br><span class="line">            HashMap&lt;String, String&gt; hearderMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">            <span class="comment">//创建事件</span></span><br><span class="line">            <span class="type">SimpleEvent</span> <span class="variable">event</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SimpleEvent</span>();</span><br><span class="line">            <span class="comment">//循环封装事件</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">                <span class="comment">//给事件设置头信息</span></span><br><span class="line">                event.setHeaders(hearderMap);</span><br><span class="line">                <span class="comment">//给事件设置内容</span></span><br><span class="line">                event.setBody((field + i).getBytes());</span><br><span class="line">                <span class="comment">//将事件写入 channel</span></span><br><span class="line">                getChannelProcessor().processEvent(event);</span><br><span class="line">                Thread.sleep(delay);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> Status.BACKOFF;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Status.READY;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getBackOffSleepIncrement</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getMaxBackOffSleepInterval</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（5）测试</p>
<p>将写好的代码打成jar包，放到&#x2F;opt&#x2F;module&#x2F;flume&#x2F;lib&#x2F;下</p>
<p>编写配置文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# vim mysoure.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = com.atguigu.source.MySource</span><br><span class="line">a1.sources.r1.delay = 2000</span><br><span class="line">a1.sources.r1.field = atguigu</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>开启任务：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -f job/mysource.conf -n a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>结果展示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 16:15:01,046 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75 30                         atguigu0 &#125;</span><br><span class="line">2023-10-22 16:15:03,044 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75 31                         atguigu1 &#125;</span><br><span class="line">2023-10-22 16:15:05,047 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75 32                         atguigu2 &#125;</span><br><span class="line">2023-10-22 16:15:07,049 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75 33                         atguigu3 &#125;</span><br><span class="line">2023-10-22 16:15:09,051 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75 34                         atguigu4 &#125;</span><br><span class="line">2023-10-22 16:15:11,054 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75 30                         atguigu0 &#125;</span><br><span class="line">2023-10-22 16:15:13,055 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75 31                         atguigu1 &#125;</span><br><span class="line">2023-10-22 16:15:15,057 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75 32                         atguigu2 &#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-7-自定义Sink（较少使用）"><a href="#3-7-自定义Sink（较少使用）" class="headerlink" title="3.7 自定义Sink（较少使用）"></a>3.7 自定义Sink（较少使用）</h2><p>（1）介绍</p>
<p>Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个 Flume Agent。</p>
<p>Sink 是完全事务性的。在从 Channel 批量删除数据之前，每个 Sink 用 Channel 启动一个事务。批量事件一旦成功写出到存储系统或下一个 Flume Agent，Sink 就利用 Channel 提交事务。事务一旦被提交，该 Channel 从自己的内部缓冲区删除事件。</p>
<p>Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、null、HBase、solr、自定义。官方提供的 Sink 类型已经很多，但是有时候并不能满足实际开发当中的需求，此时我们就需要根据实际需求自定义某些 Sink。</p>
<p>根据官方说明自定义MySink 需要继承 AbstractSink 类并实现 Configurable 接口。</p>
<img src="Snipaste_2023-10-22_16-19-36.png" alt="Snipaste_2023-10-22_16-19-36" style="zoom:50%;">

<p>（2）需求：</p>
<p>使用 flume 接收数据，并在 Sink 端给每条数据添加前缀和后缀，输出到控制台。前后缀可在 flume 任务配置文件中配置</p>
<img src="Snipaste_2023-10-22_16-21-42.png" alt="Snipaste_2023-10-22_16-21-42" style="zoom:50%;">

<p>（3）编码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySink</span> <span class="keyword">extends</span> <span class="title class_">AbstractSink</span> <span class="keyword">implements</span> <span class="title class_">Configurable</span> &#123;</span><br><span class="line">    <span class="comment">//创建 Logger 对象</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Logger</span> <span class="variable">LOG</span> <span class="operator">=</span></span><br><span class="line">            LoggerFactory.getLogger(AbstractSink.class);</span><br><span class="line">    <span class="keyword">private</span> String prefix;</span><br><span class="line">    <span class="keyword">private</span> String suffix;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Status <span class="title function_">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//声明返回值状态信息</span></span><br><span class="line">        Status status;</span><br><span class="line">        <span class="comment">//获取当前 Sink 绑定的 Channel</span></span><br><span class="line">        <span class="type">Channel</span> <span class="variable">ch</span> <span class="operator">=</span> getChannel();</span><br><span class="line">        <span class="comment">//获取事务</span></span><br><span class="line">        <span class="type">Transaction</span> <span class="variable">txn</span> <span class="operator">=</span> ch.getTransaction();</span><br><span class="line">        <span class="comment">//声明事件</span></span><br><span class="line">        Event event;</span><br><span class="line">        <span class="comment">//开启事务</span></span><br><span class="line">        txn.begin();</span><br><span class="line">        <span class="comment">//读取 Channel 中的事件，直到读取到事件结束循环</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            event = ch.take();</span><br><span class="line">            <span class="keyword">if</span> (event != <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//处理事件（打印）</span></span><br><span class="line">            LOG.info(prefix + <span class="keyword">new</span> <span class="title class_">String</span>(event.getBody()) +</span><br><span class="line">                    suffix);</span><br><span class="line">            <span class="comment">//事务提交</span></span><br><span class="line">            txn.commit();</span><br><span class="line">            status = Status.READY;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">//遇到异常，事务回滚</span></span><br><span class="line">            txn.rollback();</span><br><span class="line">            status = Status.BACKOFF;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">//关闭事务</span></span><br><span class="line">            txn.close();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> status;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">        <span class="comment">//读取配置文件内容，有默认值</span></span><br><span class="line">        prefix = context.getString(<span class="string">&quot;prefix&quot;</span>, <span class="string">&quot;hello:&quot;</span>);</span><br><span class="line">        <span class="comment">//读取配置文件内容，无默认值</span></span><br><span class="line">        suffix = context.getString(<span class="string">&quot;suffix&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）测试</p>
<p>将编写的代码打包，并放到&#x2F;opt&#x2F;module&#x2F;flume&#x2F;lib下。</p>
<p>编写配置文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 job]# vim mysink.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = com.atguigu.sink.MySink</span><br><span class="line">a1.sinks.k1.prefix = atguigu:</span><br><span class="line">a1.sinks.k1.suffix = :atguigu</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>开启服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/mysink.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

<p>开启客户端：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 lib]# nc localhost 44444</span><br><span class="line">hello</span><br><span class="line">OK</span><br><span class="line">wyh</span><br><span class="line">OK</span><br><span class="line">alibaba</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>结果展示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 16:43:01,296 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - com.atguigu.sink.MySink.process(MySink.java:47)] atguigu:hello:atguigu</span><br><span class="line">2023-10-22 16:43:09,521 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - com.atguigu.sink.MySink.process(MySink.java:47)] atguigu:wyh:atguigu</span><br><span class="line">2023-10-22 16:43:12,871 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - com.atguigu.sink.MySink.process(MySink.java:47)] atguigu:alibaba:atguigu</span><br></pre></td></tr></table></figure>

<p>注意：此时这个flume进程用ctrl+C退出不了，可以再开一个窗口kill -9进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 lib]# jps</span><br><span class="line">4100 RunJar</span><br><span class="line">3942 JobHistoryServer</span><br><span class="line">4071 RunJar</span><br><span class="line">3240 NameNode</span><br><span class="line">3421 DataNode</span><br><span class="line">9901 Application</span><br><span class="line">10061 Jps</span><br><span class="line">3758 NodeManager</span><br><span class="line">[root@hadoop102 lib]# kill -9 9901</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">已杀死</span><br><span class="line">[root@hadoop102 flume]# </span><br></pre></td></tr></table></figure>

<h2 id="3-8-Flume数据流监控"><a href="#3-8-Flume数据流监控" class="headerlink" title="3.8 Flume数据流监控"></a>3.8 Flume数据流监控</h2><h3 id="3-8-1-Ganglia的安装与部署"><a href="#3-8-1-Ganglia的安装与部署" class="headerlink" title="3.8.1 Ganglia的安装与部署"></a>3.8.1 Ganglia的安装与部署</h3><p>Ganglia 由 gmond、gmetad 和 gweb 三部分组成。</p>
<p>gmond（Ganglia Monitoring Daemon）是一种轻量级服务，安装在每台需要收集指标数据的节点主机上。使用 gmond，你可以很容易收集很多系统指标数据，如 CPU、内存、磁盘、网络和活跃进程的数据等。</p>
<p>gmetad（Ganglia Meta Daemon）整合所有信息，并将其以 RRD 格式存储至磁盘的服务。</p>
<p>gweb（Ganglia Web）Ganglia 可视化工具，gweb 是一种利用浏览器显示 gmetad 所存储数据的 PHP 前端。在 Web 界面中以图表方式展现集群的运行状态下收集的多种不同指标数据。</p>
<p>（1）安装ganglia</p>
<p>①规划</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102: web gmetad gmod</span><br><span class="line">hadoop103: gmod</span><br><span class="line">hadoop104: gmod</span><br></pre></td></tr></table></figure>

<p>②在 102 103 104 分别安装 epel-release</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 lib]# yum -y install epel-release</span><br><span class="line">[root@hadoop103 ~]# yum -y install epel-release</span><br><span class="line">[root@hadoop104 ~]# yum -y install epel-release</span><br></pre></td></tr></table></figure>

<p>③在102安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 lib]# yum -y install ganglia-gmetad</span><br><span class="line">[root@hadoop102 lib]# yum -y install ganglia-web</span><br><span class="line">[root@hadoop102 lib]# yum -y install ganglia-gmond</span><br></pre></td></tr></table></figure>

<p>④在103和104上安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 ~]# yum -y install ganglia-gmond</span><br><span class="line">[root@hadoop104 ~]# yum -y install ganglia-gmond</span><br></pre></td></tr></table></figure>

<p>（2）在102修改配置文件&#x2F;etc&#x2F;httpd&#x2F;conf.d&#x2F;ganglia.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 lib]# vim /etc/httpd/conf.d/ganglia.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># Ganglia monitoring system php web frontend</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"></span></span><br><span class="line">Alias /ganglia /usr/share/ganglia</span><br><span class="line"></span><br><span class="line">&lt;Location /ganglia&gt;</span><br><span class="line">  Require local</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">通过windows访问ganglia,需要配置 Linux 对应的主机(windows)ip 地址</span></span><br><span class="line">  Require ip 192.168.255.102</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Require ip 10.1.2.3</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">Require host example.org</span></span><br><span class="line">&lt;/Location&gt;</span><br></pre></td></tr></table></figure>

<p>（3）在102修改配置文件&#x2F;etc&#x2F;ganglia&#x2F;gmetad.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 lib]# vim /etc/ganglia/gmetad.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_source &quot;my cluster&quot; hadoop102</span><br></pre></td></tr></table></figure>

<p>（4）在102，103，104修改配置文件&#x2F;etc&#x2F;ganglia&#x2F;gmond.conf</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 lib]# vim /etc/ganglia/gmond.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">cluster &#123;</span><br><span class="line"> name = &quot;my cluster&quot;</span><br><span class="line"> owner = &quot;unspecified&quot;</span><br><span class="line"> latlong = &quot;unspecified&quot;</span><br><span class="line"> url = &quot;unspecified&quot;</span><br><span class="line">&#125;</span><br><span class="line">udp_send_channel &#123;</span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash">bind_hostname = <span class="built_in">yes</span> <span class="comment"># Highly recommended, soon to be default.</span></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">This option tells gmond to use a <span class="built_in">source</span></span> </span><br><span class="line">address</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">that resolves to the machine<span class="string">&#x27;s hostname.</span></span> </span><br><span class="line">Without</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">this, the metrics may appear to come from</span></span> </span><br><span class="line">any</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">interface and the DNS names associated with</span></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">those IPs will be used to create the RRDs.</span></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">mcast_join = 239.2.11.71</span></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">数据发送给 hadoop102</span></span></span><br><span class="line"> host = hadoop102</span><br><span class="line"> port = 8649</span><br><span class="line"> ttl = 1</span><br><span class="line">&#125;</span><br><span class="line">udp_recv_channel &#123;</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">mcast_join = 239.2.11.71</span></span></span><br><span class="line"> port = 8649</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">接收来自任意连接的数据</span></span></span><br><span class="line"> bind = 0.0.0.0</span><br><span class="line"> retry_bind = true</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">Size of the UDP buffer. If you are handling lots of metrics</span></span> </span><br><span class="line">you really</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">should bump it up to e.g. 10MB or even higher.</span></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash"><span class="string">buffer = 10485760</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>向103和014分发一下修改完的配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ganglia]# xsync gmond.conf</span><br></pre></td></tr></table></figure>

<p>（5）在102修改配置文件&#x2F;etc&#x2F;selinux&#x2F;config</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ganglia]# vim /etc/selinux/config</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">This file controls the state of SELinux on the system.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">SELINUX= can take one of these three values:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">enforcing - SELinux security policy is enforced.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">permissive - SELinux prints warnings instead of enforcing.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">disabled - No SELinux policy is loaded.</span></span><br><span class="line">SELINUX=disabled</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">SELINUXTYPE= can take one of these two values:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">targeted - Targeted processes are protected,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mls - Multi Level Security protection.</span></span><br><span class="line">SELINUXTYPE=targeted</span><br></pre></td></tr></table></figure>

<p>临时生效：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ganglia]# setenforce 0</span><br></pre></td></tr></table></figure>

<p>（6）启动ganglia</p>
<p>修改&#x2F;var&#x2F;lib&#x2F;ganglia 目录的权限：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ganglia]# chmod -R 777 /var/lib/ganglia</span><br></pre></td></tr></table></figure>

<p>①在102，103，104启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ganglia]# systemctl start gmond</span><br><span class="line">[root@hadoop103 ganglia]# systemctl start gmond</span><br><span class="line">[root@hadoop104 ~]# systemctl start gmond</span><br></pre></td></tr></table></figure>

<p>②在102启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ganglia]# systemctl start httpd</span><br><span class="line">[root@hadoop102 ganglia]# systemctl start gmetad</span><br></pre></td></tr></table></figure>

<p>（7）用linux系统的火狐浏览器打开ganglia页面</p>
<p><a target="_blank" rel="noopener" href="http://hadoop102/ganglia">http://hadoop102/ganglia</a></p>
<p><img src="Snipaste_2023-10-22_22-11-32.png" alt="Snipaste_2023-10-22_22-11-32"></p>
<h3 id="3-8-2-操作Flume测试监控"><a href="#3-8-2-操作Flume测试监控" class="headerlink" title="3.8.2 操作Flume测试监控"></a>3.8.2 操作Flume测试监控</h3><p>（1）启动Flume任务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flume]# bin/flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -Dflume.root.logger==INFO,console -Dflume.monitoring.type=ganglia -Dflume.monitoring.hosts=hadoop102:8649</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# nc localhost 44444</span><br><span class="line">hello</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>数据是通的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2023-10-22 22:20:13,344 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F                                  hello &#125;</span><br></pre></td></tr></table></figure>

<p>（2）发送数据后观察ganglia监测图：</p>
<img src="Snipaste_2023-10-22_22-25-14.png" alt="Snipaste_2023-10-22_22-25-14" style="zoom:50%;">

<img src="Snipaste_2023-10-22_22-25-58.png" alt="Snipaste_2023-10-22_22-25-58" style="zoom:50%;">

<h1 id="第四章-企业真实面试题（重点）"><a href="#第四章-企业真实面试题（重点）" class="headerlink" title="第四章 企业真实面试题（重点）"></a>第四章 企业真实面试题（重点）</h1><p>见《大数据面试题总结》</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/10/20/flume%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-zookeeper框架学习笔记" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/19/zookeeper%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">zookeeper框架学习笔记</a>
    </h1>
  

        
        <a href="/2023/10/19/zookeeper%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2023-10-19T01:57:51.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-10-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Zookeeper入门"><a href="#第一章-Zookeeper入门" class="headerlink" title="第一章 Zookeeper入门"></a>第一章 Zookeeper入门</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><p>Zookeeper 是一个开源的分布式的，为分布式框架提供协调服务的 Apache 项目</p>
<p><img src="Snipaste_2023-10-19_10-17-44.png" alt="Snipaste_2023-10-19_10-17-44"></p>
<p>服务器：技师</p>
<p>客户端：顾客</p>
<p>Zookeeper集群：妈妈桑</p>
<h2 id="1-2-特点"><a href="#1-2-特点" class="headerlink" title="1.2 特点"></a>1.2 特点</h2><p><img src="Snipaste_2023-10-19_10-27-02.png" alt="Snipaste_2023-10-19_10-27-02"></p>
<h2 id="1-3-数据结构"><a href="#1-3-数据结构" class="headerlink" title="1.3 数据结构"></a>1.3 数据结构</h2><p>ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。ZNode既可以存储数据，又可以存储其他节点，每一个 ZNode 默认能够存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识。</p>
<img src="Snipaste_2023-10-19_10-29-53.png" alt="Snipaste_2023-10-19_10-29-53" style="zoom:43%;">

<h2 id="1-4-应用场景"><a href="#1-4-应用场景" class="headerlink" title="1.4 应用场景"></a>1.4 应用场景</h2><p>提供的服务包括：统一命名服务、统一配置管理、统一集群管理、服务器节点动态上下线、软负载均衡等。</p>
<h3 id="1-4-1-统一命名服务"><a href="#1-4-1-统一命名服务" class="headerlink" title="1.4.1 统一命名服务"></a>1.4.1 统一命名服务</h3><p>在分布式环境中，经常需要对应用程序或服务进行统一命名，以便识别。这是因为服务器的IP地址不容易记住，但是域名容易记住。如下图，在统一命名后，3个客户端可以通过访问域名“<a target="_blank" rel="noopener" href="http://www.baidu.com”访问正确的服务器地址./">www.baidu.com”访问正确的服务器地址。</a></p>
<img src="Snipaste_2023-10-19_10-44-28.png" alt="Snipaste_2023-10-19_10-44-28" style="zoom:43%;">

<h3 id="1-4-2-统一管理配置"><a href="#1-4-2-统一管理配置" class="headerlink" title="1.4.2 统一管理配置"></a>1.4.2 统一管理配置</h3><p>在分布式环境中，配置文件同步很常见。一般要求一个集群中所有节点的配置信息保持一致，如Kafka集群，Hadoop集群等。在对配置文件进行修改后，希望能够将其快速同步到各个节点上，可以交给Zookeeper实现，将配置信息写入Zookeeper中的一个ZNode，各个客户端都会监听这个ZNode，一旦这个ZNode中的配置信息被修改，Zookeeper就会通知各个客户端。</p>
<img src="Snipaste_2023-10-19_10-47-51.png" alt="Snipaste_2023-10-19_10-47-51" style="zoom:43%;">

<h3 id="1-4-3-统一集群管理"><a href="#1-4-3-统一集群管理" class="headerlink" title="1.4.3 统一集群管理"></a>1.4.3 统一集群管理</h3><p>在分布式环境中，实时掌握每个节点的状态是必要的，可以根据节点的实时状态做出适当的调整。</p>
<p>Zookeeper可以实时监控节点的状态变化情况，将节点信息写入Zookeeper中的一个ZNode，监听这个ZNode，可以获取节点的实时状态变化情况。</p>
<img src="Snipaste_2023-10-19_10-50-43.png" alt="Snipaste_2023-10-19_10-50-43" style="zoom:43%;">

<h3 id="1-4-4-动态感知服务器节点的上下线"><a href="#1-4-4-动态感知服务器节点的上下线" class="headerlink" title="1.4.4 动态感知服务器节点的上下线"></a>1.4.4 动态感知服务器节点的上下线</h3><p>服务器节点在启动时，会到Zookeeper集群上注册节点信息，客户端会从Zookeeper处获取当前在线的服务器列表，并且注册监听。当服务器节点下线时，Zookeeper会向注册监听的客户端发送节点下线通知，客户端会重新获取在线的服务器列表，并且注册监听。</p>
<img src="Snipaste_2023-10-19_10-54-34.png" alt="Snipaste_2023-10-19_10-54-34" style="zoom:43%;">

<h3 id="1-4-5-软负载均衡"><a href="#1-4-5-软负载均衡" class="headerlink" title="1.4.5 软负载均衡"></a>1.4.5 软负载均衡</h3><img src="Snipaste_2023-10-19_10-55-14.png" alt="Snipaste_2023-10-19_10-55-14" style="zoom:43%;">

<h1 id="第二章-Zookeeper本地安装"><a href="#第二章-Zookeeper本地安装" class="headerlink" title="第二章 Zookeeper本地安装"></a>第二章 Zookeeper本地安装</h1><h2 id="2-1-本地模式安装"><a href="#2-1-本地模式安装" class="headerlink" title="2.1 本地模式安装"></a>2.1 本地模式安装</h2><p>1）安装前准备</p>
<p>①安装JDK</p>
<p>②拷贝zookeeper安装包到Linux下（&#x2F;opt&#x2F;software&#x2F;）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 1473696</span><br><span class="line">-rw-r--r--. 1 root root 356079876 12月  2 2022 apache-hive-3.1.3-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root   9311744 5月  20 2021 apache-zookeeper-3.5.7-bin.tar.gz    # 在这里</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 609556480 12月  2 2022 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line">-rw-r--r--. 1 root root    985600 12月  2 2022 mysql-connector-java-5.1.37.jar</span><br><span class="line">drwxr-xr-x. 2 root root      4096 10月  7 15:30 mysql_lib</span><br></pre></td></tr></table></figure>

<p>③解压到指定目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# cd /opt/module/</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x.  6 root root  134 10月 19 11:06 apache-zookeeper-3.5.7-bin  # 在这里</span><br><span class="line">drwxr-xr-x.  2 root root   99 10月 10 13:38 data</span><br><span class="line">drwxr-xr-x.  3 root root   62 10月  9 13:35 datas</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 12 root root  243 10月  8 13:38 hive</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>④修改名称</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mv apache-zookeeper-3.5.7-bin/ zookeeper-3.5.7</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x.  2 root root   99 10月 10 13:38 data</span><br><span class="line">drwxr-xr-x.  3 root root   62 10月  9 13:35 datas</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 12 root root  243 10月  8 13:38 hive</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br><span class="line">drwxr-xr-x.  6 root root  134 10月 19 11:06 zookeeper-3.5.7</span><br></pre></td></tr></table></figure>

<p>2）配置修改</p>
<p>①将&#x2F;opt&#x2F;module&#x2F;zookeeper-3.5.7&#x2F;conf 这个路径下的 zoo_sample.cfg 修改为 zoo.cfg</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# mv zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure>

<p>②打开 zoo.cfg 文件，修改 dataDir 路径：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim zoo.cfg </span><br><span class="line">...</span><br><span class="line">dataDir=/opt/module/zookeeper-3.5.7/zkData</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>③在&#x2F;opt&#x2F;module&#x2F;zookeeper-3.5.7&#x2F;这个目录上创建 zkData 文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/zookeeper-3.5.7/</span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# mkdir zkData</span><br></pre></td></tr></table></figure>

<p>3）操作Zookeeper</p>
<p>①启动Zookeeper</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 zookeeper-3.5.7]# bin/zkServer.sh start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# jps</span><br><span class="line">6434 Jps</span><br><span class="line">3699 RunJar</span><br><span class="line">3428 NodeManager</span><br><span class="line">2903 NameNode</span><br><span class="line">6391 QuorumPeerMain   # 在这里</span><br><span class="line">3084 DataNode</span><br><span class="line">3615 JobHistoryServer</span><br><span class="line">3727 RunJar</span><br></pre></td></tr></table></figure>

<p>②查看状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 zookeeper-3.5.7]#  bin/zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: standalone</span><br></pre></td></tr></table></figure>

<p>③启动客户端</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 zookeeper-3.5.7]#  bin/zkCli.sh</span><br></pre></td></tr></table></figure>

<p>④退出</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] ls /</span><br><span class="line">[zookeeper]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 2] quit</span><br></pre></td></tr></table></figure>

<p>⑤停止Zookeeper</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 zookeeper-3.5.7]# bin/zkServer.sh stop</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Stopping zookeeper ... STOPPED</span><br></pre></td></tr></table></figure>

<h2 id="2-2-配置参数解读"><a href="#2-2-配置参数解读" class="headerlink" title="2.2 配置参数解读"></a>2.2 配置参数解读</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of milliseconds of each tick</span></span><br><span class="line">tickTime=2000</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of ticks that the initial</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">synchronization phase can take</span></span><br><span class="line">initLimit=10</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of ticks that can pass between</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sending a request and getting an acknowledgement</span></span><br><span class="line">syncLimit=5</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the directory <span class="built_in">where</span> the snapshot is stored.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">do</span> not use /tmp <span class="keyword">for</span> storage, /tmp here is just</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">example sakes.</span></span><br><span class="line">dataDir=/opt/module/zookeeper-3.5.7/zkData</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the port at <span class="built_in">which</span> the clients will connect</span></span><br><span class="line">clientPort=2181</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the maximum number of client connections.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">increase this <span class="keyword">if</span> you need to handle more clients</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">maxClientCnxns=60</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># Be sure to read the maintenance section of the</span></span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">administrator guide before turning on autopurge.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># The number of snapshots to retain in dataDir</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">autopurge.snapRetainCount=3</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Purge task interval <span class="keyword">in</span> hours</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Set to <span class="string">&quot;0&quot;</span> to <span class="built_in">disable</span> auto purge feature</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">autopurge.purgeInterval=1</span></span><br></pre></td></tr></table></figure>

<p>（1）tickTime &#x3D; 2000：通信心跳时间，Zookeeper服务器与客户端心跳时间，单位毫秒</p>
<img src="Snipaste_2023-10-19_14-56-28.png" alt="Snipaste_2023-10-19_14-56-28" style="zoom:43%;">

<p>（2）initLimit &#x3D; 10：LF初始通信时限</p>
<img src="Snipaste_2023-10-19_14-57-10.png" alt="Snipaste_2023-10-19_14-57-10" style="zoom:43%;">

<p>（3）syncLimit &#x3D; 5：LF同步通信时限</p>
<img src="Snipaste_2023-10-19_14-57-52.png" alt="Snipaste_2023-10-19_14-57-52" style="zoom:43%;">

<p>（4）dataDir：保存Zookeeper中的数据</p>
<p>注意：默认的tmp目录，容易被Linux系统定期删除，所以一般不用默认的tmp目录</p>
<p>（5）clientPort &#x3D; 2181：客户端连接端口，通常不做修改</p>
<h1 id="第三章-Zookeeper集群操作"><a href="#第三章-Zookeeper集群操作" class="headerlink" title="第三章 Zookeeper集群操作"></a>第三章 Zookeeper集群操作</h1><h2 id="3-1-集群操作"><a href="#3-1-集群操作" class="headerlink" title="3.1 集群操作"></a>3.1 集群操作</h2><h3 id="3-1-1-集群安装"><a href="#3-1-1-集群安装" class="headerlink" title="3.1.1 集群安装"></a>3.1.1 集群安装</h3><p>（1）集群规划：在hadoop102，hadoop103，hadoop104节点服务器上部署Zookeeper</p>
<p>（2）压缩安装：将&#x2F;opt&#x2F;module&#x2F;zookeeper-3.5.7目录下的内容同步到hadoop103，hadoop104节点服务器中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# xsync zookeeper-3.5.7/</span><br></pre></td></tr></table></figure>

<p>（3）配置服务器编号</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module/zookeeper-3.5.7/这个目录下创建 zkData（之前已经创建好了）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module/zookeeper-3.5.7/zkData 目录下创建一个 myid 的文件</span></span><br><span class="line">[root@hadoop102 zkData]# vim myid</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在myid文件中，根据zoo.cfg文件中配置的ServerID与节点服务器IP地址的对应关系，添加与Server对应的编号，如在hadoop102节点服务器中添加2</span></span><br><span class="line">2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将配置好的myid文件复制到其他节点服务器中，在hadoop103和hadoop104节点服务器中将myid文件中的内容分别修改为3，4</span></span><br><span class="line">[root@hadoop102 zkData]# cat myid </span><br><span class="line">2</span><br><span class="line">[root@hadoop103 zkData]# cat myid </span><br><span class="line">3</span><br><span class="line">[root@hadoop104 zkData]# cat myid </span><br><span class="line">4</span><br></pre></td></tr></table></figure>

<p>（4）配置zoo.cfg文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打开 zoo.cfg 文件</span></span><br><span class="line">[root@hadoop102 conf]# vim zoo.cfg</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增加如下配置，指出Zookeeper集群中3台节点服务器的相关信息</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">######################cluster##########################</span></span></span><br><span class="line">server.2=hadoop102:2888:3888</span><br><span class="line">server.3=hadoop103:2888:3888</span><br><span class="line">server.4=hadoop104:2888:3888</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发配置文件</span></span><br><span class="line">[root@hadoop102 conf]# xsync zoo.cfg</span><br></pre></td></tr></table></figure>

<p>解读配置参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server.A=B:C:D</span><br></pre></td></tr></table></figure>

<p><strong>A</strong> 是一个数字，表示这个是第几号服务器；</p>
<p>集群模式下配置一个文件 myid，这个文件在 dataDir 目录下，这个文件里面有一个数据就是 A 的值，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个 server。</p>
<p><strong>B</strong> 是这个服务器的地址；</p>
<p><strong>C</strong> 是这个服务器 Follower 与集群中的 Leader 服务器交换信息的端口；</p>
<p><strong>D</strong> 是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>
<p>（5）集群启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分别启动Zookeeper</span></span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# bin/zkServer.sh start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">[root@hadoop103 zookeeper-3.5.7]# bin/zkServer.sh start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">[root@hadoop104 zookeeper-3.5.7]# bin/zkServer.sh start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看状态</span></span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# bin/zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: follower</span><br><span class="line">[root@hadoop103 zookeeper-3.5.7]# bin/zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: leader</span><br><span class="line">[root@hadoop104 zookeeper-3.5.7]# bin/zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-选举机制（面试重点）"><a href="#3-1-2-选举机制（面试重点）" class="headerlink" title="3.1.2 选举机制（面试重点）"></a>3.1.2 选举机制（面试重点）</h3><p>Zookeeper运行在一组节点服务器上，客户端无论连接哪一台节点服务器，都可以获取<strong>同样的服务</strong>。此外，只要有<strong>半数以上</strong>的节点服务器存活，Zookeeper就可以正常提供服务。Zookeeper中每台节点服务器的角色都是相同的，存储的数据也是相同的，哪台节点服务器会成为Leader是由<strong>选举机制</strong>决定的。</p>
<p>只要集群中有半数以上的节点服务器存活，集群就可用。</p>
<p>Zookeeper在工作时，有一台节点服务器为Leader，其他节点服务器均为Follower，Leader是通过内部的选举机制临时产生的。</p>
<p><img src="Snipaste_2023-10-19_16-04-00.png" alt="Snipaste_2023-10-19_16-04-00"></p>
<p>在正常运行过程中，如果Leader宕机了，则会再进行一次选举，只要有超过半数的节点服务器存活，就可以产生新的Leader。</p>
<p><img src="Snipaste_2023-10-19_16-18-31.png" alt="Snipaste_2023-10-19_16-18-31"></p>
<h3 id="3-1-3-Zookeeper集群启动停止脚本"><a href="#3-1-3-Zookeeper集群启动停止脚本" class="headerlink" title="3.1.3 Zookeeper集群启动停止脚本"></a>3.1.3 Zookeeper集群启动停止脚本</h3><p>（1）在在 hadoop102 的~&#x2F;bin 目录下创建脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# vim zk.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo ---------- zookeeper $i 启动 ------------</span><br><span class="line">        ssh $i &quot;/opt/module/zookeeper-3.5.7/bin/zkServer.sh start&quot;</span><br><span class="line">	done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo ---------- zookeeper $i 停止 ------------ </span><br><span class="line">        ssh $i &quot;/opt/module/zookeeper-3.5.7/bin/zkServer.sh stop&quot;</span><br><span class="line">    done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;status&quot;)&#123;</span><br><span class="line">    for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">    do</span><br><span class="line">        echo ---------- zookeeper $i 状态 ------------ </span><br><span class="line">        ssh $i &quot;/opt/module/zookeeper-3.5.7/bin/zkServer.sh status&quot;</span><br><span class="line">    done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>（2）增加脚本执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]#  chmod u+x zk.sh</span><br></pre></td></tr></table></figure>

<p>（3）执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# zk.sh start</span><br><span class="line">---------- zookeeper hadoop102 启动 ------------</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">---------- zookeeper hadoop103 启动 ------------</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">---------- zookeeper hadoop104 启动 ------------</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">[root@hadoop102 bin]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">3699 RunJar</span><br><span class="line">3428 NodeManager</span><br><span class="line">2903 NameNode</span><br><span class="line">8632 Jps</span><br><span class="line">3084 DataNode</span><br><span class="line">3615 JobHistoryServer</span><br><span class="line">3727 RunJar</span><br><span class="line">8575 QuorumPeerMain</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">3025 NodeManager</span><br><span class="line">6882 Jps</span><br><span class="line">2870 ResourceManager</span><br><span class="line">2638 DataNode</span><br><span class="line">6814 QuorumPeerMain</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">2739 SecondaryNameNode</span><br><span class="line">7030 QuorumPeerMain</span><br><span class="line">2616 DataNode</span><br><span class="line">7082 Jps</span><br><span class="line">2830 NodeManager</span><br></pre></td></tr></table></figure>

<p><strong>截至目前：已经写了五个脚本：</strong></p>
<p>**myhadoop.sh：hadoop集群启停脚本 **</p>
<p>**hiveservices.sh：hive服务启停脚本 **</p>
<p>**zk.sh：Zookeeper集群启停脚本 **</p>
<p><strong>xcall.sh：集群命令同时执行脚本</strong></p>
<p><strong>xsync：集群间文件分发脚本</strong></p>
<h2 id="3-2-客户端命令行操作"><a href="#3-2-客户端命令行操作" class="headerlink" title="3.2 客户端命令行操作"></a>3.2 客户端命令行操作</h2><h3 id="3-2-1-命令行语法"><a href="#3-2-1-命令行语法" class="headerlink" title="3.2.1 命令行语法"></a>3.2.1 命令行语法</h3><p><img src="Snipaste_2023-10-19_19-20-11.png" alt="Snipaste_2023-10-19_19-20-11"></p>
<p><img src="Snipaste_2023-10-19_19-20-28.png" alt="Snipaste_2023-10-19_19-20-28"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动客户端</span></span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# bin/zkCli.sh -server hadoop102:2181</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-ZNode节点数据信息"><a href="#3-2-2-ZNode节点数据信息" class="headerlink" title="3.2.2 ZNode节点数据信息"></a>3.2.2 ZNode节点数据信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前znode中所包含的内容</span></span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 1] ls /</span><br><span class="line">[zookeeper]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看当前节点详细数据</span></span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 2] ls -s /</span><br><span class="line">[zookeeper]cZxid = 0x0</span><br><span class="line">ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">mZxid = 0x0</span><br><span class="line">mtime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">pZxid = 0x0</span><br><span class="line">cversion = -1</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 0</span><br><span class="line">numChildren = 1</span><br></pre></td></tr></table></figure>

<p>各参数含义如下：</p>
<p><strong>（1）czxid：创建节点的事务 zxid</strong></p>
<p>每次修改 ZooKeeper 状态都会产生一个 ZooKeeper 事务 ID。事务 ID 是 ZooKeeper 中所有修改总的次序。每次修改都有唯一的 zxid，如果 zxid1 小于 zxid2，那么 zxid1 在 zxid2 之前发生。</p>
<p>（2）ctime：znode 被创建的毫秒数（从 1970 年开始）</p>
<p>（3）mzxid：znode 最后更新的事务 zxid</p>
<p>（4）mtime：znode 最后修改的毫秒数（从 1970 年开始）</p>
<p>（5）pZxid：znode 最后更新的子节点 zxid</p>
<p>（6）cversion：znode 子节点变化号，znode 子节点修改次数</p>
<p><strong>（7）dataversion：znode 数据变化号</strong></p>
<p>（8）aclVersion：znode 访问控制列表的变化号</p>
<p>（9）ephemeralOwner：如果是临时节点，这个是 znode 拥有者的 session id。如果不是临时节点则是 0。</p>
<p><strong>（10）dataLength：znode 的数据长度</strong></p>
<p><strong>（11）numChildren：znode 子节点数量</strong></p>
<h3 id="3-2-3-节点类型（持久-x2F-短暂-x2F-有序号-x2F-无序号）"><a href="#3-2-3-节点类型（持久-x2F-短暂-x2F-有序号-x2F-无序号）" class="headerlink" title="3.2.3 节点类型（持久&#x2F;短暂&#x2F;有序号&#x2F;无序号）"></a>3.2.3 节点类型（持久&#x2F;短暂&#x2F;有序号&#x2F;无序号）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建节点测试</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-19_20-07-41.png" alt="Snipaste_2023-10-19_20-07-41"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1.在根节点下分别创建两个持久化节点，什么命令都不附加，就是创建持久化节点</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/sanguo是目录，就是一个节点，<span class="string">&quot;diaochan&quot;</span>是节点中的数据，即在/sanguo这个目录为新创建的节点，其中的数据为<span class="string">&quot;diaochan&quot;</span></span></span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 3] create /sanguo &quot;diaochan&quot;</span><br><span class="line">Created /sanguo</span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 4] ls /</span><br><span class="line">[sanguo, zookeeper]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/sanguo/shuguo是多级目录，也是一个节点，它是/sanguo的子节点</span></span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 8] create /sanguo/shuguo &quot;liubei&quot;</span><br><span class="line">Created /sanguo/shuguo</span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 9] ls /sanguo</span><br><span class="line">[shuguo]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取节点的值</span></span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 13] get -s /sanguo</span><br><span class="line">diaochan</span><br><span class="line">cZxid = 0x200000004</span><br><span class="line">ctime = Thu Oct 19 20:17:53 CST 2023</span><br><span class="line">mZxid = 0x200000004</span><br><span class="line">mtime = Thu Oct 19 20:17:53 CST 2023</span><br><span class="line">pZxid = 0x200000007</span><br><span class="line">cversion = 3</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 8</span><br><span class="line">numChildren = 1</span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 14] get -s /sanguo/shuguo</span><br><span class="line">liubei</span><br><span class="line">cZxid = 0x200000007</span><br><span class="line">ctime = Thu Oct 19 20:19:43 CST 2023</span><br><span class="line">mZxid = 0x200000007</span><br><span class="line">mtime = Thu Oct 19 20:19:43 CST 2023</span><br><span class="line">pZxid = 0x200000007</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 6</span><br><span class="line">numChildren = 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2. 创建临时节点【-e】</span></span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 15] create -e /sanguo/weiguo &quot;zhouyu&quot;</span><br><span class="line">Created /sanguo/weiguo</span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/sanguo</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在当前客户端查看节点，可以看到/sanguo/weiguo</span></span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 16] ls /sanguo</span><br><span class="line">[shuguo, weiguo]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">退出当前客户端，然后重启客户端</span></span><br><span class="line">[zk: hadoop102:2181(CONNECTED) 17] quit</span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# bin/zkCli.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再次查看，可以发现/sanguo/weiguo节点已经被删除</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /sanguo</span><br><span class="line">[shuguo]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3. 创建持久化顺序编号节点【-s】</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 2] create  /sanguo/weiguo &quot;caocao&quot;</span><br><span class="line">Created /sanguo/weiguo</span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] create -s /sanguo/weiguo/xiaoqiao &quot;jinlian&quot;</span><br><span class="line">Created /sanguo/weiguo/xiaoqiao0000000000</span><br><span class="line">[zk: localhost:2181(CONNECTED) 4] create -s /sanguo/weiguo/daqiao &quot;jinlian&quot;</span><br><span class="line">Created /sanguo/weiguo/daqiao0000000001</span><br><span class="line">[zk: localhost:2181(CONNECTED) 5] create -s /sanguo/weiguo/diaochan &quot;jinlian&quot;</span><br><span class="line">Created /sanguo/weiguo/diaochan0000000002</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">4.创建短暂顺序编号节点【-e -s】</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 6] create -e -s /sanguo/wuguo &quot;zhouyu&quot;</span><br><span class="line">Created /sanguo/wuguo0000000004</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">5.修改节点数据值</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 7] get /sanguo/weiguo</span><br><span class="line">caocao</span><br><span class="line">[zk: localhost:2181(CONNECTED) 8] set /sanguo/weiguo &quot;simayi&quot;</span><br><span class="line">[zk: localhost:2181(CONNECTED) 9] get /sanguo/weiguo</span><br><span class="line">simayi</span><br></pre></td></tr></table></figure>

<h3 id="3-2-4-监听器原理"><a href="#3-2-4-监听器原理" class="headerlink" title="3.2.4 监听器原理"></a>3.2.4 监听器原理</h3><p>客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、节点删除、子目录节点增加删除）时，ZooKeeper 会通知客户端。监听机制保证 ZooKeeper 保存的任何的数据的任何改变都能快速的响应到监听了该节点的应用程序。</p>
<p><img src="Snipaste_2023-10-19_21-02-42.png" alt="Snipaste_2023-10-19_21-02-42"></p>
<p>（1）节点的值变化监听</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 hadoop103 主机上注册监听/sanguo 节点数据变化</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] get -w /sanguo</span><br><span class="line">diaochan</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 hadoop104 主机上修改/sanguo 节点的数据</span></span><br><span class="line">[zk: localhost:2181(CONNECTING) 0] set /sanguo &quot;xishi&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">观察 hadoop103 主机收到数据变化的监听</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] </span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:NodeDataChanged path:/sanguo</span><br></pre></td></tr></table></figure>

<p>注意：在hadoop104再多次修改&#x2F;sanguo的值，hadoop103上不会再收到监听。因为注册一次，只能监听一次。想再次监听，需要再次注册。</p>
<p>（2）节点的子节点变化监听（路径变化）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 hadoop104 主机上注册监听/sanguo 节点的子节点变化</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] ls -w /sanguo</span><br><span class="line">[shuguo, weiguo, wuguo0000000004]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在 hadoop103 主机/sanguo 节点上创建子节点</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] create /sanguo/jin &quot;simayi&quot;</span><br><span class="line">Created /sanguo/jin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">观察 hadoop104 主机收到子节点变化的监听</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 2] </span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/sanguo</span><br></pre></td></tr></table></figure>

<p>注意：节点的路径变化，也是注册一次，生效一次。想多次生效，就需要多次注册。</p>
<h3 id="3-2-5-节点删除与查看"><a href="#3-2-5-节点删除与查看" class="headerlink" title="3.2.5 节点删除与查看"></a>3.2.5 节点删除与查看</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除节点-delete</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 2] ls /sanguo</span><br><span class="line">[jin, shuguo, weiguo, wuguo0000000004]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] delete /sanguo/jin</span><br><span class="line">[zk: localhost:2181(CONNECTED) 4] ls /sanguo</span><br><span class="line">[shuguo, weiguo, wuguo0000000004]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">递归删除节点-deleteall</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 6] ls /sanguo/weiguo</span><br><span class="line">[daqiao0000000001, diaochan0000000002, xiaoqiao0000000000]</span><br><span class="line">[zk: localhost:2181(CONNECTED) 7] deleteall /sanguo/weiguo</span><br><span class="line">[zk: localhost:2181(CONNECTED) 8] ls /sanguo/weiguo</span><br><span class="line">Node does not exist: /sanguo/weiguo</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看节点状态-<span class="built_in">stat</span></span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 9] stat /sanguo</span><br><span class="line">cZxid = 0x200000004</span><br><span class="line">ctime = Thu Oct 19 20:17:53 CST 2023</span><br><span class="line">mZxid = 0x200000015</span><br><span class="line">mtime = Thu Oct 19 21:08:36 CST 2023</span><br><span class="line">pZxid = 0x20000001b</span><br><span class="line">cversion = 10</span><br><span class="line">dataVersion = 1</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 5</span><br><span class="line">numChildren = 2</span><br></pre></td></tr></table></figure>

<h2 id="3-3-客户端API操作"><a href="#3-3-客户端API操作" class="headerlink" title="3.3 客户端API操作"></a>3.3 客户端API操作</h2><p>前提：保证 hadoop102、hadoop103、hadoop104 服务器上 Zookeeper 集群服务端启动。</p>
<h3 id="3-3-1-IDEA环境搭建"><a href="#3-3-1-IDEA环境搭建" class="headerlink" title="3.3.1 IDEA环境搭建"></a>3.3.1 IDEA环境搭建</h3><p>（1）创建Maven工程zookeeper，并在pom文件中添加以下内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）在zookeeper工程中的src&#x2F;main&#x2F;resources目录下新建log4j.properties文件，在该文件中添加以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, stdout </span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender </span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n </span><br><span class="line">log4j.appender.logfile=org.apache.log4j.FileAppender </span><br><span class="line">log4j.appender.logfile.File=target/spring.log </span><br><span class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</span><br></pre></td></tr></table></figure>

<p>（3）创建com.atguigu.zk包，在该包中创建zkClient类</p>
<h3 id="3-3-2-创建Zookeeper客户端"><a href="#3-3-2-创建Zookeeper客户端" class="headerlink" title="3.3.2 创建Zookeeper客户端"></a>3.3.2 创建Zookeeper客户端</h3><p>编写初始化方法init()，在该方法中创建ZooKeeper客户端，增加@Before注解，在测试其他方法时会首先调用该方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">String</span> <span class="variable">connectString</span> <span class="operator">=</span> <span class="string">&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">sessionTimeout</span> <span class="operator">=</span> <span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkClient;</span><br><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    zkClient = <span class="keyword">new</span> <span class="title class_">ZooKeeper</span>(connectString, sessionTimeout, <span class="keyword">new</span> <span class="title class_">Watcher</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(WatchedEvent watchedEvent)</span> &#123;</span><br><span class="line">            <span class="comment">// 收到事件通知后的回调函数（用户的业务逻辑）</span></span><br><span class="line">            System.out.println(watchedEvent.getType() + <span class="string">&quot;--&quot;</span></span><br><span class="line">                    + watchedEvent.getPath());</span><br><span class="line">            <span class="comment">// 再次启动监听</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                List&lt;String&gt; children = zkClient.getChildren(<span class="string">&quot;/&quot;</span>,</span><br><span class="line">                        <span class="literal">true</span>);</span><br><span class="line">                <span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">                    System.out.println(child);</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(<span class="string">&quot;-----------------------------------&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-3-3-创建子节点"><a href="#3-3-3-创建子节点" class="headerlink" title="3.3.3 创建子节点"></a>3.3.3 创建子节点</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="comment">//创建子节点</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">create</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException &#123;</span><br><span class="line">    <span class="comment">//参数 1：要创建的节点的路径； 参数 2：节点数据 ； 参数 3：节点权限 ；</span></span><br><span class="line">    <span class="comment">//参数 4：节点的类型</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">nodeCreated</span> <span class="operator">=</span> zkClient.create(<span class="string">&quot;/atguigu&quot;</span>, <span class="string">&quot;shuaige&quot;</span>.getBytes(),</span><br><span class="line">            ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行该方法，在hadoop102节点服务器的ZooKeeper客户端查看创建节点的情况，可以发现&#x2F;atguigu节点创建成功：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] get -s /atguigu</span><br><span class="line">shuaige</span><br><span class="line">cZxid = 0x20000001f</span><br><span class="line">ctime = Thu Oct 19 22:01:08 CST 2023</span><br><span class="line">mZxid = 0x20000001f</span><br><span class="line">mtime = Thu Oct 19 22:01:08 CST 2023</span><br><span class="line">pZxid = 0x20000001f</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 7</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure>

<h3 id="3-3-4-获取子节点并监听节点变化"><a href="#3-3-4-获取子节点并监听节点变化" class="headerlink" title="3.3.4 获取子节点并监听节点变化"></a>3.3.4 获取子节点并监听节点变化</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getChildren</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException &#123;</span><br><span class="line">    <span class="comment">//监听根目录下的节点</span></span><br><span class="line">    List&lt;String&gt; children = zkClient.getChildren(<span class="string">&quot;/&quot;</span>, <span class="literal">true</span>);</span><br><span class="line">    <span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">        System.out.println(child);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 延时阻塞,运行该方法不立刻结束，保如果我再增加节点时可以监听到</span></span><br><span class="line">    Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行该方法，再IDEA控制台输出以下节点：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zookeeper</span><br><span class="line">sanguo</span><br><span class="line">atguigu</span><br></pre></td></tr></table></figure>

<p>在 hadoop102 的客户端上创建再创建一个节点&#x2F;atguigu1，观察 IDEA 控制台</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 3] create /atguigu1 &quot;atguigu1&quot;</span><br></pre></td></tr></table></figure>

<p>在IDEA控制台中发现输出以下节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">atguigu1</span><br><span class="line">zookeeper</span><br><span class="line">sanguo</span><br><span class="line">atguigu</span><br></pre></td></tr></table></figure>

<p>在 hadoop102 的客户端上删除节点&#x2F;atguigu1，观察 IDEA 控制台</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 4]  delete /atguigu1</span><br></pre></td></tr></table></figure>

<p>在IDEA控制台中发现输出以下节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zookeeper</span><br><span class="line">sanguo</span><br><span class="line">atguigu</span><br></pre></td></tr></table></figure>

<h3 id="3-3-5-判断ZNode是否存在"><a href="#3-3-5-判断ZNode是否存在" class="headerlink" title="3.3.5 判断ZNode是否存在"></a>3.3.5 判断ZNode是否存在</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">exist</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException &#123;</span><br><span class="line">    <span class="type">Stat</span> <span class="variable">stat</span> <span class="operator">=</span> zkClient.exists(<span class="string">&quot;/atguigu&quot;</span>, <span class="literal">false</span>);</span><br><span class="line">    System.out.println(stat == <span class="literal">null</span> ? <span class="string">&quot;not exist&quot;</span> : <span class="string">&quot;exist&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行该方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exist</span><br></pre></td></tr></table></figure>

<hr>
<p>完整代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">zkClient</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">connectString</span> <span class="operator">=</span> <span class="string">&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">sessionTimeout</span> <span class="operator">=</span> <span class="number">2000</span>;</span><br><span class="line">    <span class="keyword">private</span> ZooKeeper zkClient;</span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        zkClient = <span class="keyword">new</span> <span class="title class_">ZooKeeper</span>(connectString, sessionTimeout, <span class="keyword">new</span> <span class="title class_">Watcher</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(WatchedEvent watchedEvent)</span> &#123;</span><br><span class="line">                <span class="comment">// 收到事件通知后的回调函数（用户的业务逻辑）</span></span><br><span class="line">                System.out.println(watchedEvent.getType() + <span class="string">&quot;--&quot;</span></span><br><span class="line">                        + watchedEvent.getPath());</span><br><span class="line">                <span class="comment">// 再次启动监听</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    List&lt;String&gt; children = zkClient.getChildren(<span class="string">&quot;/&quot;</span>,</span><br><span class="line">                            <span class="literal">true</span>);</span><br><span class="line">                    <span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">                        System.out.println(child);</span><br><span class="line">                    &#125;</span><br><span class="line">                    System.out.println(<span class="string">&quot;-----------------------------------&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="comment">//创建子节点</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">create</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException &#123;</span><br><span class="line">        <span class="comment">//参数 1：要创建的节点的路径； 参数 2：节点数据 ； 参数 3：节点权限 ；</span></span><br><span class="line">        <span class="comment">//参数 4：节点的类型</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">nodeCreated</span> <span class="operator">=</span> zkClient.create(<span class="string">&quot;/atguigu&quot;</span>, <span class="string">&quot;shuaige&quot;</span>.getBytes(),</span><br><span class="line">                ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getChildren</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException &#123;</span><br><span class="line">        <span class="comment">//监听根目录下的节点</span></span><br><span class="line">        List&lt;String&gt; children = zkClient.getChildren(<span class="string">&quot;/&quot;</span>, <span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">            System.out.println(child);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 延时阻塞,运行该方法不立刻结束，保如果我再增加节点时可以监听到</span></span><br><span class="line">        Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">exist</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException &#123;</span><br><span class="line">        <span class="type">Stat</span> <span class="variable">stat</span> <span class="operator">=</span> zkClient.exists(<span class="string">&quot;/atguigu&quot;</span>, <span class="literal">false</span>);</span><br><span class="line">        System.out.println(stat == <span class="literal">null</span> ? <span class="string">&quot;not exist&quot;</span> : <span class="string">&quot;exist&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-4-客户端向服务端写数据流程"><a href="#3-4-客户端向服务端写数据流程" class="headerlink" title="3.4 客户端向服务端写数据流程"></a>3.4 客户端向服务端写数据流程</h2><p><strong>写流程之写入请求直接发送给Leader节点</strong></p>
<img src="Snipaste_2023-10-20_12-16-20.png" alt="Snipaste_2023-10-20_12-16-20" style="zoom:43%;">

<p><strong>写流程之写入请求发送给follower节点</strong></p>
<img src="Snipaste_2023-10-20_12-17-04.png" alt="Snipaste_2023-10-20_12-17-04" style="zoom:43%;">

<h1 id="第四章-服务器动态上下线监听案例"><a href="#第四章-服务器动态上下线监听案例" class="headerlink" title="第四章 服务器动态上下线监听案例"></a>第四章 服务器动态上下线监听案例</h1><h2 id="4-1-需求"><a href="#4-1-需求" class="headerlink" title="4.1 需求"></a>4.1 需求</h2><p>某分布式系统中，主节点可以有多台，可以动态上下线，任意一台客户端都能实时感知到主节点服务器的上下线。</p>
<h2 id="4-2-需求分析"><a href="#4-2-需求分析" class="headerlink" title="4.2 需求分析"></a>4.2 需求分析</h2><img src="Snipaste_2023-10-20_12-27-29.png" alt="Snipaste_2023-10-20_12-27-29" style="zoom:43%;">

<h2 id="4-3-具体实现"><a href="#4-3-具体实现" class="headerlink" title="4.3 具体实现"></a>4.3 具体实现</h2><p>（1）先在集群上创建&#x2F;servers 节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] create /servers &quot;servers&quot;</span><br><span class="line">Created /servers</span><br></pre></td></tr></table></figure>

<p>（2）在 Idea 中创建包名：com.atguigu.zkcase1</p>
<p>（3）服务器端向 Zookeeper 注册代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributeServer</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">String</span> <span class="variable">connectString</span> <span class="operator">=</span></span><br><span class="line">            <span class="string">&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">sessionTimeout</span> <span class="operator">=</span> <span class="number">2000</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">ZooKeeper</span> <span class="variable">zk</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">parentNode</span> <span class="operator">=</span> <span class="string">&quot;/servers&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建到 zk 的客户端连接</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getConnect</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        zk = <span class="keyword">new</span> <span class="title class_">ZooKeeper</span>(connectString, sessionTimeout, <span class="keyword">new</span> <span class="title class_">Watcher</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(WatchedEvent watchedEvent)</span> &#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注册服务器</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span>  <span class="title function_">registServer</span><span class="params">(String hostname)</span> <span class="keyword">throws</span> InterruptedException, KeeperException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">create</span> <span class="operator">=</span> zk.create(parentNode + <span class="string">&quot;/servers&quot;</span>, hostname.getBytes(),</span><br><span class="line">                ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);</span><br><span class="line">        System.out.println(hostname +<span class="string">&quot; is online &quot;</span>+ create);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//业务功能</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">business</span><span class="params">(String hostname)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        System.out.println(hostname + <span class="string">&quot; is working ...&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, KeeperException &#123;</span><br><span class="line">        <span class="comment">// 1 获取 zk 连接</span></span><br><span class="line">        <span class="type">DistributeServer</span> <span class="variable">server</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DistributeServer</span>();</span><br><span class="line">        server.getConnect();</span><br><span class="line">        <span class="comment">// 2 利用 zk 连接注册服务器信息</span></span><br><span class="line">        server.registServer(args[<span class="number">0</span>]);</span><br><span class="line">        <span class="comment">// 3 启动业务功能</span></span><br><span class="line">        server.business(args[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）客户端代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributeClient</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">String</span> <span class="variable">connectString</span> <span class="operator">=</span></span><br><span class="line">            <span class="string">&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">sessionTimeout</span> <span class="operator">=</span> <span class="number">2000</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">ZooKeeper</span> <span class="variable">zk</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">parentNode</span> <span class="operator">=</span> <span class="string">&quot;/servers&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建到 zk 的客户端连接</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getConnect</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        zk = <span class="keyword">new</span> <span class="title class_">ZooKeeper</span>(connectString, sessionTimeout, <span class="keyword">new</span> <span class="title class_">Watcher</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(WatchedEvent watchedEvent)</span> &#123;</span><br><span class="line">                <span class="comment">// 再次启动监听</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    getServerList();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取服务器列表信息</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getServerList</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException &#123;</span><br><span class="line">        <span class="comment">// 1 获取服务器子节点信息，并且对父节点进行监听</span></span><br><span class="line">        List&lt;String&gt; children = zk.getChildren(parentNode, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 存储服务器信息列表</span></span><br><span class="line">        ArrayList&lt;String&gt; servers = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 遍历所有节点，获取节点中的主机名称信息</span></span><br><span class="line">        <span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">            <span class="type">byte</span>[] data = zk.getData(parentNode + <span class="string">&quot;/&quot;</span> + child,</span><br><span class="line">                    <span class="literal">false</span>, <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">            servers.add(<span class="keyword">new</span> <span class="title class_">String</span>(data));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 打印服务器列表信息</span></span><br><span class="line">        System.out.println(servers);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 业务功能</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">business</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;client is working ...&quot;</span>);</span><br><span class="line">        Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, KeeperException &#123;</span><br><span class="line">        <span class="comment">// 1 获取 zk 连接</span></span><br><span class="line">        <span class="type">DistributeClient</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DistributeClient</span>();</span><br><span class="line">        client.getConnect();</span><br><span class="line">        <span class="comment">// 2 获取 servers 的子节点信息，从中获取服务器信息列表</span></span><br><span class="line">        client.getServerList();</span><br><span class="line">        <span class="comment">// 3 业务进程启动</span></span><br><span class="line">        client.business();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-4-测试"><a href="#4-4-测试" class="headerlink" title="4.4 测试"></a>4.4 测试</h2><p>（1）在Linux命令行上操作增加减少服务器</p>
<p>①启动DistributeClient 客户端</p>
<p>②在 hadoop102 上 zk 的客户端&#x2F;servers 目录上创建临时带序号节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 0] create -e -s /servers/hadoop102 &quot;hadoop102&quot;</span><br><span class="line">Created /servers/hadoop1020000000000</span><br><span class="line">[zk: localhost:2181(CONNECTED) 1] create -e -s /servers/hadoop103 &quot;hadoop103&quot;</span><br><span class="line">Created /servers/hadoop1030000000001</span><br></pre></td></tr></table></figure>

<p>③观察 Idea 控制台变化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop102, hadoop103]</span><br></pre></td></tr></table></figure>

<p>④执行删除操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] delete /servers/hadoop1020000000000</span><br></pre></td></tr></table></figure>

<p>⑤观察IDEA控制台变化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop103]</span><br></pre></td></tr></table></figure>

<p>（2）在 Idea 上操作增加减少服务器</p>
<p>①启动 DistributeClient 客户端（如果已经启动过，不需要重启）</p>
<p>②启动 DistributeServer 服务</p>
<p><img src="Snipaste_2023-10-20_13-17-03.png" alt="Snipaste_2023-10-20_13-17-03"></p>
<img src="Snipaste_2023-10-20_13-17-42.png" alt="Snipaste_2023-10-20_13-17-42" style="zoom:43%;">

<p>回到DistributeServer的main方法 ，右键 ，在弹出的窗口中点击Run“DistributeServer.main()”</p>
<p>观察 DistributeServer 控制台，提示 hadoop102 is working和上线</p>
<img src="Snipaste_2023-10-20_13-19-13.png" alt="Snipaste_2023-10-20_13-19-13" style="zoom:43%;">

<h1 id="第五章-Zookeeper分布式锁案例"><a href="#第五章-Zookeeper分布式锁案例" class="headerlink" title="第五章 Zookeeper分布式锁案例"></a>第五章 Zookeeper分布式锁案例</h1><p>什么叫做分布式锁呢？</p>
<p>比如说”进程 1”在使用该资源的时候，会先去获得锁，”进程 1”获得锁以后会对该资源 保持独占，这样其他进程就无法访问该资源，”进程 1”用完该资源以后就将锁释放掉，让其他进程来获得锁，那么通过这个锁机制，我们就能保证了分布式系统中多个进程能够有序的访问该临界资源。那么我们把这个分布式环境下的这个锁叫作分布式锁。</p>
<p><img src="Snipaste_2023-10-20_13-26-42.png" alt="Snipaste_2023-10-20_13-26-42"></p>
<h2 id="5-1-原生Zookeeper实现分布式锁案例"><a href="#5-1-原生Zookeeper实现分布式锁案例" class="headerlink" title="5.1 原生Zookeeper实现分布式锁案例"></a>5.1 原生Zookeeper实现分布式锁案例</h2><p>（1）分布式锁实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributedLock</span> &#123;</span><br><span class="line">    <span class="comment">// zookeeper server 列表</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">connectString</span> <span class="operator">=</span></span><br><span class="line">            <span class="string">&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span>;</span><br><span class="line">    <span class="comment">// 超时时间</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">sessionTimeout</span> <span class="operator">=</span> <span class="number">2000</span>;</span><br><span class="line">    <span class="keyword">private</span> ZooKeeper zk;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">rootNode</span> <span class="operator">=</span> <span class="string">&quot;locks&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">subNode</span> <span class="operator">=</span> <span class="string">&quot;seq-&quot;</span>;</span><br><span class="line">    <span class="comment">// 当前 client 等待的子节点</span></span><br><span class="line">    <span class="keyword">private</span> String waitPath;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//ZooKeeper 连接</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">CountDownLatch</span> <span class="variable">connectLatch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountDownLatch</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">//ZooKeeper 节点等待</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">CountDownLatch</span> <span class="variable">waitLatch</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountDownLatch</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 当前 client 创建的子节点</span></span><br><span class="line">    <span class="keyword">private</span> String currentNode;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 和 zk 服务建立连接，并创建根节点（创建一个构造器）</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">DistributedLock</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, KeeperException &#123;</span><br><span class="line">        zk = <span class="keyword">new</span> <span class="title class_">ZooKeeper</span>(connectString, sessionTimeout, <span class="keyword">new</span> <span class="title class_">Watcher</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(WatchedEvent event)</span> &#123;</span><br><span class="line">                <span class="comment">// 连接建立时, 打开 latch, 唤醒 wait 在该 latch 上的线程</span></span><br><span class="line">                <span class="keyword">if</span> (event.getState() ==</span><br><span class="line">                        Event.KeeperState.SyncConnected) &#123;</span><br><span class="line">                    connectLatch.countDown();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 发生了 waitPath 的删除事件</span></span><br><span class="line">                <span class="keyword">if</span> (event.getType() ==</span><br><span class="line">                        Event.EventType.NodeDeleted &amp;&amp; event.getPath().equals(waitPath))</span><br><span class="line">                &#123;</span><br><span class="line">                    waitLatch.countDown();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 等待连接建立</span></span><br><span class="line">        connectLatch.await();</span><br><span class="line">        <span class="comment">//获取根节点状态</span></span><br><span class="line">        <span class="type">Stat</span> <span class="variable">stat</span> <span class="operator">=</span> zk.exists(<span class="string">&quot;/&quot;</span> + rootNode, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果根节点不存在，则创建根节点，根节点类型为永久节点</span></span><br><span class="line">        <span class="keyword">if</span> (stat == <span class="literal">null</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;根节点不存在&quot;</span>);</span><br><span class="line">            zk.create(<span class="string">&quot;/&quot;</span> + rootNode, <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">0</span>],</span><br><span class="line">                    ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 加锁方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">zkLock</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//在根节点下创建临时顺序节点，返回值为创建的节点路径</span></span><br><span class="line">            currentNode = zk.create(<span class="string">&quot;/&quot;</span> + rootNode + <span class="string">&quot;/&quot;</span> + subNode,</span><br><span class="line">                    <span class="literal">null</span>, ZooDefs.Ids.OPEN_ACL_UNSAFE,</span><br><span class="line">                    CreateMode.EPHEMERAL_SEQUENTIAL);</span><br><span class="line">            <span class="comment">// wait 一小会, 让结果更清晰一些</span></span><br><span class="line">            Thread.sleep(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 注意, 没有必要监听&quot;/locks&quot;的子节点的变化情况</span></span><br><span class="line">            List&lt;String&gt; childrenNodes = zk.getChildren(<span class="string">&quot;/&quot;</span> +</span><br><span class="line">                    rootNode, <span class="literal">false</span>);</span><br><span class="line">            <span class="comment">// 列表中只有一个子节点, 那肯定就是 currentNode , 说明</span></span><br><span class="line">            <span class="comment">//client 获得锁</span></span><br><span class="line">            <span class="keyword">if</span> (childrenNodes.size() == <span class="number">1</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//对根节点下的所有临时顺序节点进行从小到大排序</span></span><br><span class="line">                Collections.sort(childrenNodes);</span><br><span class="line">                <span class="comment">//当前节点名称</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">thisNode</span> <span class="operator">=</span> currentNode.substring((<span class="string">&quot;/&quot;</span> +</span><br><span class="line">                        rootNode + <span class="string">&quot;/&quot;</span>).length());</span><br><span class="line">                <span class="comment">//获取当前节点的位置</span></span><br><span class="line">                <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> childrenNodes.indexOf(thisNode);</span><br><span class="line">                <span class="keyword">if</span> (index == -<span class="number">1</span>) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;数据异常&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (index == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="comment">// index == 0, 说明 thisNode 在列表中最小, 当前</span></span><br><span class="line">                    <span class="comment">//client 获得锁</span></span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// 获得排名比 currentNode 前 1 位的节点</span></span><br><span class="line">                    <span class="built_in">this</span>.waitPath = <span class="string">&quot;/&quot;</span> + rootNode + <span class="string">&quot;/&quot;</span> +</span><br><span class="line">                            childrenNodes.get(index - <span class="number">1</span>);</span><br><span class="line">                    <span class="comment">// 在 waitPath 上注册监听器, 当 waitPath 被删除时,</span></span><br><span class="line">                    <span class="comment">//zookeeper 会回调监听器的 process 方法</span></span><br><span class="line">                    zk.getData(waitPath, <span class="literal">true</span>, <span class="keyword">new</span> <span class="title class_">Stat</span>());</span><br><span class="line">                    <span class="comment">//进入等待锁状态</span></span><br><span class="line">                    waitLatch.await();</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 解锁方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">zkUnlock</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zk.delete(<span class="built_in">this</span>.currentNode, -<span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException | KeeperException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）分布式锁测试</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributedLockTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, KeeperException &#123;</span><br><span class="line">        <span class="comment">// 创建分布式锁 1</span></span><br><span class="line">        <span class="keyword">final</span> <span class="type">DistributedLock</span> <span class="variable">lock1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DistributedLock</span>();</span><br><span class="line">        <span class="comment">// 创建分布式锁 2</span></span><br><span class="line">        <span class="keyword">final</span> <span class="type">DistributedLock</span> <span class="variable">lock2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DistributedLock</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>()&#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="comment">// 获取锁对象</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    lock1.zkLock();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 1 获取锁&quot;</span>);</span><br><span class="line">                    Thread.sleep(<span class="number">5</span> * <span class="number">1000</span>);</span><br><span class="line">                    lock1.zkUnlock();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 1 释放锁&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="comment">// 获取锁对象</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    lock2.zkLock();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 2 获取锁&quot;</span>);</span><br><span class="line">                    Thread.sleep(<span class="number">5</span> * <span class="number">1000</span>);</span><br><span class="line">                    lock2.zkUnlock();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 2 释放锁&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行测试方法，观察控制台的变化：</p>
<img src="Snipaste_2023-10-20_13-53-41.png" alt="Snipaste_2023-10-20_13-53-41" style="zoom:43%;">

<h2 id="5-2-Curator框架实现分布式锁案例"><a href="#5-2-Curator框架实现分布式锁案例" class="headerlink" title="5.2 Curator框架实现分布式锁案例"></a>5.2 Curator框架实现分布式锁案例</h2><p>（1）原生的Java API开发存在的问题</p>
<ul>
<li>会话连接是异步的，需要自己去处理。比如使用 CountDownLatch</li>
<li>Watch 需要重复注册，不然就不能生效</li>
<li>开发的复杂性还是比较高的</li>
<li>不支持多节点删除和创建。需要自己去递归</li>
</ul>
<p>（2）Curator是一个专门解决分布式锁的框架，解决了原生Java API开发分布式遇到的问题</p>
<p>（3）Curator案例实操</p>
<p>①添加依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-framework<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-recipes<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.3.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>②代码实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CuratorLockTest</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">rootNode</span> <span class="operator">=</span> <span class="string">&quot;/locks&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// zookeeper server 列表</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">connectString</span> <span class="operator">=</span></span><br><span class="line">            <span class="string">&quot;hadoop102:2181,hadoop103:2181,hadoop104:2181&quot;</span>;</span><br><span class="line">    <span class="comment">// connection 超时时间</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">connectionTimeout</span> <span class="operator">=</span> <span class="number">2000</span>;</span><br><span class="line">    <span class="comment">// session 超时时间</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">sessionTimeout</span> <span class="operator">=</span> <span class="number">2000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">CuratorLockTest</span>().test();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 测试</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">test</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">// 创建分布式锁 1</span></span><br><span class="line">        <span class="keyword">final</span> <span class="type">InterProcessLock</span> <span class="variable">lock1</span> <span class="operator">=</span> <span class="keyword">new</span></span><br><span class="line">                <span class="title class_">InterProcessMutex</span>(getCuratorFramework(), rootNode);</span><br><span class="line">        <span class="comment">// 创建分布式锁 2</span></span><br><span class="line">        <span class="keyword">final</span> <span class="type">InterProcessLock</span> <span class="variable">lock2</span> <span class="operator">=</span> <span class="keyword">new</span></span><br><span class="line">                <span class="title class_">InterProcessMutex</span>(getCuratorFramework(), rootNode);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="comment">// 获取锁对象</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    lock1.acquire();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 1 获取锁&quot;</span>);</span><br><span class="line">                    <span class="comment">// 测试锁重入</span></span><br><span class="line">                    lock1.acquire();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 1 再次获取锁&quot;</span>);</span><br><span class="line">                    Thread.sleep(<span class="number">5</span> * <span class="number">1000</span>);</span><br><span class="line">                    lock1.release();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 1 释放锁&quot;</span>);</span><br><span class="line">                    lock1.release();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 1 再次释放锁&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="comment">// 获取锁对象</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    lock2.acquire();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 2 获取锁&quot;</span>);</span><br><span class="line">                    <span class="comment">// 测试锁重入</span></span><br><span class="line">                    lock2.acquire();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 2 再次获取锁&quot;</span>);</span><br><span class="line">                    Thread.sleep(<span class="number">5</span> * <span class="number">1000</span>);</span><br><span class="line">                    lock2.release();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 2 释放锁&quot;</span>);</span><br><span class="line">                    lock2.release();</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程 2 再次释放锁&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分布式锁初始化</span></span><br><span class="line">    <span class="keyword">public</span> CuratorFramework <span class="title function_">getCuratorFramework</span> <span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">//重试策略，初试时间 3 秒，重试 3 次</span></span><br><span class="line">        <span class="type">RetryPolicy</span> <span class="variable">policy</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ExponentialBackoffRetry</span>(<span class="number">3000</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//通过工厂创建 Curator</span></span><br><span class="line">        <span class="type">CuratorFramework</span> <span class="variable">client</span> <span class="operator">=</span></span><br><span class="line">                CuratorFrameworkFactory.builder()</span><br><span class="line">                        .connectString(connectString)</span><br><span class="line">                        .connectionTimeoutMs(connectionTimeout)</span><br><span class="line">                        .sessionTimeoutMs(sessionTimeout)</span><br><span class="line">                        .retryPolicy(policy).build();</span><br><span class="line">        <span class="comment">//开启连接</span></span><br><span class="line">        client.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;zookeeper 初始化完成...&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> client;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行后在控制台：</p>
<img src="Snipaste_2023-10-20_14-07-33.png" alt="Snipaste_2023-10-20_14-07-33" style="zoom:50%;">

<h1 id="第六章-企业面试真题（面试重点）"><a href="#第六章-企业面试真题（面试重点）" class="headerlink" title="第六章 企业面试真题（面试重点）"></a>第六章 企业面试真题（面试重点）</h1><h2 id="6-1-选举机制"><a href="#6-1-选举机制" class="headerlink" title="6.1 选举机制"></a>6.1 选举机制</h2><p>半数机制，超过半数的投票通过，即通过。</p>
<p>（1）第一次启动选举规则：</p>
<p>投票过半数时，服务器 id 大的胜出</p>
<p>（2）第二次启动选举规则：</p>
<p>①EPOCH 大的直接胜出</p>
<p>②EPOCH 相同，事务 id 大的胜出</p>
<p>③事务 id 相同，服务器 id 大的胜出</p>
<h2 id="6-2-生产集群安装多少zk合适？"><a href="#6-2-生产集群安装多少zk合适？" class="headerlink" title="6.2 生产集群安装多少zk合适？"></a>6.2 生产集群安装多少zk合适？</h2><p>安装奇数台。</p>
<p>生产经验：</p>
<ul>
<li>10 台服务器：3 台 zk；</li>
<li>20 台服务器：5 台 zk；</li>
<li>100 台服务器：11 台 zk；</li>
<li>200 台服务器：11 台 zk</li>
</ul>
<p>服务器台数多：好处，提高可靠性；坏处：提高通信延时</p>
<h2 id="6-3-常用命令"><a href="#6-3-常用命令" class="headerlink" title="6.3 常用命令"></a>6.3 常用命令</h2><p>ls、get、create、delete</p>
<h1 id="第七章-Zookeeper源码分析"><a href="#第七章-Zookeeper源码分析" class="headerlink" title="第七章 Zookeeper源码分析"></a>第七章 Zookeeper源码分析</h1><h2 id="7-1-算法基础"><a href="#7-1-算法基础" class="headerlink" title="7.1 算法基础"></a>7.1 算法基础</h2><p>Zookeeper 是如何保证数据一致性的？这也是困扰分布式系统框架的一个难题</p>
<h3 id="7-1-1-拜占庭将军问题"><a href="#7-1-1-拜占庭将军问题" class="headerlink" title="7.1.1 拜占庭将军问题"></a>7.1.1 拜占庭将军问题</h3>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/10/19/zookeeper%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-scala语言学习笔记" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/11/scala%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">scala语言学习笔记</a>
    </h1>
  

        
        <a href="/2023/10/11/scala%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2023-10-11T04:12:32.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-10-11</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Scala入门"><a href="#第一章-Scala入门" class="headerlink" title="第一章 Scala入门"></a>第一章 Scala入门</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><h3 id="1-1-1-scala优势"><a href="#1-1-1-scala优势" class="headerlink" title="1.1.1 scala优势"></a>1.1.1 scala优势</h3><ul>
<li>基于JVM，和Java完全兼容</li>
<li>比Java更加面向对象</li>
<li>函数式编程语言</li>
<li>对集合类型数据处理有非常好的支持</li>
</ul>
<h3 id="1-1-2-Scala和Java的关系"><a href="#1-1-2-Scala和Java的关系" class="headerlink" title="1.1.2 Scala和Java的关系"></a>1.1.2 Scala和Java的关系</h3><p><img src="Snipaste_2023-10-11_12-42-35.png" alt="Snipaste_2023-10-11_12-42-35"></p>
<h3 id="1-1-3-Scala语言特点"><a href="#1-1-3-Scala语言特点" class="headerlink" title="1.1.3 Scala语言特点"></a>1.1.3 Scala语言特点</h3><p><img src="Snipaste_2023-10-11_13-06-17.png" alt="Snipaste_2023-10-11_13-06-17"></p>
<h2 id="1-2-Scala环境搭建"><a href="#1-2-Scala环境搭建" class="headerlink" title="1.2 Scala环境搭建"></a>1.2 Scala环境搭建</h2><p>下载scla-2.12.11.zip到E:\scala，配置Scala环境变量</p>
<img src="Snipaste_2023-10-11_13-14-56.png" alt="Snipaste_2023-10-11_13-14-56" style="zoom:50%;">

<img src="Snipaste_2023-10-11_13-15-41.png" alt="Snipaste_2023-10-11_13-15-41" style="zoom:50%;">

<p>测试安装成功：</p>
<img src="Snipaste_2023-10-11_13-16-30.png" alt="Snipaste_2023-10-11_13-16-30" style="zoom:50%;">

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> a: <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line">a: <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> b: <span class="type">Int</span> = <span class="number">20</span></span><br><span class="line">b: <span class="type">Int</span> = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> res: <span class="type">Int</span> = a + b</span><br><span class="line">res: <span class="type">Int</span> = <span class="number">30</span></span><br><span class="line"></span><br><span class="line">scala&gt; println(<span class="string">&quot;hello world&quot;</span>)</span><br><span class="line">hello world</span><br><span class="line"></span><br><span class="line">scala&gt; :quit</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloScala</span></span>&#123;   <span class="comment">//表明是一个对象，对象名为HelloScala</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;  <span class="comment">//定义一个函数，函数名为main，传入的参数名为args，参数类型为String型数组（或叫集合）Array[String],Array表示集合，String表示泛型。Unit表示函数返回值为空。“=”后面跟着函数体</span></span><br><span class="line">        println(<span class="string">&quot;Hello Scala&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="1-3-Scala插件安装及配置调试"><a href="#1-3-Scala插件安装及配置调试" class="headerlink" title="1.3. Scala插件安装及配置调试"></a>1.3. Scala插件安装及配置调试</h2><img src="Snipaste_2023-10-11_13-43-28.png" alt="Snipaste_2023-10-11_13-43-28" style="zoom:50%;">

<p>在maven工程中的main文件下创建一个新directory：scala</p>
<img src="Snipaste_2023-10-11_13-46-42.png" alt="Snipaste_2023-10-11_13-46-42" style="zoom:43%;">

<p>给scala进行Mark Directory as Sources Root：</p>
<img src="Snipaste_2023-10-11_13-47-46.png" alt="Snipaste_2023-10-11_13-47-46" style="zoom:43%;">

<p>然后对当前的项目进行添加框架支持：</p>
<img src="Snipaste_2023-10-11_13-50-13.png" alt="Snipaste_2023-10-11_13-50-13" style="zoom: 33%;">

<img src="Snipaste_2023-10-11_13-53-38.png" alt="Snipaste_2023-10-11_13-53-38" style="zoom:43%;">

<p>然后就可以新建Scala class了：</p>
<img src="Snipaste_2023-10-11_13-54-16.png" alt="Snipaste_2023-10-11_13-54-16" style="zoom:43%;">

<h2 id="1-4-编写Scala代码测试"><a href="#1-4-编写Scala代码测试" class="headerlink" title="1.4 编写Scala代码测试"></a>1.4 编写Scala代码测试</h2><p>（1）在com.atguigu.chapter01包下创建一个HelloWorld的对象</p>
<img src="Snipaste_2023-10-11_13-57-27.png" alt="Snipaste_2023-10-11_13-57-27" style="zoom:43%;">

<p>（2）编写如下代码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">   object:关键字，声明一个单例对象（伴生对象）,</span></span><br><span class="line"><span class="comment">   这种伴生对象就是为了解决删除掉static关键字并且还要实现静态功能的需求而设计出来的</span></span><br><span class="line"><span class="comment">   class关键字和java中的class关键字作用相同，用来定义一个类</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">   main方法名：main方法是从外部可以直接调用执行的方法</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">   def 方法名称(参数名称：参数类型)：返回值类型 = &#123; 方法体 &#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">   小括号表示参数列表</span></span><br><span class="line"><span class="comment">        参数声明方式：java -&gt; 类型 参数名</span></span><br><span class="line"><span class="comment">                    scala  -&gt; 参数名：类型</span></span><br><span class="line"><span class="comment">   scala没有public关键字，如果不声明访问权限，那么就是公共的</span></span><br><span class="line"><span class="comment">   scala没有静态语法，所以没有static关键字，由object实现类似静态方法的功能（类名.方法名）</span></span><br><span class="line"><span class="comment">   Scala中用Unit类型表示没有返回值</span></span><br><span class="line"><span class="comment">   scala中，方法名(参数列表)：返回值类型</span></span><br><span class="line"><span class="comment">   scala中声明方法必须采用关键字def声明</span></span><br><span class="line"><span class="comment">   scala中方法实现赋值给方法声明，中间用等号连接</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloWorld</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;Hello World!&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）执行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello World!</span><br></pre></td></tr></table></figure>

<p>（4）java中的代码在scala中也能运行</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloWorld</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;Hello World!&quot;</span>)</span><br><span class="line">    <span class="type">System</span>.out.println(<span class="string">&quot;Hello scala from java&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hello World!</span><br><span class="line">Hello scala from java</span><br></pre></td></tr></table></figure>

<p>但是还是不建议java和scala在同一个类中混合使用，很容易懵逼</p>
<p>（5）对照java类和scala类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//java类</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Student</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">String</span> <span class="variable">school</span> <span class="operator">=</span> <span class="string">&quot;atguigu&quot;</span>;<span class="comment">//用static修饰，变成全局属性，所有学生实例的school属性都是&quot;atguigu&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Student</span><span class="params">(String name, Integer age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">printInfo</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(<span class="built_in">this</span>.name + <span class="string">&quot; &quot;</span> + <span class="built_in">this</span>.age + <span class="string">&quot; &quot;</span> + Student.school);</span><br><span class="line">    &#125;<span class="comment">//因为school属性是静态的，所以可以用类名直接调用，它不随着实例的变化而变化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Student</span> <span class="variable">student1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Student</span>(<span class="string">&quot;wang&quot;</span>, <span class="number">20</span>);</span><br><span class="line">        <span class="type">Student</span> <span class="variable">student2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Student</span>(<span class="string">&quot;alice&quot;</span>, <span class="number">22</span>);</span><br><span class="line">        student1.printInfo();<span class="comment">//wang 20 atguigu</span></span><br><span class="line">        student2.printInfo();<span class="comment">//alice 22 atguigu</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//scala类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>(<span class="params">var name: <span class="type">String</span>, var age: <span class="type">Int</span></span>) </span>&#123; <span class="comment">//这种写法直接表明了类中的属性，并且同时实现了构造方法</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">printInfo</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(name + <span class="string">&quot; &quot;</span> + age + <span class="string">&quot; &quot;</span> + <span class="type">Student</span>.school)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//引入伴生对象（必须与Student类名字完全相同）</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Student</span></span>&#123;</span><br><span class="line">  <span class="keyword">val</span> school: <span class="type">String</span> = <span class="string">&quot;atguigu&quot;</span> <span class="comment">//就相当于java中的static属性了</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123; <span class="comment">//main方法只能声明在伴生对象中</span></span><br><span class="line">    <span class="keyword">val</span> student1 = <span class="keyword">new</span> <span class="type">Student</span>(<span class="string">&quot;wang&quot;</span>, <span class="number">20</span>)</span><br><span class="line">    <span class="keyword">val</span> student2 = <span class="keyword">new</span> <span class="type">Student</span>(<span class="string">&quot;alice&quot;</span>, <span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    student1.printInfo()<span class="comment">//wang 20 atguigu</span></span><br><span class="line">    student2.printInfo()<span class="comment">//alice 22 atguigu</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="第二章-变量和数据类型"><a href="#第二章-变量和数据类型" class="headerlink" title="第二章 变量和数据类型"></a>第二章 变量和数据类型</h1><h2 id="2-1-注释"><a href="#2-1-注释" class="headerlink" title="2.1 注释"></a>2.1 注释</h2><p>与java完全一样（略）</p>
<h2 id="2-2-变量和常量（重点）"><a href="#2-2-变量和常量（重点）" class="headerlink" title="2.2 变量和常量（重点）"></a>2.2 变量和常量（重点）</h2><img src="Snipaste_2023-10-11_15-40-20.png" alt="Snipaste_2023-10-11_15-40-20" style="zoom:43%;">

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">（1）声明变量时，类型可以省略，编译器自动推导，即类型推导</span></span><br><span class="line"><span class="comment">（2）类型确定后，就不能修改，说明 Scala 是强数据类型语言。</span></span><br><span class="line"><span class="comment">（3）变量声明时，必须要有初始值</span></span><br><span class="line"><span class="comment">（4）在声明/定义一个变量时，可以使用 var 或者 val 来修饰，var 修饰的变量可改变，</span></span><br><span class="line"><span class="comment">val 修饰的变量不可改。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test02_Variable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//声明一个变量的通用语法</span></span><br><span class="line">    <span class="keyword">var</span> a:<span class="type">Int</span> = <span class="number">10</span></span><br><span class="line">    <span class="comment">//（1）声明变量时，类型可以省略，编译器自动推导，即类型推导</span></span><br><span class="line">    <span class="keyword">var</span> a1 = <span class="number">10</span></span><br><span class="line">    <span class="keyword">var</span> c1 = &#x27;p&#x27;</span><br><span class="line">    <span class="keyword">var</span> s1 = <span class="string">&quot;word&quot;</span></span><br><span class="line">    <span class="keyword">val</span> b1 = <span class="number">23</span></span><br><span class="line">    <span class="keyword">var</span> alice:<span class="type">Student</span> = <span class="keyword">new</span> <span class="type">Student</span>(<span class="string">&quot;alice&quot;</span>,<span class="number">23</span>)</span><br><span class="line">    <span class="comment">//或者自动推导类型</span></span><br><span class="line">    <span class="keyword">var</span> alice1 = <span class="keyword">new</span> <span class="type">Student</span>(<span class="string">&quot;alice&quot;</span>, <span class="number">23</span>)</span><br><span class="line">    <span class="keyword">val</span> bob = <span class="keyword">new</span> <span class="type">Student</span>(<span class="string">&quot;bob&quot;</span>,<span class="number">24</span>)</span><br><span class="line">    <span class="comment">//（2）类型确定后，就不能修改，说明 Scala 是强数据类型语言。</span></span><br><span class="line"><span class="comment">//    a1 = &quot;ssl&quot;</span></span><br><span class="line">    <span class="comment">//（3）变量声明时，必须要有初始值</span></span><br><span class="line"><span class="comment">//    var a3:Int</span></span><br><span class="line">    <span class="comment">//对于变量值的修改，修改的时候就不要带上var和Int了</span></span><br><span class="line">    a1 = <span class="number">2003</span></span><br><span class="line">    alice1 = <span class="keyword">new</span> <span class="type">Student</span>(<span class="string">&quot;alice&quot;</span>,<span class="number">28</span>)</span><br><span class="line">    alice1.printInfo() <span class="comment">//alice 28 atguigu</span></span><br><span class="line">    alice1.name = <span class="string">&quot;Alice&quot;</span></span><br><span class="line">    alice1.age = <span class="number">29</span></span><br><span class="line">    alice1.printInfo() <span class="comment">//Alice 29 atguigu</span></span><br><span class="line">    <span class="comment">//因为bob是val常量，所以本身不能改变，但其中的属性是变量，可以变</span></span><br><span class="line"><span class="comment">//    bob = new Student(&quot;bob1&quot;,56)</span></span><br><span class="line">    bob.name = <span class="string">&quot;bob1&quot;</span></span><br><span class="line">    bob.age = <span class="number">56</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-3-标识符命名规范"><a href="#2-3-标识符命名规范" class="headerlink" title="2.3 标识符命名规范"></a>2.3 标识符命名规范</h2><p>Scala 对各种变量、方法、函数等命名时使用的字符序列称为标识符。即：凡是自己可以起名字的地方都叫标识符。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">Scala 中的标识符声明，基本和 Java 是一致的，但是细节上会有所变化，有以下三种规</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">则：</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">（1）以字母或者下划线开头，后接字母、数字、下划线</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">（2）以操作符开头，且只包含操作符（+ - * / # !等）</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">（3）用反引号`....`包括的任意字符串，即使是 Scala 关键字（39 个）也可以</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">• package, import, class, object, trait, extends, with, type, for</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">• private, protected, abstract, sealed, final, implicit, lazy, override</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">• try, catch, finally, throw </span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">• if, else, match, case, do, while, for, return, yield</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">• def, val, var </span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">• this, super</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">• new</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">• true, false, null</span></span><br><span class="line"><span class="comment">/</span></span><br></pre></td></tr></table></figure>

<h2 id="2-4-字符串输出"><a href="#2-4-字符串输出" class="headerlink" title="2.4 字符串输出"></a>2.4 字符串输出</h2><p>1）基本语法</p>
<p>（1）字符串，通过+号连接</p>
<p>（2）printf 用法：字符串，通过%传值。</p>
<p>（3）字符串模板（插值字符串）：通过$获取变量值</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test04_String</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//（1）字符串，通过+号连接</span></span><br><span class="line">    <span class="keyword">val</span> name:<span class="type">String</span> = <span class="string">&quot;Alice&quot;</span></span><br><span class="line">    <span class="keyword">val</span> age: <span class="type">Int</span> = <span class="number">19</span></span><br><span class="line">    println(age + <span class="string">&quot;岁的&quot;</span> + name + <span class="string">&quot;在学习&quot;</span>) <span class="comment">//19岁的Alice在学习</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//*用于将一个字符串复制多次拼接</span></span><br><span class="line">    println(name * <span class="number">3</span>) <span class="comment">//AliceAliceAlice</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//（2）printf 用法：字符串，通过%传值。</span></span><br><span class="line">    printf(<span class="string">&quot;%d岁的%s在学习&quot;</span>, age, name) <span class="comment">//19岁的Alice在学习</span></span><br><span class="line">    println()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//（3）字符串模板（插值字符串）：通过$获取变量值</span></span><br><span class="line">    println(<span class="string">s&quot;<span class="subst">$&#123;age&#125;</span>岁的<span class="subst">$&#123;name&#125;</span>在学习&quot;</span>)  <span class="comment">//19岁的Alice在学习</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> num: <span class="type">Double</span> = <span class="number">2.3456</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//格式化模板字符串</span></span><br><span class="line">    println(<span class="string">f&quot;The num is <span class="subst">$&#123;num&#125;</span>%2.2f&quot;</span>) <span class="comment">//The num is 2.35</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//三引号表示字符串，保持多行字符串的原格式输出</span></span><br><span class="line">    <span class="keyword">val</span> sql =</span><br><span class="line">      <span class="string">s&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">         |select *</span></span><br><span class="line"><span class="string">         |from student</span></span><br><span class="line"><span class="string">         |where name = $&#123;name&#125; and age &gt; $&#123;age&#125;</span></span><br><span class="line"><span class="string">         |limit 2,6</span></span><br><span class="line"><span class="string">         |&quot;</span><span class="string">&quot;&quot;</span>.stripMargin</span><br><span class="line">    println(sql)</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    select *</span></span><br><span class="line"><span class="comment">    from student</span></span><br><span class="line"><span class="comment">    where name = Alice and age &gt; 19</span></span><br><span class="line"><span class="comment">    limit 2,6</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-5-键盘输入"><a href="#2-5-键盘输入" class="headerlink" title="2.5 键盘输入"></a>2.5 键盘输入</h2><p>StdIn.readLine()、StdIn.readShort()、StdIn.readDouble()</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test05_StdIn</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//输入信息</span></span><br><span class="line">    println(<span class="string">&quot;请输入您的名字：&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> name: <span class="type">String</span> = <span class="type">StdIn</span>.readLine()</span><br><span class="line">    println(<span class="string">&quot;请输入您的年龄：&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> age: <span class="type">Int</span> = <span class="type">StdIn</span>.readInt()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//控制台打印输出</span></span><br><span class="line">    println(<span class="string">s&quot;欢迎<span class="subst">$&#123;age&#125;</span>岁的<span class="subst">$&#123;name&#125;</span>来到本学校学习&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-5-文件输入输出"><a href="#2-5-文件输入输出" class="headerlink" title="2.5* 文件输入输出"></a>2.5* 文件输入输出</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test06_FileIO</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//1.从文件中读取数据，并逐行打印</span></span><br><span class="line">    <span class="type">Source</span>.fromFile(<span class="string">&quot;src\\main\\resources\\test.txt&quot;</span>).foreach(print)</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    hello word</span></span><br><span class="line"><span class="comment">    hello scala</span></span><br><span class="line"><span class="comment">    how are you</span></span><br><span class="line"><span class="comment">    fine thank you</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//或者：</span></span><br><span class="line">    <span class="keyword">val</span> source = <span class="type">Source</span>.fromFile(<span class="string">&quot;src\\main\\resources\\test.txt&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> iter: <span class="type">Iterator</span>[<span class="type">String</span>] = source.getLines()</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext)&#123;</span><br><span class="line">      println(iter.next())</span><br><span class="line">    &#125;</span><br><span class="line">    source.close()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2. 将数据写入文件</span></span><br><span class="line">    <span class="comment">//scala中的写入采用的就是java中的写入</span></span><br><span class="line">    <span class="keyword">val</span> writer = <span class="keyword">new</span> <span class="type">PrintWriter</span>(<span class="keyword">new</span> <span class="type">File</span>(<span class="string">&quot;src\\main\\resources\\output.txt&quot;</span>))</span><br><span class="line">    writer.write(<span class="string">&quot;hello scala from java writer&quot;</span>)</span><br><span class="line">    writer.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>成功写入：</p>
<img src="Snipaste_2023-10-11_21-00-30.png" alt="Snipaste_2023-10-11_21-00-30" style="zoom:43%;">

<h2 id="2-6-数据类型（重点）"><a href="#2-6-数据类型（重点）" class="headerlink" title="2.6 数据类型（重点）"></a>2.6 数据类型（重点）</h2><p><img src="Snipaste_2023-10-11_21-17-50.png" alt="Snipaste_2023-10-11_21-17-50"></p>
<p><img src="Snipaste_2023-10-11_21-24-43.png" alt="Snipaste_2023-10-11_21-24-43"></p>
<h2 id="2-7-整数类型（Byte、Short、Int、Long）"><a href="#2-7-整数类型（Byte、Short、Int、Long）" class="headerlink" title="2.7 整数类型（Byte、Short、Int、Long）"></a>2.7 整数类型（Byte、Short、Int、Long）</h2><img src="Snipaste_2023-10-11_21-26-13.png" alt="Snipaste_2023-10-11_21-26-13" style="zoom:43%;">

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> i: <span class="type">Int</span> = <span class="number">10</span></span><br><span class="line"><span class="keyword">val</span> s: <span class="type">String</span> = <span class="string">&quot;abc&quot;</span></span><br><span class="line"><span class="keyword">val</span> ax: <span class="type">AnyVal</span> = i</span><br><span class="line"><span class="keyword">val</span> bx: <span class="type">AnyRef</span> = s</span><br><span class="line"><span class="keyword">var</span> cx: <span class="type">Any</span> = bx</span><br><span class="line"><span class="comment">//1. 整数类型</span></span><br><span class="line">    <span class="comment">//Byte:整数范围：-128~127</span></span><br><span class="line">    <span class="keyword">val</span> a1: <span class="type">Byte</span> = <span class="number">127</span>;</span><br><span class="line"><span class="comment">//    val a2: Byte = 128  编译报错</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> a3 = <span class="number">12</span> <span class="comment">//整数默认类型为Int</span></span><br><span class="line">	<span class="comment">//Scala 的整型，默认为 Int 型，声明 Long 型，须后加‘l’或‘L’</span></span><br><span class="line">    <span class="keyword">val</span> a4 = <span class="number">1272673673637637637</span>L  <span class="comment">//后面加上L表示长整形</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//scala中的强制类型转换</span></span><br><span class="line">    <span class="keyword">val</span> b1: <span class="type">Byte</span> = (<span class="number">10</span>+<span class="number">20</span>).toByte</span><br></pre></td></tr></table></figure>

<h2 id="2-8-浮点类型（Float、Double）"><a href="#2-8-浮点类型（Float、Double）" class="headerlink" title="2.8 浮点类型（Float、Double）"></a>2.8 浮点类型（Float、Double）</h2><img src="Snipaste_2023-10-12_12-20-28.png" alt="Snipaste_2023-10-12_12-20-28" style="zoom:43%;">

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//2. 浮点类型</span></span><br><span class="line"><span class="comment">//Scala 的浮点型常量默认为 Double 型，声明 Float 型常量，须后加‘f’或‘F’</span></span><br><span class="line"><span class="keyword">val</span> f1: <span class="type">Float</span> = <span class="number">1.23</span>f</span><br><span class="line"><span class="keyword">val</span> d1 = <span class="number">1.23</span> <span class="comment">//默认Double类型</span></span><br></pre></td></tr></table></figure>

<h2 id="2-9-字符类型（Char）"><a href="#2-9-字符类型（Char）" class="headerlink" title="2.9 字符类型（Char）"></a>2.9 字符类型（Char）</h2><p>字符类型可以表示单个字符，字符类型是 Char</p>
<p>（1）字符常量是用单引号 ‘ ‘ 括起来的单个字符。</p>
<p>（2）\t ：一个制表位，实现对齐的功能</p>
<p>（3）\n ：换行符</p>
<p>（4）\ ：表示\</p>
<p>（5）&quot; ：表示”</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//3.字符类型</span></span><br><span class="line"><span class="keyword">val</span> c1: <span class="type">Char</span> = &#x27;a&#x27;</span><br><span class="line">println(<span class="string">&quot;abc&quot;</span> + &#x27;\t&#x27; + <span class="string">&quot;def&quot;</span>) <span class="comment">//abc  def</span></span><br><span class="line">println(<span class="string">&quot;abc&quot;</span> + &#x27;\n&#x27; + <span class="string">&quot;def&quot;</span>)</span><br><span class="line">println(<span class="string">&quot;abc&quot;</span> + &#x27;\\&#x27; + <span class="string">&quot;def&quot;</span>) <span class="comment">//abc\def</span></span><br><span class="line">println(<span class="string">&quot;abc&quot;</span> + &#x27;\<span class="string">&quot;&#x27; + &quot;</span><span class="string">def&quot;) //abc&quot;</span><span class="function"><span class="keyword">def</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//字符变量底层保存ASCII码值</span></span><br><span class="line"><span class="keyword">val</span> i1: <span class="type">Int</span> = c1</span><br><span class="line">println(i1) <span class="comment">//97</span></span><br></pre></td></tr></table></figure>

<h2 id="2-10-布尔类型（Boolean）"><a href="#2-10-布尔类型（Boolean）" class="headerlink" title="2.10 布尔类型（Boolean）"></a>2.10 布尔类型（Boolean）</h2><p>Booolean 类型数据只允许取值 true 和 false，boolean 类型占 1 个字节</p>
<h2 id="2-11-Unit类型、Null类型和Nothing类型（重点）"><a href="#2-11-Unit类型、Null类型和Nothing类型（重点）" class="headerlink" title="2.11 Unit类型、Null类型和Nothing类型（重点）"></a>2.11 Unit类型、Null类型和Nothing类型（重点）</h2><img src="Snipaste_2023-10-12_12-49-43.png" alt="Snipaste_2023-10-12_12-49-43" style="zoom:43%;">

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//5.空类型</span></span><br><span class="line">    <span class="comment">//5.1 空值Unit</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">m1</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;m1被调用执行&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> a = m1()</span><br><span class="line">    println(a) <span class="comment">//()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//5.2 空引用Null</span></span><br><span class="line">    <span class="comment">//Null 类只有一个实例对象，Null 类似于 Java 中的 null 引用。Null 可以赋值给任</span></span><br><span class="line">    <span class="comment">//意引用类型（AnyRef），但是不能赋值给值类型（AnyVal）</span></span><br><span class="line">    <span class="keyword">var</span> student: <span class="type">Student</span> = <span class="keyword">new</span> <span class="type">Student</span>(<span class="string">&quot;alice&quot;</span>, <span class="number">20</span>)</span><br><span class="line">    student = <span class="literal">null</span></span><br><span class="line">    println(student)  <span class="comment">//null</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    val n: Int = null   //error</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//5.3 Nothing可以作为没有正常返回值的方法的返回类型，非常直观的告诉你这个方</span></span><br><span class="line">    <span class="comment">//法不会正常返回，而且由于 Nothing 是其他任意类型的子类，他还能跟要求返回值的方法兼</span></span><br><span class="line">    <span class="comment">//容</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">m2</span></span>(n:<span class="type">Int</span>) : <span class="type">Int</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (n == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">Exception</span>()</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> n</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> b = m2(<span class="number">2</span>)</span><br><span class="line">    println(<span class="string">&quot;b: &quot;</span> + b) <span class="comment">//b: 2</span></span><br></pre></td></tr></table></figure>

<h2 id="2-12-类型转换"><a href="#2-12-类型转换" class="headerlink" title="2.12 类型转换"></a>2.12 类型转换</h2><h3 id="2-12-1-数值类型自动转换"><a href="#2-12-1-数值类型自动转换" class="headerlink" title="2.12.1 数值类型自动转换"></a>2.12.1 数值类型自动转换</h3><p>当 Scala 程序在进行赋值或者运算时，精度小的类型自动转换为精度大的数值类型，这个就是自动类型转换（隐式转换）。数据类型按精度（容量）大小排序为：</p>
<img src="Snipaste_2023-10-12_13-20-24.png" alt="Snipaste_2023-10-12_13-20-24" style="zoom:43%;">

<p>（1）自动提升原则：有多种类型的数据混合运算时，系统首先自动将所有数据转换成精度大的那种数据类型，然后再进行计算。</p>
<p>（2）把精度大的数值类型赋值给精度小的数值类型时，就会报错，反之就会进行自动类型转换。</p>
<p>（3）（byte，short）和 char 之间不会相互自动转换。</p>
<p>（4）byte，short，char 他们三者可以计算，在计算时首先转换为 int 类型</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test08_DataTypeConversion</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//（1）自动提升原则：有多种类型的数据混合运算时，系统首先自动将所有数据转换成精度大的那种数据类型，然后再进行计算。</span></span><br><span class="line">    <span class="keyword">val</span> a1: <span class="type">Byte</span> = <span class="number">10</span></span><br><span class="line">    <span class="keyword">val</span> b1: <span class="type">Long</span> = <span class="number">2267</span>L</span><br><span class="line">    <span class="keyword">val</span> result: <span class="type">Long</span> = a1 + b1 <span class="comment">//系统首先自动将所有数据转换成精度大的那种数据类型，然后再进行计算</span></span><br><span class="line">    <span class="keyword">val</span> result1: <span class="type">Int</span> = result.toInt  <span class="comment">//强制类型转换</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//（2）把精度大的数值类型赋值给精度小的数值类型时，就会报错，反之就会进行自动类型转换。</span></span><br><span class="line">    <span class="keyword">val</span> a2: <span class="type">Int</span> = <span class="number">20</span></span><br><span class="line"><span class="comment">//    val b2: Byte = a2   //error</span></span><br><span class="line">    <span class="keyword">val</span> b2: <span class="type">Byte</span> = a2.toByte</span><br><span class="line"></span><br><span class="line">    <span class="comment">//（3）（byte，short）和 char 之间不会相互自动转换。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//（4）byte，short，char 他们三者可以计算，在计算时首先转换为 int 类型</span></span><br><span class="line">    <span class="keyword">val</span> a4: <span class="type">Byte</span> = <span class="number">12</span></span><br><span class="line">    <span class="keyword">val</span> b4: <span class="type">Short</span> = <span class="number">25</span></span><br><span class="line">    <span class="keyword">val</span> c4: <span class="type">Char</span> = &#x27;c&#x27;</span><br><span class="line">    <span class="keyword">val</span> result4: <span class="type">Int</span> = a4 + b4</span><br><span class="line">    <span class="keyword">val</span> result44: <span class="type">Int</span> = a4 + b4 + c4</span><br><span class="line">    println(result4) <span class="comment">//37</span></span><br><span class="line">    println(result44) <span class="comment">//136</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-12-2-强制类型转换"><a href="#2-12-2-强制类型转换" class="headerlink" title="2.12.2 强制类型转换"></a>2.12.2 强制类型转换</h3><p>自动类型转换的逆过程，将精度大的数值类型转换为精度小的数值类型。使用时要加上强制转函数，但可能造成精度降低或溢出，格外要注意。</p>
<p>（1）将数据由高精度转换为低精度，就需要使用到强制转换</p>
<p>（2）强转符号只针对于最近的操作数有效，往往会使用小括号提升优先级</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//2.强制类型转换</span></span><br><span class="line"><span class="keyword">val</span> n1: <span class="type">Int</span> = <span class="number">2.9</span>.toInt <span class="comment">//强制类型转换，注意不是四舍五入，而是直接截断</span></span><br><span class="line"><span class="keyword">val</span> n2: <span class="type">Int</span> = <span class="number">-2.9</span>.toInt</span><br><span class="line">println(n1 + <span class="string">&quot;\t&quot;</span> + n2)  <span class="comment">//2 -2</span></span><br></pre></td></tr></table></figure>

<h3 id="2-12-3-数值类型和String类型之间的转换"><a href="#2-12-3-数值类型和String类型之间的转换" class="headerlink" title="2.12.3 数值类型和String类型之间的转换"></a>2.12.3 数值类型和String类型之间的转换</h3><p>在程序开发中，我们经常需要将基本数值类型转成 String 类型。或者将 String 类型转成基本数值类型。</p>
<p>（1）基本类型转 String 类型（语法：将基本类型的值+”” 即可）</p>
<p>（2）String 类型转基本数值类型（语法：s1.toInt、s1.toFloat、s1.toDouble、s1.toByte、 s1.toLong、s1.toShort）</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//3.数值类型和字符串类型的转换</span></span><br><span class="line"><span class="comment">//(1)数值转String</span></span><br><span class="line"><span class="keyword">val</span> n: <span class="type">Int</span> = <span class="number">27</span></span><br><span class="line"><span class="keyword">val</span> s: <span class="type">String</span> = n + <span class="string">&quot;&quot;</span></span><br><span class="line">println(s)  <span class="comment">//27</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//(2)String转数值</span></span><br><span class="line"><span class="keyword">val</span> m: <span class="type">Int</span> = <span class="string">&quot;12&quot;</span>.toInt</span><br><span class="line"><span class="keyword">val</span> f: <span class="type">Float</span> = <span class="string">&quot;12.3&quot;</span>.toFloat</span><br><span class="line"><span class="keyword">val</span> f2: <span class="type">Int</span> = <span class="string">&quot;12.3&quot;</span>.toDouble.toInt</span><br></pre></td></tr></table></figure>

<p>扩展面试题：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">130的Int类型（占据4字节32位）二进制 0000 0000 0000 0000 0000 0000 1000 0010</span></span><br><span class="line"><span class="comment">强转为Byte类型（占据1字节8位）                                    1000 0010</span></span><br><span class="line"><span class="comment">其中最高位为符号位，所以实际表示为 -128+2 = -126</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test09_Problem_DataTypeConversion</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> n: <span class="type">Int</span> = <span class="number">130</span></span><br><span class="line">    <span class="keyword">val</span> b: <span class="type">Byte</span> = n.toByte</span><br><span class="line">    println(b)  <span class="comment">//-126</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="第三章-运算符"><a href="#第三章-运算符" class="headerlink" title="第三章 运算符"></a>第三章 运算符</h1><p>Scala 运算符的使用和 Java 运算符的使用基本相同，只有个别细节上不同。</p>
<h2 id="3-1-算术运算符"><a href="#3-1-算术运算符" class="headerlink" title="3.1 算术运算符"></a>3.1 算术运算符</h2><img src="Snipaste_2023-10-12_14-10-01.png" alt="Snipaste_2023-10-12_14-10-01" style="zoom:43%;">

<p>对于除号“&#x2F;”，它的整数除和小数除是有区别的：整数之间做除法时，只保留整数部分而舍弃小数部分</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> result = <span class="number">10</span> / <span class="number">3</span>  <span class="comment">//都是整型，结果一定也是整型</span></span><br><span class="line">println(result)  <span class="comment">//3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> result1 = <span class="number">10.0</span> / <span class="number">3</span>  <span class="comment">//有一个是Double类型，运算结果就是Double类型</span></span><br><span class="line">println(result1)  <span class="comment">//3.3333333333333335</span></span><br></pre></td></tr></table></figure>

<h2 id="3-2-关系型运算符（比较运算符）"><a href="#3-2-关系型运算符（比较运算符）" class="headerlink" title="3.2 关系型运算符（比较运算符）"></a>3.2 关系型运算符（比较运算符）</h2><img src="Snipaste_2023-10-12_14-42-36.png" alt="Snipaste_2023-10-12_14-42-36" style="zoom:43%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在java中</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestOperator</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        ==比较两个变量本身的值，即两个对象在内存中的首地址；</span></span><br><span class="line"><span class="comment">        equals 比较字符串中所包含的内容是否相同。</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">s1</span> <span class="operator">=</span> <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">s2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Boolean</span> <span class="variable">isEqual</span> <span class="operator">=</span> (s1==s2);</span><br><span class="line">        System.out.println(isEqual); <span class="comment">//false</span></span><br><span class="line">        System.out.println(s1.equals(s2)); <span class="comment">//true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在scala中</span></span><br><span class="line"><span class="comment">//2.关系运算符，比较运算符</span></span><br><span class="line"><span class="comment">//==更加类似于 Java 中的 equals，参照 jd 工具</span></span><br><span class="line"><span class="keyword">val</span> s1: <span class="type">String</span> = <span class="string">&quot;hello&quot;</span></span><br><span class="line"><span class="keyword">val</span> s2: <span class="type">String</span> = <span class="keyword">new</span> <span class="type">String</span>(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line"></span><br><span class="line">println(s1 == s2)  <span class="comment">//true</span></span><br><span class="line">println(s1.equals(s2))  <span class="comment">//true</span></span><br><span class="line">println(s1.eq(s2))    <span class="comment">//false  //eq()是判断两个对象在内存中的地址是否相等的</span></span><br></pre></td></tr></table></figure>

<h2 id="3-3-逻辑运算符"><a href="#3-3-逻辑运算符" class="headerlink" title="3.3 逻辑运算符"></a>3.3 逻辑运算符</h2><img src="Snipaste_2023-10-12_15-08-30.png" alt="Snipaste_2023-10-12_15-08-30" style="zoom:43%;">

<p>逻辑运算符都有<strong>短路的特征</strong>，</p>
<p>当A&amp;&amp;B时，当A已经判断为false时，B跳过判断，整个式子就为false</p>
<p>当A||B时，当A已经判断为true时，B跳过判断，整个式子就为true</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//判断一个字符串是否为空</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isNotEmpty</span></span>(str: <span class="type">String</span>) : <span class="type">Boolean</span> = &#123;</span><br><span class="line">  <span class="keyword">return</span> str != <span class="literal">null</span> &amp;&amp; !(<span class="string">&quot;&quot;</span>.equals(str.trim))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">println(isNotEmpty(<span class="literal">null</span>))  <span class="comment">//false</span></span><br></pre></td></tr></table></figure>

<h2 id="3-4-赋值运算符"><a href="#3-4-赋值运算符" class="headerlink" title="3.4 赋值运算符"></a>3.4 赋值运算符</h2><img src="Snipaste_2023-10-12_15-20-21.png" alt="Snipaste_2023-10-12_15-20-21" style="zoom: 50%;">

<p>注意：Scala 中没有++、–操作符，可以通过+&#x3D;、-&#x3D;来实现同样的效果</p>
<h2 id="3-5-位运算符"><a href="#3-5-位运算符" class="headerlink" title="3.5 位运算符"></a>3.5 位运算符</h2><p>下表中变量a为60，b为13</p>
<img src="Snipaste_2023-10-12_15-27-17.png" alt="Snipaste_2023-10-12_15-27-17" style="zoom:43%;">

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> a = <span class="number">60</span></span><br><span class="line">println(a &lt;&lt; <span class="number">1</span>)  <span class="comment">//120,相当于乘以2</span></span><br><span class="line">println(a &lt;&lt; <span class="number">2</span>)  <span class="comment">//240,相当于乘以4</span></span><br><span class="line">println(a &lt;&lt; <span class="number">3</span>)  <span class="comment">//480,相当于乘以8</span></span><br><span class="line">println(a &gt;&gt; <span class="number">1</span>)  <span class="comment">//30,相当于除以2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> b: <span class="type">Short</span> = <span class="number">-13</span></span><br><span class="line">println(b &lt;&lt; <span class="number">2</span>)  <span class="comment">//-52</span></span><br><span class="line">println(b &gt;&gt; <span class="number">2</span>)  <span class="comment">//-4</span></span><br><span class="line">println(b &gt;&gt;&gt; <span class="number">2</span>)  <span class="comment">//1073741820</span></span><br></pre></td></tr></table></figure>

<h2 id="3-6-Scala运算符本质"><a href="#3-6-Scala运算符本质" class="headerlink" title="3.6 Scala运算符本质"></a>3.6 Scala运算符本质</h2><p>在 Scala 中其实是没有运算符的，所有运算符都是方法。</p>
<p>1）当调用对象的方法时，点.可以省略</p>
<p>2）如果函数参数只有一个，或者没有参数，()可以省略</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//运算符的本质：真正做到完全面向对象</span></span><br><span class="line">    <span class="keyword">val</span> n1: <span class="type">Int</span> = <span class="number">12</span></span><br><span class="line">    <span class="keyword">val</span> n2: <span class="type">Int</span> = <span class="number">37</span></span><br><span class="line"></span><br><span class="line">    println(n1.+(n2))   <span class="comment">//实际上+()是一个方法，每个对象用.去调用</span></span><br><span class="line"><span class="comment">//    println(n1 + n2)</span></span><br><span class="line">    println(<span class="number">7.5</span>.toString())</span><br><span class="line">    println(<span class="number">7.5</span> toString())</span><br><span class="line">    println(<span class="number">7.5</span> toString)</span><br><span class="line">    println(<span class="number">7.5</span> toInt toString)</span><br></pre></td></tr></table></figure>

<h1 id="第四章-流程控制"><a href="#第四章-流程控制" class="headerlink" title="第四章 流程控制"></a>第四章 流程控制</h1><h2 id="4-1-分支流程if-else"><a href="#4-1-分支流程if-else" class="headerlink" title="4.1 分支流程if-else"></a>4.1 分支流程if-else</h2><h3 id="4-1-1-单分支"><a href="#4-1-1-单分支" class="headerlink" title="4.1.1 单分支"></a>4.1.1 单分支</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (条件表达式) &#123;</span><br><span class="line">执行代码块</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2-双分支"><a href="#4-1-2-双分支" class="headerlink" title="4.1.2 双分支"></a>4.1.2 双分支</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (条件表达式) &#123;</span><br><span class="line">执行代码块 1</span><br><span class="line">&#125; else &#123;</span><br><span class="line">执行代码块 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3-多分支"><a href="#4-1-3-多分支" class="headerlink" title="4.1.3 多分支"></a>4.1.3 多分支</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">if (条件表达式 1) &#123;</span><br><span class="line">执行代码块 1</span><br><span class="line">&#125;</span><br><span class="line">else if (条件表达式 2) &#123;</span><br><span class="line">执行代码块 2</span><br><span class="line">&#125;</span><br><span class="line"> ……</span><br><span class="line">else &#123;</span><br><span class="line">执行代码块 n</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test01_ifElse</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;请输入您的年龄：&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> age: <span class="type">Int</span> = <span class="type">StdIn</span>.readInt()</span><br><span class="line"></span><br><span class="line">    <span class="comment">//1.单分支</span></span><br><span class="line">    <span class="keyword">if</span> (age &gt;= <span class="number">18</span>)&#123;</span><br><span class="line">      println(<span class="string">&quot;成年&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.双分支</span></span><br><span class="line">    <span class="keyword">if</span> (age &gt;= <span class="number">18</span>)&#123;</span><br><span class="line">      println(<span class="string">&quot;成年&quot;</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      println(<span class="string">&quot;未成年&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.多分支</span></span><br><span class="line">    <span class="keyword">if</span> (age &lt; <span class="number">18</span>)&#123;</span><br><span class="line">      println(<span class="string">&quot;童年&quot;</span>)</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(age&gt;=<span class="number">18</span> &amp;&amp; age&lt;<span class="number">30</span>)&#123;</span><br><span class="line">      println(<span class="string">&quot;中年&quot;</span>)</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">      println(<span class="string">&quot;老年&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//Scala 中 if else 表达式其实是有返回值的，具体返回值取决于满足条件的</span></span><br><span class="line">    <span class="comment">//代码体的最后一行内容。</span></span><br><span class="line">    <span class="keyword">val</span> res: <span class="type">String</span> = <span class="keyword">if</span> (age &lt; <span class="number">18</span>) &#123;</span><br><span class="line">      <span class="string">&quot;童年&quot;</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (age &gt;= <span class="number">18</span> &amp;&amp; age &lt; <span class="number">30</span>) &#123;</span><br><span class="line">      <span class="string">&quot;中年&quot;</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="string">&quot;老年&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(res) <span class="comment">//中年(输入的是25)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//Scala 中返回值类型不一致，取它们共同的祖先类型。</span></span><br><span class="line">    <span class="keyword">val</span> res1:<span class="type">Any</span> = <span class="keyword">if</span> (age &lt; <span class="number">18</span>)&#123;</span><br><span class="line">      <span class="string">&quot;童年&quot;</span></span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(age&gt;=<span class="number">18</span> &amp;&amp; age&lt;<span class="number">30</span>)&#123;</span><br><span class="line">      <span class="string">&quot;中年&quot;</span></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="number">100</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(res1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">//Java 中的三元运算符可以用 if else 实现</span></span><br><span class="line">    <span class="comment">//如果大括号&#123;&#125;内的逻辑代码只有一行，大括号可以省略。如果省略大括号，if 只对最近</span></span><br><span class="line">    <span class="comment">//的一行逻辑代码起作用</span></span><br><span class="line">    <span class="keyword">val</span> res2:<span class="type">Any</span> = <span class="keyword">if</span> (age &lt; <span class="number">18</span>) <span class="string">&quot;童年&quot;</span> <span class="keyword">else</span> <span class="string">&quot;成年&quot;</span></span><br><span class="line">    println(res2)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-2-嵌套分支"><a href="#4-2-嵌套分支" class="headerlink" title="4.2 嵌套分支"></a>4.2 嵌套分支</h2><p>在一个分支结构中又完整的嵌套了另一个完整的分支结构，里面的分支的结构称为内层。分支外面的分支结构称为外层分支。嵌套分支不要超过 3 层。</p>
<h2 id="4-3-Switch分支结构-模式匹配"><a href="#4-3-Switch分支结构-模式匹配" class="headerlink" title="4.3 Switch分支结构-模式匹配"></a>4.3 Switch分支结构-模式匹配</h2><h2 id="4-4-For循环控制"><a href="#4-4-For循环控制" class="headerlink" title="4.4 For循环控制"></a>4.4 For循环控制</h2><p>Scala 也为 for 循环这一常见的控制结构提供了非常多的特性，这些 for 循环的特性被称为 for 推导式或 for 表达式</p>
<h3 id="4-4-1-范围数据循环（To）"><a href="#4-4-1-范围数据循环（To）" class="headerlink" title="4.4.1 范围数据循环（To）"></a>4.4.1 范围数据循环（To）</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1、范围数据循环（To）</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>)&#123;</span><br><span class="line">  <span class="comment">//i 表示循环的变量，&lt;- 规定 to</span></span><br><span class="line">  <span class="comment">//i 将会从 1-10 循环，前后闭合</span></span><br><span class="line">  println(i + <span class="string">&quot;. hello world!&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">1. hello world!</span></span><br><span class="line"><span class="comment">2. hello world!</span></span><br><span class="line"><span class="comment">3. hello world!</span></span><br><span class="line"><span class="comment">4. hello world!</span></span><br><span class="line"><span class="comment">5. hello world!</span></span><br><span class="line"><span class="comment">6. hello world!</span></span><br><span class="line"><span class="comment">7. hello world!</span></span><br><span class="line"><span class="comment">8. hello world!</span></span><br><span class="line"><span class="comment">9. hello world!</span></span><br><span class="line"><span class="comment">10. hello world!</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<h3 id="4-4-2-范围数据循环（Until）"><a href="#4-4-2-范围数据循环（Until）" class="headerlink" title="4.4.2 范围数据循环（Until）"></a>4.4.2 范围数据循环（Until）</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//2.范围数据循环（Until）</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> until <span class="number">10</span>)&#123;</span><br><span class="line">  <span class="comment">//前闭合后开的范围</span></span><br><span class="line">  println(i + <span class="string">&quot;. hello world!&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">1. hello world!</span></span><br><span class="line"><span class="comment">2. hello world!</span></span><br><span class="line"><span class="comment">3. hello world!</span></span><br><span class="line"><span class="comment">4. hello world!</span></span><br><span class="line"><span class="comment">5. hello world!</span></span><br><span class="line"><span class="comment">6. hello world!</span></span><br><span class="line"><span class="comment">7. hello world!</span></span><br><span class="line"><span class="comment">8. hello world!</span></span><br><span class="line"><span class="comment">9. hello world!</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//或者使用Range()，也能表示左闭右开</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="type">Range</span>(<span class="number">1</span>,<span class="number">10</span>))&#123;</span><br><span class="line">    println(i + <span class="string">&quot;. hello world!&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//扩展：集合遍历</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="type">Array</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))&#123;</span><br><span class="line">  print(i + <span class="string">&quot;\t&quot;</span>)  <span class="comment">//1  2  3  4  5  6</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="type">List</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))&#123;</span><br><span class="line">  print(i + <span class="string">&quot;\t&quot;</span>)  <span class="comment">//1  2  3  4  5  6</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="type">Set</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))&#123;</span><br><span class="line">  print(i + <span class="string">&quot;\t&quot;</span>)  <span class="comment">//1  2  3  4  5  6</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//以上集合遍历不考虑下标，类似于java中的增强for循环</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在java中</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    ArrayList&lt;Integer&gt; list1 = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;Integer&gt;();</span><br><span class="line">    list1.add(<span class="number">1</span>);</span><br><span class="line">    list1.add(<span class="number">2</span>);</span><br><span class="line">    list1.add(<span class="number">3</span>);</span><br><span class="line">    list1.add(<span class="number">4</span>);</span><br><span class="line">    list1.add(<span class="number">5</span>);</span><br><span class="line">    list1.add(<span class="number">6</span>);</span><br><span class="line">    <span class="keyword">for</span> (Integer list : list1) &#123;</span><br><span class="line">        System.out.print(list + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line">    &#125;<span class="comment">//1	2	3	4	5	6</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-4-3-循环守卫"><a href="#4-4-3-循环守卫" class="headerlink" title="4.4.3 循环守卫"></a>4.4.3 循环守卫</h3><p>循环守卫，即循环保护式（也称条件判断式，守卫）。保护式为 true 则进入循环体内部，为 false 则跳过，类似于 continue</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//3.循环守卫</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span> <span class="keyword">if</span> i != <span class="number">5</span>)&#123;</span><br><span class="line">  println(i)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//以上代码等价于：</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>)&#123;</span><br><span class="line">  <span class="keyword">if</span> (i != <span class="number">5</span>)&#123;</span><br><span class="line">    println(i)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-4-4-循环步长"><a href="#4-4-4-循环步长" class="headerlink" title="4.4.4 循环步长"></a>4.4.4 循环步长</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//4.循环步长</span></span><br><span class="line"><span class="comment">//by 表示步长</span></span><br><span class="line"><span class="comment">//输出 1 到 10 以内的所有奇数</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span> by <span class="number">2</span>)&#123;</span><br><span class="line">  println(<span class="string">&quot;i= &quot;</span> + i)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">13</span> to <span class="number">30</span> by <span class="number">3</span>)&#123;</span><br><span class="line">  println(<span class="string">&quot;i= &quot;</span> + i)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//也可以倒着输出</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">30</span> to <span class="number">13</span> by <span class="number">-2</span>)&#123;</span><br><span class="line">  println(<span class="string">&quot;i= &quot;</span> + i)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//或者直接逆序输出</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span> reverse)&#123;</span><br><span class="line">  println(<span class="string">&quot;i= &quot;</span> + i)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//甚至可以每次走一个小数的步</span></span><br><span class="line"><span class="keyword">for</span> (data &lt;- <span class="type">BigDecimal</span>(<span class="number">1.0</span>) to <span class="type">BigDecimal</span>(<span class="number">10.0</span>) by <span class="number">0.5</span>)&#123;</span><br><span class="line">  println(data)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (data &lt;- <span class="type">BigDecimal</span>(<span class="number">1.0</span>) to <span class="type">BigDecimal</span>(<span class="number">10.0</span>) by <span class="number">0.3</span>)&#123;</span><br><span class="line">  println(data)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">1.0</span></span><br><span class="line"><span class="comment">1.3</span></span><br><span class="line"><span class="comment">1.6</span></span><br><span class="line"><span class="comment">1.9</span></span><br><span class="line"><span class="comment">2.2</span></span><br><span class="line"><span class="comment">2.5</span></span><br><span class="line"><span class="comment">2.8</span></span><br><span class="line"><span class="comment">3.1</span></span><br><span class="line"><span class="comment">3.4</span></span><br><span class="line"><span class="comment">3.7</span></span><br><span class="line"><span class="comment">4.0</span></span><br><span class="line"><span class="comment">4.3</span></span><br><span class="line"><span class="comment">4.6</span></span><br><span class="line"><span class="comment">4.9</span></span><br><span class="line"><span class="comment">5.2</span></span><br><span class="line"><span class="comment">5.5</span></span><br><span class="line"><span class="comment">5.8</span></span><br><span class="line"><span class="comment">6.1</span></span><br><span class="line"><span class="comment">6.4</span></span><br><span class="line"><span class="comment">6.7</span></span><br><span class="line"><span class="comment">7.0</span></span><br><span class="line"><span class="comment">7.3</span></span><br><span class="line"><span class="comment">7.6</span></span><br><span class="line"><span class="comment">7.9</span></span><br><span class="line"><span class="comment">8.2</span></span><br><span class="line"><span class="comment">8.5</span></span><br><span class="line"><span class="comment">8.8</span></span><br><span class="line"><span class="comment">9.1</span></span><br><span class="line"><span class="comment">9.4</span></span><br><span class="line"><span class="comment">9.7</span></span><br><span class="line"><span class="comment">10.0</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<h3 id="4-4-5-嵌套循环"><a href="#4-4-5-嵌套循环" class="headerlink" title="4.4.5 嵌套循环"></a>4.4.5 嵌套循环</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//5. 循环嵌套</span></span><br><span class="line"><span class="comment">//方式1：</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">3</span>)&#123;</span><br><span class="line">  <span class="keyword">for</span> (j &lt;- <span class="number">1</span> to <span class="number">3</span>)&#123;</span><br><span class="line">    println(i + <span class="string">&quot;,&quot;</span> + j)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//方式2：</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">3</span>; j &lt;- <span class="number">1</span> to <span class="number">3</span>)&#123;</span><br><span class="line">  println(i + <span class="string">&quot;,&quot;</span> + j)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//方式1：</span></span><br><span class="line">   <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">9</span>)&#123;</span><br><span class="line">     <span class="keyword">for</span> (j &lt;- <span class="number">1</span> to i)&#123;</span><br><span class="line">       print(<span class="string">s&quot;<span class="subst">$&#123;j&#125;</span> * <span class="subst">$&#123;i&#125;</span> = <span class="subst">$&#123;i * j&#125;</span> \t&quot;</span>)</span><br><span class="line">     &#125;</span><br><span class="line">     println()</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">//方式2：</span></span><br><span class="line">   <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">9</span>; j &lt;- <span class="number">1</span> to i)&#123;</span><br><span class="line">     print(<span class="string">s&quot;<span class="subst">$&#123;j&#125;</span> * <span class="subst">$&#123;i&#125;</span> = <span class="subst">$&#123;i * j&#125;</span> \t&quot;</span>)</span><br><span class="line">     <span class="keyword">if</span> (j == i) println()</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1 * 1 = 1 	</span><br><span class="line">1 * 2 = 2 	2 * 2 = 4 	</span><br><span class="line">1 * 3 = 3 	2 * 3 = 6 	3 * 3 = 9 	</span><br><span class="line">1 * 4 = 4 	2 * 4 = 8 	3 * 4 = 12 	4 * 4 = 16 	</span><br><span class="line">1 * 5 = 5 	2 * 5 = 10 	3 * 5 = 15 	4 * 5 = 20 	5 * 5 = 25 	</span><br><span class="line">1 * 6 = 6 	2 * 6 = 12 	3 * 6 = 18 	4 * 6 = 24 	5 * 6 = 30 	6 * 6 = 36 	</span><br><span class="line">1 * 7 = 7 	2 * 7 = 14 	3 * 7 = 21 	4 * 7 = 28 	5 * 7 = 35 	6 * 7 = 42 	7 * 7 = 49 	</span><br><span class="line">1 * 8 = 8 	2 * 8 = 16 	3 * 8 = 24 	4 * 8 = 32 	5 * 8 = 40 	6 * 8 = 48 	7 * 8 = 56 	8 * 8 = 64 	</span><br><span class="line">1 * 9 = 9 	2 * 9 = 18 	3 * 9 = 27 	4 * 9 = 36 	5 * 9 = 45 	6 * 9 = 54 	7 * 9 = 63 	8 * 9 = 72 	9 * 9 = 81 </span><br></pre></td></tr></table></figure>

<h3 id="4-4-6-引入变量"><a href="#4-4-6-引入变量" class="headerlink" title="4.4.6 引入变量"></a>4.4.6 引入变量</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//6. 引入变量</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>; j = <span class="number">10</span> - i)&#123;</span><br><span class="line">  println(<span class="string">&quot;i=&quot;</span> + i + <span class="string">&quot; j=&quot;</span> + j)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//等价于</span></span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>)&#123;</span><br><span class="line">  <span class="keyword">var</span> j = <span class="number">10</span> - i</span><br><span class="line">  println(<span class="string">&quot;i=&quot;</span> + i + <span class="string">&quot; j=&quot;</span> + j)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//或者写成：</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">  i &lt;- <span class="number">1</span> to <span class="number">10</span></span><br><span class="line">  j = <span class="number">10</span> - i</span><br><span class="line">&#125;&#123;</span><br><span class="line">  println(<span class="string">&quot;i=&quot;</span> + i + <span class="string">&quot; j=&quot;</span> + j)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-4-7-循环返回值"><a href="#4-4-7-循环返回值" class="headerlink" title="4.4.7 循环返回值"></a>4.4.7 循环返回值</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//默认情况下，scala的for循环返回值都是空()</span></span><br><span class="line"><span class="keyword">val</span> a: <span class="type">Unit</span> = <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>) &#123;</span><br><span class="line">  println(i)</span><br><span class="line">&#125;</span><br><span class="line">println(a)  <span class="comment">//()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//将遍历过程中处理的结果返回到一个新 Vector 集合中，使用 yield 关键字。开发中很少用</span></span><br><span class="line"><span class="keyword">val</span> res = <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>) <span class="keyword">yield</span> i</span><br><span class="line">println(res)  <span class="comment">//Vector(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</span></span><br><span class="line"><span class="comment">//将原数据中所有值乘以 2，并把数据返回到一个新的集合中</span></span><br><span class="line"><span class="keyword">val</span> res1 = <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>) <span class="keyword">yield</span> i * <span class="number">2</span></span><br><span class="line">println(res1)   <span class="comment">//Vector(2, 4, 6, 8, 10, 12, 14, 16, 18, 20)</span></span><br></pre></td></tr></table></figure>

<h3 id="4-4-8-倒序打印"><a href="#4-4-8-倒序打印" class="headerlink" title="4.4.8 倒序打印"></a>4.4.8 倒序打印</h3><p>如果想倒序打印一组数据，可以用 reverse</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span> reverse)&#123;</span><br><span class="line">  print(i + <span class="string">&quot;\t&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//10 9  8  7  6  5  4  3  2  1</span></span><br></pre></td></tr></table></figure>

<h2 id="4-5-while循环和do-while循环（不推荐使用）"><a href="#4-5-while循环和do-while循环（不推荐使用）" class="headerlink" title="4.5 while循环和do..while循环（不推荐使用）"></a>4.5 while循环和do..while循环（不推荐使用）</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">循环变量初始化</span><br><span class="line">while (循环条件) &#123;</span><br><span class="line"> 循环体(语句)</span><br><span class="line"> 循环变量迭代</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<p>（1）循环条件是返回一个布尔值的表达式</p>
<p>（2）while 循环是先判断再执行语句</p>
<p>（3）与 for 语句不同，while 语句没有返回值，即整个 while 语句的结果是 Unit 类型()</p>
<p>（4）因为 while 中没有返回值，所以当要用该语句来计算并返回结果时，就不可避免的使用变量，而变量需要声明在 while 循环的外部，那么就等同于循环的内部对外部的变量造成了影响，所以不推荐使用，而是推荐使用 for 循环。</p>
<h2 id="4-6-循环中断"><a href="#4-6-循环中断" class="headerlink" title="4.6 循环中断"></a>4.6 循环中断</h2><p>Scala 内置控制结构特地<strong>去掉了</strong> <strong>break</strong> <strong>和</strong> <strong>continue</strong>，是为了更好的适应<strong>函数式编程</strong>，推荐使用函数式的风格解决break和continue的功能，而不是一个关键字。Scala中使用breakable控制结构来实现 break 和 continue 功能</p>
<p>java中的例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//使用break退出循环</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span> (i == <span class="number">3</span>)&#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.print(i + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println();</span><br><span class="line">    System.out.println(<span class="string">&quot;这是循环外的代码&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    0	1	2	</span></span><br><span class="line"><span class="comment">    这是循环外的代码</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//用try..catch实现退出循环的功能</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">3</span>)&#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.print(i + <span class="string">&quot;\t&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">        <span class="comment">//什么都不做，只是退出循环</span></span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println();</span><br><span class="line">    System.out.println(<span class="string">&quot;这是循环外的代码&quot;</span>);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>scala中的例子：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test06_Break</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//1.采用抛出异常的方式退出循环</span></span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">      <span class="keyword">for</span> (i &lt;- <span class="number">0</span> to <span class="number">3</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span> (i == <span class="number">3</span>)&#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">RuntimeException</span>()</span><br><span class="line">        &#125;</span><br><span class="line">        print(i + <span class="string">&quot;\t&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;   <span class="comment">//什么都不做，只是退出循环</span></span><br><span class="line">    &#125;</span><br><span class="line">    println()</span><br><span class="line">    println(<span class="string">&quot;这是循环外的代码&quot;</span>)</span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">    <span class="comment">//2.使用scala中的Breaks类的break方法，实现异常的抛出和捕获</span></span><br><span class="line">    <span class="type">Breaks</span>.breakable(</span><br><span class="line">      <span class="keyword">for</span> (i &lt;- <span class="number">0</span> to <span class="number">3</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span> (i == <span class="number">3</span>)</span><br><span class="line">          <span class="type">Breaks</span>.<span class="keyword">break</span>()</span><br><span class="line">        println(i)</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">//还可以对Breaks进行省略</span></span><br><span class="line">    breakable(</span><br><span class="line">      <span class="keyword">for</span> (i &lt;- <span class="number">0</span> to <span class="number">3</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span> (i == <span class="number">3</span>)</span><br><span class="line">          <span class="keyword">break</span>()</span><br><span class="line">        println(i)</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line">    println()</span><br><span class="line">    println(<span class="string">&quot;这是循环外的代码&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="第五章-函数式编程"><a href="#第五章-函数式编程" class="headerlink" title="第五章 函数式编程"></a>第五章 函数式编程</h1><p>解决问题时，将问题分解成一个一个的步骤，将每个步骤进行封装（函数），通过调用这些封装好的步骤，解决问题。</p>
<p>例如：请求-&gt;用户名、密码-&gt;连接 JDBC-&gt;读取数据库</p>
<p>Scala 语言是一个完全函数式编程语言。万物皆函数。</p>
<p>函数的本质：函数可以当做一个值进行传递</p>
<p>在 Scala 中函数式编程和面向对象编程完美融合在一起了</p>
<h2 id="5-1-函数基础"><a href="#5-1-函数基础" class="headerlink" title="5.1 函数基础"></a>5.1 函数基础</h2><h3 id="5-1-1-函数基本语法"><a href="#5-1-1-函数基本语法" class="headerlink" title="5.1.1 函数基本语法"></a>5.1.1 函数基本语法</h3><img src="Snipaste_2023-10-13_12-26-27.png" alt="Snipaste_2023-10-13_12-26-27" style="zoom:43%;">

<h3 id="5-1-2-函数和方法的区别"><a href="#5-1-2-函数和方法的区别" class="headerlink" title="5.1.2 函数和方法的区别"></a>5.1.2 函数和方法的区别</h3><p>（1）为完成某一功能的程序语句的集合，称为函数。</p>
<p>（2）类中的函数称之方法。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test01_FunctionAndMethod</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//1.定义函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sayHi</span></span>(name: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;hi, &quot;</span> + name)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用函数，此时调用的是临近的函数</span></span><br><span class="line">    sayHi(<span class="string">&quot;bob&quot;</span>)  <span class="comment">//hi, bob</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用对象方法，此时调用的是紧贴类中定义的方法</span></span><br><span class="line">    <span class="type">Test01_FunctionAndMethod</span>.sayHi(<span class="string">&quot;Alice&quot;</span>)  <span class="comment">//Hi, Alice</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取方法返回值</span></span><br><span class="line">    <span class="keyword">val</span> res: <span class="type">String</span> = <span class="type">Test01_FunctionAndMethod</span>.sayHi(<span class="string">&quot;wang&quot;</span>,<span class="number">25</span>)  <span class="comment">//Hi, wang,25</span></span><br><span class="line">    println(res)  <span class="comment">//Hello</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//定义对象的方法（可以规定：紧贴类中定义的叫方法，在main方法内定义的叫函数）</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sayHi</span></span>(name: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;Hi, &quot;</span> + name)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//方法重载(方法可以重载或重写，函数不能)</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sayHi</span></span>(name: <span class="type">String</span>, age: <span class="type">Int</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    println(<span class="string">&quot;Hi, &quot;</span> + name + <span class="string">&quot;,&quot;</span> + age)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hello&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-1-3-函数定义"><a href="#5-1-3-函数定义" class="headerlink" title="5.1.3 函数定义"></a>5.1.3 函数定义</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test02_FunctionDefine</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//（1）函数 1：无参，无返回值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f1</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;1：无参，无返回值&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    f1()</span><br><span class="line">    println(f1())  <span class="comment">//()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//（2）函数 2：无参，有返回值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f2</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;2：无参，有返回值&quot;</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="number">12</span></span><br><span class="line">    &#125;</span><br><span class="line">    println(f2())  <span class="comment">//12</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//（3）函数 3：有参，无返回值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f3</span> </span>(name: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;3：有参，无返回值&quot;</span> + name)</span><br><span class="line">    &#125;</span><br><span class="line">    println(f3(<span class="string">&quot;alice&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//（4）函数 4：有参，有返回值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f4</span> </span>(name: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;4：有参，有返回值&quot;</span> + name)</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;hi,&quot;</span> + name</span><br><span class="line">    &#125;</span><br><span class="line">    println(f4(<span class="string">&quot;alice&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">//（5）函数 5：多参，无返回值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f5</span></span>(name1: <span class="type">String</span>, name2: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$&#123;name1&#125;</span>和<span class="subst">$&#123;name2&#125;</span>都是我的好朋友&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    f5(<span class="string">&quot;alice&quot;</span>,<span class="string">&quot;wang&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//（6）函数 6：多参，有返回值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f6</span></span>(a:<span class="type">Int</span>, b:<span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      <span class="keyword">return</span> a + b</span><br><span class="line">    &#125;</span><br><span class="line">    println(f6(<span class="number">12</span>,<span class="number">23</span>))  <span class="comment">//35</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4-函数参数"><a href="#5-1-4-函数参数" class="headerlink" title="5.1.4 函数参数"></a>5.1.4 函数参数</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test03_FunctionParameter</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//（1）可变参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f1</span></span>(str: <span class="type">String</span>*): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(str)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    f1(<span class="string">&quot;bob&quot;</span>)  <span class="comment">//WrappedArray(bob)</span></span><br><span class="line">    f1(<span class="string">&quot;alice&quot;</span>, <span class="string">&quot;bob&quot;</span>, <span class="string">&quot;wang&quot;</span>)  <span class="comment">//WrappedArray(alice, bob, wang)</span></span><br><span class="line">    f1()  <span class="comment">//List()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//（2）如果参数列表中存在多个参数，那么可变参数一般放置在最后</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f2</span></span>(str1: <span class="type">String</span>, str2: <span class="type">String</span>*): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;str1: &quot;</span> + str1 + <span class="string">&quot;, str2: &quot;</span> + str2)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    f2(<span class="string">&quot;alice&quot;</span>)  <span class="comment">//str1: alice, str2: WrappedArray()</span></span><br><span class="line">    f2(<span class="string">&quot;aaa&quot;</span>, <span class="string">&quot;bbb&quot;</span>, <span class="string">&quot;ccc&quot;</span>)  <span class="comment">//str1: aaa, str2: WrappedArray(bbb, ccc)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//（3）参数默认值，一般将有默认值的参数放置在参数列表的后面</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f3</span></span>(name: <span class="type">String</span>, age: <span class="type">Int</span> = <span class="number">30</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$&#123;name&#125;</span>, <span class="subst">$&#123;age&#125;</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果参数传递了值，那么会覆盖默认值</span></span><br><span class="line">    f3(<span class="string">&quot;alice&quot;</span>, <span class="number">20</span>)  <span class="comment">//alice, 20</span></span><br><span class="line">    <span class="comment">// 如果参数有默认值，在调用的时候，可以省略这个参数</span></span><br><span class="line">    f3(<span class="string">&quot;alice&quot;</span>)  <span class="comment">//alice, 30</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//（4）带名参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f4</span></span>(name: <span class="type">String</span>, age: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">s&quot;<span class="subst">$&#123;age&#125;</span>岁的<span class="subst">$&#123;name&#125;</span>在学习&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    f4(<span class="string">&quot;alice&quot;</span>, <span class="number">20</span>)</span><br><span class="line">    f4(age = <span class="number">20</span>, name = <span class="string">&quot;alice&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-1-5-函数至简原则（重点）"><a href="#5-1-5-函数至简原则（重点）" class="headerlink" title="5.1.5 函数至简原则（重点）"></a>5.1.5 函数至简原则（重点）</h3><p>（1）return 可以省略，Scala 会使用函数体的最后一行代码作为返回值</p>
<p>（2）如果函数体只有一行代码，可以省略花括号</p>
<p>（3）返回值类型如果能够推断出来，那么可以省略（:和返回值类型一起省略）</p>
<p>（4）如果有 return，则不能省略返回值类型，必须指定</p>
<p>（5）如果函数明确声明 unit，那么即使函数体中使用 return 关键字也不起作用</p>
<p>（6）Scala 如果期望是无返回值类型，可以省略等号</p>
<p>（7）如果函数无参，但是声明了参数列表，那么调用时，小括号，可加可不加</p>
<p>（8）如果函数没有参数列表，那么小括号可以省略，调用时小括号必须省略</p>
<p>（9）如果不关心名称，只关心逻辑处理，那么函数名（def）可以省略</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Test04_Simplify</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f0</span></span>(name: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">      <span class="keyword">return</span> name</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(f0(<span class="string">&quot;bob&quot;</span>))  <span class="comment">//bob</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//    （1）return 可以省略，Scala 会使用函数体的最后一行代码作为返回值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f1</span></span>(name: <span class="type">String</span>): <span class="type">String</span> = &#123;</span><br><span class="line">       name</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    （2）如果函数体只有一行代码，可以省略花括号</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f2</span></span>(name: <span class="type">String</span>): <span class="type">String</span> = name</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    （3）返回值类型如果能够推断出来，那么可以省略（:和返回值类型一起省略）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f3</span></span>(name: <span class="type">String</span>) = name</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    （4）如果有 return，则不能省略返回值类型，必须指定</span></span><br><span class="line">    <span class="comment">//    （5）如果函数明确声明 unit，那么即使函数体中使用 return 关键字也不起作用</span></span><br><span class="line">    <span class="comment">//    （6）Scala 如果期望是无返回值类型，可以省略等号（也叫过程）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f6</span></span>(name: <span class="type">String</span>) &#123;</span><br><span class="line">      println(name)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//    （7）如果函数无参，但是声明了参数列表，那么调用时，小括号，可加可不加</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f7</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;atguigu&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    f7()  <span class="comment">//atguigu</span></span><br><span class="line">    f7  <span class="comment">//atguigu</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//    （8）如果函数没有参数列表，那么小括号可以省略，调用时小括号必须省略</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f8</span></span>: <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;atguigu&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    f8  <span class="comment">//atguigu</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//    （9）如果不关心名称，只关心逻辑处理，那么def和函数名可以同时省略，称之为【匿名函数】</span></span><br><span class="line">    <span class="comment">//1.def和函数名要同时省略</span></span><br><span class="line">    <span class="comment">//2.返回值类型也要省略，由逻辑代码自动推断</span></span><br><span class="line">    <span class="comment">//3.等号需要增加大于号表示关联</span></span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f9</span></span>(name: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(name)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//匿名函数，lambda表达式：</span></span><br><span class="line">    (name: <span class="type">String</span>) =&gt; &#123;println(name)&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="5-2-函数高级"><a href="#5-2-函数高级" class="headerlink" title="5.2 函数高级"></a>5.2 函数高级</h2><h3 id="5-2-1-高阶函数"><a href="#5-2-1-高阶函数" class="headerlink" title="5.2.1 高阶函数"></a>5.2.1 高阶函数</h3><p>（1）函数作为值传递</p>
<p>在scala中，函数也是对象，对象也是函数</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">new_scala_Function_Hell</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//函数也是对象，对象也是函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>() : <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//如果一个函数声明时，参数列表中没有参数，那么调用时可以省略小括号</span></span><br><span class="line">    println(test)   <span class="comment">//()   //打印test方法的执行结果</span></span><br><span class="line">    <span class="comment">//如果不想让函数执行，只是想访问这个函数本身（当作对象），可以采用特殊符号进行转换</span></span><br><span class="line">    println(test _)  <span class="comment">//com.atguigu.chapter05.new_scala_Function_Hell$$$Lambda$5/1289479439@66d33a</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">new_scala_Function_Hell_02</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">      println(<span class="string">&quot;test...&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将函数对象赋值给一个变量，那么这个变量其实就是函数</span></span><br><span class="line">    <span class="comment">//既然这个变量就是函数，所以这个变量是可以传参后执行，注意需要加上括号</span></span><br><span class="line">    <span class="keyword">val</span> f = test _</span><br><span class="line">    f()  <span class="comment">//test...</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）函数可以作为参数进行传递</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">new_scala_Function_Hell_01</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">//TODO 函数其实就是对象</span></span><br><span class="line">    <span class="comment">//1.对象应该有类型</span></span><br><span class="line">    <span class="comment">//2.对象可以赋值给其他人使用</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>(): <span class="type">Unit</span> = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test1</span></span>(age: <span class="type">Int</span>): <span class="type">String</span> = &#123;</span><br><span class="line">      age.toString</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//将函数对象test赋值给f，此时f就可以通过编译器自动推断类型，函数对象的类型称之为函数类型</span></span><br><span class="line">    <span class="comment">//Function0[Unit]:</span></span><br><span class="line">    <span class="comment">//       这里类型中的0表示函数参数列表中参数的个数</span></span><br><span class="line">    <span class="comment">//       中括号中的Unit表示函数没有返回值</span></span><br><span class="line">    <span class="keyword">val</span> f: <span class="type">Function0</span>[<span class="type">Unit</span>] = test _</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Function1[Int, String]:</span></span><br><span class="line">    <span class="comment">//       这里类型中的1表示函数参数列表中参数的个数</span></span><br><span class="line">    <span class="comment">//       中括号中的Int表示函数参数的类型</span></span><br><span class="line">    <span class="comment">//       中括号中的String表示函数的返回值类型</span></span><br><span class="line">    <span class="keyword">val</span> f1: <span class="type">Function1</span>[<span class="type">Int</span>, <span class="type">String</span>] = test1 _</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 函数对象的参数只能有22个</span></span><br><span class="line">    <span class="comment">//TODO 为了使用方便，函数类型可以使用另外一种声明方式</span></span><br><span class="line">    <span class="comment">//这里的函数类型为：Int(参数列表的参数类型) =&gt; String(返回值类型)</span></span><br><span class="line">    <span class="keyword">val</span> f2: <span class="type">Int</span> =&gt; <span class="type">String</span> = test1 _</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test3</span></span>(name: <span class="type">String</span>, age: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> f3: (<span class="type">String</span>, <span class="type">Int</span>) =&gt; <span class="type">Unit</span> = test3 _</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">new_scala_Function_Hell_04</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sum</span></span>(x: <span class="type">Int</span>, y: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      <span class="keyword">return</span> x + y</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">diff</span></span>(x: <span class="type">Int</span>, y: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">      <span class="keyword">return</span> x - y</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//这里面我们只知道函数f的参数列表和返回值类型，具体的函数f内部的执行逻辑不知道（黑箱）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>(f : (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> result = f(<span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">      println(result)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//将函数对象作为参数使用，就类似于将逻辑进行传递，意味着逻辑可以不用写死</span></span><br><span class="line">    test(sum) <span class="comment">//30</span></span><br><span class="line">    test(diff)  <span class="comment">//-10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 下划线的省略</span></span><br><span class="line">    <span class="comment">//将函数名称直接作为参数传递给另一个函数，此时，不需要使用下划线</span></span><br><span class="line">    <span class="comment">//使用下划线的目的是不让函数执行，而是将它作为对象使用，那么如果能明确知道函数不执行，那么下划线可以省略</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 函数的名称真的那么重要吗？</span></span><br><span class="line">    <span class="comment">//如果将函数对象作为参数使用时，那么参数的名称很重要，因为调用时使用的就是参数名称</span></span><br><span class="line">    <span class="comment">//传递的函数名称本身不重要</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）函数可以作为函数返回值返回</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">new_scala_Function_Hell_06</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    TODO java:</span></span><br><span class="line"><span class="comment">    public User test()&#123;</span></span><br><span class="line"><span class="comment">       User user = new User();</span></span><br><span class="line"><span class="comment">       return user;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">//TODO scala也可以将函数对象作为返回结果返回</span></span><br><span class="line">    <span class="comment">//函数的返回子类型一般情况下是不声明的，使用自动推断</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">outer</span></span>() = &#123;</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">inner</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="string">&quot;inner...&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      inner _</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//此时，f就是一个函数对象,有函数对象：() =&gt; Unit</span></span><br><span class="line">    <span class="keyword">val</span> f = outer()</span><br><span class="line">    <span class="comment">//执行函数对象</span></span><br><span class="line">    f()  <span class="comment">//inner...</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">new_scala_Function_Hell_07</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">outer</span></span>() = &#123;</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">inner</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">        println(<span class="string">&quot;inner...&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      inner _</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    val f = outer()</span></span><br><span class="line"><span class="comment">//    f()</span></span><br><span class="line"></span><br><span class="line">    outer()()  <span class="comment">//inner...</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Outer</span></span>(x: <span class="type">Int</span>) = &#123;</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">Mid</span></span>(f: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span>) = &#123;</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">Inner</span></span>(y: <span class="type">Int</span>) = &#123;</span><br><span class="line">          f(x, y)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">Inner</span> _</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="type">Mid</span> _</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    val mid = Outer(10)</span></span><br><span class="line"><span class="comment">//    val inner = mid(_ + _)</span></span><br><span class="line"><span class="comment">//    val result = inner(20)</span></span><br><span class="line"><span class="comment">//    println(result)  //30</span></span><br><span class="line"></span><br><span class="line">    println(<span class="type">Outer</span>(<span class="number">10</span>)(_ + _)(<span class="number">20</span>))  <span class="comment">//30</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-2-匿名函数"><a href="#5-2-2-匿名函数" class="headerlink" title="5.2.2 匿名函数"></a>5.2.2 匿名函数</h3><p>没有名字的函数就是匿名函数。</p>
<p>(x:Int)&#x3D;&gt;{函数体}</p>
<p>x：表示输入参数类型；Int：表示输入参数类型；函数体：表示具体代码逻辑</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">new_scala_Function_Hell_05</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//如果函数名称不重要，那么在传参时，就可以省略函数名称</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span></span>(f: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span> ): <span class="type">Unit</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> result = f(<span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">      println(result)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    def sum(x: Int, y: Int): Int = &#123;</span></span><br><span class="line"><span class="comment">//      x + y</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    test(sum)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//如果函数没有名称和def，就叫做匿名函数，一般就是作为参数使用</span></span><br><span class="line">    test((x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; &#123;x + y&#125;)  <span class="comment">//30</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO 匿名函数作为参数使用时，可以采用至简原则</span></span><br><span class="line">    <span class="comment">//1.匿名函数的逻辑代码只有一行，那么大括号可以省略</span></span><br><span class="line">    test((x: <span class="type">Int</span>, y: <span class="type">Int</span>) =&gt; x + y)  <span class="comment">//30</span></span><br><span class="line">    <span class="comment">//2.匿名函数的参数类型如果可以推断出来，那么参数类型可以省略</span></span><br><span class="line">    test((x, y) =&gt; x + y)  <span class="comment">//30</span></span><br><span class="line">    <span class="comment">//3.匿名函数中如果参数列表的个数只有一个，那么小括号可以省略</span></span><br><span class="line">    <span class="comment">//4.匿名函数中如果参数按照顺序只执行一次的场合，那么可以使用下划线代替参数，省略参数列表和箭头</span></span><br><span class="line">    test(_ + _)  <span class="comment">//30</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//实现计算器的功能</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">new_scala_Function_Hell_05_test</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calc</span></span>(x: <span class="type">Int</span>, f: (<span class="type">Int</span>, <span class="type">Int</span>) =&gt; <span class="type">Int</span>, y: <span class="type">Int</span> ): <span class="type">Int</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> i = f(x, y)</span><br><span class="line">      i</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    calc(5, (x, y) =&gt; &#123;x + y&#125;, 3)</span></span><br><span class="line">    <span class="keyword">val</span> result = calc(<span class="number">5</span>, _ + _, <span class="number">3</span>)</span><br><span class="line">    println(result)  <span class="comment">//8</span></span><br><span class="line">    <span class="keyword">val</span> result1 = calc(<span class="number">5</span>, _ - _, <span class="number">3</span>)</span><br><span class="line">    println(result1)  <span class="comment">//2</span></span><br><span class="line">    <span class="keyword">val</span> result2 = calc(<span class="number">5</span>, _ * _, <span class="number">3</span>)</span><br><span class="line">    println(result2)  <span class="comment">//15</span></span><br><span class="line">    <span class="keyword">val</span> result3 = calc(<span class="number">5</span>, _ / _, <span class="number">3</span>)</span><br><span class="line">    println(result3)  <span class="comment">//1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>扩展练习：</p>
<p>练习 1：定义一个匿名函数，并将它作为值赋给变量 fun。函数有三个参数，类型分别为 Int，String，Char，返回值类型为 Boolean。</p>
<p>要求调用函数 fun(0, “”, ‘0’)得到返回值为 false，其它情况均返回 true。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HigtFunction_test</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> fun: (<span class="type">Int</span>, <span class="type">String</span>, <span class="type">Char</span>) =&gt; <span class="type">Boolean</span> = (i: <span class="type">Int</span>, s: <span class="type">String</span>, c: <span class="type">Char</span>) =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (i == <span class="number">0</span> &amp;&amp; s == <span class="string">&quot;&quot;</span> &amp;&amp; c == &#x27;<span class="number">0</span>&#x27;) <span class="literal">false</span> <span class="keyword">else</span> <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    println(fun(<span class="number">0</span>, <span class="string">&quot;&quot;</span>, &#x27;<span class="number">0</span>&#x27;))  <span class="comment">//false</span></span><br><span class="line">    println(fun(<span class="number">2</span>, <span class="string">&quot;dd&quot;</span>, &#x27;j&#x27;))  <span class="comment">//true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>练习 2： 定义一个函数 func，它接收一个 Int 类型的参数，返回一个函数（记作 f1）。它返回的函数 f1，接收一个 String 类型的参数，同样返回一个函数（记作 f2）。函数 f2 接收一个 Char 类型的参数，返回一个 Boolean 的值。</p>
<p>要求调用函数 func(0) (“”) (‘0’)得到返回值为 false，其它情况均返回 true。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span></span>(x: <span class="type">Int</span>) = &#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">f1</span></span>(y: <span class="type">String</span>) = &#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f2</span></span>(z: <span class="type">Char</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">      <span class="keyword">if</span> (x == <span class="number">0</span> &amp;&amp; y == <span class="string">&quot;&quot;</span> &amp;&amp; z == &#x27;<span class="number">0</span>&#x27;) <span class="literal">false</span> <span class="keyword">else</span> <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    f2 _</span><br><span class="line">  &#125;</span><br><span class="line">  f1 _</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">println(func(<span class="number">0</span>)(<span class="string">&quot;&quot;</span>)(&#x27;<span class="number">0</span>&#x27;)) <span class="comment">//false</span></span><br><span class="line">println(func(<span class="number">2</span>)(<span class="string">&quot;gg&quot;</span>)(&#x27;i&#x27;))  <span class="comment">//true</span></span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//函数还可以简化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span></span>(x: <span class="type">Int</span>)</span><br></pre></td></tr></table></figure>


      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">Java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/10/11/scala%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Hive框架学习笔记" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Hive框架学习笔记</a>
    </h1>
  

        
        <a href="/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2023-10-07T05:50:56.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-10-07</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Hive入门"><a href="#第一章-Hive入门" class="headerlink" title="第一章 Hive入门"></a>第一章 Hive入门</h1><h2 id="1-1-什么是Hive"><a href="#1-1-什么是Hive" class="headerlink" title="1.1 什么是Hive"></a>1.1 什么是Hive</h2><p>基于Hadoop的一个<strong>数据仓库工具</strong>，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</p>
<p>Hive是一个Hadoop客户端，用于<strong>将HQL（Hive SQL）转化成MapReduce程序</strong>。</p>
<p>（1）Hive中每张表的数据存储在HDFS</p>
<p>（2）Hive分析数据底层的实现是MapReduce（也可配置为Spark或者Tez） </p>
<p>（3）执行程序运行在Yarn上</p>
<p>为什么使用Hive？</p>
<p>MapReduce如果要实现复杂查询，逻辑开发难度比较大，使用Hive可以提高快速开发的能力，避免书写MapReduce，减少学习成本</p>
<h2 id="1-2-Hive架构原理"><a href="#1-2-Hive架构原理" class="headerlink" title="1.2 Hive架构原理"></a>1.2 Hive架构原理</h2><p>一句话说清hive的架构原理：<strong>Hive架构由用户接口、元数据存储（Metastore）和驱动（解释器、编译器、优化器、执行器等）组成。</strong>用户通过接口创建HQL语句，由Metastore记录对应的元数据，通过一系列驱动进行HQL语句的分析优化和查询计划的生成（或者说翻译成MapReduce程序），生成的查询计划存储在HDFS中，随后在MapReduce调用执行，最后将计算结果返回给用户。</p>
<p><img src="111111%E5%9B%BE%E7%89%871.png" alt="图片1"></p>
<p>（1）用户接口：Client</p>
<p>CLI（command-line interface）、JDBC&#x2F;ODBC。</p>
<p>①JDBC的移植性比ODBC好；（通常情况下，安装完ODBC驱动程序之后，还需要经过确定的配置才能够应用。而不相同的配置在不相同数据库服务器之间不能够通用。所以，安装一次就需要再配置一次。<strong>JDBC只需要选取适当的JDBC数据库驱动程序，就不需要额外的配置。在安装过程中，JDBC数据库驱动程序会自己完成有关的配置</strong>。）</p>
<p>②两者使用的语言不同，JDBC在Java编程时使用，ODBC一般在C&#x2F;C++编程时使用</p>
<p>（2）元数据：<em><strong>Metastore</strong></em></p>
<p>元数据包括：数据库（默认是default）、表名、表的拥有者、列&#x2F;分区字段、表的类型（是否是外部表）、表的数据所在目录等。</p>
<p><strong>Hive的元数据主要分为5大部分</strong>：<strong>数据库相关的元数据</strong>、<strong>表相关的元数据</strong>、<strong>分区相关的元数据</strong>、<strong>文件存储的元数据</strong>、<strong>其他</strong></p>
<p>默认存储在自带的derby数据库中，由于derby数据库只支持单客户端访问，生产环境中为了多人开发，推荐使用<strong>MySQL</strong>存储Metastore。</p>
<p>（3）<strong>驱动器：Driver</strong></p>
<p>①解析器（SQLParser）：将SQL字符串转换成抽象语法树（AST）</p>
<p>②语义分析（Semantic Analyzer）：将AST进一步划分为QeuryBlock</p>
<p>③逻辑计划生成器（Logical Plan Gen）：将语法树生成逻辑计划</p>
<p>④逻辑优化器（Logical Optimizer）：对逻辑计划进行优化</p>
<p>⑤物理计划生成器（Physical Plan Gen）：根据优化后的逻辑计划生成物理计划</p>
<p>⑥物理优化器（Physical Optimizer）：对物理计划进行优化</p>
<p>⑦执行器（Execution）：执行该计划，得到查询结果并返回给客户端</p>
<p><img src="%E5%9B%BE%E7%89%872.png" alt="图片2"></p>
<p><img src="%E5%9B%BE%E7%89%873.png" alt="图片3"></p>
<p>（4）Hadoop</p>
<p>使用HDFS进行存储，可以选择MapReduce&#x2F;Tez&#x2F;Spark进行计算。</p>
<h2 id="1-3-Hive-SQL编译成MapReduce的过程"><a href="#1-3-Hive-SQL编译成MapReduce的过程" class="headerlink" title="1.3 Hive SQL编译成MapReduce的过程"></a>1.3 Hive SQL编译成MapReduce的过程</h2><p>（1）词法、语法解析：根据 Antlr 定义的 sql 语法规则，将相关 sql 进行词法、语法解析，转化为抽象语法树 AST Tree</p>
<p>（2）语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock（包括输入源、计算过程、输出）</p>
<p>（3）生成逻辑执行阶段：遍历 QueryBlock，翻译为执行操作树 OperatorTree（TableScanOperator、SelectOperator、FilterOperator、JoinOperator、GroupByOperator、ReduceSinkOperator）</p>
<p>（4）优化逻辑执行计划：谓词下推、多路join等，达到减少MapReduce Job，减少数据传输及shuffle数据量</p>
<p>（5）生成物理执行过程：遍历 OperatorTree，翻译为 MapReduce 任务</p>
<p>（6）优化物理执行过程：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划</p>
<h1 id="第二章-Hive安装"><a href="#第二章-Hive安装" class="headerlink" title="第二章 Hive安装"></a>第二章 Hive安装</h1><h2 id="2-1-Hive安装部署"><a href="#2-1-Hive安装部署" class="headerlink" title="2.1 Hive安装部署"></a>2.1 Hive安装部署</h2><h3 id="2-1-1-安装Hive"><a href="#2-1-1-安装Hive" class="headerlink" title="2.1.1 安装Hive"></a>2.1.1 安装Hive</h3><p>（0）首先确保hadoop集群启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">3026 DataNode</span><br><span class="line">3397 NodeManager</span><br><span class="line">3659 Jps</span><br><span class="line">2876 NameNode</span><br><span class="line">3583 JobHistoryServer</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">3062 NodeManager</span><br><span class="line">2681 DataNode</span><br><span class="line">2906 ResourceManager</span><br><span class="line">3435 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">2914 NodeManager</span><br><span class="line">2820 SecondaryNameNode</span><br><span class="line">2699 DataNode</span><br><span class="line">3055 Jps</span><br></pre></td></tr></table></figure>

<p>（1）把apache-hive-3.1.3-bin.tar.gz上传到Linux的&#x2F;opt&#x2F;software目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 868360</span><br><span class="line">-rw-r--r--. 1 root root 356079876 12月  2 2022 apache-hive-3.1.3-bin.tar.gz  # 在这里</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br></pre></td></tr></table></figure>

<p>（2）解压apache-hive-3.1.3-bin.tar.gz到&#x2F;opt&#x2F;module&#x2F;目录下面</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf apache-hive-3.1.3-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# cd /opt/module/</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x. 10 root root  184 10月  7 14:51 apache-hive-3.1.3-bin</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>（3）修改apache-hive-3.1.3-bin的名称为hive</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mv apache-hive-3.1.3-bin/ hive</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 10 root root  184 10月  7 14:51 hive   # 在这里</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>（4）修改&#x2F;etc&#x2F;profile.d&#x2F;my_env.sh，添加环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 etc]# vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HIVE_HOME</span></span><br><span class="line">export HIVE_HOME=/opt/module/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">source</span>一下</span></span><br><span class="line">[root@hadoop102 etc]# source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>（5）初始化元数据库（默认是derby数据库）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# bin/schematool -dbType derby -initSchema</span><br></pre></td></tr></table></figure>

<p>至此，Hive的最小化部署已经完成。</p>
<h3 id="2-1-2-启动并使用Hive"><a href="#2-1-2-启动并使用Hive" class="headerlink" title="2.1.2 启动并使用Hive"></a>2.1.2 启动并使用Hive</h3><p>（1）启动Hive</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# bin/hive</span><br></pre></td></tr></table></figure>

<p>（2）使用Hive</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">default</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.416</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<p>如果我们不去声明使用哪个数据库，我们默认使用的就是default数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.03</span> seconds</span><br><span class="line"></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> stu(id <span class="type">int</span>, name string);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.397</span> seconds</span><br></pre></td></tr></table></figure>

<p>建表语句执行的同时，可以在HDFS的Web端看到相应的路径：也就是说Hive中的表在Hadoop中是目录；Hive中的数据在Hadoop中是文件</p>
<p><img src="Snipaste_2023-10-07_15-12-21.png" alt="Snipaste_2023-10-07_15-12-21"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> stu <span class="keyword">values</span>(<span class="number">1</span>,&quot;ss&quot;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-07_15-15-44.png" alt="Snipaste_2023-10-07_15-15-44" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br><span class="line">OK</span><br><span class="line"><span class="number">1</span>	ss</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.114</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<p>（3）derby的问题：原因在于Hive默认使用的元数据库为<em><strong>derby。</strong></em>derby数据库的特点是同一时间只允许一个客户端访问。如果多个Hive客户端同时访问，就会报错。由于在企业开发中，都是多人协作开发，需要多客户端同时访问Hive，怎么解决呢？我们可以将Hive的元数据改为用MySQL存储，MySQL支持多客户端同时访问。</p>
<p><img src="%E5%9B%BE%E7%89%874.png" alt="图片4"></p>
<p>（4）退出hive客户端，在Hive的安装目录下及那个derby.log和metastore_db删除。顺便将HDFS上目录删除</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">hive&gt; </span><span class="language-bash">quit;</span></span><br><span class="line">[root@hadoop102 hive]# rm -rf derby.log metastore_db</span><br></pre></td></tr></table></figure>

<h2 id="2-2-MySQL安装"><a href="#2-2-MySQL安装" class="headerlink" title="2.2 MySQL安装"></a>2.2 MySQL安装</h2><h3 id="2-2-1-安装MySQL"><a href="#2-2-1-安装MySQL" class="headerlink" title="2.2.1 安装MySQL"></a>2.2.1 安装MySQL</h3><p>（1）上传MySQL安装包及MySQL驱动jar包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 1464596</span><br><span class="line">-rw-r--r--. 1 root root 356079876 12月  2 2022 apache-hive-3.1.3-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 609556480 12月  2 2022 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar  # 在这里</span><br><span class="line">-rw-r--r--. 1 root root    985600 12月  2 2022 mysql-connector-java-5.1.37.jar   # 在这里</span><br></pre></td></tr></table></figure>

<p>（2）解压MySQL安装包到&#x2F;opt&#x2F;software&#x2F;mysql_lib</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# mkdir mysql_lib</span><br><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 1464596</span><br><span class="line">-rw-r--r--. 1 root root 356079876 12月  2 2022 apache-hive-3.1.3-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 609556480 12月  2 2022 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line">-rw-r--r--. 1 root root    985600 12月  2 2022 mysql-connector-java-5.1.37.jar</span><br><span class="line">drwxr-xr-x. 2 root root         6 10月  7 15:30 mysql_lib</span><br><span class="line">[root@hadoop102 software]# tar -xf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar -C mysql_lib/</span><br><span class="line">[root@hadoop102 software]# cd mysql_lib/</span><br><span class="line">[root@hadoop102 mysql_lib]# ll</span><br><span class="line">总用量 595272</span><br><span class="line">-rw-r--r--. 1 7155 31415  45109364 9月  30 2019 mysql-community-client-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415    318768 9月  30 2019 mysql-community-common-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415   7037096 9月  30 2019 mysql-community-devel-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415  49329100 9月  30 2019 mysql-community-embedded-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415  23354908 9月  30 2019 mysql-community-embedded-compat-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415 136837816 9月  30 2019 mysql-community-embedded-devel-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415   4374364 9月  30 2019 mysql-community-libs-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415   1353312 9月  30 2019 mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415 208694824 9月  30 2019 mysql-community-server-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415 133129992 9月  30 2019 mysql-community-test-5.7.28-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p>（3）卸载系统自带的mariadb</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# rpm -qa | grep mariadb | xargs sudo rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<p>（4）安装MySQL依赖</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-common-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-common-5.7.28-1.e################################# [100%]</span><br><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-libs-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-libs-5.7.28-1.el7################################# [100%]</span><br><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-libs-compat-5.7.2################################# [100%]</span><br></pre></td></tr></table></figure>

<p>（5）安装mysql-client</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-client-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-client-5.7.28-1.e################################# [100%]</span><br></pre></td></tr></table></figure>

<p>（6）安装mysql-server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-server-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-server-5.7.28-1.e################################# [100%]</span><br></pre></td></tr></table></figure>

<p>（7）启动MySQL</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# systemctl start mysqld</span><br><span class="line">[root@hadoop102 mysql_lib]# systemctl status mysqld</span><br><span class="line">● mysqld.service - MySQL Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 六 2023-10-07 15:42:21 CST; 42s ago</span><br><span class="line">     Docs: man:mysqld(8)</span><br><span class="line">           http://dev.mysql.com/doc/refman/en/using-systemd.html</span><br><span class="line">  Process: 4915 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 4861 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 4918 (mysqld)</span><br><span class="line">    Tasks: 27</span><br><span class="line">   CGroup: /system.slice/mysqld.service</span><br><span class="line">           └─4918 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line"></span><br><span class="line">10月 07 15:42:17 hadoop102 systemd[1]: Starting MySQL Server...</span><br><span class="line">10月 07 15:42:21 hadoop102 systemd[1]: Started MySQL Server.</span><br></pre></td></tr></table></figure>

<p>（8）查看MySQL密码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# cat /var/log/mysqld.log | grep password</span><br><span class="line">2023-10-07T07:42:18.978817Z 1 [Note] A temporary password is generated for root@localhost: yy54Rff=kwJI</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-配置MySQL"><a href="#2-2-2-配置MySQL" class="headerlink" title="2.2.2 配置MySQL"></a>2.2.2 配置MySQL</h3><p>配置主要是root用户+密码，在任何主机上都能登录MySQL数据库</p>
<p>（1）用刚刚查到的密码进入MySQL</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# mysql -uroot -p&#x27;yy54Rff=kwJI&#x27;</span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.7.28</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span></span><br></pre></td></tr></table></figure>

<p>（2）设置自己的密码（wy<strong><strong>199</strong></strong>8）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 首先更改MySQL密码策略</span><br><span class="line">mysql&gt; set global validate_password_policy=0;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global validate_password_length=4;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"># 设置密码</span><br><span class="line">mysql&gt; set password=password(&quot;wy****199****8&quot;);</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>（3）修改user表，把Host表内容修改为%</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update user set host=&quot;%&quot; where user=&quot;root&quot;;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; select user, host from user;</span><br><span class="line">+---------------+-----------+</span><br><span class="line">| user          | host      |</span><br><span class="line">+---------------+-----------+</span><br><span class="line">| root          | %         |</span><br><span class="line">| mysql.session | localhost |</span><br><span class="line">| mysql.sys     | localhost |</span><br><span class="line">+---------------+-----------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>（4）刷新并退出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; quit;</span><br><span class="line">Bye</span><br></pre></td></tr></table></figure>

<h2 id="2-3-配置Hive元数据存储到MySQL"><a href="#2-3-配置Hive元数据存储到MySQL" class="headerlink" title="2.3 配置Hive元数据存储到MySQL"></a>2.3 配置Hive元数据存储到MySQL</h2><h3 id="2-3-1-配置元数据到MySQL"><a href="#2-3-1-配置元数据到MySQL" class="headerlink" title="2.3.1 配置元数据到MySQL"></a>2.3.1 配置元数据到MySQL</h3><p>（1）新建Hive元数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 登录MySQL</span><br><span class="line"># 创建Hive元数据库</span><br><span class="line">mysql&gt; create database metastore;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; quit;</span><br><span class="line">Bye</span><br></pre></td></tr></table></figure>

<p>（2）将MySQL的JDBC驱动拷贝到Hive的lib目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# cp mysql-connector-java-5.1.37.jar /opt/module/hive/lib/</span><br></pre></td></tr></table></figure>

<p>（3）在$HIVE_HOME&#x2F;conf目录下新建hive-site.xml文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# cd /opt/module/hive/</span><br><span class="line">[root@hadoop102 hive]# ll</span><br><span class="line">总用量 56</span><br><span class="line">drwxr-xr-x. 3 root root   157 10月  7 14:51 bin</span><br><span class="line">drwxr-xr-x. 2 root root  4096 10月  7 14:51 binary-package-licenses</span><br><span class="line">drwxr-xr-x. 2 root root  4096 10月  7 14:51 conf</span><br><span class="line">drwxr-xr-x. 4 root root    34 10月  7 14:51 examples</span><br><span class="line">drwxr-xr-x. 7 root root    68 10月  7 14:51 hcatalog</span><br><span class="line">drwxr-xr-x. 2 root root    44 10月  7 14:51 jdbc</span><br><span class="line">drwxr-xr-x. 4 root root 12288 10月  7 16:06 lib</span><br><span class="line">-rw-rw-r--. 1 root root 20798 8月  11 2022 LICENSE</span><br><span class="line">-rw-rw-r--. 1 root root   230 8月  11 2022 NOTICE</span><br><span class="line">-rw-rw-r--. 1 root root   540 8月  11 2022 RELEASE_NOTES.txt</span><br><span class="line">drwxr-xr-x. 4 root root    35 10月  7 14:51 scripts</span><br><span class="line">[root@hadoop102 hive]# cd conf/</span><br><span class="line">[root@hadoop102 conf]# vim hive-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的URL --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop102:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的Driver--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">	<span class="comment">&lt;!-- jdbc连接的username--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的password --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>wy****19*****8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Hive默认在HDFS：的工作目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（4）初始化Hive元数据库（修改采用MySQL存储元数据）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# bin/schematool -dbType mysql -initSchema -verbose</span><br></pre></td></tr></table></figure>

<h3 id="2-3-2-验证元数据是否配置成功"><a href="#2-3-2-验证元数据是否配置成功" class="headerlink" title="2.3.2 验证元数据是否配置成功"></a>2.3.2 验证元数据是否配置成功</h3><p>（1）再次启动Hive</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# bin/hive</span><br></pre></td></tr></table></figure>

<p>（2）使用Hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">hive&gt; create table stu(id int, name string);</span><br><span class="line">hive&gt; insert into stu values(1,&quot;ss&quot;);</span><br><span class="line">hive&gt; select * from stu;</span><br></pre></td></tr></table></figure>

<p>一切正常，证明配置成功！！！</p>
<h3 id="2-3-3-查看MySQL中的元数据（了解即可）"><a href="#2-3-3-查看MySQL中的元数据（了解即可）" class="headerlink" title="2.3.3 查看MySQL中的元数据（了解即可）"></a>2.3.3 查看MySQL中的元数据（了解即可）</h3><p>查看元数据库metastore存储的库信息</p>
<p><img src="Snipaste_2023-10-07_18-10-58.png" alt="Snipaste_2023-10-07_18-10-58"></p>
<p>查看元数据库metastore存储的表信息</p>
<p><img src="Snipaste_2023-10-07_18-12-02.png" alt="Snipaste_2023-10-07_18-12-02"></p>
<p>查看元数据库metastore存储的列相关信息</p>
<p><img src="Snipaste_2023-10-07_18-13-41.png" alt="Snipaste_2023-10-07_18-13-41"></p>
<h2 id="2-4-Hive服务部署"><a href="#2-4-Hive服务部署" class="headerlink" title="2.4 Hive服务部署"></a>2.4 Hive服务部署</h2><h3 id="2-4-1-hiveserver2服务"><a href="#2-4-1-hiveserver2服务" class="headerlink" title="2.4.1 hiveserver2服务"></a>2.4.1 hiveserver2服务</h3><p>Hive的hiveserver2服务的作用是提供jdbc&#x2F;odbc接口，为用户提供远程访问Hive数据的功能，例如用户期望在个人电脑中访问远程服务中的Hive数据，就需要用到Hiveserver2。</p>
<img src="Snipaste_2023-10-07_18-17-22.png" alt="Snipaste_2023-10-07_18-17-22" style="zoom:43%;">

<h4 id="（1）用户说明"><a href="#（1）用户说明" class="headerlink" title="（1）用户说明"></a>（1）用户说明</h4><p>在远程访问Hive数据时，客户端并未直接访问Hadoop集群，而是由Hivesever2代理访问。由于Hadoop集群中的数据具备访问权限控制，所以此时需考虑一个问题：那就是访问Hadoop集群的用户身份是谁？是Hiveserver2的启动用户？还是客户端的登录用户？</p>
<p>答案是都有可能，具体是谁，<strong>由Hiveserver2的hive.server2.enable.doAs参数决定</strong>，该参数的含义是是否启用Hiveserver2用户模拟的功能。若启用，则Hiveserver2会模拟成客户端的登录用户去访问Hadoop集群的数据，不启用，则Hivesever2会直接使用启动用户访问Hadoop集群数据。模拟用户的功能，默认是开启的。</p>
<p>未启用：</p>
<img src="Snipaste_2023-10-07_20-32-27.png" alt="Snipaste_2023-10-07_20-32-27" style="zoom:43%;">

<p>启用：</p>
<img src="Snipaste_2023-10-07_20-32-51.png" alt="Snipaste_2023-10-07_20-32-51" style="zoom:43%;">

<p><strong>生产环境，推荐开启用户模拟功能，因为开启后才能保证各用户之间的权限隔离。</strong></p>
<h4 id="（2）hiveserver2部署"><a href="#（2）hiveserver2部署" class="headerlink" title="（2）hiveserver2部署"></a>（2）hiveserver2部署</h4><p>①hadoop端配置</p>
<p>hivesever2的模拟用户功能，依赖于Hadoop提供的proxy user（代理用户功能），只有Hadoop中的代理用户才能模拟其他用户的身份访问Hadoop集群。因此，需要将hiveserver2的启动用户设置为Hadoop的代理用户，配置方式如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# cd /opt/module/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[root@hadoop102 hadoop]# vim core-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--配置所有节点的atguigu用户都可作为代理用户--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--配置atguigu用户能够代理的用户组为任意组--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--配置atguigu用户能够代理的用户为任意用户--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发配置文件</span></span><br><span class="line">[root@hadoop102 hadoop]# xsync core-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启集群</span></span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh stop</span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh start</span><br></pre></td></tr></table></figure>

<p>②Hive端配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# cd /opt/module/hive/conf/</span><br><span class="line">[root@hadoop102 conf]# vim hive-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的端口号 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="（3）测试"><a href="#（3）测试" class="headerlink" title="（3）测试"></a>（3）测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动hiveserver2</span></span><br><span class="line">[root@hadoop102 hive]# bin/hiveserver2 </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">企业中启动hiveserver2</span></span><br><span class="line">[root@hadoop102 hive]# nohup bin/hiveserver2 &gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line">[1] 10500</span><br><span class="line">[root@hadoop102 hive]# jps</span><br><span class="line">10016 JobHistoryServer</span><br><span class="line">10659 Jps</span><br><span class="line">10500 RunJar</span><br><span class="line">9301 NameNode</span><br><span class="line">9482 DataNode</span><br><span class="line">9819 NodeManager</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用命令行客户端beeline进行远程访问</span></span><br><span class="line">[root@hadoop102 hive]# bin/beeline</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/opt/module/hive/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Beeline version 3.1.3 by Apache Hive</span><br><span class="line"><span class="meta prompt_">beeline&gt; </span><span class="language-bash">!connect jdbc:hive2://hadoop102:10000</span></span><br><span class="line">Connecting to jdbc:hive2://hadoop102:10000</span><br><span class="line">Enter username for jdbc:hive2://hadoop102:10000: root</span><br><span class="line">Enter password for jdbc:hive2://hadoop102:10000: </span><br><span class="line">Connected to: Apache Hive (version 3.1.3)</span><br><span class="line">Driver: Hive JDBC (version 3.1.3)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">0: jdbc:hive2://hadoop102:10000&gt; show tables;</span><br><span class="line">INFO  : Compiling command(queryId=root_20231007210619_ce543413-c7bd-4d24-abb6-6351d5b5541f): show tables</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Semantic Analysis Completed (retrial = false)</span><br><span class="line">INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)</span><br><span class="line">INFO  : Completed compiling command(queryId=root_20231007210619_ce543413-c7bd-4d24-abb6-6351d5b5541f); Time taken: 0.579 seconds</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Executing command(queryId=root_20231007210619_ce543413-c7bd-4d24-abb6-6351d5b5541f): show tables</span><br><span class="line">INFO  : Starting task [Stage-0:DDL] in serial mode</span><br><span class="line">INFO  : Completed executing command(queryId=root_20231007210619_ce543413-c7bd-4d24-abb6-6351d5b5541f); Time taken: 0.024 seconds</span><br><span class="line">INFO  : OK</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">+-----------+</span><br><span class="line">| tab_name  |</span><br><span class="line">+-----------+</span><br><span class="line">| stu       |</span><br><span class="line">+-----------+</span><br><span class="line">1 row selected (0.932 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop102:10000&gt; select * from stu;</span><br><span class="line">INFO  : Compiling command(queryId=root_20231007210647_ebd8e686-1d22-4de3-a407-9f97a8451ed3): select * from stu</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Semantic Analysis Completed (retrial = false)</span><br><span class="line">INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:stu.id, type:int, comment:null), FieldSchema(name:stu.name, type:string, comment:null)], properties:null)</span><br><span class="line">INFO  : Completed compiling command(queryId=root_20231007210647_ebd8e686-1d22-4de3-a407-9f97a8451ed3); Time taken: 1.078 seconds</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Executing command(queryId=root_20231007210647_ebd8e686-1d22-4de3-a407-9f97a8451ed3): select * from stu</span><br><span class="line">INFO  : Completed executing command(queryId=root_20231007210647_ebd8e686-1d22-4de3-a407-9f97a8451ed3); Time taken: 0.0 seconds</span><br><span class="line">INFO  : OK</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">+---------+-----------+</span><br><span class="line">| stu.id  | stu.name  |</span><br><span class="line">+---------+-----------+</span><br><span class="line">| 1       | ss        |</span><br><span class="line">+---------+-----------+</span><br><span class="line">1 row selected (1.477 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop102:10000&gt; !quit</span><br><span class="line">Closing: 0: jdbc:hive2://hadoop102:10000</span><br></pre></td></tr></table></figure>

<p>使用Datagrip图形化客户端进行远程访问：</p>
<h4 id="（4）配置Datagrip连接"><a href="#（4）配置Datagrip连接" class="headerlink" title="（4）配置Datagrip连接"></a>（4）配置Datagrip连接</h4><p>①创建连接</p>
<img src="Snipaste_2023-10-07_21-10-17.png" alt="Snipaste_2023-10-07_21-10-17" style="zoom:43%;">

<p>②配置连接属性</p>
<img src="Snipaste_2023-10-07_21-13-20.png" alt="Snipaste_2023-10-07_21-13-20" style="zoom:50%;">

<p>③测试sql执行</p>
<p><img src="Snipaste_2023-10-07_21-16-48.png" alt="Snipaste_2023-10-07_21-16-48"></p>
<h3 id="2-4-2-metastore服务"><a href="#2-4-2-metastore服务" class="headerlink" title="2.4.2 metastore服务"></a>2.4.2 metastore服务</h3><p>Hive的metastore服务的作用是为Hive CLI或者Hiveserver2提供元数据访问接口。metastore有两种运行模式，分别为嵌入式模式和独立服务模式，生产环境中，推荐使用独立服务模式。</p>
<p>直接看独立服务模式：</p>
<p><strong>将metastore服务部署在hadoop102，在hadoop103上部署一个客户端</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">①首先将hadoop102的hive安装包发送到hadoop103</span></span><br><span class="line">[root@hadoop102 hive]# scp -r /opt/module/hive/ hadoop103:/opt/module/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">②查看hive确实成功转发到hadoop103</span></span><br><span class="line">[root@hadoop103 ~]# cd /opt/module/</span><br><span class="line">[root@hadoop103 module]# ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 13 atguigu atguigu 204 9月  14 22:14 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 10 root    root    184 10月  8 12:11 hive</span><br><span class="line">drwxr-xr-x.  7 atguigu atguigu 245 8月   7 17:06 jdk1.8.0_212</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">③在hadoop102上启动metastore服务</span></span><br><span class="line">[root@hadoop102 conf]# nohup hive --service metastore &amp;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">④在hadoop103配置客户端</span></span><br><span class="line">[root@hadoop103 conf]# vim hive-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Hive默认在HDFS的工作目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的端口号 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定metastore服务的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://hadoop102:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">⑤在hadoop103上访问hive</span></span><br><span class="line">[root@hadoop103 hive]# bin/hive</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">stu</span><br><span class="line">test</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.16</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br><span class="line">OK</span><br><span class="line"><span class="number">1</span>	ss</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.234</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<h3 id="2-4-3-编写Hive服务启动脚本"><a href="#2-4-3-编写Hive服务启动脚本" class="headerlink" title="2.4.3 编写Hive服务启动脚本"></a>2.4.3 编写Hive服务启动脚本</h3><p>注意：如果不编写脚本执行以下两个语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动hiveserver2</span></span><br><span class="line">[root@hadoop102 hive]# nohup hive --service hiveserver2 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动metastore服务</span></span><br><span class="line">[root@hadoop102 conf]# nohup hive --service metastore 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看进程，可以看到有两个RunJar，证明这两个服务在后台启动成功</span></span><br><span class="line">[root@hadoop102 hive]# jps</span><br><span class="line">3777 JobHistoryServer</span><br><span class="line">3074 NameNode</span><br><span class="line">4101 RunJar</span><br><span class="line">4854 RunJar</span><br><span class="line">3255 DataNode</span><br><span class="line">3591 NodeManager</span><br><span class="line">5004 Jps</span><br></pre></td></tr></table></figure>

<p>下面来编写Hive服务的启停脚本，实现服务的启动和关闭（类似于myhadoop.sh）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# cd /opt/module/hive/bin</span><br><span class="line">[root@hadoop102 bin]# vim hiveservices.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">HIVE_LOG_DIR=$HIVE_HOME/logs</span><br><span class="line">if [ ! -d $HIVE_LOG_DIR ]</span><br><span class="line">then</span><br><span class="line">	mkdir -p $HIVE_LOG_DIR</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">检查进程是否运行正常，参数1为进程名，参数2为进程端口</span></span><br><span class="line">function check_process()</span><br><span class="line">&#123;</span><br><span class="line">    pid=$(ps -ef 2&gt;/dev/null | grep -v grep | grep -i $1 | awk &#x27;&#123;print $2&#125;&#x27;)</span><br><span class="line">    ppid=$(netstat -nltp 2&gt;/dev/null | grep $2 | awk &#x27;&#123;print $7&#125;&#x27; | cut -d &#x27;/&#x27; -f 1)</span><br><span class="line">    echo $pid</span><br><span class="line">    [[ &quot;$pid&quot; =~ &quot;$ppid&quot; ]] &amp;&amp; [ &quot;$ppid&quot; ] &amp;&amp; return 0 || return 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function hive_start()</span><br><span class="line">&#123;</span><br><span class="line">    metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">    cmd=&quot;nohup hive --service metastore &gt;$HIVE_LOG_DIR/metastore.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    [ -z &quot;$metapid&quot; ] &amp;&amp; eval $cmd || echo &quot;Metastroe服务已启动&quot;</span><br><span class="line">    server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">    cmd=&quot;nohup hive --service hiveserver2 &gt;$HIVE_LOG_DIR/hiveServer2.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    [ -z &quot;$server2pid&quot; ] &amp;&amp; eval $cmd || echo &quot;HiveServer2服务已启动&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function hive_stop()</span><br><span class="line">&#123;</span><br><span class="line">metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">    [ &quot;$metapid&quot; ] &amp;&amp; kill $metapid || echo &quot;Metastore服务未启动&quot;</span><br><span class="line">    server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">    [ &quot;$server2pid&quot; ] &amp;&amp; kill $server2pid || echo &quot;HiveServer2服务未启动&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">    hive_start</span><br><span class="line">    ;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">    hive_stop</span><br><span class="line">    ;;</span><br><span class="line">&quot;restart&quot;)</span><br><span class="line">    hive_stop</span><br><span class="line">    sleep 2</span><br><span class="line">    hive_start</span><br><span class="line">    ;;</span><br><span class="line">&quot;status&quot;)</span><br><span class="line">    check_process HiveMetastore 9083 &gt;/dev/null &amp;&amp; echo &quot;Metastore服务运行正常&quot; || echo &quot;Metastore服务运行异常&quot;</span><br><span class="line">    check_process HiveServer2 10000 &gt;/dev/null &amp;&amp; echo &quot;HiveServer2服务运行正常&quot; || echo &quot;HiveServer2服务运行异常&quot;</span><br><span class="line">    ;;</span><br><span class="line">*)</span><br><span class="line">    echo Invalid Args!</span><br><span class="line">    echo &#x27;Usage: &#x27;$(basename $0)&#x27; start|stop|restart|status&#x27;</span><br><span class="line">    ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加执行权限</span></span><br><span class="line">[root@hadoop102 bin]# chmod +x hiveservices.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试关闭Hive后台服务</span></span><br><span class="line">[root@hadoop102 bin]# hiveservices.sh stop</span><br><span class="line">[root@hadoop102 bin]# jps</span><br><span class="line">3777 JobHistoryServer</span><br><span class="line">3074 NameNode</span><br><span class="line">3255 DataNode</span><br><span class="line">3591 NodeManager</span><br><span class="line">5211 Jps</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试启动Hive后台服务</span></span><br><span class="line">[root@hadoop102 bin]# hiveservices.sh start</span><br><span class="line">[root@hadoop102 bin]# jps</span><br><span class="line">3777 JobHistoryServer</span><br><span class="line">3074 NameNode</span><br><span class="line">3255 DataNode</span><br><span class="line">3591 NodeManager</span><br><span class="line">5512 Jps</span><br><span class="line">5274 RunJar</span><br><span class="line">5243 RunJar</span><br></pre></td></tr></table></figure>

<h2 id="2-5-Hive使用技巧"><a href="#2-5-Hive使用技巧" class="headerlink" title="2.5 Hive使用技巧"></a>2.5 Hive使用技巧</h2><h3 id="2-5-1-Hive常用交互命令"><a href="#2-5-1-Hive常用交互命令" class="headerlink" title="2.5.1 Hive常用交互命令"></a>2.5.1 Hive常用交互命令</h3><p>（1）“-e”不进入hive的交互窗口执行hql语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# hive -e &quot;insert into stu values(1,&#x27;aa&#x27;)&quot;</span><br></pre></td></tr></table></figure>

<p>（2）“-f”执行脚本中的hql语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">①/opt/module/hive/下创建datas目录并在datas目录下创建hivef.sql文件</span></span><br><span class="line">[root@hadoop102 bin]# cd /opt/module/hive/</span><br><span class="line">[root@hadoop102 hive]# mkdir datas</span><br><span class="line">[root@hadoop102 hive]# vim hivef.sql</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">②执行文件中的hql语句</span></span><br><span class="line">[root@hadoop102 hive]# hive -f hivef.sql</span><br><span class="line">...</span><br><span class="line">1	aa</span><br><span class="line">1	ss</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">③执行文件中的hql语句并将结果写入文件中</span></span><br><span class="line">[root@hadoop102 hive]# hive -f hivef.sql &gt; /opt/module/hive/datas/hive_result.txt</span><br><span class="line">[root@hadoop102 hive]# cd datas/</span><br><span class="line">[root@hadoop102 datas]# vim hive_result.txt</span><br><span class="line">1       aa</span><br><span class="line">1       ss</span><br></pre></td></tr></table></figure>

<h3 id="2-5-2-Hive参数配置方式"><a href="#2-5-2-Hive参数配置方式" class="headerlink" title="2.5.2 Hive参数配置方式"></a>2.5.2 Hive参数配置方式</h3><p>（1）查看当前所有的配置信息</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span><span class="keyword">set</span>;</span><br></pre></td></tr></table></figure>

<p>（2）参数的配置三种方式</p>
<p>①配置文件方式</p>
<p>默认配置文件：hive-default.xml</p>
<p>用户自定义配置文件：hive-site.xml</p>
<p>注意：<strong>用户自定义配置会覆盖默认配置</strong>。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，<strong>Hive的配置会覆盖Hadoop的配置</strong>。配置文件的设定对本机启动的所有Hive进程都有效。</p>
<p>②命令行参数方式</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动Hive时，可以在命令行添加-hiveconf param=value来设定参数。仅对本次Hive启动有效，例如：</span></span><br><span class="line">[root@hadoop102 datas]# bin/hive -hiveconf mapreduce.job.reduces=10;</span><br></pre></td></tr></table></figure>

<p>③参数声明方式</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在Hql中使用<span class="keyword">set</span>关键字设定参数，仅对本次Hive启动有效</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">10</span>;</span><br><span class="line"># 查看当前参数值</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces;</span><br><span class="line">mapreduce.job.reduces<span class="operator">=</span><span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>上述三种设定方式的优先级依次递增。即<strong>配置文件&lt; 命令行参数</strong>&lt; 参数声明。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</p>
<h3 id="2-5-3-Hive常见属性配置"><a href="#2-5-3-Hive常见属性配置" class="headerlink" title="2.5.3 Hive常见属性配置"></a>2.5.3 Hive常见属性配置</h3><p>（1）Hive客户端显示当前库和表头</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在hive-site.xml中加入如下两个配置:</span></span><br><span class="line">[root@hadoop102 conf]# vim hive-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether to print the names of the columns in query output.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether to include the current database in the Hive prompt.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>此时再打开hive客户端：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br><span class="line">OK</span><br><span class="line">stu.id	stu.name</span><br><span class="line"><span class="number">1</span>	aa</span><br><span class="line"><span class="number">1</span>	ss</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.121</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<p>（2）hive运行日志路径配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">首先修改/conf/hive-log4j2.properties.template文件名称为hive-log4j2.properties</span></span><br><span class="line">[root@hadoop102 conf]# mv hive-log4j2.properties.template hive-log4j2.properties</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hive-log4j2.properties文件中修改<span class="built_in">log</span>存放位置</span></span><br><span class="line">[root@hadoop102 conf]# vim hive-log4j2.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 修改配置如下：</span><br><span class="line">property.hive.log.dir=/opt/module/hive/logs</span><br></pre></td></tr></table></figure>

<p>（3）Hive的JVM堆内存设置</p>
<p>新版本的Hive启动的时候，默认申请的JVM堆内存大小为256M，JVM堆内存申请的太小，导致后期开启本地模式，执行复杂的SQL时经常会报错：java.lang.OutOfMemoryError: Java heap space，因此最好提前调整一下HADOOP_HEAPSIZE这个参数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将/conf下的hive-env.sh.template为hive-env.sh</span></span><br><span class="line">[root@hadoop102 conf]# mv hive-env.sh.template hive-env.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将hive-env.sh其中的参数 <span class="built_in">export</span> HADOOP_HEAPSIZE修改为2048，重启Hive。</span></span><br><span class="line">export HADOOP_HEAPSIZE=2048</span><br><span class="line">[root@hadoop102 conf]# hiveservices.sh restart</span><br></pre></td></tr></table></figure>

<p>（4）关闭Hadoop虚拟内存检查</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭hadoop集群</span></span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh stop</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置文件yarn-site.xml</span></span><br><span class="line">[root@hadoop102 hadoop]# pwd</span><br><span class="line">/opt/module/hadoop-3.1.3/etc/hadoop</span><br><span class="line">[root@hadoop102 hadoop]# vim yarn-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加如下配置</span></span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发配置文件</span></span><br><span class="line">[root@hadoop102 hadoop]# xsync yarn-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启集群</span></span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh start</span><br></pre></td></tr></table></figure>

<h1 id="第三章-DDL数据定义"><a href="#第三章-DDL数据定义" class="headerlink" title="第三章 DDL数据定义"></a>第三章 DDL数据定义</h1><h2 id="3-1-数据库（database）"><a href="#3-1-数据库（database）" class="headerlink" title="3.1 数据库（database）"></a>3.1 数据库（database）</h2><h3 id="3-1-1-创建数据库"><a href="#3-1-1-创建数据库" class="headerlink" title="3.1.1 创建数据库"></a>3.1.1 创建数据库</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] database_name</span><br><span class="line">[COMMENT database_comment]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[<span class="keyword">WITH</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...)];</span><br></pre></td></tr></table></figure>

<p>Hive会为每个数据库创建一个目录，数据库中的表将会以这个数据库目录的子目录形式存储。有一个例外就是default数据库中的表，因为这个数据库本身没有自己的目录。默认情况下，default数据库中的表目录会直接位于${hive.metastore.warehouse.dir}目录之后</p>
<p>（2）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 创建一个数据库，不指定路径</span><br><span class="line">--若不指定路径，其默认路径为$&#123;hive.metastore.warehouse.dir&#125;/database_name.db，</span><br><span class="line">--其中，$&#123;hive.metastore.warehouse.dir&#125;默认为/user/hive/warehouse</span><br><span class="line">create database db_hive;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_14-40-04.png" alt="Snipaste_2023-10-08_14-40-04"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>创建一个数据库，指定路径</span><br><span class="line"><span class="keyword">create</span> database db_hive2 location <span class="string">&#x27;/db_hive2&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_14-41-48.png" alt="Snipaste_2023-10-08_14-41-48"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>创建一个数据库，带有dbproperties</span><br><span class="line"><span class="keyword">create</span> database db_hive3 <span class="keyword">with</span> dbproperties (<span class="string">&#x27;create_date&#x27;</span><span class="operator">=</span><span class="string">&#x27;2023-10-08&#x27;</span>);</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-查询数据库"><a href="#3-1-2-查询数据库" class="headerlink" title="3.1.2 查询数据库"></a>3.1.2 查询数据库</h3><h4 id="3-1-2-1-展示所有数据库"><a href="#3-1-2-1-展示所有数据库" class="headerlink" title="3.1.2.1 展示所有数据库"></a>3.1.2.1 展示所有数据库</h4><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> DATABASES [<span class="keyword">LIKE</span> <span class="string">&#x27;identifier_with_wildcards&#x27;</span>];</span><br></pre></td></tr></table></figure>

<p>注：like通配表达式说明：*表示任意个任意字符，|表示或的关系。</p>
<p>（2）案例</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> databases ;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">db_hive</span><br><span class="line">db_hive2</span><br><span class="line">db_hive3</span><br><span class="line">default</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> databases <span class="keyword">like</span> <span class="string">&#x27;db_hive*&#x27;</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">db_hive</span><br><span class="line">db_hive2</span><br><span class="line">db_hive3</span><br></pre></td></tr></table></figure>

<h4 id="3-1-2-2-查看数据库信息"><a href="#3-1-2-2-查看数据库信息" class="headerlink" title="3.1.2.2 查看数据库信息"></a>3.1.2.2 查看数据库信息</h4><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DESCRIBE</span> DATABASE [EXTENDED] db_name;</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">describe</span> database extended db_hive3;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_14-53-15.png" alt="Snipaste_2023-10-08_14-53-15"></p>
<h3 id="3-1-3-修改数据库"><a href="#3-1-3-修改数据库" class="headerlink" title="3.1.3 修改数据库"></a>3.1.3 修改数据库</h3><p>用户可以使用alter database命令修改数据库某些信息，其中能够修改的信息包括dbproperties、location、owner user。需要注意的是：修改数据库location，不会改变当前已有表的路径信息，而只是改变后续创建的新表的默认的父目录。</p>
<p>（1）语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 修改dbproperties</span><br><span class="line">ALTER DATABASE database_name SET DBPROPERTIES (property_name=property_value, ...);</span><br><span class="line"></span><br><span class="line">-- 修改location</span><br><span class="line">ALTER DATABASE database_name SET LOCATION hdfs_path;</span><br><span class="line"></span><br><span class="line">-- 修改owner user</span><br><span class="line">ALTER DATABASE database_name SET OWNER USER user_name;</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> database db_hive3 <span class="keyword">set</span> dbproperties (<span class="string">&#x27;create_date&#x27;</span><span class="operator">=</span><span class="string">&#x27;2023-10-10&#x27;</span>);</span><br><span class="line"><span class="keyword">describe</span> database extended db_hive3;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_15-06-49.png" alt="Snipaste_2023-10-08_15-06-49"></p>
<h3 id="3-1-4-删除数据库（慎用）"><a href="#3-1-4-删除数据库（慎用）" class="headerlink" title="3.1.4 删除数据库（慎用）"></a>3.1.4 删除数据库（慎用）</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> DATABASE [IF <span class="keyword">EXISTS</span>] database_name [RESTRICT<span class="operator">|</span>CASCADE];</span><br></pre></td></tr></table></figure>

<p>注：RESTRICT：严格模式，若数据库不为空，则会删除失败，默认为该模式。</p>
<p>  CASCADE：级联模式，若数据库不为空，则会将库中的表一并删除。</p>
<h3 id="3-1-5-切换当前数据库"><a href="#3-1-5-切换当前数据库" class="headerlink" title="3.1.5 切换当前数据库"></a>3.1.5 切换当前数据库</h3><p>略</p>
<h2 id="3-2-表（table）"><a href="#3-2-表（table）" class="headerlink" title="3.2 表（table）"></a>3.2 表（table）</h2><h3 id="3-2-1-创建表"><a href="#3-2-1-创建表" class="headerlink" title="3.2.1 创建表"></a>3.2.1 创建表</h3><h4 id="3-2-1-1-语法"><a href="#3-2-1-1-语法" class="headerlink" title="3.2.1.1 语法"></a>3.2.1.1 语法</h4><p>（1）普通建表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [TEMPORARY] [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name   </span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[COMMENT table_comment]</span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) </span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS]</span><br><span class="line">[<span class="type">ROW</span> FORMAT row_format] </span><br><span class="line">[STORED <span class="keyword">AS</span> file_format]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[TBLPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]</span><br></pre></td></tr></table></figure>

<p>关键字说明：</p>
<p>①<strong>TEMPORARY</strong>：临时表，该表只在当前会话可见，会话结束，表会被删除。</p>
<p>②<strong>EXTERNAL</strong>：外部表，与之相对应的是内部表（管理表）。管理表意味着Hive会完全接管该表，包括元数据和HDFS中的数据。而外部表则意味着Hive只接管元数据，而不完全接管HDFS中的数据，外部表指向已经存在于HDFS上的数据。</p>
<p><strong>内部表和外部表的区别，面试可能会问，详见《大数据面试题总结》</strong></p>
<ul>
<li>由external修饰的表为外部表，未被external修饰的表为内部表</li>
<li>内部表由Hive自身管理（包括元数据和HDFS中的数据）；外部表Hive只接管元数据，数据由HDFS管理</li>
<li>删除（drop）内部表会直接删除元数据及HDFS上的文件；删除（drop）外部表仅仅会删除元数据，HDFS上的文件并不会删除</li>
<li>清空（truncate）表操作只能清空内部表，清空外部表将报错</li>
</ul>
<p>③<strong>data_type</strong>（重点）：</p>
<img src="Snipaste_2023-10-08_15-23-29.png" alt="Snipaste_2023-10-08_15-23-29" style="zoom:43%;">

<p><strong>注意1：</strong>所有以上的数据类型都是对Java中的接口的实现，因此这些数据类型的具体行为细节和Java中对应的类型是完全一样的。string类型实现的是Java中的String等等。</p>
<p><strong>注意2：</strong>说明decimal(16,2)：代表最多有16位数字，其中后2位是小数，整数部分是14位；如果整数部分超过14位，这个字段就会变成null，如果小数部分不足2位，后面用0补齐两位，小数部分超过两位，超出部分四舍五入。直接写decimal默认是decimal(10,0)。</p>
<p>12345678909876.12</p>
<p>123456789098765——null</p>
<p>12345678909876.1—–12345678909876.10</p>
<p>12345678909876.125—–12345678909876.13</p>
<p><strong>注意3：</strong>timestamp的值可以是整数（距离1970年1月1日午夜12点的秒数），也可以是浮点数（距离1970年1月1日午夜12点的秒数精确到纳秒，小数点后保留9位），还可以是字符串（YYYY-MM-DD hh:mm:ss.fffffffff）</p>
<p><strong>注意4：</strong>binary数据类型类似于关系型数据库中的varbinary，binary可以在记录中包含任意字节，这样可以防止Hive尝试将其作为数字、字符串等进行解析。</p>
<p>一般而言，在hive中，整数用int，特别多的整数用bigint，小数用double或decimal(推荐)，字符串用string</p>
<img src="Snipaste_2023-10-08_15-23-50.png" alt="Snipaste_2023-10-08_15-23-50" style="zoom:43%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table emp (</span><br><span class="line">	name string,</span><br><span class="line">    salary float,</span><br><span class="line">    subordinates array&lt;string&gt;, --下属员工，是一个字符串值数组，该数组中，我们可以认为name是“主键”，因此subordinates中每一个元素都将会引用这张表中的一条记录，没有下属的雇员，这个字段就为空数组，在传统模型中，将会以雇员和雇员经理这种对应关系表表示</span><br><span class="line">    deductions map&lt;string, float&gt;, --每个键都是string类型的，每个值都是float类型的</span><br><span class="line">    address struct&lt;street:string, city:string, state:string, zip:int&gt;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p><strong>Hive的基本数据类型可以相互转换</strong>：</p>
<p><strong>隐式转换（知道就行）</strong>：</p>
<p>a. 任何整数类型都可以隐式地转换为一个范围更广的类型，如tinyint可以转换成int，int可以转换成bigint。</p>
<p>b. 所有整数类型、float和string类型都可以隐式地转换成double。</p>
<p>c. tinyint、smallint、int都可以转换为float。</p>
<p>d. boolean类型不可以转换为任何其它的类型。</p>
<p><strong>显式转换</strong>：</p>
<p>可以借助cast函数完成显示的类型转换</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="string">&#x27;1&#x27;</span> <span class="operator">+</span> <span class="number">2</span>, <span class="built_in">cast</span>(<span class="string">&#x27;1&#x27;</span> <span class="keyword">as</span> <span class="type">int</span>) <span class="operator">+</span> <span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">3,3</span><br><span class="line">第一个3是double类型，第二个3是int类型</span><br></pre></td></tr></table></figure>

<p>④<strong>PARTITIONED BY</strong>（重点）：创建分区表</p>
<p>⑤<strong>CLUSTERED BY … SORTED BY…INTO … BUCKETS</strong>（重点）：创建分桶表</p>
<p>⑥<strong>ROW FORMAT</strong>（重点）：指定SERDE，SERDE是Serializer and Deserializer的简写。Hive使用SERDE序列化和反序列化每行数据。</p>
<img src="Snipaste_2023-10-08_16-15-03.png" alt="Snipaste_2023-10-08_16-15-03" style="zoom:50%;">

<img src="Snipaste_2023-10-08_16-15-26.png" alt="Snipaste_2023-10-08_16-15-26" style="zoom:50%;">

<p>⑦<strong>STORED AS</strong>（重点）：指定文件格式，常用的文件格式有，textfile（默认值），sequence file，orc file、parquet file等等。</p>
<p>⑧<strong>LOCATION</strong>：指定表所对应的HDFS路径，若不指定路径，其默认值${hive.metastore.warehouse.dir}&#x2F;db_name.db&#x2F;table_name</p>
<p>⑨<strong>TBLPROPERTIES</strong>：用于配置表的一些KV键值对参数</p>
<p>（2）Create Table As Select（CTAS）建表</p>
<p>该语法允许用户利用select查询语句返回的结果，直接建表，表的结构和查询语句的结构保持一致，且保证包含select查询语句放回的内容。</p>
<p><img src="Snipaste_2023-10-08_16-28-23.png" alt="Snipaste_2023-10-08_16-28-23"></p>
<p>（3）Create Table Like语法</p>
<p>该语法允许用户复刻一张已经存在的表结构，与上述的CTAS语法不同，该语法创建出来的表中<strong>不包含数据</strong>，只是一个表的框架</p>
<p><img src="Snipaste_2023-10-08_16-28-47.png" alt="Snipaste_2023-10-08_16-28-47"></p>
<h4 id="3-2-1-2-案例"><a href="#3-2-1-2-案例" class="headerlink" title="3.2.1.2 案例"></a>3.2.1.2 案例</h4><h5 id="（1）内部表与外部表"><a href="#（1）内部表与外部表" class="headerlink" title="（1）内部表与外部表"></a>（1）内部表与外部表</h5><p><strong>最重要的区别：</strong>删除内部表，表的元数据信息和表内的数据都会被删除；删除外部表，表的元数据信息会被删除，但是表中的数据不会被删除。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- （1）内部表</span></span><br><span class="line"><span class="comment">-- Hive中默认创建的表都是的内部表，有时也被称为管理表。对于内部表，Hive会完全管理表的元数据和数据文件。</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student(</span><br><span class="line">    id <span class="type">int</span>,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/user/hive/warehouse/student&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>准备其需要的文件如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mkdir /opt/module/datas</span><br><span class="line">[root@hadoop102 module]# vim /opt/module/datas/student.txt</span><br><span class="line">1001	student1</span><br><span class="line">1002	student2</span><br><span class="line">1003	student3</span><br><span class="line">1004	student4</span><br><span class="line">1005	student5</span><br><span class="line">1006	student6</span><br><span class="line">1007	student7</span><br><span class="line">1008	student8</span><br><span class="line">1009	student9</span><br><span class="line">1010	student10</span><br><span class="line">1011	student11</span><br><span class="line">1012	student12</span><br><span class="line">1013	student13</span><br><span class="line">1014	student14</span><br><span class="line">1015	student15</span><br><span class="line">1016	student16</span><br></pre></td></tr></table></figure>

<p>上传文件到Hive表指定的路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# hadoop fs -put student.txt /user/hive/warehouse/student</span><br><span class="line">2023-10-08 19:29:10,755 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<p>在datagrip端就可以查到：</p>
<img src="Snipaste_2023-10-08_19-30-17.png" alt="Snipaste_2023-10-08_19-30-17" style="zoom: 33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 删除表，其中表结构和数据都被删除了，HDFS上的文件也没了</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- （2）外部表</span></span><br><span class="line"><span class="comment">--     外部表通常可用于处理其他工具上传的数据文件，对于外部表，</span></span><br><span class="line"><span class="comment">-- Hive只负责管理元数据，不负责管理HDFS中的数据文件。</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student(</span><br><span class="line">    id <span class="type">int</span>,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/user/hive/warehouse/student&#x27;</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上传文件到Hive表指定的路径</span></span><br><span class="line">[root@hadoop102 datas]# hadoop fs -put student.txt /user/hive/warehouse/student</span><br><span class="line">2023-10-08 19:42:09,630 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 删除表，此时HDFS中的数据文件仍然存在</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-08_19-44-22.png" alt="Snipaste_2023-10-08_19-44-22" style="zoom:43%;">

<img src="Snipaste_2023-10-08_19-45-03.png" alt="Snipaste_2023-10-08_19-45-03" style="zoom:43%;">

<h5 id="（2）SERDE和复杂数据类型"><a href="#（2）SERDE和复杂数据类型" class="headerlink" title="（2）SERDE和复杂数据类型"></a>（2）<strong>SERDE和复杂数据类型</strong></h5><p>若现有如下格式的JSON文件需要由Hive进行分析处理，请考虑如何设计表？</p>
<p>注：以下内容为格式化之后的结果，文件中每行数据为一个完整的JSON字符串。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dasongsong&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;friends&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;bingbing&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;lili&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;students&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;xiaohaihai&quot;</span><span class="punctuation">:</span> <span class="number">18</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;xiaoyangyang&quot;</span><span class="punctuation">:</span> <span class="number">16</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;address&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;street&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hui long guan&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span> <span class="string">&quot;beijing&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;postal_code&quot;</span><span class="punctuation">:</span> <span class="number">10010</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>我们可以考虑使用专门负责JSON文件的JSON Serde，设计表字段时，表的字段与JSON字符串中的一级字段保持一致，对于具有嵌套结构的JSON字符串，考虑使用合适复杂数据类型保存其内容。最终设计出的表结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create table teacher</span><br><span class="line">(</span><br><span class="line">    name     string,</span><br><span class="line">    friends  array&lt;string&gt;,</span><br><span class="line">    students map&lt;string,int&gt;,</span><br><span class="line">    address  struct&lt;city:string,street:string,postal_code:int&gt;</span><br><span class="line">)</span><br><span class="line">row format serde &#x27;org.apache.hadoop.hive.serde2.JsonSerDe&#x27;</span><br><span class="line">location &#x27;/user/hive/warehouse/teacher&#x27;;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建文件数据并上传到HIve表指定的路径</span></span><br><span class="line">[root@hadoop102 datas]# vim /opt/module/datas/teacher.txt</span><br><span class="line">&#123;&quot;name&quot;:&quot;dasongsong&quot;,&quot;friends&quot;:[&quot;bingbing&quot;,&quot;lili&quot;],&quot;students&quot;:&#123;&quot;xiaohaihai&quot;:18,&quot;xiaoyangyang&quot;:16&#125;,&quot;address&quot;:&#123;&quot;street&quot;:&quot;hui long guan&quot;,&quot;city&quot;:&quot;beijing&quot;,&quot;postal_code&quot;:10010&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dasongsong&quot;,&quot;friends&quot;:[&quot;bingbing&quot;,&quot;lili&quot;],&quot;students&quot;:&#123;&quot;xiaohaihai&quot;:18,&quot;xiaoyangyang&quot;:16&#125;,&quot;address&quot;:&#123;&quot;street&quot;:&quot;hui long guan&quot;,&quot;city&quot;:&quot;beijing&quot;,&quot;postal_code&quot;:10010&#125;&#125;</span><br><span class="line">[root@hadoop102 datas]# hadoop fs -put teacher.txt /user/hive/warehouse/teacher</span><br><span class="line">2023-10-08 21:16:23,678 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<p>在datagrip端可以看到数据：</p>
<p><img src="Snipaste_2023-10-08_21-17-46.png" alt="Snipaste_2023-10-08_21-17-46"></p>
<p>尝试从复杂数据类型的字段中取值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select friends[0], students[&#x27;xiaohaihai&#x27;], address.city</span><br><span class="line">from teacher;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-08_21-22-42.png" alt="Snipaste_2023-10-08_21-22-42" style="zoom:50%;">

<h5 id="（3）creat-table-as和create-table-like"><a href="#（3）creat-table-as和create-table-like" class="headerlink" title="（3）creat table as和create table like"></a>（3）creat table as和create table like</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- creat table as建出来的表结构和数据都有</span><br><span class="line">create table teacher1 as select * from teacher;</span><br><span class="line">select * from teacher1;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_21-28-54.png" alt="Snipaste_2023-10-08_21-28-54"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- create table like建出来的表只有结构没有里面的数据，是一个空表</span><br><span class="line">create table teacher2 like teacher;</span><br><span class="line">select * from teacher2;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_21-30-45.png" alt="Snipaste_2023-10-08_21-30-45"></p>
<h4 id="3-2-1-3-读时模式"><a href="#3-2-1-3-读时模式" class="headerlink" title="3.2.1.3 读时模式"></a>3.2.1.3 读时模式</h4><p>当用户向传统数据库中写入数据时候（装载外部数据、将一个查询的输出结果写入、使用UPDATE语句），数据库对于存储都具有完全的控制力，即写时模式（shema on write），即数据在写入数据库时对模式进行检查。</p>
<p>Hive对底层存储并没有这样的控制，对于Hive要查询的数据，有很多种方式对其进行创建、修改、甚至损坏。因此，Hive不会再数据加载时进行检验，而是再查询时进行，也就是读时模式（schema on read）。如果模式和文件内容并不匹配，Hive依旧可以读取这些数据，如果每行记录中的字段个数少于对应的模式中定义的字段个数的话，用户将看到查询结果中有很多null值。如果字段是数值型的，但是Hive在读取时发现存在非数值型的字符串值的话，那么对于那些字段将会返回null值。</p>
<h3 id="3-2-2-查看表"><a href="#3-2-2-查看表" class="headerlink" title="3.2.2 查看表"></a>3.2.2 查看表</h3><p>（1）展示所有表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> TABLES [<span class="keyword">IN</span> database_name] <span class="keyword">LIKE</span> [<span class="string">&#x27;identifier_with_wildcards&#x27;</span>];</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show tables like &#x27;stu*&#x27;;</span><br></pre></td></tr></table></figure>

<p>（2）查看表信息</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DESCRIBE</span> [EXTENDED <span class="operator">|</span> FORMATTED] [db_name.]table_name</span><br></pre></td></tr></table></figure>

<p>注：EXTENDED：展示详细信息</p>
<p>​	FORMATTED：对详细信息进行格式化的展示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 查看基本信息</span><br><span class="line">describe teacher;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-09_12-17-14.png" alt="Snipaste_2023-10-09_12-17-14"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 查看更多信息</span><br><span class="line">desc formatted stu;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-09_12-18-43.png" alt="Snipaste_2023-10-09_12-18-43"></p>
<h3 id="3-2-3-修改表"><a href="#3-2-3-修改表" class="headerlink" title="3.2.3 修改表"></a>3.2.3 修改表</h3><p><strong>注意：</strong>ALTER TABLE仅仅会修改表元数据，表数据本身不会有任何修改</p>
<p>（1）重命名表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name RENAME <span class="keyword">TO</span> new_table_name</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table stu rename to stu1;</span><br></pre></td></tr></table></figure>

<p>（2）修改列信息</p>
<p><strong>注意：</strong>一般而言，如果表创建好了，想要增加列只能在原来列的末尾增加，如果想在指定位置增加只能将原来的列进行替换操作；删除列是无法操作的，可以将其进行注释废置，表明该列不再使用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- ①增加列：该语句允许用户增加新的列，新增列的位置位于末尾。</span><br><span class="line">-- ALTER TABLE table_name ADD COLUMNS (col_name data_type [COMMENT col_comment], ...)</span><br><span class="line">alter table stu1 add columns(age int);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_12-40-32.png" alt="Snipaste_2023-10-09_12-40-32" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- ②更新列：该语句允许用户修改指定列的列名、数据类型、注释信息以及在表中的位置。</span><br><span class="line">-- ALTER TABLE table_name</span><br><span class="line">-- CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]</span><br><span class="line">alter table stu1 change column age ages double;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_12-42-02.png" alt="Snipaste_2023-10-09_12-42-02" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- ③替换列：该语句允许用户用新的列集替换表中原有的全部列。</span><br><span class="line">-- ALTER TABLE table_name REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)</span><br><span class="line">alter table stu1 replace columns(id int, name string);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_12-42-43.png" alt="Snipaste_2023-10-09_12-42-43" style="zoom:50%;">

<h3 id="3-2-4-删除表"><a href="#3-2-4-删除表" class="headerlink" title="3.2.4 删除表"></a>3.2.4 删除表</h3><p>删除表，同时删除表中的数据和表结构（也可以理解为直接删除表结构，表结构都没了，表中数据自然就没了）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 删除表</span><br><span class="line">-- DROP TABLE [IF EXISTS] table_name;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5-清空表"><a href="#3-2-5-清空表" class="headerlink" title="3.2.5 清空表"></a>3.2.5 清空表</h3><p>清空表，顾名思义，就是保留表结构，清空表中的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 清空表：注意：truncate只能清空管理表，不能删除外部表中数据。</span><br><span class="line">-- TRUNCATE [TABLE] table_name</span><br></pre></td></tr></table></figure>

<h1 id="第四章-DML（数据操作）"><a href="#第四章-DML（数据操作）" class="headerlink" title="第四章 DML（数据操作）"></a>第四章 DML（数据操作）</h1><h2 id="4-1-Load"><a href="#4-1-Load" class="headerlink" title="4.1 Load"></a>4.1 Load</h2><p>Load语句可将文件导入到Hive表中。</p>
<p>（1）语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [LOCAL] INPATH &#x27;filepath&#x27; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)];</span><br></pre></td></tr></table></figure>

<p>关键字说明：</p>
<p>①local：表示从本地加载数据到Hive表；否则从HDFS加载数据到Hive表。</p>
<p>加上local表示从本地<strong>复制</strong>数据到hive表，不加local表示从HDFS上<strong>剪切</strong>数据到hive表</p>
<p>②overwrite：表示覆盖表中已有数据，否则表示追加。</p>
<p>③partition：表示上传到指定分区，若目标是分区表，需指定分区。</p>
<p>（2）案例实操</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- ①首先创建一张表</span><br><span class="line">create table student(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- ②加载本地文件到hive（从本地复制数据到hive表）</span><br><span class="line">load data local inpath &#x27;/opt/module/datas/student.txt&#x27; into table student;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_13-04-13.png" alt="Snipaste_2023-10-09_13-04-13" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">③上传文件到HDFS</span></span><br><span class="line">[root@hadoop102 datas]# hadoop fs -mkdir /user/atguigu</span><br><span class="line">[root@hadoop102 datas]# hadoop fs -put /opt/module/datas/student.txt /user/atguigu</span><br><span class="line">2023-10-09 13:08:00,034 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- ③加载HDFS上的数据，导入完成后去HDFS上查看文件是否还存在（不存在了）</span><br><span class="line">load data inpath &#x27;/user/atguigu/student.txt&#x27; into table student;</span><br></pre></td></tr></table></figure>

<p>追加操作：</p>
<img src="Snipaste_2023-10-09_13-14-06.png" alt="Snipaste_2023-10-09_13-14-06" style="zoom:50%;">

<p>位于HDFS上的&#x2F;user&#x2F;atguigu&#x2F;student.txt文件已经不在了</p>
<img src="Snipaste_2023-10-09_13-15-13.png" alt="Snipaste_2023-10-09_13-15-13" style="zoom:50%;">

<h2 id="4-2-Insert"><a href="#4-2-Insert" class="headerlink" title="4.2 Insert"></a>4.2 Insert</h2><h3 id="4-2-1-将查询结果插入表中"><a href="#4-2-1-将查询结果插入表中" class="headerlink" title="4.2.1 将查询结果插入表中"></a>4.2.1 将查询结果插入表中</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> (<span class="keyword">INTO</span> <span class="operator">|</span> OVERWRITE) <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] select_statement;</span><br></pre></td></tr></table></figure>

<p>关键字说明：</p>
<p>①INTO：将结果追加到目标表</p>
<p>②OVERWRITE：用结果覆盖原有数据</p>
<p>（2）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 新建一张表</span><br><span class="line">create table student1(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 据查询结果插入数据</span><br><span class="line">insert overwrite table student1</span><br><span class="line">select * from student;</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-将给定Values插入表中"><a href="#4-2-2-将给定Values插入表中" class="headerlink" title="4.2.2 将给定Values插入表中"></a>4.2.2 将给定Values插入表中</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> (<span class="keyword">INTO</span> <span class="operator">|</span> OVERWRITE) <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1[<span class="operator">=</span>val1], partcol2[<span class="operator">=</span>val2] ...)] <span class="keyword">VALUES</span> values_row [, values_row ...]</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 将给定Values插入表中</span><br><span class="line">insert into table student1</span><br><span class="line">values(1,&#x27;wangwu&#x27;),(2,&#x27;zhaoliu&#x27;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_13-30-17.png" alt="Snipaste_2023-10-09_13-30-17" style="zoom:50%;">

<h3 id="4-2-3-将查询结果写入目标路径"><a href="#4-2-3-将查询结果写入目标路径" class="headerlink" title="4.2.3 将查询结果写入目标路径"></a>4.2.3 将查询结果写入目标路径</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory</span><br><span class="line">  [<span class="type">ROW</span> FORMAT row_format] [STORED <span class="keyword">AS</span> file_format] select_statement;</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 将查询结果写入目标路径(本地路径)</span><br><span class="line">insert overwrite local directory &#x27;/opt/module/datas/student111&#x27;</span><br><span class="line">ROW FORMAT SERDE &#x27;org.apache.hadoop.hive.serde2.JsonSerDe&#x27; -- 以JSON格式存入目标路径</span><br><span class="line">select id,name from student;</span><br></pre></td></tr></table></figure>

<p>再去查看’&#x2F;opt&#x2F;module&#x2F;datas&#x2F;student111’,</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/datas/student111/</span><br><span class="line">[root@hadoop102 student111]# ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 root root 1102 10月  9 13:35 000000_0</span><br><span class="line">[root@hadoop102 student111]# cat 000000_0</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1001</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student1&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1002</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student2&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1003</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student3&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1004</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student4&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1005</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student5&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1006</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student6&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1007</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student7&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1008</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student8&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1009</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student9&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1010</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student10&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1011</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student11&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1012</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student12&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1013</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student13&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1014</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student14&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1015</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student15&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1016</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student16&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1001</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student1&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1002</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student2&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1003</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student3&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1004</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student4&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1005</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student5&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1006</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student6&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1007</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student7&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1008</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student8&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1009</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student9&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1010</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student10&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1011</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student11&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1012</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student12&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1013</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student13&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1014</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student14&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1015</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student15&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1016</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student16&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-2-4-multi-group-by语法替换多个查询语句求并集"><a href="#4-2-4-multi-group-by语法替换多个查询语句求并集" class="headerlink" title="4.2.4 multi-group-by语法替换多个查询语句求并集"></a>4.2.4 multi-group-by语法替换多个查询语句求并集</h3><p>这是表过滤常见的操作，表过滤指的是过滤掉同一个SQL语句需要多次访问相同表的数据，将重复的访问操作过滤并压缩成只读一次</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line">set hive.exec.dynamic.partition=true;</span><br><span class="line">explain</span><br><span class="line">insert into table ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df partition(dt = &#x27;&#123;&#123; ds &#125;&#125;&#x27;)</span><br><span class="line">select t.real_app_name,</span><br><span class="line">       max(app_score) as state,</span><br><span class="line">       &#x27;max&#x27; as tp</span><br><span class="line">from ks_ad_dw.dm_pub_audit_xintongyuan_df t </span><br><span class="line">where t.p_date = &#x27;&#123;&#123; ds_nodash &#125;&#125;&#x27;</span><br><span class="line">group by t.real_app_name</span><br><span class="line"></span><br><span class="line">union all</span><br><span class="line"></span><br><span class="line">select t.real_app_name,</span><br><span class="line">       min(app_score) as state,</span><br><span class="line">       &#x27;min&#x27; as tp</span><br><span class="line">from ks_ad_dw.dm_pub_audit_xintongyuan_df t </span><br><span class="line">where t.p_date = &#x27;&#123;&#123; ds_nodash &#125;&#125;&#x27;</span><br><span class="line">group by t.real_app_name</span><br></pre></td></tr></table></figure>

<p>以上操作在计算最大值和最小值的时候在Map阶段都会进行一次表扫描（TableScan）的操作，存在重读读取表数据的情况。如果一次读取的数据比较大时会占用更多的磁盘IO资源。未来避免这种情况发生，Hive引入了from..select形式，查询的表在一次读取后，可以被多个查询语句使用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line">set hive.exec.dynamic.partition=true;</span><br><span class="line">explain</span><br><span class="line">from ks_ad_dw.dm_pub_audit_xintongyuan_df t</span><br><span class="line">insert into table ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df partition(dt = &#x27;&#123;&#123; ds &#125;&#125;&#x27;)</span><br><span class="line">select t.real_app_name,</span><br><span class="line">       max(app_score) as state,</span><br><span class="line">       &#x27;max&#x27; as tp</span><br><span class="line">where t.p_date = &#x27;&#123;&#123; ds_nodash &#125;&#125;&#x27;</span><br><span class="line">group by t.real_app_name</span><br><span class="line"></span><br><span class="line">insert into table ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">select t.real_app_name,</span><br><span class="line">       min(app_score) as state,</span><br><span class="line">       &#x27;min&#x27; as tp </span><br><span class="line">where t.p_date = &#x27;&#123;&#123; ds_nodash &#125;&#125;&#x27;</span><br><span class="line">group by t.real_app_name</span><br></pre></td></tr></table></figure>

<p>从执行计划中可以看到只需要一次读取，就可以完成所有的计算。</p>
<h2 id="4-3-Export-amp-Import"><a href="#4-3-Export-amp-Import" class="headerlink" title="4.3 Export&amp;Import"></a>4.3 Export&amp;Import</h2><p>Export导出语句可将表的<strong>数据和元数据信息</strong>一并导出到HDFS路径，Import可将Export导出的内容导入Hive，表的数据和元数据信息都会恢复。<strong>Export和Import可用于两个Hive实例之间的数据迁移。</strong></p>
<p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 导出</span></span><br><span class="line">EXPORT <span class="keyword">TABLE</span> tablename <span class="keyword">TO</span> <span class="string">&#x27;export_target_path&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导入</span></span><br><span class="line">IMPORT [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> new_or_original_tablename <span class="keyword">FROM</span> <span class="string">&#x27;source_path&#x27;</span> [LOCATION <span class="string">&#x27;import_target_path&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>（1）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 导出</span><br><span class="line">export table default.student to &#x27;/user/hive/warehouse/export/student&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_13-45-53.png" alt="Snipaste_2023-10-09_13-45-53" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--导入</span><br><span class="line">import table student2 from &#x27;/user/hive/warehouse/export/student&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_13-48-53.png" alt="Snipaste_2023-10-09_13-48-53" style="zoom:50%;">

<p><strong>注意：因为Hadoop不支持HDFS文件中数据的更改和删除（只能一条条追加数据），所以Hive中也不支持对数据的改写和删除</strong></p>
<h1 id="第五章-查询"><a href="#第五章-查询" class="headerlink" title="第五章 查询"></a>第五章 查询</h1><h2 id="5-0-Hive数据类型及其引用总结"><a href="#5-0-Hive数据类型及其引用总结" class="headerlink" title="5.0 Hive数据类型及其引用总结"></a>5.0 Hive数据类型及其引用总结</h2><h3 id="5-0-1-基本数据类型"><a href="#5-0-1-基本数据类型" class="headerlink" title="5.0.1 基本数据类型"></a>5.0.1 基本数据类型</h3><table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>tinyint</td>
<td>1字节有符号整数</td>
</tr>
<tr>
<td>smallint</td>
<td>2字节有符号整数</td>
</tr>
<tr>
<td>int</td>
<td>4字节有符号整数</td>
</tr>
<tr>
<td>bigint</td>
<td>8字节有符号整数</td>
</tr>
<tr>
<td>boolean</td>
<td>布尔类型，true或false</td>
</tr>
<tr>
<td>float</td>
<td>单精度浮点数</td>
</tr>
<tr>
<td>double</td>
<td>双精度浮点数</td>
</tr>
<tr>
<td>decimal</td>
<td>十进制精度数字类型</td>
</tr>
<tr>
<td>varchar</td>
<td>字符序列，需要指定最大长度</td>
</tr>
<tr>
<td>string</td>
<td>字符序列，无需指定最大长度</td>
</tr>
<tr>
<td>timestamp</td>
<td>时间类型</td>
</tr>
<tr>
<td>binary</td>
<td>二进制数据</td>
</tr>
</tbody></table>
<h3 id="5-0-2-复杂（集合）数据类型"><a href="#5-0-2-复杂（集合）数据类型" class="headerlink" title="5.0.2 复杂（集合）数据类型"></a>5.0.2 复杂（集合）数据类型</h3><table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>array</td>
<td>数组是一组相同类型的值的集合</td>
</tr>
<tr>
<td>map</td>
<td>map是一组相同类型的键值对组合（键值对组合类型唯一确定）</td>
</tr>
<tr>
<td>struct</td>
<td>结构体由多个属性组成，每个属性都有自己的属性名和数据类型</td>
</tr>
</tbody></table>
<p>当用户选择的是集合数据类型时，Hive会使用JSON语法应用于输出，下面看下如何引用集合数据类型中的元素</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">select a from tmp;--列a是array类型的，注意集合的字符串元素是加上引号的，而基本数据类型string的列值是不加引号的</span><br><span class="line">--[&quot;Mary&quot;,&quot;Jack&quot;,&quot;King&quot;] </span><br><span class="line">select b from tmp;--列b是map类型的</span><br><span class="line">--&#123;&quot;Fed&quot;:0.2, &quot;Stjj&quot;:0.99, &quot;interff&quot;:0.1&#125;</span><br><span class="line">select c from tmp;--列c是struct类型的</span><br><span class="line">&#123;&quot;name&quot;:&quot;Jack&quot;, &quot;street&quot;:&quot;ccc&quot;, &quot;tel&quot;:13878665437&#125;</span><br></pre></td></tr></table></figure>

<p>引用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">select a[1] from tmp;--数组类型基于索引去引用</span><br><span class="line">--Jack</span><br><span class="line">select b[&quot;Fed&quot;] from tmp;--map类型通过键值索引去引用</span><br><span class="line">--0.2</span><br><span class="line">select c.tel from tmp;--strct类型通过“.”符号去引用</span><br><span class="line">--13878665437</span><br></pre></td></tr></table></figure>

<h2 id="5-1-基础语法"><a href="#5-1-基础语法" class="headerlink" title="5.1 基础语法"></a>5.1 基础语法</h2><p>基本语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...</span><br><span class="line">  <span class="keyword">FROM</span> table_reference       <span class="comment">-- 从什么表查</span></span><br><span class="line">  [<span class="keyword">WHERE</span> where_condition]   <span class="comment">-- 过滤</span></span><br><span class="line">  [<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list]        <span class="comment">-- 分组查询</span></span><br><span class="line">   [<span class="keyword">HAVING</span> col_list]          <span class="comment">-- 分组后过滤</span></span><br><span class="line">  [<span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]        <span class="comment">-- 排序</span></span><br><span class="line">  [CLUSTER <span class="keyword">BY</span> col_list</span><br><span class="line">    <span class="operator">|</span> [DISTRIBUTE <span class="keyword">BY</span> col_list] [SORT <span class="keyword">BY</span> col_list]</span><br><span class="line">  ]</span><br><span class="line"> [LIMIT number]                <span class="comment">-- 限制输出的行数</span></span><br></pre></td></tr></table></figure>

<h2 id="5-2-基本查询（Select…from）"><a href="#5-2-基本查询（Select…from）" class="headerlink" title="5.2 基本查询（Select…from）"></a>5.2 基本查询（Select…from）</h2><h3 id="5-2-1-数据准备"><a href="#5-2-1-数据准备" class="headerlink" title="5.2.1 数据准备"></a>5.2.1 数据准备</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module/hive/datas/路径上创建dept.txt文件，并赋值如下内容：部门编号 部门名称 部门位置<span class="built_in">id</span></span></span><br><span class="line">[root@hadoop102 datas]# cd /opt/module/hive/datas/</span><br><span class="line">[root@hadoop102 datas]# vim dept.txt</span><br><span class="line">10	行政部	1700</span><br><span class="line">20	财务部	1800</span><br><span class="line">30	教学部	1900</span><br><span class="line">40	销售部	1700</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module/hive/datas/路径上创建emp.txt文件，并赋值如下内容：员工编号 姓名 岗位    薪资  部门</span></span><br><span class="line">[root@hadoop102 datas]# vim emp.txt</span><br><span class="line">7369	张三	研发	800.00	30</span><br><span class="line">7499	李四	财务	1600.00	20</span><br><span class="line">7521	王五	行政	1250.00	10</span><br><span class="line">7566	赵六	销售	2975.00	40</span><br><span class="line">7654	侯七	研发	1250.00	30</span><br><span class="line">7698	马八	研发	2850.00	30</span><br><span class="line">7782	金九	\N	2450.0	30</span><br><span class="line">7788	银十	行政	3000.00	10</span><br><span class="line">7839	小芳	销售	5000.00	40</span><br><span class="line">7844	小明	销售	1500.00	40</span><br><span class="line">7876	小李	行政	1100.00	10</span><br><span class="line">7900	小元	讲师	950.00	30</span><br><span class="line">7902	小海	行政	3000.00	10</span><br><span class="line">7934	小红明	讲师	1300.00	30</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">-- 创建部门表</span><br><span class="line">create table if not exists dept(</span><br><span class="line">    deptno int,    -- 部门编号</span><br><span class="line">    dname string,  -- 部门名称</span><br><span class="line">    loc int        -- 部门位置</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 创建员工表</span><br><span class="line">create table if not exists emp(</span><br><span class="line">    empno int,      -- 员工编号</span><br><span class="line">    ename string,   -- 员工姓名</span><br><span class="line">    job string,     -- 员工岗位（大数据工程师、前端工程师、java工程师）</span><br><span class="line">    sal double,     -- 员工薪资</span><br><span class="line">    deptno int      -- 部门编号</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 导入数据</span><br><span class="line">load data local inpath &#x27;/opt/module/hive/datas/dept.txt&#x27; into table dept;</span><br><span class="line">load data local inpath &#x27;/opt/module/hive/datas/emp.txt&#x27; into table emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-08-51.png" alt="Snipaste_2023-10-09_15-08-51" style="zoom:50%;">

<img src="Snipaste_2023-10-09_15-09-01.png" alt="Snipaste_2023-10-09_15-09-01" style="zoom:50%;">

<h3 id="5-2-2-全表和特定列查询"><a href="#5-2-2-全表和特定列查询" class="headerlink" title="5.2.2 全表和特定列查询"></a>5.2.2 全表和特定列查询</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 全表查询</span><br><span class="line">select * from emp;</span><br><span class="line">-- 选择特定列查询</span><br><span class="line">select empno, ename from emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-11-15.png" alt="Snipaste_2023-10-09_15-11-15" style="zoom:50%;">

<p>注意：</p>
<p>（1）SQL 语言大小写不敏感。 </p>
<p>（2）SQL 可以写在一行或者多行。</p>
<p>（3）关键字不能被缩写也不能分行。</p>
<p>（4）各子句一般要分行写。</p>
<p>（5）使用缩进提高语句的可读性。</p>
<h3 id="5-2-3-列别名"><a href="#5-2-3-列别名" class="headerlink" title="5.2.3 列别名"></a>5.2.3 列别名</h3><p>1）重命名一个列</p>
<p>2）便于计算</p>
<p>3）紧跟列名，也可以在列名和别名之间加入关键字‘AS’（个人习惯，最好加上吧）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 查询名称和部门</span><br><span class="line">select ename AS name,</span><br><span class="line">       deptno dn</span><br><span class="line">from emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-15-04.png" alt="Snipaste_2023-10-09_15-15-04" style="zoom:50%;">

<h3 id="5-2-4-Limit语句"><a href="#5-2-4-Limit语句" class="headerlink" title="5.2.4 Limit语句"></a>5.2.4 Limit语句</h3><p>典型的查询会返回多行数据。limit子句用于限制返回的行数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from emp</span><br><span class="line">limit 5;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-17-07.png" alt="Snipaste_2023-10-09_15-17-07" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from emp</span><br><span class="line">limit 2,3;-- 表示从第2行开始，向下抓取3行（行索引从0开始）</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-17-52.png" alt="Snipaste_2023-10-09_15-17-52" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 取第一行数据，以下两种方式都行</span><br><span class="line">select * from emp</span><br><span class="line">limit 0,1;</span><br><span class="line">select * from emp</span><br><span class="line">limit 1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-21-45.png" alt="Snipaste_2023-10-09_15-21-45" style="zoom:50%;">

<h3 id="5-2-5-Where语句"><a href="#5-2-5-Where语句" class="headerlink" title="5.2.5 Where语句"></a>5.2.5 Where语句</h3><p>1）使用where子句，将不满足条件的行过滤掉</p>
<p>2）where子句紧随from子句</p>
<p>3）不能再where语句中使用列别名</p>
<h3 id="5-2-6-关系运算符"><a href="#5-2-6-关系运算符" class="headerlink" title="5.2.6 关系运算符"></a>5.2.6 关系运算符</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select empno as emp_id,</span><br><span class="line">       ename as emp_name</span><br><span class="line">from emp</span><br><span class="line">where sal between 500 and 1000;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-30-43.png" alt="Snipaste_2023-10-09_15-30-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where job in (&#x27;研发&#x27;,&#x27;销售&#x27;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-32-09.png" alt="Snipaste_2023-10-09_15-32-09" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- like进行模糊匹配</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where ename like &#x27;张%&#x27;;--字符”_”表示任意单个字符，而字符”%”表示任意数量的字符</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7369,张三,研发,800,30</span><br></pre></td></tr></table></figure>

<h3 id="5-2-7-逻辑运算符"><a href="#5-2-7-逻辑运算符" class="headerlink" title="5.2.7 逻辑运算符"></a>5.2.7 逻辑运算符</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where ename like &#x27;张%&#x27; or ename like &#x27;赵%&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-40-51.png" alt="Snipaste_2023-10-09_15-40-51" style="zoom:50%;">

<h3 id="5-2-8-聚合函数"><a href="#5-2-8-聚合函数" class="headerlink" title="5.2.8 聚合函数"></a>5.2.8 聚合函数</h3><p>count(*)，表示统计所有行数，包含null值，对表计数；同count(1)</p>
<p>count(某列)，表示该列一共有多少行，不包含null值，是对列计数，涉及字段的筛选，以及数据序列化和反序列化；(*)，表示统计所有行数，包含null值；</p>
<p>count(某列)，表示该列一共有多少行，不包含null值；</p>
<p>max()，求最大值，不包含null，除非所有值都是null；</p>
<p>min()，求最小值，不包含null，除非所有值都是null；</p>
<p>sum()，求和，不包含null。</p>
<p>avg()，求平均值，不包含null。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 求总行数</span><br><span class="line">select count(*)</span><br><span class="line">from emp;--14</span><br><span class="line"></span><br><span class="line">select count(job)</span><br><span class="line">from emp;--13,因为job列中有null值，计数时不算在内</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-49-08.png" alt="Snipaste_2023-10-09_15-49-08" style="zoom:50%;">

<p><strong>分析count(列)，count(*)，count(1)的执行计划，三者执行计划类似</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select count(fingerprint)</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27; </span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Select Operator</span><br><span class="line">              expressions<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)</span><br><span class="line">              outputColumnNames<span class="punctuation">:</span> fingerprint</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//按count函数中指定的列，即fingerprint，进行数据局部聚合</span></span><br><span class="line">              Group By Operator</span><br><span class="line">                aggregations<span class="punctuation">:</span> count(fingerprint)</span><br><span class="line">                mode<span class="punctuation">:</span> hash</span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0</span><br><span class="line">                skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                Reduce Output Operator</span><br><span class="line">                  sort order<span class="punctuation">:</span> </span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  TopN Hash Memory Usage<span class="punctuation">:</span> <span class="number">0.4</span></span><br><span class="line">                  value expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        <span class="comment">//进行数据全局聚合</span></span><br><span class="line">        Group By Operator</span><br><span class="line">          aggregations<span class="punctuation">:</span> count(VALUE._col0)</span><br><span class="line">          mode<span class="punctuation">:</span> mergepartial</span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0</span><br><span class="line">          skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          Limit</span><br><span class="line">            Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            File Output Operator</span><br><span class="line">              compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              table<span class="punctuation">:</span></span><br><span class="line">                  input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                  output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                  serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 求工资的最大值（max）</span><br><span class="line">select max(sal) as max_sal</span><br><span class="line">from emp;--5000</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 求工资的最小值（min）</span><br><span class="line">select min(sal) as min_sal</span><br><span class="line">from emp;--800</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-58-43.png" alt="Snipaste_2023-10-09_15-58-43" style="zoom:50%;">

<img src="Snipaste_2023-10-09_16-08-01.png" alt="Snipaste_2023-10-09_16-08-01" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 求工资的总和（sum）</span><br><span class="line">select sum(sal) as sum_sal</span><br><span class="line">from emp;--29025</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_16-11-07.png" alt="Snipaste_2023-10-09_16-11-07" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 求工资的平均值（avg）</span><br><span class="line">select avg(sal) as avg_sal</span><br><span class="line">from emp;--2073.214285714286</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_16-13-06.png" alt="Snipaste_2023-10-09_16-13-06" style="zoom:50%;">

<h2 id="5-3-分组"><a href="#5-3-分组" class="headerlink" title="5.3 分组"></a>5.3 分组</h2><h3 id="5-3-1-Group-By语句"><a href="#5-3-1-Group-By语句" class="headerlink" title="5.3.1 Group By语句"></a>5.3.1 Group By语句</h3><p>Group By语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 计算emp表每个部门的平均工资</span><br><span class="line">select deptno, avg(sal) as avg_sal</span><br><span class="line">from emp</span><br><span class="line">group by deptno;</span><br><span class="line">-- 注意：只要使用了group by ,select语句中只能选择两个字段：一个是group by分组的字段，另外一个是聚合函数字段</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_20-37-43.png" alt="Snipaste_2023-10-09_20-37-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 计算emp中每个部门中每个岗位的最高薪水</span><br><span class="line">select deptno, job, max(sal) as nax_sal</span><br><span class="line">from emp</span><br><span class="line">group by deptno, job;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_20-41-06.png" alt="Snipaste_2023-10-09_20-41-06" style="zoom:50%;">

<h3 id="5-3-2-Having语句"><a href="#5-3-2-Having语句" class="headerlink" title="5.3.2 Having语句"></a>5.3.2 Having语句</h3><p>1）having与where不同点</p>
<p>（1）where后面不能写分组聚合函数，而<strong>having后面可以使用分组聚合函数</strong>。</p>
<p>（2）<strong>having只用于group by分组统计语句</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 计算emp表中每个部门的平均工资大于等于2000的部门编号和平均工资</span><br><span class="line">-- 使用having对group by分组后的表数据进行过滤，和where效果一样，只是这里必须使用having</span><br><span class="line">select deptno, avg(sal) as avg_sal</span><br><span class="line">from emp</span><br><span class="line">group by deptno</span><br><span class="line">having avg_sal &gt;= 2000;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--等价于</span><br><span class="line">select deptno, avg_sal</span><br><span class="line">from(</span><br><span class="line">    select deptno, avg(sal) as avg_sal</span><br><span class="line">    from emp</span><br><span class="line">    group by deptno</span><br><span class="line">        ) t1</span><br><span class="line">where avg_sal &gt;= 2000;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_20-53-11.png" alt="Snipaste_2023-10-09_20-53-11" style="zoom:50%;">

<p><strong>查看having的执行计划</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select fingerprint,</span><br><span class="line">       sum(downloadcount) as downloadcount</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27; </span><br><span class="line">group by fingerprint</span><br><span class="line">having sum(downloadcount) &gt; 10;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Select Operator</span><br><span class="line">              expressions<span class="punctuation">:</span> downloadcount (type<span class="punctuation">:</span> bigint)<span class="punctuation">,</span> fingerprint (type<span class="punctuation">:</span> string)</span><br><span class="line">              outputColumnNames<span class="punctuation">:</span> downloadcount<span class="punctuation">,</span> fingerprint</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//在Map端预聚合</span></span><br><span class="line">              Group By Operator</span><br><span class="line">                aggregations<span class="punctuation">:</span> sum(downloadcount)</span><br><span class="line">                keys<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)</span><br><span class="line">                mode<span class="punctuation">:</span> hash</span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1</span><br><span class="line">                skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                Reduce Output Operator</span><br><span class="line">                  key expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)</span><br><span class="line">                  sort order<span class="punctuation">:</span> +</span><br><span class="line">                  Map-reduce partition columns<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)</span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  value expressions<span class="punctuation">:</span> _col1 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        Group By Operator</span><br><span class="line">          aggregations<span class="punctuation">:</span> sum(VALUE._col0)</span><br><span class="line">          keys<span class="punctuation">:</span> KEY._col0 (type<span class="punctuation">:</span> string)</span><br><span class="line">          mode<span class="punctuation">:</span> mergepartial</span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1</span><br><span class="line">          skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">116</span> Data size<span class="punctuation">:</span> <span class="number">49718</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          <span class="comment">//having过滤操作</span></span><br><span class="line">          Filter Operator</span><br><span class="line">            predicate<span class="punctuation">:</span> (_col1 &gt; <span class="number">10</span>) (type<span class="punctuation">:</span> boolean)</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Limit</span><br><span class="line">              Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              File Output Operator</span><br><span class="line">                compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                table<span class="punctuation">:</span></span><br><span class="line">                    input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p>可以看到，having子句的过滤操作发生在Reduce阶段</p>
<h3 id="5-3-3-高级分组聚合（grouping-sets，grouping-id，cube，rollup）"><a href="#5-3-3-高级分组聚合（grouping-sets，grouping-id，cube，rollup）" class="headerlink" title="5.3.3 高级分组聚合（grouping sets，grouping__id，cube，rollup）"></a>5.3.3 高级分组聚合（grouping sets，grouping__id，cube，rollup）</h3><p>高级分组聚合，也称为分析窗口函数</p>
<h4 id="（1）grouping-sets和grouping-id"><a href="#（1）grouping-sets和grouping-id" class="headerlink" title="（1）grouping sets和grouping__id"></a>（1）grouping sets和grouping__id</h4><p>在一个GROUP BY查询中，根据不同的维度组合进行聚合，等价于将不同维度的GROUP BY结果集进行Union ALL；GROUPING__ID，表示结果属于哪一个分组集合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    A,</span><br><span class="line">    B,</span><br><span class="line">    C,</span><br><span class="line">    GROUPING__ID, </span><br><span class="line">    count(*)</span><br><span class="line">from</span><br><span class="line">    tableName</span><br><span class="line">group by  </span><br><span class="line">    A,</span><br><span class="line">    B,</span><br><span class="line">    C</span><br><span class="line">grouping sets</span><br><span class="line">(</span><br><span class="line">   (A,B,C),</span><br><span class="line">   (A,C),</span><br><span class="line">   (A,B),</span><br><span class="line">   (B,C),</span><br><span class="line">   (A),</span><br><span class="line">   (B),</span><br><span class="line">   (C),</span><br><span class="line">   ()</span><br><span class="line">) </span><br></pre></td></tr></table></figure>

<p>其中grouping sets中的(A,C),   (A,B),   (B,C),   (C) 代表4个group by 组合， 相当于写了四个sql查询语句使用了四个不同的group by策略。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">select a,b,c from tmp group by a,b,c grouping sets((a,b,c),(a,b),(b,c),(a,c),(a),(b),(c),())</span><br><span class="line">--等价于</span><br><span class="line">select a,b,c from tmp group by a,b,c</span><br><span class="line">union all</span><br><span class="line">select a,b,null from tmp group by a,b</span><br><span class="line">union all</span><br><span class="line">select null,b,c from tmp group by b,c</span><br><span class="line">union all</span><br><span class="line">select a,null,c from tmp group by a,c</span><br><span class="line">union all</span><br><span class="line">select a,null,null from tmp group by a</span><br><span class="line">union all</span><br><span class="line">select null,b,null from tmp group by b</span><br><span class="line">union all </span><br><span class="line">select null,null,c from tmp group by c</span><br></pre></td></tr></table></figure>

<p>group_id是为了区分每条输出结果是属于哪一个group by的数据。它是根据group by后面声明的顺序字段是否存在于当前group by中的一个二进制位组合数据。 是一个标识维度组合的二进制数据（形式转为十进制存在）。</p>
<p><strong>grouping__id的生成规则：</strong></p>
<p>group by 所有字段中，如果在 grouping sets 的组合中存在的字段使用 0 表示，没有使用则使用 1 表示</p>
<table>
<thead>
<tr>
<th>grouping sets组合</th>
<th>二进制组合</th>
<th>生成的grouping__id</th>
</tr>
</thead>
<tbody><tr>
<td>(A,B,C)</td>
<td>000</td>
<td>0</td>
</tr>
<tr>
<td>(A,C)</td>
<td>010</td>
<td>2</td>
</tr>
<tr>
<td>(A,B)</td>
<td>001</td>
<td>1</td>
</tr>
<tr>
<td>(B,C)</td>
<td>100</td>
<td>4</td>
</tr>
<tr>
<td>(A)</td>
<td>011</td>
<td>3</td>
</tr>
<tr>
<td>(B)</td>
<td>101</td>
<td>5</td>
</tr>
<tr>
<td>(C)</td>
<td>110</td>
<td>6</td>
</tr>
<tr>
<td>()</td>
<td>111</td>
<td>7</td>
</tr>
</tbody></table>
<p>select中的字段是完整的A,B,C，但是我们知道由于group by的存在，select 字段本不应该出现非group by字段的，所以这里我们要特别说明，如果解释器发现group by A,C 但是select A,B,C 那么运行时会将所有from 表取出的结果复制一份，B都置为null，也就是在结果中，B都为null。</p>
<p><strong>举例：</strong></p>
<img src="Snipaste_2024-05-30_17-26-37.png" alt="Snipaste_2024-05-30_17-26-37" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select key, value, GROUPING__ID, count(*)</span><br><span class="line">from T1</span><br><span class="line">group by key,value with rollup;</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<img src="Snipaste_2024-05-30_17-29-03.png" alt="Snipaste_2024-05-30_17-29-03" style="zoom:50%;">

<h4 id="（2）cube和rollup"><a href="#（2）cube和rollup" class="headerlink" title="（2）cube和rollup"></a>（2）cube和rollup</h4><p>cube：根据group by的维度的所有组合进行聚合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">group by a,b,c with cube</span><br><span class="line">--等价于</span><br><span class="line">group by a,b,c grouping sets ((a,b,c),(a,b),(b,c),(a,c),(a),(b),(c),())</span><br></pre></td></tr></table></figure>

<p>rollup：是cube的子集，<strong>以最左侧</strong>的维度为主，从该维度进行层级聚合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">group by a,b,c with rollup</span><br><span class="line">--等价于</span><br><span class="line">group by a,b,c grouping sets ((a,b,c),(a,b),(a),())</span><br></pre></td></tr></table></figure>

<h4 id="（3）grouping-函数"><a href="#（3）grouping-函数" class="headerlink" title="（3）grouping()函数"></a>（3）grouping()函数</h4><p>grouping()函数可以查看某列的null值是否是cube或rollup（本质都是grouping sets）分组产生的，是1否0</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select key, value, GROUPING__ID, grouping(key), grouping(value), count(*)</span><br><span class="line">from T1</span><br><span class="line">group by key,value with rollup;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>key</th>
<th>value</th>
<th>GROUPING__ID</th>
<th>grouping(key)</th>
<th>grouping(value)</th>
<th>count(*)</th>
</tr>
</thead>
<tbody><tr>
<td>null</td>
<td>null</td>
<td>3</td>
<td>1</td>
<td>1</td>
<td>6</td>
</tr>
<tr>
<td>1</td>
<td>null</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>null</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>null</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>null</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>null</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>null</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<hr>
<p><strong>注意：</strong></p>
<p>使用高级分组聚合，仅用了一个作业就能够实现union写法需要多个作业才能实现的事情，从这点来看能够减少多个作业在磁盘和网络IO时多增加的负担，是一种优化，但是同时也要注意因过度使用高级分组聚合语法而导致的数据极速膨胀的问题。hive中使用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.new.job.grouping.set.cardinality</span><br></pre></td></tr></table></figure>

<p>配置项来应对上面可能出现的问题，如果SQL语句中处理的分组聚合情况超过该配置项指定的值（默认值30），则会创建一个新的作业来处理该配置项的情况。</p>
<h2 id="5-4-Join语句"><a href="#5-4-Join语句" class="headerlink" title="5.4 Join语句"></a>5.4 Join语句</h2><h3 id="5-4-1-等值Join"><a href="#5-4-1-等值Join" class="headerlink" title="5.4.1 等值Join"></a>5.4.1 等值Join</h3><p>简单理解Join：即把两张表横向“合并”成一个宽表</p>
<p>Hive支持通常的sql join语句，不等值连接不常用，但Hive3.x也支持，此处不再举例。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门名称。</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_21-10-09.png" alt="Snipaste_2023-10-09_21-10-09" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 根据员工表和部门表中的部门编号相等，查询不同地区的员工数</span><br><span class="line">select d.loc, count(*)</span><br><span class="line">from emp e join dept d</span><br><span class="line">on e.deptno = d.deptno</span><br><span class="line">group by d.loc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_21-13-07.png" alt="Snipaste_2023-10-09_21-13-07" style="zoom:50%;">

<h3 id="5-4-2-内连接（inner-join）"><a href="#5-4-2-内连接（inner-join）" class="headerlink" title="5.4.2 内连接（inner join）"></a>5.4.2 内连接（inner join）</h3><p>内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 内连接</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-3-左外连接（left-join）"><a href="#5-4-3-左外连接（left-join）" class="headerlink" title="5.4.3 左外连接（left join）"></a>5.4.3 左外连接（left join）</h3><p>左外连接：join操作符左边表中符合where子句的所有记录将会被返回。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 左外连接</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e left join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-4-右外连接（right-join）"><a href="#5-4-4-右外连接（right-join）" class="headerlink" title="5.4.4. 右外连接（right join）"></a>5.4.4. 右外连接（right join）</h3><p>右外连接：join操作符右边表中符合where子句的所有记录将会被返回。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 右外连接</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e right join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-5-满（全）外连接（full-join）"><a href="#5-4-5-满（全）外连接（full-join）" class="headerlink" title="5.4.5 满（全）外连接（full join）"></a>5.4.5 满（全）外连接（full join）</h3><p>满外连接：将会返回所有表中符合where语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用null值替代。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 满外连接</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e full join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-6-左半连接（left-semi-join）"><a href="#5-4-6-左半连接（left-semi-join）" class="headerlink" title="5.4.6 左半连接（left semi join）"></a>5.4.6 左半连接（left semi join）</h3><p>左半连接：返回左表&#x2F;数据集中与右表&#x2F;数据集匹配的记录，不会返回左表的所有记录，不会因此形成null值。用于判断一个表的数据在另一个表中是否有相同的数据。可用于替代Hive中in&#x2F;exists类型的子查询（执行计划相同）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select * from tab1</span><br><span class="line">where col1 in (select col1 from tab2)</span><br><span class="line">--用left semi join写法如下</span><br><span class="line">select * from tab1</span><br><span class="line">left semi join tab2 on tab1.col = tab2.col</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong>hive不支持右半连接，semi join比通常的inner join要更高效，因为对于左表中一条指定的记录，在右边表中一旦找到匹配的记录，Hive就会立即停止扫描，左边表中选择的列是可以预测的</p>
<p>left semi join的限制是，右侧表只能在连接条件（on子句）中引用，而不能在where或select子句中引用。</p>
<h3 id="5-4-7-多表连接"><a href="#5-4-7-多表连接" class="headerlink" title="5.4.7 多表连接"></a>5.4.7 多表连接</h3><p>注意：连接n个表，至少需要n-1个连接条件。例如：连接三个表，至少需要两个连接条件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">数据准备：在/opt/module/hive/datas/下：vim location.txt  部门位置<span class="built_in">id</span>  部门位置</span></span><br><span class="line">[root@hadoop102 datas]# vim location.txt</span><br><span class="line">1700	北京</span><br><span class="line">1800	上海</span><br><span class="line">1900	深圳</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 创建位置表</span><br><span class="line">create table if not exists location(</span><br><span class="line">    loc int,           -- 部门位置id</span><br><span class="line">    loc_name string   -- 部门位置</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 导入数据</span><br><span class="line">load data local inpath &#x27;/opt/module/hive/datas/location.txt&#x27; into table location;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 多表连接查询</span><br><span class="line">select e.ename, d.dname, l.loc_name</span><br><span class="line">from emp e join dept d</span><br><span class="line">on e.deptno = d.deptno</span><br><span class="line">join location l</span><br><span class="line">on d.loc = l.loc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_21-43-32.png" alt="Snipaste_2023-10-09_21-43-32" style="zoom:50%;">

<p>大多数情况下，Hive会对每对join连接对象启动一个MapReduce任务。本例中会首先启动一个MapReduce job对表e和表d进行连接操作，然后会再启动一个MapReduce job将第一个MapReduce job的输出和表l进行连接操作。</p>
<h3 id="5-4-8-笛卡尔积"><a href="#5-4-8-笛卡尔积" class="headerlink" title="5.4.8 笛卡尔积"></a>5.4.8 笛卡尔积</h3><p>1）笛卡尔集会在下面条件下产生（在实际生产环境中应该避免）</p>
<p>（1）省略连接条件</p>
<p>（2）连接条件无效</p>
<p>（3）所有表中的所有行互相连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 笛卡尔积写法1</span><br><span class="line">select *</span><br><span class="line">from emp, dept;</span><br><span class="line">-- 笛卡尔积写法2</span><br><span class="line">select *</span><br><span class="line">from emp join dept;</span><br><span class="line">-- 笛卡尔积写法3</span><br><span class="line">select *</span><br><span class="line">from emp join dept</span><br><span class="line">on true;</span><br></pre></td></tr></table></figure>

<p><strong>cross join：返回左右两表连接字段的笛卡尔积</strong></p>
<h3 id="5-4-9-联合（union-amp-union-all）"><a href="#5-4-9-联合（union-amp-union-all）" class="headerlink" title="5.4.9 联合（union&amp;union all）"></a>5.4.9 联合（union&amp;union all）</h3><p>union和union all都是上下拼接sql的结果，这点是和join有区别的，join是左右关联，union和union all是上下拼接。<strong>union去重，union all不去重</strong>。</p>
<p><strong>注意：union连接的一定是select查询语句</strong></p>
<p>union和union all在上下拼接sql结果时有两个要求：</p>
<p>（1）两个sql的结果，列的个数必须相同</p>
<p>（2）两个sql的结果，上下所对应列的类型必须一致</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- 将员工表30部门的员工信息和40部门的员工信息，利用union进行拼接显示。</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where deptno = 30</span><br><span class="line">union</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where deptno = 40;</span><br><span class="line">-- 等价于</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where deptno in (30, 40);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-17-38.png" alt="Snipaste_2023-10-10_12-17-38" style="zoom:50%;">

<h2 id="5-5-排序"><a href="#5-5-排序" class="headerlink" title="5.5 排序"></a>5.5 排序</h2><h3 id="5-5-1-全局排序（order-by）"><a href="#5-5-1-全局排序（order-by）" class="headerlink" title="5.5.1 全局排序（order by）"></a>5.5.1 全局排序（order by）</h3><p>Order By：<strong>全局排序，只有一个Reduce</strong>。asc（ascend）：升序（默认）；desc（descend）：降序</p>
<p><strong>Order By子句在select语句的结尾</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- 查询员工信息按工资升序排列</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">order by sal;</span><br><span class="line">--查询员工信息按工资降序排列</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">order by sal desc;</span><br><span class="line">-- 按照别名排序：按照员工薪水的2倍排序</span><br><span class="line">select ename, sal *2 as two_sal</span><br><span class="line">from emp</span><br><span class="line">order by two_sal;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-32-16.png" alt="Snipaste_2023-10-10_12-32-16" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--多个列排序：按照部门和工资升序排序。</span><br><span class="line">select ename, deptno, sal</span><br><span class="line">from emp</span><br><span class="line">order by deptno, sal;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-42-52.png" alt="Snipaste_2023-10-10_12-42-52" style="zoom: 33%;">

<p>在生产实践中，order by一般不单独使用，因为单独使用最终会汇总到一个大的reduce中进行全局排序，效率低下也容易出问题。所以往往将<strong>order by结合limit一起使用实现TOPN的效果</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--与limit结合使用</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">order by sal desc</span><br><span class="line">limit 5;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-37-57.png" alt="Snipaste_2023-10-10_12-37-57" style="zoom:50%;">

<hr>
<p>以下三个by是hive中特有的，但在实际的工作当中，很少用</p>
<h3 id="5-5-2-每个Reduce内部排序（sort-by）"><a href="#5-5-2-每个Reduce内部排序（sort-by）" class="headerlink" title="5.5.2 每个Reduce内部排序（sort by）"></a>5.5.2 每个Reduce内部排序（sort by）</h3><p>Sort By：对于大规模的数据集order by的效率非常低。在很多情况下，并不需要全局排序，此时可以使用****Sort by****。</p>
<p>Sort by为每个reduce产生一个排序文件。每个Reduce内部进行排序，对全局结果集来说不是排序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--测试sort by</span><br><span class="line">--设置reduce个数</span><br><span class="line">set mapreduce.job.reduces=3;</span><br><span class="line">--根据部门编号降序查看员工信息</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">sort by deptno desc ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-57-18.png" alt="Snipaste_2023-10-10_12-57-18" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--将查询结果导入到文件中（按照部门编号降序排序）</span><br><span class="line">insert overwrite local directory &#x27;/opt/module/hive/datas/sortby-result&#x27;</span><br><span class="line">select * from emp sort by deptno desc;</span><br></pre></td></tr></table></figure>

<p>查看目标路径下的文件：有三个文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# cd /opt/module/hive/datas/sortby-result/</span><br><span class="line">[root@hadoop102 sortby-result]# ll</span><br><span class="line">总用量 12</span><br><span class="line">-rw-r--r--. 1 root root 170 10月 10 12:58 000000_0</span><br><span class="line">-rw-r--r--. 1 root root 176 10月 10 12:58 000001_0</span><br><span class="line">-rw-r--r--. 1 root root  57 10月 10 12:58 000002_0</span><br><span class="line">[root@hadoop102 sortby-result]# cat 000000_0</span><br><span class="line">7844小明销售1500.040</span><br><span class="line">7839小芳销售5000.040</span><br><span class="line">7782金九\N2450.030</span><br><span class="line">7698马八研发2850.030</span><br><span class="line">7654侯七研发1250.030</span><br><span class="line">7788银十行政3000.010</span><br><span class="line">[root@hadoop102 sortby-result]# cat 000001_0</span><br><span class="line">7566赵六销售2975.040</span><br><span class="line">7934小红明讲师1300.030</span><br><span class="line">7900小元讲师950.030</span><br><span class="line">7499李四财务1600.020</span><br><span class="line">7876小李行政1100.010</span><br><span class="line">7521王五行政1250.010</span><br><span class="line">[root@hadoop102 sortby-result]# cat 000002_0</span><br><span class="line">7369张三研发800.030</span><br><span class="line">7902小海行政3000.010</span><br></pre></td></tr></table></figure>

<h3 id="5-5-3-分区（distribute-by）"><a href="#5-5-3-分区（distribute-by）" class="headerlink" title="5.5.3 分区（distribute by）"></a>5.5.3 分区（distribute by）</h3><p>Distribute By：在有些情况下，我们需要控制某个特定行应该到哪个Reducer，通常是为了进行后续的聚集操作。****distribute by*<em><strong>子句可以做这件事。</strong>distribute by</em>*类似MapReduce中partition（自定义分区），进行分区，结合sort by使用。 </p>
<p>对于distribute by进行测试，一定要分配多reduce进行处理，否则无法看到distribute by的效果。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--测试distribute by</span><br><span class="line">--先按照deptno分区，再按照sal排序</span><br><span class="line">set mapreduce.job.reduces=4;</span><br><span class="line">insert overwrite local directory</span><br><span class="line">&#x27;/opt/module/hive/datas/distribute-result&#x27;</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">distribute by deptno</span><br><span class="line">sort by sal desc;</span><br></pre></td></tr></table></figure>

<p>查看目标路径下的文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# cd /opt/module/hive/datas/distribute-result/</span><br><span class="line">[root@hadoop102 distribute-result]# ll</span><br><span class="line">总用量 12</span><br><span class="line">-rw-r--r--. 1 root root 171 10月 10 13:09 000000_0</span><br><span class="line">-rw-r--r--. 1 root root 203 10月 10 13:09 000001_0</span><br><span class="line">-rw-r--r--. 1 root root  29 10月 10 13:09 000002_0</span><br><span class="line">[root@hadoop102 distribute-result]# cat 000000_0</span><br><span class="line">7698马八研发2850.030</span><br><span class="line">7782金九\N2450.030</span><br><span class="line">7934小红明讲师1300.030</span><br><span class="line">7654侯七研发1250.030</span><br><span class="line">7900小元讲师950.030</span><br><span class="line">7369张三研发800.030</span><br><span class="line">[root@hadoop102 distribute-result]# cat 000001_0</span><br><span class="line">7839小芳销售5000.040</span><br><span class="line">7788银十行政3000.010</span><br><span class="line">7902小海行政3000.010</span><br><span class="line">7566赵六销售2975.040</span><br><span class="line">7844小明销售1500.040</span><br><span class="line">7521王五行政1250.010</span><br><span class="line">7876小李行政1100.010</span><br><span class="line">[root@hadoop102 distribute-result]# cat 000002_0</span><br><span class="line">7499李四财务1600.020</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p>distribute by的分区规则是根据分区字段的hash码与reduce的个数进行相除后，余数相同的分到一个区。</p>
<p>Hive要求****distribute by****语句要写在sort by语句之前。</p>
<p>演示完以后mapreduce.job.reduces的值要设置回-1，否则下面分区or分桶表load跑MapReduce的时候会报错。</p>
<h3 id="5-5-4-分区排序（cluster-by）"><a href="#5-5-4-分区排序（cluster-by）" class="headerlink" title="5.5.4 分区排序（cluster by）"></a>5.5.4 分区排序（cluster by）</h3><p>当distribute by和sort by字段相同时，可以使用cluster by方式。</p>
<p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为asc或者desc。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">--测试cluster by</span><br><span class="line">insert overwrite local directory</span><br><span class="line">&#x27;/opt/module/hive/datas/cluster-result&#x27;</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">cluster by deptno;</span><br><span class="line">-- 等价于</span><br><span class="line">insert overwrite local directory</span><br><span class="line">&#x27;/opt/module/hive/datas/cluster-result&#x27;</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">distribute by deptno</span><br><span class="line">sort by deptno;</span><br></pre></td></tr></table></figure>

<p>查看文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 distribute-result]# cd /opt/module/hive/datas/cluster-result/</span><br><span class="line">[root@hadoop102 cluster-result]# ll</span><br><span class="line">总用量 12</span><br><span class="line">-rw-r--r--. 1 root root 171 10月 10 13:21 000000_0</span><br><span class="line">-rw-r--r--. 1 root root 203 10月 10 13:21 000001_0</span><br><span class="line">-rw-r--r--. 1 root root  29 10月 10 13:21 000002_0</span><br><span class="line">[root@hadoop102 cluster-result]# cat 000000_0</span><br><span class="line">7934小红明讲师1300.030</span><br><span class="line">7900小元讲师950.030</span><br><span class="line">7782金九\N2450.030</span><br><span class="line">7698马八研发2850.030</span><br><span class="line">7654侯七研发1250.030</span><br><span class="line">7369张三研发800.030</span><br><span class="line">[root@hadoop102 cluster-result]# cat 000001_0</span><br><span class="line">7788银十行政3000.010</span><br><span class="line">7521王五行政1250.010</span><br><span class="line">7902小海行政3000.010</span><br><span class="line">7876小李行政1100.010</span><br><span class="line">7566赵六销售2975.040</span><br><span class="line">7844小明销售1500.040</span><br><span class="line">7839小芳销售5000.040</span><br><span class="line">[root@hadoop102 cluster-result]# cat 000002_0</span><br><span class="line">7499李四财务1600.020</span><br></pre></td></tr></table></figure>

<h1 id="第六章-综合案例练习（初级）"><a href="#第六章-综合案例练习（初级）" class="headerlink" title="第六章 综合案例练习（初级）"></a>第六章 综合案例练习（初级）</h1><p>需要的表一览：</p>
<p>student_info:</p>
<img src="Snipaste_2023-10-10_13-50-15.png" alt="Snipaste_2023-10-10_13-50-15" style="zoom:50%;">

<p>course_info:</p>
<img src="Snipaste_2023-10-10_13-51-08.png" alt="Snipaste_2023-10-10_13-51-08" style="zoom:50%;">

<p>teacher_info:</p>
<img src="Snipaste_2023-10-10_13-51-59.png" alt="Snipaste_2023-10-10_13-51-59" style="zoom:50%;">

<p>score_info:</p>
<img src="Snipaste_2023-10-10_13-52-37.png" alt="Snipaste_2023-10-10_13-52-37" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">--1.查询姓名中带“冰”的学生名单</span><br><span class="line">select *</span><br><span class="line">from student_info</span><br><span class="line">where stu_name like &quot;%冰%&quot;;</span><br><span class="line">--2.查询姓“王”的老师的个数</span><br><span class="line">select count(*) as wang_count</span><br><span class="line">from teacher_info</span><br><span class="line">where tea_name like &quot;%王%&quot;;</span><br><span class="line">--3.检索课程编号为“04”且分数小于60的学生的课程信息，结果按分数降序排列</span><br><span class="line">select *</span><br><span class="line">from score_info</span><br><span class="line">where course_id = &#x27;04&#x27; and score &lt; 60</span><br><span class="line">order by score desc ;</span><br><span class="line">--4.查询数学成绩不及格的学生和其对应的成绩，按照学号升序排序</span><br><span class="line">select s1.stu_id, s1.stu_name, s2.score</span><br><span class="line">from student_info s1 join score_info s2</span><br><span class="line">on s1.stu_id = s2.stu_id</span><br><span class="line">join course_info c</span><br><span class="line">on c.course_id = s2.course_id</span><br><span class="line">where c.course_name = &#x27;数学&#x27; and s2.score &lt; 60</span><br><span class="line">order by s1.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_14-52-31.png" alt="Snipaste_2023-10-10_14-52-31" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--5. 查询编号为“02”的课程的总成绩</span><br><span class="line">select course_id, sum(score) as score_sum</span><br><span class="line">from score_info</span><br><span class="line">group by course_id</span><br><span class="line">having course_id = &#x27;02&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_14-53-15.png" alt="Snipaste_2023-10-10_14-53-15" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--6. 查询参加考试的学生个数(思路：对成绩表中的学号做去重并count)</span><br><span class="line">select count(distinct stu_id) as stu_num</span><br><span class="line">from score_info;--19</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--7. 查询各科成绩最高和最低的分，以如下的形式显示：课程号，最高分，最低分</span><br><span class="line">select course_id, max(score) as max_score, min(score) as min_score</span><br><span class="line">from score_info</span><br><span class="line">group by course_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_14-58-41.png" alt="Snipaste_2023-10-10_14-58-41" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--8. 查询每门课程有多少学生参加了考试（有考试成绩）</span><br><span class="line">select course_id, count(stu_id) as stu_num</span><br><span class="line">from score_info</span><br><span class="line">group by course_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-01-16.png" alt="Snipaste_2023-10-10_15-01-16" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--9. 查询男生、女生人数</span><br><span class="line">select sex, count(*) as count</span><br><span class="line">from student_info</span><br><span class="line">group by sex;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-16-09.png" alt="Snipaste_2023-10-10_15-16-09" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--10.查询平均成绩大于60分的学生的学号和平均成绩</span><br><span class="line">select stu_id, avg(score) as avg_score</span><br><span class="line">from  score_info</span><br><span class="line">group by stu_id</span><br><span class="line">having avg_score &gt; 60;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-21-47.png" alt="Snipaste_2023-10-10_15-21-47" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--11.查询至少选修四门课程的学生学号</span><br><span class="line">select stu_id, count(course_id) as course_num</span><br><span class="line">from score_info</span><br><span class="line">group by stu_id</span><br><span class="line">having course_num &gt;=4;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-25-15.png" alt="Snipaste_2023-10-10_15-25-15" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--12.查询同姓（假设每个学生姓名的第一个字为姓）的学生名单并统计同姓人数大于等于2的姓</span><br><span class="line">select t1.first_name, count(*) as count_first_name</span><br><span class="line">from(</span><br><span class="line">    select stu_id, stu_name, substr(stu_name,0,1) as first_name</span><br><span class="line">    from student_info</span><br><span class="line">        ) t1</span><br><span class="line">group by t1.first_name</span><br><span class="line">having count_first_name &gt;= 2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-31-30.png" alt="Snipaste_2023-10-10_15-31-30" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--13.查询每门课程的平均成绩，结果按平均成绩升序排序，平均成绩相同时，按课程号降序排列</span><br><span class="line">select course_id, avg(score) as avg_score</span><br><span class="line">from score_info</span><br><span class="line">group by course_id</span><br><span class="line">order by avg_score, course_id desc ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-34-04.png" alt="Snipaste_2023-10-10_15-34-04" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--14.统计参加考试人数大于等于15的学科</span><br><span class="line">select course_id, count(stu_id) as exam_num</span><br><span class="line">from score_info</span><br><span class="line">group by course_id</span><br><span class="line">having exam_num &gt;= 15;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-36-30.png" alt="Snipaste_2023-10-10_15-36-30" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--15.查询每个学生的总成绩并按照总成绩降序排序</span><br><span class="line">select stu_id, sum(score) as sum_score</span><br><span class="line">from score_info</span><br><span class="line">group by stu_id</span><br><span class="line">order by sum_score desc ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-38-51.png" alt="Snipaste_2023-10-10_15-38-51" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">--16.按照如下格式显示学生的语文、数学、英语三科成绩，没有成绩的输出为0，按照学生的有效平均成绩降序显示</span><br><span class="line">--学生id 语文 数学 英语 有效课程数 有效平均成绩</span><br><span class="line">select</span><br><span class="line">       t4.stu_id as `学生id`,</span><br><span class="line">       nvl(t1.score,0) as `语文`,</span><br><span class="line">       nvl(t2.score,0) as `数学`,</span><br><span class="line">       nvl(t3.score,0) as `英语`,</span><br><span class="line">       `有效课程数`,</span><br><span class="line">       `平均成绩`</span><br><span class="line">from (</span><br><span class="line">    select stu_id, score</span><br><span class="line">    from score_info</span><br><span class="line">    where course_id = &#x27;01&#x27;--查询所有学生的语文成绩</span><br><span class="line">         ) t1</span><br><span class="line">    full join (</span><br><span class="line">        select stu_id, score</span><br><span class="line">        from score_info</span><br><span class="line">        where course_id = &#x27;02&#x27;--查询所有学生的数学成绩</span><br><span class="line">    ) t2 on t1.stu_id = t2.stu_id</span><br><span class="line">    full join (</span><br><span class="line">        select stu_id, score</span><br><span class="line">        from score_info</span><br><span class="line">        where course_id = &#x27;03&#x27;--查询所有学生的英语成绩</span><br><span class="line">    ) t3 on nvl(t1.stu_id, t2.stu_id) = t3.stu_id</span><br><span class="line">    full join (</span><br><span class="line">        select stu_id, count(*) as `有效课程数`, avg(score) as `平均成绩`</span><br><span class="line">        from score_info</span><br><span class="line">        group by stu_id</span><br><span class="line">    ) t4 on coalesce(t1.stu_id, t2.stu_id, t3.stu_id) = t4.stu_id</span><br><span class="line">order by `平均成绩` desc;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- 第二种解法：sum(if()):有条件的聚合</span><br><span class="line">select stu_id                              as `学生id`,</span><br><span class="line">       sum(if(course_id = &quot;01&quot;, score, 0)) as `语文`,</span><br><span class="line">       sum(if(course_id = &quot;02&quot;, score, 0)) as `数学`,</span><br><span class="line">       sum(if(course_id = &quot;03&quot;, score, 0)) as `英语`,</span><br><span class="line">       count(*)                            as `有效课程数`,</span><br><span class="line">       avg(score)                          as `有效平均成绩`</span><br><span class="line">from score_info</span><br><span class="line">group by stu_id</span><br><span class="line">order by `有效平均成绩` desc;</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<p>nvl(expr1, expr2)：若expr1为Null，则返回expr2，否则返回expr1</p>
<p>COALESCE(a1,a2,……,an)：返回a1,a2,……,an中遇到的第一个不为NULL的值</p>
<img src="Snipaste_2023-10-10_16-17-55.png" alt="Snipaste_2023-10-10_16-17-55" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 3.4.3 查询一共参加三门课程且其中一门为语文课程的学生的id和姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id, sum(if(course_id = &#x27;01&#x27;, 1, 0)) as flag</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having count(*) = 3</span><br><span class="line">            and flag = 1</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on t1.stu_id = s.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_21-46-10.png" alt="Snipaste_2023-10-17_21-46-10" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">-- 4.1.1 查询所有课程成绩均小于60分的学生的学号、姓名</span><br><span class="line">-- 思路1：所有课程分数小于60，证明其所有成绩的最高分也小于60，我们只需要把每个学生的成绩最高分筛选出来，再选择小于60的即可</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id,</span><br><span class="line">                max(score) as max_score</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having max_score &lt; 60</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s</span><br><span class="line">              on s.stu_id = t1.stu_id;</span><br><span class="line">              </span><br><span class="line">-- 思路2：所有课程分数均小于60，可以使用sum(if())有条件聚合，只有某个学生的成绩大于等于60就设置为flag为1，否则为0，最后相加flag，</span><br><span class="line">-- 如果flag为0，就说明，所有课程成绩都小于60分</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id, sum(if(score &gt;= 60, 1, 0)) as flag</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having flag = 0</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on s.stu_id = t1.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_21-52-37.png" alt="Snipaste_2023-10-17_21-52-37" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 4.1.2 查询没有学全所有课的学生的学号、姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id, collect_list(course_id) as per_course_list</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having size(per_course_list) &lt; 5</span><br><span class="line">     ) t1</span><br><span class="line">join student_info s on s.stu_id = t1.stu_id</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-06-44.png" alt="Snipaste_2023-10-18_11-06-44" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 4.1.3 查询出只选修了三门课程的全部学生的学号和姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id, collect_list(course_id) as per_course_list</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having size(per_course_list) = 3</span><br><span class="line">     ) t1</span><br><span class="line">join student_info s on s.stu_id = t1.stu_id</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-08-58.png" alt="Snipaste_2023-10-18_11-08-58" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.1 查询有两门及以上的课程不及格的同学的学号及其平均成绩</span><br><span class="line">select stu_id, avg_score</span><br><span class="line">from (</span><br><span class="line">         select stu_id, sum(if(score &lt; 60, 1, 0)) as not_hege_course_ct, avg(score) as avg_score</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having not_hege_course_ct &gt;= 2</span><br><span class="line">     ) t1</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-18-24.png" alt="Snipaste_2023-10-18_11-18-24" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.2 查询所有学生的学号、姓名、选课数、总成绩</span><br><span class="line">select s.stu_id,</span><br><span class="line">       s.stu_name,</span><br><span class="line">       count(sc.course_id) as count_course,</span><br><span class="line">       sum(sc.score)       as sum_score</span><br><span class="line">from student_info s</span><br><span class="line">         left join score_info sc on s.stu_id = sc.stu_id</span><br><span class="line">group by s.stu_id, s.stu_name;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-23-24.png" alt="Snipaste_2023-10-18_11-23-24" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.3 查询平均成绩大于85的所有学生的学号、姓名和平均成绩</span><br><span class="line">select s.stu_id, stu_name, avg_score</span><br><span class="line">from (</span><br><span class="line">         select stu_id, avg(score) avg_score</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having avg_score &gt; 85</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on s.stu_id = t1.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-28-32.png" alt="Snipaste_2023-10-18_11-28-32" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.5 查询出每门课程的及格人数和不及格人数</span><br><span class="line">select c.course_id, course_name, `及格人数`, `不及格人数`</span><br><span class="line">from (</span><br><span class="line">         select course_id,</span><br><span class="line">                sum(if(score &gt;= 60, 1, 0)) as `及格人数`,</span><br><span class="line">                sum(if(score &lt; 60, 1, 0))  as `不及格人数`</span><br><span class="line">         from score_info</span><br><span class="line">         group by course_id</span><br><span class="line">     ) t1</span><br><span class="line">         join course_info c on c.course_id = t1.course_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-39-08.png" alt="Snipaste_2023-10-18_11-39-08" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.6 查询课程编号为03且课程成绩在80分以上的学生的学号和姓名及课程信息</span><br><span class="line">select s.stu_id, stu_name, score, course_id</span><br><span class="line">from (</span><br><span class="line">         select stu_id, score, course_id</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id = &#x27;03&#x27;</span><br><span class="line">           and score &gt; 80</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on t1.stu_id = s.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-45-12.png" alt="Snipaste_2023-10-18_11-45-12" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.1 课程编号为&quot;01&quot;且课程分数小于60，按分数降序排列的学生信息</span><br><span class="line">select s.stu_id, stu_name, birthday, sex, score</span><br><span class="line">from (</span><br><span class="line">         select stu_id, course_id, score</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id = &#x27;01&#x27;</span><br><span class="line">           and score &lt; 60</span><br><span class="line">     ) t1</span><br><span class="line">join student_info s on s.stu_id = t1.stu_id</span><br><span class="line">order by score desc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-49-39.png" alt="Snipaste_2023-10-18_11-49-39" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.2 查询所有课程成绩在70分以上的学生的姓名、课程名称和分数，按分数升序排列</span><br><span class="line">select s.stu_id, stu_name, course_name, score</span><br><span class="line">from (</span><br><span class="line">         select stu_id,</span><br><span class="line">                min(score) min_score</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having min_score &gt;= 70</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on s.stu_id = t1.stu_id</span><br><span class="line">         left join score_info s1 on s.stu_id = s1.stu_id</span><br><span class="line">         left join course_info c on c.course_id = s1.course_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_12-01-19.png" alt="Snipaste_2023-10-18_12-01-19" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.4 查询课程编号为“01”的课程比“02”的课程成绩高的所有学生的学号</span><br><span class="line">select t1.stu_id</span><br><span class="line">from (</span><br><span class="line">         select stu_id, course_id, score</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id = &#x27;01&#x27;</span><br><span class="line">     ) t1</span><br><span class="line">         join</span><br><span class="line">     (</span><br><span class="line">         select stu_id, course_id, score</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id = &#x27;02&#x27;</span><br><span class="line">     ) t2 on t1.stu_id = t2.stu_id</span><br><span class="line">where t1.score &gt; t2.score;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_14-50-08.png" alt="Snipaste_2023-10-18_14-50-08" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.5 查询学过编号为“01”的课程并且也学过编号为“02”的课程的学生的学号、姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id,</span><br><span class="line">                sum(if(course_id = &#x27;01&#x27;, 1, 0)) as c_id_01,</span><br><span class="line">                sum(if(course_id = &#x27;02&#x27;, 1, 0)) as c_id_02</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having c_id_01 = 1</span><br><span class="line">            and c_id_02 = 1</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on s.stu_id = t1.stu_id</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_14-58-43.png" alt="Snipaste_2023-10-18_14-58-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.6 查询学过“李体音”老师所教的所有课的同学的学号、姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id in (</span><br><span class="line">             select course_id</span><br><span class="line">             from course_info c</span><br><span class="line">                      join teacher_info t</span><br><span class="line">                           on c.tea_id = t.tea_id</span><br><span class="line">             where tea_name = &#x27;李体音&#x27;</span><br><span class="line">         )</span><br><span class="line">         group by stu_id</span><br><span class="line">         having count(*) = 2</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on t1.stu_id = s.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-07-49.png" alt="Snipaste_2023-10-18_15-07-49" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.7 [课堂讲解]查询学过“李体音”老师所讲授的任意一门课程的学生的学号、姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id in (</span><br><span class="line">             select course_id</span><br><span class="line">             from course_info c</span><br><span class="line">                      join teacher_info t</span><br><span class="line">                           on c.tea_id = t.tea_id</span><br><span class="line">             where tea_name = &#x27;李体音&#x27;</span><br><span class="line">         )</span><br><span class="line">         group by stu_id</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on t1.stu_id = s.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-34-02.png" alt="Snipaste_2023-10-18_15-34-02" style="zoom:50%;">





<h1 id="第七章-函数"><a href="#第七章-函数" class="headerlink" title="第七章 函数"></a>第七章 函数</h1><p>Hive提供了大量的内置函数，按照其特点可大致分为如下几类：单行函数、聚合函数、炸裂函数、窗口函数。</p>
<h2 id="7-0-发现和描述函数"><a href="#7-0-发现和描述函数" class="headerlink" title="7.0 发现和描述函数"></a>7.0 发现和描述函数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show function;--可以列举出当前Hive会话中所加载的所有函数名称，其中包括内置的和用户加载进来的函数</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-16_10-37-39.png" alt="Snipaste_2024-06-16_10-37-39" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">describe function concat;--展示对应函数的简短介绍</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-16_10-39-50.png" alt="Snipaste_2024-06-16_10-39-50"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">describe function extended concat;--函数可能包含更多的详细文档，可以通过增加extended关键在进行查看</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-16_10-42-17.png" alt="Snipaste_2024-06-16_10-42-17"></p>
<h2 id="7-1-单行函数"><a href="#7-1-单行函数" class="headerlink" title="7.1 单行函数"></a>7.1 单行函数</h2><p>单行函数的特点是一进一出，即输入一行，输出一行。</p>
<p>单行函数按照功能可分为如下几类: 日期函数、字符串函数、集合函数、数学函数、流程控制函数等。</p>
<h3 id="7-1-1-算术运算函数"><a href="#7-1-1-算术运算函数" class="headerlink" title="7.1.1 算术运算函数"></a>7.1.1 算术运算函数</h3><img src="Snipaste_2023-10-10_20-49-10.png" alt="Snipaste_2023-10-10_20-49-10" style="zoom:50%;">

<h3 id="7-1-2-数值函数"><a href="#7-1-2-数值函数" class="headerlink" title="7.1.2 数值函数"></a>7.1.2 数值函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--round：四舍五入</span><br><span class="line">select round(3.3);</span><br><span class="line">--3</span><br><span class="line">-- ceil：向上取整</span><br><span class="line">select ceil(3.1);</span><br><span class="line">--4</span><br><span class="line">-- floor：向下取整</span><br><span class="line">select floor(4.8);</span><br><span class="line">--4</span><br></pre></td></tr></table></figure>

<h3 id="7-1-3-字符串函数"><a href="#7-1-3-字符串函数" class="headerlink" title="7.1.3 字符串函数"></a>7.1.3 字符串函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 1. substring：截取字符串</span><br><span class="line">-- 获取第二个字符以后的所有字符（正向索引从1开始,负向索引从-1开始）</span><br><span class="line">select substring(&quot;atguigu&quot;,2);</span><br><span class="line">--tguigu</span><br><span class="line">-- 获取倒数第三个字符以后的所有字符</span><br><span class="line">select substring(&quot;atguigu&quot;,-3);</span><br><span class="line">--igu</span><br><span class="line">-- 从第3个字符开始，向后获取2个字符</span><br><span class="line">select substring(&quot;atguigu&quot;,3,2);</span><br><span class="line">--gu</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 2.replace ：替换</span><br><span class="line">-- replace(string A, string B, string C)--将字符串A中的子字符串B替换为C。</span><br><span class="line">select replace(&#x27;atguigu&#x27;, &#x27;a&#x27;, &#x27;A&#x27;);</span><br><span class="line">--Atguigu</span><br><span class="line">select replace(&#x27;atguigu&#x27;, &#x27;gu&#x27;, &#x27;GU&#x27;); --全局替换</span><br><span class="line">--atGUiGU</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">--3.regexp_replace：正则替换</span><br><span class="line">/**</span><br><span class="line">    语法：regexp_replace(string A, string B, string C)</span><br><span class="line">    返回值：string</span><br><span class="line">    说明：将字符串A中的符合java正则表达式B的部分替换为C。注意，在有些情况下要使用转义字符。</span><br><span class="line"> */</span><br><span class="line">select regexp_replace(&#x27;100-200&#x27;, &#x27;(\\d+)&#x27;, &#x27;num&#x27;);</span><br><span class="line">--num-num</span><br><span class="line">select regexp_replace(&#x27;abc-1022-def&#x27;, &#x27;[0-9]+&#x27;, &#x27;*&#x27;);</span><br><span class="line">--abc-*-def</span><br><span class="line">select regexp_replace(&#x27;abc-1022-def&#x27;, &#x27;[0-9]&#x27;, &#x27;*&#x27;);</span><br><span class="line">--abc-****-def</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--4.regexp：正则匹配</span><br><span class="line">/**</span><br><span class="line">    语法：字符串 regexp 正则表达式</span><br><span class="line">    返回值：boolean</span><br><span class="line">    说明：若字符串符合正则表达式，则返回true，否则返回false。</span><br><span class="line"> */</span><br><span class="line">select &#x27;string&#x27; regexp &#x27;.*tr.*&#x27;;</span><br><span class="line">--true</span><br><span class="line">select &#x27;dfsaaaa&#x27; regexp &#x27;dfsa+&#x27;;</span><br><span class="line">-- true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--5. repeat：重复字符串</span><br><span class="line">/**</span><br><span class="line">    语法：repeat(string A, int n)</span><br><span class="line">    返回值：string</span><br><span class="line">    说明：将字符串A重复n遍。</span><br><span class="line"> */</span><br><span class="line">select repeat(&#x27;123&#x27;, 3);</span><br><span class="line">-- 123123123</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--6. split ：字符串切割</span><br><span class="line">/**</span><br><span class="line">    语法：split(string str, string pat)</span><br><span class="line">    返回值：array</span><br><span class="line">    说明：按照正则表达式pat匹配到的内容分割str，分割后的字符串，以数组的形式返回。</span><br><span class="line"> */</span><br><span class="line">select split(&#x27;a-b-c-d&#x27;,&#x27;-&#x27;);</span><br><span class="line">-- [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]</span><br><span class="line">select split(&#x27;192.168.10.102&#x27;, &#x27;\\.&#x27;);</span><br><span class="line">-- [&quot;192&quot;,&quot;168&quot;,&quot;10&quot;,&quot;102&quot;]</span><br><span class="line"></span><br><span class="line">--7. nvl ：替换null值</span><br><span class="line">/**</span><br><span class="line">  语法：nvl(A,B)</span><br><span class="line">  说明：若A的值不为null，则返回A，否则返回B</span><br><span class="line"> */</span><br><span class="line">select nvl(null,1);</span><br><span class="line">--1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--8. concat ：拼接字符串</span><br><span class="line">/**</span><br><span class="line">语法：concat(string A, string B, string C, ……)</span><br><span class="line">返回：string</span><br><span class="line">说明：将A,B,C……等字符拼接为一个字符串</span><br><span class="line"> */</span><br><span class="line">select concat(&#x27;beijing&#x27;,&#x27;-&#x27;,&#x27;shanghai&#x27;,&#x27;-&#x27;,&#x27;shenzhen&#x27;);</span><br><span class="line">-- beijing-shanghai-shenzhen</span><br><span class="line">select &#x27;beijing&#x27;||&#x27;-&#x27;||&#x27;shanghai&#x27;||&#x27;-&#x27;||&#x27;shenzhen&#x27;;</span><br><span class="line">-- beijing-shanghai-shenzhen</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--9.concat_ws：以指定分隔符拼接字符串或者字符串数组</span><br><span class="line">/**</span><br><span class="line">语法：concat_ws(string A, string…| array(string))</span><br><span class="line">返回值：string</span><br><span class="line">说明：使用分隔符A拼接多个字符串，或者一个数组的所有元素。</span><br><span class="line"> */</span><br><span class="line">select concat_ws(&#x27;-&#x27;,&#x27;beijing&#x27;,&#x27;shanghai&#x27;,&#x27;shenzhen&#x27;);</span><br><span class="line">-- beijing-shanghai-shenzhen</span><br><span class="line">select concat_ws(&#x27;-&#x27;,array(&#x27;beijing&#x27;,&#x27;shenzhen&#x27;,&#x27;shanghai&#x27;));</span><br><span class="line">--beijing-shenzhen-shanghai</span><br></pre></td></tr></table></figure>

<p><strong>nvl()与coalesce()的区别:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvl(参数1,参数2);--如果第一个参数为null，则返回第二个参数，如果第一个参数不为null，则返回第一个参数</span><br><span class="line">coalesce(参数1,参数2,参数3....参数n);--从左往右数，遇到第一个非null值，则返回该非null值</span><br></pre></td></tr></table></figure>

<p><strong>关于JSON字符串的说明</strong></p>
<p>JSON通常用于Web项目前后端的交互上，做大数据一般不会涉及这个前后端的交互。我们的数据通常来源于业务系统，采集到的数据通常是JSON格式的字符串。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;1001&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">10</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;1001&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">10</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;1001&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">10</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;1001&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">10</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--10.get_json_object：解析json字符串</span><br><span class="line">/**</span><br><span class="line">语法：get_json_object(string json_string, string path)</span><br><span class="line">返回值：string</span><br><span class="line">说明：解析json的字符串json_string，返回path指定的内容。如果输入的json字符串无效，那么返回NULL。</span><br><span class="line"> */</span><br><span class="line">--获取json数组里面的json具体数据，其中$指代的就是传入的Json字符串本身</span><br><span class="line">select get_json_object(&#x27;[&#123;&quot;name&quot;:&quot;大海海&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;25&quot;&#125;,&#123;&quot;name&quot;:&quot;小宋宋&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;47&quot;&#125;]&#x27;,&#x27;$.[0]&#x27;);</span><br><span class="line">--&#123;&quot;name&quot;:&quot;大海海&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;25&quot;&#125;</span><br><span class="line">select get_json_object(&#x27;[&#123;&quot;name&quot;:&quot;大海海&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;25&quot;&#125;,&#123;&quot;name&quot;:&quot;小宋宋&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;47&quot;&#125;]&#x27;,&#x27;$.[0].name&#x27;);</span><br><span class="line">--大海海</span><br></pre></td></tr></table></figure>

<h3 id="7-1-4-日期函数"><a href="#7-1-4-日期函数" class="headerlink" title="7.1.4 日期函数"></a>7.1.4 日期函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">--1.unix_timestamp：返回当前或指定时间的时间戳</span><br><span class="line">-- 说明：-前面是日期后面是指，日期传进来的具体格式</span><br><span class="line">select unix_timestamp();--如果不传参数，默认返回当前日期的时间戳</span><br><span class="line">-- 1697520215</span><br><span class="line">select unix_timestamp(&#x27;2022/08/08 08-08-08&#x27;,&#x27;yyyy/MM/dd HH-mm-ss&#x27;); --获取指定时间的时间戳</span><br><span class="line">-- 1659946088</span><br><span class="line"></span><br><span class="line">-- 2.from_unixtime：转化UNIX时间戳（从 1970-01-01 00:00:00 UTC 到指定时间的秒数）到当前时区的时间格式</span><br><span class="line">select from_unixtime(1659946088);</span><br><span class="line">-- 2022-08-08 08:08:08</span><br><span class="line">select from_utc_timestamp(cast(1697519302 as BIGINT)*1000, &#x27;GMT+8&#x27;);</span><br><span class="line">-- 2023-10-17 13:08:22.000000000</span><br><span class="line"></span><br><span class="line">-- 3.current_date：当前日期</span><br><span class="line">select current_date;--2023-10-17</span><br><span class="line"></span><br><span class="line">-- 4.current_timestamp：当前的日期加时间，并且精确的毫秒</span><br><span class="line">select current_timestamp;--2023-10-17 13:28:22.389000000</span><br><span class="line"></span><br><span class="line">-- 5.month：获取日期中的月</span><br><span class="line">/*</span><br><span class="line"> 语法：month (string date)</span><br><span class="line"> 返回值：int</span><br><span class="line"> */</span><br><span class="line">select month(&quot;2022-09-08 08:09:45&quot;);  --9</span><br><span class="line"></span><br><span class="line">--6.day：获取日期中的日</span><br><span class="line">/*</span><br><span class="line"> 语法：day (string date)</span><br><span class="line"> 返回值：int</span><br><span class="line"> */</span><br><span class="line">select day(&quot;2022-09-08 08:09:45&quot;);  --8</span><br><span class="line"></span><br><span class="line">--7.hour：获取日期中的小时</span><br><span class="line">select hour(&#x27;2022-08-08 12:08:08&#x27;);  --12</span><br><span class="line"></span><br><span class="line">--8.datediff：两个日期相差的天数（结束日期减去开始日期的天数）</span><br><span class="line">/*</span><br><span class="line"> 语法：datediff(string enddate, string startdate)</span><br><span class="line"> 返回值：int</span><br><span class="line"> */</span><br><span class="line">select datediff(&#x27;2023-08-08&#x27;,&#x27;2022-10-09&#x27;);  --303</span><br><span class="line">select datediff(&#x27;2021-08-08&#x27;,&#x27;2022-10-09&#x27;);  -- -427</span><br><span class="line"></span><br><span class="line">--9.date_add：日期加天数</span><br><span class="line">/*</span><br><span class="line"> 语法：date_add(string startdate, int days)</span><br><span class="line"> 返回值：string</span><br><span class="line"> 说明：返回开始日期 startdate 增加 days 天后的日期</span><br><span class="line"> */</span><br><span class="line">select date_add(&quot;2023-04-18&quot;,100);  --2023-07-27</span><br><span class="line"></span><br><span class="line">--10.date_sub：日期减天数</span><br><span class="line">select date_sub(&quot;2023-04-18&quot;,100);  --2023-01-08</span><br><span class="line"></span><br><span class="line">--11.date_format:将标准日期解析成指定格式字符串</span><br><span class="line">select date_format(&#x27;2023-04-18&#x27;, &#x27;yyyy年-MM月-dd日&#x27;); --2023年-04月-18日</span><br></pre></td></tr></table></figure>

<h3 id="7-1-5-流程控制函数"><a href="#7-1-5-流程控制函数" class="headerlink" title="7.1.5 流程控制函数"></a>7.1.5 流程控制函数</h3><p>（1）case when：条件判断函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 语法一：case when a then b [when c then d]* [else e] end</span><br><span class="line"> 返回值：T</span><br><span class="line"> 说明：如果a为true，则返回b；如果c为true，则返回d；否则返回 e</span><br><span class="line"> */</span><br><span class="line">-- 需求：对表score_info表中的成绩进行等级划分</span><br><span class="line">select stu_id, course_id,</span><br><span class="line">       case</span><br><span class="line">           when score &gt;= 90 then &#x27;A&#x27;</span><br><span class="line">           when score &gt;= 80 then &#x27;B&#x27;</span><br><span class="line">           when score &gt;= 70 then &#x27;C&#x27;</span><br><span class="line">           when score &gt;= 60 then &#x27;D&#x27;</span><br><span class="line">           else &#x27;不及格&#x27;</span><br><span class="line">       end</span><br><span class="line">from db_hive.score_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_15-01-17.png" alt="Snipaste_2023-10-17_15-01-17" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 等值判断</span><br><span class="line"> 语法二： case a when b then c [when d then e]* [else f] end</span><br><span class="line"> 返回值: T</span><br><span class="line"> 说明：如果a等于b，那么返回c；如果a等于d，那么返回e；否则返回f</span><br><span class="line"> */</span><br><span class="line"> select stu_id,</span><br><span class="line">       case course_id</span><br><span class="line">           when 01 then &#x27;语文&#x27;</span><br><span class="line">           when 02 then &#x27;数学&#x27;</span><br><span class="line">           when 03 then &#x27;英语&#x27;</span><br><span class="line">           when 04 then &#x27;体育&#x27;</span><br><span class="line">           when 05 then &#x27;音乐&#x27;</span><br><span class="line">       end,</span><br><span class="line">       score</span><br><span class="line">from db_hive.score_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_15-06-39.png" alt="Snipaste_2023-10-17_15-06-39" style="zoom:50%;">

<p>（2）if：条件判断，类似于java中的三元运算符</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 语法：if（boolean testCondition, T valueTrue, T valueFalseOrNull）</span><br><span class="line"> 返回值：T</span><br><span class="line"> 说明：当条件testCondition为true时，返回valueTrue；否则返回valueFalseOrNull</span><br><span class="line"> */</span><br><span class="line">select stu_id,course_id,</span><br><span class="line">       `if`(score &gt;= 85, &#x27;高分&#x27;, &#x27;低分&#x27;)</span><br><span class="line">from db_hive.score_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_15-15-37.png" alt="Snipaste_2023-10-17_15-15-37" style="zoom:50%;">

<h3 id="7-1-6-集合函数"><a href="#7-1-6-集合函数" class="headerlink" title="7.1.6 集合函数"></a>7.1.6 集合函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">-- （1）array 声明array集合</span><br><span class="line">/*</span><br><span class="line"> 语法：array(val1, val2, …)</span><br><span class="line"> 说明：根据输入的参数构建数组array类</span><br><span class="line"> */</span><br><span class="line">select `array`(&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;4&#x27;,&#x27;5&#x27;);</span><br><span class="line">-- [&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;]</span><br><span class="line"></span><br><span class="line">-- （2）array_contains: 判断array中是否包含某个元素</span><br><span class="line">select array_contains(`array`(&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;4&#x27;,&#x27;5&#x27;), &#x27;1&#x27;);</span><br><span class="line">-- true</span><br><span class="line"></span><br><span class="line">-- （3）sort_array：将array中的元素排序，默认升序</span><br><span class="line">select sort_array(`array`(2,3,4,5,9,23,67,21));</span><br><span class="line">-- [2,3,4,5,9,21,23,67]</span><br><span class="line"></span><br><span class="line">-- （4）size：集合中元素的个数（集合长度）</span><br><span class="line">select size(`array`(2,3,4,5,9,23,67,21)); --8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--（5）map：创建map集合</span><br><span class="line">/*</span><br><span class="line"> 语法：map (key1, value1, key2, value2, …)</span><br><span class="line"> 说明：根据输入的key和value对构建map类型</span><br><span class="line"> */</span><br><span class="line">select `map`(&#x27;xiaowang&#x27;, 1, &#x27;xiaoliu&#x27;, 2);</span><br><span class="line">-- &#123;&quot;xiaowang&quot;:1,&quot;xiaoliu&quot;:2&#125;</span><br><span class="line"></span><br><span class="line">-- （6）map_keys： 返回map中的key；map_values: 返回map中的value</span><br><span class="line">select map_keys( `map`(&#x27;xiaowang&#x27;, 1, &#x27;xiaoliu&#x27;, 2));</span><br><span class="line">-- [&quot;xiaowang&quot;,&quot;xiaoliu&quot;]</span><br><span class="line"></span><br><span class="line">select map_values(`map`(&#x27;xiaowang&#x27;, 1, &#x27;xiaoliu&#x27;, 2));</span><br><span class="line">-- [1,2]</span><br><span class="line"></span><br><span class="line">-- （7）struct声明struct中的各属性</span><br><span class="line">/*</span><br><span class="line"> 语法：struct(val1, val2, val3, …)</span><br><span class="line"> 说明：根据输入的参数构建结构体struct类</span><br><span class="line"> */</span><br><span class="line">select struct(&#x27;name&#x27;, &#x27;age&#x27;, &#x27;weight&#x27;);</span><br><span class="line">-- &#123;&quot;col1&quot;:&quot;name&quot;,&quot;col2&quot;:&quot;age&quot;,&quot;col3&quot;:&quot;weight&quot;&#125;</span><br><span class="line"></span><br><span class="line">-- （8）named_struct声明struct的属性和值</span><br><span class="line">select named_struct(&#x27;name&#x27;,&#x27;xiaosong&#x27;,&#x27;age&#x27;,18,&#x27;weight&#x27;,80);</span><br><span class="line">-- &#123;&quot;name&quot;:&quot;xiaosong&quot;,&quot;age&quot;:18,&quot;weight&quot;:80&#125;</span><br></pre></td></tr></table></figure>

<h3 id="7-1-7-案例准备"><a href="#7-1-7-案例准备" class="headerlink" title="7.1.7 案例准备"></a>7.1.7 案例准备</h3><p><img src="Snipaste_2023-10-17_15-46-21.png" alt="Snipaste_2023-10-17_15-46-21"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 1）统计每个月的入职人数</span><br><span class="line">select month(replace(hiredate, &#x27;/&#x27;, &#x27;-&#x27;)) as month,count(*) as cn</span><br><span class="line">from employee</span><br><span class="line">group by month(replace(hiredate, &#x27;/&#x27;, &#x27;-&#x27;));</span><br><span class="line">--或</span><br><span class="line">select substr(hiredate, 6, 2) as month, count(*) as cn</span><br><span class="line">from employee</span><br><span class="line">group by substr(hiredate, 6, 2);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_16-11-54.png" alt="Snipaste_2023-10-17_16-11-54" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 2）查询每个人的年龄（年 + 月）</span><br><span class="line">select name, y || &#x27;年&#x27; || m || &#x27;月&#x27; as age</span><br><span class="line">from (</span><br><span class="line">         select name, floor(num_month / 12) y, floor(num_month % 12) m</span><br><span class="line">         from (</span><br><span class="line">                  select name, months_between(current_date(), replace(birthday, &#x27;/&#x27;, &#x27;-&#x27;)) num_month</span><br><span class="line">                  from employee</span><br><span class="line">              ) t1</span><br><span class="line">     ) t2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_16-28-47.png" alt="Snipaste_2023-10-17_16-28-47" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 3）按照薪资，奖金的和进行倒序排序，如果奖金为null，置位0</span><br><span class="line">select name, salary + nvl(bonus, 0) as sal</span><br><span class="line">from employee</span><br><span class="line">order by sal desc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_17-41-43.png" alt="Snipaste_2023-10-17_17-41-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 4）查询每个人有多少个朋友</span><br><span class="line">select name, size(friends) as cnt</span><br><span class="line">from employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_17-43-45.png" alt="Snipaste_2023-10-17_17-43-45" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 5）查询每个人的孩子的姓名</span><br><span class="line">select name, map_keys(children) ch_name</span><br><span class="line">from employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_17-50-18.png" alt="Snipaste_2023-10-17_17-50-18" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">-- 6）查询每个岗位男女各多少人</span><br><span class="line">select nvl(male.job, female.job) job,</span><br><span class="line">       nvl(male.cnt, 0),</span><br><span class="line">       nvl(female.cnt, 0)</span><br><span class="line">from (</span><br><span class="line">         select job, count(*) as cnt</span><br><span class="line">         from employee</span><br><span class="line">         where sex = &#x27;男&#x27;</span><br><span class="line">         group by job</span><br><span class="line">     ) male</span><br><span class="line">         full join</span><br><span class="line">     (</span><br><span class="line">         select job, count(*) as cnt</span><br><span class="line">         from employee</span><br><span class="line">         where sex = &#x27;女&#x27;</span><br><span class="line">         group by job</span><br><span class="line">     ) female</span><br><span class="line">     on male.job = female.job;</span><br><span class="line"></span><br><span class="line">-- 另外的做法：小技巧：sum-if组合实现</span><br><span class="line">select job,</span><br><span class="line">       sum(if(sex = &#x27;男&#x27;, 1, 0)) as male,</span><br><span class="line">       sum(if(sex = &#x27;女&#x27;, 1, 0)) as female</span><br><span class="line">from employee</span><br><span class="line">group by job;</span><br><span class="line"></span><br><span class="line">select job,</span><br><span class="line">       count(if(sex = &#x27;男&#x27;, 1, null)) as male,</span><br><span class="line">       count(if(sex = &#x27;女&#x27;, 1, null)) as female</span><br><span class="line">from employee</span><br><span class="line">group by job;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_17-59-21.png" alt="Snipaste_2023-10-17_17-59-21" style="zoom:50%;">

<h2 id="7-2-高级聚合函数"><a href="#7-2-高级聚合函数" class="headerlink" title="7.2 高级聚合函数"></a>7.2 高级聚合函数</h2><p>多进一出 （多行传入，一个行输出）。</p>
<p>1）普通聚合：count(),  sum(),  max(),   min(),  avg()等函数，见5.2.8节</p>
<p>2）collect_list 收集并形成list集合，结果<strong>不去重</strong></p>
<p>3）collect_set 收集并形成set集合，结果<strong>去重</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select collect_list(job)</span><br><span class="line">from employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_18-25-40.png" alt="Snipaste_2023-10-17_18-25-40" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select collect_set(job)</span><br><span class="line">from employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_18-26-25.png" alt="Snipaste_2023-10-17_18-26-25" style="zoom:50%;">

<h3 id="7-2-1-案例演示"><a href="#7-2-1-案例演示" class="headerlink" title="7.2.1 案例演示"></a>7.2.1 案例演示</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 1）每个月的入职人数以及姓名</span><br><span class="line">select month(replace(hiredate, &#x27;/&#x27;, &#x27;-&#x27;)) as month,</span><br><span class="line">       count(*)                           as cn,</span><br><span class="line">       collect_list(name)                 as name_list</span><br><span class="line">from employee</span><br><span class="line">group by month(replace(hiredate, &#x27;/&#x27;, &#x27;-&#x27;));</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_20-53-58.png" alt="Snipaste_2023-10-17_20-53-58" style="zoom:50%;">

<h2 id="7-3-炸裂函数（重难点）"><a href="#7-3-炸裂函数（重难点）" class="headerlink" title="7.3 炸裂函数（重难点）"></a>7.3 炸裂函数（重难点）</h2><h3 id="7-3-1-概述"><a href="#7-3-1-概述" class="headerlink" title="7.3.1 概述"></a>7.3.1 概述</h3><p>UDTF，接收一行数据，输出一行或多行数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- （1）explode(ARRAY&lt;T&gt; a)</span><br><span class="line">select explode(array(1, 2, 3));</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-55-53.png" alt="Snipaste_2023-10-18_15-55-53" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- （2）explode(Map&lt;K,V&gt; m)</span><br><span class="line">select explode(map(&quot;a&quot;,1,&quot;b&quot;,2,&quot;c&quot;,3)) as (key,value);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-56-55.png" alt="Snipaste_2023-10-18_15-56-55" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- （3）posexplode(ARRAY&lt;T&gt; a)</span><br><span class="line">select posexplode(array(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)) as (pos,item);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-58-10.png" alt="Snipaste_2023-10-18_15-58-10" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- （4）inline(ARRAY&lt;STRUCT&lt;f1:T1,...,fn:Tn&gt;&gt; a)</span><br><span class="line">select inline(array(named_struct(&quot;id&quot;, 1, &quot;name&quot;, &quot;zs&quot;),</span><br><span class="line">                    named_struct(&quot;id&quot;, 2, &quot;name&quot;, &quot;ls&quot;),</span><br><span class="line">                    named_struct(&quot;id&quot;, 3, &quot;name&quot;, &quot;ww&quot;))) as (id, name);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_16-00-44.png" alt="Snipaste_2023-10-18_16-00-44" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-- (5)json_tuple</span><br></pre></td></tr></table></figure>

<p>Latera View 通常与UDTF配合使用。Lateral View可以将UDTF应用到源表的每行数据，将每行数据转换为一行或多行，并将源表中每行的输出结果与该行连接起来，形成一个虚拟表。</p>
<img src="Snipaste_2023-10-18_16-05-59.png" alt="Snipaste_2023-10-18_16-05-59" style="zoom:50%;">



<h3 id="7-3-2-案例演示"><a href="#7-3-2-案例演示" class="headerlink" title="7.3.2 案例演示"></a>7.3.2 案例演示</h3><img src="Snipaste_2023-10-18_16-10-33.png" alt="Snipaste_2023-10-18_16-10-33" style="zoom:50%;">

<p>根据上述电影信息表，统计各分类的电影数量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select movie, split(category, &#x27;,&#x27;) cates</span><br><span class="line">from movie_info;</span><br></pre></td></tr></table></figure>

<img src="1111_2023-10-18_16-21-36.png" alt="Snipaste_2023-10-18_16-21-36" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select movie, cate</span><br><span class="line">from (</span><br><span class="line">         select movie, split(category, &#x27;,&#x27;) cates</span><br><span class="line">         from movie_info</span><br><span class="line">    ) t1 lateral view explode(cates) tmp as cate;</span><br></pre></td></tr></table></figure>

<img src="1123-10-18_16-22-27.png" alt="Snipaste_2023-10-18_16-22-27" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">select cate, count(*)</span><br><span class="line">from (</span><br><span class="line">         select movie, cate</span><br><span class="line">         from (</span><br><span class="line">                  select movie, split(category, &#x27;,&#x27;) cates</span><br><span class="line">                  from movie_info</span><br><span class="line">              ) t1 lateral view explode(cates) tmp as cate</span><br><span class="line">     ) t2</span><br><span class="line">group by cate;</span><br></pre></td></tr></table></figure>

<img src="111112paste_2023-10-18_16-24-10.png" alt="Snipaste_2023-10-18_16-24-10" style="zoom:50%;">

<h2 id="7-4-窗口函数（开窗函数）"><a href="#7-4-窗口函数（开窗函数）" class="headerlink" title="7.4 窗口函数（开窗函数）"></a>7.4 窗口函数（开窗函数）</h2><h3 id="7-4-1-概述"><a href="#7-4-1-概述" class="headerlink" title="7.4.1 概述"></a>7.4.1 概述</h3><p>窗口函数，能为每行数据划分一个窗口，然后对窗口范围内的数据进行计算，最后将计算结果返回给该行数据。</p>
<p>窗口函数的语法中主要包括“窗口”和“函数”两部分。<strong>其中“窗口”用于定义计算范围，“函数”用于定义计算逻辑</strong>。</p>
<img src="22226-34-30.png" alt="Snipaste_2023-10-18_16-34-30" style="zoom:50%;">

<p>①<strong>语法-函数：绝大多数的聚合函数都可以配合窗口使用，例如max(),min(),sum(),count(),avg()等。</strong></p>
<p>②<strong>语法-窗口：窗口范围的定义分为两种类型，一种是基于行的，一种是基于值的</strong></p>
<p><img src="Snipaste_2023-10-18_16-55-01.png" alt="Snipaste_2023-10-18_16-55-01"></p>
<p><img src="333e_2023-10-18_16-56-15.png" alt="Snipaste_2023-10-18_16-56-15"></p>
<p>此时order by[column]必须写，表明按照column列的顺序基于行进行窗口范围划分</p>
<p><img src="Snipaste_2023-10-18_20-16-12.png" alt="Snipaste_2023-10-18_20-16-12"></p>
<p><img src="444023-10-18_19-59-55.png" alt="Snipaste_2023-10-18_19-59-55"></p>
<p>此时order by[column]中的column是基于column字段进行窗口范围划分</p>
<p>③<strong>语法-窗口-分区：定义窗口范围时，可以指定分区字段，每个分区单独划分窗口。  语法：partition by</strong></p>
<p><img src="Snipaste_2023-10-18_20-29-46.png" alt="Snipaste_2023-10-18_20-29-46"></p>
<p>④<strong>语法-窗口-缺省</strong></p>
<img src="Snipaste_2023-10-18_20-38-28.png" alt="Snipaste_2023-10-18_20-38-28" style="zoom:50%;">

<p><img src="Snipaste_2023-10-18_20-39-09.png" alt="Snipaste_2023-10-18_20-39-09"></p>
<h3 id="7-4-2-常用窗口函数"><a href="#7-4-2-常用窗口函数" class="headerlink" title="7.4.2 常用窗口函数"></a>7.4.2 常用窗口函数</h3><p>按照功能，常用窗口可划分为如下几类：聚合函数、跨行取值函数、排名函数。</p>
<ul>
<li>聚合函数：max，min，sum，avg，count</li>
<li>跨行取值函数：lead和lag，first_value和last_value</li>
<li>排名函数：rank，dense_rank，row_number</li>
</ul>
<img src="Snipaste_2023-10-18_20-52-54.png" alt="Snipaste_2023-10-18_20-52-54" style="zoom:50%;">

<p><strong>注：lag和lead函数不支持自定义窗口</strong></p>
<img src="552023-10-18_20-58-47.png" alt="Snipaste_2023-10-18_20-58-47" style="zoom:50%;">

<p>注意：这里面的窗口范围是默认的range[第一行的值，当前行的值]；所以从上到下的窗口范围依次为：</p>
<p>[2022-01-01, 2022-01-01]		first_date:   2022-01-01		last_date:  2022-01-01</p>
<p>[2022-01-01, 2022-01-02]		first_date:   2022-01-01		last_date:  2022-01-02</p>
<p>[2022-01-01, 2022-01-03]		first_date:   2022-01-01		last_date:  2022-01-03</p>
<p>[2022-01-04, 2022-01-04]		first_date:   2022-01-04		last_date:  2022-01-04</p>
<p>[2022-01-04, 2022-01-05]		first_date:   2022-01-04		last_date:  2022-01-05</p>
<p>[2022-01-04, 2022-01-06]		first_date:   2022-01-04		last_date:  2022-01-06</p>
<img src="6ste_2023-10-18_21-15-06.png" alt="Snipaste_2023-10-18_21-15-06" style="zoom:50%;">

<p><strong>注：rank 、dense_rank、row_number不支持自定义窗口。</strong></p>
<h3 id="7-4-3-案例演示"><a href="#7-4-3-案例演示" class="headerlink" title="7.4.3 案例演示"></a>7.4.3 案例演示</h3><img src="Snipaste_2023-10-18_21-17-31.png" alt="Snipaste_2023-10-18_21-17-31" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 1）统计每个用户截至每次下单的累积下单总额</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       sum(order_amount)</span><br><span class="line">           over (partition by user_id order by order_date rows between unbounded preceding and current row ) as sum_so_far</span><br><span class="line">from order_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_21-38-36.png" alt="Snipaste_2023-10-18_21-38-36" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 2）统计每个用户截至每次下单的当月累积下单总额</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       sum(order_amount)</span><br><span class="line">           over (partition by user_id, substring(order_date, 1, 7) order by order_date rows between unbounded preceding and current row) as sum_so_far</span><br><span class="line">from order_info;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-18_21-47-50.png" alt="Snipaste_2023-10-18_21-47-50"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">-- 3）统计每个用户每次下单距离上次下单相隔的天数（首次下单按0天算）</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       nvl(datediff(order_date, last_order_date), 0) as diff</span><br><span class="line">from (</span><br><span class="line">         select order_id,</span><br><span class="line">                user_id,</span><br><span class="line">                user_name,</span><br><span class="line">                order_date,</span><br><span class="line">                order_amount,</span><br><span class="line">                lag(order_date, 1, null) over (partition by user_id order by order_date) as last_order_date</span><br><span class="line">         from order_info</span><br><span class="line">     ) t1;</span><br><span class="line">     </span><br><span class="line">--或者</span><br><span class="line"></span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       datediff(order_date, last_order_date) as diff</span><br><span class="line">from (</span><br><span class="line">         select order_id,</span><br><span class="line">                user_id,</span><br><span class="line">                user_name,</span><br><span class="line">                order_date,</span><br><span class="line">                order_amount,</span><br><span class="line">                lag(order_date, 1, order_date) over (partition by user_id order by order_date) as last_order_date</span><br><span class="line">         from order_info</span><br><span class="line">     ) t1;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-18_22-06-19.png" alt="Snipaste_2023-10-18_22-06-19"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-- 4）查询所有下单记录以及每个用户的每个下单记录所在月份的首/末次下单日期,注意：first_value不需要加窗口范围；last_value需要加窗口范围</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       first_value(order_date, false)</span><br><span class="line">                   over (partition by user_id, substring(order_date, 1, 7) order by order_date)                                                         as first_date,</span><br><span class="line">       last_value(order_date, false)</span><br><span class="line">                  over (partition by user_id, substring(order_date, 1, 7) order by order_date range between unbounded preceding and unbounded following) as last_date</span><br><span class="line">from order_info;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-18_22-19-32.png" alt="Snipaste_2023-10-18_22-19-32"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 5）为每个用户的所有下单记录按照订单金额进行排名</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       rank() over (partition by user_id order by order_amount desc )      as rk,</span><br><span class="line">       dense_rank() over (partition by user_id order by order_amount desc) as drk,</span><br><span class="line">       row_number() over (partition by user_id order by order_amount desc) as rn</span><br><span class="line">from order_info;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-19_09-39-12.png" alt="Snipaste_2023-10-19_09-39-12"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-- 扩展：分组TOPN:【固定套路，要记住】</span><br><span class="line">-- 查询score_info表中每一门科目的前三名（分数最高的前三个）</span><br><span class="line">select course_id,stu_id,score,rk</span><br><span class="line">from (</span><br><span class="line">         select course_id,</span><br><span class="line">                stu_id,</span><br><span class="line">                score,</span><br><span class="line">                rank() over (partition by course_id order by score desc ) as rk</span><br><span class="line">         from db_hive.score_info</span><br><span class="line">     )t1</span><br><span class="line">where rk in (1,2,3);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-19_09-48-16.png" alt="Snipaste_2023-10-19_09-48-16" style="zoom:50%;">

<h2 id="7-5-自定义函数（用的不多）"><a href="#7-5-自定义函数（用的不多）" class="headerlink" title="7.5 自定义函数（用的不多）"></a>7.5 自定义函数（用的不多）</h2><p>Hive自定义了一些函数，如min，max等，但是数量有限，我们可以通过自定义UDF来方便扩展</p>
<img src="Snipaste_2023-10-31_19-53-53.png" alt="Snipaste_2023-10-31_19-53-53" style="zoom:50%;">

<img src="Snipaste_2023-10-31_19-57-23.png" alt="Snipaste_2023-10-31_19-57-23" style="zoom:50%;">

<h2 id="7-6-自定义UDF函数"><a href="#7-6-自定义UDF函数" class="headerlink" title="7.6 自定义UDF函数"></a>7.6 自定义UDF函数</h2><p>（0）需求：自定义一个UDF实现计算给定基本数据类型的长度，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select my_len(&quot;abcd&quot;);</span><br><span class="line">4</span><br></pre></td></tr></table></figure>

<p>（1）创建一个Maven工程Hive</p>
<p>（2）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（3）创建一个类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyLength</span> <span class="keyword">extends</span> <span class="title class_">GenericUDF</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断传进来的参数的类型和长度</span></span><br><span class="line"><span class="comment">     * 约定返回的数据类型</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> ObjectInspector <span class="title function_">initialize</span><span class="params">(ObjectInspector[] arguments)</span> <span class="keyword">throws</span> UDFArgumentException &#123;</span><br><span class="line">        <span class="keyword">if</span> (arguments.length !=<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span>  <span class="keyword">new</span> <span class="title class_">UDFArgumentLengthException</span>(<span class="string">&quot;please give me  only one arg&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!arguments[<span class="number">0</span>].getCategory().equals(ObjectInspector.Category.PRIMITIVE))&#123;</span><br><span class="line">            <span class="keyword">throw</span>  <span class="keyword">new</span> <span class="title class_">UDFArgumentTypeException</span>(<span class="number">1</span>, <span class="string">&quot;i need primitive type arg&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> PrimitiveObjectInspectorFactory.javaIntObjectInspector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解决具体逻辑的</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">evaluate</span><span class="params">(DeferredObject[] arguments)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">o</span> <span class="operator">=</span> arguments[<span class="number">0</span>].get();</span><br><span class="line">        <span class="keyword">if</span>(o==<span class="literal">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> o.toString().length();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">// 用于获取解释的字符串explain</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getDisplayString</span><span class="params">(String[] strings)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）创建临时函数</p>
<p>①打成jar包上传到服务器&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# ll</span><br><span class="line">总用量 20</span><br><span class="line">drwxr-xr-x. 2 root root  117 10月 10 13:21 cluster-result</span><br><span class="line">-rw-r--r--. 1 root root   72 10月  9 15:04 dept.txt</span><br><span class="line">drwxr-xr-x. 2 root root  117 10月 10 13:16 distribute-result</span><br><span class="line">-rw-r--r--. 1 root root  416 10月  9 15:06 emp.txt</span><br><span class="line">-rw-r--r--. 1 root root   10 10月  8 13:44 hive_result.txt</span><br><span class="line">-rw-r--r--. 1 root root   36 10月  9 21:35 location.txt</span><br><span class="line">-rw-r--r--  1 root root 2983 10月 31 21:38 myudf.jar</span><br><span class="line">drwxr-xr-x. 2 root root  117 10月 10 12:58 sortby-result</span><br></pre></td></tr></table></figure>

<p>②将jar包添加到hive的classpath，临时生效</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add jar /opt/module/hive/datas/myudf.jar;</span><br></pre></td></tr></table></figure>

<p>③创建临时函数与开发好的java class关联</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create temporary function my_len</span><br><span class="line">as &quot;com.atguigu.hive.udf.MyLength&quot;;</span><br></pre></td></tr></table></figure>

<p>④即可在hql中使用自定义的临时函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select my_len(&quot;ghghgh&quot;);--6</span><br></pre></td></tr></table></figure>

<p>注意：临时函数只跟会话有关系，跟库没有关系。只要创建临时函数的会话不断，在当前会话下，任意一个库都可以使用，其他会话全都不能使用。</p>
<p>⑤删除临时函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop temporary function my_len;</span><br></pre></td></tr></table></figure>

<p>（5）创建永久函数</p>
<p>在hadoop102网页端新建udf文件夹并上传jar包</p>
<img src="Snipaste_2023-10-31_21-52-13.png" alt="Snipaste_2023-10-31_21-52-13" style="zoom:50%;">

<p>执行创建函数的语句：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create function my_len</span><br><span class="line">as &quot;com.atguigu.hive.udf.MyLength&quot;</span><br><span class="line">using jar &quot;hdfs://hadoop102:8020/udf/myudf.jar&quot;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select my_len(&quot;ghghgh&quot;);--6</span><br></pre></td></tr></table></figure>

<p>注意：永久函数跟会话没有关系，创建函数的会话断了以后，其他会话也可以使用。</p>
<p>永久函数创建的时候，在函数名之前需要自己加上库名，如果不指定库名的话，会默认把当前库的库名给加上。</p>
<p>永久函数使用的时候，需要在指定的库里面操作，或者在其他库里面使用的话加上，<strong>库名.函数名。</strong></p>
<h2 id="7-7-宏命令"><a href="#7-7-宏命令" class="headerlink" title="7.7 宏命令"></a>7.7 宏命令</h2><p>宏命令提供了在HiveSQL中调用其他函数和操作符来定义函数的功能，对于特定的情况，使用宏命令要比使用Java编写UDF方便</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create temporary macro</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create temporary macro sigmoid (x double)</span><br><span class="line">1.0 / (1.0 + exp(-x));</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">create temporary macro get_tfc_type1(stid_mix string)</span><br><span class="line">case when split(stid_mix, &#x27;_&#x27;)[0]=&#x27;0&#x27; then &#x27;未拆分&#x27;</span><br><span class="line">     when split(stid_mix, &#x27;_&#x27;)[0]=&#x27;1&#x27; then &#x27;消费整体&#x27;</span><br><span class="line">     when split(stid_mix, &#x27;_&#x27;)[0]=&#x27;2&#x27; then &#x27;直播整体&#x27;</span><br><span class="line">     when split(stid_mix, &#x27;_&#x27;)[0]=&#x27;3&#x27; then &#x27;电商整体&#x27;</span><br><span class="line">     when split(stid_mix, &#x27;_&#x27;)[0]=&#x27;4&#x27; then &#x27;广告整体&#x27;</span><br><span class="line">     when split(stid_mix, &#x27;_&#x27;)[0]=&#x27;5&#x27; then &#x27;社交整体&#x27;</span><br><span class="line">     when split(stid_mix, &#x27;_&#x27;)[0]=&#x27;6&#x27; then &#x27;流量运营中台整体&#x27;</span><br><span class="line">     when split(stid_mix, &#x27;_&#x27;)[0]=&#x27;7&#x27; then &#x27;本地生活&#x27;</span><br><span class="line">     else &#x27;未知&#x27;</span><br><span class="line">end</span><br><span class="line">;</span><br></pre></td></tr></table></figure>

<h1 id="第八章-综合案例练习（中级）"><a href="#第八章-综合案例练习（中级）" class="headerlink" title="第八章 综合案例练习（中级）"></a>第八章 综合案例练习（中级）</h1><p>用户信息表：</p>
<img src="Snipaste_2023-10-31_14-11-36.png" alt="Snipaste_2023-10-31_14-11-36" style="zoom:50%;">

<p>商品信息表：</p>
<img src="Snipaste_2023-10-31_14-13-44.png" alt="Snipaste_2023-10-31_14-13-44" style="zoom:50%;">

<p>商品分类信息表：</p>
<img src="Snipaste_2023-10-31_14-15-37.png" alt="Snipaste_2023-10-31_14-15-37" style="zoom:50%;">

<p>订单信息表：</p>
<img src="Snipaste_2023-10-31_14-16-41.png" alt="Snipaste_2023-10-31_14-16-41" style="zoom:50%;">

<p>订单明细表：</p>
<img src="Snipaste_2023-10-31_14-18-02.png" alt="Snipaste_2023-10-31_14-18-02" style="zoom:50%;">

<p>登录明细表：</p>
<img src="Snipaste_2023-10-31_14-19-10.png" alt="Snipaste_2023-10-31_14-19-10" style="zoom:50%;">

<p>商品价格变更明细表：</p>
<img src="Snipaste_2023-10-31_14-20-10.png" alt="Snipaste_2023-10-31_14-20-10" style="zoom:50%;">

<p>配送信息表：</p>
<img src="Snipaste_2023-10-31_14-21-06.png" alt="Snipaste_2023-10-31_14-21-06" style="zoom:50%;">

<p>好友关系表：</p>
<img src="Snipaste_2023-10-31_14-21-47.png" alt="Snipaste_2023-10-31_14-21-47" style="zoom:50%;">

<p>收藏信息表：</p>
<img src="Snipaste_2023-10-31_14-22-43.png" alt="Snipaste_2023-10-31_14-22-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--2.1 查询累积销量排名第二的商品</span><br><span class="line">--①查询每个sku_id的商品销量，并按照order_num降序排序,并选取排名第二的这行数据</span><br><span class="line">select sku_id, sum(sku_num) as order_num</span><br><span class="line">from order_detail</span><br><span class="line">group by sku_id</span><br><span class="line">order by order_num desc</span><br><span class="line">limit 1,1;</span><br><span class="line">--②查询①表中的sku_id这列返回</span><br><span class="line">select sku_id</span><br><span class="line">from (</span><br><span class="line">         select sku_id, sum(sku_num) as order_num</span><br><span class="line">         from order_detail</span><br><span class="line">         group by sku_id</span><br><span class="line">         order by order_num desc</span><br><span class="line">         limit 1,1</span><br><span class="line">)t1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_14-47-25.png" alt="Snipaste_2023-10-31_14-47-25" style="zoom:50%;">

<img src="Snipaste_2023-10-31_14-47-50.png" alt="Snipaste_2023-10-31_14-47-50" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">--2.2 查询至少连续三天下单的用户</span><br><span class="line">--思路1</span><br><span class="line">--①查询用户id和下单时间，并去重，三种去重方法（当且仅当user_id和create_date这两个字段同时对应相同时算重复）</span><br><span class="line">select distinct user_id, create_date</span><br><span class="line">from order_info;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">select user_id, create_date</span><br><span class="line">from order_info</span><br><span class="line">group by user_id, create_date;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">select user_id,create_date</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                row_number() over (partition by user_id,create_date) rn</span><br><span class="line">         from order_info</span><br><span class="line">     )t1</span><br><span class="line">where rn = 1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_14-59-09.png" alt="Snipaste_2023-10-31_14-59-09" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--②使用Lead窗口函数，以user_id进行分区且对create_date进行排序，得到新的一列lead2</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       lead(create_date, 2, &#x27;9999-12-31&#x27;) over (partition by user_id order by create_date) as lead2</span><br><span class="line">from (</span><br><span class="line">         select distinct user_id, create_date</span><br><span class="line">         from order_info</span><br><span class="line">     ) t1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_15-30-25.png" alt="Snipaste_2023-10-31_15-30-25" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">--③对查询表②的lead2字段和create_date字段进行减法运算，得到差值diff字段，并筛选diff字段等于2的行</span><br><span class="line">select user_id,</span><br><span class="line">       datediff(lead2, create_date) as diff</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                lead(create_date, 2, &#x27;9999-12-31&#x27;) over (partition by user_id order by create_date) as lead2</span><br><span class="line">         from (</span><br><span class="line">                  select distinct user_id, create_date</span><br><span class="line">                  from order_info</span><br><span class="line">              ) t1</span><br><span class="line">     ) t2</span><br><span class="line">where datediff(lead2, create_date) = 2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_15-31-04.png" alt="Snipaste_2023-10-31_15-31-04" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--④选择查询表③的user_id字段，并去重</span><br><span class="line">select distinct user_id</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                datediff(lead2, create_date) as diff</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         create_date,</span><br><span class="line">                         lead(create_date, 2, &#x27;9999-12-31&#x27;) over (partition by user_id order by create_date) as lead2</span><br><span class="line">                  from (</span><br><span class="line">                           select distinct user_id, create_date</span><br><span class="line">                           from order_info</span><br><span class="line">                       ) t1</span><br><span class="line">              ) t2</span><br><span class="line">         where datediff(lead2, create_date) = 2</span><br><span class="line">)t3;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_15-31-52.png" alt="Snipaste_2023-10-31_15-31-52" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">--2.2 思路2</span><br><span class="line">--使用窗口函数rank()，得到新字段rk，然后让create_date取减rk，得到新列diff，如果diff列中相同结果的个数大于等于3，证明</span><br><span class="line">--存在至少连续三天下单的用户</span><br><span class="line">select distinct user_id</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                diff,</span><br><span class="line">                count(*) cnt</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         create_date,</span><br><span class="line">                         date_sub(create_date, rank() over (partition by user_id order by create_date)) diff</span><br><span class="line">                  from (</span><br><span class="line">                           select distinct user_id, create_date</span><br><span class="line">                           from order_info</span><br><span class="line">                       ) t1</span><br><span class="line">              ) t2</span><br><span class="line">         group by user_id, diff</span><br><span class="line">         having cnt &gt;= 3</span><br><span class="line">     )t3;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">--2.2 思路3</span><br><span class="line">--使用count(*) over(partition by user_id order by ts range between 86400 preceding and 86400 following)</span><br><span class="line">--如果得到该列数据大于等于3证明存在至少连续三天下单的用户</span><br><span class="line">select distinct user_id</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                ts,</span><br><span class="line">                count(*) over (partition by user_id order by ts range between 86400 preceding and 86400 following) cnt</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         unix_timestamp(create_date, &#x27;yyyy-MM-dd&#x27;) ts</span><br><span class="line">                  from (</span><br><span class="line">                           select distinct user_id, create_date</span><br><span class="line">                           from order_info</span><br><span class="line">                       ) t1</span><br><span class="line">              ) t2</span><br><span class="line">     )t3</span><br><span class="line">where cnt &gt;= 3;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--2.3 查询各品类销售商品的种类数及销量最高的商品</span><br><span class="line">--①查询不同商品id的销售量</span><br><span class="line">select sku_id,</span><br><span class="line">       sum(sku_num) order_num</span><br><span class="line">from order_detail</span><br><span class="line">group by sku_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-32-43.png" alt="Snipaste_2023-10-31_16-32-43" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">--②将查询表①join上sku_info表和category_info表，按照商品分类给销量进行升序排列，并统计每个商品分类下的商品数</span><br><span class="line">select od.sku_id,</span><br><span class="line">                sku.name,</span><br><span class="line">                sku.category_id,</span><br><span class="line">                cate.category_name,</span><br><span class="line">                order_num,</span><br><span class="line">                rank() over (partition by sku.category_id order by order_num desc ) rk,</span><br><span class="line">                count(distinct od.sku_id) over (partition by sku.category_id)      sku_cnt</span><br><span class="line">         from (</span><br><span class="line">                  select sku_id,</span><br><span class="line">                         sum(sku_num) order_num</span><br><span class="line">                  from order_detail</span><br><span class="line">                  group by sku_id</span><br><span class="line">              ) od</span><br><span class="line">                  left join</span><br><span class="line">              sku_info sku</span><br><span class="line">              on od.sku_id = sku.sku_id</span><br><span class="line">                  left join</span><br><span class="line">              category_info cate</span><br><span class="line">              on sku.category_id = cate.category_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-33-27.png" alt="Snipaste_2023-10-31_16-33-27" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">--③对表②进行过滤rk=1（销量最高）</span><br><span class="line">select category_id,</span><br><span class="line">       category_name,</span><br><span class="line">       sku_id,</span><br><span class="line">       name,</span><br><span class="line">       order_num,</span><br><span class="line">       sku_cnt</span><br><span class="line">from (</span><br><span class="line">         select od.sku_id,</span><br><span class="line">                sku.name,</span><br><span class="line">                sku.category_id,</span><br><span class="line">                cate.category_name,</span><br><span class="line">                order_num,</span><br><span class="line">                rank() over (partition by sku.category_id order by order_num desc) rk,</span><br><span class="line">                count(distinct od.sku_id) over (partition by sku.category_id)      sku_cnt</span><br><span class="line">         from (</span><br><span class="line">                  select sku_id,</span><br><span class="line">                         sum(sku_num) order_num</span><br><span class="line">                  from order_detail</span><br><span class="line">                  group by sku_id</span><br><span class="line">              ) od</span><br><span class="line">                  left join</span><br><span class="line">              sku_info sku</span><br><span class="line">              on od.sku_id = sku.sku_id</span><br><span class="line">                  left join</span><br><span class="line">              category_info cate</span><br><span class="line">              on sku.category_id = cate.category_id</span><br><span class="line">     ) t1</span><br><span class="line">where rk = 1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-34-24.png" alt="Snipaste_2023-10-31_16-34-24" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--2.4 查询用户的累计消费金额及VIP等级</span><br><span class="line">-- 从订单信息表(order_info)中统计每个用户截止其每个下单日期的累积消费金额，以及每个用户在其每个下单日期的VIP等级。</span><br><span class="line">-- 用户vip等级根据累积消费金额计算，计算规则如下：</span><br><span class="line">-- 设累积消费总额为X，</span><br><span class="line">-- 若0=&lt;X&lt;10000,则vip等级为普通会员</span><br><span class="line">-- 若10000&lt;=X&lt;30000,则vip等级为青铜会员</span><br><span class="line">-- 若30000&lt;=X&lt;50000,则vip等级为白银会员</span><br><span class="line">-- 若50000&lt;=X&lt;80000,则vip为黄金会员</span><br><span class="line">-- 若80000&lt;=X&lt;100000,则vip等级为白金会员</span><br><span class="line">-- 若X&gt;=100000,则vip等级为钻石会员</span><br><span class="line"></span><br><span class="line">--①每个用户在每一天的消费金额</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       sum(total_amount) amount_by_day</span><br><span class="line">from order_info</span><br><span class="line">group by user_id, create_date;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-39-32.png" alt="Snipaste_2023-10-31_16-39-32" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--②每个用户的累计消费金额</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       sum(amount_by_day) over(partition by user_id order by create_date) amount_so_far</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                sum(total_amount) amount_by_day</span><br><span class="line">         from order_info</span><br><span class="line">         group by user_id, create_date</span><br><span class="line">     )t1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-42-51.png" alt="Snipaste_2023-10-31_16-42-51" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">--③加上对应等级</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       amount_so_far,</span><br><span class="line">       case</span><br><span class="line">           when amount_so_far &gt;= 100000 then &#x27;钻石会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 80000 then &#x27;白金会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 50000 then &#x27;黄金会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 30000 then &#x27;白银会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 10000 then &#x27;青铜会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 0 then &#x27;普通会员&#x27;</span><br><span class="line">           end vip_level</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                sum(amount_by_day) over (partition by user_id order by create_date) amount_so_far</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         create_date,</span><br><span class="line">                         sum(total_amount) amount_by_day</span><br><span class="line">                  from order_info</span><br><span class="line">                  group by user_id, create_date</span><br><span class="line">              ) t1</span><br><span class="line">     )t2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-45-33.png" alt="Snipaste_2023-10-31_16-45-33" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">--2.5 查询首次下单后第二天连续下单的用户比率</span><br><span class="line">-- 从订单信息表(order_info)中查询首次下单后第二天仍然下单的用户占所有下单用户的比例，结果保留一位小数，使用百分数显示</span><br><span class="line">--①对用户和下单日期进行去重，以用户id进行分组并且给日期排序</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       rank() over (partition by user_id order by create_date) rk</span><br><span class="line">from (</span><br><span class="line">         select distinct user_id, create_date</span><br><span class="line">         from order_info</span><br><span class="line">)t1</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_19-28-34.png" alt="Snipaste_2023-10-31_19-28-34" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">--②过滤查询表①中的rk &lt;= 2的行</span><br><span class="line">select user_id,create_date</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                rank() over (partition by user_id order by create_date) rk</span><br><span class="line">         from (</span><br><span class="line">                  select distinct user_id, create_date</span><br><span class="line">                  from order_info</span><br><span class="line">              ) t1</span><br><span class="line">     )t2</span><br><span class="line">where rk &lt;= 2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_19-31-55.png" alt="Snipaste_2023-10-31_19-31-55" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">--③将查询表②中的每个用户的两个日期分成第一次下单日期和第二次下单日期</span><br><span class="line">select user_id,</span><br><span class="line">       min(create_date) first_create_date,</span><br><span class="line">       max(create_date) second_create_date</span><br><span class="line">from (</span><br><span class="line">         select user_id, create_date</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         create_date,</span><br><span class="line">                         rank() over (partition by user_id order by create_date) rk</span><br><span class="line">                  from (</span><br><span class="line">                           select distinct user_id, create_date</span><br><span class="line">                           from order_info</span><br><span class="line">                       ) t1</span><br><span class="line">              ) t2</span><br><span class="line">         where rk &lt;= 2</span><br><span class="line">)t3</span><br><span class="line">group by user_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_19-40-28.png" alt="Snipaste_2023-10-31_19-40-28" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">--④求比例</span><br><span class="line">select concat(round(sum(`if`(datediff(second_create_date,first_create_date) = 1,1,0))/count(*)*100,1),&#x27;%&#x27;) percentage</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                min(create_date) first_create_date,</span><br><span class="line">                max(create_date) second_create_date</span><br><span class="line">         from (</span><br><span class="line">                  select user_id, create_date</span><br><span class="line">                  from (</span><br><span class="line">                           select user_id,</span><br><span class="line">                                  create_date,</span><br><span class="line">                                  rank() over (partition by user_id order by create_date) rk</span><br><span class="line">                           from (</span><br><span class="line">                                    select distinct user_id, create_date</span><br><span class="line">                                    from order_info</span><br><span class="line">                                ) t1</span><br><span class="line">                       ) t2</span><br><span class="line">                  where rk &lt;= 2</span><br><span class="line">              ) t3</span><br><span class="line">         group by user_id</span><br><span class="line">     )t4;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_19-44-44.png" alt="Snipaste_2023-10-31_19-44-44" style="zoom:50%;">

<h1 id="第九章-分区表和分桶表"><a href="#第九章-分区表和分桶表" class="headerlink" title="第九章 分区表和分桶表"></a>第九章 分区表和分桶表</h1><h2 id="9-1-分区表"><a href="#9-1-分区表" class="headerlink" title="9.1 分区表"></a>9.1 分区表</h2><p>Hive中的分区就是把一张大表的数据按照业务需要分散的存储到多个目录，每个目录就称为该表的一个分区。在查询时通过where子句中的表达式选择查询所需要的分区，这样的查询效率会提高很多。如果将Hive设置为严格模式（set hive.mapred.mode &#x3D; strict;），这样如果对分区表进行查询而where子句没有加分区过滤的话，将会禁止提交这个任务。</p>
<h3 id="9-1-1-分区表基本语法"><a href="#9-1-1-分区表基本语法" class="headerlink" title="9.1.1 分区表基本语法"></a>9.1.1 分区表基本语法</h3><h4 id="1-创建分区表"><a href="#1-创建分区表" class="headerlink" title="1. 创建分区表"></a>1. 创建分区表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--算上分区字段一共四个字段</span><br><span class="line">create table dept_partition</span><br><span class="line">(</span><br><span class="line">    deptno int,    --部门编号</span><br><span class="line">    dname  string, --部门名称</span><br><span class="line">    loc    string  --部门位置</span><br><span class="line">)</span><br><span class="line">    partitioned by (day string)</span><br><span class="line">    row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<h4 id="2-分区表读写数据"><a href="#2-分区表读写数据" class="headerlink" title="2. 分区表读写数据"></a>2. 分区表读写数据</h4><p>（1）写数据-load</p>
<p>在&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;路径上创建文件dept_20220401.log，并输入如下内容。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# vim dept_20220401.log</span><br><span class="line"></span><br><span class="line">10	行政部	1700</span><br><span class="line">20	财务部	1800</span><br></pre></td></tr></table></figure>

<p>装载语句：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/hive/datas/dept_20220401.log&#x27;</span><br><span class="line">into table dept_partition</span><br><span class="line">partition(day=&#x27;20220401&#x27;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-08-35.png" alt="Snipaste_2023-11-01_15-08-35" style="zoom:33%;">

<p>（2）写数据-insert</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 将day=&#x27;20220401&#x27;分区的数据插入到day=&#x27;20220402&#x27;分区，可执行如下装载语句</span><br><span class="line">insert overwrite table dept_partition partition (day = &#x27;20220402&#x27;)</span><br><span class="line">select deptno, dname, loc</span><br><span class="line">from dept_partition</span><br><span class="line">where day = &#x27;20220401&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-09-23.png" alt="Snipaste_2023-11-01_15-09-23" style="zoom:33%;">

<p>（3）读数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 查询分区表数据时，可以将分区字段看作表的伪列，可像使用其他字段一样使用分区字段。</span><br><span class="line">select deptno, dname, loc ,day</span><br><span class="line">from dept_partition</span><br><span class="line">where day = &#x27;20220401&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-12-08.png" alt="Snipaste_2023-11-01_15-12-08" style="zoom:33%;">

<h4 id="3-分区表基本操作"><a href="#3-分区表基本操作" class="headerlink" title="3. 分区表基本操作"></a>3. 分区表基本操作</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 1）查看所有分区信息</span><br><span class="line">show partitions dept_partition;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-20-14.png" alt="Snipaste_2023-11-01_15-20-14" style="zoom:33%;">

<p>当然查看hadoop102web端也能看到：</p>
<img src="Snipaste_2023-11-01_15-18-40.png" alt="Snipaste_2023-11-01_15-18-40" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 2）增加分区</span><br><span class="line">--（1）创建单个分区</span><br><span class="line">alter table dept_partition</span><br><span class="line">add partition(day=&#x27;20220403&#x27;); --执行这个命令相当于在HDFS上增加了一个目录，并在hive的元数据中增加了一条分区信息</span><br><span class="line">show partitions dept_partition;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-23-13.png" alt="Snipaste_2023-11-01_15-23-13" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--（2）同时创建多个分区（分区之间不能有逗号）</span><br><span class="line">alter table dept_partition</span><br><span class="line">add partition(day=&#x27;20220404&#x27;) partition(day=&#x27;20220405&#x27;);</span><br><span class="line">show partitions dept_partition;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-23-56.png" alt="Snipaste_2023-11-01_15-23-56" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-- 3）删除分区</span><br><span class="line">-- （1）删除单个分区</span><br><span class="line">alter table dept_partition</span><br><span class="line">drop partition (day=&#x27;20220403&#x27;);</span><br><span class="line">-- （2）同时删除多个分区（分区之间必须有逗号）</span><br><span class="line">alter table dept_partition</span><br><span class="line">drop partition (day=&#x27;20220404&#x27;), partition(day=&#x27;20220405&#x27;);</span><br></pre></td></tr></table></figure>

<p>4）修复分区</p>
<p>Hive将分区表的所有分区信息都保存在了元数据中，只有元数据与HDFS上的分区路径一致时，分区表才能正常读写数据。若用户手动创建&#x2F;删除分区路径，Hive都是感知不到的，这样就会导致Hive的元数据和HDFS的分区路径不一致。再比如，若分区表为外部表，用户执行drop partition命令后，分区元数据会被删除，而HDFS的分区路径不会被删除，同样会导致Hive的元数据和HDFS的分区路径不一致。</p>
<p>若出现元数据和HDFS路径不一致的情况，可通过如下几种手段进行修复。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter table dept_partition add partition (day = &#x27;20220403&#x27;);</span><br><span class="line">alter table dept_partition drop partition (day = &#x27;20220403&#x27;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-35-02.png" alt="Snipaste_2023-11-01_15-35-02" style="zoom:50%;">

<h3 id="9-1-2-二级分区表"><a href="#9-1-2-二级分区表" class="headerlink" title="9.1.2 二级分区表"></a>9.1.2 二级分区表</h3><p>思考：如果一天内的日志数据量也很大，如何再将数据拆分?答案是二级分区表，例如可以在按天分区的基础上，再对每天的数据按小时进行分区。</p>
<p>在实际项目中，分区表都是按照时间分区的。因为Hive做的是批处理（离线处理），也就是Hive攒下一批数据后做一次统一的处理，大多数离线项目中，一批也就是一天</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-- 1）二级分区表建表语句</span><br><span class="line">create table dept_partition2(</span><br><span class="line">    deptno int,    -- 部门编号</span><br><span class="line">    dname string, -- 部门名称</span><br><span class="line">    loc string     -- 部门位置</span><br><span class="line">)</span><br><span class="line">partitioned by (day string, hour string) --采用二级分区</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 2）数据装载语句</span><br><span class="line">load data local inpath &#x27;/opt/module/hive/datas/dept_20220401.log&#x27;</span><br><span class="line">into table dept_partition2</span><br><span class="line">partition(day=&#x27;20220401&#x27;, hour=&#x27;12&#x27;);</span><br><span class="line">-- 3）查询分区数据</span><br><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from dept_partition2</span><br><span class="line">where day=&#x27;20220401&#x27; and hour=&#x27;12&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_16-27-48.png" alt="Snipaste_2023-11-01_16-27-48" style="zoom:33%;">

<h3 id="9-1-3-动态分区"><a href="#9-1-3-动态分区" class="headerlink" title="9.1.3 动态分区"></a>9.1.3 动态分区</h3><p>动态分区是指向分区表insert数据时，被写往的分区不由用户指定，而是由每行数据的最后一个字段的值来动态的决定。<strong>使用动态分区，可只用一个insert语句将数据写入多个分区。</strong></p>
<p>（1）动态分区相关参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">-- （1）动态分区功能总开关（默认true，开启）</span><br><span class="line">set hive.exec.dynamic.partition=true;</span><br><span class="line">-- （2）严格模式和非严格模式</span><br><span class="line">-- 动态分区的模式，默认strict（严格模式），要求必须指定至少一个分区为静态分区，nonstrict（非严格模式）允许所有的分区字段都使用动态分区。</span><br><span class="line">set hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line">-- （3）一条insert语句可同时创建的最大的分区个数，默认为1000。</span><br><span class="line">set hive.exec.max.dynamic.partitions=1000;</span><br><span class="line">-- （4）单个Mapper或者Reducer可同时创建的最大的分区个数，默认为100。</span><br><span class="line">set hive.exec.max.dynamic.partitions.pernode=100;</span><br><span class="line">-- （5）一条insert语句可以创建的最大的文件个数，默认100000。</span><br><span class="line">set hive.exec.max.created.files=100000;</span><br><span class="line">-- （6）当查询结果为空时且进行动态分区时，是否抛出异常，默认false。</span><br><span class="line">set hive.error.on.empty.partition=false;</span><br></pre></td></tr></table></figure>

<p>（2）案例实操</p>
<p>需求：将dept表中的数据按照地区（loc字段），插入到目标表dept_partition_dynamic的相应分区中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">-- （1）创建目标分区表</span><br><span class="line">create table dept_partition_dynamic(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">partitioned by (loc int)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 2）设置动态分区</span><br><span class="line">set hive.exec.dynamic.partition.mode = nonstrict;</span><br><span class="line">insert into table dept_partition_dynamic</span><br><span class="line">partition(loc)  --不需要声明指定某个分区，只需要声明分区字段即可</span><br><span class="line">select</span><br><span class="line">    deptno,</span><br><span class="line">    dname,</span><br><span class="line">    loc  --按照loc字段的值进行动态分区</span><br><span class="line">from default.dept;</span><br><span class="line">-- （3）查看目标分区表的分区情况</span><br><span class="line">show partitions dept_partition_dynamic;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_19-22-32.png" alt="Snipaste_2023-11-01_19-22-32" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select *from dept_partition_dynamic;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_19-24-28.png" alt="Snipaste_2023-11-01_19-24-28" style="zoom:33%;">

<p>在HDFS中：&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;partition_bucket.db&#x2F;dept_partition_dynamic&#x2F;loc&#x3D;1700目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">10	行政部</span><br><span class="line">40	销售部</span><br></pre></td></tr></table></figure>

<p>&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;partition_bucket.db&#x2F;dept_partition_dynamic&#x2F;loc&#x3D;1800目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">20	财务部</span><br></pre></td></tr></table></figure>

<p>&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;partition_bucket.db&#x2F;dept_partition_dynamic&#x2F;loc&#x3D;1900目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">30	教学部</span><br></pre></td></tr></table></figure>

<p>（3）一些注意点</p>
<p>动态分区可以是多个（<strong>动态二级分区</strong>）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">-- 1）二级分区表建表语句</span><br><span class="line">create table dept_partition2(</span><br><span class="line">    deptno int,    -- 部门编号</span><br><span class="line">    dname string, -- 部门名称</span><br><span class="line">    loc string     -- 部门位置</span><br><span class="line">)</span><br><span class="line">partitioned by (day string, hour string) --采用二级分区</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 2）设置动态分区</span><br><span class="line">set hive.exec.dynamic.partition.mode = nonstrict;</span><br><span class="line">insert into table dept_partition2</span><br><span class="line">partition(day,hour)  --不需要声明指定某个分区，只需要声明分区字段即可</span><br><span class="line">select</span><br><span class="line">    deptno,</span><br><span class="line">    dname,</span><br><span class="line">    loc,</span><br><span class="line">    day,</span><br><span class="line">    hour  --按照day和hour字段的值进行动态分区</span><br><span class="line">from default.dept;</span><br></pre></td></tr></table></figure>

<p>动静态分区混合使用（<strong>前提是静态分区键必须出现在动态分区键之前</strong>）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">-- 1）二级分区表建表语句</span><br><span class="line">create table dept_partition2(</span><br><span class="line">    deptno int,    -- 部门编号</span><br><span class="line">    dname string, -- 部门名称</span><br><span class="line">    loc string     -- 部门位置</span><br><span class="line">)</span><br><span class="line">partitioned by (day string, hour string) --采用二级分区</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 2）设置动态分区</span><br><span class="line">set hive.exec.dynamic.partition.mode = nonstrict;</span><br><span class="line">insert into table dept_partition2</span><br><span class="line">partition(day = &#x27;20240304&#x27;,hour)  --不需要声明指定某个分区，只需要声明分区字段即可</span><br><span class="line">select</span><br><span class="line">    deptno,</span><br><span class="line">    dname,</span><br><span class="line">    loc,</span><br><span class="line">    day,</span><br><span class="line">    hour  --按照day和hour字段的值进行动态分区</span><br><span class="line">from default.dept</span><br><span class="line">where day = &#x27;20240304&#x27;;</span><br></pre></td></tr></table></figure>

<h3 id="9-1-4-分区过滤"><a href="#9-1-4-分区过滤" class="headerlink" title="9.1.4 分区过滤"></a>9.1.4 分区过滤</h3><p>HiveSQL里面分区过滤使用方法是在where子句新增分区列的筛选条件。普通where子句的过滤是发生在Map阶段，而分区列筛选其实是在Map的上一个阶段，即在输入阶段进行路径的过滤。</p>
<p>分区列能够在Map之前的<strong>更早阶段</strong>进行数据过滤，每个分区在分布式文件系统中是以目录形式存在，一个分区对应一个目录，在构建作业之初，在FileInputFormat中设置分区的路径时，不符合条件的路径直接略过不会读取，所以分区能从一开始就进行数据的过滤。</p>
<h2 id="9-2-分桶表"><a href="#9-2-分桶表" class="headerlink" title="9.2 分桶表"></a>9.2 分桶表</h2><p>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围划分，分区针对的是数据的存储路径，分桶针对的是数据文件。</p>
<p>分桶表的基本原理是，首先为每行数据计算一个指定字段的数据的hash值，然后模以（%）一个指定的分桶数，最后将取模运算结果相同的行，写入同一个文件中，这个文件就称为一个分桶（bucket）。将数据按照指定的字段进行分成多个桶中去，说白了就是将数据按照字段进行划分，可以将数据按照字段划分到<strong>多个文件</strong>当中去。</p>
<p>一个表没有分区直接分桶，就将表整体去分桶。如果一个表已经分区了，就在每个分好区的表内进行分桶。</p>
<h3 id="9-2-1-分桶表基本语法"><a href="#9-2-1-分桶表基本语法" class="headerlink" title="9.2.1 分桶表基本语法"></a>9.2.1 分桶表基本语法</h3><p>（1）建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table stu_buck(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">clustered by(id) [sorted by(id)] into 4 buckets  --分桶字段是表中已经存在的字段，分4个桶,[还可以按id字段进行排序，分桶排序表]</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<p>（2）数据装载</p>
<p>在&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;路径上创建student.txt文件，并输入如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1001	student1</span><br><span class="line">1002	student2</span><br><span class="line">1003	student3</span><br><span class="line">1004	student4</span><br><span class="line">1005	student5</span><br><span class="line">1006	student6</span><br><span class="line">1007	student7</span><br><span class="line">1008	student8</span><br><span class="line">1009	student9</span><br><span class="line">1010	student10</span><br><span class="line">1011	student11</span><br><span class="line">1012	student12</span><br><span class="line">1013	student13</span><br><span class="line">1014	student14</span><br><span class="line">1015	student15</span><br><span class="line">1016	student16</span><br></pre></td></tr></table></figure>

<p>（3）导入数据到分桶表中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/hive/datas/student.txt&#x27;</span><br><span class="line">into table stu_buck;</span><br></pre></td></tr></table></figure>

<p>（4）查看创建的分桶表中是否分成4个桶</p>
<p><img src="Snipaste_2023-11-01_19-47-52.png" alt="Snipaste_2023-11-01_19-47-52"></p>
<p>（5）观察每个分桶表中的数据，实际上是按照id字段的hash值分桶的</p>
<p>000000_0:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1016	student16</span><br><span class="line">1012	student12</span><br><span class="line">1008	student8</span><br><span class="line">1004	student4</span><br></pre></td></tr></table></figure>

<p>000001_0:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1009	student9</span><br><span class="line">1005	student5</span><br><span class="line">1001	student1</span><br><span class="line">1013	student13</span><br></pre></td></tr></table></figure>

<p>000002_0:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1010	student10</span><br><span class="line">1002	student2</span><br><span class="line">1006	student6</span><br><span class="line">1014	student14</span><br></pre></td></tr></table></figure>

<p>000003_0:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1003	student3</span><br><span class="line">1011	student11</span><br><span class="line">1007	student7</span><br><span class="line">1015	student15</span><br></pre></td></tr></table></figure>

<h2 id="9-3-补充：Hive表在使用层面的分类"><a href="#9-3-补充：Hive表在使用层面的分类" class="headerlink" title="9.3 补充：Hive表在使用层面的分类"></a>9.3 补充：Hive表在使用层面的分类</h2><p>（1）分区表（partition table），可以使用PARTIONED BY子句创建分区表。一个表可以有一个或多个分区列，并且为分区列中的每个不同值组合创建一个单独的数据目录。</p>
<p>（2）桶排序表（bucketed sorted table），数据按照指定的列进行分桶，每个桶内的数据按指定的字段进行排序。这样的组织方式有助于集群抽样。同时表本身自带排序，对于查询也有一定的帮助。</p>
<p>（3）倾斜表（skewed table），当表的部分列具有倾斜值时，可以用这种特性提高表的性能。原理：指定了列，会告诉计算引擎，计算的时候先过滤掉某些列，这些采用单独的作业去计算。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Create table list_bucket_single (key string,value string)</span><br><span class="line">skewed by (key) on (1,5,6) [stored as directories];</span><br></pre></td></tr></table></figure>

<p>其中，key表示倾斜列，1，5，6为倾斜值</p>
<p>（4）临时表（Temporary Table），Hive的临时表只有一种——会话（session）内临时表，即在当前会话内创建，会话结束后被删除。临时表的数据暂存在scratch目录，即hive.exec.scratchdir配置的目录。注意三点：</p>
<ul>
<li>临时表不能和已经创建的非临时表名冲突</li>
<li>临时表不支持分区</li>
<li>临时表不支持创建索引</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Create temporary table tmp_123_llsid_di(col1 string,col2 int,col3 bigint);</span><br></pre></td></tr></table></figure>

<h1 id="第十章-文件格式和压缩"><a href="#第十章-文件格式和压缩" class="headerlink" title="第十章 文件格式和压缩"></a>第十章 文件格式和压缩</h1><h2 id="10-1-Hadoop压缩概述"><a href="#10-1-Hadoop压缩概述" class="headerlink" title="10.1 Hadoop压缩概述"></a>10.1 Hadoop压缩概述</h2><img src="Snipaste_2023-11-01_20-24-12.png" alt="Snipaste_2023-11-01_20-24-12" style="zoom:50%;">

<img src="Snipaste_2023-11-01_20-26-33.png" alt="Snipaste_2023-11-01_20-26-33" style="zoom:50%;">

<h2 id="10-2-Hive文件格式"><a href="#10-2-Hive文件格式" class="headerlink" title="10.2 Hive文件格式"></a>10.2 Hive文件格式</h2><p>为Hive表中的数据选择一个合适的文件格式，对提高查询性能的提高是十分有益的。Hive表数据的存储格式，可以选择text file、orc、parquet、sequence file等。<strong>orc和parquet最常使用</strong></p>
<h3 id="10-2-1-Text-File"><a href="#10-2-1-Text-File" class="headerlink" title="10.2.1 Text File"></a>10.2.1 Text File</h3><p>文本文件是Hive默认使用的文件格式，文本文件中的一行内容，就对应Hive表中的一行记录。默认格式，数据不做压缩，磁盘开销大，数据解析开销大。</p>
<p>建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create table textfile_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure>

<h3 id="10-2-2-ORC"><a href="#10-2-2-ORC" class="headerlink" title="10.2.2 ORC"></a>10.2.2 ORC</h3><p>ORC（Optimized Row Columnar）file format是Hive 0.11版里引入的一种****列式存储****的文件格式。ORC文件能够提高Hive读写数据和处理数据的性能。与列式存储相对的是行式存储，下图是两者的对比：</p>
<img src="Snipaste_2023-11-01_20-35-19.png" alt="Snipaste_2023-11-01_20-35-19" style="zoom:50%;">

<p>（1）行存储的特点</p>
<p>查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。select *效率高</p>
<p>（2）列存储的特点</p>
<p>因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法。select 某些字段 效率高</p>
<p><strong>前文提到的text file和sequence file都是基于行存储的，orc和parquet是基于列式存储的。</strong></p>
<p><img src="Snipaste_2023-11-01_20-50-27.png" alt="Snipaste_2023-11-01_20-50-27"></p>
<p>每个Orc文件由Header、Body和Tail三部分组成。</p>
<p>其中Header内容为ORC，用于表示文件类型。</p>
<p>Body由1个或多个stripe组成，每个stripe一般为HDFS的块大小，每一个stripe包含多条记录，这些记录按照列进行独立存储，每个stripe里有三部分组成，分别是Index Data，Row Data，Stripe Footer。</p>
<p><strong>Index Data：</strong>一个轻量级的index，默认是为各列每隔1W行做一个索引。每个索引会记录第n万行的位置，和最近一万行的最大值和最小值等信息。</p>
<p><strong>Row Data：</strong>存的是具体的数据，按列进行存储，并对每个列进行编码，分成多个Stream来存储。</p>
<p><strong>Stripe Footer：</strong>存放的是各个Stream的位置以及各column的编码信息。</p>
<p>Tail由File Footer和PostScript组成。File Footer中保存了各Stripe的其实位置、索引长度、数据长度等信息，各Column的统计信息等；PostScript记录了整个文件的压缩类型以及File Footer的长度信息等。</p>
<p>在读取ORC文件时，会先从最后一个字节读取PostScript长度，进而读取到PostScript，从里面解析到File Footer长度，进而读取FileFooter，从中解析到各个Stripe信息，再读各个Stripe，<strong>即从后往前读。</strong></p>
<p>（3）建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table orc_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as orc</span><br><span class="line">tblproperties (property_name=property_value, ...);  --设置参数</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_21-02-32.png" alt="Snipaste_2023-11-01_21-02-32" style="zoom:50%;">

<p>其中orc.stripe.size应该设置成和Hadoop中block大小一致，故最好设置成128M（134217728）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">create table test_orc</span><br><span class="line">(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">stored as orc;</span><br><span class="line"></span><br><span class="line">show create table test_orc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_21-19-14.png" alt="Snipaste_2023-11-01_21-19-14" style="zoom:50%;">

<h3 id="10-2-3-Parquet"><a href="#10-2-3-Parquet" class="headerlink" title="10.2.3 Parquet"></a>10.2.3 Parquet</h3><p>Parquet文件是Hadoop生态中的一个通用的文件格式，它也是一个列式存储的文件格式。</p>
<p><img src="Snipaste_2023-11-01_21-27-51.png" alt="Snipaste_2023-11-01_21-27-51"></p>
<p>上图展示了一个Parquet文件的基本结构，文件的首尾都是该文件的Magic Code，用于校验它是否是一个Parquet文件。</p>
<p>首尾中间由若干个Row Group和一个Footer（File Meta Data）组成。</p>
<p>每个Row Group包含多个Column Chunk，每个Column Chunk包含多个Page。以下是Row Group、Column Chunk和Page三个概念的说明：</p>
<p><strong>行组（Row Group）</strong>：一个行组对应逻辑表中的若干行。 </p>
<p><strong>列块（Column Chunk）</strong>：一个行组中的一列保存在一个列块中。 </p>
<p><strong>页（Page）</strong>：一个列块的数据会划分为若干个页。 </p>
<p>Footer（File Meta Data）中存储了每个行组（Row Group）中的每个列快（Column Chunk）的元数据信息，元数据信息包含了该列的数据类型、该列的编码方式、该类的Data Page位置等信息。</p>
<p>（1）建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Create table parquet_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as parquet</span><br><span class="line">tblproperties (property_name=property_value, ...);  --设置参数</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_21-32-04.png" alt="Snipaste_2023-11-01_21-32-04" style="zoom:50%;">

<p>三种文件格式的性能比较：</p>
<p>压缩比比较：ORC&gt;Parquet&gt;textFile</p>
<p>存储文件的查询效率比较：ORC&gt;TextFile&gt;Parquet</p>
<h3 id="10-2-4-数据归档"><a href="#10-2-4-数据归档" class="headerlink" title="10.2.4 数据归档"></a>10.2.4 数据归档</h3><p>对于HDFS中有大量小文件的表，可以通过Hadoop归档（Hadoop archive）的方式将文件归并成几个较大的文件。归并后的分区会先创建一个data.har目录，里面包含两部分内容：索引（index和_masterindex）和数据（part-*）。其中，索引记录归并前的文件在归并后的所在位置。</p>
<p>相关参数与写法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--启用数据归档</span><br><span class="line">set hive.archive.enabled = true;</span><br><span class="line">set hive.archive.har.parentdir.settable = true;</span><br><span class="line">--归档后的最大文件大小</span><br><span class="line">set har.partfile.size = 1099511627776;</span><br><span class="line">--对分区执行归档的命令</span><br><span class="line">alter table tablename archive partition (partition_col=partition_val)</span><br><span class="line">--将归档的分区还原成原来的普通分区</span><br><span class="line">alter table tablename unarchive partition (partition_col = partition_val)</span><br></pre></td></tr></table></figure>

<h2 id="10-3-压缩"><a href="#10-3-压缩" class="headerlink" title="10.3 压缩"></a>10.3 压缩</h2><p>在Hive表中和计算过程中，保持数据的压缩，对磁盘空间的有效利用和提高查询性能都是十分有益的。</p>
<p><strong>表中的压缩即为表中存储的数据的压缩，计算过程的压缩即为MapReduce各个阶段输出的数据的压缩。</strong></p>
<h3 id="10-3-1-Hive表数据进行压缩"><a href="#10-3-1-Hive表数据进行压缩" class="headerlink" title="10.3.1 Hive表数据进行压缩"></a>10.3.1 Hive表数据进行压缩</h3><p>在Hive中，不同文件类型的表，声明数据压缩的方式是不同的。</p>
<p>（1）TextFile</p>
<p>若一张表的文件类型为TextFile，若需要对该表中的数据进行压缩，多数情况下，无需在建表语句做出声明。直接将压缩后的文件导入到该表即可，Hive在查询表中数据时，可自动识别其压缩格式，进行解压。</p>
<p>需要注意的是，在执行往表中导入数据的SQL语句时，用户需设置以下参数，来保证写入表中的数据是被压缩的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--SQL语句的最终输出结果是否压缩</span><br><span class="line">set hive.exec.compress.output=true;</span><br><span class="line">--输出结果的压缩格式（以下示例为snappy）</span><br><span class="line">set mapreduce.output.fileoutputformat.compress.codec =org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>

<p>（2）ORC</p>
<p>若一张表的文件类型为ORC，若需要对该表数据进行压缩，需在建表语句中声明压缩格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table orc_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as orc</span><br><span class="line">tblproperties (&quot;orc.compress&quot;=&quot;snappy&quot;);</span><br></pre></td></tr></table></figure>

<p>（3）Parquet</p>
<p>若一张表的文件类型为Parquet，若需要对该表数据进行压缩，需在建表语句中声明压缩格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table orc_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as parquet</span><br><span class="line">tblproperties (&quot;parquet.compression&quot;=&quot;snappy&quot;);</span><br></pre></td></tr></table></figure>

<h3 id="10-3-2-计算过程中使用压缩"><a href="#10-3-2-计算过程中使用压缩" class="headerlink" title="10.3.2 计算过程中使用压缩"></a>10.3.2 计算过程中使用压缩</h3><p>（1）单个MR的中间结果进行压缩</p>
<p>单个MR的中间结果是指Mapper输出的数据，对其进行压缩可降低shuffle阶段的网络IO，可通过以下参数进行配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--开启MapReduce中间数据压缩功能</span><br><span class="line">set mapreduce.map.output.compress=true;</span><br><span class="line">--设置MapReduce中间数据数据的压缩方式（以下示例为snappy）</span><br><span class="line">set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>

<p>（2）单条SQL语句的中间结果进行压缩</p>
<p>单条SQL语句的中间结果是指，两个MR（一条SQL语句可能需要通过MR进行计算）之间的临时数据，可通过以下参数进行配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--是否对两个MR之间的临时数据进行压缩</span><br><span class="line">set hive.exec.compress.intermediate=true;</span><br><span class="line">--压缩格式（以下示例为snappy）</span><br><span class="line">set hive.intermediate.compression.codec= org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>

<h1 id="第十一章-企业级调优"><a href="#第十一章-企业级调优" class="headerlink" title="第十一章 企业级调优"></a>第十一章 企业级调优</h1><img src="Hive on Spark调优.png" alt="Hive on Spark调优" style="zoom: 200%;">

<h2 id="11-1-计算资源配置"><a href="#11-1-计算资源配置" class="headerlink" title="11.1 计算资源配置"></a>11.1 计算资源配置</h2><h3 id="11-1-1-Yarn资源配置"><a href="#11-1-1-Yarn资源配置" class="headerlink" title="11.1.1 Yarn资源配置"></a>11.1.1 Yarn资源配置</h3><p>Yarn资源配置对于数仓开发一般不调整，因为调这些参数需要修改配置文件，这些参数平台一般会设定好</p>
<p>（1）Yarn配置说明</p>
<p>需要调整的Yarn参数均与CPU、内存等资源有关，核心配置参数如下</p>
<p>①yarn.nodemanager.resource.memory-mb</p>
<p>该参数的含义是，<strong>一个NodeManager节点分配给Container使用的内存</strong>。该参数的配置，取决于NodeManager所在节点的总内存容量和该节点运行的其他服务的数量。</p>
<p>考虑上述因素，此处可将该参数设置为64G，如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>65536<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>②yarn.nodemanager.resource.cpu-vcores</p>
<p>该参数的含义是，<strong>一个NodeManager节点分配给Container使用的CPU核数</strong>。该参数的配置，同样取决于NodeManager所在节点的总CPU核数和该节点运行的其他服务。</p>
<p>考虑上述因素，此处可将该参数设置为16。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>16<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>③yarn.scheduler.maximum-allocation-mb</p>
<p>该参数的含义是，<strong>单个Container能够使用的最大内存</strong>。由于Spark的yarn模式下，Driver和Executor都运行在Container中，故该参数不能小于Driver和Executor的内存配置。推荐配置如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>16384<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>④yarn.scheduler.minimum-allocation-mb</p>
<p>该参数的含义是，<strong>单个Container能够使用的最小内存</strong>，推荐配置如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）Yarn配置实操</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[root@hadoop102 hadoop]# vim yarn-site.xml </span><br></pre></td></tr></table></figure>

<p>修改之后，分发配置文件，并重启Yarn</p>
<p>注意：以上参数要根据自己电脑的配置调整。16G运存的电脑建议不要调整了。</p>
<h3 id="11-1-2-MapReduce资源配置（如果使用Hadoop引擎的话）"><a href="#11-1-2-MapReduce资源配置（如果使用Hadoop引擎的话）" class="headerlink" title="11.1.2 MapReduce资源配置（如果使用Hadoop引擎的话）"></a>11.1.2 MapReduce资源配置（如果使用Hadoop引擎的话）</h3><p>MapReduce资源配置主要包括<strong>Map Task的内存和CPU核数</strong>，以及<strong>Reduce Task的内存和CPU核数</strong>。核心配置参数如下：</p>
<p>1）mapreduce.map.memory.mb	</p>
<p>该参数的含义是，<strong>单个Map Task申请的container容器内存大小</strong>，其默认值为1024。<strong>该值不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。</strong></p>
<p>该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.map.memory.mb=2048;</span><br></pre></td></tr></table></figure>

<p>2）mapreduce.map.cpu.vcores	</p>
<p>该参数的含义是，<strong>单个Map Task申请的container容器cpu核数</strong>，其默认值为1。该值一般无需调整。</p>
<p>3）mapreduce.reduce.memory.mb		</p>
<p>该参数的含义是，<strong>单个Reduce Task申请的container容器内存大小</strong>，其默认值为1024。<strong>该值同样不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。</strong></p>
<p>该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.reduce.memory.mb=2048;</span><br></pre></td></tr></table></figure>

<p>4）mapreduce.reduce.cpu.vcores	</p>
<p>该参数的含义是，<strong>单个Reduce Task申请的container容器cpu核数</strong>，其默认值为1。该值一般无需调整。</p>
<h3 id="11-1-3-Spark资源配置（如果使用Spark引擎的话）"><a href="#11-1-3-Spark资源配置（如果使用Spark引擎的话）" class="headerlink" title="11.1.3 Spark资源配置（如果使用Spark引擎的话）"></a>11.1.3 Spark资源配置（如果使用Spark引擎的话）</h3><p>Executor的内存、Cpu核数、个数 和 Driver内存的配置大原则要依赖YARN的配置，因为Executor和Driver都在Yarn的NodeManager上的container中运行。</p>
<h4 id="Executor配置说明"><a href="#Executor配置说明" class="headerlink" title="Executor配置说明"></a>Executor配置说明</h4><h5 id="（1）Executor-CPU核数配置"><a href="#（1）Executor-CPU核数配置" class="headerlink" title="（1）Executor CPU核数配置"></a>（1）Executor CPU核数配置</h5><p><strong>单个Executor的CPU核数</strong>，由spark.executor.cores参数决定，建议配置为4-6，具体配置为多少，视具体情况而定，原则是尽量充分利用资源。</p>
<p>此处单个节点共有16个核可供Executor使用，则spark.executor.core配置为4最合适。原因是，若配置为5，则单个节点只能启动3个Executor，会剩余1个核未使用；若配置为6，则只能启动2个Executor，会剩余4个核未使用。</p>
<h5 id="（2）Executor内存配置"><a href="#（2）Executor内存配置" class="headerlink" title="（2）Executor内存配置"></a>（2）Executor内存配置</h5><p>Spark在Yarn模式下的Executor内存模型如下图所示：</p>
<p><img src="Snipaste_2024-07-19_11-42-10.png" alt="Snipaste_2024-07-19_11-42-10"></p>
<p>Executor相关的参数有：spark.executor.memory和spark.executor.memoryOverhead。</p>
<p><strong>spark.executor.memory用于指定Executor进程的堆内存大小，这部分内存用于任务的计算和存储；</strong></p>
<p><strong>spark.executor.memoryOverhead用于指定Executor进程的堆外内存，这部分内存用于JVM的额外开销，操作系统开销等。</strong>两者的和才算一个Executor进程所需的总内存大小。默认情况下spark.executor.memoryOverhead的值等于spark.executor.memory*0.1。（即堆内内存大小：堆外内存大小&#x3D;10：1）</p>
<p>以上两个参数的推荐配置思路是，先按照单个NodeManager的核数和单个Executor的核数，计算出每个NodeManager最多能运行多少个Executor。在将NodeManager的总内存平均分配给每个Executor，最后再将单个Executor的内存按照大约10:1的比例分配到spark.executor.memory和spark.executor.memoryOverhead。</p>
<p>根据上述思路，可得到如下关系：</p>
<p>(spark.executor.memory+spark.executor.memoryOverhead)&#x3D; yarn.nodemanager.resource.memory-mb * (spark.executor.cores&#x2F;yarn.nodemanager.resource.cpu-vcores)</p>
<h5 id="（3）Executor个数配置"><a href="#（3）Executor个数配置" class="headerlink" title="（3）Executor个数配置"></a>（3）Executor个数配置</h5><p>此处的Executor个数是指分配给一个Spark应用的Executor个数，Executor个数对于Spark应用的执行速度有很大的影响，所以Executor个数的确定十分重要。</p>
<p>一个Spark应用的Executor个数的指定方式有两种，<strong>静态分配</strong>和<strong>动态分配</strong>。</p>
<ul>
<li>静态分配：</li>
</ul>
<p>可通过spark.executor.instances指定一个Spark应用启动的Executor个数。这种方式需要自行估计每个Spark应用所需的资源，并为每个应用单独配置Executor个数。</p>
<ul>
<li>动态分配：</li>
</ul>
<p>动态分配可根据一个Spark应用的工作负载，动态的调整其所占用的资源（Executor个数）。这意味着一个Spark应用程序可以在运行的过程中，需要时，申请更多的资源（启动更多的Executor），不用时，便将其释放。</p>
<p>在生产集群中，推荐使用动态分配。动态分配相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--启动动态分配</span><br><span class="line">set spark.dynamicAllocation.enabled = true;</span><br><span class="line">--启用Spark shuffle服务</span><br><span class="line">set spark.shuffle.service.enabled = true;</span><br><span class="line">--Executor个数初始值</span><br><span class="line">set spark.dynamicAllocation.initialExecutors = 100;</span><br><span class="line">--Executor个数最小值</span><br><span class="line">set spark.dynamicAllocation.minExecutors = 100;</span><br><span class="line">--Executor个数最大值</span><br><span class="line">set spark.dynamicAllocation.maxExecutors = 500;</span><br><span class="line">--Executor空闲时长，若某Executor空闲时间超过此值，则会被关闭，单位秒</span><br><span class="line">set spark.dynamicAllocation.executorIdleTimeout = 60;</span><br><span class="line">--积压任务等待时长，若有Task等待时间超过此值，则申请启动新的Executor，单位秒</span><br><span class="line">set spark.dynamicAllocation.schedulerBacklogTimeout = 10;</span><br><span class="line">--spark shuffle老版本协议</span><br><span class="line">set spark.shuffle.useOldFetchProtocol = true;</span><br></pre></td></tr></table></figure>

<p><strong>说明</strong>：Spark shuffle服务的作用是管理Executor中的各Task的输出文件，主要是shuffle过程map端的输出文件。由于启用资源动态分配后，Spark会在一个应用未结束前，将已经完成任务，处于空闲状态的Executor关闭。Executor关闭后，其输出的文件，也就无法供其他Executor使用了。需要启用Spark shuffle服务，来管理各Executor输出的文件，这样就能关闭空闲的Executor，而不影响后续的计算任务了。</p>
<h4 id="Driver配置说明"><a href="#Driver配置说明" class="headerlink" title="Driver配置说明"></a>Driver配置说明</h4><p>Driver主要配置内存即可，相关的参数有spark.driver.memory和spark.driver.memoryOverhead。</p>
<p>spark.driver.memory用于指定Driver进程的堆内存大小，spark.driver.memoryOverhead用于指定Driver进程的堆外内存大小。默认情况下，两者的关系如下：spark.driver.memoryOverhead&#x3D;spark.driver.memory*0.1。两者的和才算一个Driver进程所需的总内存大小。</p>
<p>一般情况下，按照如下经验进行调整即可：假定yarn.nodemanager.resource.memory-mb设置为X，</p>
<p>若X&gt;50G，则Driver可设置为12G，</p>
<p>若12G&lt;X&lt;50G，则Driver可设置为4G。</p>
<p>若1G&lt;X&lt;12G，则Driver可设置为1G。</p>
<h2 id="11-2-测试用表（略）"><a href="#11-2-测试用表（略）" class="headerlink" title="11.2 测试用表（略）"></a>11.2 测试用表（略）</h2><h2 id="11-3-Explain查看执行计划（重点）"><a href="#11-3-Explain查看执行计划（重点）" class="headerlink" title="11.3 Explain查看执行计划（重点）"></a>11.3 Explain查看执行计划（重点）</h2><h3 id="11-3-1-Explain执行计划概述"><a href="#11-3-1-Explain执行计划概述" class="headerlink" title="11.3.1 Explain执行计划概述"></a>11.3.1 Explain执行计划概述</h3><p>Explain呈现的执行计划，由一系列Stage组成，这一系列Stage具有依赖关系，每个Stage对应一个MapReduce Job，或者一个文件系统操作等。</p>
<p>若某个Stage对应的一个MapReduce Job，其Map端和Reduce端的计算逻辑分别由Map Operator Tree和Reduce Operator Tree进行描述，Operator Tree由一系列的Operator组成，一个Operator代表在Map或Reduce阶段的一个单一的逻辑操作，例如TableScan Operator，Select Operator，Join Operator等。</p>
<p>下图是由一个执行计划绘制而成：</p>
<img src="图片111.png" alt="图片111" style="zoom: 67%;">

<p>常见的Operator及其作用如下：</p>
<ul>
<li>TableScan：表扫描操作，通常map端第一个操作肯定是表扫描操作</li>
<li>Select Operator：选取操作</li>
<li>Group By Operator：分组聚合操作</li>
<li>Reduce Output Operator：输出到 reduce 操作</li>
<li>Filter Operator：过滤操作</li>
<li>Join Operator：join 操作</li>
<li>File Output Operator：文件输出操作</li>
<li>Fetch Operator 客户端获取数据操作</li>
</ul>
<h3 id="11-3-2-基本语法"><a href="#11-3-2-基本语法" class="headerlink" title="11.3.2 基本语法"></a>11.3.2 基本语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN [FORMATTED | EXTENDED | DEPENDENCY] query-sql</span><br></pre></td></tr></table></figure>

<p>注：FORMATTED、EXTENDED、DEPENDENCY关键字为可选项，各自作用如下。</p>
<ul>
<li>FORMATTED：将执行计划以JSON字符串的形式输出</li>
<li>EXTENDED：输出执行计划中的额外信息，通常是读写的文件名等信息</li>
<li>DEPENDENCY：输出执行计划读取的表及分区</li>
</ul>
<h3 id="11-3-3-案例实操"><a href="#11-3-3-案例实操" class="headerlink" title="11.3.3 案例实操"></a>11.3.3 案例实操</h3><p>（1）部署可视化工具</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd dist/</span><br><span class="line">[root@hadoop102 dist]# python -m SimpleHTTPServer 8900</span><br><span class="line">Serving HTTP on 0.0.0.0 port 8900 ...</span><br></pre></td></tr></table></figure>

<p>（2）访问hadoop102:8900</p>
<p><img src="Snipaste_2023-11-03_14-59-36.png" alt="Snipaste_2023-11-03_14-59-36"></p>
<p>（3）查看下面这条语句的执行计划</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">explain formatted</span><br><span class="line">select order_id,</span><br><span class="line">       sum(sku_num) num</span><br><span class="line">from order_detail</span><br><span class="line">group by order_id;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;STAGE DEPENDENCIES&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Stage-1&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;ROOT STAGE&quot;</span><span class="punctuation">:</span><span class="string">&quot;TRUE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;Stage-0&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;DEPENDENT STAGES&quot;</span><span class="punctuation">:</span><span class="string">&quot;Stage-1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;STAGE PLANS&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Stage-1&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Map Reduce&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Map Operator Tree:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;TableScan&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;alias:&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_detail&quot;</span><span class="punctuation">,</span><span class="attr">&quot;columns:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;order_id&quot;</span><span class="punctuation">,</span><span class="string">&quot;sku_num&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;database:&quot;</span><span class="punctuation">:</span><span class="string">&quot;functions&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 99 Data size: 2756 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;table:&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_detail&quot;</span><span class="punctuation">,</span><span class="attr">&quot;isTempTable:&quot;</span><span class="punctuation">:</span><span class="string">&quot;false&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;TS_0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;children&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Select Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;expressions:&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_id (type: string), sku_num (type: int)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;columnExprMap:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;BLOCK__OFFSET__INSIDE__FILE&quot;</span><span class="punctuation">:</span><span class="string">&quot;BLOCK__OFFSET__INSIDE__FILE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;INPUT__FILE__NAME&quot;</span><span class="punctuation">:</span><span class="string">&quot;INPUT__FILE__NAME&quot;</span><span class="punctuation">,</span><span class="attr">&quot;ROW__ID&quot;</span><span class="punctuation">:</span><span class="string">&quot;ROW__ID&quot;</span><span class="punctuation">,</span><span class="attr">&quot;create_date&quot;</span><span class="punctuation">:</span><span class="string">&quot;create_date&quot;</span><span class="punctuation">,</span><span class="attr">&quot;order_detail_id&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_detail_id&quot;</span><span class="punctuation">,</span><span class="attr">&quot;order_id&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_id&quot;</span><span class="punctuation">,</span><span class="attr">&quot;price&quot;</span><span class="punctuation">:</span><span class="string">&quot;price&quot;</span><span class="punctuation">,</span><span class="attr">&quot;sku_id&quot;</span><span class="punctuation">:</span><span class="string">&quot;sku_id&quot;</span><span class="punctuation">,</span><span class="attr">&quot;sku_num&quot;</span><span class="punctuation">:</span><span class="string">&quot;sku_num&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;outputColumnNames:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;order_id&quot;</span><span class="punctuation">,</span><span class="string">&quot;sku_num&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 99 Data size: 2756 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;SEL_7&quot;</span><span class="punctuation">,</span><span class="attr">&quot;children&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Group By Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;aggregations:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;sum(sku_num)&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;columnExprMap:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_id&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;keys:&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_id (type: string)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;mode:&quot;</span><span class="punctuation">:</span><span class="string">&quot;hash&quot;</span><span class="punctuation">,</span><span class="attr">&quot;outputColumnNames:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;_col0&quot;</span><span class="punctuation">,</span><span class="string">&quot;_col1&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 99 Data size: 2756 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;GBY_8&quot;</span><span class="punctuation">,</span><span class="attr">&quot;children&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Reduce Output Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;columnExprMap:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;KEY._col0&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;VALUE._col0&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;key expressions:&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col0 (type: string)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;sort order:&quot;</span><span class="punctuation">:</span><span class="string">&quot;+&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Map-reduce partition columns:&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col0 (type: string)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 99 Data size: 2756 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value expressions:&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col1 (type: bigint)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;RS_9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;Execution mode:&quot;</span><span class="punctuation">:</span><span class="string">&quot;vectorized&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Reduce Operator Tree:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Group By Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;aggregations:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;sum(VALUE._col0)&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;columnExprMap:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="string">&quot;KEY._col0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;keys:&quot;</span><span class="punctuation">:</span><span class="string">&quot;KEY._col0 (type: string)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;mode:&quot;</span><span class="punctuation">:</span><span class="string">&quot;mergepartial&quot;</span><span class="punctuation">,</span><span class="attr">&quot;outputColumnNames:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;_col0&quot;</span><span class="punctuation">,</span><span class="string">&quot;_col1&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 49 Data size: 1364 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;GBY_4&quot;</span><span class="punctuation">,</span><span class="attr">&quot;children&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;File Output Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;compressed:&quot;</span><span class="punctuation">:</span><span class="string">&quot;false&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 49 Data size: 1364 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;table:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;input format:&quot;</span><span class="punctuation">:</span><span class="string">&quot;org.apache.hadoop.mapred.SequenceFileInputFormat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;output format:&quot;</span><span class="punctuation">:</span><span class="string">&quot;org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;serde:&quot;</span><span class="punctuation">:</span><span class="string">&quot;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;FS_6&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;Stage-0&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Fetch Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;limit:&quot;</span><span class="punctuation">:</span><span class="string">&quot;-1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Processor Tree:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;ListSink&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;LIST_SINK_10&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-11-03_15-05-06.png" alt="Snipaste_2023-11-03_15-05-06"></p>
<p>案例2：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain select sum(score) from score_info;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span>   <span class="comment">//各个 stage 之间的依赖性</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage        <span class="comment">//Stage-1 是根 stage，说明这是开始的 stage</span></span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span>        <span class="comment">//Stage-0 依赖 Stage-1，Stage-1 执行完成后执行Stage-0</span></span><br><span class="line"><span class="string">&quot;&quot;</span></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span>     <span class="comment">//各个 stage 的执行计划</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce  <span class="comment">//表示当前任务执行所用的计算引擎是MapReduce</span></span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span>     <span class="comment">//MAP 端的执行计划树，表示当前描述的Map阶段执行的操作信息</span></span><br><span class="line">          TableScan       <span class="comment">//TableScan：表扫描操作，map 端第一个操作肯定是加载表，所以就是表扫描操作。表示对关键字alias声明的结果集</span></span><br><span class="line">            alias<span class="punctuation">:</span> score_info     <span class="comment">//alias：表名称</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8130</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE  <span class="comment">//Statistics：表统计信息，包含表中数据条数，数据大小等</span></span><br><span class="line">            Select Operator     <span class="comment">//Select Operator：表示在之前的结果集上对列进行投影，即筛选列</span></span><br><span class="line">              expressions<span class="punctuation">:</span> score (type<span class="punctuation">:</span> int)      <span class="comment">//expressions：需要投影（筛选）的字段名称及字段类型</span></span><br><span class="line">              outputColumnNames<span class="punctuation">:</span> score        <span class="comment">//outputColumnNames：输出的列名称</span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8130</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE <span class="comment">//Statistics：表统计信息，包含表中数据条数，数据大小等</span></span><br><span class="line">              Group By Operator    <span class="comment">//Group By Operator：表示在之前的结果集上进行分组聚合操作</span></span><br><span class="line">                aggregations<span class="punctuation">:</span> sum(score)     <span class="comment">//aggregations：表示分组聚合使用的算法</span></span><br><span class="line">                mode<span class="punctuation">:</span> hash      <span class="comment">//mode：聚合模式，值有 hash：随机聚合，就是 hash partition；partial：局部聚合；final：最终聚合</span></span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0      <span class="comment">//outputColumnNames：聚合之后输出列名</span></span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE  <span class="comment">//Statistics： 表统计信息，包含分组聚合之后的数据条数，数据大小等</span></span><br><span class="line">                Reduce Output Operator    <span class="comment">//Reduce Output Operator：输出到 reduce 操作。表示当前描述的是对之前结果聚合后的输出信息，这里表示Map端聚合后的输出信息</span></span><br><span class="line">                  sort order<span class="punctuation">:</span>   <span class="comment">//sort order：值为空 不排序；值为 + 正序排序，值为 - 倒序排序；值为 +- 排序的列为两列，第一列为正序，第二列为倒序</span></span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  value expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)<span class="comment">//指代sum(score)列</span></span><br><span class="line">      Execution mode<span class="punctuation">:</span> vectorized</span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span>     <span class="comment">//Reduce 端的执行计划树，表示当前描述的是Reduce阶段的操作信息</span></span><br><span class="line">        Group By Operator    <span class="comment">//Group By Operator：分组聚合操作</span></span><br><span class="line">          aggregations<span class="punctuation">:</span> sum(VALUE._col0)</span><br><span class="line">          mode<span class="punctuation">:</span> mergepartial</span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          File Output Operator    <span class="comment">//File Output Operator：文件输出操作</span></span><br><span class="line">            compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span>     <span class="comment">//compressed：文件输出的结果是否压缩</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            table<span class="punctuation">:</span>     <span class="comment">//table：表示当前操作的表的信息，包含输入输出文件格式化方式，序列化方式等</span></span><br><span class="line">                input format<span class="punctuation">:</span> org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">                serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"><span class="string">&quot;&quot;</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator     <span class="comment">//Fetch Operator 客户端获取数据操作</span></span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">-1</span>      <span class="comment">//limit，值为 -1 表示不限制条数，其他值为限制的条数</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p>拿到一个执行计划，首先看STAGE DEPENDENCIES信息，它描述了作业之间的依赖关系，即stage-0依赖stage-1的执行结果。stage-0表示客户端读取stage-1的执行结果，stage-1表示整条sql语句的执行过程。可以看到stsge-1分为Map和Reduce两个阶段。相关关键词解析：</p>
<ul>
<li><strong>Map Reduce</strong>：表示当前任务执行所用的计算引擎是MapReduce</li>
<li><strong>Map Operator Tree</strong>：MAP 端的执行计划树，表示当前描述的Map阶段执行的操作信息</li>
<li><strong>Reduce Operator Tree</strong>：Reduce 端的执行计划树，表示当前描述的是Reduce阶段的操作信息</li>
<li><strong>TableScan</strong>：表扫描操作，map 端第一个操作肯定是加载表，所以就是表扫描操作。表示对关键字alias声明的结果集</li>
<li><strong>alias</strong>：表名称</li>
<li><strong>Statistics</strong>：表统计信息，包含表中数据条数，数据大小等</li>
<li><strong>Filter Operator</strong>：表示在之前操作（TableScan）的结果集上进行数据的过滤</li>
<li><strong>predicate</strong>：表示filter operator进行过滤时，所用的谓词（即where语句后跟的过滤条件）</li>
<li><strong>Select Operator</strong>：表示在之前的结果集上对列进行投影，即筛选列</li>
<li><strong>expressions</strong>：需要投影（筛选）的字段名称及字段类型</li>
<li><strong>outputColumnNames</strong>：输出的列名称</li>
<li><strong>Group By Operator</strong>：表示在之前的结果集上进行分组聚合操作</li>
<li><strong>aggregations</strong>：表示分组聚合使用的算法</li>
<li><strong>keys</strong>：表示分组的列</li>
<li><strong>mode</strong>：聚合模式，值有 hash：随机聚合，就是 hash partition；partial：局部聚合；final：最终聚合</li>
<li><strong>Reduce Output Operator</strong>：输出到 reduce 操作。表示当前描述的是对之前结果聚合后的输出信息，这里表示Map端聚合后的输出信息</li>
<li><strong>sort order</strong>：值为空 不排序；值为 + 正序排序，值为 - 倒序排序；值为 +- 排序的列为两列，第一列为正序，第二列为倒序</li>
<li><strong>key expressions&#x2F;value expressions</strong>：MapReduce计算引擎，在Map阶段和Reduce阶段输出的欧式键-值对的形式，这里key expression和value expressions分别描述的就是Map阶段输出的键（key）和值（value）所用的数据列</li>
<li><strong>File Output Operator</strong>：文件输出操作</li>
<li><strong>compressed</strong>：文件输出的结果是否压缩</li>
<li><strong>table</strong>：表示当前操作的表的信息，包含输入输出文件格式化方式，序列化方式等</li>
<li><strong>input format&#x2F;output format</strong>：分别表示文件输入和输出的文件类型</li>
<li><strong>serde</strong>：表示读取表数据的序列化和反序列化的方式</li>
</ul>
<p><strong>一个 HIVE 查询被转换为一个由一个或多个 stage 组成的序列（有向无环图 DAG）。这些 stage 可以是 MapReduce stage，也可以是负责元数据存储的 stage，也可以是负责文件系统的操作（比如移动和重命名）的 stage</strong>。</p>
<p>对于两个写法不同的sql，我们可以观察它们的执行过程，来看两者的效率高低</p>
<p>案例3：explian dependency的用法</p>
<img src="Snipaste_2023-11-29_15-12-21.png" alt="Snipaste_2023-11-29_15-12-21" style="zoom: 50%;">

<p><strong>使用 explain dependency 查看 SQL 查询非分区普通表</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain dependency select s_age,count(1) num from student_orc;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_tb _orc&quot;</span><span class="punctuation">,</span><span class="string">&quot;tabl</span></span><br><span class="line"><span class="string">etype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><strong>使用 explain dependency 查看 SQL 查询分区表</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain dependency select s_age,count(1) num from student_orc_partition;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@ part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=3&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=4&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=5&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=6&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=7&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=8&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-29_15-16-47.png" alt="Snipaste_2023-11-29_15-16-47" style="zoom:50%;">

<p>explain dependency的实际应用</p>
<p>①识别看似等价的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--代码1：</span><br><span class="line">select</span><br><span class="line">a.s_no</span><br><span class="line">from student_orc_partition a</span><br><span class="line">inner join</span><br><span class="line">student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part and a.part&gt;=1 and a.part&lt;=2;</span><br><span class="line"></span><br><span class="line">--代码2：</span><br><span class="line">select</span><br><span class="line">a.s_no</span><br><span class="line">from student_orc_partition a</span><br><span class="line">inner join</span><br><span class="line">student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part</span><br><span class="line">where a.part&gt;=1 and a.part&lt;=2;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//代码1的explain dependency结果：</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//代码2的explain dependency结果：</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;default@student_orc_partition@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span> <span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>通过上面的输出结果可以看到，其实上述的两个 SQL 并不等价，代码 1 在内连接（inner join）中的连接条件（on）中加入非等值的过滤条件后，并没有将内连接的左右两个表按照过滤条件进行过滤，内连接在执行时会多读取 part&#x3D;0 的分区数据。而在代码 2 中，会过滤掉不符合条件的分区。</p>
<p>②识别SQL读取数据范围的差别</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--代码 1：</span><br><span class="line">explain dependency</span><br><span class="line">select</span><br><span class="line">a.s_no</span><br><span class="line">from student_orc_partition a</span><br><span class="line">left join</span><br><span class="line">student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part and b.part&gt;=1 and b.part&lt;=2;</span><br><span class="line"></span><br><span class="line">--代码 2：</span><br><span class="line">explain dependency</span><br><span class="line">select</span><br><span class="line">a.s_no</span><br><span class="line">from student_orc_partition a</span><br><span class="line">left join</span><br><span class="line">student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part and a.part&gt;=1 and a.part&lt;=2;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//代码 1 的 explain dependency 结果：</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;default@student_orc_partition@part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> …中间省略 <span class="number">7</span> 个分区</span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="comment">//代码 2 的 explain dependency 结果：</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> …中间省略 <span class="number">7</span> 个分区</span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> …中间省略 <span class="number">7</span> 个分区</span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>可以看到，对左外连接在连接条件中加入非等值过滤的条件，<strong>如果过滤条件是作用于右表（b 表）有起到过滤的效果，则右表只要扫描两个分区即可，但是左表（a表）会进行全表扫描。如果过滤条件是针对左表，则完全没有起到过滤的作用，那么两个表将进行全表扫描</strong>。这时的情况就如同全外连接一样都需要对两个数据进行全表扫描。</p>
<p>所以，在使用表数据之前尽可能过滤掉不需要的数据，将代码2写成如下形式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">select a.s_no</span><br><span class="line">from (</span><br><span class="line">select s_no, part</span><br><span class="line">from student_orc_partition</span><br><span class="line">--在子查询内部进行过滤</span><br><span class="line">where part&gt;=1 and part&lt;=2</span><br><span class="line">) a</span><br><span class="line">left join student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part;</span><br></pre></td></tr></table></figure>

<p>案例4：explain authorization的用法</p>
<p>通过 explain authorization 可以知道当前 SQL 访问的数据来源（INPUTS） 和数据输出（OUTPUTS），以及当前 Hive 的访问用户 （CURRENT_USER）和操作（OPERATION）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">explain authorization</span><br><span class="line">select variance(s_score) from student_tb_orc;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">INPUTS<span class="punctuation">:</span>  <span class="comment">//数据来源</span></span><br><span class="line">default@student_tb_orc</span><br><span class="line">OUTPUTS<span class="punctuation">:</span>   <span class="comment">//输出路径</span></span><br><span class="line">hdfs<span class="punctuation">:</span><span class="comment">//node01:8020/tmp/hive/hdfs/cbf182a5-8258-4157-9194- 90f1475a3ed5/-mr-10000</span></span><br><span class="line">CURRENT_USER<span class="punctuation">:</span>   <span class="comment">//当前操作用户</span></span><br><span class="line">hdfs</span><br><span class="line">OPERATION<span class="punctuation">:</span>   <span class="comment">//操作类型</span></span><br><span class="line">QUERY</span><br><span class="line">AUTHORIZATION_FAILURES<span class="punctuation">:</span></span><br><span class="line">No privilege &#x27;Select&#x27; found for inputs <span class="punctuation">&#123;</span> database<span class="punctuation">:</span>default<span class="punctuation">,</span> table<span class="punctuation">:</span>student_ tb_orc<span class="punctuation">,</span></span><br><span class="line">columnName<span class="punctuation">:</span>s_score<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="11-3-4-简单SQL的执行计划解读"><a href="#11-3-4-简单SQL的执行计划解读" class="headerlink" title="11.3.4 简单SQL的执行计划解读"></a>11.3.4 简单SQL的执行计划解读</h3><p>简单SQL只不含有列操作、条件过滤、UDF、聚合和连接等操作的SQL，这种类型的SQL在执行时只会用到Map阶段，因为这类SQL只有从表中读取数据并执行数据行的过滤，并没有需要将分布式文件存储在其他节点的数据与该节点的数据放在一起处理的必要，所以不需要进行Reduce操作。对应这一类SQL被归结为select-from-where型。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select fingerprint,score</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      <span class="comment">//Map操作树</span></span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan <span class="comment">//表遍历的操作</span></span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df <span class="comment">//alias表示遍历的表</span></span><br><span class="line">            <span class="comment">//这个阶段的统计信息，处理232行数据，数据99437bytes</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            <span class="comment">//在tablescan基础上进行过滤（filter操作）</span></span><br><span class="line">            Filter Operator</span><br><span class="line">              <span class="comment">//predicate表示过滤操作的条件谓词</span></span><br><span class="line">              predicate<span class="punctuation">:</span> (score &gt; <span class="number">1000</span>) (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              <span class="comment">//filter操作阶段的的统计信息，经过过滤剩下77行数据</span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//在filter过滤结果集上进行列的筛选</span></span><br><span class="line">              Select Operator</span><br><span class="line">                <span class="comment">//表示选择过滤的列</span></span><br><span class="line">                expressions<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> score (type<span class="punctuation">:</span> string)</span><br><span class="line">                <span class="comment">//输出两列</span></span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                <span class="comment">//limit限制行数阶段</span></span><br><span class="line">                Limit</span><br><span class="line">                  <span class="comment">//平台系统默认限制输出行数100000行</span></span><br><span class="line">                  Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  <span class="comment">//文件输出操作</span></span><br><span class="line">                  File Output Operator</span><br><span class="line">                    <span class="comment">//输出结果，不是压缩的</span></span><br><span class="line">                    compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                    Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                    table<span class="punctuation">:</span></span><br><span class="line">                        input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                        output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                        serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p><strong>注意1：从执行计划中我们貌似看不到分区过滤，这是因为分区列筛选其实是在Map的上一个阶段，即在输入阶段进行路径的过滤。所以执行计划看不出来。</strong></p>
<p><strong>注意：每一个操作阶段后面都会接一个Statistics表示该操作阶段的统计信息</strong></p>
<p><strong>该过程只有Map阶段，在Map中的运行逻辑如下</strong>：</p>
<p><strong>表扫描操作（TableScan）—》过滤操作（Filter Operator）—》列投影操作（select Operator）—》行数限制操作（Limit）—》文件输出操作（File Output Operator）</strong></p>
<h3 id="11-3-5-带普通函数、操作符SQL的执行计划解读"><a href="#11-3-5-带普通函数、操作符SQL的执行计划解读" class="headerlink" title="11.3.5 带普通函数、操作符SQL的执行计划解读"></a>11.3.5 带普通函数、操作符SQL的执行计划解读</h3><p>普通函数特指除UDTF、UDAF和窗口函数之外的函数，这类SQL可以归结为select-operation-from-where-operation</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select nvl(fingerprint,&#x27;&#x27;),</span><br><span class="line">       case when score &gt; 100 then &#x27;高分&#x27; else &#x27;低分&#x27; end level,</span><br><span class="line">       concat(score,&#x27;-&#x27;,&#x27;name&#x27;) as sid</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27; and score &gt; 1000</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate<span class="punctuation">:</span> (score &gt; <span class="number">1000</span>) (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//列投影</span></span><br><span class="line">              Select Operator</span><br><span class="line">                expressions<span class="punctuation">:</span> NVL(fingerprint<span class="punctuation">,</span>&#x27;&#x27;) (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> CASE WHEN ((score &gt; <span class="number">100</span>)) THEN (&#x27;高分&#x27;) ELSE (&#x27;低分&#x27;) END (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> concat(score<span class="punctuation">,</span> &#x27;-&#x27;<span class="punctuation">,</span> &#x27;name&#x27;) (type<span class="punctuation">:</span> string)</span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1<span class="punctuation">,</span> _col2</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                Limit</span><br><span class="line">                  Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  File Output Operator</span><br><span class="line">                    compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                    Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                    table<span class="punctuation">:</span></span><br><span class="line">                        input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                        output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                        serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p>可以发现，这种类型的SQL也只有Map阶段的操作，Map操作里的任务流程也是一样的</p>
<h3 id="11-3-6-带聚合函数的SQL执行计划解读"><a href="#11-3-6-带聚合函数的SQL执行计划解读" class="headerlink" title="11.3.6 带聚合函数的SQL执行计划解读"></a>11.3.6 带聚合函数的SQL执行计划解读</h3><p>汇总操作，数据可能分布在不同的机器节点上，这决定了带聚合函数的SQL，不仅需要Map处理过程，还需要Reduce的数据汇总过程，这种SQL称之为select-aggr_function-from-where-groupby类型</p>
<h4 id="（1）在Reduce阶段聚合的SQL"><a href="#（1）在Reduce阶段聚合的SQL" class="headerlink" title="（1）在Reduce阶段聚合的SQL"></a>（1）在Reduce阶段聚合的SQL</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">set hive.map.aggr = false;</span><br><span class="line">explain</span><br><span class="line">select fingerprint,displayname,packagename,</span><br><span class="line">       avg(score) as avg_score,</span><br><span class="line">       sum(downloadcount) as downloadcount</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27; and score &gt; 1000</span><br><span class="line">group by fingerprint,displayname,packagename</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      <span class="comment">//Map操作树</span></span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          <span class="comment">//表扫描</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            <span class="comment">//过滤操作</span></span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate<span class="punctuation">:</span> (score &gt; <span class="number">1000</span>) (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//输出阶段【其实就是告诉reduce阶段：在Map阶段输出五列fingerprint，displayname，packagename，score，downloadcount，其中fingerprint，displayname，packagename为输出的key，score，downloadcount为输出的value。输出时按fingerprint，displayname，packagename进行分区和排序】</span></span><br><span class="line">              Reduce Output Operator</span><br><span class="line">                <span class="comment">//表示Map阶段输出到key，本例中是fingerprint，displayname，packagename</span></span><br><span class="line">                key expressions<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> displayname (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> packagename (type<span class="punctuation">:</span> string)</span><br><span class="line">                <span class="comment">//表示Map输出后是否进行排序，+表示正序排序，-表示倒序排序，一个符号代表对一列进行排序，两个符号代表两列，以此类推</span></span><br><span class="line">                sort order<span class="punctuation">:</span> +++</span><br><span class="line">                <span class="comment">//指定一个或者多个列字段，表示在Map阶段输出数据时，根据这些字段来区分数据</span></span><br><span class="line">                Map-reduce partition columns<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> displayname (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> packagename (type<span class="punctuation">:</span> string)</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                TopN Hash Memory Usage<span class="punctuation">:</span> <span class="number">0.4</span></span><br><span class="line">                <span class="comment">//表示Map阶段输出到value，本例中说score，downloadcount</span></span><br><span class="line">                value expressions<span class="punctuation">:</span> score (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> downloadcount (type<span class="punctuation">:</span> bigint)</span><br><span class="line">      <span class="comment">//Reduce操作树</span></span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        <span class="comment">//分组聚合操作</span></span><br><span class="line">        Group By Operator</span><br><span class="line">          <span class="comment">//指定分组聚合的算法，VALUE指代的就是Map阶段Reduce Output Operator阶段中所指定的value expressions，VALUE._col0指代score，VALUE._col1指代downloadcount</span></span><br><span class="line">          aggregations<span class="punctuation">:</span> avg(VALUE._col0)<span class="punctuation">,</span> sum(VALUE._col1)</span><br><span class="line">          <span class="comment">//指代按哪些列进行分组，KEY指代的就是Map阶段Reduce Output Operator阶段中所指定的key expressions，KEY._col0指代fingerprint，KEY._col1指代displayname，KEY._col2指代packagename</span></span><br><span class="line">          keys<span class="punctuation">:</span> KEY._col0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> KEY._col1 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> KEY._col2 (type<span class="punctuation">:</span> string)</span><br><span class="line">          <span class="comment">//mode表示整个Hive执行过程的模式，complete表示所有的聚合操作都在Reduce阶段中进行</span></span><br><span class="line">          mode<span class="punctuation">:</span> complete</span><br><span class="line">          <span class="comment">//指定输出的列，一般对应所有分组字段和聚合字段</span></span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1<span class="punctuation">,</span> _col2<span class="punctuation">,</span> _col3<span class="punctuation">,</span> _col4</span><br><span class="line">          skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          Limit</span><br><span class="line">            Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            File Output Operator</span><br><span class="line">              compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              table<span class="punctuation">:</span></span><br><span class="line">                  input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                  output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                  serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p><strong>Map阶段分以下几步：</strong></p>
<p><strong>表扫描操作（TableScan）—》过滤操作（Filter Operator）—》输出到Reduce操作（Reduce Output Operation）</strong></p>
<p>其中，Reduce Output Operation的内容就是Shuffle</p>
<h4 id="（2）在Map和Reduce阶段聚合的SQL"><a href="#（2）在Map和Reduce阶段聚合的SQL" class="headerlink" title="（2）在Map和Reduce阶段聚合的SQL"></a>（2）在Map和Reduce阶段聚合的SQL</h4><p>上一个案例我们知道Map阶段其实没做计算的操作，只是对数据进行了重新组织，方便Reduce的分组聚合。下面我们来启用Map端聚合，在Map阶段做一些计算的操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">set hive.map.aggr = true;</span><br><span class="line">explain</span><br><span class="line">select fingerprint,displayname,packagename,</span><br><span class="line">       avg(score) as avg_score,</span><br><span class="line">       sum(downloadcount) as downloadcount</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27; and score &gt; 1000</span><br><span class="line">group by fingerprint,displayname,packagename</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate<span class="punctuation">:</span> (score &gt; <span class="number">1000</span>) (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//分组聚合操作</span></span><br><span class="line">              Group By Operator</span><br><span class="line">                <span class="comment">//指定聚合的算法</span></span><br><span class="line">                aggregations<span class="punctuation">:</span> avg(score)<span class="punctuation">,</span> sum(downloadcount)</span><br><span class="line">                <span class="comment">//指定分组的列</span></span><br><span class="line">                keys<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> displayname (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> packagename (type<span class="punctuation">:</span> string)</span><br><span class="line">                <span class="comment">//指定聚合的模式，采用hash表的格式</span></span><br><span class="line">                mode<span class="punctuation">:</span> hash</span><br><span class="line">                <span class="comment">//指定改阶段输出的列</span></span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1<span class="punctuation">,</span> _col2<span class="punctuation">,</span> _col3<span class="punctuation">,</span> _col4</span><br><span class="line">                skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                <span class="comment">//描述的是Map输出数据到Reduce阶段这整个过程的操作</span></span><br><span class="line">                Reduce Output Operator</span><br><span class="line">                  <span class="comment">//表示Map阶段最终输出的key</span></span><br><span class="line">                  key expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col1 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col2 (type<span class="punctuation">:</span> string)</span><br><span class="line">                  <span class="comment">//对列进行排序</span></span><br><span class="line">                  sort order<span class="punctuation">:</span> +++</span><br><span class="line">                  <span class="comment">//表示在Map阶段输出数据时，会根据这些字段来分区</span></span><br><span class="line">                  Map-reduce partition columns<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col1 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col2 (type<span class="punctuation">:</span> string)</span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  TopN Hash Memory Usage<span class="punctuation">:</span> <span class="number">0.4</span></span><br><span class="line">                  <span class="comment">//表示Map阶段最终输出的value，Map阶段不计算平均值，只计算了总数和对应的个数</span></span><br><span class="line">                  value expressions<span class="punctuation">:</span> _col3 (type<span class="punctuation">:</span> struct&lt;count<span class="punctuation">:</span>bigint<span class="punctuation">,</span>sum<span class="punctuation">:</span>double<span class="punctuation">,</span>input<span class="punctuation">:</span>string&gt;)<span class="punctuation">,</span> _col4 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        Group By Operator</span><br><span class="line">          aggregations<span class="punctuation">:</span> avg(VALUE._col0)<span class="punctuation">,</span> sum(VALUE._col1)</span><br><span class="line">          keys<span class="punctuation">:</span> KEY._col0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> KEY._col1 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> KEY._col2 (type<span class="punctuation">:</span> string)</span><br><span class="line">          mode<span class="punctuation">:</span> mergepartial</span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1<span class="punctuation">,</span> _col2<span class="punctuation">,</span> _col3<span class="punctuation">,</span> _col4</span><br><span class="line">          skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          Limit</span><br><span class="line">            Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            File Output Operator</span><br><span class="line">              compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">38</span> Data size<span class="punctuation">:</span> <span class="number">16286</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              table<span class="punctuation">:</span></span><br><span class="line">                  input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                  output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                  serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p><strong>可见本次Map阶段的流程为：</strong></p>
<p><strong>表扫描（TableScan）—》过滤操作（Filter Operator）—》分组聚合（Group By Operator）—》输出到Reduce操作（Reduce Output Operator）</strong></p>
<p><strong>比之前的执行计划多了分组聚合阶段，可以看到，在Map端和Reduce端都进行了分组聚合，在Map进行预聚合，在Reduce端进行了最终的聚合。</strong></p>
<h4 id="（3）高级分组聚合（了解）"><a href="#（3）高级分组聚合（了解）" class="headerlink" title="（3）高级分组聚合（了解）"></a>（3）高级分组聚合（了解）</h4><p>高级分组聚合指的是在聚合的时候使用GROUPING SETS、cube和rollup的分组聚合</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">set hive.map.aggr = true;</span><br><span class="line">explain</span><br><span class="line">select fingerprint,displayname,packagename,</span><br><span class="line">       avg(score) as avg_score,</span><br><span class="line">       sum(downloadcount) as downloadcount</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27; and score &gt; 1000</span><br><span class="line">group by fingerprint,displayname,packagename</span><br><span class="line">grouping sets((fingerprint,displayname),(displayname,packagename))</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      <span class="comment">//Map操作树</span></span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate<span class="punctuation">:</span> (score &gt; <span class="number">1000</span>) (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//分组聚合阶段</span></span><br><span class="line">              Group By Operator</span><br><span class="line">              <span class="comment">//分组聚合的算法avg和sum</span></span><br><span class="line">                aggregations<span class="punctuation">:</span> avg(score)<span class="punctuation">,</span> sum(downloadcount)</span><br><span class="line">                <span class="comment">//指定分组的列，这里包含了一列固定列&#x27;0&#x27;</span></span><br><span class="line">                keys<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> displayname (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> packagename (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> <span class="number">0</span> (type<span class="punctuation">:</span> int)</span><br><span class="line">                mode<span class="punctuation">:</span> hash</span><br><span class="line">                <span class="comment">//最终输出了6列，依次表示fingerprint (type: string), displayname (type: string), packagename (type: string), 0 (type: int)，avg(score), sum(downloadcount)</span></span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1<span class="punctuation">,</span> _col2<span class="punctuation">,</span> _col3<span class="punctuation">,</span> _col4<span class="punctuation">,</span> _col5</span><br><span class="line">                skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">154</span> Data size<span class="punctuation">:</span> <span class="number">66004</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                <span class="comment">//表示该阶段为Map阶段聚合后的操作，准备输出到Reudce阶段</span></span><br><span class="line">                Reduce Output Operator</span><br><span class="line">                  <span class="comment">//Map阶段最终输出的key，依次表示fingerprint (type: string), displayname (type: string), packagename (type: string), 0 (type: int)</span></span><br><span class="line">                  key expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col1 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col2 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col3 (type<span class="punctuation">:</span> int)</span><br><span class="line">                  sort order<span class="punctuation">:</span> ++++</span><br><span class="line">                  <span class="comment">//表示Map阶段数据输出的分区列，用fingerprint , displayname , packagename , 0进行分区</span></span><br><span class="line">                  Map-reduce partition columns<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col1 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col2 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col3 (type<span class="punctuation">:</span> int)</span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">154</span> Data size<span class="punctuation">:</span> <span class="number">66004</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  TopN Hash Memory Usage<span class="punctuation">:</span> <span class="number">0.4</span></span><br><span class="line">                  <span class="comment">//Map阶段输出的value</span></span><br><span class="line">                  value expressions<span class="punctuation">:</span> _col4 (type<span class="punctuation">:</span> struct&lt;count<span class="punctuation">:</span>bigint<span class="punctuation">,</span>sum<span class="punctuation">:</span>double<span class="punctuation">,</span>input<span class="punctuation">:</span>string&gt;)<span class="punctuation">,</span> _col5 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">      <span class="comment">//Reduce操作树</span></span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        <span class="comment">//分组聚合操作</span></span><br><span class="line">        Group By Operator</span><br><span class="line">          <span class="comment">//分组聚合算法，avg(score), sum(downloadcount)</span></span><br><span class="line">          aggregations<span class="punctuation">:</span> avg(VALUE._col0)<span class="punctuation">,</span> sum(VALUE._col1)</span><br><span class="line">          <span class="comment">//指定分组的key，fingerprint (type: string), displayname (type: string), packagename (type: string), 0 (type: int)</span></span><br><span class="line">          keys<span class="punctuation">:</span> KEY._col0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> KEY._col1 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> KEY._col2 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> KEY._col3 (type<span class="punctuation">:</span> int)</span><br><span class="line">          mode<span class="punctuation">:</span> mergepartial</span><br><span class="line">          <span class="comment">//表示最终输出的列，fingerprint (type: string), displayname (type: string), packagename (type: string)，avg(score), sum(downloadcount)</span></span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1<span class="punctuation">,</span> _col2<span class="punctuation">,</span> _col4<span class="punctuation">,</span> _col5</span><br><span class="line">          skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          <span class="comment">//表示是否对最终输出的grouping id进行修剪，如果为true，则表示在输出列时会将key expressions或者keys的最后一列进行抛弃，案例中指&#x27;0&#x27;列</span></span><br><span class="line">          pruneGroupingSetId<span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">          <span class="comment">//表示在该阶段处理的投影操作（列筛选）</span></span><br><span class="line">          Select Operator</span><br><span class="line">            <span class="comment">//输出的最终的列表达式，fingerprint (type: string), displayname (type: string), packagename (type: string)，avg(score), sum(downloadcount)</span></span><br><span class="line">            expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col1 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col2 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> _col4 (type<span class="punctuation">:</span> double)<span class="punctuation">,</span> _col5 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">            <span class="comment">//分配各列新名</span></span><br><span class="line">            outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1<span class="punctuation">,</span> _col2<span class="punctuation">,</span> _col3<span class="punctuation">,</span> _col4</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Limit</span><br><span class="line">              Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              File Output Operator</span><br><span class="line">                compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">77</span> Data size<span class="punctuation">:</span> <span class="number">33002</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                table<span class="punctuation">:</span></span><br><span class="line">                    input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<h3 id="11-3-7-带窗口、分析函数的SQL执行计划解读"><a href="#11-3-7-带窗口、分析函数的SQL执行计划解读" class="headerlink" title="11.3.7 带窗口、分析函数的SQL执行计划解读"></a>11.3.7 带窗口、分析函数的SQL执行计划解读</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select fingerprint,</span><br><span class="line">       row_number() over(partition by displayname order by score) rk</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      <span class="comment">//Map操作树</span></span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          <span class="comment">//扫描表</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            <span class="comment">//描述Map传输到Reduce输入到整个过程【Map阶段输出三列：key：displayname (type: string), score (type: string)，value：fingerprint (type: string)；分区列为displayname (type: string)】</span></span><br><span class="line">            Reduce Output Operator</span><br><span class="line">              <span class="comment">//表示Map阶段输出key包含两个列，displayname (type: string), score (type: string)</span></span><br><span class="line">              key expressions<span class="punctuation">:</span> displayname (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> score (type<span class="punctuation">:</span> string)</span><br><span class="line">              sort order<span class="punctuation">:</span> ++</span><br><span class="line">              <span class="comment">//Map阶段采用的分区器的分区列是displayname (type: string)</span></span><br><span class="line">              Map-reduce partition columns<span class="punctuation">:</span> displayname (type<span class="punctuation">:</span> string)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//Map阶段输出的value值</span></span><br><span class="line">              value expressions<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)</span><br><span class="line">      <span class="comment">//Reduce操作树</span></span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        <span class="comment">//投影操作</span></span><br><span class="line">        Select Operator </span><br><span class="line">          <span class="comment">//VALUE._col21 (type: string)：对应Map阶段输出的value，即fingerprint (type: string)</span></span><br><span class="line">          <span class="comment">//KEY.reducesinkkey0 (type: string)：对应Map阶段输出的key的第一列，即displayname (type: string)</span></span><br><span class="line">          <span class="comment">//KEY.reducesinkkey1 (type: string)：对应Map阶段输出的key的第二列，即score (type: string)</span></span><br><span class="line">          expressions<span class="punctuation">:</span> KEY.reducesinkkey0 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> VALUE._col21 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> KEY.reducesinkkey1 (type<span class="punctuation">:</span> string)</span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col22<span class="punctuation">,</span> _col23</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          <span class="comment">//窗口/分析函数操作</span></span><br><span class="line">          PTF Operator</span><br><span class="line">            <span class="comment">//函数定义</span></span><br><span class="line">            Function definitions<span class="punctuation">:</span></span><br><span class="line">                Input definition</span><br><span class="line">                  input alias<span class="punctuation">:</span> ptf_0</span><br><span class="line">                  output shape<span class="punctuation">:</span> _col0<span class="punctuation">:</span> string<span class="punctuation">,</span> _col22<span class="punctuation">:</span> string<span class="punctuation">,</span> _col23<span class="punctuation">:</span> string</span><br><span class="line">                  type<span class="punctuation">:</span> WINDOWING</span><br><span class="line">                <span class="comment">//窗口的定义</span></span><br><span class="line">                Windowing table definition</span><br><span class="line">                  input alias<span class="punctuation">:</span> ptf_1</span><br><span class="line">                  name<span class="punctuation">:</span> windowingtablefunction</span><br><span class="line">                  <span class="comment">//窗口函数的排序列，对应over子句的score</span></span><br><span class="line">                  order by<span class="punctuation">:</span> _col23 ASC NULLS FIRST</span><br><span class="line">                  <span class="comment">//窗口函数的分区列，对应over子句的displayname</span></span><br><span class="line">                  partition by<span class="punctuation">:</span> _col0</span><br><span class="line">                  raw input shape<span class="punctuation">:</span></span><br><span class="line">                  window functions<span class="punctuation">:</span></span><br><span class="line">                      window function definition</span><br><span class="line">                        alias<span class="punctuation">:</span> row_number_window_0</span><br><span class="line">                        <span class="comment">//窗口函数的方法</span></span><br><span class="line">                        name<span class="punctuation">:</span> row_number</span><br><span class="line">                        <span class="comment">//窗口函数对应的java类</span></span><br><span class="line">                        window function<span class="punctuation">:</span> GenericUDAFRowNumberEvaluator</span><br><span class="line">                        <span class="comment">//表示当前窗口上下边界，默认PRECEDING(MAX)~FOLLOWING(MAX)，MAX表示无边界，即会计算整个分区的数据</span></span><br><span class="line">                        window frame<span class="punctuation">:</span> PRECEDING(MAX)~FOLLOWING(MAX)</span><br><span class="line">                        isPivotResult<span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Select Operator</span><br><span class="line">              <span class="comment">//_col22表示fingerprint，row_number_window_0表示窗口/分析函数计算结果输出的列，即rk</span></span><br><span class="line">              expressions<span class="punctuation">:</span> _col22 (type<span class="punctuation">:</span> string)<span class="punctuation">,</span> row_number_window_0 (type<span class="punctuation">:</span> int)</span><br><span class="line">              outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              Limit</span><br><span class="line">                Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                File Output Operator</span><br><span class="line">                  compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  table<span class="punctuation">:</span></span><br><span class="line">                      input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                      output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                      serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<h3 id="11-3-8-表连接的SQL执行计划解读"><a href="#11-3-8-表连接的SQL执行计划解读" class="headerlink" title="11.3.8 表连接的SQL执行计划解读"></a>11.3.8 表连接的SQL执行计划解读</h3><h4 id="（1）内连接和外连接"><a href="#（1）内连接和外连接" class="headerlink" title="（1）内连接和外连接"></a>（1）内连接和外连接</h4><p>执行计划中，内连接与外连接基本一致，唯一区别在于Reduce阶段的Join Operator</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select t.account_id,</span><br><span class="line">       t.product_name</span><br><span class="line">from ks_ad_dw.ad_dim_account_info_df t </span><br><span class="line">inner join ks_ad_dw.dim_ad_active_account_di a </span><br><span class="line">on t.account_id=a.account_id and a.p_date = &#x27;20240717&#x27;</span><br><span class="line">where t.p_date = &#x27;20240717&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      <span class="comment">//Map操作树</span></span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          <span class="comment">//扫描表操作1</span></span><br><span class="line">          TableScan</span><br><span class="line">            <span class="comment">//表别名</span></span><br><span class="line">            alias<span class="punctuation">:</span> t</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">292534450</span> Data size<span class="punctuation">:</span> <span class="number">8331296902</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            <span class="comment">//过滤操作1</span></span><br><span class="line">            Filter Operator</span><br><span class="line">              <span class="comment">//对匹配字段进行非空过滤</span></span><br><span class="line">              predicate<span class="punctuation">:</span> account_id is not <span class="literal"><span class="keyword">null</span></span> (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">292534450</span> Data size<span class="punctuation">:</span> <span class="number">8331296902</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//Map端输出到Reduce操作1</span></span><br><span class="line">              Reduce Output Operator</span><br><span class="line">                key expressions<span class="punctuation">:</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                sort order<span class="punctuation">:</span> +</span><br><span class="line">                Map-reduce partition columns<span class="punctuation">:</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">292534450</span> Data size<span class="punctuation">:</span> <span class="number">8331296902</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                value expressions<span class="punctuation">:</span> product_name (type<span class="punctuation">:</span> string)</span><br><span class="line">          <span class="comment">//扫描表操作2</span></span><br><span class="line">          TableScan</span><br><span class="line">            <span class="comment">//表别名</span></span><br><span class="line">            alias<span class="punctuation">:</span> a</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            <span class="comment">//过滤操作2</span></span><br><span class="line">            Filter Operator</span><br><span class="line">              <span class="comment">//对匹配字段进行非空过滤</span></span><br><span class="line">              predicate<span class="punctuation">:</span> account_id is not <span class="literal"><span class="keyword">null</span></span> (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//Map端输出到Reduce操作2</span></span><br><span class="line">              Reduce Output Operator</span><br><span class="line">                key expressions<span class="punctuation">:</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                sort order<span class="punctuation">:</span> +</span><br><span class="line">                Map-reduce partition columns<span class="punctuation">:</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">      <span class="comment">//Reduce操作树</span></span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        <span class="comment">//表连接操作</span></span><br><span class="line">        Join Operator</span><br><span class="line">          condition map<span class="punctuation">:</span></span><br><span class="line">               Inner Join <span class="number">0</span> to <span class="number">1</span> <span class="comment">//指定两个数据集进行匹配，并声明了他们之间的连接算法，本例表示0和1数据集进行匹配，连接算法采用inner join</span></span><br><span class="line">          <span class="comment">//指定两表连接到条件</span></span><br><span class="line">          keys<span class="punctuation">:</span></span><br><span class="line">            <span class="number">0</span> account_id (type<span class="punctuation">:</span> bigint)<span class="comment">//0指的是Map阶段一个表输出的数据集，该案例指t输出的数据集，account_id表示该数据集和另外一个数据集匹配的条件</span></span><br><span class="line">            <span class="number">1</span> account_id (type<span class="punctuation">:</span> bigint)<span class="comment">//0指的是Map阶段另外一个表输出的数据集，该案例指a输出的数据集，account_id表示该数据集和另外一个数据集匹配的条件</span></span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col18</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">321787901</span> Data size<span class="punctuation">:</span> <span class="number">9164426790</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          Select Operator</span><br><span class="line">            expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)<span class="punctuation">,</span> _col18 (type<span class="punctuation">:</span> string)</span><br><span class="line">            outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">321787901</span> Data size<span class="punctuation">:</span> <span class="number">9164426790</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Limit</span><br><span class="line">              Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">100000</span> Data size<span class="punctuation">:</span> <span class="number">2800000</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              File Output Operator</span><br><span class="line">                compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">100000</span> Data size<span class="punctuation">:</span> <span class="number">2800000</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                table<span class="punctuation">:</span></span><br><span class="line">                    input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p>与之前任务中不同的是Map会同时读取两个表，都会经历TableScan-Filter-Reduce Output这三个操作。其中Filter操作，两表都会进行匹配字段的非空过滤，这是内连接内置的过滤；Reduce Output操作，定义表在Map阶段输出到数据形式，两个Reduce Output表示内容一致，key输出的字段是account_id，在输出时采用正序，数据分区字段也是account_id。也就是说，两个表在经过Map处理后以相同的key进行排序和分区，最后会将相同key的数据传递到相同的Reduce任务中。</p>
<p>如果使用全（左，右）外连接分别代替inner join的写法，所打印的执行计划区别只有Condition map</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">full outer join: Outer Join 0 to 1;</span><br><span class="line">left outer join: Left Join 0 to 1;</span><br><span class="line">right outer join: Right Outer 0 to 1;</span><br></pre></td></tr></table></figure>

<h4 id="（2）左半连接"><a href="#（2）左半连接" class="headerlink" title="（2）左半连接"></a>（2）左半连接</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select t.account_id,</span><br><span class="line">        t.product_name</span><br><span class="line">from ks_ad_dw.ad_dim_account_info_df t </span><br><span class="line">left semi join ks_ad_dw.dim_ad_active_account_di a </span><br><span class="line">on t.account_id=a.account_id and a.p_date = &#x27;20240717&#x27;</span><br><span class="line">where t.p_date = &#x27;20240717&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map </span><br><span class="line">      <span class="comment">//Map操作树</span></span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> t</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">292534450</span> Data size<span class="punctuation">:</span> <span class="number">8331296902</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate<span class="punctuation">:</span> account_id is not <span class="literal"><span class="keyword">null</span></span> (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">292534450</span> Data size<span class="punctuation">:</span> <span class="number">8331296902</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              Reduce Output Operator</span><br><span class="line">                key expressions<span class="punctuation">:</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                sort order<span class="punctuation">:</span> +</span><br><span class="line">                Map-reduce partition columns<span class="punctuation">:</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">292534450</span> Data size<span class="punctuation">:</span> <span class="number">8331296902</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                value expressions<span class="punctuation">:</span> product_name (type<span class="punctuation">:</span> string)</span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> a</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate<span class="punctuation">:</span> account_id is not <span class="literal"><span class="keyword">null</span></span> (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              Select Operator</span><br><span class="line">                expressions<span class="punctuation">:</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                <span class="comment">//在a表进行分组聚合操作，作用是数据去重，减少数据量</span></span><br><span class="line">                Group By Operator</span><br><span class="line">                  keys<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)<span class="punctuation">,</span> &#x27;<span class="number">20240717</span>&#x27; (type<span class="punctuation">:</span> string)</span><br><span class="line">                  mode<span class="punctuation">:</span> hash</span><br><span class="line">                  outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1</span><br><span class="line">                  skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  Reduce Output Operator</span><br><span class="line">                    key expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                    sort order<span class="punctuation">:</span> +</span><br><span class="line">                    Map-reduce partition columns<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                    Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">      <span class="comment">//Reduce操作树</span></span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        Join Operator</span><br><span class="line">          condition map<span class="punctuation">:</span></span><br><span class="line">               Left Semi Join <span class="number">0</span> to <span class="number">1</span></span><br><span class="line">          keys<span class="punctuation">:</span></span><br><span class="line">            <span class="number">0</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">            <span class="number">1</span> _col0 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col18</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">321787901</span> Data size<span class="punctuation">:</span> <span class="number">9164426790</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          Select Operator</span><br><span class="line">            expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)<span class="punctuation">,</span> _col18 (type<span class="punctuation">:</span> string)</span><br><span class="line">            outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">321787901</span> Data size<span class="punctuation">:</span> <span class="number">9164426790</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Limit</span><br><span class="line">              Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">100000</span> Data size<span class="punctuation">:</span> <span class="number">2800000</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              File Output Operator</span><br><span class="line">                compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">100000</span> Data size<span class="punctuation">:</span> <span class="number">2800000</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                table<span class="punctuation">:</span></span><br><span class="line">                    input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<h2 id="11-4-HQL语法优化之分组聚合优化"><a href="#11-4-HQL语法优化之分组聚合优化" class="headerlink" title="11.4 HQL语法优化之分组聚合优化"></a>11.4 HQL语法优化之分组聚合优化</h2><h3 id="11-4-1-优化说明"><a href="#11-4-1-优化说明" class="headerlink" title="11.4.1 优化说明"></a>11.4.1 优化说明</h3><p>Hive中未经优化的分组聚合，是通过一个MapReduce Job实现的。Map端负责读取数据，并按照分组字段分区，通过Shuffle，将数据发往Reduce端，各组数据在Reduce端完成最终的聚合运算。</p>
<p>Hive对分组聚合的优化<strong>主要围绕着减少Shuffle数据量进行</strong>，具体做法是map-side聚合。所谓map-side聚合，就是在map端维护一个hash table，利用其完成部分的聚合，然后将部分聚合的结果，按照分组字段分区，发送至reduce端，完成最终的聚合。map-side聚合能有效减少shuffle的数据量，提高分组聚合运算的效率。</p>
<p>map-side 聚合相关的参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--启用map-side聚合</span><br><span class="line">set hive.map.aggr=true;</span><br><span class="line"></span><br><span class="line">--用于检测源表数据是否适合进行map-side聚合。检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。</span><br><span class="line">set hive.map.aggr.hash.min.reduction=0.5;</span><br><span class="line"></span><br><span class="line">--用于检测源表是否适合map-side聚合的条数。</span><br><span class="line">set hive.groupby.mapaggr.checkinterval=100000;</span><br><span class="line"></span><br><span class="line">--map-side聚合所用的hash table，占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。</span><br><span class="line">set hive.map.aggr.hash.force.flush.memory.threshold=0.9;</span><br></pre></td></tr></table></figure>

<h3 id="11-4-2-生产环境实操举例"><a href="#11-4-2-生产环境实操举例" class="headerlink" title="11.4.2 生产环境实操举例"></a>11.4.2 生产环境实操举例</h3><p>注意：目前在很多公司的生产环境参数hive.map.aggr已经自动开启为true；</p>
<p>优化前：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">set hive.map.aggr = false;</span><br><span class="line">--explain formatted</span><br><span class="line">select t.account_id,</span><br><span class="line">       count(*)</span><br><span class="line">from ks_ad_dw.ad_log_full_hi t</span><br><span class="line">where p_date = &#x27;20240713&#x27; and p_hourmin = &#x27;0900&#x27;</span><br><span class="line">group by t.account_id</span><br></pre></td></tr></table></figure>

<img src="graph.png" alt="graph" style="zoom: 33%;">

<p>优化后：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">set hive.map.aggr = true;</span><br><span class="line">--explain formatted</span><br><span class="line">select t.account_id,</span><br><span class="line">       count(*)</span><br><span class="line">from ks_ad_dw.ad_log_full_hi t</span><br><span class="line">where p_date = &#x27;20240713&#x27; and p_hourmin = &#x27;0900&#x27;</span><br><span class="line">group by t.account_id</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-07-19_15-07-57.png" alt="Snipaste_2024-07-19_15-07-57" style="zoom: 50%;">

<p>可见在开启map-side聚合后Map Operator Tree中增加了一个Group By Operator</p>
<h2 id="11-5-HQL语法优化之Join优化"><a href="#11-5-HQL语法优化之Join优化" class="headerlink" title="11.5 HQL语法优化之Join优化"></a>11.5 HQL语法优化之Join优化</h2><h3 id="11-5-1-Join算法概述"><a href="#11-5-1-Join算法概述" class="headerlink" title="11.5.1 Join算法概述"></a>11.5.1 Join算法概述</h3><p><img src="Snipaste_2024-07-27_08-55-26.png" alt="Snipaste_2024-07-27_08-55-26"></p>
<p>Hive拥有多种join算法，包括Common Join，Map Join，Bucket Map Join，Sort Merge Buckt Map Join等，下面对每种join算法做简要说明：</p>
<p>（1）Common Join</p>
<p>Common Join是Hive中最稳定的join算法，其通过一个MapReduce Job完成一个join操作。Map端负责读取join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。如下图所示：</p>
<img src="Snipaste_2023-11-03_20-40-41.png" alt="Snipaste_2023-11-03_20-40-41" style="zoom:50%;">

<p>需要<strong>注意</strong>的是，sql语句中的join操作和执行计划中的Common Join任务并非一对一的关系，一个sql语句中的<strong>相邻</strong>的且<strong>关联字段相同</strong>的多个join操作可以合并为一个Common Join任务。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">    a.val, </span><br><span class="line">    b.val, </span><br><span class="line">    c.val </span><br><span class="line">from a </span><br><span class="line">join b on (a.key = b.key1) </span><br><span class="line">join c on (c.key = b.key1)</span><br></pre></td></tr></table></figure>

<p>上述sql语句中两个join操作的关联字段均为b表的key1字段，则该语句中的两个join操作可由一个Common Join任务实现，也就是可通过一个Map Reduce任务实现。 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">    a.val, </span><br><span class="line">    b.val, </span><br><span class="line">    c.val </span><br><span class="line">from a </span><br><span class="line">join b on (a.key = b.key1) </span><br><span class="line">join c on (c.key = b.key2)</span><br></pre></td></tr></table></figure>

<p>上述sql语句中的两个join操作关联字段各不相同，则该语句的两个join操作需要各自通过一个Common Join任务实现，也就是通过两个Map Reduce任务实现。</p>
<p>（2）Map Join</p>
<p>Map Join算法可以通过两个只有map阶段的Job完成一个join操作。其适用场景为大表join小表。若某join操作满足要求，则第一个Job会读取小表数据，将其制作为hash table，并上传至Hadoop分布式缓存（本质上是上传至HDFS）。第二个Job会先从分布式缓存中读取小表数据，并缓存在Map Task的内存中，然后扫描大表数据与其匹配，这样在map端即可完成关联操作。如下图所示：</p>
<img src="Snipaste_2023-11-03_21-09-27.png" alt="Snipaste_2023-11-03_21-09-27" style="zoom:50%;">

<p><strong>执行计划分析</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--开启无条件转Map Join</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line">explain</span><br><span class="line">select t.account_id,</span><br><span class="line">        t.product_name</span><br><span class="line">from ks_ad_dw.ad_dim_account_info_df t </span><br><span class="line">inner join ks_ad_dw.dim_ad_active_account_di a </span><br><span class="line">on t.account_id=a.account_id and a.p_date = &#x27;20240717&#x27;</span><br><span class="line">where t.p_date = &#x27;20240717&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-3</span> is a root stage</span><br><span class="line">  Stage<span class="number">-1</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-3</span></span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-3</span></span><br><span class="line">    <span class="comment">//本地MapReduce作业</span></span><br><span class="line">    Map Reduce Local Work</span><br><span class="line">      Alias -&gt; Map Local Tables<span class="punctuation">:</span></span><br><span class="line">        a </span><br><span class="line">          Fetch Operator</span><br><span class="line">            limit<span class="punctuation">:</span> <span class="number">-1</span></span><br><span class="line">      <span class="comment">//启动一个本地Map作业，扫描（TableScan）a表取得account_id不为null的数据，最终结果存在HashTable（HashTable Sink）的key为account_id</span></span><br><span class="line">      Alias -&gt; Map Local Operator Tree<span class="punctuation">:</span></span><br><span class="line">        a </span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> a</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate<span class="punctuation">:</span> account_id is not <span class="literal"><span class="keyword">null</span></span> (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">249996</span> Data size<span class="punctuation">:</span> <span class="number">27955341</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              HashTable Sink Operator</span><br><span class="line">                keys<span class="punctuation">:</span></span><br><span class="line">                  <span class="number">0</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                  <span class="number">1</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> t</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">292534450</span> Data size<span class="punctuation">:</span> <span class="number">8331296902</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate<span class="punctuation">:</span> account_id is not <span class="literal"><span class="keyword">null</span></span> (type<span class="punctuation">:</span> boolean)</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">292534450</span> Data size<span class="punctuation">:</span> <span class="number">8331296902</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              Map Join Operator</span><br><span class="line">                condition map<span class="punctuation">:</span></span><br><span class="line">                     Inner Join <span class="number">0</span> to <span class="number">1</span></span><br><span class="line">                keys<span class="punctuation">:</span></span><br><span class="line">                  <span class="number">0</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                  <span class="number">1</span> account_id (type<span class="punctuation">:</span> bigint)</span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col18</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">321787901</span> Data size<span class="punctuation">:</span> <span class="number">9164426790</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                Select Operator</span><br><span class="line">                  expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)<span class="punctuation">,</span> _col18 (type<span class="punctuation">:</span> string)</span><br><span class="line">                  outputColumnNames<span class="punctuation">:</span> _col0<span class="punctuation">,</span> _col1</span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">321787901</span> Data size<span class="punctuation">:</span> <span class="number">9164426790</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  Limit</span><br><span class="line">                    Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">                    Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">100000</span> Data size<span class="punctuation">:</span> <span class="number">2800000</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                    File Output Operator</span><br><span class="line">                      compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">                      Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">100000</span> Data size<span class="punctuation">:</span> <span class="number">2800000</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                      table<span class="punctuation">:</span></span><br><span class="line">                          input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                          output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                          serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line">      <span class="comment">//Local work下面的Map Reduce Local work指代的就是stage-3的内容</span></span><br><span class="line">      Local Work<span class="punctuation">:</span></span><br><span class="line">        Map Reduce Local Work</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p>（3）Bucket Map Join</p>
<p>Bucket Map Join是对Map Join算法的改进，其打破了Map Join只适用于大表join小表的限制，可用于大表join大表的场景。</p>
<p>Bucket Map Join的核心思想是：<strong>若能保证参与join的表均为分桶表，且关联字段为分桶字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍</strong>，就能保证参与join的两张表的分桶之间具有明确的关联关系，所以就可以在两表的分桶间进行Map Join操作了。这样一来，第二个Job的Map端就无需再缓存小表的全表数据了，而只需缓存其所需的分桶即可。其原理如图所示：</p>
<img src="Snipaste_2023-11-03_21-37-40.png" alt="Snipaste_2023-11-03_21-37-40" style="zoom:50%;">

<p>（4）Sort Merge Bucket Map Join</p>
<p>Sort Merge Bucket Map Join（简称SMB Map Join）基于Bucket Map Join。SMB Map Join要求，<strong>参与join的表均为分桶表，且需保证分桶内的数据是有序的，且分桶字段、排序字段和关联字段为相同字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍。</strong></p>
<p>SMB Map Join同Bucket Join一样，同样是利用两表各分桶之间的关联关系，在分桶之间进行join操作，不同的是，分桶之间的join操作的实现原理。Bucket Map Join，两个分桶之间的join实现原理为Hash Join算法；而SMB Map Join，两个分桶之间的join实现原理为Sort Merge Join算法。</p>
<p>Hash Join和Sort Merge Join均为关系型数据库中常见的Join实现算法。Hash Join的原理相对简单，就是对参与join的一张表构建hash table，然后扫描另外一张表，然后进行逐行匹配。Sort Merge Join需要在两张按照关联字段排好序的表中进行，其原理如图所示：</p>
<img src="Snipaste_2023-11-05_13-27-38.png" alt="Snipaste_2023-11-05_13-27-38" style="zoom:50%;">

<p>Hive中的SMB Map Join就是对两个分桶的数据按照上述思路进行Join操作。可以看出，SMB Map Join与Bucket Map Join相比，在进行Join操作时，Map端是无需对整个Bucket构建hash table，也无需在Map端缓存整个Bucket数据的，每个Mapper只需按顺序逐个key读取两个分桶的数据进行join即可。</p>
<h3 id="11-5-2-Map-Join"><a href="#11-5-2-Map-Join" class="headerlink" title="11.5.2 Map Join"></a>11.5.2 Map Join</h3><h4 id="11-5-2-1-优化说明"><a href="#11-5-2-1-优化说明" class="headerlink" title="11.5.2.1 优化说明"></a>11.5.2.1 优化说明</h4><p>Map Join有两种触发方式，一种是用户在SQL语句中增加hint提示（过时了不推荐），另外一种是Hive优化器根据参与join表的数据量大小，自动触发。 </p>
<p>Hive在编译SQL语句阶段，起初所有的join操作均采用Common Join算法实现。</p>
<p>之后在物理优化阶段，Hive会根据每个Common Join任务所需表的大小判断该Common Join任务是否能够转换为Map Join任务，若满足要求，便将Common Join任务自动转换为Map Join任务。</p>
<p>但有些Common Join任务所需的表大小，在SQL的编译阶段是未知的（例如对子查询进行join操作），所以这种Common Join任务是否能转换成Map Join任务在编译阶是无法确定的。</p>
<p>针对这种情况，Hive会在编译阶段生成一个条件任务（Conditional Task），其下会包含一个计划列表，计划列表中包含转换后的Map Join任务以及原有的Common Join任务。最终具体采用哪个计划，是在运行时决定的。大致思路如下图所示：</p>
<p><img src="11%E5%9B%BE%E7%89%871.png" alt="11图片1"></p>
<p>Map join自动转换的具体判断逻辑如下图所示：</p>
<p>注意：a left join b：大表是a</p>
<p>​           a inner join b：大表是a或b</p>
<p>​      	 a right join b：大表是b</p>
<p>​		   a full join b：不能进行map join，只能进行common join</p>
<p><img src="12%E5%9B%BE%E7%89%871.png" alt="12图片1"></p>
<p>图中涉及到的参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--启动Map Join自动转换，hive0.11及以后的版本默认开启 </span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line"></span><br><span class="line">--一个Common Join operator转为Map Join operator的判断条件,若该Common Join相关的表中,存在n-1张表的已知大小总和&lt;=该值,则生成一个Map Join计划,此时可能存在多种n-1张表的组合均满足该条件,则hive会为每种满足条件的组合均生成一个Map Join计划,同时还会保留原有的Common Join计划作为后备(back up)计划,实际运行时,优先执行Map Join计划，若不能执行成功，则启动Common Join后备计划。</span><br><span class="line">set hive.mapjoin.smalltable.filesize=250000;</span><br><span class="line"></span><br><span class="line">--开启无条件转Map Join</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line"></span><br><span class="line">--无条件转Map Join时的小表之和阈值,若一个Common Join operator相关的表中，存在n-1张表的大小总和&lt;=该值,此时hive便不会再为每种n-1张表的组合均生成Map Join计划,同时也不会保留Common Join作为后备计划。而是只生成一个最优的Map Join计划。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask.size=10000000;</span><br></pre></td></tr></table></figure>

<h4 id="11-5-2-2-优化案例"><a href="#11-5-2-2-优化案例" class="headerlink" title="11.5.2.2 优化案例"></a>11.5.2.2 优化案例</h4><p>（1）示例SQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from order_detail od</span><br><span class="line">join product_info product on od.product_id = product.id</span><br><span class="line">join province_info province on od.province_id = province.id;</span><br></pre></td></tr></table></figure>

<p>（2）优化前</p>
<p>上述SQL语句共有三张表进行两次join操作，且两次join操作的关联字段不同。故优化前的执行计划应该包含两个Common Join operator，也就是由两个MapReduce任务实现。执行计划如下图所示：</p>
<img src="13图片1.png" alt="13图片1" style="zoom:50%;">

<p>（3）优化思路</p>
<img src="Snipaste_2023-11-05_15-26-23.png" alt="Snipaste_2023-11-05_15-26-23" style="zoom:50%;">

<p>三张表中，product_info和province_info数据量较小，可考虑将其作为小表，进行Map Join优化。</p>
<p><strong>方案1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--启用Map Join自动转换。 </span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line">--不使用无条件转Map Join。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=false;</span><br><span class="line">--调整hive.mapjoin.smalltable.filesize参数，使其大于等于product_info。 </span><br><span class="line">set hive.mapjoin.smalltable.filesize=25285707;</span><br></pre></td></tr></table></figure>

<p>样可保证将两个Common Join operator均可转为Map Join operator，并保留Common Join作为后备计划，保证计算任务的稳定。调整完的执行计划如下图：</p>
<p><img src="14%E5%9B%BE%E7%89%871.png" alt="14图片1"></p>
<p><strong>方案2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--启用Map Join自动转换。</span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line">--使用无条件转Map Join。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line">--调整hive.auto.convert.join.noconditionaltask.size参数，使其大于等于product_info和province_info之和。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask.size=25286076;</span><br></pre></td></tr></table></figure>

<p>这样可直接将两个Common Join operator转为两个Map Join operator，并且由于两个Map Join operator的小表大小之和小于等于hive.auto.convert.join.noconditionaltask.size，故两个Map Join operator任务可合并为同一个。这个方案计算效率最高，但需要的内存也是最多的。</p>
<p><img src="15%E5%9B%BE%E7%89%871.png" alt="15图片1"></p>
<p><strong>方案3：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--启用Map Join自动转换。</span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line">--使用无条件转Map Join。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line">--调整hive.auto.convert.join.noconditionaltask.size参数，使其等于product_info。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask.size=25285707;</span><br></pre></td></tr></table></figure>

<p>这样可直接将两个Common Join operator转为Map Join operator，但不会将两个Map Join的任务合并。该方案计算效率比方案二低，但需要的内存也更少。</p>
<p>调整完的执行计划如下图：</p>
<p><img src="16%E5%9B%BE%E7%89%871.png" alt="16图片1"></p>
<h3 id="11-5-3-Bucket-Map-Join"><a href="#11-5-3-Bucket-Map-Join" class="headerlink" title="11.5.3 Bucket Map Join"></a>11.5.3 Bucket Map Join</h3><h4 id="11-5-3-1-优化说明"><a href="#11-5-3-1-优化说明" class="headerlink" title="11.5.3.1 优化说明"></a>11.5.3.1 优化说明</h4><p>Bucket Map Join不支持自动转换，发须通过用户在SQL语句中提供如下Hint提示，并配置如下相关参数，方可使用。注意，在MR引擎下的Hive已经烂尾了，在Hive on spark上是可以进行自动转换的。</p>
<p>（1）Hint提示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select /*+ mapjoin(ta) */</span><br><span class="line">    ta.id,</span><br><span class="line">    tb.id</span><br><span class="line">from table_a ta</span><br><span class="line">join table_b tb on ta.id=tb.id;</span><br></pre></td></tr></table></figure>

<p>（2）相关参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--关闭cbo优化，cbo会导致hint信息被忽略</span><br><span class="line">set hive.cbo.enable=false;</span><br><span class="line">--map join hint默认会被忽略(因为已经过时)，需将如下参数设置为false</span><br><span class="line">set hive.ignore.mapjoin.hint=false;</span><br><span class="line">--启用bucket map join优化功能</span><br><span class="line">set hive.optimize.bucketmapjoin = true;</span><br></pre></td></tr></table></figure>

<h4 id="11-5-3-2-优化案例"><a href="#11-5-3-2-优化案例" class="headerlink" title="11.5.3.2 优化案例"></a>11.5.3.2 优化案例</h4><p>（1）示例SQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from order_detail</span><br><span class="line">    where dt=&#x27;2020-06-14&#x27;</span><br><span class="line">)od</span><br><span class="line">join(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from payment_detail</span><br><span class="line">    where dt=&#x27;2020-06-14&#x27;</span><br><span class="line">)pd</span><br><span class="line">on od.id=pd.order_detail_id;</span><br></pre></td></tr></table></figure>

<p>（2）优化前</p>
<p>上述SQL语句共有两张表一次join操作，故优化前的执行计划应包含一个Common Join任务，通过一个MapReduce Job实现。执行计划如下图所示：</p>
<img src="17图片1.png" alt="17图片1" style="zoom:50%;">

<p>（3）优化思路</p>
<img src="Snipaste_2023-11-05_16-19-16.png" alt="Snipaste_2023-11-05_16-19-16" style="zoom:50%;">

<p>张表都相对较大，若采用普通的Map Join算法，则Map端需要较多的内存来缓存数据，当然可以选择为Map段分配更多的内存，来保证任务运行成功。但是，Map端的内存不可能无上限的分配，所以当参与Join的表数据量均过大时，就可以考虑采用Bucket Map Join算法。下面演示如何使用Bucket Map Join。</p>
<p>首先需要依据源表创建两个分桶表，order_detail建议分16个bucket，payment_detail建议分8个bucket,注意<strong>分桶个数</strong>的倍数关系以及<strong>分桶字段</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">--订单表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">drop table if exists order_detail_bucketed;</span><br><span class="line">create table order_detail_bucketed(</span><br><span class="line">    id           string comment &#x27;订单id&#x27;,</span><br><span class="line">    user_id      string comment &#x27;用户id&#x27;,</span><br><span class="line">    product_id   string comment &#x27;商品id&#x27;,</span><br><span class="line">    province_id  string comment &#x27;省份id&#x27;,</span><br><span class="line">    create_time  string comment &#x27;下单时间&#x27;,</span><br><span class="line">    product_num  int comment &#x27;商品件数&#x27;,</span><br><span class="line">    total_amount decimal(16, 2) comment &#x27;下单金额&#x27;</span><br><span class="line">)</span><br><span class="line">clustered by (id) into 16 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">--支付表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">drop table if exists payment_detail_bucketed;</span><br><span class="line">create table payment_detail_bucketed(</span><br><span class="line">    id              string comment &#x27;支付id&#x27;,</span><br><span class="line">    order_detail_id string comment &#x27;订单明细id&#x27;,</span><br><span class="line">    user_id         string comment &#x27;用户id&#x27;,</span><br><span class="line">    payment_time    string comment &#x27;支付时间&#x27;,</span><br><span class="line">    total_amount    decimal(16, 2) comment &#x27;支付金额&#x27;</span><br><span class="line">)</span><br><span class="line">clustered by (order_detail_id) into 8 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<p>然后向两个分桶表导入数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">--订单表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">insert overwrite table order_detail_bucketed</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    user_id,</span><br><span class="line">    product_id,</span><br><span class="line">    province_id,</span><br><span class="line">    create_time,</span><br><span class="line">    product_num,</span><br><span class="line">    total_amount   </span><br><span class="line">from order_detail</span><br><span class="line">where dt=&#x27;2020-06-14&#x27;;</span><br><span class="line"></span><br><span class="line">--分桶表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">insert overwrite table payment_detail_bucketed</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    order_detail_id,</span><br><span class="line">    user_id,</span><br><span class="line">    payment_time,</span><br><span class="line">    total_amount</span><br><span class="line">from payment_detail</span><br><span class="line">where dt=&#x27;2020-06-14&#x27;;</span><br></pre></td></tr></table></figure>

<p>然后设置以下参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--关闭cbo优化，cbo会导致hint信息被忽略，需将如下参数修改为false</span><br><span class="line">set hive.cbo.enable=false;</span><br><span class="line">--map join hint默认会被忽略(因为已经过时)，需将如下参数修改为false</span><br><span class="line">set hive.ignore.mapjoin.hint=false;</span><br><span class="line">--启用bucket map join优化功能,默认不启用，需将如下参数修改为true</span><br><span class="line">set hive.optimize.bucketmapjoin = true;</span><br></pre></td></tr></table></figure>

<p>最后在重写SQL语句，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select /*+ mapjoin(pd) */</span><br><span class="line">    *</span><br><span class="line">from order_detail_bucketed od</span><br><span class="line">join payment_detail_bucketed pd on od.id = pd.order_detail_id;</span><br></pre></td></tr></table></figure>

<p>优化后的执行计划如图所示：</p>
<p><img src="18%E5%9B%BE%E7%89%871.png" alt="18图片1"></p>
<h3 id="11-5-4-Sort-Merge-Bucket-Map-Join"><a href="#11-5-4-Sort-Merge-Bucket-Map-Join" class="headerlink" title="11.5.4 Sort Merge Bucket Map Join"></a>11.5.4 Sort Merge Bucket Map Join</h3><h4 id="11-5-4-1-优化说明"><a href="#11-5-4-1-优化说明" class="headerlink" title="11.5.4.1 优化说明"></a>11.5.4.1 优化说明</h4><p>Sort Merge Bucket Map Join有两种触发方式，包括Hint提示和自动转换。Hint提示已过时，不推荐使用。下面是自动转换的相关参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--启动Sort Merge Bucket Map Join优化</span><br><span class="line">set hive.optimize.bucketmapjoin.sortedmerge=true;</span><br><span class="line">--使用自动转换SMB Join</span><br><span class="line">set hive.auto.convert.sortmerge.join=true;</span><br></pre></td></tr></table></figure>

<h4 id="11-5-4-2-优化案例"><a href="#11-5-4-2-优化案例" class="headerlink" title="11.5.4.2 优化案例"></a>11.5.4.2 优化案例</h4><p>（1）示例SQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from order_detail</span><br><span class="line">    where dt=&#x27;2020-06-14&#x27;</span><br><span class="line">)od</span><br><span class="line">join(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from payment_detail</span><br><span class="line">    where dt=&#x27;2020-06-14&#x27;</span><br><span class="line">)pd</span><br><span class="line">on od.id=pd.order_detail_id;</span><br></pre></td></tr></table></figure>

<p>（2）优化前</p>
<p>上述SQL语句共有两张表一次join操作，故优化前的执行计划应包含一个Common Join任务，通过一个MapReduce Job实现。</p>
<p>（3）优化思路</p>
<img src="Snipaste_2023-11-05_16-28-49.png" alt="Snipaste_2023-11-05_16-28-49" style="zoom:50%;">

<p>两张表都相对较大，除了可以考虑采用Bucket Map Join算法，还可以考虑SMB Join。相较于Bucket Map Join，SMB Map Join对分桶大小是没有要求的。下面演示如何使用SMB Map Join。</p>
<p>首先需要依据源表创建两个的有序的分桶表，order_detail建议分16个bucket，payment_detail建议分8个bucket,注意****分桶个数*<em><strong>的倍数关系以及</strong>分桶字段和排序字段</em>*。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">--订单表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">drop table if exists order_detail_sorted_bucketed;</span><br><span class="line">create table order_detail_sorted_bucketed(</span><br><span class="line">    id           string comment &#x27;订单id&#x27;,</span><br><span class="line">    user_id      string comment &#x27;用户id&#x27;,</span><br><span class="line">    product_id   string comment &#x27;商品id&#x27;,</span><br><span class="line">    province_id  string comment &#x27;省份id&#x27;,</span><br><span class="line">    create_time  string comment &#x27;下单时间&#x27;,</span><br><span class="line">    product_num  int comment &#x27;商品件数&#x27;,</span><br><span class="line">    total_amount decimal(16, 2) comment &#x27;下单金额&#x27;</span><br><span class="line">)</span><br><span class="line">clustered by (id) sorted by(id) into 16 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">--支付表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">drop table if exists payment_detail_sorted_bucketed;</span><br><span class="line">create table payment_detail_sorted_bucketed(</span><br><span class="line">    id              string comment &#x27;支付id&#x27;,</span><br><span class="line">    order_detail_id string comment &#x27;订单明细id&#x27;,</span><br><span class="line">    user_id         string comment &#x27;用户id&#x27;,</span><br><span class="line">    payment_time    string comment &#x27;支付时间&#x27;,</span><br><span class="line">    total_amount    decimal(16, 2) comment &#x27;支付金额&#x27;</span><br><span class="line">)</span><br><span class="line">clustered by (order_detail_id) sorted by(order_detail_id) into 8 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<p>然后向两个分桶表导入数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">--订单表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">insert overwrite table order_detail_sorted_bucketed</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    user_id,</span><br><span class="line">    product_id,</span><br><span class="line">    province_id,</span><br><span class="line">    create_time,</span><br><span class="line">    product_num,</span><br><span class="line">    total_amount   </span><br><span class="line">from order_detail</span><br><span class="line">where dt=&#x27;2020-06-14&#x27;;</span><br><span class="line"></span><br><span class="line">--分桶表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">insert overwrite table payment_detail_sorted_bucketed</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    order_detail_id,</span><br><span class="line">    user_id,</span><br><span class="line">    payment_time,</span><br><span class="line">    total_amount</span><br><span class="line">from payment_detail</span><br><span class="line">where dt=&#x27;2020-06-14&#x27;;</span><br></pre></td></tr></table></figure>

<p>然后设置以下参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--启动Sort Merge Bucket Map Join优化</span><br><span class="line">set hive.optimize.bucketmapjoin.sortedmerge=true;</span><br><span class="line">--使用自动转换SMB Join</span><br><span class="line">set hive.auto.convert.sortmerge.join=true;</span><br></pre></td></tr></table></figure>

<p>最后在重写SQL语句，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from order_detail_sorted_bucketed od</span><br><span class="line">join payment_detail_sorted_bucketed pd</span><br><span class="line">on od.id = pd.order_detail_id;</span><br></pre></td></tr></table></figure>

<p>优化后的执行计如图所示：</p>
<img src="19图片1.png" alt="19图片1" style="zoom:50%;">

<h2 id="11-6-HQL语法优化之数据倾斜"><a href="#11-6-HQL语法优化之数据倾斜" class="headerlink" title="11.6 HQL语法优化之数据倾斜"></a>11.6 HQL语法优化之数据倾斜</h2><h3 id="11-6-1-数据倾斜概述"><a href="#11-6-1-数据倾斜概述" class="headerlink" title="11.6.1 数据倾斜概述"></a>11.6.1 数据倾斜概述</h3><p>数据倾斜问题，通常是指参与计算的数据分布不均，即某个key或者某些key的数据量远超其他key，导致在shuffle阶段，大量相同key的数据被发往同一个Reduce，进而导致该Reduce所需的时间远超其他Reduce，成为整个任务的瓶颈。</p>
<p>Hive中的数据倾斜常出现在分组聚合和join操作的场景中，下面分别介绍在上述两种场景下的优化思路。</p>
<h3 id="11-6-2-分组聚合导致的数据倾斜"><a href="#11-6-2-分组聚合导致的数据倾斜" class="headerlink" title="11.6.2 分组聚合导致的数据倾斜"></a>11.6.2 分组聚合导致的数据倾斜</h3><h4 id="11-6-2-1-优化说明"><a href="#11-6-2-1-优化说明" class="headerlink" title="11.6.2.1 优化说明"></a>11.6.2.1 优化说明</h4><p>前文提到过，Hive中未经优化的分组聚合，是通过一个MapReduce Job实现的。Map端负责读取数据，并按照分组字段分区，通过Shuffle，将数据发往Reduce端，各组数据在Reduce端完成最终的聚合运算。</p>
<p>如果group by分组字段的值分布不均，就可能导致大量相同的key进入同一Reduce，从而导致数据倾斜问题。</p>
<p>由分组聚合导致的数据倾斜问题，有以下两种解决思路：</p>
<h5 id="（1）Map-Side聚合"><a href="#（1）Map-Side聚合" class="headerlink" title="（1）Map-Side聚合"></a>（1）Map-Side聚合</h5><p>开启Map-Side聚合后，数据会现在Map端完成部分聚合工作。这样一来即便原始数据是倾斜的，经过Map端的初步聚合后，发往Reduce的数据也就不再倾斜了。最佳状态下，Map-端聚合能完全屏蔽数据倾斜问题。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--启用map-side聚合，默认开启</span><br><span class="line">set hive.map.aggr=true;</span><br><span class="line"></span><br><span class="line">--用于检测源表数据是否适合进行map-side聚合。检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。</span><br><span class="line">set hive.map.aggr.hash.min.reduction=0.5;</span><br><span class="line"></span><br><span class="line">--用于检测源表是否适合map-side聚合的条数。</span><br><span class="line">set hive.groupby.mapaggr.checkinterval=100000;</span><br><span class="line"></span><br><span class="line">--map-side聚合所用的hash table，占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。</span><br><span class="line">set hive.map.aggr.hash.force.flush.memory.threshold=0.9;</span><br></pre></td></tr></table></figure>

<h5 id="（2）Skew-GroupBy优化"><a href="#（2）Skew-GroupBy优化" class="headerlink" title="（2）Skew-GroupBy优化"></a>（2）Skew-GroupBy优化</h5><p>Skew-GroupBy的原理是启动两个MR任务，第一个MR按照随机数分区，将数据分散发送到Reduce，完成部分聚合，第二个MR按照分组字段分区，完成最终聚合。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--启用分组聚合数据倾斜优化</span><br><span class="line">set hive.groupby.skewindata=true;</span><br></pre></td></tr></table></figure>

<h3 id="11-6-3-Join导致的数据倾斜"><a href="#11-6-3-Join导致的数据倾斜" class="headerlink" title="11.6.3 Join导致的数据倾斜"></a>11.6.3 Join导致的数据倾斜</h3><h4 id="11-6-3-1-优化说明"><a href="#11-6-3-1-优化说明" class="headerlink" title="11.6.3.1 优化说明"></a>11.6.3.1 优化说明</h4><p>前文提到过，未经优化的join操作，默认是使用common join算法，也就是通过一个MapReduce Job完成计算。Map端负责读取join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。</p>
<p>如果关联字段的值分布不均，就可能导致大量相同的key进入同一Reduce，从而导致数据倾斜问题。</p>
<p>由join导致的数据倾斜问题，有如下三种解决方案：</p>
<h5 id="（1）map-join"><a href="#（1）map-join" class="headerlink" title="（1）map join"></a>（1）map join</h5><p>使用map join算法，join操作仅在map端就能完成，没有shuffle操作，没有reduce阶段，自然不会产生reduce端的数据倾斜。该方案适用于大表join小表时发生数据倾斜的场景。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--启动Map Join自动转换</span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line"></span><br><span class="line">--一个Common Join operator转为Map Join operator的判断条件,若该Common Join相关的表中,存在n-1张表的大小总和&lt;=该值,则生成一个Map Join计划,此时可能存在多种n-1张表的组合均满足该条件,则hive会为每种满足条件的组合均生成一个Map Join计划,同时还会保留原有的Common Join计划作为后备(back up)计划,实际运行时,优先执行Map Join计划，若不能执行成功，则启动Common Join后备计划。</span><br><span class="line">set hive.mapjoin.smalltable.filesize=250000;</span><br><span class="line"></span><br><span class="line">--开启无条件转Map Join</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line"></span><br><span class="line">--无条件转Map Join时的小表之和阈值,若一个Common Join operator相关的表中，存在n-1张表的大小总和&lt;=该值,此时hive便不会再为每种n-1张表的组合均生成Map Join计划,同时也不会保留Common Join作为后备计划。而是只生成一个最优的Map Join计划。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask.size=10000000;</span><br></pre></td></tr></table></figure>

<h5 id="（2）skew-join"><a href="#（2）skew-join" class="headerlink" title="（2）skew join"></a>（2）skew join</h5><p>skew join的原理是，为倾斜的大key单独启动一个map join任务进行计算，其余key进行正常的common join。原理图如下：</p>
<p><img src="Snipaste_2023-11-05_17-15-08.png" alt="Snipaste_2023-11-05_17-15-08"></p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--启用skew join优化</span><br><span class="line">set hive.optimize.skewjoin=true;</span><br><span class="line">--触发skew join的阈值，若某个key的行数超过该参数值，则触发</span><br><span class="line">set hive.skewjoin.key=100000;</span><br></pre></td></tr></table></figure>

<p>这种方案对参与join的源表大小没有要求，但是对两表中倾斜的key的数据量有要求，要求一张表中的倾斜key的数据量比较小（方便走mapjoin）。</p>
<h5 id="（3）调整SQL语句"><a href="#（3）调整SQL语句" class="headerlink" title="（3）调整SQL语句"></a>（3）调整SQL语句</h5><p>若参与join的两表均为大表，其中一张表的数据是倾斜的，此时也可通过以下方式对SQL语句进行相应的调整。</p>
<p>假设原始SQL语句如下：A，B两表均为大表，且其中一张表的数据是倾斜的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from A</span><br><span class="line">join B</span><br><span class="line">on A.id=B.id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-05_19-29-39.png" alt="Snipaste_2023-11-05_19-29-39" style="zoom:50%;">

<p>图中1001为倾斜的大key，可以看到，其被发往了同一个Reduce进行处理。</p>
<p>调整SQL语句如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from(</span><br><span class="line">    select --打散操作</span><br><span class="line">        concat(id,&#x27;_&#x27;,cast(rand()*2 as int)) id,</span><br><span class="line">        value</span><br><span class="line">    from A</span><br><span class="line">)ta</span><br><span class="line">join(</span><br><span class="line">    select --扩容操作</span><br><span class="line">        concat(id,&#x27;_&#x27;,0) id,</span><br><span class="line">        value</span><br><span class="line">    from B</span><br><span class="line">    union all</span><br><span class="line">    select</span><br><span class="line">        concat(id,&#x27;_&#x27;,1) id,</span><br><span class="line">        value</span><br><span class="line">    from B</span><br><span class="line">)tb</span><br><span class="line">on ta.id=tb.id;</span><br></pre></td></tr></table></figure>

<p>调整之后的SQL语句执行计划如下图所示：</p>
<img src="Snipaste_2023-11-05_19-30-24.png" alt="Snipaste_2023-11-05_19-30-24" style="zoom:50%;">

<h2 id="11-7-HQL语法优化之任务并行度"><a href="#11-7-HQL语法优化之任务并行度" class="headerlink" title="11.7 HQL语法优化之任务并行度"></a>11.7 HQL语法优化之任务并行度</h2><h3 id="11-7-1-优化说明"><a href="#11-7-1-优化说明" class="headerlink" title="11.7.1 优化说明"></a>11.7.1 优化说明</h3><p>对于一个分布式的计算任务而言，设置一个合适的并行度十分重要。Hive的计算任务由MapReduce完成，故并行度的调整需要分为Map端和Reduce端。</p>
<h4 id="11-7-1-1-Map端并行度"><a href="#11-7-1-1-Map端并行度" class="headerlink" title="11.7.1.1 Map端并行度"></a>11.7.1.1 Map端并行度</h4><p>Map端的并行度，也就是Map的个数。是由输入文件的切片数决定的。一般情况下，Map端的并行度无需手动调整。</p>
<p>以下特殊情况可考虑调整map端并行度：</p>
<p>（1）查询的表中存在大量小文件</p>
<p>按照Hadoop默认的切片策略，一个小文件会单独启动一个map task负责计算。若查询的表中存在大量小文件，则会启动大量map task，造成计算资源的浪费。这种情况下，可以使用Hive提供的CombineHiveInputFormat，多个小文件合并为一个切片，从而控制map task个数。相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>

<p>（2）map端有复杂的查询逻辑</p>
<p>若SQL语句中有正则替换、json解析等复杂耗时的查询逻辑时，map端的计算会相对慢一些。若想加快计算速度，在计算资源充足的情况下，可考虑增大map端的并行度，令map task多一些，每个map task计算的数据少一些。相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--一个切片的最大值</span><br><span class="line">set mapreduce.input.fileinputformat.split.maxsize=256000000;</span><br></pre></td></tr></table></figure>

<h4 id="11-7-1-2-Reduce端的并行度"><a href="#11-7-1-2-Reduce端的并行度" class="headerlink" title="11.7.1.2 Reduce端的并行度"></a>11.7.1.2 Reduce端的并行度</h4><p>Reduce端的并行度，也就是Reduce个数。相对来说，更需要关注。Reduce端的并行度，可由用户自己指定，也可由Hive自行根据该MR Job输入的文件大小进行估算。</p>
<p>Reduce端的并行度的相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--指定Reduce端并行度，默认值为-1，表示用户未指定</span><br><span class="line">set mapreduce.job.reduces;</span><br><span class="line">--Reduce端并行度最大值</span><br><span class="line">set hive.exec.reducers.max;</span><br><span class="line">--单个Reduce Task计算的数据量，用于估算Reduce并行度</span><br><span class="line">set hive.exec.reducers.bytes.per.reducer;</span><br></pre></td></tr></table></figure>

<p>Reduce端并行度的确定逻辑如下：</p>
<p>若指定参数<strong>mapreduce.job.reduces</strong>的值为一个非负整数，则Reduce并行度为指定值。否则，Hive自行估算Reduce并行度，估算逻辑如下：</p>
<p>假设Job输入的文件大小为<em><strong>*totalInputBytes*</strong></em></p>
<p>参数****hive.exec.reducers.bytes.per.reducer****的值为bytesPerReducer。</p>
<p>参数****hive.exec.reducers.max****的值为maxReducers。</p>
<p>则Reduce端的并行度为：</p>
<p><img src="wps1.jpg" alt="img"> </p>
<p>根据上述描述，可以看出，Hive自行估算Reduce并行度时，是以整个MR Job输入的文件大小作为依据的。因此，在某些情况下其估计的并行度很可能并不准确，此时就需要用户根据实际情况来指定Reduce并行度了。</p>
<h2 id="11-8-HQL语法优化之小文件合并"><a href="#11-8-HQL语法优化之小文件合并" class="headerlink" title="11.8 HQL语法优化之小文件合并"></a>11.8 HQL语法优化之小文件合并</h2><h3 id="HIve中小文件产生的原因"><a href="#HIve中小文件产生的原因" class="headerlink" title="HIve中小文件产生的原因"></a>HIve中小文件产生的原因</h3><p>（1）直接向表中插入数据：每次插入都会产生一个文件，多次插入少量数据就会出现多个小文件</p>
<p>（2）通过load方式加载数据，每导入一个文件hive表就会产生一个文件</p>
<p>（3）通过查询方式加载数据（最常见）：其中，文件数量&#x3D;ReduceTask数量×分区数（只有map阶段就是，文件数量&#x3D;MapTask数量×分区数）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table A  select s_id,c_name,s_score from B;</span><br></pre></td></tr></table></figure>

<h3 id="小文件过多的危害"><a href="#小文件过多的危害" class="headerlink" title="小文件过多的危害"></a>小文件过多的危害</h3><p>（1）对于HDFS而言，其本身就不适合存储大量小文件，小文件过多会导致NameNode元数据特别大，占用内存太多，影响HDFS性能。</p>
<p>（2）对Hive而言，在进行查询时，每个小文件都会启动一个Map任务来完成，Map任务启动和初始化的时间远远大于逻辑处理的时间，本末倒置，造成资源浪费</p>
<h3 id="11-8-1-优化说明"><a href="#11-8-1-优化说明" class="headerlink" title="11.8.1 优化说明"></a>11.8.1 优化说明</h3><p>小文件合并优化，分为两个方面，分别是Map端输入的小文件合并，和Reduce端输出的小文件合并。</p>
<h4 id="11-8-1-1-Map端输入文件合并"><a href="#11-8-1-1-Map端输入文件合并" class="headerlink" title="11.8.1.1 Map端输入文件合并"></a>11.8.1.1 Map端输入文件合并</h4><p>合并Map端输入的小文件，是指将多个小文件划分到一个切片中，进而由一个Map Task去处理。目的是防止为单个小文件启动一个Map Task，浪费计算资源。</p>
<p>相关参数为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--可将多个小文件切片，合并为一个切片，进而由一个map任务处理</span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>

<h4 id="11-8-1-2-Reduce端文件合并"><a href="#11-8-1-2-Reduce端文件合并" class="headerlink" title="11.8.1.2 Reduce端文件合并"></a>11.8.1.2 Reduce端文件合并</h4><p>合并Reduce端输出的小文件，是指将多个小文件合并成大文件。目的是减少HDFS小文件数量。其原理是根据计算任务输出文件的平均大小进行判断，若符合条件，则单独启动一个额外的任务进行合并。</p>
<p>相关参数为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--开启合并map only任务输出的小文件</span><br><span class="line">set hive.merge.mapfiles=true;</span><br><span class="line"></span><br><span class="line">--开启合并map reduce任务输出的小文件</span><br><span class="line">set hive.merge.mapredfiles=true;</span><br><span class="line"></span><br><span class="line">--合并后的文件大小</span><br><span class="line">set hive.merge.size.per.task=256000000;</span><br><span class="line"></span><br><span class="line">--触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并</span><br><span class="line">set hive.merge.smallfiles.avgsize=16000000;</span><br></pre></td></tr></table></figure>

<h4 id="11-8-1-3-减少Reduce的数量"><a href="#11-8-1-3-减少Reduce的数量" class="headerlink" title="11.8.1.3 减少Reduce的数量"></a>11.8.1.3 减少Reduce的数量</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--reduce 的个数决定了输出的文件的个数，所以可以调整reduce的个数控制hive表的文件数量</span><br><span class="line">set mapreduce.job.reduces=10;</span><br></pre></td></tr></table></figure>

<h4 id="11-8-1-4-使用Hive自带的concatenate命令，自动合并小文件"><a href="#11-8-1-4-使用Hive自带的concatenate命令，自动合并小文件" class="headerlink" title="11.8.1.4 使用Hive自带的concatenate命令，自动合并小文件"></a>11.8.1.4 使用Hive自带的concatenate命令，自动合并小文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--对于非分区表</span><br><span class="line">alter table A concatenate;</span><br><span class="line"></span><br><span class="line">--对于分区表</span><br><span class="line">alter table B partition(day=20201224) concatenate;</span><br><span class="line">--使用concatenate命令合并小文件时不能指定合并后的文件数量，但可以多次执行该命令。 </span><br><span class="line">--当多次使用concatenate后文件数量不在变化，这个跟参数 mapreduce.input.fileinputformat.split.minsize=256mb 的设置有关，可设定每个文件的最小size。</span><br></pre></td></tr></table></figure>

<h4 id="11-8-1-5-使用hadoop的archive将小文件归档"><a href="#11-8-1-5-使用hadoop的archive将小文件归档" class="headerlink" title="11.8.1.5 使用hadoop的archive将小文件归档"></a>11.8.1.5 使用hadoop的archive将小文件归档</h4><p>Hadoop Archive简称HAR，是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样在减少namenode内存使用的同时，仍然允许对文件进行透明的访问</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">--用来控制归档是否可用</span><br><span class="line">set hive.archive.enabled=true;</span><br><span class="line">--通知Hive在创建归档时是否可以设置父目录</span><br><span class="line">set hive.archive.har.parentdir.settable=true;</span><br><span class="line">--控制需要归档文件的大小</span><br><span class="line">set har.partfile.size=1099511627776;</span><br><span class="line"></span><br><span class="line">--使用以下命令进行归档</span><br><span class="line">ALTER TABLE A ARCHIVE PARTITION(dt=&#x27;2020-12-24&#x27;, hr=&#x27;12&#x27;);</span><br><span class="line"></span><br><span class="line">--对已归档的分区恢复为原文件</span><br><span class="line">ALTER TABLE A UNARCHIVE PARTITION(dt=&#x27;2020-12-24&#x27;, hr=&#x27;12&#x27;);</span><br></pre></td></tr></table></figure>

<h2 id="11-9-其他优化"><a href="#11-9-其他优化" class="headerlink" title="11.9 其他优化"></a>11.9 其他优化</h2><h3 id="11-9-1-CBO优化"><a href="#11-9-1-CBO优化" class="headerlink" title="11.9.1 CBO优化"></a>11.9.1 CBO优化</h3><h4 id="11-9-1-1-优化说明"><a href="#11-9-1-1-优化说明" class="headerlink" title="11.9.1.1 优化说明"></a>11.9.1.1 优化说明</h4><p>CBO是指Cost based Optimizer，即基于计算成本的优化。</p>
<p>在Hive中，计算成本模型考虑到了：数据的行数、CPU、本地IO、HDFS IO、网络IO等方面。Hive会计算同一SQL语句的不同执行计划的计算成本，并选出成本最低的执行计划。目前CBO在hive的MR引擎下主要用于join的优化，例如多表join的join顺序。</p>
<p>相关参数为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--是否启用cbo优化 </span><br><span class="line">set hive.cbo.enable=true;</span><br><span class="line">--spark中</span><br><span class="line">set spark.sql.cbo.enabled = true;</span><br></pre></td></tr></table></figure>

<h4 id="11-9-1-2-优化案例"><a href="#11-9-1-2-优化案例" class="headerlink" title="11.9.1.2 优化案例"></a>11.9.1.2 优化案例</h4><p>（1）示例SQL语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from order_detail od</span><br><span class="line">join product_info product on od.product_id=product.id</span><br><span class="line">join province_info province on od.province_id=province.id;</span><br></pre></td></tr></table></figure>

<p>（2）关闭CBO优化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--关闭cbo优化 </span><br><span class="line">set hive.cbo.enable=false;</span><br><span class="line"></span><br><span class="line">--为了测试效果更加直观，关闭map join自动转换</span><br><span class="line">set hive.auto.convert.join=false;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-05_20-50-35.png" alt="Snipaste_2023-11-05_20-50-35" style="zoom:50%;">

<p>（3）开启CBO优化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--开启cbo优化 </span><br><span class="line">set hive.cbo.enable=true;</span><br><span class="line">--为了测试效果更加直观，关闭map join自动转换</span><br><span class="line">set hive.auto.convert.join=false;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-05_20-51-12.png" alt="Snipaste_2023-11-05_20-51-12" style="zoom:50%;">

<p>（4）总结</p>
<p>根据上述案例可以看出，CBO优化对于执行计划中join顺序是有影响的，其之所以会将province_info的join顺序提前，是因为province info的数据量较小，将其提前，会有更大的概率使得中间结果的数据量变小，从而使整个计算任务的数据量减小，也就是使计算成本变小。</p>
<h3 id="11-9-2-谓词下推"><a href="#11-9-2-谓词下推" class="headerlink" title="11.9.2 谓词下推"></a>11.9.2 谓词下推</h3><h4 id="11-9-2-1-优化说明"><a href="#11-9-2-1-优化说明" class="headerlink" title="11.9.2.1 优化说明"></a>11.9.2.1 优化说明</h4><p>谓词下推（predicate pushdown）是指，尽量将过滤操作前移，以减少后续计算步骤的数据量。</p>
<p>相关参数为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--是否启动谓词下推（predicate pushdown）优化</span><br><span class="line">set hive.optimize.ppd = true;</span><br></pre></td></tr></table></figure>

<p>需要注意的是：</p>
<p>CBO优化也会完成一部分的谓词下推优化工作，因为在执行计划中，谓词越靠前，整个计划的计算成本就会越低。</p>
<h3 id="11-9-3-矢量化查询"><a href="#11-9-3-矢量化查询" class="headerlink" title="11.9.3 矢量化查询"></a>11.9.3 矢量化查询</h3><p>Hive的矢量化查询优化，依赖于CPU的矢量化计算，CPU的矢量化计算的基本原理如下图：</p>
<img src="Snipaste_2023-11-05_20-54-26.png" alt="Snipaste_2023-11-05_20-54-26" style="zoom:50%;">

<p>Hive的矢量化查询，可以极大的提高一些典型查询场景（例如scans, filters, aggregates, and joins）下的CPU使用效率。它大大减少了扫描、过滤器、聚合和连接等典型查询操作的CPU使用。标准查询执行系统一次处理一行。矢量化查询执行可以一次性处理1024行的数据块，以减少底层操作系统处理数据时的指令和上下文切换。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.vectorized.execution.enabled=true;</span><br></pre></td></tr></table></figure>

<p>若执行计划中，出现“Execution mode: vectorized”字样，即表明使用了矢量化计算。</p>
<h3 id="11-9-4-Fetch抓取"><a href="#11-9-4-Fetch抓取" class="headerlink" title="11.9.4 Fetch抓取"></a>11.9.4 Fetch抓取</h3><p>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：select * from emp;在这种情况下，Hive可以简单地读取emp对应的存储目录下的文件，然后输出查询结果到控制台。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--是否在特定场景转换为fetch 任务</span><br><span class="line">--设置为none表示不转换</span><br><span class="line">--设置为minimal表示支持select *，分区字段过滤，Limit等</span><br><span class="line">--设置为more表示支持select 任意字段,包括函数，过滤，和limit等</span><br><span class="line">set hive.fetch.task.conversion=more;</span><br></pre></td></tr></table></figure>

<h3 id="11-9-5-本地模式"><a href="#11-9-5-本地模式" class="headerlink" title="11.9.5 本地模式"></a>11.9.5 本地模式</h3><h4 id="11-9-5-1-优化说明"><a href="#11-9-5-1-优化说明" class="headerlink" title="11.9.5.1 优化说明"></a>11.9.5.1 优化说明</h4><p>大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--开启自动转换为本地模式</span><br><span class="line">set hive.exec.mode.local.auto=true;  </span><br><span class="line"></span><br><span class="line">--设置local MapReduce的最大输入数据量，当输入数据量小于这个值时采用local  MapReduce的方式，默认为134217728，即128M</span><br><span class="line">set hive.exec.mode.local.auto.inputbytes.max=50000000;</span><br><span class="line"></span><br><span class="line">--设置local MapReduce的最大输入文件个数，当输入文件个数小于这个值时采用local MapReduce的方式，默认为4</span><br><span class="line">set hive.exec.mode.local.auto.input.files.max=10;</span><br></pre></td></tr></table></figure>

<h3 id="11-9-6-并行模式"><a href="#11-9-6-并行模式" class="headerlink" title="11.9.6 并行模式"></a>11.9.6 并行模式</h3><p>Hive会将一个SQL语句转化成一个或者多个Stage，每个Stage对应一个MR Job。默认情况下，Hive同时只会执行一个Stage。但是某SQL语句可能会包含多个Stage，但这多个Stage可能并非完全互相依赖，也就是说有些Stage是可以并行执行的。此处提到的并行执行就是指这些Stage的并行执行。相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--启用并行执行优化</span><br><span class="line">set hive.exec.parallel=true;       </span><br><span class="line">    </span><br><span class="line">--同一个sql允许最大并行度，默认为8</span><br><span class="line">set hive.exec.parallel.thread.number=8;</span><br></pre></td></tr></table></figure>

<h3 id="11-9-7-严格模式"><a href="#11-9-7-严格模式" class="headerlink" title="11.9.7 严格模式"></a>11.9.7 严格模式</h3><p>Hive可以通过设置某些参数防止危险操作：</p>
<p>（1）分区表不使用分区过滤</p>
<p>将hive.strict.checks.no.partition.filter设置为true时，对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p>
<p>（2）使用order by没有limit过滤</p>
<p>将hive.strict.checks.orderby.no.limit设置为true时，对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reduce中进行处理，强制要求用户增加这个limit语句可以防止Reduce额外执行很长一段时间（开启了limit可以在数据进入到Reduce之前就减少一部分数据）。</p>
<p>（3）笛卡尔积</p>
<p>将hive.strict.checks.cartesian.product设置为true时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p>
<h3 id="11-9-8-列裁剪、分区裁剪、提前数据收敛"><a href="#11-9-8-列裁剪、分区裁剪、提前数据收敛" class="headerlink" title="11.9.8 列裁剪、分区裁剪、提前数据收敛"></a>11.9.8 列裁剪、分区裁剪、提前数据收敛</h3><p>列裁剪就是尽量少选择不需要的列，分区裁剪就是加上分区过滤条件</p>
<p>提前数据收敛：在子查询中，有些条件能先过滤的尽量放在子查询里面先过滤，减少子查询输出的数据量</p>
<h3 id="11-9-9-相关性优化"><a href="#11-9-9-相关性优化" class="headerlink" title="11.9.9 相关性优化"></a>11.9.9 相关性优化</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.optimize.correlation = true;</span><br></pre></td></tr></table></figure>

<p>打开上述配置可以减少重复的shuffle操作。如果一个join操作后输出的结果是作为group by阶段的操作的输入，这种情况下group by操作没有必要重新shuffle，这种操作与操作之间的相关性在开启上述参数会被感知到并且减少shuflle操作。</p>
<h2 id="11-10-Hive数据抽样"><a href="#11-10-Hive数据抽样" class="headerlink" title="11.10 Hive数据抽样"></a>11.10 Hive数据抽样</h2><p>当数据规模不断膨胀时，我们需要找到一个数据的子集来加快数据分析效率。因此我们就需要通过筛选和分析数据集为了进行<strong>模式 &amp; 趋势识别</strong>。目前来说有三种方式来进行抽样：<strong>随机抽样</strong>，<strong>桶表抽样</strong>，和<strong>块抽样</strong></p>
<h3 id="11-10-1-随机抽样"><a href="#11-10-1-随机抽样" class="headerlink" title="11.10.1 随机抽样"></a>11.10.1 随机抽样</h3><p>关键词：<strong>rand()函数</strong>。</p>
<p>使用 rand()函数进行随机抽样，limit 关键字限制抽样返回的数据，其中 rand函数前的 distribute 和 sort 关键字可以保证数据在 mapper 和 reducer 阶段是随机分布的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select * from table_name</span><br><span class="line">where col=xxx</span><br><span class="line">distribute by rand() sort by rand()</span><br><span class="line">limit num;</span><br></pre></td></tr></table></figure>

<h3 id="11-10-2-块抽样"><a href="#11-10-2-块抽样" class="headerlink" title="11.10.2 块抽样"></a>11.10.2 块抽样</h3><p>关键词：<strong>tablesample()函数</strong>。</p>
<ol>
<li>tablesample(n percent) 根据 hive 表数据的大小按比例抽取数据，并保存到新的 hive 表中。如：抽取原 hive 表中 10%的数据</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from xxx tablesample(10 percent)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>tablesample(nM) 指定抽样数据的大小，单位为 M。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from xxx tablesample(20M)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>tablesample(n rows) 指定抽样数据的行数，其中 n 代表每个 map 任务均取 n 行数据，map 数量可通过 hive 表的简单查询语句确认（关键词：numberof mappers: x)</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from xxx tablesample(100 rows)</span><br></pre></td></tr></table></figure>

<h3 id="11-10-3-桶表抽样"><a href="#11-10-3-桶表抽样" class="headerlink" title="11.10.3 桶表抽样"></a>11.10.3 桶表抽样</h3><p>关键词：**tablesample (bucket x out of y [on colname])**。</p>
<p>其中 x 是要抽样的桶编号，桶编号从 1 开始，colname 表示抽样的列，y 表示桶的数量。hive 中分桶其实就是根据某一个字段 Hash 取模，放入指定数据的桶中，比如将表 table_1 按照 ID 分成 100 个桶，其算法是 hash(id) % 100，这样，hash(id) %100 &#x3D; 0 的数据被放到第一个桶中，hash(id) % 100 &#x3D; 1 的记录被放到第二个桶中。创建分桶表的关键语句为：CLUSTER BY 语句。</p>
<p>例如：将表随机分成 10 组，抽取其中的第一个桶的数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from table_01</span><br><span class="line">tablesample(bucket 1 out of 10 on rand())</span><br></pre></td></tr></table></figure>

<h2 id="11-11-Hive计算引擎"><a href="#11-11-Hive计算引擎" class="headerlink" title="11.11 Hive计算引擎"></a>11.11 Hive计算引擎</h2><p>目前 Hive 支持 MapReduce、Tez 和 Spark 三种计算引擎</p>
<ol>
<li>MapReduce：这是Hive最初使用的计算引擎，也是Hadoop生态系统中的主要计算模型。MapReduce通过将任务分解成多个小任务（Map和Reduce阶段）来处理数据，这使得它非常适合大规模数据处理。然而，MapReduce的批处理特性使得它在处理交互式查询和实时数据处理方面不够高效。</li>
<li>Tez：完全基于内存，Tez将MapReduce的两次扫描优化为一次扫描，提高了查询性能。<strong>一般用于快速出结果，数据量较小的场景</strong></li>
<li>Spark：Spark是另一种高性能的计算引擎，它提供了内存计算和DAG（有向无环图）执行引擎，使得数据处理速度更快。<strong>一般处理天指标</strong></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set hive.execution.engine = mr;--切换为mr引擎，默认就是mr</span><br><span class="line">set hive.execution.engine = spark; --切换为spark引擎</span><br></pre></td></tr></table></figure>

<p><strong>注意：切换引擎后，使用查看执行计划语句explain查看的执行计划就不一样了，分别为mapreduce的执行计划和spark的执行计划，但两者大同小异</strong></p>
<h2 id="11-12-HiveSQL语法层面的优化"><a href="#11-12-HiveSQL语法层面的优化" class="headerlink" title="11.12 HiveSQL语法层面的优化"></a>11.12 HiveSQL语法层面的优化</h2><h3 id="（1）分解count-distinct-的SQL优化与原理"><a href="#（1）分解count-distinct-的SQL优化与原理" class="headerlink" title="（1）分解count(distinct)的SQL优化与原理"></a>（1）分解count(distinct)的SQL优化与原理</h3><p><strong>只有一个count(distinct)语句</strong>，如果系统引擎会自动做优化，那就看是否进行两部聚合效率更高。如果系统不会自动进行优化，需要我们手动优化，我们就需要看count(distinct)的字段是否分布很不均匀，然后再做讨论。</p>
<p>说明：代码1是将去重和计数放到一个MapReduce作业中完成；代码2是将去重和计数放到两个MapReduce作业中完成。</p>
<p>当user_id分布很广且不均匀，会出现数据倾斜，数据量很大的时候，代码2有两个作业，可以把处理逻辑分散到两个阶段中，即第一个阶段先处理一部分数据，缩小数据量，第二个节点在已经缩小的数据集上继续处理。代码2效率更高。</p>
<p>但是如果user_id是非常有限的可枚举值，不需要避免数据倾斜，distinct的命令会在内存中构建一个hashtable，查找去重的时间复杂度为O(1)，而且代码1只会产生一个任务，更少消耗磁盘网络IO资源。代码1效率更高。</p>
<p>配置set hive.optimize.countdistinct&#x3D;true，即使出现数据倾斜也能实现自动优化。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">--代码1</span><br><span class="line">select ft_type,</span><br><span class="line">       app_id,</span><br><span class="line">       count(distinct case when flag = 0 then user_id else null end) as A_cnt</span><br><span class="line">from tmp</span><br><span class="line">where dt &gt;= &#x27;20240304&#x27;</span><br><span class="line">group by ft_type,</span><br><span class="line">         app_id</span><br><span class="line">     </span><br><span class="line">     </span><br><span class="line">--代码2</span><br><span class="line">select ft_type,</span><br><span class="line">       app_id,</span><br><span class="line">       sum(case when A_cnt&gt; 0 then 1 else 0 end) as A_cnt</span><br><span class="line">from (</span><br><span class="line">    select ft_type,</span><br><span class="line">           app_id,</span><br><span class="line">           count(case when flag = 0 then user_id else null end) as A_cnt</span><br><span class="line">    from tmp</span><br><span class="line">    where dt &gt;= &#x27;20240304&#x27;</span><br><span class="line">    group by ft_type,</span><br><span class="line">             app_id,</span><br><span class="line">             user_id</span><br><span class="line">    )t</span><br><span class="line">group by ft_type,</span><br><span class="line">         app_id</span><br></pre></td></tr></table></figure>

<p><strong>当有多个count(distinct)语句</strong>，distinct算子在处理过程中会将原有数据膨胀，有几个distinct关键字就会在Map端膨胀几倍（expand算子），expand算子是窄依赖，分区数会继承上一个stage的分区数，会导致单个task处理过多的数据，跑得慢。【简单理解：数据复制N份，再每份上做group by去重】。有两种优化手段：第一种就是代码层面拆分为两个两层，内层groupby+count，外层sum；第二种方法是设置<code>spark.sql.files.maxPartitionBytes</code>为更小的值，让每一个task处理的数据少一些</p>
<img src="73aaba1e7b30b5dd99d13c1975a7a79f.png" alt="73aaba1e7b30b5dd99d13c1975a7a79f" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">--代码1</span><br><span class="line">select ft_type,</span><br><span class="line">       app_id,</span><br><span class="line">       count(distinct case when flag = 0 then user_id else null end) as A_cnt,</span><br><span class="line">       count(distinct case when flag = 1 then user_id else null end) as B_cnt</span><br><span class="line">from tmp</span><br><span class="line">where dt &gt;= &#x27;20240304&#x27;</span><br><span class="line">group by ft_type,</span><br><span class="line">         app_id</span><br><span class="line">     </span><br><span class="line">     </span><br><span class="line">--代码2</span><br><span class="line">set spark.sql.files.maxPartitionBytes = 20M;</span><br><span class="line">select ft_type,</span><br><span class="line">       app_id,</span><br><span class="line">       sum(case when A_cnt&gt; 0 then 1 else 0 end) as A_cnt,</span><br><span class="line">       sum(case when B_cnt&gt; 0 then 1 else 0 end) as B_cnt</span><br><span class="line">from (</span><br><span class="line">    select ft_type,</span><br><span class="line">           app_id,</span><br><span class="line">           count(case when flag = 0 then user_id else null end) as A_cnt,</span><br><span class="line">           count(case when flag = 1 then user_id else null end) as B_cnt</span><br><span class="line">    from tmp</span><br><span class="line">    where dt &gt;= &#x27;20240304&#x27;</span><br><span class="line">    group by ft_type,</span><br><span class="line">             app_id,</span><br><span class="line">             user_id</span><br><span class="line">    )t</span><br><span class="line">group by ft_type,</span><br><span class="line">         app_id</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>扩展：</strong></p>
<p>distinct的执行计划：distinct的执行计划和使用group by去重的执行计划<strong>完全一致</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">explain</span><br><span class="line">select distinct fingerprint</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27;;</span><br><span class="line">--与使用group by去重等价</span><br><span class="line">select fingerprint</span><br><span class="line">from ks_ad_dw_dev.app_pub_xintongyuan_overview_daily_df</span><br><span class="line">where dt = &#x27;2024-07-17&#x27;</span><br><span class="line">group by fingerprint;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">Explain</span><br><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage</span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line"></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span></span><br><span class="line">          TableScan</span><br><span class="line">            alias<span class="punctuation">:</span> app_pub_xintongyuan_overview_daily_df</span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            Select Operator</span><br><span class="line">              expressions<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)</span><br><span class="line">              outputColumnNames<span class="punctuation">:</span> fingerprint</span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              <span class="comment">//在Map端进行数据局部聚合</span></span><br><span class="line">              Group By Operator</span><br><span class="line">                keys<span class="punctuation">:</span> fingerprint (type<span class="punctuation">:</span> string)</span><br><span class="line">                mode<span class="punctuation">:</span> hash</span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0</span><br><span class="line">                skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                Reduce Output Operator</span><br><span class="line">                  key expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)</span><br><span class="line">                  sort order<span class="punctuation">:</span> +</span><br><span class="line">                  Map-reduce partition columns<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> string)</span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">232</span> Data size<span class="punctuation">:</span> <span class="number">99437</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  TopN Hash Memory Usage<span class="punctuation">:</span> <span class="number">0.4</span></span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span></span><br><span class="line">        <span class="comment">//distinct去重实际上是使用了group by去重，即数据的全部聚合</span></span><br><span class="line">        Group By Operator</span><br><span class="line">          keys<span class="punctuation">:</span> KEY._col0 (type<span class="punctuation">:</span> string)</span><br><span class="line">          mode<span class="punctuation">:</span> mergepartial</span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0</span><br><span class="line">          skewOptimizeStrategy<span class="punctuation">:</span> UNSET</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">116</span> Data size<span class="punctuation">:</span> <span class="number">49718</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          Limit</span><br><span class="line">            Number of rows<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">116</span> Data size<span class="punctuation">:</span> <span class="number">49718</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            File Output Operator</span><br><span class="line">              compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">116</span> Data size<span class="punctuation">:</span> <span class="number">49718</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">              table<span class="punctuation">:</span></span><br><span class="line">                  input format<span class="punctuation">:</span> org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                  output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                  serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator</span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">100000</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<h3 id="（2）使用grouping-sets代替union"><a href="#（2）使用grouping-sets代替union" class="headerlink" title="（2）使用grouping sets代替union"></a>（2）使用grouping sets代替union</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">--优化前的代码</span><br><span class="line">select age,</span><br><span class="line">       sex,</span><br><span class="line">       count(1) as num</span><br><span class="line">from tmp</span><br><span class="line">group by age,</span><br><span class="line">         sex</span><br><span class="line">         </span><br><span class="line">union all</span><br><span class="line"></span><br><span class="line">select age,</span><br><span class="line">       null as sex,</span><br><span class="line">       count(1) as num</span><br><span class="line">from tmp</span><br><span class="line">group by age</span><br><span class="line"></span><br><span class="line">--优化后的代码</span><br><span class="line">select age,</span><br><span class="line">       sex,</span><br><span class="line">       count(1) as num</span><br><span class="line">from tmp</span><br><span class="line">group by age,sex</span><br><span class="line">grouping sets ((age,sex),(age))</span><br></pre></td></tr></table></figure>

<h3 id="（3）通过SQL-Hint语法进行优化（尽量不用）"><a href="#（3）通过SQL-Hint语法进行优化（尽量不用）" class="headerlink" title="（3）通过SQL-Hint语法进行优化（尽量不用）"></a>（3）通过SQL-Hint语法进行优化（尽量不用）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--使用MapJoin</span><br><span class="line">select /*+ MAPJOIN(b)*/ a.key,a.value</span><br><span class="line">from a </span><br><span class="line">join b on a.key = b.key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--默认情况下在reduce阶段进行连接，hive会把左表中的数据放在缓存中，右表中的数据作为流数据表，如果想要改变这种方式，就使用/*+streamtable(表名)*/来指定你想要作为流数据的表</span><br><span class="line">select /*+streamtable(a)*/ a.val,b.val,c.val</span><br><span class="line">from a</span><br><span class="line">join b on (a.key = b.key1)</span><br><span class="line">join c on (c.key = b.key1)</span><br></pre></td></tr></table></figure>

<h3 id="（4）尽早过滤掉不需要的数据"><a href="#（4）尽早过滤掉不需要的数据" class="headerlink" title="（4）尽早过滤掉不需要的数据"></a>（4）尽早过滤掉不需要的数据</h3><p>尽可能将where子句的过滤操作（filter操作）发生在Map端，减少跨机器进行网络传输到Reduce端的数据量。在多个Map-Reduce任务的时候，最差情况也应该在前面的Map和Reduce中过滤掉大量数据，有利于减少后面的作业处理和传输的数据量，提高整体的性能。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">--处理前</span><br><span class="line">select count(s_age) </span><br><span class="line">from (</span><br><span class="line">    select s_age,count(1) as num</span><br><span class="line">    from tmp_1</span><br><span class="line">    group by s_age</span><br><span class="line">)a</span><br><span class="line">where s_age &lt; 30 and num &gt; 20</span><br><span class="line"></span><br><span class="line">--处理后</span><br><span class="line">select count(s_age) </span><br><span class="line">from (</span><br><span class="line">    select s_age,count(1) as num</span><br><span class="line">    from tmp_1</span><br><span class="line">    where s_age &lt; 30</span><br><span class="line">    group by s_age</span><br><span class="line">    having num &gt; 20</span><br><span class="line">)a</span><br></pre></td></tr></table></figure>

<h1 id="第十二章-Hive千亿级数据倾斜"><a href="#第十二章-Hive千亿级数据倾斜" class="headerlink" title="第十二章 Hive千亿级数据倾斜"></a>第十二章 Hive千亿级数据倾斜</h1><h2 id="12-1-数据倾斜问题的本质原因"><a href="#12-1-数据倾斜问题的本质原因" class="headerlink" title="12.1 数据倾斜问题的本质原因"></a>12.1 数据倾斜问题的本质原因</h2><p>数据倾斜广义定义：当所需处理的数据量级较大时，某个类型的节点所需要处理的数据量级，大于同类型的节点一个数量级（10倍）以上，就叫做数据倾斜。</p>
<p>（1）map端：如果文件使用GZIP压缩等不支持文件分割操作的压缩方式时，若该不可分割的文件超大，被一个map读取时，就会发生map阶段的数据倾斜。</p>
<p>（2）reduce端（更容易出现）：map 到 reduce 会经过 shuffle 阶段，在 shuffle 中默认会按照 key进行 hash，<strong>如果相同的 key 过多，那么 hash 的结果就是大量相同的 key 进入到同一个 reduce 中</strong>，导致数据倾斜</p>
<p>简而言之：旱的旱死涝的涝死</p>
<h2 id="12-2-数据倾斜解决方案"><a href="#12-2-数据倾斜解决方案" class="headerlink" title="12.2 数据倾斜解决方案"></a>12.2 数据倾斜解决方案</h2><h3 id="12-2-1-空值引发的数据倾斜"><a href="#12-2-1-空值引发的数据倾斜" class="headerlink" title="12.2.1 空值引发的数据倾斜"></a>12.2.1 空值引发的数据倾斜</h3><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><p>实际业务中有些大量的 null 值或者一些无意义的数据参与到计算作业中，表中有大量的 null 值，如果表之间进行 join 操作，就会有 shuffle 产生，<strong>这样所有的 null 值都会被分配到一个 reduce 中，必然产生数据倾斜。</strong></p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>①可以直接不让 null 值参与 join 操作，即不让 null 值有 shuffle 阶段</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM log a</span><br><span class="line">JOIN users b</span><br><span class="line">ON a.user_id IS NOT NULL</span><br><span class="line">AND a.user_id = b.user_id</span><br><span class="line">UNION ALL</span><br><span class="line">SELECT *</span><br><span class="line">FROM log a</span><br><span class="line">WHERE a.user_id IS NULL;</span><br></pre></td></tr></table></figure>

<p>②因为 null 值参与 shuffle 时的 hash 结果是一样的，那么我们可以给null 值随机赋值，这样它们的 hash 结果就不一样，就会进到不同的 reduce 中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM log a</span><br><span class="line">LEFT JOIN users b ON CASE</span><br><span class="line">WHEN a.user_id IS NULL THEN concat(&#x27;hive_&#x27;, rand())</span><br><span class="line">ELSE a.user_id</span><br><span class="line">END = b.user_id;</span><br></pre></td></tr></table></figure>

<h3 id="12-2-2-不同数据类型引发的数据倾斜"><a href="#12-2-2-不同数据类型引发的数据倾斜" class="headerlink" title="12.2.2 不同数据类型引发的数据倾斜"></a>12.2.2 不同数据类型引发的数据倾斜</h3><h4 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h4><p>对于两个表join，表a中需要 join的字段key为 int，表b中key 字段既有string类型也有 int 类型。当按照 key 进行两个表的 join 操作时，默认的 Hash 操作会按 int 型的 id 来进行分配，这样所有的 string 类型都被分配成同一个 id，结果就是所有的 string 类型的字段进入到一个 reduce 中，引发数据倾斜。</p>
<h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p>如果 key 字段既有 string 类型也有 int 类型，默认的 hash 就都会按 int 类型来分配，那我们直接把 int 类型都转为 string 就好了，这样 key 字段都为 string，hash 时就按照 string 类型分配了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM users a</span><br><span class="line">LEFT JOIN logs b ON a.usr_id = CAST(b.user_id AS string);</span><br></pre></td></tr></table></figure>

<h3 id="12-2-3-不可拆分大文件引发的数据倾斜"><a href="#12-2-3-不可拆分大文件引发的数据倾斜" class="headerlink" title="12.2.3 不可拆分大文件引发的数据倾斜"></a>12.2.3 不可拆分大文件引发的数据倾斜</h3><h4 id="原因-2"><a href="#原因-2" class="headerlink" title="原因"></a>原因</h4><p>如果文件使用GZIP压缩等不支持文件分割操作的压缩方式时，若该不可分割的文件超大，被一个map读取时，就会发生map阶段的数据倾斜。</p>
<h4 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h4><p>这种数据倾斜问题没有什么好的解决方案，只能将使用 GZIP 压缩等不支持文件分割的文件转为 bzip 和 zip 等支持文件分割的压缩方式。所以，<strong>我们在对文件进行压缩时，为避免因不可拆分大文件而引发数据读取的倾斜，在数据压缩的时候可以采用 bzip2 和 Zip 等支持文件分割的压缩算法</strong>。</p>
<h3 id="12-2-4-数据膨胀引发的数据倾斜"><a href="#12-2-4-数据膨胀引发的数据倾斜" class="headerlink" title="12.2.4 数据膨胀引发的数据倾斜"></a>12.2.4 数据膨胀引发的数据倾斜</h3><h4 id="原因-3"><a href="#原因-3" class="headerlink" title="原因"></a>原因</h4><p>在多维聚合计算时，如果进行分组聚合的字段过多，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select a，b，c，count（1）</span><br><span class="line">from log </span><br><span class="line">group by a，b，c </span><br><span class="line">with rollup;</span><br></pre></td></tr></table></figure>

<p>如果上面的 log 表的数据量很大，并且 Map 端的聚合不能很好地起到数据压缩的情况下，会导致 Map 端产出的数据急速膨胀，这种情况容易导致作业内存溢出的异常。如果 log 表含有数据倾斜 key，会加剧 Shuffle 过程的数据倾斜。</p>
<h4 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h4><p>在 Hive 中可以通过参数 hive.new.job.grouping.set.cardinality 配置的方式自动控制作业的拆解，该参数默认值是 30。表示针对 groupingsets&#x2F;rollups&#x2F;cubes 这类多维聚合的操作，如果最后拆解的键组合大于该值，会启用新的任务去处理大于该值之外的组合。如果在处理数据时，某个分组聚合的列有较大的倾斜，可以适当调小该值。</p>
<h3 id="12-2-5-表join连接时引发的数据倾斜"><a href="#12-2-5-表join连接时引发的数据倾斜" class="headerlink" title="12.2.5 表join连接时引发的数据倾斜"></a>12.2.5 表join连接时引发的数据倾斜</h3><p>去看前面的内容，此处略</p>
<h3 id="12-2-6-确实无法减少数据量引发的数据倾斜"><a href="#12-2-6-确实无法减少数据量引发的数据倾斜" class="headerlink" title="12.2.6 确实无法减少数据量引发的数据倾斜"></a>12.2.6 确实无法减少数据量引发的数据倾斜</h3><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>这类问题最直接的方式就是调整 reduce 所执行的内存大小。调整 reduce 的内存大小使用 mapreduce.reduce.memory.mb 这个配置</p>
<h1 id="第十三章-Hive视图"><a href="#第十三章-Hive视图" class="headerlink" title="第十三章 Hive视图"></a>第十三章 Hive视图</h1><p>视图可以允许保存一个查询并像对待表一样对这个查询进行操作。这是一个逻辑结构，它不像一个表会存储数据。</p>
<h2 id="13-1-使用视图来降低查询复杂度"><a href="#13-1-使用视图来降低查询复杂度" class="headerlink" title="13.1 使用视图来降低查询复杂度"></a>13.1 使用视图来降低查询复杂度</h2><p>当查询变得长或复杂的时候，通过视图将这个查询语句分隔成多个小的、可控的的片段可以降低这种复杂度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">--如下是一个具有嵌套子查询查询</span><br><span class="line">select a.lastname</span><br><span class="line">from (</span><br><span class="line">    selct *</span><br><span class="line">    from people join cart</span><br><span class="line">    on cart.people_id = people.id</span><br><span class="line">    where firstname = &#x27;john&#x27;</span><br><span class="line">    ) a</span><br><span class="line">where a.id = 3;</span><br><span class="line"></span><br><span class="line">--嵌套子查询变成一个视图</span><br><span class="line">creat view shorter_join as </span><br><span class="line">selct *</span><br><span class="line">from people join cart</span><br><span class="line">on cart.people_id = people.id</span><br><span class="line">where firstname = &#x27;john&#x27;;</span><br><span class="line"></span><br><span class="line">--这样就可以像操作表一样来操作视图</span><br><span class="line">select lastname from shorter_join where id = 3;</span><br></pre></td></tr></table></figure>

<h2 id="13-2-使用视图来限制基于条件过滤的数据"><a href="#13-2-使用视图来限制基于条件过滤的数据" class="headerlink" title="13.2 使用视图来限制基于条件过滤的数据"></a>13.2 使用视图来限制基于条件过滤的数据</h2><p>不给用户直接访问具有敏感数据的原始表，而是提供给用户一个通过where子句限制的视图，以供访问</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">--通过视图限制数据访问保护信息不被随意查询</span><br><span class="line">create table userinfo </span><br><span class="line">(firstname string, lastname string, ssh string, password string);</span><br><span class="line">create view safer_user_info as</span><br><span class="line">select firstname, lastname from userinfo;</span><br><span class="line">--使用where语句</span><br><span class="line">create table employee</span><br><span class="line">(firstname string, lastname string, ssh string, password string, department string);</span><br><span class="line">create view tech_employee as </span><br><span class="line">select firstname, lastname, ssh</span><br><span class="line">from employee </span><br><span class="line">where department = &#x27;tech&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="13-3-其他"><a href="#13-3-其他" class="headerlink" title="13.3 其他"></a>13.3 其他</h2><p>视图实际上是对其所使用的表和列的一个查询语句的固化过程，因此，如果视图所涉及的表或者列不存在时，会导致视图查询失败</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--删除视图</span><br><span class="line">drop view if exists 视图名;</span><br></pre></td></tr></table></figure>



<h2 id="13-4-物化视图"><a href="#13-4-物化视图" class="headerlink" title="13.4 物化视图"></a>13.4 物化视图</h2>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Hadoop框架学习笔记" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/05/Hadoop%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Hadoop框架学习笔记</a>
    </h1>
  

        
        <a href="/2023/08/05/Hadoop%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2023-08-05T11:31:39.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-08-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一部分-大数据概论"><a href="#第一部分-大数据概论" class="headerlink" title="第一部分 大数据概论"></a>第一部分 大数据概论</h1><h2 id="第一章-大数据概念"><a href="#第一章-大数据概念" class="headerlink" title="第一章 大数据概念"></a>第一章 大数据概念</h2><p>大数据：指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程化能力的<strong>海量、高增长和多样化的信息资产</strong>。</p>
<p>大数据主要解决的问题：<strong>海量数据的采集、存储和分析计算问题</strong>。</p>
<h2 id="第二章-大数据特点（4V）"><a href="#第二章-大数据特点（4V）" class="headerlink" title="第二章 大数据特点（4V）"></a>第二章 大数据特点（4V）</h2><ol>
<li>Volume（大量）：一些大型企业的数据量已经接近EB量级。</li>
<li>Velocity（高速）</li>
<li>Variety（多样）：结构化数据和非结构化数据</li>
<li>Value（价值密度低）：价值密度的高低与数据总量的大小成反比</li>
</ol>
<h2 id="第三章-大数据部门内组织结构"><a href="#第三章-大数据部门内组织结构" class="headerlink" title="第三章 大数据部门内组织结构"></a>第三章 大数据部门内组织结构</h2><ol>
<li>平台组</li>
</ol>
<ul>
<li>Hadoop、Flume、Kafka、HBase、Spark等框架平台搭建</li>
<li>集群性能监控</li>
<li>集群性能调优</li>
</ul>
<ol start="2">
<li>数据仓库组</li>
</ol>
<ul>
<li>ETL工程师（数据清洗）</li>
<li>数据分析、数据仓库建模（<strong>建模是灵魂</strong>）</li>
</ul>
<ol start="3">
<li>实时组</li>
</ol>
<ul>
<li>实时指标分析性能调优</li>
</ul>
<ol start="4">
<li>数据挖掘组</li>
</ol>
<ul>
<li>算法工程师</li>
<li>推荐系统工程师</li>
<li>用户画像工程师</li>
</ul>
<ol start="5">
<li>报表开发组</li>
</ol>
<ul>
<li>JavaEE工程师</li>
<li>前端工程师</li>
</ul>
<h1 id="第二部分-Hadoop入门"><a href="#第二部分-Hadoop入门" class="headerlink" title="第二部分 Hadoop入门"></a>第二部分 Hadoop入门</h1><h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><h2 id="第二章-Hadoop运行环境搭建（开发重点）"><a href="#第二章-Hadoop运行环境搭建（开发重点）" class="headerlink" title="第二章 Hadoop运行环境搭建（开发重点）"></a>第二章 Hadoop运行环境搭建（开发重点）</h2><h3 id="2-1-模板虚拟机环境准备"><a href="#2-1-模板虚拟机环境准备" class="headerlink" title="2.1 模板虚拟机环境准备"></a>2.1 模板虚拟机环境准备</h3><p>0）安装虚拟机，IP地址192.168.255.100、主机名称hadoop100、内存4G、硬盘50G</p>
<p>1）hadoop虚拟机配置要求如下</p>
<p>①测试可以上网</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# ping www.baidu.com</span><br><span class="line">PING www.a.shifen.com (110.242.68.3) 56(84) bytes of data.</span><br><span class="line">64 bytes from 110.242.68.3 (110.242.68.3): icmp_seq=1 ttl=128 time=29.9 ms</span><br><span class="line">64 bytes from 110.242.68.3 (110.242.68.3): icmp_seq=2 ttl=128 time=30.4 ms</span><br><span class="line">64 bytes from 110.242.68.3 (110.242.68.3): icmp_seq=3 ttl=128 time=30.4 ms</span><br><span class="line">64 bytes from 110.242.68.3 (110.242.68.3): icmp_seq=4 ttl=128 time=30.3 ms</span><br><span class="line">^C</span><br><span class="line">--- www.a.shifen.com ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3008ms</span><br><span class="line">rtt min/avg/max/mdev = 29.936/30.301/30.491/0.276 ms</span><br></pre></td></tr></table></figure>

<p>②安装epel-release</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y epel-release</span><br><span class="line">已加载插件：fastestmirror, langpacks</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.bupt.edu.cn</span><br><span class="line">正在解决依赖关系</span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">正在检查事务</span></span><br><span class="line"><span class="meta prompt_">---&gt; </span><span class="language-bash">软件包 epel-release.noarch.0.7-11 将被 安装</span></span><br><span class="line"><span class="meta prompt_">--&gt; </span><span class="language-bash">解决依赖关系完成</span></span><br><span class="line"></span><br><span class="line">依赖关系解决</span><br><span class="line"></span><br><span class="line">=============================================</span><br><span class="line"> Package       架构    版本    源       大小</span><br><span class="line">=============================================</span><br><span class="line">正在安装:</span><br><span class="line"> epel-release  noarch  7-11    extras   15 k</span><br><span class="line"></span><br><span class="line">事务概要</span><br><span class="line">=============================================</span><br><span class="line">安装  1 软件包</span><br><span class="line"></span><br><span class="line">总下载量：15 k</span><br><span class="line">安装大小：24 k</span><br><span class="line">Downloading packages:</span><br><span class="line">epel-release-7-11.noarc |  15 kB   00:00     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  正在安装    : epel-release-7-11.noar   1/1 </span><br><span class="line">  验证中      : epel-release-7-11.noar   1/1 </span><br><span class="line"></span><br><span class="line">已安装:</span><br><span class="line">  epel-release.noarch 0:7-11                 </span><br><span class="line"></span><br><span class="line">完毕！</span><br></pre></td></tr></table></figure>

<p>2）关闭防火墙，关闭防火墙开机自启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# systemctl stop firewalld</span><br><span class="line">[root@hadoop100 ~]# systemctl disable firewalld.service</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.</span><br><span class="line">Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</span><br></pre></td></tr></table></figure>

<p>3）创建atguigu用户</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# useradd atguigu</span><br><span class="line">[root@hadoop100 ~]# passwd atguigu</span><br></pre></td></tr></table></figure>

<p>密码为123456</p>
<p>4）配置atguigu用户具有root权限，方便后期加sudo执行root权限的命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# vim /etc/sudoers</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Allows people in group wheel to run all commands</span></span></span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash">wheel  ALL=(ALL)       ALL</span></span><br><span class="line">atguigu     ALL=(ALL)       NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<p>即添加atguigu这一行即可</p>
<p>5）在&#x2F;opt目录下创建文件夹，并修改所属主和所属组</p>
<p>①在&#x2F;opt目录下创建module、software文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# mkdir /opt/module</span><br><span class="line">[root@hadoop100 ~]# mkdir /opt/software</span><br></pre></td></tr></table></figure>

<p>②修改module、software文件夹的所有者和所属组均为tom用户</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# chown atguigu:atguigu /opt/module</span><br><span class="line">[root@hadoop100 ~]# chown atguigu:atguigu /opt/software</span><br></pre></td></tr></table></figure>

<p>③查看module，software文件夹的所有者和所属组</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# cd /opt/</span><br><span class="line">[root@hadoop100 opt]# ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 6 8月   5 21:09 module</span><br><span class="line">drwxr-xr-x. 2 root    root    6 10月 31 2018 rh</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu 6 8月   5 21:09 software</span><br></pre></td></tr></table></figure>

<p>6）卸载虚拟机自带的JDK</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 opt]# rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<img src="webwxgetmsgimg (54).jpg" alt="webwxgetmsgimg (54)" style="zoom:50%;">

<p>7）重启虚拟机</p>
<h3 id="2-2-克隆虚拟机"><a href="#2-2-克隆虚拟机" class="headerlink" title="2.2 克隆虚拟机"></a>2.2 克隆虚拟机</h3><p>1）利用模板机hadoop100，克隆三台虚拟机：hadoop102  hadoop103  hadoop104</p>
<p>2）克隆详细内容参考Linux和Shell基础知识</p>
<h3 id="2-3-在hadoop102安装JDK"><a href="#2-3-在hadoop102安装JDK" class="headerlink" title="2.3 在hadoop102安装JDK"></a>2.3 在hadoop102安装JDK</h3><p>1）卸载现有JDK</p>
<p>2）用Xftp传输工具将JDK导入到opt目录下面的software文件夹下面</p>
<img src="Snipaste_2023-08-05_22-11-25.png" alt="Snipaste_2023-08-05_22-11-25" style="zoom:43%;">

<p>3）在Linux系统下的opt目录中查看软件包是否导入成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# ls /opt/software</span><br><span class="line">jdk-8u212-linux-x64.tar.gz</span><br></pre></td></tr></table></figure>

<p>4）解压JDK到&#x2F;opt&#x2F;module目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>5）配置JDK环境变量</p>
<p>①新建&#x2F;etc&#x2F;profile.d&#x2F;my_env.sh文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>添加如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<p>②保存后退出</p>
<p>③source一下&#x2F;etc&#x2F;profile文件，让新的环境变量PATH生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# source /etc/profile</span><br></pre></td></tr></table></figure>

<p>6）测试JDK是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# java -version</span><br><span class="line">java version &quot;1.8.0_212&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_212-b10)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)</span><br></pre></td></tr></table></figure>

<h3 id="2-4-在hadoop102安装Hadoop"><a href="#2-4-在hadoop102安装Hadoop" class="headerlink" title="2.4 在hadoop102安装Hadoop"></a>2.4 在hadoop102安装Hadoop</h3><p>1）用Xftp传输工具将hadoop文件导入到opt目录下面的software文件夹下面</p>
<p>2）进入到Hadoop安装包路径下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/software/</span><br></pre></td></tr></table></figure>

<p>3）解压安装文件到&#x2F;opt&#x2F;module下面</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>4）查看是否解压成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop102 software]# ls /opt/module/</span><br><span class="line">hadoop-3.1.3  jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>5）将Hadoop添加到环境变量</p>
<p>①获取Hadoop安装路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# pwd</span><br><span class="line">/opt/module/hadoop-3.1.3</span><br></pre></td></tr></table></figure>

<p>②打开&#x2F;etc&#x2F;profile.d&#x2F;my_env.sh文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# sudo vim /etc/profile.d/my_env.sh </span><br></pre></td></tr></table></figure>

<p>在文件末尾添加如下语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>③让修改后的文件生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# source /etc/profile</span><br></pre></td></tr></table></figure>

<p>6）测试是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop version</span><br><span class="line">Hadoop 3.1.3</span><br><span class="line">Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579</span><br><span class="line">Compiled by ztang on 2019-09-12T02:47Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum ec785077c385118ac91aadde5ec9799</span><br><span class="line">This command was run using /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-common-3.1.3.jar</span><br></pre></td></tr></table></figure>

<h3 id="2-5-Hadoop目录结构"><a href="#2-5-Hadoop目录结构" class="headerlink" title="2.5 Hadoop目录结构"></a>2.5 Hadoop目录结构</h3><p>1）查看Hadoop目录结构</p>
<img src="Snipaste_2023-08-05_22-57-07.png" alt="Snipaste_2023-08-05_22-57-07" style="zoom:43%;">

<img src="webwxgetmsgimg.jpg" alt="webwxgetmsgimg" style="zoom:50%;">

<p>bin目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# cd bin/</span><br><span class="line">[root@hadoop102 bin]# ll</span><br><span class="line">总用量 996</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh 441936 9月  12 2019 container-executor</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh   8707 9月  12 2019 hadoop</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh  11265 9月  12 2019 hadoop.cmd</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh  11026 9月  12 2019 hdfs</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh   8081 9月  12 2019 hdfs.cmd</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh   6237 9月  12 2019 mapred</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh   6311 9月  12 2019 mapred.cmd</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh 483728 9月  12 2019 test-container-executor</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh  11888 9月  12 2019 yarn</span><br><span class="line">-rwxr-xr-x. 1 wyh wyh  12840 9月  12 2019 yarn.cmd</span><br></pre></td></tr></table></figure>

<h2 id="第三章-Hadoop运行模式"><a href="#第三章-Hadoop运行模式" class="headerlink" title="第三章 Hadoop运行模式"></a>第三章 Hadoop运行模式</h2><p>Hadoop的运行模式包括：<strong>本地模式</strong>，<strong>伪分布式模式</strong>，<strong>完全分布式模式</strong></p>
<ul>
<li>本地模式：单机运行，只是用来演示一下官方案例。生产环境不用</li>
<li>伪分布式模式：也是单机运行，但是具备Hadoop集群的所有功能，一台服务器模拟一个分布式的环境。个别缺钱的公司用来测试，生产环境不用</li>
<li>完全分布式模式：多台服务器组成分布式环境。生产环境使用</li>
</ul>
<h3 id="3-1-本地运行模式（官方WordCount）"><a href="#3-1-本地运行模式（官方WordCount）" class="headerlink" title="3.1 本地运行模式（官方WordCount）"></a>3.1 本地运行模式（官方WordCount）</h3><p>1）进入hadoop-3.1.3文件夹下，创建一个wcinput文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/hadoop-3.1.3</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# mkdir wcinput</span><br></pre></td></tr></table></figure>

<p>2）在wcinput文件下创建一个word.txt文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# cd wcinput/</span><br><span class="line">[root@hadoop102 wcinput]# vim word.txt</span><br></pre></td></tr></table></figure>

<p>3）编辑word.txt文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop HDFS</span><br><span class="line">hadoop mapreduce</span><br><span class="line">hadoop yarn</span><br><span class="line">spark core</span><br><span class="line">spark MLlib</span><br><span class="line">spark RDD</span><br><span class="line">flink core</span><br><span class="line">flink alink</span><br></pre></td></tr></table></figure>

<p>4）回到&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 wcinput]# cd /opt/module/hadoop-3.1.3</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# </span><br></pre></td></tr></table></figure>

<p>5）执行程序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput/ wcoutput</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<ul>
<li>hadoop-mapreduce-examples-3.1.3.jar包下有多个案例，我们现在只用一个案例，案例名为wordcount</li>
<li>wcinput为输入路径，wcoutput为输出路径</li>
<li>mapreduce程序必须指定输入路径和输出路径，且输出路径是不存在的，如果存在，会<strong>抛出异常</strong></li>
</ul>
<p>6）查看结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# cd wcoutput/</span><br><span class="line">[root@hadoop102 wcoutput]# ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 root root 80 8月   7 10:45 part-r-00000</span><br><span class="line">-rw-r--r--. 1 root root  0 8月   7 10:45 _SUCCESS</span><br></pre></td></tr></table></figure>

<p>可以看到输出路径文件夹wcoutput中有两个文件，part-r-00000为真正存储的数据，查看结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 wcoutput]# cat part-r-00000 </span><br><span class="line">HDFS	1</span><br><span class="line">MLlib	1</span><br><span class="line">RDD	1</span><br><span class="line">alink	1</span><br><span class="line">core	2</span><br><span class="line">flink	2</span><br><span class="line">hadoop	3</span><br><span class="line">mapreduce	1</span><br><span class="line">spark	3</span><br><span class="line">yarn	1</span><br></pre></td></tr></table></figure>

<p>小插曲：切换用户</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 wcoutput]# su atguigu</span><br><span class="line">[atguigu@hadoop102 wcoutput]$ </span><br></pre></td></tr></table></figure>

<h3 id="3-2-完全分布式运行模式（开发重点。至少自己安装三遍以上）"><a href="#3-2-完全分布式运行模式（开发重点。至少自己安装三遍以上）" class="headerlink" title="3.2 完全分布式运行模式（开发重点。至少自己安装三遍以上）"></a>3.2 完全分布式运行模式（开发重点。至少自己安装三遍以上）</h3><p>1）准备三台客户机（关闭防火墙、静态IP、主机名称）</p>
<p>2）安装JDK</p>
<p>3）配置环境变量</p>
<p>4）安装Hadoop</p>
<p>5）配置集群</p>
<p>6）单点启动</p>
<p>7）配置ssh</p>
<p>8）群起并测试集群</p>
<h4 id="3-2-1-虚拟机准备"><a href="#3-2-1-虚拟机准备" class="headerlink" title="3.2.1 虚拟机准备"></a>3.2.1 虚拟机准备</h4><p>分别为hadoop_copy2—–hadoop102</p>
<p>hadoop_copy3—–hadoop103</p>
<p>hadoop_copy4—–hadoop104</p>
<p>目前的情况是：<strong>hadoop102上已经安装了jdk和hadoop，但是hadoop103和hadoop104还没有安装</strong></p>
<h4 id="3-2-2-编写一些Shell脚本"><a href="#3-2-2-编写一些Shell脚本" class="headerlink" title="3.2.2 编写一些Shell脚本"></a>3.2.2 编写一些Shell脚本</h4><p>这个集群分发脚本要做的事情就是将hadoop102上的jdk和hadoop拷贝到hadoop103和hadoop104上</p>
<h5 id="1）scp（secure-copy）安全拷贝"><a href="#1）scp（secure-copy）安全拷贝" class="headerlink" title="1）scp（secure copy）安全拷贝"></a><strong>1）scp（secure copy）安全拷贝</strong></h5><p>①scp定义</p>
<p>scp可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）</p>
<p>②基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp     -r      $pdir/$fname                $user@$host:$pdir/$fname</span><br><span class="line"></span><br><span class="line">命令    递归     要拷贝的文件路径/名称        目的地用户@主机：目的地路径/名称</span><br></pre></td></tr></table></figure>

<p>③案例实操</p>
<p>前提：在hadoop102，hadoop103，hadoop104都已经创建好&#x2F;opt&#x2F;module，&#x2F;opt&#x2F;software两个目录，并且已经把这两个目录修改为atguigu:atguigu</p>
<p>（a）在hadoop102上，将hadoop102中&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_212目录拷贝到hadoop103上（推文件）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ scp -r /opt/module/jdk1.8.0_212/ atguigu@hadoop103:/opt/module/</span><br></pre></td></tr></table></figure>

<p>此时在hadoop103上可以看到jdk</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 opt]$ cd /opt/module/</span><br><span class="line">[atguigu@hadoop103 module]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 7 atguigu atguigu 245 8月   7 17:06 jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>（b）在hadoop103上，将hadoop102中&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3目录拷贝到hadoop103上（拉文件）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ scp -r atguigu@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/</span><br></pre></td></tr></table></figure>

<p>此时：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ cd /opt/module/</span><br><span class="line">[atguigu@hadoop103 module]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 11 atguigu atguigu 180 8月   7 17:14 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x.  7 atguigu atguigu 245 8月   7 17:06 jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>（c）在hadoop103上操作，将hadoop102中&#x2F;opt&#x2F;module目录下所有的目录拷贝到hadoop104上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ scp -r atguigu@hadoop102:/opt/module/* atguigu@hadoop104:/opt/module/</span><br></pre></td></tr></table></figure>

<p>复制成功：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop104 opt]$ cd /opt/module/</span><br><span class="line">[atguigu@hadoop104 module]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 11 atguigu atguigu 180 8月   7 17:23 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x.  7 atguigu atguigu 245 8月   7 17:24 jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<h5 id="2）rsync远程同步工具"><a href="#2）rsync远程同步工具" class="headerlink" title="2）rsync远程同步工具"></a><strong>2）rsync远程同步工具</strong></h5><p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p>
<p>rsync和scp区别：用raync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去</p>
<p>①基本语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rsync       -av       $pdir/$fname              $user@$host:$pdir/$fname</span><br><span class="line">命令        选项参数   要拷贝的文件/路径          目的地用户@主机：目的地路径/名称</span><br><span class="line"></span><br><span class="line">选项参数说明：</span><br><span class="line">-a：归档拷贝</span><br><span class="line">-v：显示复杂过程</span><br></pre></td></tr></table></figure>

<p>②案例实操</p>
<p>（a）删除hadoop103中&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;wcinput</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 hadoop-3.1.3]$ rm -rf wcinput/</span><br></pre></td></tr></table></figure>

<p>（b）同步hadoop102中的&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3到hadoop103</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ rsync -av hadoop-3.1.3/ atguigu@hadoop103:/opt/module/hadoop-3.1.3/</span><br></pre></td></tr></table></figure>

<p>同步成功，在hadoop103中可以找到被删除的wcinput</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 hadoop-3.1.3]$ ll</span><br><span class="line">总用量 176</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu    183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 3 atguigu atguigu     20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu    106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 atguigu atguigu     20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 atguigu atguigu    288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 147145 9月   4 2019 LICENSE.txt</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu  21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu   1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 atguigu atguigu   4096 9月  12 2019 sbin</span><br><span class="line">drwxr-xr-x. 4 atguigu atguigu     31 9月  12 2019 share</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu     22 8月   7 10:36 wcinput</span><br><span class="line">drwxr-xr-x. 2 atguigu atguigu     88 8月   7 10:45 wcoutput</span><br></pre></td></tr></table></figure>

<h5 id="3）xsync集群分发脚本"><a href="#3）xsync集群分发脚本" class="headerlink" title="3）xsync集群分发脚本"></a><strong>3）xsync集群分发脚本</strong></h5><p>①需求：循环复制文件到所有服务器节点的相同目录下（比如我在hadoop101节点的根目录下新建了一个文件，执行xsync命令后，将该文件复制到hadoop102和hadoop103节点的根目录下）</p>
<p>②需求分析</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">rsync命令原始拷贝</span> </span><br><span class="line">rsync -av /opt/module   atguigu@hadoop103:/opt/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">期望脚本</span></span><br><span class="line">xsync 要同步的文件名称</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">期望脚本在任何路径都能使用（脚本放在声明了全局环境变量的路径）</span></span><br><span class="line">[atguigu@hadoop102 ~]$ echo $PATH</span><br><span class="line">/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/module/jdk1.8.0_212/bin:/opt/module/hadoop-3.1.3/bin:/opt/module/hadoop-3.1.3/sbin:/root/bin:/opt/module/jdk1.8.0_212/bin:/opt/module/hadoop-3.1.3/bin:/opt/module/hadoop-3.1.3/sbin</span><br></pre></td></tr></table></figure>

<p>③脚本实现</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/bin目录下创建xsync文件</span></span><br><span class="line">[root@hadoop102 ~]$ cd /bin</span><br><span class="line">[root@hadoop102 bin]$ vim xsync</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在文件中编写如下代码</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1.判断参数格式</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo Not Enough Arguement!</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2.遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo ============ $host ==============</span><br><span class="line">    # 3.遍历所有目录，挨个发送</span><br><span class="line"></span><br><span class="line">    for file in $@</span><br><span class="line">    do</span><br><span class="line">       # 4.判断文件是否存在</span><br><span class="line">       if [ -e $file ]</span><br><span class="line">           then</span><br><span class="line">               # 5.获取父目录</span><br><span class="line">               pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">               # 6.获取当前文件的名称</span><br><span class="line">               fname=$(basename $file)</span><br><span class="line">               ssh $host &quot;mkdir -P $pdir&quot;</span><br><span class="line">               rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">           else</span><br><span class="line">               echo $file does not exists!</span><br><span class="line">       fi</span><br><span class="line">    done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改脚本文件xsync，使其具有执行权限</span></span><br><span class="line">[root@hadoop102 bin]$ chmod 777 xsync</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用脚本文件xsync进行集群分发测试，将hadoop102节点下的 /bin目录 复制到hadoop103和hadoop104中</span></span><br><span class="line">[root@hadoop102 bin]# su atguigu</span><br><span class="line">[atguigu@hadoop102 bin]$ xsync /bin</span><br><span class="line">============ hadoop102 ==============</span><br><span class="line">The authenticity of host &#x27;hadoop102 (192.168.255.102)&#x27; can&#x27;t be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:U30fwJUGD+M1SYtW9uchyBhmZZcfSFfbYtFZCKRI0b4.</span><br><span class="line">ECDSA key fingerprint is MD5:40:4d:49:d3:f0:83:12:0a:af:13:d6:9d:de:61:1f:77.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added &#x27;hadoop102,192.168.255.102&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">atguigu@hadoop102&#x27;s password: </span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">atguigu@hadoop102&#x27;s password: </span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 49 bytes  received 12 bytes  17.43 bytes/sec</span><br><span class="line">total size is 7  speedup is 0.11</span><br><span class="line">============ hadoop103 ==============</span><br><span class="line">atguigu@hadoop103&#x27;s password: </span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">atguigu@hadoop103&#x27;s password: </span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 49 bytes  received 12 bytes  17.43 bytes/sec</span><br><span class="line">total size is 7  speedup is 0.11</span><br><span class="line">============ hadoop104 ==============</span><br><span class="line">atguigu@hadoop104&#x27;s password: </span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">atguigu@hadoop104&#x27;s password: </span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 49 bytes  received 12 bytes  24.40 bytes/sec</span><br><span class="line">total size is 7  speedup is 0.11</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">下面正式分发环境变量，由于会出现环境拒绝，所以要在命令前加上sudo：</span></span><br><span class="line">[atguigu@hadoop102 bin]$ sudo xsync /etc/profile.d/my_env.sh </span><br><span class="line">============ hadoop102 ==============</span><br><span class="line">root@hadoop102&#x27;s password: </span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">root@hadoop102&#x27;s password: </span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 48 bytes  received 12 bytes  17.14 bytes/sec</span><br><span class="line">total size is 215  speedup is 3.58</span><br><span class="line">============ hadoop103 ==============</span><br><span class="line">root@hadoop103&#x27;s password: </span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">root@hadoop103&#x27;s password: </span><br><span class="line">sending incremental file list</span><br><span class="line">my_env.sh</span><br><span class="line"></span><br><span class="line">sent 310 bytes  received 35 bytes  98.57 bytes/sec</span><br><span class="line">total size is 215  speedup is 0.62</span><br><span class="line">============ hadoop104 ==============</span><br><span class="line">root@hadoop104&#x27;s password: </span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">root@hadoop104&#x27;s password: </span><br><span class="line">sending incremental file list</span><br><span class="line">my_env.sh</span><br><span class="line"></span><br><span class="line">sent 310 bytes  received 35 bytes  98.57 bytes/sec</span><br><span class="line">total size is 215  speedup is 0.62</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">目前为止，所有的服务器上都成功安装了java和hadoop（要在atguigu用户下查看）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hadoop102</span></span><br><span class="line">[atguigu@hadoop102 ~]$ java -version</span><br><span class="line">java version &quot;1.8.0_212&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_212-b10)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)</span><br><span class="line">[atguigu@hadoop102 ~]$ hadoop version</span><br><span class="line">Hadoop 3.1.3</span><br><span class="line">Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579</span><br><span class="line">Compiled by ztang on 2019-09-12T02:47Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum ec785077c385118ac91aadde5ec9799</span><br><span class="line">This command was run using /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-common-3.1.3.jar</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hadoop103</span></span><br><span class="line">[atguigu@hadoop103 ~]$ java -version</span><br><span class="line">java version &quot;1.8.0_212&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_212-b10)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)</span><br><span class="line">[atguigu@hadoop103 ~]$ hadoop version</span><br><span class="line">Hadoop 3.1.3</span><br><span class="line">Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579</span><br><span class="line">Compiled by ztang on 2019-09-12T02:47Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum ec785077c385118ac91aadde5ec9799</span><br><span class="line">This command was run using /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-common-3.1.3.jar</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hadoop104</span></span><br><span class="line">[atguigu@hadoop104 root]$ java -version</span><br><span class="line">java version &quot;1.8.0_212&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_212-b10)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)</span><br><span class="line">[atguigu@hadoop104 root]$ hadoop version</span><br><span class="line">Hadoop 3.1.3</span><br><span class="line">Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579</span><br><span class="line">Compiled by ztang on 2019-09-12T02:47Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From source with checksum ec785077c385118ac91aadde5ec9799</span><br><span class="line">This command was run using /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-common-3.1.3.jar</span><br></pre></td></tr></table></figure>

<h5 id="4）集群命令同时执行脚本"><a href="#4）集群命令同时执行脚本" class="headerlink" title="4）集群命令同时执行脚本"></a><strong>4）集群命令同时执行脚本</strong></h5><p>在启动集群后，用户需要使用jps命令查看各节点服务器进程的启动情况，操作起来比较麻烦，所以我们编写一个集群命令同时执行脚本，达到使用一个脚本查看所有节点上的所有进程的目的。使用该脚本，还可以执行一些需要同时在集群不同节点上运行的命令。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/bin目录下创建xsync文件</span></span><br><span class="line">[root@hadoop102 ~]$ cd /bin</span><br><span class="line">[root@hadoop102 bin]$ vim xcall.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在文件中编写如下代码</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">  echo -----------$i---------------</span><br><span class="line">  ssh $i &quot;$*&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改脚本文件，使其具有执行权限</span></span><br><span class="line">[root@hadoop102 bin]# chmod 777 xcall.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动xcall.sh脚本</span></span><br><span class="line">[root@hadoop102 bin]# su atguigu</span><br><span class="line">[atguigu@hadoop102 ~]$ xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">atguigu@hadoop102&#x27;s password: </span><br><span class="line">5290 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">atguigu@hadoop103&#x27;s password: </span><br><span class="line">4580 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">atguigu@hadoop104&#x27;s password: </span><br><span class="line">4322 Jps</span><br></pre></td></tr></table></figure>

<h4 id="3-2-3-SSH免密登录"><a href="#3-2-3-SSH免密登录" class="headerlink" title="3.2.3 SSH免密登录"></a>3.2.3 SSH免密登录</h4><p>①有密登录（需要输入密码）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ ssh hadoop103</span><br><span class="line">atguigu@hadoop103&#x27;s password: </span><br><span class="line">Last login: Thu Sep 14 11:17:37 2023</span><br><span class="line">[atguigu@hadoop103 ~]$ </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">退回到hadoop102</span></span><br><span class="line">[atguigu@hadoop103 ~]$ exit</span><br><span class="line">登出</span><br><span class="line">Connection to hadoop103 closed.</span><br><span class="line">[atguigu@hadoop102 ~]$ </span><br></pre></td></tr></table></figure>

<p>②免密登录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hadoop102可以免密登录hadoop103和hadoop104</span></span><br><span class="line">[atguigu@hadoop102 ~]$ cd .ssh/</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa # 按三次回车</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/home/atguigu/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /home/atguigu/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /home/atguigu/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:oGyOphAWb7dzBrQcfHLKMRNjhgt6WyVB7o9Qrq77LrM atguigu@hadoop102</span><br><span class="line">The key&#x27;s randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|   .+*           |</span><br><span class="line">| . o= +          |</span><br><span class="line">|... +@.o         |</span><br><span class="line">|. +*=.@.         |</span><br><span class="line">|.o.=*B  S        |</span><br><span class="line">|..o*.oo          |</span><br><span class="line">|. + oo.o         |</span><br><span class="line">|++    +          |</span><br><span class="line">|EO+              |</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将hadoop102上的公钥拷贝到hadoop103和hadoop104上</span></span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/home/atguigu/.ssh/id_rsa.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">atguigu@hadoop103&#x27;s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;hadoop103&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">现在可以免密登录hadoop103了</span></span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh hadoop103</span><br><span class="line">Last login: Thu Sep 14 17:46:12 2023 from hadoop102</span><br><span class="line">[atguigu@hadoop103 ~]$ </span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/home/atguigu/.ssh/id_rsa.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">atguigu@hadoop104&#x27;s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;hadoop104&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">现在可以免密登录hadoop104了</span></span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh hadoop104</span><br><span class="line">Last login: Thu Sep 14 11:21:54 2023</span><br><span class="line">[atguigu@hadoop104 ~]$ </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">当然了对自己hadoop102也需要配置一次</span></span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/home/atguigu/.ssh/id_rsa.pub&quot;</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">atguigu@hadoop102&#x27;s password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   &quot;ssh &#x27;hadoop102&#x27;&quot;</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh hadoop102</span><br><span class="line">Last login: Thu Sep 14 18:07:11 2023</span><br><span class="line">[atguigu@hadoop102 ~]$ </span><br></pre></td></tr></table></figure>

<p>同理，对hadoop103和hadoop104做同样的操作，使得这三个服务器之间的atguigu用户可以互相免密登录。</p>
<p>再将hadoop102上的root用户配置对103和104的免密登录。</p>
<h4 id="3-2-4-集群配置"><a href="#3-2-4-集群配置" class="headerlink" title="3.2.4 集群配置"></a>3.2.4 集群配置</h4><h5 id="①集群部署规划"><a href="#①集群部署规划" class="headerlink" title="①集群部署规划"></a>①集群部署规划</h5><p>HDFS主要角色：NameNode，DataNode，SecindaryNameNode和Client。DataNode主要负责数据的存储工作，需要在每一台节点服务器上部署，SecindaryNameNode主要负责在集群遇到故障时候，协助NameNode进行故障恢复，所以SecindaryNameNode和NameNode不要安装在同一台服务器。</p>
<p>YARN主要角色：ResourceManager和NodeManager。NodeManager是单个节点服务器上的资源和任务管理器，需要在每一台节点服务器上部署，ResourceManager主要负责集群整体的资源调度工作，非常消耗内存，所以不要将其与同样消耗内存的NameNode配置在同一个节点服务器上。</p>
<table>
<thead>
<tr>
<th>节点服务器</th>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>JobHistoryServer<br>NameNode<br>DateNode</td>
<td>DateNode</td>
<td>DateNode<br>SecindaryNameNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>NodeManager<br>ResourceManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<h5 id="②配置文件说明"><a href="#②配置文件说明" class="headerlink" title="②配置文件说明"></a>②配置文件说明</h5><p>Hadoop配置文件有两类：<strong>默认配置文件</strong>和<strong>自定义配置文件</strong>，默认配置文件是Hadoop源码中自带的，提供了所有参数的默认值，如果用户想要修改默认值，则需要在<strong>自定义配置文件</strong>中修改。<strong>自定义配置文件的优先级高于默认配置文件</strong>。</p>
<img src="Snipaste_2023-09-14_18-47-42.png" alt="Snipaste_2023-09-14_18-47-42" style="zoom:50%;">

<p>自定义配置文件：<strong>core-site.xml、hdfs-site.xml</strong>、<strong>yarn-site.xml</strong>、<strong>mapred-site.xml</strong> 四个配置文件存放在</p>
<p>$HADOOP_HOME&#x2F;etc&#x2F;hadoop 这个路径上，用户可以根据项目需求重新进行修改配置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ cd /opt/module/hadoop-3.1.3/</span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ ll</span><br><span class="line">总用量 176</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh     288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh  147145 9月   4 2019 LICENSE.txt</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh   21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh    1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh    4096 9月  12 2019 sbin</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh      31 9月  12 2019 share</span><br><span class="line">drwxr-xr-x. 2 root root     22 8月   7 10:36 wcinput</span><br><span class="line">drwxr-xr-x. 2 root root     88 8月   7 10:45 wcoutput</span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ cd etc/hadoop</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">就可以找到四个自定义配置文件了</span></span><br><span class="line">[atguigu@hadoop102 hadoop]$ ll</span><br><span class="line">总用量 172</span><br><span class="line">-rw-r--r--. 1 wyh wyh  8260 9月  12 2019 capacity-scheduler.xml</span><br><span class="line">-rw-r--r--. 1 wyh wyh  1335 9月  12 2019 configuration.xsl</span><br><span class="line">-rw-r--r--. 1 wyh wyh  1940 9月  12 2019 container-executor.cfg</span><br><span class="line">-rw-r--r--. 1 wyh wyh   774 9月  12 2019 core-site.xml  # 自定义配置文件</span><br><span class="line">-rw-r--r--. 1 wyh wyh  3999 9月  12 2019 hadoop-env.cmd</span><br><span class="line">-rw-r--r--. 1 wyh wyh 15903 9月  12 2019 hadoop-env.sh</span><br><span class="line">-rw-r--r--. 1 wyh wyh  3323 9月  12 2019 hadoop-metrics2.properties</span><br><span class="line">-rw-r--r--. 1 wyh wyh 11392 9月  12 2019 hadoop-policy.xml</span><br><span class="line">-rw-r--r--. 1 wyh wyh  3414 9月  12 2019 hadoop-user-functions.sh.example</span><br><span class="line">-rw-r--r--. 1 wyh wyh   775 9月  12 2019 hdfs-site.xml  # 自定义配置文件</span><br><span class="line">-rw-r--r--. 1 wyh wyh  1484 9月  12 2019 httpfs-env.sh</span><br><span class="line">-rw-r--r--. 1 wyh wyh  1657 9月  12 2019 httpfs-log4j.properties</span><br><span class="line">-rw-r--r--. 1 wyh wyh    21 9月  12 2019 httpfs-signature.secret</span><br><span class="line">-rw-r--r--. 1 wyh wyh   620 9月  12 2019 httpfs-site.xml</span><br><span class="line">-rw-r--r--. 1 wyh wyh  3518 9月  12 2019 kms-acls.xml</span><br><span class="line">-rw-r--r--. 1 wyh wyh  1351 9月  12 2019 kms-env.sh</span><br><span class="line">-rw-r--r--. 1 wyh wyh  1747 9月  12 2019 kms-log4j.properties</span><br><span class="line">-rw-r--r--. 1 wyh wyh   682 9月  12 2019 kms-site.xml</span><br><span class="line">-rw-r--r--. 1 wyh wyh 13326 9月  12 2019 log4j.properties</span><br><span class="line">-rw-r--r--. 1 wyh wyh   951 9月  12 2019 mapred-env.cmd</span><br><span class="line">-rw-r--r--. 1 wyh wyh  1764 9月  12 2019 mapred-env.sh</span><br><span class="line">-rw-r--r--. 1 wyh wyh  4113 9月  12 2019 mapred-queues.xml.template</span><br><span class="line">-rw-r--r--. 1 wyh wyh   758 9月  12 2019 mapred-site.xml  # 自定义配置文件</span><br><span class="line">drwxr-xr-x. 2 wyh wyh    24 9月  12 2019 shellprofile.d</span><br><span class="line">-rw-r--r--. 1 wyh wyh  2316 9月  12 2019 ssl-client.xml.example</span><br><span class="line">-rw-r--r--. 1 wyh wyh  2697 9月  12 2019 ssl-server.xml.example</span><br><span class="line">-rw-r--r--. 1 wyh wyh  2642 9月  12 2019 user_ec_policies.xml.template</span><br><span class="line">-rw-r--r--. 1 wyh wyh    10 9月  12 2019 workers</span><br><span class="line">-rw-r--r--. 1 wyh wyh  2250 9月  12 2019 yarn-env.cmd</span><br><span class="line">-rw-r--r--. 1 wyh wyh  6056 9月  12 2019 yarn-env.sh</span><br><span class="line">-rw-r--r--. 1 wyh wyh  2591 9月  12 2019 yarnservice-log4j.properties</span><br><span class="line">-rw-r--r--. 1 wyh wyh   690 9月  12 2019 yarn-site.xml  # 自定义配置文件</span><br></pre></td></tr></table></figure>

<h5 id="③配置集群"><a href="#③配置集群" class="headerlink" title="③配置集群"></a>③配置集群</h5><p>1）配置core-site.xml文件</p>
<p>主要用于将分布式文件系统HDFS的NameNode的<strong>入口地址</strong>和分布式文件系统中的<strong>数据</strong> 存储于服务器本地磁盘中进行配置。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到core-site.xml文件</span></span><br><span class="line">[atguigu@hadoop102 hadoop]$ sudo vim core-site.xml </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置如下</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">     &lt;!-- 指定 NameNode 的地址 --&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">     &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;hdfs://hadoop102:8020&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">     &lt;!-- 指定 hadoop 数据的存储目录 --&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;/opt/module/hadoop-3.1.3/data&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">     &lt;!-- 配置 HDFS 网页登录使用的静态用户为 atguigu --&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">     &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;atguigu&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>2）配置hdfs-site.xml文件</p>
<p>我们主要对HDFS的属性进行配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到hdfs-site.xml文件</span></span><br><span class="line">[atguigu@hadoop102 hadoop]$ sudo vim hdfs-site.xml </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置如下</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- nn web 端访问地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">     &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;hadoop102:9870&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">    &lt;!-- 2nn web 端访问地址--&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">     &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;hadoop104:9868&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>3）配置yarn-site.xml文件（<strong>注意：这里的配置文件按照书中的来，不按照视频的来</strong>）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到yarn-site.xml文件</span></span><br><span class="line">[atguigu@hadoop102 hadoop]$ sudo vim yarn-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置如下</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定 MR 走 shuffle --&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line"> &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;!-- 指定 ResourceManager 的地址--&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line"> &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;hadoop103&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;!-- 环境变量的继承 --&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line"> &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;</span><br><span class="line"></span><br><span class="line">&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CO</span><br><span class="line">NF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP</span><br><span class="line">RED_HOME&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.application.classpath&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/opt/module/hadoop-3.1.3/etc/hadoop:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/*:/opt/module/hadoop-3.1.3/share/hadoop/common/*:/opt/module/hadoop-3.1.3/share/hadoop/hdfs:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/*:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/*:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/lib/*:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/*:/opt/module/hadoop-3.1.3/share/hadoop/yarn:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/*:/opt/module/hadoop-3.1.3/share/hadoop/yarn/*&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>4）配置mapred-site.xml文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到mapred-site.xml文件</span></span><br><span class="line">[atguigu@hadoop102 hadoop]$ sudo vim mapred-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置如下</span></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 指定 MapReduce 程序运行在 Yarn 上 --&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line"> &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.map.env&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h5 id="④在集群上分发配置好的Hadoop配置文件"><a href="#④在集群上分发配置好的Hadoop配置文件" class="headerlink" title="④在集群上分发配置好的Hadoop配置文件"></a>④在集群上分发配置好的Hadoop配置文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 etc]$ xsync hadoop/</span><br><span class="line">============ hadoop102 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 887 bytes  received 18 bytes  603.33 bytes/sec</span><br><span class="line">total size is 107,531  speedup is 118.82</span><br><span class="line">============ hadoop103 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line">hadoop/</span><br><span class="line">hadoop/core-site.xml</span><br><span class="line">hadoop/hdfs-site.xml</span><br><span class="line">hadoop/mapred-site.xml</span><br><span class="line">hadoop/workers</span><br><span class="line">hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 3,310 bytes  received 164 bytes  6,948.00 bytes/sec</span><br><span class="line">total size is 107,531  speedup is 30.95</span><br><span class="line">============ hadoop104 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line">hadoop/</span><br><span class="line">hadoop/capacity-scheduler.xml</span><br><span class="line">hadoop/configuration.xsl</span><br><span class="line">hadoop/container-executor.cfg</span><br><span class="line">hadoop/core-site.xml</span><br><span class="line">hadoop/hadoop-env.cmd</span><br><span class="line">hadoop/hadoop-env.sh</span><br><span class="line">hadoop/hadoop-metrics2.properties</span><br><span class="line">hadoop/hadoop-policy.xml</span><br><span class="line">hadoop/hadoop-user-functions.sh.example</span><br><span class="line">hadoop/hdfs-site.xml</span><br><span class="line">hadoop/httpfs-env.sh</span><br><span class="line">hadoop/httpfs-log4j.properties</span><br><span class="line">hadoop/httpfs-signature.secret</span><br><span class="line">hadoop/httpfs-site.xml</span><br><span class="line">hadoop/kms-acls.xml</span><br><span class="line">hadoop/kms-env.sh</span><br><span class="line">hadoop/kms-log4j.properties</span><br><span class="line">hadoop/kms-site.xml</span><br><span class="line">hadoop/log4j.properties</span><br><span class="line">hadoop/mapred-env.cmd</span><br><span class="line">hadoop/mapred-env.sh</span><br><span class="line">hadoop/mapred-queues.xml.template</span><br><span class="line">hadoop/mapred-site.xml</span><br><span class="line">hadoop/ssl-client.xml.example</span><br><span class="line">hadoop/ssl-server.xml.example</span><br><span class="line">hadoop/user_ec_policies.xml.template</span><br><span class="line">hadoop/workers</span><br><span class="line">hadoop/yarn-env.cmd</span><br><span class="line">hadoop/yarn-env.sh</span><br><span class="line">hadoop/yarn-site.xml</span><br><span class="line">hadoop/yarnservice-log4j.properties</span><br><span class="line">hadoop/shellprofile.d/</span><br><span class="line">hadoop/shellprofile.d/example.sh</span><br><span class="line"></span><br><span class="line">sent 5,002 bytes  received 1,638 bytes  4,426.67 bytes/sec</span><br><span class="line">total size is 107,531  speedup is 16.19</span><br></pre></td></tr></table></figure>

<h5 id="⑤配置workers文件"><a href="#⑤配置workers文件" class="headerlink" title="⑤配置workers文件"></a>⑤配置workers文件</h5><p>主节点服务器NameNode和ResourceManager的角色已经在配置文件中进行了配置，下面配置从节点服务器的角色。配置文件workers主要用于配置Hadoop分布式集群中各个从节点服务器的角色。对workers文件进行配置，将3台服务器全部指定为从节点服务器，启动DataNode和NodeManager进程。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">找到workers文件</span></span><br><span class="line">[atguigu@hadoop102 hadoop]$ sudo vim workers</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">增加以下内容</span></span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发给103和104</span></span><br><span class="line">[atguigu@hadoop102 hadoop]$ xsync workers </span><br><span class="line">============ hadoop102 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 56 bytes  received 12 bytes  45.33 bytes/sec</span><br><span class="line">total size is 30  speedup is 0.44</span><br><span class="line">============ hadoop103 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line">workers</span><br><span class="line"></span><br><span class="line">sent 133 bytes  received 41 bytes  348.00 bytes/sec</span><br><span class="line">total size is 30  speedup is 0.17</span><br><span class="line">============ hadoop104 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line">workers</span><br><span class="line"></span><br><span class="line">sent 133 bytes  received 41 bytes  116.00 bytes/sec</span><br><span class="line">total size is 30  speedup is 0.17</span><br></pre></td></tr></table></figure>

<h5 id="⑥启动集群"><a href="#⑥启动集群" class="headerlink" title="⑥启动集群"></a>⑥启动集群</h5><h6 id="1）在hadoop102节点格式化NameNode"><a href="#1）在hadoop102节点格式化NameNode" class="headerlink" title="1）在hadoop102节点格式化NameNode"></a>1）在hadoop102节点格式化NameNode</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">调整为root用户，否则权限不够</span></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ su root</span><br><span class="line">密码：</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hdfs namenode -format</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到data文件和logs文件</span></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ ll</span><br><span class="line">总用量 176</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 3 root root     17 9月  14 22:01 data  # 新增的文件</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh     288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh  147145 9月   4 2019 LICENSE.txt</span><br><span class="line">drwxr-xr-x. 2 root root     37 9月  14 22:01 logs  # 新增的文件</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh   21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh    1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh    4096 9月  12 2019 sbin</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh      31 9月  12 2019 share</span><br><span class="line">drwxr-xr-x. 2 root root     22 8月   7 10:36 wcinput</span><br><span class="line">drwxr-xr-x. 2 root root     88 8月   7 10:45 wcoutput</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进一步查看data-dfs-name-current-VERSION</span></span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ cd data/</span><br><span class="line">[atguigu@hadoop102 data]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 3 root root 18 9月  14 22:01 dfs</span><br><span class="line">[atguigu@hadoop102 data]$ cd dfs/</span><br><span class="line">[atguigu@hadoop102 dfs]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 3 root root 21 9月  14 22:01 name</span><br><span class="line">[atguigu@hadoop102 dfs]$ cd name/</span><br><span class="line">[atguigu@hadoop102 name]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 2 root root 112 9月  14 22:01 current</span><br><span class="line">[atguigu@hadoop102 name]$ cd current/</span><br><span class="line">[atguigu@hadoop102 current]$ ll</span><br><span class="line">总用量 16</span><br><span class="line">-rw-r--r--. 1 root root 391 9月  14 22:01 fsimage_0000000000000000000</span><br><span class="line">-rw-r--r--. 1 root root  62 9月  14 22:01 fsimage_0000000000000000000.md5</span><br><span class="line">-rw-r--r--. 1 root root   2 9月  14 22:01 seen_txid</span><br><span class="line">-rw-r--r--. 1 root root 220 9月  14 22:01 VERSION</span><br><span class="line">[atguigu@hadoop102 current]$ vim VERSION </span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-14_22-08-06.png" alt="Snipaste_2023-09-14_22-08-06" style="zoom:50%;">

<p>可以查看到服务器的namespaceID</p>
<h6 id="2）启动HDFS"><a href="#2）启动HDFS" class="headerlink" title="2）启动HDFS"></a>2）启动HDFS</h6><p>在格式化NameNode后，执行start-dfs.sh命令启动HDFS，即可同时启动所有的DataNode和SecondaryNameNode</p>
<p>之前要修改如下文件，否则启动失败（在102，103，104上都修改）：</p>
<img src="Snipaste_2023-09-14_22-35-15.png" alt="Snipaste_2023-09-14_22-35-15" style="zoom:43%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">换成root用户</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# sbin/start-dfs.sh</span><br><span class="line">WARNING: HADOOP_SECURE_DN_USER has been replaced by HDFS_DATANODE_SECURE_USER. Using value of HADOOP_SECURE_DN_USER.</span><br><span class="line">Starting namenodes on [hadoop102]</span><br><span class="line">上一次登录：四 9月 14 22:30:10 CST 2023pts/0 上</span><br><span class="line">Starting datanodes</span><br><span class="line">上一次登录：四 9月 14 22:32:59 CST 2023pts/0 上</span><br><span class="line">Starting secondary namenodes [hadoop104]</span><br><span class="line">上一次登录：四 9月 14 22:33:01 CST 2023pts/0 上</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">13140 DataNode</span><br><span class="line">13476 Jps</span><br><span class="line">12959 NameNode</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">8524 DataNode</span><br><span class="line">9052 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">8118 SecondaryNameNode</span><br><span class="line">8921 Jps</span><br><span class="line">8013 DataNode</span><br></pre></td></tr></table></figure>

<p>可以看到所有服务器的HDFS都成功启动：</p>
<img src="Snipaste_2023-09-14_22-36-43.png" alt="Snipaste_2023-09-14_22-36-43" style="zoom:43%;">

<p>（亲尝：此时关机后HDFS会关闭，再次 [root用户下]cd &#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;———-&gt;sbin&#x2F;start-dfs.sh———-&gt;xcall.sh jps 即可启动三台服务器的HDFS并查看启动情况，YARN同理）</p>
<h6 id="3）启动YARN"><a href="#3）启动YARN" class="headerlink" title="3）启动YARN"></a>3）启动YARN</h6><p>通过执行start-yarn.sh命令启动YARN，可以同时启动ResourceManager和所有NodeManager，需要注意，因为NameNode和ResourceManager不在同一个服务器节点上，所以<strong>必须在hadoop103上启动YARN（即在ResourceManager所在的节点上）</strong>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 hadoop-3.1.3]# sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">之后我们在102上查看所有节点服务器的进程情况，可以发现与最初规划的表格内容一致</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">2900 NameNode</span><br><span class="line">3086 DataNode</span><br><span class="line">4158 Jps</span><br><span class="line">3999 NodeManager</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">2723 DataNode</span><br><span class="line">4595 NodeManager</span><br><span class="line">4822 Jps</span><br><span class="line">3325 ResourceManager</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">2849 SecondaryNameNode</span><br><span class="line">2723 DataNode</span><br><span class="line">3619 NodeManager</span><br><span class="line">3783 Jps</span><br></pre></td></tr></table></figure>

<h6 id="4）NameNode的Web端"><a href="#4）NameNode的Web端" class="headerlink" title="4）NameNode的Web端"></a>4）NameNode的Web端</h6><p>输入”<a target="_blank" rel="noopener" href="http://hadoop102:9870/">http://hadoop102:9870</a>“</p>
<img src="Snipaste_2023-09-15_11-10-08.png" alt="Snipaste_2023-09-15_11-10-08" style="zoom: 33%;">

<h6 id="5）YARN的Web端"><a href="#5）YARN的Web端" class="headerlink" title="5）YARN的Web端"></a>5）YARN的Web端</h6><p>输入”<a target="_blank" rel="noopener" href="http://hadoop103:8088/">http://hadoop103:8088</a>“</p>
<img src="Snipaste_2023-09-15_11-13-41.png" alt="Snipaste_2023-09-15_11-13-41" style="zoom: 33%;">

<h5 id="⑦集群基本测试"><a href="#⑦集群基本测试" class="headerlink" title="⑦集群基本测试"></a>⑦集群基本测试</h5><p>测试Hadoop的基本功能：数据存储和数据计算，测试主要围绕文件上传、文件下载和简单计算三方面展开</p>
<h6 id="1）文件上传测试"><a href="#1）文件上传测试" class="headerlink" title="1）文件上传测试"></a>1）文件上传测试</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">小文件上传</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在hadoop集群中的根目录下创建一个文件夹input，这里涉及到了Hadoop的shell命令，后续介绍</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -mkdir /input</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以看到在Web端监视到了我们在集群中创建的文件夹input</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-15_11-23-16.png" alt="Snipaste_2023-09-15_11-23-16" style="zoom:43%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再将服务器本地的word.txt文件上传至集群的input文件夹中</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -put wcinput/word.txt /input</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在Web端根目录下的input文件夹下我们看到了文件word.txt</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-15_11-28-33.png" alt="Snipaste_2023-09-15_11-28-33" style="zoom:33%;">

<p>点击即可查看文件内容，也可以下载</p>
<img src="Snipaste_2023-09-15_11-30-37.png" alt="Snipaste_2023-09-15_11-30-37" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">大文件上传测试，上传JDK安装包到Hadoop的根目录下</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -put wcinput/word.txt /input</span><br></pre></td></tr></table></figure>

<p>可以查看到</p>
<img src="Snipaste_2023-09-15_11-34-32.png" alt="Snipaste_2023-09-15_11-34-32" style="zoom: 50%;">

<hr>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上传文件的存储位置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行以下命令，进入HDFS文件的存储路径，查看路径下的文件列表</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">其中blk_************文件就是存储于Hadoop中的数据块文件（文件在HDFS中是分块存储的）</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# cd /opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1662165003-192.168.255.102-1694700063570/current/finalized/subdir0/subdir0/</span><br><span class="line">[root@hadoop102 subdir0]# ll</span><br><span class="line">总用量 191944</span><br><span class="line">-rw-r--r--. 1 root root        97 9月  15 11:27 blk_1073741825</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 11:27 blk_1073741825_1001.meta</span><br><span class="line">-rw-r--r--. 1 root root 134217728 9月  15 11:33 blk_1073741826</span><br><span class="line">-rw-r--r--. 1 root root   1048583 9月  15 11:33 blk_1073741826_1002.meta</span><br><span class="line">-rw-r--r--. 1 root root  60795424 9月  15 11:33 blk_1073741827</span><br><span class="line">-rw-r--r--. 1 root root    474975 9月  15 11:33 blk_1073741827_1003.meta</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用<span class="built_in">cat</span>命令可以查看HDFS在磁盘中存储的文件内容，较小的数据块blk_1073741825即之前上传的word.txt文件</span></span><br><span class="line">[root@hadoop102 subdir0]# cat blk_1073741825</span><br><span class="line">hadoop HDFS</span><br><span class="line">hadoop mapreduce</span><br><span class="line">hadoop yarn</span><br><span class="line">spark core</span><br><span class="line">spark MLlib</span><br><span class="line">spark RDD</span><br><span class="line">flink core</span><br><span class="line">flink alink</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我们还可以看到两块较大的数据块blk_1073741826和blk_1073741827，即之前上传的JDK安装包，由于JDK安装包体积较大，因此HDFS将其切分成了两个数据块进行存储（何种标准切分，后续介绍）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将数据块blk_1073741826和blk_1073741827重新拼接成一个压缩包，并将拼接的压缩包解压缩，即可得到原来的JDK安装包</span></span><br><span class="line">[root@hadoop102 subdir0]# cat blk_1073741826&gt;&gt;tmp.tar.gz</span><br><span class="line">[root@hadoop102 subdir0]# cat blk_1073741827&gt;&gt;tmp.tar.gz</span><br><span class="line">[root@hadoop102 subdir0]# ll</span><br><span class="line">总用量 585160</span><br><span class="line">-rw-r--r--. 1 root root        97 9月  15 11:27 blk_1073741825</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 11:27 blk_1073741825_1001.meta</span><br><span class="line">-rw-r--r--. 1 root root 134217728 9月  15 11:33 blk_1073741826</span><br><span class="line">-rw-r--r--. 1 root root   1048583 9月  15 11:33 blk_1073741826_1002.meta</span><br><span class="line">-rw-r--r--. 1 root root  60795424 9月  15 11:33 blk_1073741827</span><br><span class="line">-rw-r--r--. 1 root root    474975 9月  15 11:33 blk_1073741827_1003.meta</span><br><span class="line">-rw-r--r--. 1 root root 195013152 9月  15 17:25 tmp.tar.gz  # 可以看到tmp.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将tmp.tar.gz解压缩</span></span><br><span class="line">[root@hadoop102 subdir0]# tar -zxvf tmp.tar.gz</span><br><span class="line">......</span><br><span class="line">[root@hadoop102 subdir0]# ll</span><br><span class="line">总用量 585160</span><br><span class="line">-rw-r--r--. 1 root root        97 9月  15 11:27 blk_1073741825</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 11:27 blk_1073741825_1001.meta</span><br><span class="line">-rw-r--r--. 1 root root 134217728 9月  15 11:33 blk_1073741826</span><br><span class="line">-rw-r--r--. 1 root root   1048583 9月  15 11:33 blk_1073741826_1002.meta</span><br><span class="line">-rw-r--r--. 1 root root  60795424 9月  15 11:33 blk_1073741827</span><br><span class="line">-rw-r--r--. 1 root root    474975 9月  15 11:33 blk_1073741827_1003.meta</span><br><span class="line">drwxr-xr-x. 7   10  143       245 4月   2 2019 jdk1.8.0_212 # 解压出一个jdk</span><br><span class="line">-rw-r--r--. 1 root root 195013152 9月  15 17:25 tmp.tar.gz</span><br></pre></td></tr></table></figure>

<h6 id="2）文件下载测试"><a href="#2）文件下载测试" class="headerlink" title="2）文件下载测试"></a>2）文件下载测试</h6><p>可以直接在Web端操作下载</p>
<h6 id="3）简单计算测试"><a href="#3）简单计算测试" class="headerlink" title="3）简单计算测试"></a>3）简单计算测试</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行官方提供的示例程序jar包中的WordCount程序</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output</span><br></pre></td></tr></table></figure>

<p>从YARN的Web端可以看到任务执行成功</p>
<p><img src="Snipaste_2023-09-15_18-29-51.png" alt="Snipaste_2023-09-15_18-29-51"></p>
<p>从NameNode的Web端可以看到output文件夹</p>
<img src="Snipaste_2023-09-15_18-31-15.png" alt="Snipaste_2023-09-15_18-31-15" style="zoom:33%;">

<p>点击output文件夹可以看到结果：</p>
<img src="Snipaste_2023-09-15_18-34-16.png" alt="Snipaste_2023-09-15_18-34-16" style="zoom:33%;">

<p>当然，点击文件后面的垃圾桶按钮可以将其删除，已经设置好了root用户权限</p>
<h4 id="3-2-5-NameNode格式化问题（集群挂了如何解决）"><a href="#3-2-5-NameNode格式化问题（集群挂了如何解决）" class="headerlink" title="3.2.5 NameNode格式化问题（集群挂了如何解决）"></a>3.2.5 NameNode格式化问题（集群挂了如何解决）</h4><p>参考书，这里面不做演示</p>
<h4 id="3-2-6-配置历史服务器"><a href="#3-2-6-配置历史服务器" class="headerlink" title="3.2.6 配置历史服务器"></a>3.2.6 配置历史服务器</h4><p>在Hadoop集群上执行完一个计算任务后，所有的运行信息和相关日志都会被清除，用户无法回溯查看历史任务的运行情况。为此，我们需要配置历史服务器。配置历史服务器可以在任意一个节点服务器上，我们选择102。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤1：打开配置文件mapred-site.xml,添加以下配置</span></span><br><span class="line">[root@hadoop102 hadoop]# vim mapred-site.xml</span><br><span class="line">&lt;!-- 历史服务器端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;hadoop102:10020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 历史服务器 web 端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;hadoop102:19888&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤2：分发配置文件至其他节点服务器中</span></span><br><span class="line">[root@hadoop102 hadoop]# xsync mapred-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤3：在102节点上启动历史服务器</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# bin/mapred --daemon start historyserver</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤4：查看102节点的历史服务器是否启动</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# jps</span><br><span class="line">9681 NameNode</span><br><span class="line">13649 Jps</span><br><span class="line">9867 DataNode</span><br><span class="line">10445 NodeManager</span><br><span class="line">13534 JobHistoryServer</span><br></pre></td></tr></table></figure>

<p>最后，登录历史服务器Web端（”<a target="_blank" rel="noopener" href="http://hadoop102:19888/jobhistory%22%EF%BC%89">http://hadoop102:19888/jobhistory&quot;）</a></p>
<p><img src="Snipaste_2023-09-15_19-35-15.png" alt="Snipaste_2023-09-15_19-35-15"></p>
<p><img src="Snipaste_2023-09-15_19-37-55.png" alt="Snipaste_2023-09-15_19-37-55"></p>
<p>参数：</p>
<p><img src="Snipaste_2023-09-15_19-38-39.png" alt="Snipaste_2023-09-15_19-38-39"></p>
<h4 id="3-2-7-配置日志聚集功能"><a href="#3-2-7-配置日志聚集功能" class="headerlink" title="3.2.7 配置日志聚集功能"></a>3.2.7 配置日志聚集功能</h4><p>在程序运行完毕后，运行程序的节点服务器上会产生一些本地的日志文件。为了方便查看程序运行情况，进行程序调试，可以在程序运行完毕后，将程序运行的日志信息上传至HDFS中。</p>
<img src="Snipaste_2023-09-15_19-42-31.png" alt="Snipaste_2023-09-15_19-42-31" style="zoom:50%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤1：配置yarn-site.xml</span></span><br><span class="line">[root@hadoop102 hadoop]# vim yarn-site.xml</span><br><span class="line">&lt;!-- 开启日志聚集功能 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 设置日志聚集服务器地址 --&gt;</span><br><span class="line">&lt;property&gt; </span><br><span class="line"> &lt;name&gt;yarn.log.server.url&lt;/name&gt; </span><br><span class="line"> &lt;value&gt;http://hadoop102:19888/jobhistory/logs&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 设置日志保留时间为 7 天 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤2：分发配置文件</span></span><br><span class="line">[root@hadoop102 hadoop]# xsync yarn-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤3：关闭NodeManager，ResourceManager和HistoryServer进程</span></span><br><span class="line">[root@hadoop103 hadoop-3.1.3]# sbin/stop-yarn.sh              # 注意是103</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# mapred --daemon stop historyserver </span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤4：启动NodeManager，ResourceManager和HistoryServer进程</span></span><br><span class="line">[root@hadoop103 hadoop-3.1.3]# sbin/start-yarn.sh            # 注意是103</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# mapred --daemon start historyserver</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">成功</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">14448 JobHistoryServer</span><br><span class="line">9681 NameNode</span><br><span class="line">14529 Jps</span><br><span class="line">9867 DataNode</span><br><span class="line">14255 NodeManager</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">7265 DataNode</span><br><span class="line">10483 Jps</span><br><span class="line">9910 ResourceManager</span><br><span class="line">10251 NodeManager</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">6887 DataNode</span><br><span class="line">7003 SecondaryNameNode</span><br><span class="line">9438 Jps</span><br><span class="line">9279 NodeManager</span><br></pre></td></tr></table></figure>

<p>那么后续执行的程序就会有logs记录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重新运行WordCount程序，将输出文件夹改为/output2</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcountt /input /output2</span><br></pre></td></tr></table></figure>

<p>查看日志：</p>
<p>登录历史服务器Web端（”<a target="_blank" rel="noopener" href="http://hadoop102:19888/jobhistory%22%EF%BC%89%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E4%B8%A4%E6%9D%A1%E4%BB%BB%E5%8A%A1%E5%88%97%E8%A1%A8%EF%BC%8C%E7%82%B9%E5%87%BB%E7%AC%AC%E4%B8%80%E8%A1%8C%E7%9A%84Job">http://hadoop102:19888/jobhistory&quot;）可以看到两条任务列表，点击第一行的Job</a> ID</p>
<p><img src="Snipaste_2023-09-15_20-13-29.png" alt="Snipaste_2023-09-15_20-13-29"></p>
<p>再点击logs超链接，可以查看历史任务的运行日志</p>
<p><img src="Snipaste_2023-09-15_20-14-55.png" alt="Snipaste_2023-09-15_20-14-55"></p>
<h4 id="3-2-8-集群启动-x2F-停止方式总结"><a href="#3-2-8-集群启动-x2F-停止方式总结" class="headerlink" title="3.2.8 集群启动&#x2F;停止方式总结"></a>3.2.8 集群启动&#x2F;停止方式总结</h4><p>1）各个模块分开启动&#x2F;停止（配置ssh是前提）【常用】</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">整体启动/停止HDFS</span></span><br><span class="line">start-dfs.sh/stop-dfs.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">整体启动/停止YARN</span></span><br><span class="line">start-yarn.sh/stop-yarn.sh</span><br></pre></td></tr></table></figure>

<p>2）各个服务组件逐一启动&#x2F;停止</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分别启动/停止HDFS组件</span></span><br><span class="line">hdfs --daemon start/stop namenode/datanode/secondarynamenode</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动/停止YARN</span></span><br><span class="line">yarn --daemon start/stop resourcemanager/nodemanager</span><br></pre></td></tr></table></figure>

<h4 id="3-2-9-Hadoop集群启停脚本"><a href="#3-2-9-Hadoop集群启停脚本" class="headerlink" title="3.2.9 Hadoop集群启停脚本"></a>3.2.9 Hadoop集群启停脚本</h4><p>想要完整地启动Hadoop集群，需要执行多个启动命令，分别启动HDFS，YARN和HistoryServer等相关进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# sbin/start-dfs.sh</span><br><span class="line">[root@hadoop103 hadoop-3.1.3]# sbin/start-yarn.sh</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# bin/mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>

<p>现在我们编写一个脚本，用于一次性执行以上命令，从而快速启动和关闭Hadoop集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤1：在root的bin目录下创建脚本文件myhadoop.sh</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# cd /bin</span><br><span class="line">[root@hadoop102 bin]# vim myhadoop.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line"> 	echo &quot;No Args Input...&quot;</span><br><span class="line"> 	exit ;</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line"> 		echo &quot; =================== 启动 hadoop 集群 ===================&quot;</span><br><span class="line"> 		echo &quot; --------------- 启动 hdfs ---------------&quot;</span><br><span class="line"> 		ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh&quot;</span><br><span class="line"> 		echo &quot; --------------- 启动 yarn ---------------&quot;</span><br><span class="line"> 		ssh hadoop103 &quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;</span><br><span class="line"> 		echo &quot; --------------- 启动 historyserver ---------------&quot;</span><br><span class="line"> 		ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line"> 		echo &quot; =================== 关闭 hadoop 集群 ===================&quot;</span><br><span class="line"> 		echo &quot; --------------- 关闭 historyserver ---------------&quot;</span><br><span class="line"> 		ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver&quot;</span><br><span class="line"> 		echo &quot; --------------- 关闭 yarn ---------------&quot;</span><br><span class="line"> 		ssh hadoop103 &quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot;</span><br><span class="line"> 		echo &quot; --------------- 关闭 hdfs ---------------&quot;</span><br><span class="line"> 		ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line"> 	echo &quot;Input Args Error...&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">步骤2：赋予脚本执行权限</span></span><br><span class="line">[root@hadoop102 bin]# chmod 777 myhadoop.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用myhadoop.sh脚本，关闭hadoop集群</span></span><br><span class="line">[root@hadoop102 bin]# myhadoop.sh stop</span><br><span class="line">[root@hadoop102 bin]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">15833 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">11509 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">10509 Jps</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用myhadoop.sh脚本，开启hadoop集群</span></span><br><span class="line">[root@hadoop102 bin]# myhadoop.sh start</span><br><span class="line">[root@hadoop102 bin]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">16051 NameNode</span><br><span class="line">16564 NodeManager</span><br><span class="line">16231 DataNode</span><br><span class="line">16823 Jps</span><br><span class="line">16750 JobHistoryServer</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">12144 NodeManager</span><br><span class="line">11810 ResourceManager</span><br><span class="line">12338 Jps</span><br><span class="line">11591 DataNode</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">10708 SecondaryNameNode</span><br><span class="line">10939 Jps</span><br><span class="line">10798 NodeManager</span><br><span class="line">10591 DataNode</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发脚本，保证脚本在所有节点服务器都可以使用</span></span><br><span class="line">[root@hadoop102 bin]# xsync myhadoop.sh</span><br></pre></td></tr></table></figure>

<p>这样每次开机之后只需要执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# myhadoop.sh start</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看集群运行情况</span></span><br><span class="line">[root@hadoop102 bin]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">2881 NameNode</span><br><span class="line">3666 Jps</span><br><span class="line">3065 DataNode</span><br><span class="line">3593 JobHistoryServer</span><br><span class="line">3404 NodeManager</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">2752 DataNode</span><br><span class="line">2978 ResourceManager</span><br><span class="line">3508 Jps</span><br><span class="line">3135 NodeManager</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">2976 NodeManager</span><br><span class="line">2883 SecondaryNameNode</span><br><span class="line">2761 DataNode</span><br><span class="line">3116 Jps</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这样就可以方便快捷地启动集群啦</span></span><br></pre></td></tr></table></figure>

<h4 id="3-2-10-常用端口号和常用配置文件（两道面试题）"><a href="#3-2-10-常用端口号和常用配置文件（两道面试题）" class="headerlink" title="3.2.10 常用端口号和常用配置文件（两道面试题）"></a>3.2.10 常用端口号和常用配置文件（两道面试题）</h4><img src="Snipaste_2023-09-15_21-10-19.png" alt="Snipaste_2023-09-15_21-10-19" style="zoom:50%;">

<p>3.x : core-site.xml，hdfs-site.xml，yarn-site.xml，mapred-site.xml，workers</p>
<p>2.x：core-site.xml，hdfs-site.xml，yarn-site.xml，mapred-site.xml，slaves</p>
<h4 id="3-2-11-关于HDFS文件分块存储的概述"><a href="#3-2-11-关于HDFS文件分块存储的概述" class="headerlink" title="3.2.11 关于HDFS文件分块存储的概述"></a>3.2.11 关于HDFS文件分块存储的概述</h4><p>首先来看一下小文件word.txt，它的Block Size为128MB，实际大小为97B，所以没有分块</p>
<p><img src="Snipaste_2023-09-17_14-28-08.png" alt="Snipaste_2023-09-17_14-28-08"></p>
<img src="Snipaste_2023-09-17_14-30-31.png" alt="Snipaste_2023-09-17_14-30-31" style="zoom: 50%;">

<p>再看一下大文件，它的Block Size为128MB，实际大小185.98MB，分成了两块</p>
<p><img src="Snipaste_2023-09-17_14-39-46.png" alt="Snipaste_2023-09-17_14-39-46"></p>
<img src="Snipaste_2023-09-17_14-41-29.png" alt="Snipaste_2023-09-17_14-41-29" style="zoom: 50%;">

<h2 id="第四章-分布式文件系统HDFS"><a href="#第四章-分布式文件系统HDFS" class="headerlink" title="第四章 分布式文件系统HDFS"></a>第四章 分布式文件系统HDFS</h2><p>HDFS是Hadoop提供的分布式文件系统，使用HDFS可以在廉价的硬件设备上构建一套稳健的、可扩展的文件存储系统。</p>
<h3 id="4-1-HDFS概述"><a href="#4-1-HDFS概述" class="headerlink" title="4.1 HDFS概述"></a>4.1 HDFS概述</h3><h4 id="4-1-1-HGFS背景及意义"><a href="#4-1-1-HGFS背景及意义" class="headerlink" title="4.1.1 HGFS背景及意义"></a>4.1.1 HGFS背景及意义</h4><p>HDFS（Hadoop Distributed File System，Hadoop分布式文件系统）主要用于存储文件，通过<strong>目录树</strong>定位文件，HDFS的底层是<strong>分布式</strong>的，由多台服务器联合起来对外提供文件存储服务。</p>
<p>HDFS通常在<strong>一次写入，多次读取</strong>的场景使用。数据长期存储于HDFS中，用于进行分析计算。一个文件经过创建，写入和关闭之后就不需要改变了。对海量数据集进行分析计算的特别之处在于，每次计算的着眼点都是数据集的<strong>整体</strong>，而不是某条数据，因此读取数据集中第一条记录的延迟并不重要，重要的是获取整体数据集的延迟。</p>
<p><strong>HDFS的优点</strong>：</p>
<ul>
<li><strong>高容错性</strong>。HDFS以多副本的形式提供容错性。数据文件在被上传后，可以自动存储为多个副本，在其中一个副本丢失后，可以通过其他副本自动恢复</li>
<li><strong>适合处理大数据</strong>。<ul>
<li>数据规模：能够处理GB、TB、PB级别的数据</li>
<li>文件规模：能够处理百万规模以上的文件数量</li>
</ul>
</li>
<li><strong>Hadoop可以构建在廉价机器上</strong>。通过副本机制，提高可靠性</li>
</ul>
<p><strong>HDFS的缺点</strong>：</p>
<ul>
<li><strong>不适合低时间延迟的数据访问</strong>。毫秒级别的数据存储做不到。HDFS是为高数据量、高吞吐的数据应用程序设计的，而这些应用必然会以提高时间延迟为代价。</li>
<li><strong>无法高效存储大量小文件</strong>。<ul>
<li>HDFS会将文件的元数据（文件目录和块信息）存储在NameNode中，所以其文件存储量是受限于NameNode的内存量的。如果集群中存储了大量的小文件，则会对HDFS的存储能力造成极大损害。</li>
<li>小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。</li>
</ul>
</li>
<li><strong>文件不支持并发写入操作，不允许多个线程同时写文件</strong>。文件只能同时由一个写入者写入，不允许多个线程同时写文件。对于一个文件的写入操作，要以“仅添加”的模式在文件末尾写入数据，不支持在文件的任意位置进行修改。</li>
</ul>
<h4 id="4-1-2-HDFS的基本架构"><a href="#4-1-2-HDFS的基本架构" class="headerlink" title="4.1.2 HDFS的基本架构"></a>4.1.2 HDFS的基本架构</h4><p><img src="Snipaste_2023-09-17_15-51-45.png" alt="Snipaste_2023-09-17_15-51-45"></p>
<p><img src="Snipaste_2023-09-17_15-52-06.png" alt="Snipaste_2023-09-17_15-52-06"></p>
<h4 id="4-1-3-HDFS文件块大小（面试重点）"><a href="#4-1-3-HDFS文件块大小（面试重点）" class="headerlink" title="4.1.3 HDFS文件块大小（面试重点）"></a>4.1.3 HDFS文件块大小（面试重点）</h4><p><img src="Snipaste_2023-09-17_16-46-42.png" alt="Snipaste_2023-09-17_16-46-42"></p>
<p><img src="Snipaste_2023-09-17_16-47-10.png" alt="Snipaste_2023-09-17_16-47-10"></p>
<p><strong>另一种答案</strong>：</p>
<ul>
<li>如果数据块太小，那么一个大文件会被切分成<strong>过多个</strong>数据块，从而增加整个大文件的寻址时间，也会生成过多的<strong>元数据信息</strong>，对NameNode造成更大的存储负担。</li>
<li>如果数据块太大，那么虽然可以降低整个文件的寻址时间占比，但是磁盘传输数据的时间占比会大幅提高。</li>
</ul>
<h4 id="4-1-4-HDFS的特性"><a href="#4-1-4-HDFS的特性" class="headerlink" title="4.1.4 HDFS的特性"></a>4.1.4 HDFS的特性</h4><p>首先，它是一个文件系统，用于存储文件，通过统一的命名空间目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能。</p>
<p>①主从架构</p>
<p>HDFS采用<strong>主从</strong>架构，一般一个HDFS集群由<strong>一个NameNode</strong>和<strong>一定数目的DataNode</strong>组成。NameNode是HDFS集群的主节点，DataNode是HDFS集群的从节点。</p>
<p>②分块存储</p>
<p>HDFS中的文件在物理上是分块（block）存储的，块的大小可以通过配置参数来决定，默认128MB</p>
<p>③名字空间</p>
<p>NameNode负责维护文件系统的名字空间</p>
<h3 id="4-2-HDFS的shell操作（开发重点）"><a href="#4-2-HDFS的shell操作（开发重点）" class="headerlink" title="4.2 HDFS的shell操作（开发重点）"></a>4.2 HDFS的shell操作（开发重点）</h3><p>Hadoop为内部的文件系统提供了多种访问接口，包括Web端页面访问接口，shell命令行访问接口，JavaAPI访问接口等等。</p>
<p>基本语法:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs 具体命令  OR  hdfs dfs 具体命令</span><br></pre></td></tr></table></figure>

<h4 id="4-2-1-命令大全"><a href="#4-2-1-命令大全" class="headerlink" title="4.2.1 命令大全"></a>4.2.1 命令大全</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs </span><br><span class="line">Usage: hadoop fs [generic options]</span><br><span class="line">	[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-checksum &lt;src&gt; ...]</span><br><span class="line">	[-chgrp [-R] GROUP PATH...]</span><br><span class="line">	[-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">	[-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">	[-copyFromLocal [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-count [-q] [-h] [-v] [-t [&lt;storage type&gt;]] [-u] [-x] [-e] &lt;path&gt; ...]</span><br><span class="line">	[-cp [-f] [-p | -p[topax]] [-d] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span><br><span class="line">	[-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span><br><span class="line">	[-df [-h] [&lt;path&gt; ...]]</span><br><span class="line">	[-du [-s] [-h] [-v] [-x] &lt;path&gt; ...]</span><br><span class="line">	[-expunge]</span><br><span class="line">	[-find &lt;path&gt; ... &lt;expression&gt; ...]</span><br><span class="line">	[-get [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-getfacl [-R] &lt;path&gt;]</span><br><span class="line">	[-getfattr [-R] &#123;-n name | -d&#125; [-e en] &lt;path&gt;]</span><br><span class="line">	[-getmerge [-nl] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-head &lt;file&gt;]</span><br><span class="line">	[-help [cmd ...]]</span><br><span class="line">	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [&lt;path&gt; ...]]</span><br><span class="line">	[-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line">	[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-put [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span><br><span class="line">	[-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]</span><br><span class="line">	[-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span><br><span class="line">	[-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line">	[-setfattr &#123;-n name [-v value] | -x name&#125; &lt;path&gt;]</span><br><span class="line">	[-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span><br><span class="line">	[-stat [format] &lt;path&gt; ...]</span><br><span class="line">	[-tail [-f] [-s &lt;sleep interval&gt;] &lt;file&gt;]</span><br><span class="line">	[-test -[defsz] &lt;path&gt;]</span><br><span class="line">	[-text [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] &lt;path&gt; ...]</span><br><span class="line">	[-touchz &lt;path&gt; ...]</span><br><span class="line">	[-truncate [-w] &lt;length&gt; &lt;path&gt; ...]</span><br><span class="line">	[-usage [cmd ...]]</span><br><span class="line"></span><br><span class="line">Generic options supported are:</span><br><span class="line">-conf &lt;configuration file&gt;        specify an application configuration file</span><br><span class="line">-D &lt;property=value&gt;               define a value for a given property</span><br><span class="line">-fs &lt;file:///|hdfs://namenode:port&gt; specify default filesystem URL to use, overrides &#x27;fs.defaultFS&#x27; property from configurations.</span><br><span class="line">-jt &lt;local|resourcemanager:port&gt;  specify a ResourceManager</span><br><span class="line">-files &lt;file1,...&gt;                specify a comma-separated list of files to be copied to the map reduce cluster</span><br><span class="line">-libjars &lt;jar1,...&gt;               specify a comma-separated list of jar files to be included in the classpath</span><br><span class="line">-archives &lt;archive1,...&gt;          specify a comma-separated list of archives to be unarchived on the compute machines</span><br><span class="line"></span><br><span class="line">The general command line syntax is:</span><br><span class="line">command [genericOptions] [commandOptions]</span><br></pre></td></tr></table></figure>

<h4 id="4-2-2-命令行命令实操"><a href="#4-2-2-命令行命令实操" class="headerlink" title="4.2.2 命令行命令实操"></a>4.2.2 命令行命令实操</h4><h5 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1.准备工作"></a>1.准备工作</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（1）启动Hadoop集群</span></span><br><span class="line">[root@hadoop102 bin]# myhadoop.sh start</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看集群运行情况</span></span><br><span class="line">[root@hadoop102 bin]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">2881 NameNode</span><br><span class="line">3666 Jps</span><br><span class="line">3065 DataNode</span><br><span class="line">3593 JobHistoryServer</span><br><span class="line">3404 NodeManager</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">2752 DataNode</span><br><span class="line">2978 ResourceManager</span><br><span class="line">3508 Jps</span><br><span class="line">3135 NodeManager</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">2976 NodeManager</span><br><span class="line">2883 SecondaryNameNode</span><br><span class="line">2761 DataNode</span><br><span class="line">3116 Jps</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（2）使用-<span class="built_in">help</span>命令可以输出所查询命令的具体参数，比如<span class="built_in">rm</span>命令</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -help rm</span><br><span class="line">-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ... :</span><br><span class="line">  Delete all files that match the specified file pattern. Equivalent to the Unix</span><br><span class="line">  command &quot;rm &lt;src&gt;&quot;</span><br><span class="line">                                                                                 </span><br><span class="line">  -f          If the file does not exist, do not display a diagnostic message or </span><br><span class="line">              modify the exit status to reflect an error.                        </span><br><span class="line">  -[rR]       Recursively deletes directories.                                   </span><br><span class="line">  -skipTrash  option bypasses trash, if enabled, and immediately deletes &lt;src&gt;.  </span><br><span class="line">  -safely     option requires safety confirmation, if enabled, requires          </span><br><span class="line">              confirmation before deleting large directory with more than        </span><br><span class="line">              &lt;hadoop.shell.delete.limit.num.files&gt; files. Delay is expected when</span><br><span class="line">              walking over large directory recursively to count the number of    </span><br><span class="line">              files to be deleted before the confirmation.</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（3）在HDFS的根目录下创建测试文件夹/sanguo</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -mkdir /sanguo</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-17_20-14-14.png" alt="Snipaste_2023-09-17_20-14-14" style="zoom: 33%;">

<h5 id="2-上传"><a href="#2-上传" class="headerlink" title="2. 上传"></a>2. 上传</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">(1)-moveFromLocal命令：主要用于将文件从本地文件系统剪切到HDFS中</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建文件shuguo.txt，并且编写该文件中的内容（所有命令默认在/opt/module/hadoop3.1.3下执行）</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# vim shuguo.txt</span><br><span class="line">shuguo</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# ll</span><br><span class="line">总用量 184</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 4 root root     37 9月  15 11:02 data</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh     288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh  147145 9月   4 2019 LICENSE.txt</span><br><span class="line">drwxrwxrwx. 3 root root   4096 9月  17 14:13 logs</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh   21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh    1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh    4096 9月  14 22:32 sbin</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh      31 9月  12 2019 share</span><br><span class="line">-rw-r--r--. 1 root root      7 9月  17 20:22 shuguo.txt  # 文件在这里</span><br><span class="line">drwxr-xr-x. 2 root root     22 8月   7 10:36 wcinput</span><br><span class="line">drwxr-xr-x. 2 root root     88 8月   7 10:45 wcoutput</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行-moveFromLocal命令，将shuguo.txt文件上传至/sanguo路径下</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -moveFromLocal ./shuguo.txt  /sanguo</span><br><span class="line">2023-09-17 20:26:42,789 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看文件夹中已经没有shuguo.txt了，证明被剪切走了</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# ll</span><br><span class="line">总用量 180</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 4 root root     37 9月  15 11:02 data</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh     288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh  147145 9月   4 2019 LICENSE.txt</span><br><span class="line">drwxrwxrwx. 3 root root   4096 9月  17 14:13 logs</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh   21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh    1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh    4096 9月  14 22:32 sbin</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh      31 9月  12 2019 share</span><br><span class="line">drwxr-xr-x. 2 root root     22 8月   7 10:36 wcinput</span><br><span class="line">drwxr-xr-x. 2 root root     88 8月   7 10:45 wcoutput</span><br></pre></td></tr></table></figure>

<p>在Web端可以看到已经成功剪切到了HDFS文件中：</p>
<img src="Snipaste_2023-09-17_20-28-33.png" alt="Snipaste_2023-09-17_20-28-33" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（2）-copyFromLocal命令：主要用于从本地文件系统中上传（拷贝）文件到HDFS中</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# vim weiguo.txt</span><br><span class="line">weiguo</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -copyFromLocal weiguo.txt /sanguo</span><br><span class="line">2023-09-17 20:34:23,142 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-17_20-35-08.png" alt="Snipaste_2023-09-17_20-35-08" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（3）-put：等同于copyFromLocal,生产环境更常用</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# vim wuguo.txt</span><br><span class="line">wuguo</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -put ./wuguo.txt /sanguo</span><br><span class="line">2023-09-17 20:43:57,251 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-17_20-44-17.png" alt="Snipaste_2023-09-17_20-44-17" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（4）-appendToFile命令：主要用于将一个文件追加到已经存在的文件的末尾</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# vim liubei.txt</span><br><span class="line">liubei</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -appendToFile liubei.txt /sanguo/shuguo.txt</span><br><span class="line">2023-09-17 21:06:40,345 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-17_21-07-12.png" alt="Snipaste_2023-09-17_21-07-12" style="zoom:33%;">

<h5 id="3-下载"><a href="#3-下载" class="headerlink" title="3. 下载"></a>3. 下载</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（1）-copyToLocal命令：主要用于将文件从HDFS中下载（拷贝）到本地文件系统中</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -copyToLocal /sanguo/shuguo.txt ./</span><br><span class="line">2023-09-17 21:10:29,498 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# ll</span><br><span class="line">总用量 196</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 4 root root     37 9月  15 11:02 data</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh     288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh  147145 9月   4 2019 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1 root root      7 9月  17 21:04 liubei.txt</span><br><span class="line">drwxrwxrwx. 3 root root   4096 9月  17 14:13 logs</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh   21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh    1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh    4096 9月  14 22:32 sbin</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh      31 9月  12 2019 share</span><br><span class="line">-rw-r--r--. 1 root root     14 9月  17 21:10 shuguo.txt # 文件在这里</span><br><span class="line">drwxr-xr-x. 2 root root     22 8月   7 10:36 wcinput</span><br><span class="line">drwxr-xr-x. 2 root root     88 8月   7 10:45 wcoutput</span><br><span class="line">-rw-r--r--. 1 root root      7 9月  17 20:31 weiguo.txt</span><br><span class="line">-rw-r--r--. 1 root root      6 9月  17 20:42 wuguo.txt</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（2）-get命令：与-copyToLocal功能相同，在生产环境中，-get命令更常用</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -get /sanguo/shuguo.txt ./shuguo2.txt</span><br><span class="line">2023-09-17 21:14:44,011 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# ll</span><br><span class="line">总用量 200</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 4 root root     37 9月  15 11:02 data</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh     288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh  147145 9月   4 2019 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1 root root      7 9月  17 21:04 liubei.txt</span><br><span class="line">drwxrwxrwx. 3 root root   4096 9月  17 14:13 logs</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh   21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh    1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh    4096 9月  14 22:32 sbin</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh      31 9月  12 2019 share</span><br><span class="line">-rw-r--r--. 1 root root     14 9月  17 21:14 shuguo2.txt  # 文件在这里</span><br><span class="line">-rw-r--r--. 1 root root     14 9月  17 21:10 shuguo.txt</span><br><span class="line">drwxr-xr-x. 2 root root     22 8月   7 10:36 wcinput</span><br><span class="line">drwxr-xr-x. 2 root root     88 8月   7 10:45 wcoutput</span><br><span class="line">-rw-r--r--. 1 root root      7 9月  17 20:31 weiguo.txt</span><br><span class="line">-rw-r--r--. 1 root root      6 9月  17 20:42 wuguo.txt</span><br></pre></td></tr></table></figure>

<h5 id="4-HDFS直接操作"><a href="#4-HDFS直接操作" class="headerlink" title="4. HDFS直接操作"></a>4. HDFS直接操作</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（1）-<span class="built_in">ls</span>命令：主要用于显示目录信息</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -ls /</span><br><span class="line">Found 5 items</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2023-09-15 11:27 /input</span><br><span class="line">-rw-r--r--   3 root supergroup  195013152 2023-09-15 11:33 /jdk-8u212-linux-x64.tar.gz</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2023-09-15 18:21 /output</span><br><span class="line">drwxr-xr-x   - root supergroup          0 2023-09-17 20:43 /sanguo</span><br><span class="line">drwx------   - root supergroup          0 2023-09-15 20:07 /tmp</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -ls /sanguo</span><br><span class="line">Found 3 items</span><br><span class="line">-rw-r--r--   3 root supergroup         14 2023-09-17 21:06 /sanguo/shuguo.txt</span><br><span class="line">-rw-r--r--   3 root supergroup          7 2023-09-17 20:34 /sanguo/weiguo.txt</span><br><span class="line">-rw-r--r--   3 root supergroup          6 2023-09-17 20:43 /sanguo/wuguo.txt</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（2）-<span class="built_in">cat</span>命令：主要用于显示文件内容</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -cat /sanguo/shuguo.txt</span><br><span class="line">2023-09-17 21:22:32,080 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">shuguo</span><br><span class="line">liubei</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（3）-<span class="built_in">chgrp</span>,-<span class="built_in">chmod</span>,-<span class="built_in">chown</span>命令：与Linux命令类似，不再演示</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（4）-<span class="built_in">mkdir</span>命令：主要用于创建路径</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -mkdir /jinguo</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-17_21-29-03.png" alt="Snipaste_2023-09-17_21-29-03" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（5）-<span class="built_in">cp</span>命令：主要用于将文件从HDFS中的一个路径下复制到HDFS中的另一个路径</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">例如，我们将shuguo.txt从/sanguo目录下拷贝到/jinguo目录下</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -cp /sanguo/shuguo.txt /jinguo</span><br><span class="line">2023-09-17 21:31:32,336 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">2023-09-17 21:31:32,418 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-17_21-32-51.png" alt="Snipaste_2023-09-17_21-32-51" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（6）-<span class="built_in">mv</span>命令：主要用于在HDFS中移动（剪切）文件，可以移动多个文件，当移动多个文件时，目标路径必须是文件夹。使用该命令也可以给文件重命名。</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -mv /sanguo/weiguo.txt /jinguo</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -mv /sanguo/wuguo.txt /jinguo</span><br></pre></td></tr></table></figure>

<p>可以看到&#x2F;sanguo文件夹中没有了weiguo.txt和wuguo.txt，而&#x2F;jinguo文件夹中出现了weiguo.txt和wuguo.txt</p>
<img src="Snipaste_2023-09-17_21-36-47.png" alt="Snipaste_2023-09-17_21-36-47" style="zoom: 33%;">

<img src="Snipaste_2023-09-17_21-38-11.png" alt="Snipaste_2023-09-17_21-38-11" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（7）-<span class="built_in">tail</span>命令：主要用于显示一个文件夹末尾1KB的数据</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -tail /jinguo/shuguo.txt</span><br><span class="line">2023-09-17 21:41:22,124 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">shuguo</span><br><span class="line">liubei</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（8）-<span class="built_in">rm</span>命令：主要用于删除文件或文件夹</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -rm /sanguo/shuguo.txt</span><br><span class="line">Deleted /sanguo/shuguo.txt</span><br></pre></td></tr></table></figure>

<p>此时的&#x2F;sanguo文件夹就变成了空文件夹</p>
<img src="Snipaste_2023-09-17_21-44-09.png" alt="Snipaste_2023-09-17_21-44-09" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（9）-<span class="built_in">rm</span> -r命令：主要用于递归删除目录及其中的内容</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -rm -r /sanguo</span><br><span class="line">Deleted /sanguo</span><br></pre></td></tr></table></figure>

<p>可以看到&#x2F;sanguo文件夹没有了</p>
<img src="Snipaste_2023-09-17_21-48-18.png" alt="Snipaste_2023-09-17_21-48-18" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（10）-<span class="built_in">du</span>命令：统计文件夹的大小。如果加上-s参数，则表示只统计文件夹的大小：如果不加-s参数，则表示统计文件夹中文件的大小。</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -du -s -h /jinguo</span><br><span class="line">27  81  /jinguo</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -du -h /jinguo</span><br><span class="line">14  42  /jinguo/shuguo.txt</span><br><span class="line">7   21  /jinguo/weiguo.txt</span><br><span class="line">6   18  /jinguo/wuguo.txt</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">说明：文件夹或文件前面的两个数字分别代表文件夹或文件的字节数和文件夹或文件的3个副本的总字节数</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">（11）-setrep：主要用于设置HDFS中文件的副本数量</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop fs -setrep 10 /jinguo/shuguo.txt</span><br><span class="line">Replication 10 set: /jinguo/shuguo.txt</span><br></pre></td></tr></table></figure>

<p>可以看到，&#x2F;jinguo&#x2F;shuguo.txt的副本变成了10个</p>
<img src="Snipaste_2023-09-17_22-13-23.png" alt="Snipaste_2023-09-17_22-13-23" style="zoom:33%;">

<p><strong>通过该命令设置的副本数量只能记录在NameNode的元数据中，是否真的有那么多副本，取决于DataNode的数量，因为目前只有3台节点服务器，所以最多存在3个副本，只有当节点服务器增加到10台的时候，真正的副本数量才能到达10个。</strong></p>
<h3 id="4-3-HDFS的API操作"><a href="#4-3-HDFS的API操作" class="headerlink" title="4.3 HDFS的API操作"></a>4.3 HDFS的API操作</h3><h4 id="4-3-1-客户端环境准备"><a href="#4-3-1-客户端环境准备" class="headerlink" title="4.3.1 客户端环境准备"></a>4.3.1 客户端环境准备</h4><p>（1）复制目录地址D:\hadoop_windows\hadoop-3.1.0</p>
<p>（2）将复制内容粘贴在：此电脑-属性-高级系统设置-高级-环境变量-新建</p>
<img src="Snipaste_2023-09-18_12-44-58.png" alt="Snipaste_2023-09-18_12-44-58" style="zoom: 50%;">

<img src="Snipaste_2023-09-18_12-45-42.png" alt="Snipaste_2023-09-18_12-45-42" style="zoom:50%;">

<p>再添加到Path目录：</p>
<img src="Snipaste_2023-09-18_12-47-31.png" alt="Snipaste_2023-09-18_12-47-31" style="zoom:50%;">

<p>（3）在hadoop-3.1.0目录下的bin文件中，双击winutils.exe文件，如果一闪而过，说明正常</p>
<hr>
<p>maven核心程序地址（中军大帐）：D:\software\apache-maven\apache-maven-3.9.4</p>
<p>maven本地仓库地址（兵营）：D:\maven-repo</p>
<p>maven工作空间（战场）：D:\maven-workspace\spaceVideo</p>
<p>（4）在IDEA中创建一个Maven工程HdfsClientDemo，在该工程的pom.xml文件中添加以下依赖，其中，hadoop-client依赖主要用于执行Hadoop的相关操作，junit依赖主要用于进行方法测试，slf4j-log4j12依赖主要用于打印日志。</p>
<img src="Snipaste_2023-09-18_20-39-28.png" alt="Snipaste_2023-09-18_20-39-28" style="zoom:50%;">

<img src="Snipaste_2023-09-18_20-47-23.png" alt="Snipaste_2023-09-18_20-47-23" style="zoom:50%;">

<img src="Snipaste_2023-09-18_20-49-38.png" alt="Snipaste_2023-09-18_20-49-38" style="zoom:50%;">

<p>如果新建的工程没有resources目录，那么就new-directory-resources</p>
<p>添加依赖：</p>
<img src="Snipaste_2023-09-18_20-52-56.png" alt="Snipaste_2023-09-18_20-52-56" style="zoom:50%;">

<p>在HdfsClientDemo工程中的src&#x2F;main&#x2F;resources目录下新建一个文件log4j.properties，在该文件中添加以下内容，可以在控制台中打印日志：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, stdout </span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender </span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n </span><br><span class="line">log4j.appender.logfile=org.apache.log4j.FileAppender </span><br><span class="line">log4j.appender.logfile.File=target/spring.log </span><br><span class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</span><br></pre></td></tr></table></figure>

<p>创建com.atguigu.hdfs包，在包中创建HdfsClient类</p>
<img src="Snipaste_2023-09-18_20-59-31.png" alt="Snipaste_2023-09-18_20-59-31" style="zoom:50%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: HdfsClient</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.hdfs</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> * 编写HDFS API的具体思路如下：</span></span><br><span class="line"><span class="comment"> * ①创建一个Hadoop的配置类Configuration，在该配置类中封装有Hadoop的所有默认配置，</span></span><br><span class="line"><span class="comment"> *   若用户需要自定义配置，则可以通过该配置类进行修改</span></span><br><span class="line"><span class="comment"> * ②创建FileSystem对象，FileSystem是Hadoop提供的文件系统的客户端接口</span></span><br><span class="line"><span class="comment"> * ③通过FileSystem对象调用具体方法，对文件系统进行操作。</span></span><br><span class="line"><span class="comment"> * ④关闭客户端</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2023/9/18 0018 20:59</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HdfsClient</span> &#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMkdirs</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//0.连接集群的地址</span></span><br><span class="line">        <span class="type">URI</span> <span class="variable">uri</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:8020&quot;</span>);</span><br><span class="line">        <span class="comment">// 1.获取文件系统</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">//获取到了客户端对象</span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(uri,configuration,<span class="string">&quot;root&quot;</span>);</span><br><span class="line">        <span class="comment">//2.创建目录</span></span><br><span class="line">        fs.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan/&quot;</span>));</span><br><span class="line">        <span class="comment">//3.关闭资源</span></span><br><span class="line">        fs.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在Web端查看到相应目录，说明程序执行成功：</p>
<img src="Snipaste_2023-09-18_21-20-46.png" alt="Snipaste_2023-09-18_21-20-46" style="zoom: 33%;">

<img src="Snipaste_2023-09-18_21-21-09.png" alt="Snipaste_2023-09-18_21-21-09" style="zoom:33%;">

<p>我们把代码进行初始化和关闭资源封装，@Test处为业务逻辑代码，@Before的代码在test之前执行，@After的代码在test之后执行</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HdfsClient</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> FileSystem fs;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 对HDFS的初始化方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> URISyntaxException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//0.连接集群的地址</span></span><br><span class="line">        <span class="type">URI</span> <span class="variable">uri</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:8020&quot;</span>);</span><br><span class="line">        <span class="comment">// 1.获取文件系统</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">//获取到了客户端对象</span></span><br><span class="line">        fs = FileSystem.get(uri,configuration,<span class="string">&quot;root&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 关闭资源方法</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@After</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//3.关闭资源</span></span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMkdirs</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//2.创建目录</span></span><br><span class="line">        fs.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan1/&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<img src="Snipaste_2023-09-18_21-30-37.png" alt="Snipaste_2023-09-18_21-30-37" style="zoom: 33%;">

<h4 id="4-3-2-HDFS文件上传案例"><a href="#4-3-2-HDFS文件上传案例" class="headerlink" title="4.3.2 HDFS文件上传案例"></a>4.3.2 HDFS文件上传案例</h4><p>在D盘中新建一个文件sunwukong.txt，内容为sunwukong</p>
<p>编写程序（只显示业务逻辑代码）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//上传</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testPut</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">//参数解读：参数一：表示删除原数据；参数二：是否允许覆盖；参数三：原数据路径；参数四：目的地路径</span></span><br><span class="line">    fs.copyFromLocalFile(<span class="literal">false</span>,<span class="literal">false</span>,<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\sunwukong.txt&quot;</span>),<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan&quot;</span>));</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行成功：</p>
<img src="Snipaste_2023-09-18_21-46-11.png" alt="Snipaste_2023-09-18_21-46-11" style="zoom: 33%;">

<p>新建hdfs-site.xml文件到resources目录，编辑如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>重新执行java代码可以看到，副本数变为1：</p>
<img src="Snipaste_2023-09-18_21-55-29.png" alt="Snipaste_2023-09-18_21-55-29" style="zoom:33%;">

<p>我们再将获取文件系统时的代码添加一行：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">configuration.set(<span class="string">&quot;dfs.replication&quot;</span>,<span class="string">&quot;2&quot;</span>);<span class="comment">//表示2个副本</span></span><br></pre></td></tr></table></figure>

<p>重新执行java代码可以看到，副本数变为2：</p>
<img src="Snipaste_2023-09-18_21-59-07.png" alt="Snipaste_2023-09-18_21-59-07" style="zoom: 33%;">

<p>综上所述，Hadoop服务器可以在不同的位置进行参数配置，具有不同的优先级，优先级由高到低分别如下：</p>
<p><strong>客户端代码中设置的值 &gt; ClassPath中的用户自定义配置文件（resources目录下的配置文件） &gt; 服务器中的自定义配置文件(xxx.site.xml) &gt; 服务器中的默认配置文件(xxx-default.xml)</strong></p>
<h4 id="4-3-3-HDFS文件下载案例"><a href="#4-3-3-HDFS文件下载案例" class="headerlink" title="4.3.3 HDFS文件下载案例"></a>4.3.3 HDFS文件下载案例</h4><p>目的：将&#x2F;xiyou&#x2F;huaguoshan&#x2F;sunwukong.txt文件下载至本地文件系统中。下载功能调用FileSystem对象的copyToLocalFile()方法，此方法有如下4个参数：</p>
<ul>
<li>delSrc：boolean类型，用于设置是否将原文件删除</li>
<li>src：Path类型，要下载的文件路径</li>
<li>dst：Path类型，存储下载文件的目标路径</li>
<li>useRawLocalFileSystem：boolean类型，用于设置是否启用文件校验功能（true是不校验，false是校验）</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//下载</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testGet</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    fs.copyToLocalFile(<span class="literal">false</span>,<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan/sunwukong.txt&quot;</span>),<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\&quot;</span>),<span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="4-3-4-HDFS文件重命名与移动案例"><a href="#4-3-4-HDFS文件重命名与移动案例" class="headerlink" title="4.3.4 HDFS文件重命名与移动案例"></a>4.3.4 HDFS文件重命名与移动案例</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//文件重命名</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testRename</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">//参数解读：参数一：原文件路径，参数二：目标文件路径</span></span><br><span class="line">    fs.rename(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan/sunwukong.txt&quot;</span>),<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou/huaguoshan/sunwukong222.txt&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-19_11-06-51.png" alt="Snipaste_2023-09-19_11-06-51" style="zoom: 33%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//文件移动并更名</span></span><br><span class="line"><span class="comment">//将/jinguo/shuguo.txt移动到根目录下，并修改文件名称为shuhan.txt</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testMove</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    fs.rename(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/jinguo/shuguo.txt&quot;</span>),<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/shuhan.txt&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-19_11-29-38.png" alt="Snipaste_2023-09-19_11-29-38" style="zoom:33%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//目录更名</span></span><br><span class="line"><span class="comment">//将/jinguo目录更名为/Wudai</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testRenameCat</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    fs.rename(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/jinguo&quot;</span>),<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/Wudai&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-19_11-33-29.png" alt="Snipaste_2023-09-19_11-33-29" style="zoom:33%;">

<h4 id="4-3-5-HDFS文件删除案例"><a href="#4-3-5-HDFS文件删除案例" class="headerlink" title="4.3.5 HDFS文件删除案例"></a>4.3.5 HDFS文件删除案例</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//文件删除</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testRm</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">//参数解读：第一个参数是需要删除的文件路径，第二个参数是boolean类型的参数，用于设置是否对</span></span><br><span class="line">    <span class="comment">//文件夹进行递归删除操作，当传入的文件路径为非空文件夹时，boolean类型的参数必须为true，才会执行</span></span><br><span class="line">    <span class="comment">//删除操作，否则会报错</span></span><br><span class="line">    fs.delete(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/xiyou&quot;</span>),<span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>&#x2F;xiyou删除成功：</p>
<img src="Snipaste_2023-09-19_11-20-38.png" alt="Snipaste_2023-09-19_11-20-38" style="zoom: 33%;">

<h4 id="4-3-6-HDFS文件详情查看案例"><a href="#4-3-6-HDFS文件详情查看案例" class="headerlink" title="4.3.6 HDFS文件详情查看案例"></a>4.3.6 HDFS文件详情查看案例</h4><p>通过调用FileSystem对象的listFiles()方法实现查看文件名称、权限、长度、块信息等，返回值是一个封装了路径下所有文件状态的迭代器。迭代器内封装的对象是FileStatus类的子类LocatedFileStatus，通过它可以获取文件的所有信息。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//获取文件详细信息</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testFileDetail</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">//获取所有文件信息（ctrl+alt+v快速生成返回值）</span></span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>), <span class="literal">true</span>);</span><br><span class="line">    <span class="comment">//遍历文件</span></span><br><span class="line">    <span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">        <span class="type">LocatedFileStatus</span> <span class="variable">fileStatus</span> <span class="operator">=</span> listFiles.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;==========&quot;</span> + fileStatus.getPath() + <span class="string">&quot;============&quot;</span>);</span><br><span class="line">        System.out.println(fileStatus.getPermission());</span><br><span class="line">        System.out.println(fileStatus.getOwner());</span><br><span class="line">        System.out.println(fileStatus.getGroup());</span><br><span class="line">        System.out.println(fileStatus.getLen());</span><br><span class="line">        System.out.println(fileStatus.getModificationTime());</span><br><span class="line">        System.out.println(fileStatus.getReplication());</span><br><span class="line">        System.out.println(fileStatus.getBlockSize());</span><br><span class="line">        System.out.println(fileStatus.getPath().getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取块信息</span></span><br><span class="line">        BlockLocation[] blockLocations = fileStatus.getBlockLocations();</span><br><span class="line">        System.out.println(Arrays.toString(blockLocations));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">==========hdfs://hadoop102:8020/Wudai/weiguo.txt============</span><br><span class="line">rw-r--r--</span><br><span class="line">root</span><br><span class="line">supergroup</span><br><span class="line">7</span><br><span class="line">1694954063249</span><br><span class="line">3</span><br><span class="line">134217728</span><br><span class="line">weiguo.txt</span><br><span class="line">[0,7,hadoop104,hadoop103,hadoop102]</span><br><span class="line">==========hdfs://hadoop102:8020/Wudai/wuguo.txt============</span><br><span class="line">rw-r--r--</span><br><span class="line">root</span><br><span class="line">supergroup</span><br><span class="line">6</span><br><span class="line">1694954637356</span><br><span class="line">3</span><br><span class="line">134217728</span><br><span class="line">wuguo.txt</span><br><span class="line">[0,6,hadoop104,hadoop103,hadoop102]</span><br><span class="line">==========hdfs://hadoop102:8020/input/word.txt============</span><br><span class="line">rw-r--r--</span><br><span class="line">root</span><br><span class="line">supergroup</span><br><span class="line">97</span><br><span class="line">1694748469255</span><br><span class="line">3</span><br><span class="line">134217728</span><br><span class="line">word.txt</span><br><span class="line">[0,97,hadoop104,hadoop103,hadoop102]</span><br><span class="line">......</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="4-3-7-HDFS文件和文件夹判断案例"><a href="#4-3-7-HDFS文件和文件夹判断案例" class="headerlink" title="4.3.7 HDFS文件和文件夹判断案例"></a>4.3.7 HDFS文件和文件夹判断案例</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//判断是文件还是文件夹</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">//获取FileStatus集合</span></span><br><span class="line">    FileStatus[] listStatus = fs.listStatus(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>));</span><br><span class="line">    <span class="comment">//增强for循环</span></span><br><span class="line">    <span class="keyword">for</span> (FileStatus status :listStatus)&#123;</span><br><span class="line">        <span class="keyword">if</span> (status.isFile())&#123; <span class="comment">//如果是文件</span></span><br><span class="line">            System.out.println(<span class="string">&quot;文件: &quot;</span> + status.getPath().getName());</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;               <span class="comment">//如果是目录</span></span><br><span class="line">            System.out.println(<span class="string">&quot;目录: &quot;</span> + status.getPath().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">目录: Wudai</span><br><span class="line">目录: input</span><br><span class="line">文件: jdk-8u212-linux-x64.tar.gz</span><br><span class="line">目录: output</span><br><span class="line">文件: shuhan.txt</span><br><span class="line">目录: tmp</span><br></pre></td></tr></table></figure>

<h3 id="4-4-HDFS的读-x2F-写流程（面试重点）"><a href="#4-4-HDFS的读-x2F-写流程（面试重点）" class="headerlink" title="4.4 HDFS的读&#x2F;写流程（面试重点）"></a>4.4 HDFS的读&#x2F;写流程（面试重点）</h3><h4 id="4-4-1-HDFS中数据块大小（之前说过了）"><a href="#4-4-1-HDFS中数据块大小（之前说过了）" class="headerlink" title="4.4.1 HDFS中数据块大小（之前说过了）"></a>4.4.1 HDFS中数据块大小（之前说过了）</h4><h4 id="4-4-2-写数据流程"><a href="#4-4-2-写数据流程" class="headerlink" title="4.4.2 写数据流程"></a>4.4.2 写数据流程</h4><h5 id="1-剖析写数据流程"><a href="#1-剖析写数据流程" class="headerlink" title="1. 剖析写数据流程"></a>1. 剖析写数据流程</h5><h5 id="2-副本放置策略与机架感知"><a href="#2-副本放置策略与机架感知" class="headerlink" title="2. 副本放置策略与机架感知"></a>2. 副本放置策略与机架感知</h5><h5 id="3-网络拓扑距离与PipeLine的形成"><a href="#3-网络拓扑距离与PipeLine的形成" class="headerlink" title="3. 网络拓扑距离与PipeLine的形成"></a>3. 网络拓扑距离与PipeLine的形成</h5><h4 id="4-4-3-读数据流程"><a href="#4-4-3-读数据流程" class="headerlink" title="4.4.3 读数据流程"></a>4.4.3 读数据流程</h4><h3 id="4-5-HDFS的工作流程"><a href="#4-5-HDFS的工作流程" class="headerlink" title="4.5 HDFS的工作流程"></a>4.5 HDFS的工作流程</h3><h4 id="4-5-1-NameNode和SecondaryNameNode的工作机制"><a href="#4-5-1-NameNode和SecondaryNameNode的工作机制" class="headerlink" title="4.5.1 NameNode和SecondaryNameNode的工作机制"></a>4.5.1 NameNode和SecondaryNameNode的工作机制</h4><h4 id="4-5-2-EditLog和FsImage文件解析"><a href="#4-5-2-EditLog和FsImage文件解析" class="headerlink" title="4.5.2 EditLog和FsImage文件解析"></a>4.5.2 EditLog和FsImage文件解析</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/hadoop-3.1.3/data/dfs/name/current/</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 current]# ll</span><br><span class="line">总用量 10380</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  14 22:33 edits_0000000000000000001-0000000000000000001</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  15 11:21 edits_0000000000000000002-0000000000000000003</span><br><span class="line">-rw-r--r--. 1 root root    1364 9月  15 12:21 edits_0000000000000000004-0000000000000000021</span><br><span class="line">-rw-r--r--. 1 root root     154 9月  15 17:43 edits_0000000000000000022-0000000000000000025</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  15 17:51 edits_0000000000000000026-0000000000000000060</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  15 18:05 edits_0000000000000000061-0000000000000000062</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  15 18:06 edits_0000000000000000063-0000000000000000092</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  15 18:14 edits_0000000000000000093-0000000000000000094</span><br><span class="line">-rw-r--r--. 1 root root   14029 9月  15 19:14 edits_0000000000000000095-0000000000000000210</span><br><span class="line">-rw-r--r--. 1 root root   15050 9月  15 20:14 edits_0000000000000000211-0000000000000000328</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  15 20:14 edits_0000000000000000329-0000000000000000329</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  15 20:58 edits_0000000000000000330-0000000000000000331</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  15 21:58 edits_0000000000000000332-0000000000000000333</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  15 21:58 edits_0000000000000000334-0000000000000000334</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  17 14:00 edits_0000000000000000335-0000000000000000336</span><br><span class="line">-rw-r--r--. 1 root root     195 9月  17 14:37 edits_0000000000000000337-0000000000000000341</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  17 15:37 edits_0000000000000000342-0000000000000000343</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  17 16:37 edits_0000000000000000344-0000000000000000345</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  17 17:37 edits_0000000000000000346-0000000000000000347</span><br><span class="line">-rw-r--r--. 1 root root    1169 9月  17 20:37 edits_0000000000000000348-0000000000000000362</span><br><span class="line">-rw-r--r--. 1 root root    1717 9月  17 21:37 edits_0000000000000000363-0000000000000000384</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  17 22:12 edits_0000000000000000385-0000000000000000388</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  18 12:35 edits_0000000000000000389-0000000000000000389</span><br><span class="line">-rw-r--r--. 1 root root     281 9月  18 21:34 edits_0000000000000000390-0000000000000000394</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  18 21:58 edits_0000000000000000395-0000000000000000412</span><br><span class="line">-rw-r--r--. 1 root root     476 9月  19 11:33 edits_0000000000000000413-0000000000000000420</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  19 12:33 edits_0000000000000000421-0000000000000000422</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  19 16:30 edits_0000000000000000423-0000000000000000424</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  19 17:30 edits_0000000000000000425-0000000000000000426</span><br><span class="line">-rw-r--r--. 1 root root      42 9月  19 18:41 edits_0000000000000000427-0000000000000000428</span><br><span class="line">-rw-r--r--. 1 root root 1048576 9月  19 18:41 edits_inprogress_0000000000000000429</span><br><span class="line">-rw-r--r--. 1 root root    4149 9月  19 17:30 fsimage_0000000000000000426</span><br><span class="line">-rw-r--r--. 1 root root      62 9月  19 17:30 fsimage_0000000000000000426.md5</span><br><span class="line">-rw-r--r--. 1 root root    4149 9月  19 18:41 fsimage_0000000000000000428</span><br><span class="line">-rw-r--r--. 1 root root      62 9月  19 18:41 fsimage_0000000000000000428.md5</span><br><span class="line">-rw-r--r--. 1 root root       4 9月  19 18:41 seen_txid</span><br><span class="line">-rw-r--r--. 1 root root     220 9月  19 10:34 VERSION</span><br></pre></td></tr></table></figure>



<p>EditLog和FsImage文件都是二进制文件，所以不能直接查看</p>
<h5 id="1-使用oiv命令查看FsImage文件"><a href="#1-使用oiv命令查看FsImage文件" class="headerlink" title="1. 使用oiv命令查看FsImage文件"></a>1. 使用oiv命令查看FsImage文件</h5><p>基本语法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oiv -p 文件类型  -i  镜像文件 -o  转换后文件输出路径</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将fsimage_0000000000000000428文件转换为fsimage.xml文件</span></span><br><span class="line">[root@hadoop102 current]# hdfs oiv -p XML -i fsimage_0000000000000000428 -o /opt/software/fsimage.xml</span><br><span class="line">2023-09-19 20:11:26,790 INFO offlineImageViewer.FSImageHandler: Loading 4 strings</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入/opt/software目录</span></span><br><span class="line">[root@hadoop102 current]# cd /opt/software/</span><br><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 520620</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将fsimage.xml文件下载到本机（windows环境）</span></span><br><span class="line">[root@hadoop102 software]# sz fsimage.xml</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-09-19_20-13-52.png" alt="Snipaste_2023-09-19_20-13-52" style="zoom: 33%;">

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>16388<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>jdk-8u212-linux-x64.tar.gz<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1694748821284<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">atime</span>&gt;</span>1694931554367<span class="tag">&lt;/<span class="name">atime</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">permission</span>&gt;</span>root:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">blocks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">block</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741826<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1002<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">block</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741827<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1003<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>60795424<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line">......</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>可以看到FsImage文件是由多个inode信息构成的.</p>
<p>FsImage文件中并没有记录数据块对应的DataNode信息，这是因为在启动集群后，NameNode会要求DataNode上报数据块信息，并且在间隔一段时间后再次上报。</p>
<h5 id="2-使用oev命令查看EditLog文件"><a href="#2-使用oev命令查看EditLog文件" class="headerlink" title="2. 使用oev命令查看EditLog文件"></a>2. 使用oev命令查看EditLog文件</h5><p>基本语法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oev -o  文件类型  -i  编辑日志  -o  转换后文件输出路径</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将edits_inprogress_0000000000000000433文件转换为edits.xml文件</span></span><br><span class="line">[root@hadoop102 current]# hdfs oev -p XML -i edits_inprogress_0000000000000000433 -o /opt/software/edits.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入/opt/software目录</span></span><br><span class="line">[root@hadoop102 current]# cd /opt/software/</span><br><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 520624</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将edits.xml文件下载到本机（windows环境）</span></span><br><span class="line">[root@hadoop102 software]# sz edits.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> standalone=<span class="string">&quot;yes&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">EDITS</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">EDITS_VERSION</span>&gt;</span>-64<span class="tag">&lt;/<span class="name">EDITS_VERSION</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_START_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>433<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">EDITS</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="4-5-3-检查点时间设置"><a href="#4-5-3-检查点时间设置" class="headerlink" title="4.5.3 检查点时间设置"></a>4.5.3 检查点时间设置</h4><h4 id="4-5-4-DataNode的工作机制"><a href="#4-5-4-DataNode的工作机制" class="headerlink" title="4.5.4 DataNode的工作机制"></a>4.5.4 DataNode的工作机制</h4><p>HDFS中的文件实际是存储于DataNode中的，数据块存储于以<strong>blk</strong>为前缀的文件中，文件名中包含该文件存储的数据块的原始字节数，每个数据块文件都有一个名字相同但是带有.meta后缀的<strong>元数据文件</strong>，在元数据文件中存储了数据块的长度、校验和、时间戳等信息。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1662165003-192.168.255.102-1694700063570/current/finalized/subdir0/subdir0/</span><br><span class="line">[root@hadoop102 subdir0]# ll</span><br><span class="line">总用量 384612</span><br><span class="line">-rw-r--r--. 1 root root        97 9月  15 11:27 blk_1073741825</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 11:27 blk_1073741825_1001.meta</span><br><span class="line">-rw-r--r--. 1 root root 134217728 9月  15 11:33 blk_1073741826</span><br><span class="line">-rw-r--r--. 1 root root   1048583 9月  15 11:33 blk_1073741826_1002.meta</span><br><span class="line">-rw-r--r--. 1 root root  60795424 9月  15 11:33 blk_1073741827</span><br><span class="line">-rw-r--r--. 1 root root    474975 9月  15 11:33 blk_1073741827_1003.meta</span><br><span class="line">-rw-r--r--. 1 root root    316382 9月  15 17:51 blk_1073741828</span><br><span class="line">-rw-r--r--. 1 root root      2479 9月  15 17:51 blk_1073741828_1004.meta</span><br><span class="line">-rw-r--r--. 1 root root       108 9月  15 17:51 blk_1073741829</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 17:51 blk_1073741829_1005.meta</span><br><span class="line">-rw-r--r--. 1 root root        43 9月  15 17:51 blk_1073741830</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 17:51 blk_1073741830_1006.meta</span><br><span class="line">-rw-r--r--. 1 root root    184966 9月  15 17:51 blk_1073741831</span><br><span class="line">-rw-r--r--. 1 root root      1455 9月  15 17:51 blk_1073741831_1007.meta</span><br><span class="line">-rw-r--r--. 1 root root    316382 9月  15 18:06 blk_1073741832</span><br><span class="line">-rw-r--r--. 1 root root      2479 9月  15 18:06 blk_1073741832_1008.meta</span><br><span class="line">-rw-r--r--. 1 root root       108 9月  15 18:06 blk_1073741833</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 18:06 blk_1073741833_1009.meta</span><br><span class="line">-rw-r--r--. 1 root root        43 9月  15 18:06 blk_1073741834</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 18:06 blk_1073741834_1010.meta</span><br><span class="line">-rw-r--r--. 1 root root    185463 9月  15 18:06 blk_1073741835</span><br><span class="line">-rw-r--r--. 1 root root      1459 9月  15 18:06 blk_1073741835_1011.meta</span><br><span class="line">-rw-r--r--. 1 root root    316382 9月  15 18:14 blk_1073741836</span><br><span class="line">-rw-r--r--. 1 root root      2479 9月  15 18:14 blk_1073741836_1012.meta</span><br><span class="line">-rw-r--r--. 1 root root       108 9月  15 18:14 blk_1073741837</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 18:14 blk_1073741837_1013.meta</span><br><span class="line">-rw-r--r--. 1 root root        43 9月  15 18:14 blk_1073741838</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 18:14 blk_1073741838_1014.meta</span><br><span class="line">-rw-r--r--. 1 root root    185433 9月  15 18:14 blk_1073741839</span><br><span class="line">-rw-r--r--. 1 root root      1459 9月  15 18:14 blk_1073741839_1015.meta</span><br><span class="line">-rw-r--r--. 1 root root        80 9月  15 18:21 blk_1073741846</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  15 18:21 blk_1073741846_1022.meta</span><br><span class="line">-rw-r--r--. 1 root root     22342 9月  15 18:21 blk_1073741848</span><br><span class="line">-rw-r--r--. 1 root root       183 9月  15 18:21 blk_1073741848_1024.meta</span><br><span class="line">-rw-r--r--. 1 root root    215649 9月  15 18:21 blk_1073741849</span><br><span class="line">-rw-r--r--. 1 root root      1695 9月  15 18:21 blk_1073741849_1025.meta</span><br><span class="line">-rw-r--r--. 1 root root     22342 9月  15 20:07 blk_1073741858</span><br><span class="line">-rw-r--r--. 1 root root       183 9月  15 20:07 blk_1073741858_1034.meta</span><br><span class="line">-rw-r--r--. 1 root root    215826 9月  15 20:07 blk_1073741859</span><br><span class="line">-rw-r--r--. 1 root root      1695 9月  15 20:07 blk_1073741859_1035.meta</span><br><span class="line">-rw-r--r--. 1 root root     34635 9月  15 20:07 blk_1073741860</span><br><span class="line">-rw-r--r--. 1 root root       279 9月  15 20:07 blk_1073741860_1036.meta</span><br><span class="line">-rw-r--r--. 1 root root     99463 9月  15 20:07 blk_1073741861</span><br><span class="line">-rw-r--r--. 1 root root       787 9月  15 20:07 blk_1073741861_1037.meta</span><br><span class="line">-rw-r--r--. 1 root root         7 9月  17 20:34 blk_1073741863</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  17 20:34 blk_1073741863_1039.meta</span><br><span class="line">-rw-r--r--. 1 root root         6 9月  17 20:43 blk_1073741864</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  17 20:43 blk_1073741864_1040.meta</span><br><span class="line">-rw-r--r--. 1 root root        14 9月  17 21:31 blk_1073741865</span><br><span class="line">-rw-r--r--. 1 root root        11 9月  17 21:31 blk_1073741865_1042.meta</span><br><span class="line">drwxr-xr-x. 7   10  143       245 4月   2 2019 jdk1.8.0_212</span><br><span class="line">-rw-r--r--. 1 root root 195013152 9月  15 17:25 tmp.tar.gz</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-09-22_18-24-09.png" alt="Snipaste_2023-09-22_18-24-09"></p>
<p>DataNode在启动后向NameNode注册，在注册通过后，每隔一段时间都会向NameNode上报所有的数据块信息，时间间隔默认是6小时。</p>
<p>DataNode每隔一段时间都会扫描本节点中的数据块信息列表，时间间隔默认是6小时。</p>
<p>DataNode每隔3秒都会向NameNode发送心跳信息，心跳返回结果中包含NameNode对该DataNode的命令，如复制数据块、删除数据块等。如果DataNode进程挂掉，或者发生网络故障，导致DataNode无法与NameNode正常通信，那么NameNode不会立即将该节点判定为死亡，它会在一段时间（称为超时时长，默认配置为10分钟30秒）后将该节点判定为死亡。</p>
<p>点击HDFS的Web页面，可以查看DataNode的运行情况：</p>
<p><img src="Snipaste_2023-09-22_20-58-59.png" alt="Snipaste_2023-09-22_20-58-59"></p>
<h4 id="4-5-5-数据完整性"><a href="#4-5-5-数据完整性" class="headerlink" title="4.5.5 数据完整性"></a>4.5.5 数据完整性</h4><h2 id="第五章-分布式计算MapReduce"><a href="#第五章-分布式计算MapReduce" class="headerlink" title="第五章 分布式计算MapReduce"></a>第五章 分布式计算MapReduce</h2><h3 id="5-1-MapReduce概述"><a href="#5-1-MapReduce概述" class="headerlink" title="5.1 MapReduce概述"></a>5.1 MapReduce概述</h3><h4 id="5-1-1-MapReduce定义"><a href="#5-1-1-MapReduce定义" class="headerlink" title="5.1.1 MapReduce定义"></a>5.1.1 MapReduce定义</h4><p>MapReduce是一个分布式计算程序的编程框架。MapReduce的核心功能是将<strong>用户编写的业务逻辑代码</strong>和<strong>自带的默认组件</strong>整合成一个完整的分布式计算程序并且将其<strong>并发运行</strong>在一个Hadoop集群上。</p>
<h5 id="1-优点"><a href="#1-优点" class="headerlink" title="1. 优点"></a>1. 优点</h5><ul>
<li>易于编程</li>
<li>良好的扩展性：当计算资源不能满足海量数据的计算需求时，MapReduce可以简单地通过增加节点数量增强计算能力</li>
<li>高容错性：一个节点宕机，它可以将该节点上的计算任务转移到另一个节点运行，不至于导致这个任务运行失败</li>
<li>适合PB级以上数据的离线处理：MapReduce可以实现上千台服务器集群并发工作，提供数据处理能力。</li>
</ul>
<h5 id="2-缺点"><a href="#2-缺点" class="headerlink" title="2. 缺点"></a>2. 缺点</h5><ul>
<li>不擅长实时计算</li>
<li>不擅长流式计算：流式计算的输入数据是动态的，而MapReduce的输入是静态的，不能动态变化</li>
<li>不擅长DAG（有向无环图）计算：多个应用程序之间存在依赖关系，后一个应用程序是前一个应用程序的输出数据，</li>
</ul>
<h4 id="5-1-2-MapReduce核心思想"><a href="#5-1-2-MapReduce核心思想" class="headerlink" title="5.1.2 MapReduce核心思想"></a>5.1.2 MapReduce核心思想</h4><p><img src="Snipaste_2023-09-25_09-09-40.png" alt="Snipaste_2023-09-25_09-09-40"></p>
<p>在运行一个完整的MapReduce程序时，在集群中会发现以下3类实例进程：</p>
<ul>
<li>MRAppMaster：负责整个程序的过程调度及状态协调</li>
<li>MapTask：负责map阶段的整个数据处理流程</li>
<li>ReduceTask：负责reduce阶段的整个数据处理流程</li>
</ul>
<h3 id="5-2-MapReduce编程入门"><a href="#5-2-MapReduce编程入门" class="headerlink" title="5.2 MapReduce编程入门"></a>5.2 MapReduce编程入门</h3><h4 id="5-2-1-官方示例程序WorldCount源码"><a href="#5-2-1-官方示例程序WorldCount源码" class="headerlink" title="5.2.1 官方示例程序WorldCount源码"></a>5.2.1 官方示例程序WorldCount源码</h4><p>将hadoop-mapreduce-examples-3.1.3.jar下载到本地</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/</span><br><span class="line">[root@hadoop102 mapreduce]# ll</span><br><span class="line">总用量 5576</span><br><span class="line">-rw-r--r--. 1 wyh wyh  612175 9月  12 2019 hadoop-mapreduce-client-app-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh  804003 9月  12 2019 hadoop-mapreduce-client-common-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh 1655414 9月  12 2019 hadoop-mapreduce-client-core-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh  215372 9月  12 2019 hadoop-mapreduce-client-hs-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh   45334 9月  12 2019 hadoop-mapreduce-client-hs-plugins-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh   85396 9月  12 2019 hadoop-mapreduce-client-jobclient-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh 1659884 9月  12 2019 hadoop-mapreduce-client-jobclient-3.1.3-tests.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh  126143 9月  12 2019 hadoop-mapreduce-client-nativetask-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh   97155 9月  12 2019 hadoop-mapreduce-client-shuffle-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh   57652 9月  12 2019 hadoop-mapreduce-client-uploader-3.1.3.jar</span><br><span class="line">-rw-r--r--. 1 wyh wyh  316382 9月  12 2019 hadoop-mapreduce-examples-3.1.3.jar</span><br><span class="line">drwxr-xr-x. 2 wyh wyh    4096 9月  12 2019 jdiff</span><br><span class="line">drwxr-xr-x. 2 wyh wyh      57 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 2 wyh wyh      30 9月  12 2019 lib-examples</span><br><span class="line">drwxr-xr-x. 2 wyh wyh    4096 9月  12 2019 sources</span><br><span class="line">[root@hadoop102 mapreduce]# sz hadoop-mapreduce-examples-3.1.3.jar </span><br></pre></td></tr></table></figure>

<p>使用反编译工具，可以看到WordCount的源码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.hadoop.examples;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.PrintStream;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer.Context;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">//下面是提交作业的逻辑</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span></span><br><span class="line">    <span class="keyword">throws</span> Exception</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    String[] otherArgs = <span class="keyword">new</span> <span class="title class_">GenericOptionsParser</span>(conf, args).getRemainingArgs();</span><br><span class="line">    <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">      System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;</span>);</span><br><span class="line">      System.exit(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf, <span class="string">&quot;word count&quot;</span>);</span><br><span class="line">    job.setJarByClass(WordCount.class);</span><br><span class="line">    job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">    <span class="comment">//Combiner实际执行的逻辑和reducer是一样的</span></span><br><span class="line">    <span class="comment">//所以可以将Combiner的处理类直接用Reducer类来表示</span></span><br><span class="line">    <span class="comment">//和Reducer的差别是，combiner是在Map阶段所在的节点中执行的 </span></span><br><span class="line">    job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">    job.setReducerClass(IntSumReducer.class);</span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; i++) &#123;</span><br><span class="line">      FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[i]));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//设置文件输入路径</span></span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[(otherArgs.length - <span class="number">1</span>)]));</span><br><span class="line">    <span class="comment">//设置文件的输出路径</span></span><br><span class="line">    System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*Reduce泛型也接受声明了4个参数</span></span><br><span class="line"><span class="comment">  *前两个，即Text和IntWritable分别表示读取Mapper输出键和值的数据类型</span></span><br><span class="line"><span class="comment">  *和上面的Mapper泛型后面两个参数的数据类型保持一致</span></span><br><span class="line"><span class="comment">  *后两个，即Text, IntWritable分别表示Reducer输出键和值的数据类型</span></span><br><span class="line"><span class="comment">  *reduce函数中context.write()函数接受的数据类型要和这两个数据类型保持一致</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">IntSumReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Reduce阶段执行的逻辑代码</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span></span><br><span class="line">      <span class="keyword">throws</span> IOException, InterruptedException</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">        sum += val.get();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="built_in">this</span>.result.set(sum);</span><br><span class="line">      <span class="comment">//context结果写入HDFS中</span></span><br><span class="line">      <span class="comment">//写到HDFS的文件中，每一行的表现形式入word1 sum</span></span><br><span class="line">      <span class="comment">//其中sum表示具体数据</span></span><br><span class="line">      context.write(key, <span class="built_in">this</span>.result);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*Mapper泛型接受声明了4个参数</span></span><br><span class="line"><span class="comment">  *前两个参数Object, Text表示程序接受输入的数据类型</span></span><br><span class="line"><span class="comment">  *在MapReduce输入的数据都是采用键-值对的形式</span></span><br><span class="line"><span class="comment">  *其中，Object表示键，Text表示值，和下面map函数的前两个参数类型保持一致</span></span><br><span class="line"><span class="comment">  *后两个Text, IntWritable表示map输出的键-值对的数据类型</span></span><br><span class="line"><span class="comment">  *map函数中context.write()函数接受的数据类型要和这两个数据类型保持一致</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, IntWritable&gt;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">word</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Map阶段执行逻辑代码</span></span><br><span class="line">    <span class="comment">//下面代码接受3个参数</span></span><br><span class="line">    <span class="comment">//参数- key表示偏移量，在HDFS的文件中每一行数据都有一个行偏移量</span></span><br><span class="line">    <span class="comment">//参数- value表示每一行的内容</span></span><br><span class="line">    <span class="comment">//参数- context表示MapReduce的上下文</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Mapper&lt;Object, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">//将一行数据内容按空格切分成可以迭代的集合</span></span><br><span class="line">      <span class="type">StringTokenizer</span> <span class="variable">itr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString());</span><br><span class="line">      <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">        <span class="comment">//mapreduce不接受java的数据类型，必须转化成mapreduce可以识别的类型</span></span><br><span class="line">        <span class="comment">//例如java中的String对应Text，int对应IntWritable等</span></span><br><span class="line">        <span class="built_in">this</span>.word.set(itr.nextToken());</span><br><span class="line">        <span class="comment">//context会将文件写到HDFS的临时目录中，等待Reducer节点来取</span></span><br><span class="line">        <span class="comment">//写到HDFS的文件中，每一行表现形式如word1,1</span></span><br><span class="line">        context.write(<span class="built_in">this</span>.word, one);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="补充：常用数据序列类型"><a href="#补充：常用数据序列类型" class="headerlink" title="补充：常用数据序列类型"></a>补充：常用数据序列类型</h4><img src="Snipaste_2023-09-25_09-30-13.png" alt="Snipaste_2023-09-25_09-30-13" style="zoom:50%;">

<h4 id="5-2-2-编程规范"><a href="#5-2-2-编程规范" class="headerlink" title="5.2.2 编程规范"></a>5.2.2 编程规范</h4><p>用户编写的MapReduce程序主要分为三个部分：Mapper、Reducer和Driver</p>
<ol>
<li>Mapper组件</li>
</ol>
<ul>
<li>用户自定义类会继承Mapper类，并给出4个泛型，即map方法的输入键、输入值、输出键和输出值的数据情况。</li>
<li>Mapper组件的输入数据是键&#x2F;值对的形式，输入键是一个长整型的偏移量，输入值是一行文本；输出数据也是键&#x2F;值对的形式，输出键和输出值的数据类型是由map()方法的处理逻辑决定。</li>
<li>Mapper组件的业务逻辑写在map()方法中，map()方法的实现逻辑是由用户自行编写。</li>
<li>map()方法对每个输入数据键&#x2F;值对都只调用一次。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, IntWritable&gt;</span><br><span class="line">    <span class="comment">//用户自定义类会继承Mapper类，并给出4个泛型，</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">word</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Mapper&lt;Object, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException<span class="comment">//即map方法的输入键、输入值、输出键和输出值的数据情况。</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="type">StringTokenizer</span> <span class="variable">itr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString());</span><br><span class="line">      <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">        <span class="built_in">this</span>.word.set(itr.nextToken());</span><br><span class="line">        context.write(<span class="built_in">this</span>.word, one);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Reducer组件</li>
</ol>
<ul>
<li>用户自定义类会继承Reducer类，并且给出4个泛型，即reduce()方法的输入键、输入值、输出键和输出值的数据类型。</li>
<li>Reducer组件的输入数据是键&#x2F;值对形式，其中，输入键和输入值的数据类型与Mapper的输出键和输出值的数据类型必须匹配。</li>
<li>Reducer组件的业务逻辑写在reduce()方法中，实现逻辑由用户自定义。</li>
<li>ReduceTask进程对每组相同的键&#x2F;值对都只调用一次reduce()方法。有多少个key就调用多少个reduce()方法。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">IntSumReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt;</span><br><span class="line">    <span class="comment">//用户自定义类会继承Reducer类，并且给出4个泛型，</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span><span class="comment">//即reduce()方法的输入键、输入值、输出键和输出值的数据类型</span></span><br><span class="line">      <span class="keyword">throws</span> IOException, InterruptedException</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">        sum += val.get();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="built_in">this</span>.result.set(sum);</span><br><span class="line">      context.write(key, <span class="built_in">this</span>.result);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Driver驱动器</li>
</ol>
<ul>
<li>主要负责运行整个MapReduce程序，指定MapReduce程序的执行规范，以及控制整个MapReduce程序的运行。在这部分中，我们首先构建一个Job对象，通过Job对象指定输入数据和输出数据的路径，指定MapReduce程序的Mapper组件和Reduce组件，指定输出键和输出值的数据类型。相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数的job对象。</li>
</ul>
<h4 id="5-2-3-WordCount案例实操"><a href="#5-2-3-WordCount案例实操" class="headerlink" title="5.2.3 WordCount案例实操"></a>5.2.3 WordCount案例实操</h4><h5 id="1-需求说明"><a href="#1-需求说明" class="headerlink" title="1. 需求说明"></a>1. 需求说明</h5><p>给hello.txt文件统计词频</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">atguigu atguigu</span><br><span class="line">ss ss</span><br><span class="line">cls cls</span><br><span class="line">jiao</span><br><span class="line">banzhang</span><br><span class="line">xue</span><br><span class="line">hadoop</span><br></pre></td></tr></table></figure>

<p>期望得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">atguigu 2</span><br><span class="line">banzhang 1</span><br><span class="line">cls 2</span><br><span class="line">hadoop 1</span><br><span class="line">jiao 1</span><br><span class="line">ss 2</span><br><span class="line">xue 1</span><br></pre></td></tr></table></figure>

<h5 id="2-分析"><a href="#2-分析" class="headerlink" title="2. 分析"></a>2. 分析</h5><p><img src="Snipaste_2023-09-25_14-39-40.png" alt="Snipaste_2023-09-25_14-39-40"></p>
<h5 id="3-环境准备"><a href="#3-环境准备" class="headerlink" title="3. 环境准备"></a>3. 环境准备</h5><p>使用IDEA新建一个Maven工程，命名为“MapReduceDemo”，在pom.xml文件中添加以下依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.30<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>在项目的 src&#x2F;main&#x2F;resources 目录下，新建一个文件，命名为“log4j.properties”，在文件中填入：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, stdout </span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender </span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n </span><br><span class="line">log4j.appender.logfile=org.apache.log4j.FileAppender </span><br><span class="line">log4j.appender.logfile.File=target/spring.log </span><br><span class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout </span><br><span class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</span><br></pre></td></tr></table></figure>

<p>编写程序：三个类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//编写Mapper类</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * KEYIN, map阶段输入的key的类型：LongWritable类型</span></span><br><span class="line"><span class="comment"> * VALUEIN, map阶段输入value类型：Text类型</span></span><br><span class="line"><span class="comment"> * KEYOUT, map阶段输出的key类型：Text：类型</span></span><br><span class="line"><span class="comment"> * VALUEOUT,map阶段输出的value类型：IntWritable类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text,Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//LongWritable key 是map输入的key;Text value是map输入的value;Context context充当联络员的角色</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.对这行数据进行切割</span></span><br><span class="line">        String[] words = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.循环写出（增强for循环）</span></span><br><span class="line">        <span class="keyword">for</span> (String word : words)&#123;</span><br><span class="line">            k.set(word);<span class="comment">//Text类中的set方法通常用于设置Text对象的值。它接受一个字节数组（byte array）作为参数，并将这个数组的内容复制到Text对象中</span></span><br><span class="line">            context.write(k,v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//经历了多次map操作结果为：</span></span><br><span class="line">    <span class="comment">//(atguigu,1)</span></span><br><span class="line">    <span class="comment">//(atguigu,1)</span></span><br><span class="line">    <span class="comment">//(ss,1)</span></span><br><span class="line">    <span class="comment">//(ss,1)</span></span><br><span class="line">    <span class="comment">//(cls,1)</span></span><br><span class="line">    <span class="comment">//(cls,1)</span></span><br><span class="line">    <span class="comment">//(jiao,1)</span></span><br><span class="line">    <span class="comment">//(banzhang,1)</span></span><br><span class="line">    <span class="comment">//(xue,1)</span></span><br><span class="line">    <span class="comment">//(hadoop,1)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//编写Reduce类</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * KEYIN, reduce阶段输入的key的类型：Text类型</span></span><br><span class="line"><span class="comment"> * VALUEIN, reduce阶段输入value类型：IntWritable类型</span></span><br><span class="line"><span class="comment"> * KEYOUT, reduce阶段输出的key类型：Text类型</span></span><br><span class="line"><span class="comment"> * VALUEOUT,reduce阶段输出的value类型：IntWritable类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable,Text,IntWritable&gt; &#123;</span><br><span class="line">    <span class="type">int</span> sum;</span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1.累加求和</span></span><br><span class="line">        sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable count : values)&#123;</span><br><span class="line">            sum += count.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.输出</span></span><br><span class="line">        v.set(sum);</span><br><span class="line">        context.write(key,v);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//reduce()方法每次获取的都是相同输入键的一组键/值对</span></span><br><span class="line">    <span class="comment">// key    values</span></span><br><span class="line">    <span class="comment">//(atguigu,(1,1))----&gt;执行一次reduce()方法---&gt;输出(atguigu,2)</span></span><br><span class="line">    <span class="comment">//(ss,(1,1))----&gt;执行一次reduce()方法---&gt;输出(ss,2)</span></span><br><span class="line">    <span class="comment">//(cls,(1,1))----&gt;执行一次reduce()方法---&gt;输出(cls,2)</span></span><br><span class="line">    <span class="comment">//(jiao,1)----&gt;执行一次reduce()方法---&gt;输出(jiao,1)</span></span><br><span class="line">    <span class="comment">//(banzhang,1)----&gt;执行一次reduce()方法---&gt;输出(banzhang,1)</span></span><br><span class="line">    <span class="comment">//(xue,1)----&gt;执行一次reduce()方法---&gt;输出(xue,1)</span></span><br><span class="line">    <span class="comment">//(hadoop,1)----&gt;执行一次reduce()方法---&gt;输出(hadoop,1)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//编写Driver驱动器</span></span><br><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.wordcount;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: WordCountDriver</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.mapreduce.wordcount</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2023/9/25 0025 15:01</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="comment">//1.获取配置信息以及获取 job 对象</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.关联本 Driver 程序的 jar</span></span><br><span class="line">        job.setJarByClass(WordCountDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关联 Mapper 和 Reducer 的 jar</span></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        job.setReducerClass(WordCountReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置 Mapper 输出的 kv 类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.设置最终输出 kv 类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6.设置输入和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job,<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\inputword&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output&quot;</span>));<span class="comment">//注意：这个output目录不能提前存在</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//7.提交 job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);<span class="comment">//如果成功返回0，失败返回1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-本地测试"><a href="#4-本地测试" class="headerlink" title="4. 本地测试"></a>4. 本地测试</h5><p>运行Driver类的main()方法，在输出目录output中查看如下输出结果：</p>
<p><img src="Snipaste_2023-09-26_12-05-19.png" alt="Snipaste_2023-09-26_12-05-19"></p>
<p>可以发现有四个文件，其中真正的数据结果文件是part-r-00000，文件内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">atguigu	2</span><br><span class="line">banzhang	1</span><br><span class="line">cls	2</span><br><span class="line">hadoop	1</span><br><span class="line">jiao	1</span><br><span class="line">ss	2</span><br><span class="line">xue	1</span><br></pre></td></tr></table></figure>

<p>已经对原文件进行了词频统计</p>
<h5 id="5-集群测试"><a href="#5-集群测试" class="headerlink" title="5. 集群测试"></a>5. 集群测试</h5><p>在pom.xml文件中添加打包插件依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>因为程序最重要被提交到集群上运行，所以输入路径和输出路径不是在代码中设置的，而是通过参数传入的，将输入路径和输出路径的设置代码修改如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.setInputPaths(job,<span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br></pre></td></tr></table></figure>

<p>将程序打包成jar包，操作如下：</p>
<p><img src="Snipaste_2023-09-26_12-51-41.png" alt="Snipaste_2023-09-26_12-51-41"></p>
<p>将此jar包复制到桌面并重命名为WC.jar，并将该jar包复制到&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;路径下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# ll</span><br><span class="line">总用量 212</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     183 9月  12 2019 bin</span><br><span class="line">drwxr-xr-x. 4 root root     37 9月  15 11:02 data</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 etc</span><br><span class="line">drwxr-xr-x. 2 wyh  wyh     106 9月  12 2019 include</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh      20 9月  12 2019 lib</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh     288 9月  12 2019 libexec</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh  147145 9月   4 2019 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1 root root      7 9月  17 21:04 liubei.txt</span><br><span class="line">drwxrwxrwx. 3 root root   4096 9月  26 11:41 logs</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh   21867 9月   4 2019 NOTICE.txt</span><br><span class="line">-rw-rw-r--. 1 wyh  wyh    1366 9月   4 2019 README.txt</span><br><span class="line">drwxr-xr-x. 3 wyh  wyh    4096 9月  14 22:32 sbin</span><br><span class="line">drwxr-xr-x. 4 wyh  wyh      31 9月  12 2019 share</span><br><span class="line">-rw-r--r--. 1 root root     14 9月  17 21:14 shuguo2.txt</span><br><span class="line">-rw-r--r--. 1 root root     14 9月  17 21:10 shuguo.txt</span><br><span class="line">drwxr-xr-x. 2 root root     22 8月   7 10:36 wcinput</span><br><span class="line">-rw-r--r--. 1 root root   9910 9月  26 12:50 WC.jar   # jar包在这里</span><br><span class="line">drwxr-xr-x. 2 root root     88 8月   7 10:45 wcoutput</span><br><span class="line">-rw-r--r--. 1 root root      7 9月  17 20:31 weiguo.txt</span><br><span class="line">-rw-r--r--. 1 root root      6 9月  17 20:42 wuguo.txt</span><br></pre></td></tr></table></figure>

<p>启动hadoop集群；</p>
<p>执行WC.jar</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop jar WC.jar com.atguigu.mapreduce.wordcount2.WordCountDriver /input /output2</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">其中，com.atguigu.mapreduce.wordcount2.WordCountDriver为全类名。HDFS的/input目录下有一个word.txt文件，要将结果输出在output2目录下（要求output2目录之前不存在）</span></span><br></pre></td></tr></table></figure>

<p>程序执行成功：</p>
<img src="Snipaste_2023-09-26_13-05-13.png" alt="Snipaste_2023-09-26_13-05-13" style="zoom: 33%;">

<p><img src="Snipaste_2023-09-26_13-05-45.png" alt="Snipaste_2023-09-26_13-05-45"></p>
<h3 id="5-3-Hadoop的序列化"><a href="#5-3-Hadoop的序列化" class="headerlink" title="5.3 Hadoop的序列化"></a>5.3 Hadoop的序列化</h3><h4 id="5-3-1-序列化的概念"><a href="#5-3-1-序列化的概念" class="headerlink" title="5.3.1 序列化的概念"></a>5.3.1 序列化的概念</h4><p>序列化是指将<strong>内存</strong>中的对象转换成字节序列（或其他数据传输协议），以便将其存储于<strong>磁盘</strong>中（持久化存储）或进行网络传输的过程。</p>
<p>反序列化是指将收到的字节序列（或其他数据传输协议）或<strong>磁盘</strong>中的持久化数据转换成<strong>内存</strong>中对象的过程。</p>
<p>通过序列化可以将对象在进程之间进行<strong>通信</strong>，以及使对象<strong>持久化存储</strong>。</p>
<p>Java具有一套序列化机制（Writable），但是Java的序列化机制是一个重量级的序列化框架（Serializable）。一个对象在被序列化后，会附带很多额外信息，不便于在网络中高效传输。所以，Hadoop开发了一套自己的序列化机制。</p>
<p><strong>Hadoop序列化机制的特点：</strong></p>
<ul>
<li>紧凑：紧凑的格式有助于高效使用存储空间，充分利用网络带宽</li>
<li>快速：序列化和反序列化的性能开销很小，可以实现进程之间的快速通信</li>
<li>互操作：统一的序列化框架可以支持多语言和服务器的交互</li>
</ul>
<h4 id="5-3-2-Writable接口"><a href="#5-3-2-Writable接口" class="headerlink" title="5.3.2 Writable接口"></a>5.3.2 Writable接口</h4><p>Hadoop使用的序列化接口是Writable，在Writable接口中定义了两个方法，分别是<strong>write()方法和readFields()<strong>方法。write()方法主要用于将类中的信息</strong>写入</strong>DataOutput二进制流，readFields()方法主要用于从DataInput二进制流中<strong>读取</strong>信息。</p>
<ul>
<li>write()方法：序列化，内存——–&gt;磁盘</li>
<li>readFields()方法：反序列化，磁盘——–&gt;内存</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Writable</span> &#123;</span><br><span class="line">  <span class="comment">/** </span></span><br><span class="line"><span class="comment">   * Serialize the fields of this object to &lt;code&gt;out&lt;/code&gt;.</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> out &lt;code&gt;DataOuput&lt;/code&gt; to serialize this object into.</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** </span></span><br><span class="line"><span class="comment">   * Deserialize the fields of this object from &lt;code&gt;in&lt;/code&gt;.  </span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * &lt;p&gt;For efficiency, implementations should attempt to re-use storage in the </span></span><br><span class="line"><span class="comment">   * existing object where possible.&lt;/p&gt;</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> in &lt;code&gt;DataInput&lt;/code&gt; to deseriablize this object from.</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Hadoop为java中的基本数据类型提供了Writable接口的实现类，Writable接口的所有实现类都提供了get()方法和set()方法，分别用于获取和存储所封装的值。</p>
<p><img src="Snipaste_2023-09-25_09-30-13.png" alt="Snipaste_2023-09-25_09-30-13"></p>
<p><strong>用户不仅可以使用Hadoop提供的序列化数据类型，还可以自定义Writable接口的实现类，用于在Hadoop环境中实现序列化。</strong></p>
<h4 id="5-3-3-序列化案例实操"><a href="#5-3-3-序列化案例实操" class="headerlink" title="5.3.3 序列化案例实操"></a>5.3.3 序列化案例实操</h4><h5 id="（1）需求分析"><a href="#（1）需求分析" class="headerlink" title="（1）需求分析"></a>（1）需求分析</h5><p>有一个数据文件，存储了大量的手记号码、IP地址、浏览页面、上行流量、下行流量等信息，要求统计每个手记号码耗费的总上行流量、总下行流量、总流量</p>
<img src="Snipaste_2023-09-26_15-20-12.png" alt="Snipaste_2023-09-26_15-20-12" style="zoom:33%;">

<p>map输出kv和reduce输入kv：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  K(Text)          V(bean对象)</span><br><span class="line">(手记号码，(上行流量，下行流量，总流量))</span><br></pre></td></tr></table></figure>

<p>reduce输出kv：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  K(Text)          V(bean对象)</span><br><span class="line">(手记号码，(上行流量，下行流量，总流量))</span><br></pre></td></tr></table></figure>

<h5 id="（2）实现思路分析"><a href="#（2）实现思路分析" class="headerlink" title="（2）实现思路分析"></a>（2）实现思路分析</h5><p>在map阶段对接收的每行数据都进行切分，抽取关键字段（手记号码、上行流量、下行流量、总流量），将其封装成FlowBean对象，并且将手机号码字段设置为key，然后将数据输出。在reduce阶段，每次接收到同一个手机号码的一组FlowBean对象，都对这组FlowBean对象进行汇总，计算得到总流量，将手机号码字段设置为key，然后将数据输出。</p>
<img src="webwxgetmsgi666666mg.jpg" alt="webwxgetmsgi666666mg" style="zoom:50%;">

<h5 id="（3）编写MapReduce程序"><a href="#（3）编写MapReduce程序" class="headerlink" title="（3）编写MapReduce程序"></a>（3）编写MapReduce程序</h5><p>①编写FlowBean类，使其继承Writable接口：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: FlowBean</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.mapreduce.writable</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *  创建一个封装流量信息的JavaBean，要继承Writable接口，其中有三个重要属性，上行流量，</span></span><br><span class="line"><span class="comment"> *  下行流量，总流量</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2023/9/26 0026 15:37</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span> &#123; <span class="comment">//1.继承Writable接口</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> upFlow;<span class="comment">//上行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> downFlow;<span class="comment">//下行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> sumFlow;<span class="comment">//总流量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.提供无参构造器</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.get,set方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">()</span>&#123; <span class="comment">//相当于方法重载</span></span><br><span class="line">        <span class="built_in">this</span>.sumFlow = <span class="built_in">this</span>.upFlow + <span class="built_in">this</span>.downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;<span class="comment">//4.重写序列化方法</span></span><br><span class="line">        out.writeLong(upFlow);</span><br><span class="line">        out.writeLong(downFlow);</span><br><span class="line">        out.writeLong(sumFlow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//4.重写反序列化方法，注意反序列化的顺序和序列化的顺序完全一致，并且读取方法的调用方法于参数的类型也要一一对应</span></span><br><span class="line">        <span class="built_in">this</span>.upFlow = in.readLong();</span><br><span class="line">        <span class="built_in">this</span>.downFlow = in.readLong();</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = in.readLong();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//5.重写toString方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow + <span class="string">&quot;\t&quot;</span> + downFlow + <span class="string">&quot;\t&quot;</span> + sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>②编写Mapper接口：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: FlowMapper</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.mapreduce.writable</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2023/9/26 0026 16:00</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="keyword">private</span> <span class="type">FlowBean</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">    <span class="comment">//重写map方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, FlowBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1.获取一行数据，将其转换成字符串</span></span><br><span class="line">        <span class="comment">//1	  13736230513	192.196.100.1	www.atguigu.com	  2481	 24681	 200</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.切割数据</span></span><br><span class="line">        <span class="comment">//[1,13736230513,192.196.100.1,www.atguigu.com,2481,24681,200]</span></span><br><span class="line">        String[] split = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.抓取我们想要的数据</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">phone</span> <span class="operator">=</span> split[<span class="number">1</span>];<span class="comment">//手记号码</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">up</span> <span class="operator">=</span> split[split.length - <span class="number">3</span>];<span class="comment">//上行流量</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">down</span> <span class="operator">=</span> split[split.length - <span class="number">2</span>];<span class="comment">//下行流量</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">//4.封装</span></span><br><span class="line">        outK.set(phone);</span><br><span class="line">        outV.setUpFlow(Long.parseLong(up));</span><br><span class="line">        outV.setDownFlow(Long.parseLong(down));</span><br><span class="line">        outV.setSumFlow();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//5.写出outK,outV</span></span><br><span class="line">        context.write(outK, outV);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>③编写Reducer组件，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: FlowReducer</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.mapreduce.writable</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2023/9/26 0026 21:12</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, FlowBean, Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">FlowBean</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values, Reducer&lt;Text, FlowBean, Text, FlowBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">totalUp</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">long</span> <span class="variable">totalDown</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//1.遍历values，将其中的上行流量，下行流量分别累加</span></span><br><span class="line">        <span class="keyword">for</span> (FlowBean flowBean : values)&#123;</span><br><span class="line">            totalUp += flowBean.getUpFlow();</span><br><span class="line">            totalDown += flowBean.getDownFlow();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//2.封装outV</span></span><br><span class="line">        outV.setUpFlow(totalUp);</span><br><span class="line">        outV.setDownFlow(totalDown);</span><br><span class="line">        outV.setSumFlow();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//3.写出key和outV</span></span><br><span class="line">        context.write(key,outV);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>④编写Driver驱动类，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: FlowDriver</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.mapreduce.writable</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2023/9/26 0026 21:23</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取Job对象job</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.关联当前Driver类</span></span><br><span class="line">        job.setJarByClass(FlowDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关联Mapper组件和Reducer组件</span></span><br><span class="line">        job.setMapperClass(FlowMapper.class);</span><br><span class="line">        job.setReducerClass(FlowReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置map端输出KV的数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//5.设置程序最终输出KV的数据类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//6.设置程序的输入路径和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\inputflow&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output3&quot;</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//7.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>⑤运行Driver类中的main()方法，查看输出文件中的内容。由此可见，JavaBean对象通过实现Writable接口，可以实现进程之间的通信。</p>
<img src="Snipaste_2023-09-26_21-41-49.png" alt="Snipaste_2023-09-26_21-41-49" style="zoom:33%;">

<h3 id="5-4-MapReduce框架原理之InputFormat数据输入"><a href="#5-4-MapReduce框架原理之InputFormat数据输入" class="headerlink" title="5.4 MapReduce框架原理之InputFormat数据输入"></a>5.4 MapReduce框架原理之InputFormat数据输入</h3><p>MapReduce计算框架将数据的计算过程分为<strong>数据输入阶段</strong>、<strong>map阶段</strong>、<strong>reduce阶段</strong>和<strong>数据输出阶段</strong>。</p>
<p>在数据输入阶段，我们需要考虑<strong>如何划分数据，可以在提高任务并发度的同时提高集群性能</strong>。</p>
<img src="Snipaste_2023-09-27_12-20-44.png" alt="Snipaste_2023-09-27_12-20-44" style="zoom:50%;">

<h4 id="5-4-1-切片与MapTask并行度决定机制"><a href="#5-4-1-切片与MapTask并行度决定机制" class="headerlink" title="5.4.1 切片与MapTask并行度决定机制"></a>5.4.1 切片与MapTask并行度决定机制</h4><p>MapTask的并行度决定map阶段的任务处理并发度，进而影响整个Job的处理速度。</p>
<ul>
<li>数据块：Block是HDFS<strong>物理上</strong>把数据分成若干个数据块，<strong>数据块是HDFS的数据存储单位</strong>。</li>
<li>数据切片：指在<strong>逻辑上</strong>把输入数据进行切分，并不会在物理层面上将输入数据切分成片。<strong>数据切片是MapReduce程序计算输入数据的单位</strong>，一个数据切片可以对应启动一个MapTask。</li>
</ul>
<p>假设一个数据集由两个文件构成，这两个文件大小分别为300MB和100MB。假设将数据切片大小设置为128MB，那么会将这两个文件切分成4片，切片信息如下：</p>
<ul>
<li>split1：0~128MB</li>
<li>split2：129~256MB</li>
<li>split3：257~300MB</li>
<li>split4：1~100MB</li>
</ul>
<p>数据切片大小与数据块大小正好吻合，每个数据块都是一个数据切片：</p>
<img src="webwxgetmsgimg (1).jpg" alt="webwxgetmsgimg (1)" style="zoom: 33%;">

<hr>
<p>假设将数据切片大小设置为100MB，那么：</p>
<ul>
<li>split1：0~100MB</li>
<li>split2：101~200MB</li>
<li>split3：201~300MB</li>
<li>split4：0~100MB</li>
</ul>
<p>这时候数据切片大小与数据块大小不吻合：</p>
<img src="webwxgetmsgimg (2).jpg" alt="webwxgetmsgimg (2)" style="zoom:33%;">

<p>总结：</p>
<ol>
<li>一个Job的Map阶段并行度是由客户端在提交Job时的<strong>切片数</strong>决定的</li>
<li>默认情况下，数据切片大小与数据块大小相同，或者是数据块大小的倍数，即128MB或128MB的倍数（原因：与数据块大小相同的数据切片，可以保证一个MapTask处理的任务正好是一个数据块，Hadoop可以将该MapTask发送给数据块所在的节点服务器，实现计算的<strong>数据本地化</strong>，提高计算性能，节省带宽资源）</li>
<li>每一个切片分配一个MapTask并行实例处理。</li>
<li>切片时不考虑数据整体，只会针对数据集中的每个文件单独进行切片。</li>
</ol>
<h4 id="5-4-2-Job提交流程源码和FileInputFormat切片源码详解"><a href="#5-4-2-Job提交流程源码和FileInputFormat切片源码详解" class="headerlink" title="5.4.2 Job提交流程源码和FileInputFormat切片源码详解"></a>5.4.2 Job提交流程源码和FileInputFormat切片源码详解</h4><h5 id="1-Job提交流程源码详解"><a href="#1-Job提交流程源码详解" class="headerlink" title="1. Job提交流程源码详解"></a>1. Job提交流程源码详解</h5><p>在编写WordCount程序的代码时，在Driver类中，最后会通过Job对象job调用waitForCompletion()方法提交任务</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br></pre></td></tr></table></figure>

<p>去看waitForCompletion()方法源码，可以发现，最终调用submit()方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">waitForCompletion</span><span class="params">(<span class="type">boolean</span> verbose</span></span><br><span class="line"><span class="params">                                   )</span> <span class="keyword">throws</span> IOException, InterruptedException,</span><br><span class="line">                                            ClassNotFoundException &#123;</span><br><span class="line">    <span class="keyword">if</span> (state == JobState.DEFINE) &#123;</span><br><span class="line">      submit();</span><br><span class="line">    &#125;</span><br><span class="line">                                                </span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在submit()方法中，首先通过调用connect()方法建立连接，在建立连接时，首先通过现有配置文件获取Cluster对象，同时判断是本地运行环境还是YARN集群运行环境：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1 建立连接</span></span><br><span class="line">connect();</span><br><span class="line">    <span class="comment">// 1）创建提交 Job 的代理</span></span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Cluster</span>(getConfiguration());</span><br><span class="line">        <span class="comment">// （1）判断是本地运行环境还是 yarn 集群运行环境</span></span><br><span class="line">        initialize(jobTrackAddr, conf);</span><br></pre></td></tr></table></figure>

<p>在建立连接后，创建JobSubmiter的实例化对象submitter，submitter对象最终调用submitJobInternal()方法完成任务</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 2 提交 job</span></span><br><span class="line">submitter.submitJobInternal(Job.<span class="built_in">this</span>, cluster)</span><br></pre></td></tr></table></figure>

<p>进一步追溯submitJobInternal()方法，该方法中关键步骤源码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1）创建给集群提交数据的 Stag 路径</span></span><br><span class="line"><span class="type">Path</span> <span class="variable">jobStagingArea</span> <span class="operator">=</span> JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line"><span class="comment">// 2）获取 jobid ，并创建 Job 路径</span></span><br><span class="line"><span class="type">JobID</span> <span class="variable">jobId</span> <span class="operator">=</span> submitClient.getNewJobID();</span><br><span class="line"><span class="comment">// 3）拷贝 jar 包到集群</span></span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);</span><br><span class="line">rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"><span class="comment">// 4）计算切片，生成切片规划文件</span></span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line">maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">input.getSplits(job);<span class="comment">//使用InputFormat类的getSplits()方法对文件进行切分</span></span><br><span class="line"><span class="comment">// 5）向 Stag 路径写 XML 配置文件</span></span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line">conf.writeXml(out);</span><br><span class="line"><span class="comment">// 6）提交 Job,返回提交状态</span></span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(),job.getCredentials());</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-09-27_14-07-39.png" alt="Snipaste_2023-09-27_14-07-39"></p>
<h5 id="2-FileInputFormat切片源码详解"><a href="#2-FileInputFormat切片源码详解" class="headerlink" title="2. FileInputFormat切片源码详解"></a>2. FileInputFormat切片源码详解</h5><p>分析FileInputFormat类的源码。FileInputFormat类是所有使用文件作为其数据源的InputFormat实现类的基类，该类主要实现了两个功能，一个是指定作业的<strong>输入文件位置</strong>，另一个是将<strong>输入文件切分成数据分片</strong>的代码实现。</p>
<p>在提交任务时，使用以下代码指定输入文件路径</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.setInputPaths(job,<span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br></pre></td></tr></table></figure>

<p>查看FileInputFormat类源码，搜索getSplits()方法，对文件的分片逻辑主要体现在这个方法的实现中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;InputSplit&gt; <span class="title function_">getSplits</span><span class="params">(JobContext job)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">StopWatch</span> <span class="variable">sw</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StopWatch</span>().start();</span><br><span class="line">    <span class="type">long</span> <span class="variable">minSize</span> <span class="operator">=</span> Math.max(getFormatMinSplitSize(), getMinSplitSize(job));</span><br><span class="line">    <span class="type">long</span> <span class="variable">maxSize</span> <span class="operator">=</span> getMaxSplitSize(job);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// generate splits</span></span><br><span class="line">    List&lt;InputSplit&gt; splits = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;InputSplit&gt;();</span><br><span class="line">    List&lt;FileStatus&gt; files = listStatus(job);<span class="comment">//（1）程序先找到数据存储的目录</span></span><br><span class="line"></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">ignoreDirs</span> <span class="operator">=</span> !getInputDirRecursive(job)</span><br><span class="line">      &amp;&amp; job.getConfiguration().getBoolean(INPUT_DIR_NONRECURSIVE_IGNORE_SUBDIRS, <span class="literal">false</span>);</span><br><span class="line">    <span class="keyword">for</span> (FileStatus file: files) &#123;<span class="comment">//（2）开始遍历处理（规划切片）数据存储目录下的每个文件</span></span><br><span class="line">      <span class="keyword">if</span> (ignoreDirs &amp;&amp; file.isDirectory()) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> file.getPath();</span><br><span class="line">      <span class="type">long</span> <span class="variable">length</span> <span class="operator">=</span> file.getLen();<span class="comment">//（3）-①遍历第一个文件，获取文件大小</span></span><br><span class="line">      <span class="keyword">if</span> (length != <span class="number">0</span>) &#123;</span><br><span class="line">        BlockLocation[] blkLocations;</span><br><span class="line">        <span class="keyword">if</span> (file <span class="keyword">instanceof</span> LocatedFileStatus) &#123;</span><br><span class="line">          blkLocations = ((LocatedFileStatus) file).getBlockLocations();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> path.getFileSystem(job.getConfiguration());</span><br><span class="line">          blkLocations = fs.getFileBlockLocations(file, <span class="number">0</span>, length);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (isSplitable(job, path)) &#123;</span><br><span class="line">          <span class="type">long</span> <span class="variable">blockSize</span> <span class="operator">=</span> file.getBlockSize();</span><br><span class="line">          <span class="type">long</span> <span class="variable">splitSize</span> <span class="operator">=</span> computeSplitSize(blockSize, minSize, maxSize);<span class="comment">//（3）-②计算数据切片大小，计算公式看下面</span></span><br><span class="line"></span><br><span class="line">          <span class="type">long</span> <span class="variable">bytesRemaining</span> <span class="operator">=</span> length;</span><br><span class="line">          <span class="keyword">while</span> (((<span class="type">double</span>) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123;<span class="comment">//(3)-③在每次进行切片操作时，都要判断剩余部分是否大于数据切片大小的1.1倍，如果剩余部分不大于数据切片大小的1.1倍，则将剩余部分划分为一个数据切片</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">blkIndex</span> <span class="operator">=</span> getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class="line">            splits.add(makeSplit(path, length-bytesRemaining, splitSize,</span><br><span class="line">                        blkLocations[blkIndex].getHosts(),</span><br><span class="line">                        blkLocations[blkIndex].getCachedHosts()));</span><br><span class="line">            bytesRemaining -= splitSize;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> (bytesRemaining != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">blkIndex</span> <span class="operator">=</span> getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class="line">            splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining,</span><br><span class="line">                       blkLocations[blkIndex].getHosts(),</span><br><span class="line">                       blkLocations[blkIndex].getCachedHosts()));</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// not splitable</span></span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">            <span class="comment">// Log only if the file is big enough to be splitted</span></span><br><span class="line">            <span class="keyword">if</span> (length &gt; Math.min(file.getBlockSize(), minSize)) &#123;</span><br><span class="line">              LOG.debug(<span class="string">&quot;File is not splittable so no parallelization &quot;</span></span><br><span class="line">                  + <span class="string">&quot;is possible: &quot;</span> + file.getPath());</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          splits.add(makeSplit(path, <span class="number">0</span>, length, blkLocations[<span class="number">0</span>].getHosts(),</span><br><span class="line">                      blkLocations[<span class="number">0</span>].getCachedHosts()));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        <span class="comment">//Create empty hosts array for zero length files</span></span><br><span class="line">        splits.add(makeSplit(path, <span class="number">0</span>, length, <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">0</span>]));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Save the number of input files for metrics/loadgen</span></span><br><span class="line">    job.getConfiguration().setLong(NUM_INPUT_FILES, files.size());</span><br><span class="line">    sw.stop();</span><br><span class="line">    <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">&quot;Total # of splits generated by getSplits: &quot;</span> + splits.size()</span><br><span class="line">          + <span class="string">&quot;, TimeTaken: &quot;</span> + sw.now(TimeUnit.MILLISECONDS));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> splits;<span class="comment">//List&lt;InputSplit&gt; splits = new ArrayList&lt;InputSplit&gt;();将数据切片信息写入一个数据切片规划列表InputSplit，InputSplit中只记录数据切片的元数据信息，如起始位置、长度、所在节点列表等。</span></span><br><span class="line">  &#125;</span><br><span class="line"><span class="comment">//（4）在切片操作完成后，将数据切片规划文件提交到YARN中，YARN中的MRAppMaster进程可以根据数据切片规划文件计算需要开启的MapTask数量（几个数据切片就开启几个MapTask实例）</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//计算数据切片大小的重要公式：</span></span><br><span class="line"><span class="keyword">protected</span> <span class="type">long</span> <span class="title function_">computeSplitSize</span><span class="params">(<span class="type">long</span> blockSize, <span class="type">long</span> minSize, <span class="type">long</span> maxSize)</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> Math.max(minSize, Math.min(maxSize, blockSize));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>属性</th>
<th>数据类型</th>
<th>默认值（单位：字节）</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.input.fileinputformat.split.minsize</td>
<td>int</td>
<td>1</td>
<td>一个文件分片中最小的有效字节数</td>
</tr>
<tr>
<td>mapreduce.input.fileinputformat.split.maxsize</td>
<td>long</td>
<td>long.MAX_VALUE，即9223372036854775807</td>
<td>一个文件分片中最大的有效字节数</td>
</tr>
<tr>
<td>dfs.blocksize</td>
<td>long</td>
<td>134217728，即128MB</td>
<td>HDFS中数据块的大小</td>
</tr>
</tbody></table>
<p>在默认情况下，minsize&lt;blocksize&lt;maxsize，所以blocksize属性值表示默认的数据切片大小。在理论上，我们可以通过调整这3个关键属性的值调整数据切片的大小，但是与数据块大小相同的数据切片大小是最合理的。</p>
<p>切片大小的相关设置如下：</p>
<ul>
<li>maxsize（数据切片的最大值）：如果该属性的值比blocksize属性的值小，则会让数据切片变小，相当于配置这个属性的值</li>
<li>minsize（数据切片的最小值）：如果该属性的值比blocksize属性的值大，则会让数据切片大小变得比blocksize属性的值还大</li>
</ul>
<img src="Snipaste_2023-09-27_15-33-02.png" alt="Snipaste_2023-09-27_15-33-02" style="zoom:50%;">

<h4 id="5-4-3-FileInputFormat切片机制总结"><a href="#5-4-3-FileInputFormat切片机制总结" class="headerlink" title="5.4.3 FileInputFormat切片机制总结"></a>5.4.3 FileInputFormat切片机制总结</h4><h5 id="1-切片机制"><a href="#1-切片机制" class="headerlink" title="1. 切片机制"></a>1. 切片机制</h5><img src="Snipaste_2023-09-27_15-35-37.png" alt="Snipaste_2023-09-27_15-35-37" style="zoom: 50%;">

<h5 id="2-案例分析"><a href="#2-案例分析" class="headerlink" title="2. 案例分析"></a>2. 案例分析</h5><img src="Snipaste_2023-09-27_15-36-35.png" alt="Snipaste_2023-09-27_15-36-35" style="zoom:50%;">

<h5 id="3-参数设置"><a href="#3-参数设置" class="headerlink" title="3. 参数设置"></a>3. 参数设置</h5><p>略</p>
<h4 id="5-4-4-TextInputFormat"><a href="#5-4-4-TextInputFormat" class="headerlink" title="5.4.4 TextInputFormat"></a>5.4.4 TextInputFormat</h4><h5 id="1-FileInputFormat接口的实现类"><a href="#1-FileInputFormat接口的实现类" class="headerlink" title="1.FileInputFormat接口的实现类"></a>1.FileInputFormat接口的实现类</h5><p>在运行 MapReduce 程序时，输入的文件格式包括：基于行的日志文件、二进制格式文件、数据库表等。那么，针对不同的数据类型，MapReduce 是如何读取这些数据的呢？</p>
<p>FileInputFormat 常见的接口实现类包括：TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat 和自定义 InputFormat 等。</p>
<h5 id="2-TextInputFormat"><a href="#2-TextInputFormat" class="headerlink" title="2. TextInputFormat"></a>2. TextInputFormat</h5><p>TextInputFormat是进行普通文件输入的默认FileInputFormat接口实现类，可以<strong>按行</strong>读取每条记录，读取的键是<strong>该行在整个文件中的起始字节偏移量</strong>，数据类型为LongWritable类型；读取的值是<strong>该行的内容</strong>，不包括任何行终止符（换行符和回车符），数据类型为Text类型。</p>
<p>以下是一个示例，比如，一个分片包含了如下 4 条文本记录。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Rich learning form</span><br><span class="line">Intelligent learning engine</span><br><span class="line">Learning more convenient</span><br><span class="line">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>

<p>每条记录表示为以下键&#x2F;值对：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(0,Rich learning form)</span><br><span class="line">(20,Intelligent learning engine)</span><br><span class="line">(49,Learning more convenient)</span><br><span class="line">(74,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>

<h4 id="5-4-5-CombineTextInputFormat切片机制"><a href="#5-4-5-CombineTextInputFormat切片机制" class="headerlink" title="5.4.5 CombineTextInputFormat切片机制"></a>5.4.5 CombineTextInputFormat切片机制</h4><p> 框架默认的 TextInputFormat 切片机制是对任务按文件规划切片（一个文件，一个切片），不管文件多小，都会是一个单独的切片，都会交给一个 MapTask，这样如果有<strong>大量小文件</strong>，就会产生大量的MapTask，处理效率极其低下。</p>
<p>CombineTextInputFormat 用于<strong>小文件过多的场景</strong>，它可以将<strong>多个小文件</strong>从逻辑上规划到<strong>一个切片</strong>中，这样，多个小文件就可以交给一个 MapTask 处理。</p>
<p>通过以下代码设置数据切片的最大值：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);<span class="comment">// 4m</span></span><br></pre></td></tr></table></figure>

<p>CombineTextInputFormat切片机制的具体切片过程分为两部分，分别为虚拟存储过程和切片过程：</p>
<h5 id="1-虚拟存储过程"><a href="#1-虚拟存储过程" class="headerlink" title="1. 虚拟存储过程"></a>1. 虚拟存储过程</h5><p>将输入目录所有文件的大小 filesize 依次与设置的 setMaxInputSplitSize 值进行比较：</p>
<p>filesize &lt;&#x3D;  setMaxInputSplitSize，在逻辑上将其划分为一个虚拟存储块；</p>
<p>filesize &gt; 2*setMaxInputSplitSize，以setMaxInputSplitSize值划分第一个虚拟存储块；</p>
<p>setMaxInputSplitSize &lt; filesize &lt;&#x3D; 2*setMaxInputSplitSize，将文件均分为两个虚拟存储块；</p>
<h5 id="2-切片过程"><a href="#2-切片过程" class="headerlink" title="2. 切片过程"></a>2. 切片过程</h5><p>判断虚拟存储块的大小和setMaxInputSplitSize的大小：</p>
<p>虚拟存储块大小 &gt;&#x3D; setMaxInputSplitSize，将其单独划分为一个数据切片；</p>
<p>虚拟存储块大小 &lt; setMaxInputSplitSize，将与其下一个虚拟存储块进行合并，共同划分为一个数据切片；</p>
<p><img src="%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6(2).jpg" alt="未命名文件(2)"></p>
<h4 id="5-4-6-CombineTextInputFormat案例教程"><a href="#5-4-6-CombineTextInputFormat案例教程" class="headerlink" title="5.4.6 CombineTextInputFormat案例教程"></a>5.4.6 CombineTextInputFormat案例教程</h4><p>下面使用CombineTextInputFormat作为MapReduce的InputFormat，测试其对小文件的处理效果。准备4个小文件作为输入文件，期望将4个小文件合并成一个数据切片进行统一处理。4个输入文件的大小如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a.txt  1.7MB</span><br><span class="line">b.txt  5.1MB</span><br><span class="line">c.txt  3.4MB</span><br><span class="line">d.txt  6.8MB</span><br></pre></td></tr></table></figure>

<p>不进行任何处理，使用原来的WordCount程序，直接将这4个文件输入</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.setInputPaths(job,<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\inputcombinetextinputformat&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\outputCombine1&quot;</span>));</span><br></pre></td></tr></table></figure>

<p>观察控制台中打印的日志，可以发现产生了4个数据切片（4个文件就有4个切片）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2023-09-27 17:19:42,685 INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:4</span><br></pre></td></tr></table></figure>

<p>在 WordcountDriver 中增加如下代码，运行程序</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置 InputFormat，它默认用的是 TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置 4m</span></span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);</span><br></pre></td></tr></table></figure>

<p>可以看到，运行结果为3个切片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2023-09-27 17:25:28,331 INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:3</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置 InputFormat，它默认用的是 TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置 20m</span></span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">20971520</span>);</span><br></pre></td></tr></table></figure>

<p>可以看到，运行结果为1个切片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2023-09-27 17:27:48,003 INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:1</span><br></pre></td></tr></table></figure>

<h3 id="5-5-MapReduce框架原理之shuffle机制"><a href="#5-5-MapReduce框架原理之shuffle机制" class="headerlink" title="5.5 MapReduce框架原理之shuffle机制"></a>5.5 MapReduce框架原理之shuffle机制</h3><p>MapReduce执行排序操作并将map阶段输出的数据传递给reduce阶段的过程称为<strong>shuffle</strong>，shuffle阶段是MapReduce程序的核心阶段。</p>
<h4 id="5-5-1-shuffle机制"><a href="#5-5-1-shuffle机制" class="headerlink" title="5.5.1 shuffle机制"></a>5.5.1 shuffle机制</h4><p><img src="Snipaste_2023-09-28_13-48-05.png" alt="Snipaste_2023-09-28_13-48-05"></p>
<h4 id="5-5-2-分区"><a href="#5-5-2-分区" class="headerlink" title="5.5.2 分区"></a>5.5.2 分区</h4><h5 id="1-问题引出"><a href="#1-问题引出" class="headerlink" title="1. 问题引出"></a>1. 问题引出</h5><p>要求将统计结果<strong>按照条件</strong>输出到<strong>不同的分区（Partition）</strong>中，比如将统计结果按照手记归属地输出到不同分区中。</p>
<h5 id="2-默认分区器HashPartitioner"><a href="#2-默认分区器HashPartitioner" class="headerlink" title="2. 默认分区器HashPartitioner"></a>2. 默认分区器HashPartitioner</h5><p>默认分区器是根据key的hashCode对ReduceTask的数量取模得到的。用户没法控制哪个key存储于哪个分区中，源码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashPartitioner</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;K, V&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Use &#123;<span class="doctag">@link</span> Object#hashCode()&#125; to partition. */</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(K key, V value, <span class="type">int</span> numReduceTasks)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一个小实验：我们在最初的WordCount程序中的WordCountDriver类中添加如下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(<span class="number">2</span>);<span class="comment">//将ReduceTask个数设置为2，则最后会产生两个结果文件</span></span><br></pre></td></tr></table></figure>

<p>运行程序，可以发现最后是两个文件：</p>
<p><img src="Snipaste_2023-09-28_14-04-43.png" alt="Snipaste_2023-09-28_14-04-43"></p>
<img src="Snipaste_2023-09-28_14-06-33.png" alt="Snipaste_2023-09-28_14-06-33" style="zoom:50%;">

<p>这种情况下分区标准只和hashcoed值有关，如果想自定义分区方式，只能自定义分区器。</p>
<h5 id="3-自定义分区器"><a href="#3-自定义分区器" class="headerlink" title="3. 自定义分区器"></a>3. 自定义分区器</h5><p>①自定义继承Partitioner接口的类，需要指定两个泛型，分别是该自定义分区器要应用的MapReduce程序中的Mapper输出键和输出值的数据类型；并且需要重写getPartition()，在该方法中编写代码逻辑，实现通过不同的键返回分区值，分区值是int类型的数据。例如，如果希望最终得到5个分区，则返回0~4的整数分区值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomPartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt; &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text key, FlowBean value, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">        <span class="comment">// 控制分区代码逻辑</span></span><br><span class="line">        … …</span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>②在Job驱动中，设置自定义Partitioner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setPartitionerClass(CustomPartitioner.class);</span><br></pre></td></tr></table></figure>

<p>③自定义Partition后，要根据自定义Partitioner的逻辑设置相应数量的ReduceTask，如果自定义分区器中的逻辑指定返回的分区值为0~4，则需要将ReduceTask的数量设置为5个</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>

<h5 id="4-分区总结"><a href="#4-分区总结" class="headerlink" title="4. 分区总结"></a>4. 分区总结</h5><ul>
<li>如果ReduceTask的数量&gt; getPartition的结果数，则会多产生几个空的输出文件part-r-000xx；</li>
<li>如果1&lt;ReduceTask的数量&lt;getPartition的结果数，则有一部分分区数据无处安放，会Exception报错；</li>
<li>如 果ReduceTask的数量&#x3D;1，则不管MapTask端输出多少个分区文件，最终结果都交给这一个ReduceTask，最终也就只会产生一个结果文件 part-r-00000；</li>
<li>分区号必须从零开始，逐一累加。</li>
</ul>
<p>总结：尽量使ReduceTask的数量与getPartition()方法的返回值保持一致</p>
<h4 id="5-5-3-分区案例实操"><a href="#5-5-3-分区案例实操" class="headerlink" title="5.5.3 分区案例实操"></a>5.5.3 分区案例实操</h4><h5 id="1-需求分析"><a href="#1-需求分析" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h5><p>在统计每个手机号码耗费的总上行流量、总下行流量、总流量的基础上，使用自定义分区器，将统计结果按照手机归属地的省份输出到不同的文件中。</p>
<p>①输入数据：</p>
<img src="Snipaste_2023-09-26_15-20-12.png" alt="Snipaste_2023-09-26_15-20-12" style="zoom:33%;">

<p>②期望效果：</p>
<p>把手机号码开头为136、137、138、139的数据分别存储于4个独立文件中，将其他数据存储于1个文件中。</p>
<img src="Snipaste_2023-09-28_14-50-52.png" alt="Snipaste_2023-09-28_14-50-52" style="zoom:33%;">

<h5 id="2-需求实现"><a href="#2-需求实现" class="headerlink" title="2. 需求实现"></a>2. 需求实现</h5><p>增加自定义分区器ProvincePartitioner，编写分区逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text,FlowBean&gt; &#123;<span class="comment">//泛型要和Map的输出键值保持一致</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text text, FlowBean flowBean, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">        <span class="comment">//Text是手机号，获取手机号的前三位prePhone</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">phone</span> <span class="operator">=</span> text.toString();</span><br><span class="line">        <span class="type">String</span> <span class="variable">prePhone</span> <span class="operator">=</span> phone.substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定义一个分区号变量partition,根据prePhone的值设置分区号</span></span><br><span class="line">        <span class="type">int</span> partition;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;136&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;137&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;138&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">2</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;139&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">3</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            partition = <span class="number">4</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//最后返回分区号partition</span></span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在驱动类FlowDriver，配置自定义分区器，并设置ReduceTask的数量：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//指定自定义分区类</span></span><br><span class="line">job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//同时指定相应数量的ReduceTask</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure>

<p>设置完毕后，重写运行程序，查看运行过程中ReduceTask的数量及输出的文件数量，输出文件如下：</p>
<img src="Snipaste_2023-09-28_15-12-49.png" alt="Snipaste_2023-09-28_15-12-49" style="zoom:50%;">

<p><img src="Snipaste_2023-09-28_15-14-17.png" alt="Snipaste_2023-09-28_15-14-17"></p>
<p>可以发现，成功分区</p>
<p>如果将ReduceTask的数量设置为1个，重新运行程序，再次查看输出文件夹，发现只输出了一个结果文件，实际上分区失效</p>
<img src="Snipaste_2023-09-28_15-21-02.png" alt="Snipaste_2023-09-28_15-21-02" style="zoom:50%;">

<p>将ReduceTask的数量设置为6个，重新运行程序，再次查看输出文件夹，共输出了6个结果文件，但其中一个是空文件</p>
<img src="Snipaste_2023-09-28_15-23-33.png" alt="Snipaste_2023-09-28_15-23-33" style="zoom:50%;">

<h4 id="5-5-4-WritableComparable排序"><a href="#5-5-4-WritableComparable排序" class="headerlink" title="5.5.4 WritableComparable排序"></a>5.5.4 WritableComparable排序</h4><p>MapTask和ReduceTask均会对数据<strong>按照key</strong>进行排序。该操作属于Hadoop的默认行为。<strong>任何应用程序中的数据均会被排序，而不管逻辑上是否需要</strong>。</p>
<p>默认排序是按照<strong>字典顺序排序</strong>，且实现该排序的方法是<strong>快速排序</strong>。</p>
<p>对于MapTask，它会将处理的结果暂时放到环形缓冲区中，当环形缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次快速排序，并将这些有序数据溢写到磁盘上，而当数据处理完毕后，它会对磁盘上所有文件进行归并排序。对于ReduceTask，它从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储在内存中。如果磁盘上文件数目达到一定阈值，则进行一次归并排序以生成一个更大文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。当所有数据拷贝完毕后，<strong>ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序</strong>。</p>
<p>以上过程中提到的排序都是针对<strong>数据的键</strong>进行的，在不进行配置的情况下，必须使用Hadoop提供的序列化类，如Text类，IntWritable类等。若用户使用自定义JavaBean作为键，则需要使其继承（实现）<strong>WritableComparable接口</strong>，重写该接口中的**compareTo()**方法，定义比较逻辑。</p>
<hr>
<p>排序分类：</p>
<ul>
<li>部分排序（生产环境中常用）：MapReduce根据输入记录的键对数据集排序。<strong>保证输出的每个文件内部有序</strong>。</li>
<li>全排序（生产环境下慎用）：最终输出结果只有一个文件，并且文件内部有序。实现方式是只设置一个ReduceTask。但该方法在处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduce所提供的并行架构。</li>
<li>二次排序（自定义排序）：在自定义排序过程中，如果compareTo()方法中的判断条件为两个即为二次排序。</li>
</ul>
<h4 id="5-5-5-WritableComparable排序案例实操（全排序）"><a href="#5-5-5-WritableComparable排序案例实操（全排序）" class="headerlink" title="5.5.5 WritableComparable排序案例实操（全排序）"></a>5.5.5 WritableComparable排序案例实操（全排序）</h4><h5 id="1-需求分析-1"><a href="#1-需求分析-1" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h5><p>针对以下输出结果进行倒序排列</p>
<img src="Snipaste_2023-09-28_20-22-50.png" alt="Snipaste_2023-09-28_20-22-50" style="zoom:33%;">

<p>期望输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">13509468723 7335 110349 117684</span><br><span class="line">13736230513 2481 24681 27162</span><br><span class="line">13956435636 132 1512 1644</span><br><span class="line">13846544121 264 0 264</span><br><span class="line">。。。 。。。</span><br></pre></td></tr></table></figure>

<h5 id="2-实现思路分析"><a href="#2-实现思路分析" class="headerlink" title="2. 实现思路分析"></a>2. 实现思路分析</h5><p>将FlowBean对象作为map阶段的输出键，然后使FlowBean继承WritableComparable接口，在重写compareTo()方法时，编写按照总流量倒序排列的代码逻辑。</p>
<p>在map()方法中，将FlowBean对象作为键，将手机号码作为值输出，即可按照FlowBean对象中的总流量进行排序。</p>
<p>在reduce()方法中，输入值是以迭代器的形式给出的，所以我们遍历这个迭代器，与输入键重新组合并交换位置输出，使最后输出的数据依然是手机号码在前、流量在后，与期望输出数据相同。</p>
<h5 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3. 代码实现"></a>3. 代码实现</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//使FlowBean继承WritableComparable接口，重写compareTo()方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;FlowBean&gt; &#123; <span class="comment">//1.继承WritableComparable接口</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> upFlow;<span class="comment">//上行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> downFlow;<span class="comment">//下行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> sumFlow;<span class="comment">//总流量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.提供无参构造器</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.get,set方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">()</span>&#123; <span class="comment">//相当于方法重载</span></span><br><span class="line">        <span class="built_in">this</span>.sumFlow = <span class="built_in">this</span>.upFlow + <span class="built_in">this</span>.downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;<span class="comment">//4.重写序列化方法</span></span><br><span class="line">        out.writeLong(upFlow);</span><br><span class="line">        out.writeLong(downFlow);</span><br><span class="line">        out.writeLong(sumFlow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//4.重写反序列化方法，注意反序列化的顺序和序列化的顺序完全一致，并且读取方法的调用方法于参数的类型也要一一对应</span></span><br><span class="line">        <span class="built_in">this</span>.upFlow = in.readLong();</span><br><span class="line">        <span class="built_in">this</span>.downFlow = in.readLong();</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = in.readLong();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//5.重写toString方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow + <span class="string">&quot;\t&quot;</span> + downFlow + <span class="string">&quot;\t&quot;</span> + sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//重写compareTo方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">        <span class="comment">//按照总流量进行比较，并进行倒序排序</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.sumFlow &gt; o.sumFlow)&#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.sumFlow &lt; o.sumFlow)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//编写Mapper类，在map()方法中将FlowBean作为键、将手机号码作为值输出</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, FlowBean,Text&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">FlowBean</span> <span class="variable">outK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, FlowBean, Text&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1.获取一行数据</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.按照“\t”符号切割数据</span></span><br><span class="line">        String[] split = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.封装outK,outV</span></span><br><span class="line">        outK.setUpFlow(Long.parseLong(split[<span class="number">1</span>]));</span><br><span class="line">        outK.setDownFlow(Long.parseLong(split[<span class="number">2</span>]));</span><br><span class="line">        outK.setSumFlow();</span><br><span class="line">        outV.set(split[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.写出outK,outV</span></span><br><span class="line">        context.write(outK, outV);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//编写Reducer类，输入数据的泛型需要与Mapper类输出数据的泛型保持一致，输出键的泛型为FlowBean，输出值的泛型为Text</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;FlowBean, Text, Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(FlowBean key, Iterable&lt;Text&gt; values, Reducer&lt;FlowBean, Text, Text, FlowBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//遍历values迭代器</span></span><br><span class="line">        <span class="keyword">for</span> (Text value : values)&#123;</span><br><span class="line">            <span class="comment">//调换KV位置，反向写出</span></span><br><span class="line">            context.write(value,key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//编写Driver类，进行必要设置</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取Job对象job</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.关联当前Driver类</span></span><br><span class="line">        job.setJarByClass(FlowDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关联Mapper组件和Reducer组件</span></span><br><span class="line">        job.setMapperClass(FlowMapper.class);</span><br><span class="line">        job.setReducerClass(FlowReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置map端输出KV的数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(FlowBean.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//5.设置程序最终输出KV的数据类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//6.设置程序的输入路径和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output3&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output555&quot;</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//7.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行程序，查看输出结果，可以看到按照总流量的倒序排列了：</p>
<img src="Snipaste_2023-09-28_21-10-40.png" alt="Snipaste_2023-09-28_21-10-40" style="zoom:33%;">

<p>修改compareTo()方法，使得总流量相同时候，按照上行流量进行倒序排序</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//重写compareTo方法</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">    <span class="comment">//按照总流量进行比较，并进行倒序排序</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">this</span>.sumFlow &gt; o.sumFlow)&#123;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.sumFlow &lt; o.sumFlow)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//如果总流量相同，按照上行流量倒序排序</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.upFlow &gt; o.upFlow)&#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.upFlow &lt; o.upFlow)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行程序，查看输出结果：</p>
<img src="Snipaste_2023-09-28_21-24-14.png" alt="Snipaste_2023-09-28_21-24-14" style="zoom:33%;">

<h4 id="5-5-6-WritableComparable排序案例实操（区内排序）"><a href="#5-5-6-WritableComparable排序案例实操（区内排序）" class="headerlink" title="5.5.6 WritableComparable排序案例实操（区内排序）"></a>5.5.6 WritableComparable排序案例实操（区内排序）</h4><h5 id="1-需求分析-2"><a href="#1-需求分析-2" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h5><p>要求每个省份（136，137，138，139……）手机号输出的文件中按照总流量内部排序</p>
<h5 id="2-实现思路分析-1"><a href="#2-实现思路分析-1" class="headerlink" title="2. 实现思路分析"></a>2. 实现思路分析</h5><p>增加自定义分区器，按照省份手机号码设置分区</p>
<img src="Snipaste_2023-09-28_21-29-13.png" alt="Snipaste_2023-09-28_21-29-13" style="zoom:50%;">

<h5 id="3-案例实操"><a href="#3-案例实操" class="headerlink" title="3. 案例实操"></a>3. 案例实操</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//自定义分区器ProvincePartitioner2，指定泛型需要与Mapper类输出数据的泛型保持一致</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner2</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;FlowBean, Text&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(FlowBean flowBean, Text text, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">        <span class="comment">//获取手机号码前三位</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">phone</span> <span class="operator">=</span> text.toString();</span><br><span class="line">        <span class="type">String</span> <span class="variable">prePhone</span> <span class="operator">=</span> phone.substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定义一个分区号变量partition，根据prePhone的值设置分区号</span></span><br><span class="line">        <span class="type">int</span> partition;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;136&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;137&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;138&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">2</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;139&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">3</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            partition = <span class="number">4</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//最后返回分区号partition</span></span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//编写驱动类FlowDriver，配置自定义分区器ProvincePartitioner2</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取Job对象job</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.关联当前Driver类</span></span><br><span class="line">        job.setJarByClass(FlowDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关联Mapper组件和Reducer组件</span></span><br><span class="line">        job.setMapperClass(FlowMapper.class);</span><br><span class="line">        job.setReducerClass(FlowReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置map端输出KV的数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(FlowBean.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//5.设置程序最终输出KV的数据类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置自定义分区器</span></span><br><span class="line">        job.setPartitionerClass(ProvincePartitioner2.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置对应的ReduceTask的数量</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">5</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//6.设置程序的输入路径和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output3&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output5555&quot;</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//7.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>重新运行程序，查看输出结果：生成了5个结果文件，分别查看5个结果文件内容，都是按照总流量降序排列的</p>
<img src="Snipaste_2023-09-28_21-50-07.png" alt="Snipaste_2023-09-28_21-50-07" style="zoom:50%;">

<img src="Snipaste_2023-09-28_21-52-00.png" alt="Snipaste_2023-09-28_21-52-00" style="zoom:50%;">

<img src="Snipaste_2023-09-28_21-52-27.png" alt="Snipaste_2023-09-28_21-52-27" style="zoom:50%;">

<img src="Snipaste_2023-09-28_21-52-51.png" alt="Snipaste_2023-09-28_21-52-51" style="zoom:50%;">

<img src="Snipaste_2023-09-28_21-53-12.png" alt="Snipaste_2023-09-28_21-53-12" style="zoom:50%;">

<img src="Snipaste_2023-09-28_21-53-36.png" alt="Snipaste_2023-09-28_21-53-36" style="zoom:50%;">

<h4 id="5-5-7-Combiner合并"><a href="#5-5-7-Combiner合并" class="headerlink" title="5.5.7 Combiner合并"></a>5.5.7 Combiner合并</h4><ol>
<li>Combiner是MR程序中Mappe和Reducer之外的一种组件</li>
<li>Combiner组件的父类就是Reducer</li>
<li>Combiner和Reducer的区别在于运行的位置，<strong>Combiner是在每一个MapTask所在的节点运行，Reducer是接收全局所有Mapper的输出结果</strong></li>
<li>Combiner的意义就是对每一个MapTask的输出进行局部汇总，以减小网络传输量</li>
<li><strong>Combiner能够应用的前提是不影响最终的业务逻辑</strong>，而且Combiner的输出kv应该跟Reducer的输入kv类型要对应起来。</li>
</ol>
<h4 id="5-5-8-Combiner合并案例实操"><a href="#5-5-8-Combiner合并案例实操" class="headerlink" title="5.5.8 Combiner合并案例实操"></a>5.5.8 Combiner合并案例实操</h4><h5 id="1-需求分析-3"><a href="#1-需求分析-3" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h5><p>对输入文件进行词频统计，在统计过程中，使用Combiner组件对每个MapTask的输出数据进行局部汇总，从而减少网络传输数据量</p>
<h5 id="2-实现思路分析-2"><a href="#2-实现思路分析-2" class="headerlink" title="2. 实现思路分析"></a>2. 实现思路分析</h5><p><img src="Snipaste_2023-10-01_12-57-54.png" alt="Snipaste_2023-10-01_12-57-54"></p>
<h5 id="3-案例实操——方案1"><a href="#3-案例实操——方案1" class="headerlink" title="3. 案例实操——方案1"></a>3. 案例实操——方案1</h5><p>增加一个WordCountCombiner类，使其继承Reducer类，重写reduce()方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable,Text, IntWritable&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//封装outV</span></span><br><span class="line">        outV.set(sum);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//写出key和outV</span></span><br><span class="line">        context.write(key, outV);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在WordCountDriver驱动类中配置Combiner组件</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(WordCountCombiner.class);</span><br></pre></td></tr></table></figure>

<h5 id="4-案例实操——方案2"><a href="#4-案例实操——方案2" class="headerlink" title="4. 案例实操——方案2"></a>4. 案例实操——方案2</h5><p>在WordCountDriver驱动类中指定WordCountReducer类作为Combiner组件</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(WordCountReducer.class);</span><br></pre></td></tr></table></figure>

<p>运行程序，观察控制台中打印的日志：</p>
<img src="Snipaste_2023-10-01_14-02-50.png" alt="Snipaste_2023-10-01_14-02-50" style="zoom:50%;">

<p>实际上，在以后，如果Combiner不影响最终的业务逻辑就可以用它，并且都用方案2</p>
<h3 id="5-6-MapReduce框架原理之OutputFormat数据输出"><a href="#5-6-MapReduce框架原理之OutputFormat数据输出" class="headerlink" title="5.6 MapReduce框架原理之OutputFormat数据输出"></a>5.6 MapReduce框架原理之OutputFormat数据输出</h3><h4 id="5-6-1-OutputFormat接口的实现类"><a href="#5-6-1-OutputFormat接口的实现类" class="headerlink" title="5.6.1 OutputFormat接口的实现类"></a>5.6.1 OutputFormat接口的实现类</h4><p>OutputFormat接口是MapReduce输出类的基类，几种该接口的常见实现类：</p>
<ol>
<li>TextOutputFormat类</li>
<li>SequenceFileOutputFormat类</li>
<li>自定义OutputFormat类（注意：之前没有讲自定义InputFormat类）</li>
</ol>
<p>当用户需要将数据输出至MySQL、HBase等存储框架中时，Hadoop就不能够提供对应的OutputFormat类了，需要用户自定义OutputFormat类，步骤如下（感觉挺麻烦）：</p>
<ul>
<li>自定义一个类，使其继承RecordWriter类，在该类中创建文件的输出流及文件的输出方式。</li>
<li>自定义一个类，使其继承FileOutputFormat类，重写getRecordWriter()方法，在getRecordWriter()方法中创建自定义的RecordWriter类并返回。</li>
</ul>
<h4 id="5-6-2-自定义OutputFormat类的案例实操"><a href="#5-6-2-自定义OutputFormat类的案例实操" class="headerlink" title="5.6.2 自定义OutputFormat类的案例实操"></a>5.6.2 自定义OutputFormat类的案例实操</h4><h5 id="1-需求分析-4"><a href="#1-需求分析-4" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h5><p>过滤输入的日志信息，将包含atguigu字段的网址数据输出到…:&#x2F;atguigu.log文件，将不包含atguigu字段的网址数据输出到…:&#x2F;other.log文件中。</p>
<p><img src="Snipaste_2023-10-01_20-29-39.png" alt="Snipaste_2023-10-01_20-29-39"></p>
<h5 id="2-案例实操"><a href="#2-案例实操" class="headerlink" title="2. 案例实操"></a>2. 案例实操</h5><p>（1）编写LogMapper类，在map()方法中不对原数据进行任何处理，直接将一行数据写出</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//不进行任何处理，直接写出一行Log数据</span></span><br><span class="line">        context.write(value, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）编写LogReducer类，在reduce()方法中不进行任何特殊处理，只将数据迭代写出即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, NullWritable, Text, NullWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;NullWritable&gt; values, Reducer&lt;Text, NullWritable, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//防止有相同的数据，迭代写出</span></span><br><span class="line">        <span class="keyword">for</span> (NullWritable value : values) &#123;</span><br><span class="line">            context.write(key, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）自定义一个LogOutputFormat类，使其继承FileOutputFormat类，重写getRecordWrite()方法。getRecordWrite()方法主要用于创建一个RecordWriter对象并返回。RecordWriter类需要用户自定义</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogOutputFormat</span> <span class="keyword">extends</span> <span class="title class_">FileOutputFormat</span>&lt;Text, NullWritable&gt; &#123;<span class="comment">//它的泛型和Reduce输出的泛型一致</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> RecordWriter&lt;Text, NullWritable&gt; <span class="title function_">getRecordWriter</span><span class="params">(TaskAttemptContext job)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//创建一个自定义的RecordWriter对象并返回</span></span><br><span class="line">        <span class="type">LogRecordWriter</span> <span class="variable">lrw</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LogRecordWriter</span>(job);</span><br><span class="line">        <span class="keyword">return</span>  lrw;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）编写LogRecordWriter类，使其继承RecordWriter类，在构造方法中创建文件输出流，在write()方法中编写对文件内容进行判断并分流写出的逻辑代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogRecordWriter</span> <span class="keyword">extends</span> <span class="title class_">RecordWriter</span>&lt;Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> FSDataOutputStream atguiguOut;</span><br><span class="line">    <span class="keyword">private</span> FSDataOutputStream otherOut;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LogRecordWriter</span><span class="params">(TaskAttemptContext job)</span> &#123;</span><br><span class="line">        <span class="comment">//创建两条流</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//获取文件系统对象</span></span><br><span class="line">            <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(job.getConfiguration());</span><br><span class="line">            <span class="comment">//用文件系统对象创建两个输出流，对应不同的目录</span></span><br><span class="line">            atguiguOut = fs.create(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\liu\\atguigu.log&quot;</span>));<span class="comment">//升级为全局变量：ctrl+alt+f</span></span><br><span class="line">            otherOut = fs.create(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\liu\\other.log&quot;</span>));<span class="comment">//升级为全局变量：ctrl+alt+f</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(Text key, NullWritable value)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">log</span> <span class="operator">=</span> key.toString();</span><br><span class="line">        <span class="comment">//具体写：根据一行log数据是否包含atguigu字段，判断两条输出流输出的内容</span></span><br><span class="line">        <span class="keyword">if</span> (log.contains(<span class="string">&quot;atguigu&quot;</span>))&#123;</span><br><span class="line">            atguiguOut.writeBytes(log + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            otherOut.writeBytes(log + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">(TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//关闭流</span></span><br><span class="line">        IOUtils.closeStream(atguiguOut);</span><br><span class="line">        IOUtils.closeStream(otherOut);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（5）编写LogDriver类，将OutputFormat类设置为自定义的LogOutputFormat类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">        job.setJarByClass(LogDriver.class);</span><br><span class="line">        job.setMapperClass(LogMapper.class);</span><br><span class="line">        job.setReducerClass(LogReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line">        <span class="comment">//设置自定义的 outputformat</span></span><br><span class="line">        job.setOutputFormatClass(LogOutputFormat.class);</span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\inputoutputformat&quot;</span>));</span><br><span class="line">        <span class="comment">// 虽 然 我 们 自 定 义 了 outputformat ， 但 是 因 为 我 们 的 outputformat 继承自</span></span><br><span class="line"><span class="comment">//        fileoutputformat</span></span><br><span class="line">        <span class="comment">//而 fileoutputformat 要输出一个_SUCCESS 文件，所以在这还得指定一个输出目录</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output8&quot;</span>));</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（6）运行程序，观察输出结果，发现生成了两个结果文件，分别为atguigu.log文件和other.log文件</p>
<img src="Snipaste_2023-10-03_13-45-51.png" alt="Snipaste_2023-10-03_13-45-51" style="zoom: 50%;">

<img src="Snipaste_2023-10-03_13-46-25.png" alt="Snipaste_2023-10-03_13-46-25" style="zoom:50%;">

<p>而D:\尚硅谷大数据学习资料（无视频）\Hadoop 3.x\资料\资料\output8中只有一个运行成功的标记文件：</p>
<img src="Snipaste_2023-10-03_13-48-51.png" alt="Snipaste_2023-10-03_13-48-51" style="zoom:50%;">

<h3 id="5-7-MapReduce工作流程（面试重点）"><a href="#5-7-MapReduce工作流程（面试重点）" class="headerlink" title="5.7 MapReduce工作流程（面试重点）"></a>5.7 MapReduce工作流程（面试重点）</h3><h4 id="5-7-1-MapTask工作机制"><a href="#5-7-1-MapTask工作机制" class="headerlink" title="5.7.1 MapTask工作机制"></a>5.7.1 MapTask工作机制</h4><p><img src="Snipaste_2023-10-03_14-11-03.png" alt="Snipaste_2023-10-03_14-11-03"></p>
<p>（1）<strong>Read阶段</strong>：MapTask 通过 InputFormat 获得的 RecordReader，从输入 InputSplit 中解析出一个个 key&#x2F;value。</p>
<p>（2）<strong>Map阶段</strong>：该节点主要是将解析出的 key&#x2F;value 交给用户编写 map()函数处理，并产生一系列新的 key&#x2F;value。</p>
<p>（3）<strong>Collect 收集阶段</strong>：在用户编写 map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的 key&#x2F;value 分区（调用Partitioner），并写入一个环形内存缓冲区中。</p>
<p>（4）<strong>Spill 阶段：即“溢写”</strong>，当环形缓冲区满后，MapReduce 会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p>
<p>溢写阶段详情：</p>
<p>​		步骤 1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition 进行排序，然后按照 key 进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照 key 有序。</p>
<p>​		步骤 2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件 output&#x2F;spillN.out（N 表示当前溢写次数）中。如果用户设置了 Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p>
<p>​		步骤 3：将分区数据的元信息写到内存索引数据结构 SpillRecord 中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过 1MB，则将内存索引写到文件 output&#x2F;spillN.out.index 中。</p>
<p>（5）<strong>Merge阶段</strong>：当所有数据处理完成后，MapTask 对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p>
<p>当所有数据处理完后，MapTask 会将所有临时文件合并成一个大文件，并保存到文件output&#x2F;file.out 中，同时生成相应的索引文件 output&#x2F;file.out.index。</p>
<p>在进行文件合并过程中，MapTask 以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并 mapreduce.task.io.sort.factor（默认 10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p>
<p>让每个 MapTask 最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p>
<h4 id="5-7-2-ReduceTask工作机制"><a href="#5-7-2-ReduceTask工作机制" class="headerlink" title="5.7.2 ReduceTask工作机制"></a>5.7.2 ReduceTask工作机制</h4><p><img src="image-20231003141616898.png" alt="image-20231003141616898"></p>
<p>（1）<strong>Copy 阶段</strong>：ReduceTask 从各个 MapTask 上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p>
<p>（2）<strong>Sort 阶段</strong>：在远程拷贝数据的同时，ReduceTask 启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。按照 MapReduce 语义，用户编写 reduce()函数输入数据是按 key 进行聚集的一组数据。为了将 key 相同的数据聚在一起，Hadoop 采用了基于排序的策略。由于各个 MapTask 已经实现对自己的处理结果进行了局部排序，因此，ReduceTask 只需对所有数据进行一次归并排序即可。</p>
<p>（3）<strong>Reduce 阶段</strong>：reduce()函数将计算结果写到 HDFS 上。</p>
<h4 id="5-7-3-ReduceTask并行度决定机制"><a href="#5-7-3-ReduceTask并行度决定机制" class="headerlink" title="5.7.3 ReduceTask并行度决定机制"></a>5.7.3 ReduceTask并行度决定机制</h4><p><strong>MapTask并行度由切片个数决定，切片个数由输入文件和切片规则决定</strong></p>
<p>思考：ReduceTask并行度由谁决定？</p>
<p>（1）设置ReduceTask并行度（个数）</p>
<p>ReduceTask 的并行度同样影响整个 Job 的执行并发度和执行效率，但与 MapTask 的并发数由切片数决定不同，ReduceTask 数量的决定是可以直接手动设置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 默认值是 1，手动设置为 4</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">4</span>);</span><br></pre></td></tr></table></figure>

<p>（2）实验：测试ReduceTask多少合适</p>
<p>实验环境：一个NameNode，16个DataNode，CPU：8GHz，内存2G</p>
<img src="Snipaste_2023-10-03_14-26-16.png" alt="Snipaste_2023-10-03_14-26-16" style="zoom:50%;">

<p>（3）<strong>一些注意事项</strong></p>
<ul>
<li>ReduceTask&#x3D;0，表示没有Reduce阶段，输出文件个数和Map个数一致。</li>
<li>ReduceTask默认值就是1，所以输出文件个数为一个。</li>
<li>如果数据分布不均匀，就有可能在Reduce阶段产生数据倾斜</li>
<li>ReduceTask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个ReduceTask。</li>
<li>具体多少个ReduceTask，需要根据集群性能而定。</li>
<li>如果分区数不是1，但是ReduceTask为1，是否执行分区过程。答案是：不执行分区过程。因为在MapTask的源码中，执行分区的前提是先判断ReduceNum个数是否大于1。不大于1肯定不执行。</li>
</ul>
<h4 id="5-7-4-MapTask-amp-ReduceTask源码解析"><a href="#5-7-4-MapTask-amp-ReduceTask源码解析" class="headerlink" title="5.7.4 MapTask &amp; ReduceTask源码解析"></a>5.7.4 MapTask &amp; ReduceTask源码解析</h4><p>以分区案例代码为例进行源码分析：</p>
<img src="Snipaste_2023-09-28_14-50-52.png" alt="Snipaste_2023-09-28_14-50-52" style="zoom:50%;">

<img src="Snipaste_2023-10-03_14-46-27.png" alt="Snipaste_2023-10-03_14-46-27" style="zoom:50%;">

<p>FlowBean类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span> &#123; <span class="comment">//1.继承Writable接口</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> upFlow;<span class="comment">//上行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> downFlow;<span class="comment">//下行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> sumFlow;<span class="comment">//总流量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//2.提供无参构造器</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3.get,set方法</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">()</span>&#123; <span class="comment">//相当于方法重载</span></span><br><span class="line">        <span class="built_in">this</span>.sumFlow = <span class="built_in">this</span>.upFlow + <span class="built_in">this</span>.downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;<span class="comment">//4.重写序列化方法</span></span><br><span class="line">        out.writeLong(upFlow);</span><br><span class="line">        out.writeLong(downFlow);</span><br><span class="line">        out.writeLong(sumFlow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">//4.重写反序列化方法，注意反序列化的顺序和序列化的顺序完全一致，并且读取方法的调用方法于参数的类型也要一一对应</span></span><br><span class="line">        <span class="built_in">this</span>.upFlow = in.readLong();</span><br><span class="line">        <span class="built_in">this</span>.downFlow = in.readLong();</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = in.readLong();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//5.重写toString方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow + <span class="string">&quot;\t&quot;</span> + downFlow + <span class="string">&quot;\t&quot;</span> + sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>FlowMapper类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="keyword">private</span> <span class="type">FlowBean</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">    <span class="comment">//重写map方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, FlowBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//1.获取一行数据，将其转换成字符串</span></span><br><span class="line">        <span class="comment">//1	  13736230513	192.196.100.1	www.atguigu.com	  2481	 24681	 200</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.切割数据</span></span><br><span class="line">        <span class="comment">//[1,13736230513,192.196.100.1,www.atguigu.com,2481,24681,200]</span></span><br><span class="line">        String[] split = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.抓取我们想要的数据</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">phone</span> <span class="operator">=</span> split[<span class="number">1</span>];<span class="comment">//手记号码</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">up</span> <span class="operator">=</span> split[split.length - <span class="number">3</span>];<span class="comment">//上行流量</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">down</span> <span class="operator">=</span> split[split.length - <span class="number">2</span>];<span class="comment">//下行流量</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.封装</span></span><br><span class="line">        outK.set(phone);</span><br><span class="line">        outV.setUpFlow(Long.parseLong(up));</span><br><span class="line">        outV.setDownFlow(Long.parseLong(down));</span><br><span class="line">        outV.setSumFlow();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.写出outK,outV</span></span><br><span class="line">        context.write(outK, outV);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>FlowReducer类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, FlowBean, Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">FlowBean</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values, Reducer&lt;Text, FlowBean, Text, FlowBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">totalUp</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">long</span> <span class="variable">totalDown</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.遍历values，将其中的上行流量，下行流量分别累加</span></span><br><span class="line">        <span class="keyword">for</span> (FlowBean flowBean : values)&#123;</span><br><span class="line">            totalUp += flowBean.getUpFlow();</span><br><span class="line">            totalDown += flowBean.getDownFlow();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.封装outV</span></span><br><span class="line">        outV.setUpFlow(totalUp);</span><br><span class="line">        outV.setDownFlow(totalDown);</span><br><span class="line">        outV.setSumFlow();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.写出key和outV</span></span><br><span class="line">        context.write(key,outV);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>ProvincePartitioner类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text,FlowBean&gt; &#123;<span class="comment">//泛型要和Map的输出键值保持一致</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text text, FlowBean flowBean, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">        <span class="comment">//Text是手机号，获取手机号的前三位prePhone</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">phone</span> <span class="operator">=</span> text.toString();</span><br><span class="line">        <span class="type">String</span> <span class="variable">prePhone</span> <span class="operator">=</span> phone.substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//定义一个分区号变量partition,根据prePhone的值设置分区号</span></span><br><span class="line">        <span class="type">int</span> partition;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;136&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;137&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;138&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">2</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;139&quot;</span>.equals(prePhone))&#123;</span><br><span class="line">            partition = <span class="number">3</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            partition = <span class="number">4</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//最后返回分区号partition</span></span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>FlowDriver类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取Job对象job</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.关联当前Driver类</span></span><br><span class="line">        job.setJarByClass(FlowDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关联Mapper组件和Reducer组件</span></span><br><span class="line">        job.setMapperClass(FlowMapper.class);</span><br><span class="line">        job.setReducerClass(FlowReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置map端输出KV的数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//5.设置程序最终输出KV的数据类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定自定义分区类</span></span><br><span class="line">        job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//同时指定相应数量的ReduceTask</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">5</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//6.设置程序的输入路径和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\inputflow&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output5&quot;</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//7.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在FlowMapper中的context.write(outK, outV);打上断点：</p>
<img src="Snipaste_2023-10-03_14-51-30.png" alt="Snipaste_2023-10-03_14-51-30" style="zoom:50%;">

<p>在FlowReducer中的context.write(key,outV);打上断点：</p>
<img src="Snipaste_2023-10-03_14-53-30.png" alt="Snipaste_2023-10-03_14-53-30" style="zoom:50%;">

<p>检查输出路径存在后，进行debug，运行到FlowMapper类中的context.write方法，强制进入：</p>
<img src="Snipaste_2023-10-03_14-57-26.png" alt="Snipaste_2023-10-03_14-57-26" style="zoom:50%;">

<p>再次强行进入mapContext.write()方法：</p>
<p><img src="Snipaste_2023-10-04_13-24-24.png" alt="Snipaste_2023-10-04_13-24-24"></p>
<p>再次强行进入output.write()方法：</p>
<p><img src="Snipaste_2023-10-04_13-25-04.png" alt="Snipaste_2023-10-04_13-25-04"></p>
<p>进入getPartition()方法，即为我们自定义的方法：</p>
<p><img src="Snipaste_2023-10-04_13-26-53.png" alt="Snipaste_2023-10-04_13-26-53"></p>
<p>跳出该方法继续向下执行，进入collect环形缓冲区：</p>
<p><img src="Snipaste_2023-10-04_13-28-34.png" alt="Snipaste_2023-10-04_13-28-34"></p>
<p>继续向下走：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// serialize key bytes into buffer</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">keystart</span> <span class="operator">=</span> bufindex;<span class="comment">//把环形缓冲区的指针给了keystart</span></span><br><span class="line">    keySerializer.serialize(key);<span class="comment">//对keystart进行序列化</span></span><br><span class="line">    <span class="keyword">if</span> (bufindex &lt; keystart) &#123;</span><br><span class="line">        <span class="comment">// wrapped the key; must make contiguous</span></span><br><span class="line">        bb.shiftBufferedKey();</span><br><span class="line">        keystart = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// serialize value bytes into buffer</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">int</span> <span class="variable">valstart</span> <span class="operator">=</span> bufindex;</span><br><span class="line">    valSerializer.serialize(value);<span class="comment">//对valuestart进行序列化</span></span><br><span class="line">    <span class="comment">// It&#x27;s possible for records to have zero length, i.e. the serializer</span></span><br><span class="line">    <span class="comment">// will perform no writes. To ensure that the boundary conditions are</span></span><br><span class="line">    <span class="comment">// checked and that the kvindex invariant is maintained, perform a</span></span><br><span class="line">    <span class="comment">// zero-length write into the buffer. The logic monitoring this could be</span></span><br><span class="line">    <span class="comment">// moved into collect, but this is cleaner and inexpensive. For now, it</span></span><br><span class="line">    <span class="comment">// is acceptable.</span></span><br><span class="line">    bb.write(b0, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    ......</span><br><span class="line">    <span class="comment">// write accounting info,以下是写入Mate信息</span></span><br><span class="line">    kvmeta.put(kvindex + PARTITION, partition);</span><br><span class="line">    kvmeta.put(kvindex + KEYSTART, keystart);</span><br><span class="line">    kvmeta.put(kvindex + VALSTART, valstart);</span><br><span class="line">    kvmeta.put(kvindex + VALLEN, distanceTo(valstart, valend));</span><br><span class="line">    <span class="comment">// advance kvindex</span></span><br><span class="line">    kvindex = (kvindex - NMETA + kvmeta.capacity()) % kvmeta.capacity();</span><br><span class="line">&#125; <span class="keyword">catch</span> (MapBufferTooSmallException e) &#123;</span><br><span class="line">    LOG.info(<span class="string">&quot;Record too large for in-memory buffer: &quot;</span> + e.getMessage());</span><br><span class="line">    spillSingleRecord(key, value, partition);</span><br><span class="line">    mapOutputRecordCounter.increment(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>然后依次出write()方法，output.wirte()，mapContext,write()，直至出contxet.write()方法：</p>
<p><img src="Snipaste_2023-10-04_13-40-33.png" alt="Snipaste_2023-10-04_13-40-33"></p>
<p>至此，一行内容写完了。以此类推，一行一行写入，直到写入最后一行“13568436656”，进入方法查看：</p>
<p><img src="Snipaste_2023-10-04_13-45-57.png" alt="Snipaste_2023-10-04_13-45-57"></p>
<p><img src="Snipaste_2023-10-04_13-46-13.png" alt="Snipaste_2023-10-04_13-46-13"></p>
<p><img src="Snipaste_2023-10-04_13-46-38.png" alt="Snipaste_2023-10-04_13-46-38"></p>
<p><img src="Snipaste_2023-10-04_13-47-52.png" alt="Snipaste_2023-10-04_13-47-52"></p>
<p>之后一步步在退出方法：</p>
<p><img src="Snipaste_2023-10-04_13-49-09.png" alt="Snipaste_2023-10-04_13-49-09"></p>
<p>可以看到，最后一步退出循环，进入到cleanup(context)中：</p>
<p><img src="Snipaste_2023-10-04_13-49-34.png" alt="Snipaste_2023-10-04_13-49-34"></p>
<p>cleanup什么都不干，跳出run()方法，继续执行MapTask类：</p>
<img src="Snipaste_2023-10-04_13-51-35.png" alt="Snipaste_2023-10-04_13-51-35" style="zoom:50%;">

<p>强行进入output.close(mapperContext):</p>
<img src="Snipaste_2023-10-04_13-54-02.png" alt="Snipaste_2023-10-04_13-54-02" style="zoom:50%;">

<p>强行进入collector.flush()，在其中的源码中可以发现sortAndSpill()方法：</p>
<img src="Snipaste_2023-10-04_13-55-36.png" alt="Snipaste_2023-10-04_13-55-36" style="zoom:50%;">

<p>进入发现：</p>
<p><img src="Snipaste_2023-10-04_13-57-14.png" alt="Snipaste_2023-10-04_13-57-14"></p>
<p>再次进入：</p>
<p><img src="Snipaste_2023-10-04_13-58-21.png" alt="Snipaste_2023-10-04_13-58-21"></p>
<p>其中sortInternal()就是快排的逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">sortInternal</span><span class="params">(<span class="keyword">final</span> IndexedSortable s, <span class="type">int</span> p, <span class="type">int</span> r,</span></span><br><span class="line"><span class="params">      <span class="keyword">final</span> Progressable rep, <span class="type">int</span> depth)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">null</span> != rep) &#123;</span><br><span class="line">      rep.progress();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (r-p &lt; <span class="number">13</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> p; i &lt; r; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i; j &gt; p &amp;&amp; s.compare(j-<span class="number">1</span>, j) &gt; <span class="number">0</span>; --j) &#123;</span><br><span class="line">          s.swap(j, j-<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (--depth &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// give up</span></span><br><span class="line">      alt.sort(s, p, r, rep);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// select, move pivot into first position</span></span><br><span class="line">    fix(s, (p+r) &gt;&gt;&gt; <span class="number">1</span>, p);</span><br><span class="line">    fix(s, (p+r) &gt;&gt;&gt; <span class="number">1</span>, r - <span class="number">1</span>);</span><br><span class="line">    fix(s, p, r-<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Divide</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> p;</span><br><span class="line">    <span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> r;</span><br><span class="line">    <span class="type">int</span> <span class="variable">ll</span> <span class="operator">=</span> p;</span><br><span class="line">    <span class="type">int</span> <span class="variable">rr</span> <span class="operator">=</span> r;</span><br><span class="line">    <span class="type">int</span> cr;</span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">      <span class="keyword">while</span> (++i &lt; j) &#123;</span><br><span class="line">        <span class="keyword">if</span> ((cr = s.compare(i, p)) &gt; <span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> == cr &amp;&amp; ++ll != i) &#123;</span><br><span class="line">          s.swap(ll, i);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">while</span> (--j &gt; i) &#123;</span><br><span class="line">        <span class="keyword">if</span> ((cr = s.compare(p, j)) &gt; <span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> == cr &amp;&amp; --rr != j) &#123;</span><br><span class="line">          s.swap(rr, j);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (i &lt; j) s.swap(i, j);</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    j = i;</span><br><span class="line">    <span class="comment">// swap pivot- and all eq values- into position</span></span><br><span class="line">    <span class="keyword">while</span> (ll &gt;= p) &#123;</span><br><span class="line">      s.swap(ll--, --i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (rr &lt; r) &#123;</span><br><span class="line">      s.swap(rr++, j++);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Conquer</span></span><br><span class="line">    <span class="comment">// Recurse on smaller interval first to keep stack shallow</span></span><br><span class="line">    <span class="keyword">assert</span> i != j;</span><br><span class="line">    <span class="keyword">if</span> (i - p &lt; r - j) &#123;</span><br><span class="line">      sortInternal(s, p, i, rep, depth);</span><br><span class="line">      p = j;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      sortInternal(s, j, r, rep, depth);</span><br><span class="line">      r = i;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>至此排序完成，回到sorter.sort()后的代码：</p>
<p><img src="Snipaste_2023-10-04_13-59-56.png" alt="Snipaste_2023-10-04_13-59-56"></p>
<p>开始循环遍历每一个分区：</p>
<img src="Snipaste_2023-10-04_14-02-49.png" alt="Snipaste_2023-10-04_14-02-49" style="zoom:50%;">

<p>当0号分区写成功后:</p>
<p><img src="Snipaste_2023-10-04_14-04-42.png" alt="Snipaste_2023-10-04_14-04-42"></p>
<p>在D:\tmp\hadoop-WangYuhan\mapred\local\localRunner\WangYuhan\jobcache\job_local1485257078_0001\attempt_local1485257078_0001_m_000000_0\output文件夹中的可以看到0号分区的溢写情况：</p>
<img src="Snipaste_2023-10-04_14-09-40.png" alt="Snipaste_2023-10-04_14-09-40" style="zoom:50%;">

<p>剩下的略吧，源码不是很重要，个人觉得对于数仓开发来说是浪费时间</p>
<h3 id="5-8-Join"><a href="#5-8-Join" class="headerlink" title="5.8 Join"></a>5.8 Join</h3><p>如果连接操作发生在map阶段，则称之为Map Join；如果连接操作发生在reduce阶段，则称之为Reduce Join。</p>
<h4 id="5-8-1-Reduce-Join"><a href="#5-8-1-Reduce-Join" class="headerlink" title="5.8.1 Reduce Join"></a>5.8.1 Reduce Join</h4><p>该操作的比较常见的的连接操作，并且对数据集没有特定要求。</p>
<p>map阶段的主要工作：首先为来自不同表或文件的key&#x2F;value对打标签，用于区别不同来源的记录；然后<strong>将连接字段作为key</strong>，<strong>将其他部分和新加的标志作为value</strong>,最后进行输出。</p>
<p>reduce阶段的主要工作：在shuffle过程中的reduce端，将连接字段作为key的分组已经完成，在reduce方法中将每个分组中来自不同文件的记录（在map阶段已经打标签）分开并进行合并。</p>
<p><img src="Snipaste_2023-10-04_14-46-29.png" alt="Snipaste_2023-10-04_14-46-29"></p>
<p>代码实现：</p>
<p>（1）创建订单数据表和商品信息表合并后的TableBean类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span> &#123;<span class="comment">//实现Writable，从而完成序列化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String id;     <span class="comment">//订单编号</span></span><br><span class="line">    <span class="keyword">private</span> String pid;    <span class="comment">//商品编号</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> amount;    <span class="comment">//数量</span></span><br><span class="line">    <span class="keyword">private</span> String pname;  <span class="comment">//商品名称</span></span><br><span class="line">    <span class="keyword">private</span> String flag;   <span class="comment">//标志字段，用于判断是订单数据表，还是商品数据表</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TableBean</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(String id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getPid</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> pid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPid</span><span class="params">(String pid)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.pid = pid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAmount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> amount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAmount</span><span class="params">(<span class="type">int</span> amount)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.amount = amount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getPname</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> pname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPname</span><span class="params">(String pname)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.pname = pname;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getFlag</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setFlag</span><span class="params">(String flag)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span>  id + <span class="string">&quot;\t&quot;</span> + pname + <span class="string">&quot;\t&quot;</span> + amount ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        out.writeUTF(id);</span><br><span class="line">        out.writeUTF(pid);</span><br><span class="line">        out.writeInt(amount);</span><br><span class="line">        out.writeUTF(pname);</span><br><span class="line">        out.writeUTF(flag);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = in.readUTF();</span><br><span class="line">        <span class="built_in">this</span>.pid = in.readUTF();</span><br><span class="line">        <span class="built_in">this</span>.amount = in.readInt();</span><br><span class="line">        <span class="built_in">this</span>.pname = in.readUTF();</span><br><span class="line">        <span class="built_in">this</span>.flag = in.readUTF();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）编写TableMapper类，需要重写setup()方法。（重写该方法的目的在于通过Context对象获取文件名称）。重写map()方法，针对不同的文件，对数据进行适当的切分操作，并且将切分结果写入TableBean对象作为value、将商品编号作为key发送出去</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, TableBean&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String filename;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="keyword">private</span> <span class="type">TableBean</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Mapper&lt;LongWritable, Text, Text, TableBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//初始化</span></span><br><span class="line">        <span class="comment">//获取对应文件名称</span></span><br><span class="line">        <span class="type">InputSplit</span> <span class="variable">split</span> <span class="operator">=</span> context.getInputSplit();</span><br><span class="line">        <span class="type">FileSplit</span> <span class="variable">fileSplit</span> <span class="operator">=</span> (FileSplit) split;</span><br><span class="line">        filename = fileSplit.getPath().getName();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, TableBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">//获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//判断是哪个文件，然后针对不同的文件进行不同的操作</span></span><br><span class="line">        <span class="keyword">if</span> (filename.contains(<span class="string">&quot;order&quot;</span>))&#123;  <span class="comment">//对订单数据表的处理</span></span><br><span class="line">            String[] split = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            <span class="comment">//封装outK</span></span><br><span class="line">            outK.set(split[<span class="number">1</span>]);</span><br><span class="line">            <span class="comment">//封装outV</span></span><br><span class="line">            outV.setId(split[<span class="number">0</span>]);</span><br><span class="line">            outV.setPid(split[<span class="number">1</span>]);</span><br><span class="line">            outV.setAmount(Integer.parseInt(split[<span class="number">2</span>]));</span><br><span class="line">            outV.setPname(<span class="string">&quot;&quot;</span>);</span><br><span class="line">            outV.setFlag(<span class="string">&quot;order&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            String[] split = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            <span class="comment">//封装outK</span></span><br><span class="line">            outK.set(split[<span class="number">0</span>]);</span><br><span class="line">            <span class="comment">//封装outV</span></span><br><span class="line">            outV.setId(<span class="string">&quot;&quot;</span>);</span><br><span class="line">            outV.setPid(split[<span class="number">0</span>]);</span><br><span class="line">            outV.setAmount(<span class="number">0</span>);</span><br><span class="line">            outV.setPname(split[<span class="number">1</span>]);</span><br><span class="line">            outV.setFlag(<span class="string">&quot;pd&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//写出outK,outV</span></span><br><span class="line">        context.write(outK, outV);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）编写TableReducer类，重写reduce()方法，在reduce()方法中，先对本组数据按照来源进行分类，分成订单信息和商品信息，再将商品信息中的商品名称写入订单信息</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, TableBean, TableBean, NullWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;TableBean&gt; values, Reducer&lt;Text, TableBean, TableBean, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"><span class="comment">//        01 1001 1 order</span></span><br><span class="line"><span class="comment">//        01 1004 4 order</span></span><br><span class="line"><span class="comment">//        01 小米 pd</span></span><br><span class="line"></span><br><span class="line">        ArrayList&lt;TableBean&gt; orderBeans = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="type">TableBean</span> <span class="variable">pdBeans</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//循环遍历</span></span><br><span class="line">        <span class="keyword">for</span> (TableBean value : values) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//判断数据来自哪个表</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="string">&quot;order&quot;</span>.equals(value.getFlag()))&#123;  <span class="comment">//订单数据表</span></span><br><span class="line"></span><br><span class="line">                <span class="comment">//创建一个临时的TableBean对象，用于接收value</span></span><br><span class="line">                <span class="type">TableBean</span> <span class="variable">tmpOrderBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    BeanUtils.copyProperties(tmpOrderBean, value);<span class="comment">//将value的值赋值给tmpOrderBean</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (IllegalAccessException e) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">//将临时的TableBean对象添加到集合orderBeans中</span></span><br><span class="line">                orderBeans.add(tmpOrderBean);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;    <span class="comment">//商品信息表</span></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    BeanUtils.copyProperties(pdBeans, value);<span class="comment">//将value的值赋值给pdBean</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (IllegalAccessException e) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//以上，至此完成了将&quot;01 1001 1 order&quot;和&quot;01 1004 4 order&quot;赋值到集合orderBeans中，将</span></span><br><span class="line">        <span class="comment">//&quot;01 小米 pd&quot;赋值给了pdBean对象</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//遍历集合orderBeans，将每个orderBeans对象的商品编号替换为商品名称，然后写出</span></span><br><span class="line">        <span class="keyword">for</span> (TableBean orderBean : orderBeans) &#123;</span><br><span class="line">            orderBean.setPname(pdBeans.getPname());</span><br><span class="line"></span><br><span class="line">            <span class="comment">//写出修改后的orderBeans对象</span></span><br><span class="line">            context.write(orderBean, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）编写TableDriver类，进行必要的配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(<span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line">        job.setJarByClass(TableDriver.class);</span><br><span class="line">        job.setMapperClass(TableMapper.class);</span><br><span class="line">        job.setReducerClass(TableReducer.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(TableBean.class);</span><br><span class="line">        job.setOutputKeyClass(TableBean.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\inputtable&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output9&quot;</span>));</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行程序，查看输出结果：</p>
<img src="Snipaste_2023-10-04_16-24-57.png" alt="Snipaste_2023-10-04_16-24-57" style="zoom:50%;">

<p>缺点：这种方式中，合并的操作是在 Reduce 阶段完成，Reduce 端的处理压力太大，Map节点的运算负载则很低，资源利用率不高，且在 Reduce 阶段极易产生<strong>数据倾斜</strong>。（如果某个商品编号的订单数据远远超过其余商品编号的订单数据，那么处理该商品编号的ReduceTask的处理时间会大大延长）</p>
<p>解决方案：Map 端实现数据合并。</p>
<h4 id="5-8-3-Map-Join"><a href="#5-8-3-Map-Join" class="headerlink" title="5.8.3 Map Join"></a>5.8.3 Map Join</h4><ol>
<li>适用场景</li>
</ol>
<p>Map Join适用于一个表很小（缓存到内存中，以至于可以分发至集群中的每个节点上），另一张表很大的情景。</p>
<ol start="2">
<li>优点</li>
</ol>
<p>再map端缓存多个表，提前处理业务逻辑，从而增加map端业务，减轻reduce端的数据处理压力，可以尽可能地<strong>减少数据倾斜</strong></p>
<ol start="3">
<li>具体方法</li>
</ol>
<p>（1）在Mapper组件的setup()方法中，将文件读取到缓存集合中（<strong>先</strong>）；在map()方法中，实现数据连接操作（<strong>后</strong>）</p>
<p>（2）在Driver类驱动类中加载缓存</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//缓存普通文件到 Task 运行节点。</span></span><br><span class="line">job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file:///e:/cache/pd.txt&quot;</span>));</span><br><span class="line"><span class="comment">//如果是集群运行,需要设置 HDFS 路径</span></span><br><span class="line">job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:8020/cache/pd.txt&quot;</span>));</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-04_16-44-41.png" alt="Snipaste_2023-10-04_16-44-41" style="zoom:50%;">

<ol start="4">
<li>代码实现</li>
</ol>
<p>（1）在MapJoinDriver驱动类中添加缓存文件。因为所有的数据连接操作都在Mapper组件中完成，不需要Reducer组件，所以将ReduceTask的数量设置为0个。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MapJoinDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException, URISyntaxException &#123;</span><br><span class="line">        <span class="comment">// 1 获取 job 信息</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">        <span class="comment">// 2 设置加载 jar 包路径</span></span><br><span class="line">        job.setJarByClass(MapJoinDriver.class);</span><br><span class="line">        <span class="comment">// 3 关联 mapper</span></span><br><span class="line">        job.setMapperClass(MapJoinMapper.class);</span><br><span class="line">        <span class="comment">// 4 设置 Map 输出 KV 类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line">        <span class="comment">// 5 设置最终输出 KV 类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line">        <span class="comment">// 加载缓存数据</span></span><br><span class="line">        job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file:///D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\tablecache\\pd.txt&quot;</span>));</span><br><span class="line">        <span class="comment">// Map 端 Join 的逻辑不需要 Reduce 阶段，设置 reduceTask 数量为 0</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line">        <span class="comment">// 6 设置输入输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\inputtable2&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output99&quot;</span>));</span><br><span class="line">        <span class="comment">// 7 提交</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）在MapJoinMapper类中的setup()方法中读取缓存文件，将缓存文件中的数据写入HashMap，在map()方法中编写数据连接的逻辑代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MapJoinMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String ,String&gt; pdMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在任务开始前，将商品信息表pd.txt中的数据缓存进pdMap</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//通过缓存文件得到商品信息表pd.txt中的数据</span></span><br><span class="line">        URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">        <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(cacheFiles[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取文件系统对象并开流</span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(context.getConfiguration());</span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(path);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将字节流转换为字符串流，方便按行读取</span></span><br><span class="line">        <span class="type">BufferedReader</span> <span class="variable">reader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(fis, <span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//按行读取，按行处理</span></span><br><span class="line">        String line;</span><br><span class="line">        <span class="keyword">while</span> (StringUtils.isNotEmpty(line = reader.readLine()))&#123;</span><br><span class="line">            <span class="comment">//切割一行</span></span><br><span class="line">            <span class="comment">//01  小米</span></span><br><span class="line">            String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line">            pdMap.put(fields[<span class="number">0</span>], fields[<span class="number">1</span>]);<span class="comment">//put方法相当于在一个HashMap中添加值，fields[0]为key,fields[1]为value</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭流</span></span><br><span class="line">        IOUtils.closeStreams(reader);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//处理order.txt</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取pid</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">pid</span> <span class="operator">=</span> fields[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">//根据订单数据表order.txt中每行数据的pid（商品编号），从pdMap中获取pname（商品名称）</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">pname</span> <span class="operator">=</span> pdMap.get(pid);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//将订单数据表order.txt中每行数据的pid替换为pname</span></span><br><span class="line">        outK.set(fields[<span class="number">0</span>] + <span class="string">&quot;\t&quot;</span> + pname + <span class="string">&quot;\t&quot;</span> + fields[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//写出</span></span><br><span class="line">        context.write(outK, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行程序，查看输出结果：</p>
<img src="Snipaste_2023-10-04_21-16-30.png" alt="Snipaste_2023-10-04_21-16-30" style="zoom:50%;">

<h3 id="5-9-数据清洗"><a href="#5-9-数据清洗" class="headerlink" title="5.9 数据清洗"></a>5.9 数据清洗</h3><p>ETL，是英文 Extract-Transform-Load 的缩写，用来描述将数据从来源端经过抽取（Extract）、转换（Transform）、加载（Load）至目的端的过程。ETL 一词较常用在数据仓库，但其对象并不限于数据仓库</p>
<p>在运行核心业务 MapReduce 程序之前，往往要先对数据进行清洗，清理掉不符合用户要求的数据。<strong>清理的过程往往只需要运行 Mapper 程序，不需要运行 Reduce 程序</strong>。</p>
<ol>
<li>需求分析：过滤掉日志中字段数量不超过11个的数据</li>
</ol>
<p>原数据共14619行</p>
<ol start="2">
<li>代码实现</li>
</ol>
<p>（1）编写WebLogMapper类，在map()方法中实现对日志数据的过滤：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebLogMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取一行数据</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.解析日志</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> parseLog(line, context);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.日志不合法，退出</span></span><br><span class="line">        <span class="keyword">if</span> (!result)&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.日志合法，直接写出</span></span><br><span class="line">        context.write(value, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//封装解析日志的方法</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">parseLog</span><span class="params">(String line, Context context)</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.截取</span></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.日志长度大于11为合法</span></span><br><span class="line">        <span class="keyword">if</span> (fields.length &gt; <span class="number">11</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（2）编写WebLogDriver类，进行必要的配置，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebLogDriver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[] &#123; <span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\11_input\\inputlog&quot;</span>,</span><br><span class="line">                <span class="string">&quot;D:\\尚硅谷大数据学习资料（无视频）\\Hadoop 3.x\\资料\\资料\\output222&quot;</span> &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取 job 信息</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 加载 jar 包</span></span><br><span class="line">        job.setJarByClass(LogDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 关联 map</span></span><br><span class="line">        job.setMapperClass(WebLogMapper.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 设置最终输出类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置 reducetask 个数为 0</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 设置输入和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 提交</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）运行程序，查看输出结果：</p>
<p><img src="Snipaste_2023-10-04_21-49-35.png" alt="Snipaste_2023-10-04_21-49-35"></p>
<h3 id="5-10-Hadoop中的数据压缩"><a href="#5-10-Hadoop中的数据压缩" class="headerlink" title="5.10 Hadoop中的数据压缩"></a>5.10 Hadoop中的数据压缩</h3><h4 id="5-10-1-数据压缩概述"><a href="#5-10-1-数据压缩概述" class="headerlink" title="5.10.1 数据压缩概述"></a>5.10.1 数据压缩概述</h4><ol>
<li>压缩的好处和坏处</li>
</ol>
<ul>
<li>优点：以减少磁盘 IO、减少磁盘存储空间。</li>
<li>缺点：增加 CPU 开销</li>
</ul>
<ol start="2">
<li>压缩原则</li>
</ol>
<ul>
<li>运算密集型的 Job，少用压缩</li>
<li>IO 密集型的 Job，多用压缩</li>
</ul>
<h5 id="MapReduce支持的压缩编码"><a href="#MapReduce支持的压缩编码" class="headerlink" title="MapReduce支持的压缩编码"></a>MapReduce支持的压缩编码</h5><table>
<thead>
<tr>
<th>压缩格式</th>
<th>Hadoop 自带？</th>
<th>算法</th>
<th>文件扩展名</th>
<th>是否可切片</th>
<th>换成压缩格式后，原来的程序是否需要修改</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>是，直接使用</td>
<td>DEFLATE</td>
<td>.deflate</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>Gzip</td>
<td>是，直接使用</td>
<td>DEFLATE</td>
<td>.gz</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>bzip2</td>
<td>是，直接使用</td>
<td>bzip2</td>
<td>.bz2</td>
<td>是</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>LZO</td>
<td>否，需要安装</td>
<td>LZO</td>
<td>.lzo</td>
<td>是</td>
<td>需要创建索引，还需要指定输入格式</td>
</tr>
<tr>
<td>Snappy</td>
<td>是，直接使用</td>
<td>Snappy</td>
<td>.snappy</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
</tbody></table>
<h5 id="压缩性能比较"><a href="#压缩性能比较" class="headerlink" title="压缩性能比较"></a>压缩性能比较</h5><img src="Snipaste_2023-10-05_14-00-19.png" alt="Snipaste_2023-10-05_14-00-19" style="zoom:50%;">

<h5 id="1-压缩格式的选择"><a href="#1-压缩格式的选择" class="headerlink" title="1. 压缩格式的选择"></a>1. 压缩格式的选择</h5><p>压缩方式选择时重点考虑：压缩&#x2F;解压缩速度、压缩率（压缩后存储大小）、压缩后是否可以支持切片，在企业中LZO和Snappy用的较多。</p>
<p>①GZIP</p>
<p>优点：压缩率较高</p>
<p>缺点：不支持切片，压缩&#x2F;解压缩速度一般</p>
<p>②bzip2</p>
<p>优点：压缩率高，支持切片</p>
<p>缺点：压缩&#x2F;解压缩速度慢</p>
<p>③LZO</p>
<p>优点：压缩&#x2F;解压缩速度较快，支持切片</p>
<p>缺点：压缩率一般，支持切片需要额外创建索引</p>
<p>④Snappy</p>
<p>优点：压缩&#x2F;解压缩速度块</p>
<p>缺点：不支持切片，压缩率一般</p>
<h5 id="2-压缩位置的选择"><a href="#2-压缩位置的选择" class="headerlink" title="2. 压缩位置的选择"></a>2. 压缩位置的选择</h5><p>压缩可以在 MapReduce 作用的任意阶段启用。</p>
<img src="Snipaste_2023-10-05_14-06-57.png" alt="Snipaste_2023-10-05_14-06-57" style="zoom:50%;">

<h4 id="5-10-2-压缩参数配置"><a href="#5-10-2-压缩参数配置" class="headerlink" title="5.10.2 压缩参数配置"></a>5.10.2 压缩参数配置</h4><p>为了支持多种压缩&#x2F;解压缩算法，Hadoop 引入了编码&#x2F;解码器</p>
<img src="Snipaste_2023-10-05_15-05-32.png" alt="Snipaste_2023-10-05_15-05-32" style="zoom:50%;">

<p>要在 Hadoop 中启用压缩，可以配置如下参数</p>
<img src="Snipaste_2023-10-05_15-06-04.png" alt="Snipaste_2023-10-05_15-06-04" style="zoom:50%;">

<img src="Snipaste_2023-10-05_15-06-18.png" alt="Snipaste_2023-10-05_15-06-18" style="zoom:50%;">

<h4 id="5-10-3-压缩案例实操"><a href="#5-10-3-压缩案例实操" class="headerlink" title="5.10.3 压缩案例实操"></a>5.10.3 压缩案例实操</h4><h5 id="1-Mapper输出采用压缩"><a href="#1-Mapper输出采用压缩" class="headerlink" title="1. Mapper输出采用压缩"></a>1. Mapper输出采用压缩</h5><p>即使MapReduce的输入文件和输出文件都是未压缩的文件，也可以对<strong>MapTask的中间输出过程</strong>进行数据压缩，因为需要将其写入硬盘并通过网络将其传输到ReduceTask所在的节点中，<strong>对其进行压缩可以提高很多性能</strong>，这些工作只要设置两个属性即可，具体实现如下：</p>
<p>（1）以WordCount程序为基础，在Driver驱动类中启用Mapper输出压缩功能，并且设置压缩格式为bzip2，其余代码不变:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启 map 端输出压缩</span></span><br><span class="line">conf.setBoolean(<span class="string">&quot;mapreduce.map.output.compress&quot;</span>, <span class="literal">true</span>);</span><br><span class="line"><span class="comment">// 设置 map 端输出压缩方式</span></span><br><span class="line">conf.setClass(<span class="string">&quot;mapreduce.map.output.compress.codec&quot;</span>,</span><br><span class="line">              BZip2Codec.class, CompressionCodec.class);</span><br></pre></td></tr></table></figure>

<p>（2）Mapper组件保持不变</p>
<p>（3）Reducer组件保持不变</p>
<p>（4）运行程序，发现对输出结果没有任何影响，数据压缩只发生在map阶段</p>
<img src="Snipaste_2023-10-05_15-21-45.png" alt="Snipaste_2023-10-05_15-21-45" style="zoom:50%;">

<h5 id="2-Reducer输出采用压缩"><a href="#2-Reducer输出采用压缩" class="headerlink" title="2. Reducer输出采用压缩"></a>2. Reducer输出采用压缩</h5><p>（1）以WordCount程序为例，在Driver驱动类中启用reducer输出压缩功能，并且设置压缩格式为bzip2，其余代码不变</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置 reduce 端输出压缩开启</span></span><br><span class="line">FileOutputFormat.setCompressOutput(job, <span class="literal">true</span>);</span><br><span class="line"><span class="comment">// 设置压缩的方式</span></span><br><span class="line">FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class);</span><br><span class="line"><span class="comment">// FileOutputFormat.setOutputCompressorClass(job, GzipCodec.class); </span></span><br><span class="line"><span class="comment">// FileOutputFormat.setOutputCompressorClass(job,DefaultCodec.class);</span></span><br></pre></td></tr></table></figure>

<p>（2）Mapper组件和Reducer组件均保持不变，适用bzip2压缩格式的输出结果如下（其余同理）：</p>
<img src="Snipaste_2023-10-05_15-34-32.png" alt="Snipaste_2023-10-05_15-34-32" style="zoom:50%;">

<h3 id="5-11-MapReduce开发总结"><a href="#5-11-MapReduce开发总结" class="headerlink" title="5.11 MapReduce开发总结"></a>5.11 MapReduce开发总结</h3><h4 id="1-输入数据接口：InputFormat"><a href="#1-输入数据接口：InputFormat" class="headerlink" title="1. 输入数据接口：InputFormat"></a>1. 输入数据接口：<strong>InputFormat</strong></h4><p>（1）默认使用的实现类是：TextInputFormat</p>
<p>（2）TextInputFormat 的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为key，行内容作为 value 返回。</p>
<p>（3）CombineTextInputFormat 可以把多个小文件合并成一个切片处理，提高处理效率。</p>
<p>（4）InputFormat用的比较少了，所以没介绍自定义InputFormat</p>
<h4 id="2-逻辑处理接口：Mapper"><a href="#2-逻辑处理接口：Mapper" class="headerlink" title="2. 逻辑处理接口：Mapper"></a>2. 逻辑处理接口：<strong>Mapper</strong></h4><p>用户根据业务需求实现其中三个方法：</p>
<p>setup() ：初始化</p>
<p>map() ：用户的业务逻辑</p>
<p>cleanup () ：关闭资源</p>
<h4 id="3-Partitioner-分区"><a href="#3-Partitioner-分区" class="headerlink" title="3. Partitioner 分区"></a>3. <strong>Partitioner</strong> <strong>分区</strong></h4><p>（1）有默认实现 HashPartitioner，逻辑是根据 key 的哈希值和 numReduces 来返回一个分区号；key.hashCode()&amp;Integer.MAXVALUE % numReduces</p>
<p>（2）如果业务上有特别的需求，可以自定义分区。</p>
<h4 id="4-Comparable-排序"><a href="#4-Comparable-排序" class="headerlink" title="4. Comparable 排序"></a>4. <strong>Comparable</strong> <strong>排序</strong></h4><p>（1）当我们用自定义的对象作为 key 来输出时，就必须要实现 WritableComparable 接口，重写其中的 compareTo()方法。</p>
<p>（2）部分排序：对最终输出的每一个文件进行内部排序。</p>
<p>（3）全排序：对所有数据进行排序，通常只有一个 Reduce。</p>
<p>（4）二次排序：排序的条件有两个。</p>
<h4 id="5-Combiner-合并"><a href="#5-Combiner-合并" class="headerlink" title="5. Combiner 合并"></a>5. <strong>Combiner</strong> <strong>合并</strong></h4><p>Combiner 合并可以提高程序执行效率，减少 IO 传输。在map阶段提前聚合。但是使用时必须不能影响原有的业务处理结果（求和没问题，求平均值有问题）。解决数据倾斜的一个方法。</p>
<h4 id="6-逻辑处理接口：Reducer"><a href="#6-逻辑处理接口：Reducer" class="headerlink" title="6. 逻辑处理接口：Reducer"></a>6. 逻辑处理接口：<strong>Reducer</strong></h4><p>用户根据业务需求实现其中三个方法：</p>
<p>setup() ：初始化</p>
<p>reduce() ：用户的业务逻辑</p>
<p>cleanup () ：关闭资源</p>
<h4 id="7-输出数据接口：OutputFormat"><a href="#7-输出数据接口：OutputFormat" class="headerlink" title="7. 输出数据接口：OutputFormat"></a>7. 输出数据接口：<strong>OutputFormat</strong></h4><p>（1）默认实现类是 TextOutputFormat，功能逻辑是：将每一个 KV 对，向目标文本文件输出一行。</p>
<p>（2）用户还可以自定义 OutputFormat。</p>
<h2 id="第六章-资源调度器YARN"><a href="#第六章-资源调度器YARN" class="headerlink" title="第六章 资源调度器YARN"></a>第六章 资源调度器YARN</h2><h3 id="6-1-YARN概述"><a href="#6-1-YARN概述" class="headerlink" title="6.1 YARN概述"></a>6.1 YARN概述</h3><p>YARN是一个<strong>资源调度平台</strong>，负责为运算程序提供<strong>服务器运算资源</strong>，相当于一个<strong>分布式的操作系统</strong>，而MapReduce等运算程序相当于运行在操作系统上的应用程序。</p>
<h4 id="6-1-1-基本架构"><a href="#6-1-1-基本架构" class="headerlink" title="6.1.1 基本架构"></a>6.1.1 基本架构</h4><p>YARN采用了常见的Master-Slaver架构，其中，资源管理器<strong>ResourceManager</strong>（一个）担任Master角色，负责<strong>整个框架的资源统一管理和调度</strong>；<strong>NodeManager</strong>（多个）担任Slave角色，负责<strong>任务的执行及当前节点的资源管理</strong>。</p>
<p><img src="Snipaste_2023-10-05_16-12-45.png" alt="Snipaste_2023-10-05_16-12-45"></p>
<p>YARN主要由<strong>ResourceManager</strong>，<strong>NodeManager</strong>，<strong>ApplicationMaster</strong>和<strong>Container</strong>等组件组成。</p>
<h5 id="1-资源管理器ResourceManager"><a href="#1-资源管理器ResourceManager" class="headerlink" title="1. 资源管理器ResourceManager"></a>1. 资源管理器ResourceManager</h5><p>ResourceManager（RM）是一个全局资源管理器，负责管理整个集群的资源，主要作用：</p>
<ul>
<li>处理客户端（Client）请求</li>
<li>监控NodeManager</li>
<li>启动或监控ApplicationMaster</li>
<li>分配与调度资源</li>
</ul>
<h5 id="2-节点管理器NodeManager"><a href="#2-节点管理器NodeManager" class="headerlink" title="2. 节点管理器NodeManager"></a>2. 节点管理器NodeManager</h5><p>NodeManager（NM）是每个节点上的资源和任务的管理器，主要作用：</p>
<ul>
<li>管理单个节点上的资源和运行任务</li>
<li>处理来自ResourceManager的命令</li>
<li>定时汇报本节点的资源使用情况及各个Container的运行状态</li>
<li>处理来自ApplicationMaster的命令</li>
</ul>
<h5 id="3-ApplicationMaster"><a href="#3-ApplicationMaster" class="headerlink" title="3. ApplicationMaster"></a>3. ApplicationMaster</h5><p>用户提交的每个应用程序中均包含一个ApplicationMaster（AM），其主要作用如下：</p>
<ul>
<li>为应用程序申请资源并分配给内部的任务</li>
<li>与NodeMaster通信，以便启动或停止任务</li>
<li>监控任务的运行状态，并且在任务运行失败时重新申请资源，以便重启任务</li>
</ul>
<h5 id="4-容器（Container）"><a href="#4-容器（Container）" class="headerlink" title="4. 容器（Container）"></a>4. 容器（Container）</h5><p>Container（容器）是YARN中的资源抽象，它封装了某个节点服务器的多维度资源，如内存、CPU、磁盘、网络等。</p>
<h4 id="6-1-2-工作机制（重点面试题）"><a href="#6-1-2-工作机制（重点面试题）" class="headerlink" title="6.1.2 工作机制（重点面试题）"></a>6.1.2 工作机制（重点面试题）</h4><p><img src="Snipaste_2023-10-05_21-23-16.png" alt="Snipaste_2023-10-05_21-23-16"></p>
<p>（0）客户端通过调用job.waitForCompletion()方法，将MapReduce任务提交给整个集群，并且在客户端创建一个<strong>YARNRunner对象</strong></p>
<p>（1）YARNRunner对象向资源管理器<strong>ResourceManager</strong>申请一个<strong>Application</strong></p>
<p>（2）<strong>ResourceManager</strong>将该<strong>Application</strong>的资源提交路径返回给YARNRunner对象</p>
<p>（3）YARNRunner对象根据<strong>ResourceManager</strong>给出的资源提交路径，将该程序所需的资源（如文件分片信息、运行参数信息、运行jar包等）提交给HDFS</p>
<blockquote>
<p>0~3为准备阶段</p>
</blockquote>
<p>（4）在程序将资源提交完毕后，客户端向<strong>ResourceManager正式申请运行ApplicationMaster</strong></p>
<p>（5）<strong>ResourceManager</strong>将客户端的请求初始化成一个Task，并且为该Task调度分配资源</p>
<p>（6）集群中的一个<strong>空闲NodeManager</strong>领取Task</p>
<p>（7）该<strong>NodeManager</strong>会创建一个<strong>Container</strong>，并且在该<strong>Container</strong>中启动Task的<strong>ApplicationMaster</strong>，ApplicationMaster首先向ResourceManager注册，以便用户通过ResourceManager查看任务的运行状态</p>
<p>（8）ApplicationMaster从HDFS中将程序运行资源复制到本地节点中</p>
<blockquote>
<p>4~8为客户端向ResourceManager申请ApplicationMaster，ResourceManager在某个NodeManager创建ApplicationMaster</p>
</blockquote>
<p>（9）<strong>ApplicationMaster</strong>根据复制的程序运行资源决定需要几个<strong>MapTask</strong>，并且向<strong>ResourceManager</strong>申请运行MapTask所需的资源（此处假设需要运行2个MapTask）</p>
<p>（10）<strong>ResourceManager</strong>将MapTask任务分配给另外2个<strong>NodeManager</strong>，这两个NodeManager分别领取MapTask任务并创建<strong>Container</strong></p>
<p>（11）<strong>ApplicationMaster</strong>向2个接收到任务的<strong>NodeManager</strong>发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据进行计算，最终生成对应<strong>ReduceTask</strong>数量的分区文件。MapTask在运行过程中，不断向ApplicationMaster汇报各任务的<strong>运行状态和进度</strong>，以便让ApplicationMaster掌握各任务的运行状态和进展，并且在任务失败时尝试重启。</p>
<blockquote>
<p>9~11为ApplicationMaster向ResourceManager申请MapTask的资源，ResourceManager在某几个NodeManager上分配MapTask任务</p>
</blockquote>
<p>（12）<strong>ApplicationMaster</strong>在等待<strong>MapTask</strong>进行到一定程度（完成MapTask数量占总MapTask数量的5%以上）后，会向<strong>ResourceManager</strong>申请运行<strong>ReduceTask</strong>所需的资源。</p>
<p>（13）<strong>ResourceManager</strong>为<strong>ReduceTask</strong>分配<strong>NodeManager</strong>，NodeManager领取任务并创建2个Container。ApplicationMaster向这2个Container发送任务启动脚本，启动ReduceTask。ReduceTask向MapTask获取相应分区的数据，完成ReduceTask的计算任务，将数据输出至指定路径下。</p>
<blockquote>
<p>12~13为ApplicationMaster向ResourceManager申请ReduceTask的资源，ResourceManager在某几个NodeManager上分配ReduceTask任务</p>
</blockquote>
<p>（14）在所有程序运行完毕后，ApplicationMaster会向ResourceManager申请注销并关闭自己。</p>
<hr>
<p><strong>面试背诵版：（结合图理解）</strong></p>
<p><img src="%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6(10).png" alt="未命名文件(10)"></p>
<p>（1）客户端向YARN提交一个作业（Application）</p>
<p>（2）作业提交后，RM根据从NM收集的资源信息，在有足够资源的节点分配一个容器，并与对应的NM进行通信，要求它在该容器中启动AM</p>
<p>（3）AM创建成功后向RM中的ASM注册自己，表示自己可以去管理一个作业（job）</p>
<p>（4）AM注册成功后，会对作业需要处理的数据进行切分，然后向RM申请资源，RM会根据给定的调度策略提供给请求的资源AM</p>
<p>（5）AM申请到资源成功后，会与集群中的NM通信，要求它启动任务</p>
<p>（6）NM接收到AM的要求后，根据作业提供的信息，启动对应的任务</p>
<p>（7）启动后的每个任务会定时向AM提供自己的状态信息和执行的进度</p>
<p>（8）作业运行完成后AM会向ASM注销和关闭自己</p>
<p>HDFS、YARN、MapReduce之间的关系：</p>
<p><img src="Snipaste_2023-10-06_12-05-22.png" alt="Snipaste_2023-10-06_12-05-22"></p>
<p>在客户端向ResourceManager提交任务后，ResourceManager为MapReduce程序分配资源，并且在任意节点上启动ApplicationMaster，ApplicationMaster为各任务申请资源。其中，MapTask的计算资源会被优先分配到数据块所在的节点中。在计算完成后，将输出数据上传至HDFS集群中。在这个过程中，HDFS集群主要负责存储输入数据和输出数据。</p>
<p>NameNode主要负责处理存储数据的读&#x2F;写请求、管理元数据信息等工作。</p>
<p>DataNode主要负责文件的具体存储工作。</p>
<p>SecondaryNameNode主要负责与NameNode协调完成定期合并EditLog与FsImage文件的工作。</p>
<h3 id="6-2-YARN的资源调度器和调度算法"><a href="#6-2-YARN的资源调度器和调度算法" class="headerlink" title="6.2 YARN的资源调度器和调度算法"></a>6.2 YARN的资源调度器和调度算法</h3><p><strong>资源调度器</strong>是YARN的核心组件之一，负责整个集群的资源调度工作，主要解决如何根据管理人员的既定策略分配资源的问题。</p>
<p>目前，YARN的资源调度器主要有三种：</p>
<ul>
<li>FIFO调度器</li>
<li>容量调度器（Apache Hadoop3.1.3默认使用）</li>
<li>公平调度器（CDH框架默认使用）</li>
</ul>
<p>查看默认配置文件yarn-default.xml文件：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The class to use as the resource scheduler.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="6-2-1-FIFO调度器"><a href="#6-2-1-FIFO调度器" class="headerlink" title="6.2.1 FIFO调度器"></a>6.2.1 FIFO调度器</h4><p>在Hadoop的最初版本中，使用的是简单的FIFO（先进先出）调度器，即单队列调度器，它将任务按照其到达的时间进行排序，<strong>队列中先到达的任务先获得资源</strong></p>
<img src="Snipaste_2023-10-06_12-43-37.png" alt="Snipaste_2023-10-06_12-43-37" style="zoom:50%;">

<p>优点：简单易懂</p>
<p>缺点：不支持多队列，会造成任务堵塞。如果job1占用了集群的所有资源且任务运行需要很长时间，那么队列后方的任务将无法获取任何计算资源，在生产环境中很少使用FIFO调度器。</p>
<h4 id="6-2-2-容量调度器"><a href="#6-2-2-容量调度器" class="headerlink" title="6.2.2 容量调度器"></a>6.2.2 容量调度器</h4><p>Yahoo开发</p>
<p><img src="Snipaste_2023-10-06_12-55-03.png" alt="Snipaste_2023-10-06_12-55-03"></p>
<p><img src="Snipaste_2023-10-06_12-58-40.png" alt="Snipaste_2023-10-06_12-58-40"></p>
<p>简而言之，就是先找资源占用率最低的那个队列先执行，选好队列后，按照优先级或提交时间优先顺序执行哪个任务，选好任务后，再按照容器优先级（本地性原则）优先分配资源。</p>
<h4 id="6-2-3-公平调度器"><a href="#6-2-3-公平调度器" class="headerlink" title="6.2.3 公平调度器"></a>6.2.3 公平调度器</h4><p>Facebook开发</p>
<p><img src="Snipaste_2023-10-06_13-25-36.png" alt="Snipaste_2023-10-06_13-25-36"></p>
<p>3）公平调度器的特点</p>
<p><img src="Snipaste_2023-10-06_13-26-09.png" alt="Snipaste_2023-10-06_13-26-09"></p>
<p>4）公平调度器的资源调度策略</p>
<p><img src="Snipaste_2023-10-06_13-26-45.png" alt="Snipaste_2023-10-06_13-26-45"></p>
<p><img src="Snipaste_2023-10-06_13-30-29.png" alt="Snipaste_2023-10-06_13-30-29"></p>
<p><img src="Snipaste_2023-10-06_13-35-55.png" alt="Snipaste_2023-10-06_13-35-55"></p>
<p><img src="Snipaste_2023-10-06_13-36-38.png" alt="Snipaste_2023-10-06_13-36-38"></p>
<h3 id="6-3-YARN实操"><a href="#6-3-YARN实操" class="headerlink" title="6.3 YARN实操"></a>6.3 YARN实操</h3><h4 id="6-3-1-常用的命令行命令"><a href="#6-3-1-常用的命令行命令" class="headerlink" title="6.3.1 常用的命令行命令"></a>6.3.1 常用的命令行命令</h4><p>对于YARN的状态，除了可以在hadoop103：8088页面查看，还可以通过命令行操作查看</p>
<p>执行WordCount官方示例程序，然后使用YARN的命令查看任务执行状况</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/hadoop-3.1.3/</span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output22</span><br></pre></td></tr></table></figure>

<p>在页面端可以查看到：</p>
<p><img src="Snipaste_2023-10-06_13-55-55.png" alt="Snipaste_2023-10-06_13-55-55"></p>
<h5 id="1-查看任务命令yarn-application"><a href="#1-查看任务命令yarn-application" class="headerlink" title="1. 查看任务命令yarn application"></a>1. 查看任务命令yarn application</h5><p>1）yarn application -list命令主要用于列出所有的Application</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn application -list</span><br><span class="line">2023-10-06 13:57:43,405 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Total number of applications (application-types: [], states: [SUBMITTED, ACCEPTED, RUNNING] and tags: []):0</span><br><span class="line">                Application-Id	    Application-Name	    Application-Type	      User	     Queue               State	       Final-State	       Progress	                       Tracking-URL</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>2）yarn application -list -appStates命令主要用于根据Application的状态筛选（所有状态：ALL、NEW、NEW_SAVING、SUBMITTED、ACCEPTED、RUNNING、FINISHED、FAILED、KILLED）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">执行以下命令，筛选所有处于FINISHED状态的Application</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn application -list -appStates FINISHED</span><br><span class="line">2023-10-06 14:01:50,118 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Total number of applications (application-types: [], states: [FINISHED] and tags: []):1</span><br><span class="line">                Application-Id	    Application-Name	    Application-Type	      User	     Queue               State	       Final-State	       Progress	                       Tracking-URL</span><br><span class="line">application_1696571130879_0001	          word count	           MAPREDUCE	      root	   default            FINISHED	         SUCCEEDED	           100%	http://hadoop102:19888/jobhistory/job/job_1696571130879_0001</span><br></pre></td></tr></table></figure>

<p>3）yarn application -kill <ApplicationId>用于杀死Application</ApplicationId></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn application -kill application_1696571130879_0001</span><br><span class="line">2023-10-06 14:05:58,053 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Application application_1696571130879_0001 has already finished </span><br></pre></td></tr></table></figure>

<h5 id="2-查看日志命令yarn-logs"><a href="#2-查看日志命令yarn-logs" class="headerlink" title="2. 查看日志命令yarn logs"></a>2. 查看日志命令yarn logs</h5><p>1）yarn logs -applicationId <ApplicationId>用于查询指定ApplicationId的Application日志</ApplicationId></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn logs -applicationId application_1696571130879_0001</span><br></pre></td></tr></table></figure>

<p>2）查询 Container 日志：yarn logs -applicationId <ApplicationId> -containerId <ContainerId></ContainerId></ApplicationId></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn logs -applicationId application_1696571130879_0001 -containerId container_1696571130879_0001_01_000001</span><br></pre></td></tr></table></figure>

<h5 id="3-查看尝试运行的任务命令yarn-applicationattempt"><a href="#3-查看尝试运行的任务命令yarn-applicationattempt" class="headerlink" title="3. 查看尝试运行的任务命令yarn applicationattempt"></a>3. 查看尝试运行的任务命令yarn applicationattempt</h5><p>1）yarn applicationattempt -list <ApplicationId>列出所有 Application 尝试的列表</ApplicationId></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn applicationattempt -list application_1696571130879_0001</span><br><span class="line">2023-10-06 14:14:44,321 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Total number of application attempts :1</span><br><span class="line">         ApplicationAttempt-Id	               State	                    AM-Container-Id	                       Tracking-URL</span><br><span class="line">appattempt_1696571130879_0001_000001	            FINISHED	container_1696571130879_0001_01_000001	http://hadoop103:8088/proxy/application_1696571130879_0001/</span><br></pre></td></tr></table></figure>

<p>2）打印 ApplicationAttemp 状态：yarn applicationattempt -status <ApplicationAttemptId></ApplicationAttemptId></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn applicationattempt -status appattempt_1696571130879_0001_000001</span><br><span class="line">2023-10-06 14:19:20,970 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Application Attempt Report : </span><br><span class="line">	ApplicationAttempt-Id : appattempt_1696571130879_0001_000001</span><br><span class="line">	State : FINISHED</span><br><span class="line">	AMContainer : container_1696571130879_0001_01_000001</span><br><span class="line">	Tracking-URL : http://hadoop103:8088/proxy/application_1696571130879_0001/</span><br><span class="line">	RPC Port : 44652</span><br><span class="line">	AM Host : hadoop104</span><br><span class="line">	Diagnostics : </span><br></pre></td></tr></table></figure>

<h5 id="4-查看容器命令yarn-container"><a href="#4-查看容器命令yarn-container" class="headerlink" title="4. 查看容器命令yarn container"></a>4. 查看容器命令yarn container</h5><p>1）列出所有 Container：yarn container -list <ApplicationAttemptId></ApplicationAttemptId></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn container -list appattempt_1696571130879_0001_000001</span><br><span class="line">2023-10-06 14:20:56,801 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Total number of containers :0</span><br><span class="line">                  Container-Id	          Start Time	         Finish Time	               State	                Host	   Node Http Address	                            LOG-URL</span><br></pre></td></tr></table></figure>

<p>2）打印 Container 状态：yarn container -status <ContainerId></ContainerId></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn container -status container_1696571130879_0001_01_000001</span><br><span class="line">2023-10-06 14:22:08,834 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Container with id &#x27;container_1696571130879_0001_01_000001&#x27; doesn&#x27;t exist in RM or Timeline Server.</span><br></pre></td></tr></table></figure>

<p><strong>注意：只有在任务运行的过程中才能看到Container的状态</strong></p>
<h5 id="5-查看节点状态命令yarn-node"><a href="#5-查看节点状态命令yarn-node" class="headerlink" title="5. 查看节点状态命令yarn node"></a>5. 查看节点状态命令yarn node</h5><p>列出所有NodeManager：yarn node -list -all</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn node -list -all</span><br><span class="line">2023-10-06 14:24:49,863 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Total Nodes:3</span><br><span class="line">         Node-Id	     Node-State	Node-Http-Address	Number-of-Running-Containers</span><br><span class="line"> hadoop103:39784	        RUNNING	   hadoop103:8042	                           0</span><br><span class="line"> hadoop102:33563	        RUNNING	   hadoop102:8042	                           0</span><br><span class="line"> hadoop104:44199	        RUNNING	   hadoop104:8042	                           0</span><br></pre></td></tr></table></figure>

<h5 id="6-更新配置命令yarn-rmadmin"><a href="#6-更新配置命令yarn-rmadmin" class="headerlink" title="6. 更新配置命令yarn rmadmin"></a>6. 更新配置命令yarn rmadmin</h5><p>重载队列配置：yarn rmadmin -refreshQueues</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]#  yarn rmadmin -refreshQueues</span><br><span class="line">2023-10-06 14:26:55,694 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8033</span><br></pre></td></tr></table></figure>

<h5 id="7-查看队列命令yarn-queue"><a href="#7-查看队列命令yarn-queue" class="headerlink" title="7. 查看队列命令yarn queue"></a>7. 查看队列命令yarn queue</h5><p>yarn queue -status <QueueName>用于打印指定名称的队列的状态信息</QueueName></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn queue -status default</span><br><span class="line">2023-10-06 14:28:30,807 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8032</span><br><span class="line">Queue Information : </span><br><span class="line">Queue Name : default</span><br><span class="line">	State : RUNNING</span><br><span class="line">	Capacity : 100.0%</span><br><span class="line">	Current Capacity : .0%</span><br><span class="line">	Maximum Capacity : 100.0%</span><br><span class="line">	Default Node Label expression : &lt;DEFAULT_PARTITION&gt;</span><br><span class="line">	Accessible Node Labels : *</span><br><span class="line">	Preemption : disabled</span><br><span class="line">	Intra-queue Preemption : disabled</span><br></pre></td></tr></table></figure>

<h4 id="6-3-2-核心参数（重要）"><a href="#6-3-2-核心参数（重要）" class="headerlink" title="6.3.2 核心参数（重要）"></a>6.3.2 核心参数（重要）</h4><p><img src="Snipaste_2023-10-06_14-33-37.png" alt="Snipaste_2023-10-06_14-33-37"></p>
<h4 id="6-3-3-核心参数配置案例"><a href="#6-3-3-核心参数配置案例" class="headerlink" title="6.3.3 核心参数配置案例"></a>6.3.3 核心参数配置案例</h4><p>本节主要学习这些参数是什么意思，如何调的，基本上在企业中是调好了不轻易更改了，因为不同的服务器节点内存和CPU信息不同，所以本节的数据仅供参考，如果配置完后发现某个队列的任务跑不起来，及时返回到快照yarn1即可。</p>
<p>首先给hadoop102,hadoop103,hadoop104分别设置快照</p>
<img src="Snipaste_2023-10-06_15-12-00.png" alt="Snipaste_2023-10-06_15-12-00" style="zoom: 50%;">

<img src="Snipaste_2023-10-06_15-13-15.png" alt="Snipaste_2023-10-06_15-13-15" style="zoom:50%;">

<img src="Snipaste_2023-10-06_15-13-44.png" alt="Snipaste_2023-10-06_15-13-44" style="zoom:50%;">

<h5 id="1-需求分析-5"><a href="#1-需求分析-5" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h5><p>1）需求：从 1G 数据中，统计每个单词出现次数。服务器 3 台，每台配置 4G 内存，4 核CPU，4 线程。</p>
<p>2）需求分析：</p>
<p>1G &#x2F; 128m &#x3D; 8 个 MapTask；1 个 ReduceTask；1 个 mrAppMaster</p>
<p>平均每个节点运行 10 个 &#x2F; 3 台 ≈ 3 个任务（4 ，3 ，3）</p>
<h5 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2. 代码实现"></a>2. 代码实现</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改yarn-site.xml配置参数</span></span><br><span class="line">[root@hadoop102 hadoop-3.1.3]# cd etc/hadoop/</span><br><span class="line">[root@hadoop102 hadoop]# vim yarn-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 选择调度器，默认容量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The class to use as the resource scheduler.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capaci</span><br><span class="line">ty.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- ResourceManager 处理调度器请求的线程数量,默认 50；如果提交的任务数大于 50，可以</span></span><br><span class="line"><span class="comment">增加该值，但是不能超过 3 台 * 4 线程 = 12 线程（去除其他应用程序实际不能超过 8） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of threads to handle scheduler </span><br><span class="line">interface.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.client.thread-count<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 是否让 yarn 自动检测硬件进行配置，默认是 false，如果该节点有很多其他应用程序，建议</span></span><br><span class="line"><span class="comment">手动配置。如果该节点没有其他应用程序，可以采用自动 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Enable auto-detection of node capabilities such as</span><br><span class="line">    memory and CPU.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.detect-hardware-capabilities<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 是否将虚拟核数当作 CPU 核数，默认是 false，采用物理 CPU 核数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Flag to determine if logical processors(such as</span><br><span class="line">    hyperthreads) should be counted as cores. Only applicable on Linux</span><br><span class="line">    when yarn.nodemanager.resource.cpu-vcores is set to -1 and</span><br><span class="line">    yarn.nodemanager.resource.detect-hardware-capabilities is true.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.count-logical-processors-as-cores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 虚拟核数和物理核数乘数，默认是 1.0 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Multiplier to determine how to convert phyiscal cores to</span><br><span class="line">    vcores. This value is used if yarn.nodemanager.resource.cpu-vcores</span><br><span class="line">    is set to -1(which implies auto-calculate vcores) and</span><br><span class="line">    yarn.nodemanager.resource.detect-hardware-capabilities is set to true. </span><br><span class="line">    The number of vcores will be calculated as number of CPUs * multiplier.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.pcores-vcores-multiplier<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- NodeManager 使用内存数，默认 8G，修改为 4G 内存 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Amount of physical memory, in MB, that can be allocated </span><br><span class="line">    for containers. If set to -1 and</span><br><span class="line">    yarn.nodemanager.resource.detect-hardware-capabilities is true, it is</span><br><span class="line">    automatically calculated(in case of Windows and Linux).</span><br><span class="line">    In other cases, the default is 8192MB.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- nodemanager 的 CPU 核数，不按照硬件环境自动设定时默认是 8 个，修改为 4 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of vcores that can be allocated</span><br><span class="line">    for containers. This is used by the RM scheduler when allocating</span><br><span class="line">    resources for containers. This is not used to limit the number of</span><br><span class="line">    CPUs used by YARN containers. If it is set to -1 and</span><br><span class="line">    yarn.nodemanager.resource.detect-hardware-capabilities is true, it is</span><br><span class="line">    automatically determined from the hardware in case of Windows and Linux.</span><br><span class="line">    In other cases, number of vcores is 8 by default.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 容器最小内存，默认 1G --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The minimum allocation for every container request at theRM in MBs. Memory requests lower than this will be set to the value of </span><br><span class="line">    this property. Additionally, a node manager that is configured to have </span><br><span class="line">    less memory than this value will be shut down by the resource manager.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 容器最大内存，默认 8G --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum allocation for every container request at the </span><br><span class="line">    RM in MBs. Memory requests higher than this will throw an</span><br><span class="line">    InvalidResourceRequestException.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>8192<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 容器最小 CPU 核数，默认 1 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The minimum allocation for every container request at the </span><br><span class="line">    RM in terms of virtual CPU cores. Requests lower than this will be set to </span><br><span class="line">    the value of this property. Additionally, a node manager that is configured </span><br><span class="line">    to have fewer virtual cores than this value will be shut down by the </span><br><span class="line">    resource manager.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 容器最大 CPU 核数，默认 4 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum allocation for every container request at the </span><br><span class="line">    RM in terms of virtual CPU cores. Requests higher than this will throw an</span><br><span class="line">    InvalidResourceRequestException.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 虚拟内存检查，默认打开，修改为关闭 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether virtual memory limits will be enforced for</span><br><span class="line">    containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 虚拟内存和物理内存设置比例,默认 2.1 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Ratio between virtual memory to physical memory when</span><br><span class="line">    setting memory limits for containers. Container allocations are</span><br><span class="line">    expressed in terms of physical memory, and virtual memory usage is </span><br><span class="line">    allowed to exceed this allocation by this ratio.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2.1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发配置文件</span></span><br><span class="line">[root@hadoop102 hadoop]# xsync yarn-site.xml </span><br><span class="line">============ hadoop102 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 62 bytes  received 12 bytes  148.00 bytes/sec</span><br><span class="line">total size is 7,887  speedup is 106.58</span><br><span class="line">============ hadoop103 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line">yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 5,908 bytes  received 59 bytes  11,934.00 bytes/sec</span><br><span class="line">total size is 7,887  speedup is 1.32</span><br><span class="line">============ hadoop104 ==============</span><br><span class="line">mkdir：无效选项 -- P</span><br><span class="line">Try &#x27;mkdir --help&#x27; for more information.</span><br><span class="line">sending incremental file list</span><br><span class="line">yarn-site.xml</span><br><span class="line"></span><br><span class="line">sent 5,908 bytes  received 59 bytes  3,978.00 bytes/sec</span><br><span class="line">total size is 7,887  speedup is 1.32</span><br></pre></td></tr></table></figure>

<p><strong>注意：如果集群中每台节点服务器的硬件资源都不一致，那么对每个NodeManager单独进行配置</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重新启动集群</span></span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh start</span><br><span class="line"> =================== 启动 hadoop 集群 ===================</span><br><span class="line"> --------------- 启动 hdfs ---------------</span><br><span class="line">WARNING: HADOOP_SECURE_DN_USER has been replaced by HDFS_DATANODE_SECURE_USER. Using value of HADOOP_SECURE_DN_USER.</span><br><span class="line">Starting namenodes on [hadoop102]</span><br><span class="line">hadoop102: namenode is running as process 2962.  Stop it first.</span><br><span class="line">上一次登录：五 10月  6 13:48:04 CST 2023</span><br><span class="line">Starting datanodes</span><br><span class="line">hadoop102: datanode is running as process 3969.  Stop it first.</span><br><span class="line">hadoop104: datanode is running as process 2700.  Stop it first.</span><br><span class="line">hadoop103: datanode is running as process 2768.  Stop it first.</span><br><span class="line">上一次登录：五 10月  6 15:41:06 CST 2023</span><br><span class="line">Starting secondary namenodes [hadoop104]</span><br><span class="line">hadoop104: secondarynamenode is running as process 2825.  Stop it first.</span><br><span class="line">上一次登录：五 10月  6 15:41:06 CST 2023</span><br><span class="line"> --------------- 启动 yarn ---------------</span><br><span class="line">Starting resourcemanager</span><br><span class="line">resourcemanager is running as process 2988.  Stop it first.</span><br><span class="line">上一次登录：五 10月  6 13:48:06 CST 2023</span><br><span class="line">Starting nodemanagers</span><br><span class="line">hadoop103: nodemanager is running as process 3745.  Stop it first.</span><br><span class="line">hadoop102: nodemanager is running as process 3402.  Stop it first.</span><br><span class="line">hadoop104: nodemanager is running as process 2921.  Stop it first.</span><br><span class="line">上一次登录：五 10月  6 15:41:09 CST 2023</span><br><span class="line"> --------------- 启动 historyserver ---------------</span><br><span class="line">historyserver is running as process 4361.  Stop it first.</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看各节点集群启动状态</span></span><br><span class="line">[root@hadoop102 hadoop]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">3969 DataNode</span><br><span class="line">2962 NameNode</span><br><span class="line">7206 Jps</span><br><span class="line">4361 JobHistoryServer</span><br><span class="line">3402 NodeManager</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">2768 DataNode</span><br><span class="line">3745 NodeManager</span><br><span class="line">5498 Jps</span><br><span class="line">2988 ResourceManager</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">5264 Jps</span><br><span class="line">2825 SecondaryNameNode</span><br><span class="line">2921 NodeManager</span><br><span class="line">2700 DataNode</span><br></pre></td></tr></table></figure>

<p>执行任务：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output222</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-06_15-53-21.png" alt="Snipaste_2023-10-06_15-53-21"></p>
<h4 id="6-3-4-容量调度器配置案例"><a href="#6-3-4-容量调度器配置案例" class="headerlink" title="6.3.4 容量调度器配置案例"></a>6.3.4 容量调度器配置案例</h4><p>在使用容量调度器时候，常见的两个问题：</p>
<p><strong>问题一：容量调度器默认只有1个default队列，不能满足实际需求，那么在生产环境中以什么标准划分队列？</strong></p>
<ul>
<li>按照<strong>计算框架</strong>：按照不同的计算框架（Hive，Spark，Flink等）划分队列。（企业中用的不多）</li>
<li>按照<strong>业务模块</strong>：按照不同的业务模块（登陆注册、购物车业务、下单业务、业务部门ABC）划分队列。（企业中用的多）</li>
</ul>
<p><strong>问题二：创建多队列有什么好处？</strong></p>
<ul>
<li>可以避免因为某个用户的代码失误，在代码中使用递归死循环等不当逻辑将所有资源耗尽。</li>
<li>实现不同业务的任务降级使用，在特殊时期，可以保证重要任务的队列资源充足。</li>
</ul>
<h5 id="1-需求分析-6"><a href="#1-需求分析-6" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h5><p>需求 1：default 队列占总内存的 40%，最大资源容量占总资源 60%，hive 队列占总内存的 60%，最大资源容量占总资源 80%。</p>
<p>需求 2：配置队列优先级</p>
<h5 id="2-配置多队列的容器调度器"><a href="#2-配置多队列的容器调度器" class="headerlink" title="2. 配置多队列的容器调度器"></a>2. 配置多队列的容器调度器</h5><p>（1）capacity-scheduler.xml文件中的配置如下，在根队列下配置2个队列，分别为default队列和hive队列</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定多队列，增加 hive 队列 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.queues<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>default,hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">        The queues at the this level (root is the root queue).</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）配置default队列的资源额定容量和最大资源占有量，代码如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 降低 default 队列资源额定容量为 40%，默认 100% --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>40<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 降低 default 队列资源最大容量为 60%，默认 100% --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.default.maximum-capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（3）配置hive队列的资源额定容量和最大资源占有量，代码如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定 hive 队列的资源额定容量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 用户最多可以使用队列资源的倍数，默认为1，确保无论集群有多空闲，单个用户都不会占有超过队列配置的资源 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.user-limit-factor<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定 hive 队列的资源最大容量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.maximum-capacity<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>80<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（4）对hive队列进行必要的配置，代码如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 启动 hive 队列 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.state<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>RUNNING<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 哪些用户有权向队列提交作业 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.acl_submit_applications<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 哪些用户有权操作队列，管理员权限（查看/杀死） --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.acl_administer_queue<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 哪些用户有权配置提交任务优先级 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.acl_application_max_priority<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 任务的超时时间设置：yarn application -appId appId -updateLifetime Timeout</span></span><br><span class="line"><span class="comment">参考资料： https://blog.cloudera.com/enforcing-application-lifetime-slas-yarn/ --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 如果 application 指定了超时时间，则提交到该队列的 application 能够指定的最大超时</span></span><br><span class="line"><span class="comment">时间不能超过该值。默认值为-1代表无上限</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.maximum-application-lifetime<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 如果 application 没指定超时时间，则用 default-application-lifetime 作为默认</span></span><br><span class="line"><span class="comment">值 ，默认值为-1代表无上限--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.capacity.root.hive.default-application-lifetime<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（5）分发配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# xsync capacity-scheduler.xml</span><br></pre></td></tr></table></figure>

<p>（6）执行以下命令刷新队列</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# yarn rmadmin -refreshQueues</span><br><span class="line">2023-10-06 19:15:29,957 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.255.103:8033</span><br></pre></td></tr></table></figure>

<p>（7）观察YARN的Web端，可以看到两个队列的配置情况：</p>
<p><img src="Snipaste_2023-10-06_19-28-39.png" alt="Snipaste_2023-10-06_19-28-39"></p>
<h5 id="3-向hive队列提交任务"><a href="#3-向hive队列提交任务" class="headerlink" title="3. 向hive队列提交任务"></a>3. 向hive队列提交任务</h5><p>（1）使用hadoop jar命令运行WordCount程序，通过<strong>mapreduce.job.queuename</strong>参数向hive队列提交任务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount -D mapreduce.job.queuename=hive /input /output3</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-06_20-17-09.png" alt="Snipaste_2023-10-06_20-17-09"></p>
<p>（2）在代码中对队列进行配置</p>
<p>默认的任务提交都是提交到 default 队列的。如果希望向其他队列提交任务，需要在Driver 中声明：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WcDrvier</span> &#123;</span><br><span class="line">     <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, </span><br><span class="line">        ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">         <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">         conf.set(<span class="string">&quot;mapreduce.job.queuename&quot;</span>,<span class="string">&quot;hive&quot;</span>);</span><br><span class="line">         <span class="comment">//1. 获取一个 Job 实例</span></span><br><span class="line">         <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line">         。。。 。。。</span><br><span class="line">         <span class="comment">//6. 提交 Job</span></span><br><span class="line">         <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">         System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-任务优先级"><a href="#4-任务优先级" class="headerlink" title="4. 任务优先级"></a>4. 任务优先级</h5><p>容量调度器，支持任务优先级的配置，在资源紧张时，优先级高的任务将优先获取资源。默认情况，Yarn 将所有任务的优先级限制为 0，若想使用任务的优先级功能，须开放该限制。</p>
<p>（1）修改yarn-site.xml文件，添加以下参数，将任务的最高优先级设置为5</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.cluster.max-application-priority<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）分发配置文件，并重启YARN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# xsync yarn-site.xml</span><br><span class="line">[root@hadoop103 hadoop-3.1.3]# sbin/stop-yarn.sh</span><br><span class="line">[root@hadoop103 hadoop-3.1.3]# sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<p>（3）模拟资源紧张环境，可连续提交以下任务，直到新提交的任务申请不到资源为止。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar pi 5 2000000</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-06_20-52-10.png" alt="Snipaste_2023-10-06_20-52-10"></p>
<p>（4）再次重新提交优先级高的任务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar pi -D mapreduce.job.priority=5 5 2000000</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-06_20-53-49.png" alt="Snipaste_2023-10-06_20-53-49"></p>
<p>（5）也可以通过以下命令修改正在执行的任务的优先级。yarn application -appID <ApplicationID> -updatePriority 优先级</ApplicationID></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ yarn application -appID application_1611133087930_0009 -updatePriority 5</span><br></pre></td></tr></table></figure>

<h4 id="6-3-5-公平调度器配置案例"><a href="#6-3-5-公平调度器配置案例" class="headerlink" title="6.3.5 公平调度器配置案例"></a>6.3.5 公平调度器配置案例</h4><h5 id="1-需求分析-7"><a href="#1-需求分析-7" class="headerlink" title="1. 需求分析"></a>1. 需求分析</h5><p>创建两个队列，分别是 test 和 atguigu（以用户所属组命名）。期望实现以下效果：若用户提交任务时指定队列，则任务提交到指定队列运行；若未指定队列，test 用户提交的任务到 root.group.test 队列运行，atguigu 提交的任务到 root.group.atguigu 队列运行（注：group 为用户所属组）。</p>
<p>公平调度器的配置涉及到两个文件，一个是 yarn-site.xml，另一个是公平调度器队列分配文件 fair-scheduler.xml（文件名可自定义）。</p>
<h5 id="2-配置多队列的公平调度器"><a href="#2-配置多队列的公平调度器" class="headerlink" title="2. 配置多队列的公平调度器"></a>2. 配置多队列的公平调度器</h5><p>（1）修改 yarn-site.xml 文件，加入以下参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@hadoop102 hadoop-3.1.3]# cd etc/hadoop/</span><br><span class="line">[root@hadoop102 hadoop]# vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>配置使用公平调度器<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.fair.allocation.file<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/etc/hadoop/fair-scheduler.xml<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>指明公平调度器队列分配配置文件<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.fair.preemption<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">description</span>&gt;</span>禁止队列间资源抢占<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）创建fair-scheduler.xml文件，并且在该文件中添加以下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# vim fair-scheduler.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">allocations</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 单个队列中 Application Master 占用资源的最大比例,取值 0-1 ，企业一般配置 0.1 </span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">queueMaxAMShareDefault</span>&gt;</span>0.5<span class="tag">&lt;/<span class="name">queueMaxAMShareDefault</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 单个队列最大资源的默认值 test atguigu default --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">queueMaxResourcesDefault</span>&gt;</span>4096mb,4vcores<span class="tag">&lt;/<span class="name">queueMaxResourcesDefault</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 增加一个队列 test --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;test&quot;</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列最小资源 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">minResources</span>&gt;</span>2048mb,2vcores<span class="tag">&lt;/<span class="name">minResources</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列最大资源 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">maxResources</span>&gt;</span>4096mb,4vcores<span class="tag">&lt;/<span class="name">maxResources</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列中最多同时运行的应用数，默认 50，根据线程数配置 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">maxRunningApps</span>&gt;</span>4<span class="tag">&lt;/<span class="name">maxRunningApps</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列中 Application Master 占用资源的最大比例 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">maxAMShare</span>&gt;</span>0.5<span class="tag">&lt;/<span class="name">maxAMShare</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 该队列资源权重,默认值为 1.0 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列内部的资源分配策略 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 增加一个队列 atguigu --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">queue</span> <span class="attr">name</span>=<span class="string">&quot;atguigu&quot;</span> <span class="attr">type</span>=<span class="string">&quot;parent&quot;</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列最小资源 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">minResources</span>&gt;</span>2048mb,2vcores<span class="tag">&lt;/<span class="name">minResources</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列最大资源 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">maxResources</span>&gt;</span>4096mb,4vcores<span class="tag">&lt;/<span class="name">maxResources</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列中最多同时运行的应用数，默认 50，根据线程数配置 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">maxRunningApps</span>&gt;</span>4<span class="tag">&lt;/<span class="name">maxRunningApps</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列中 Application Master 占用资源的最大比例 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">maxAMShare</span>&gt;</span>0.5<span class="tag">&lt;/<span class="name">maxAMShare</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 该队列资源权重,默认值为 1.0 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">weight</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">weight</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 队列内部的资源分配策略 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">schedulingPolicy</span>&gt;</span>fair<span class="tag">&lt;/<span class="name">schedulingPolicy</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">queue</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 任务队列分配策略,可配置多层规则,从第一个规则开始匹配,直到匹配成功 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">queuePlacementPolicy</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 提交任务时指定队列,如未指定提交队列,则继续匹配下一个规则; false 表示：如果指</span></span><br><span class="line"><span class="comment">定队列不存在,不允许自动创建--&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;specified&quot;</span> <span class="attr">create</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 提交到 root.group.username 队列,若 root.group 不存在,不允许自动创建；若</span></span><br><span class="line"><span class="comment">root.group.user 不存在,允许自动创建 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;nestedUserQueue&quot;</span> <span class="attr">create</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;primaryGroup&quot;</span> <span class="attr">create</span>=<span class="string">&quot;false&quot;</span>/&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!-- 最后一个规则必须为 reject 或者 default。Reject 表示拒绝创建提交失败，</span></span><br><span class="line"><span class="comment">default 表示把任务提交到 default 队列 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">rule</span> <span class="attr">name</span>=<span class="string">&quot;reject&quot;</span> /&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">queuePlacementPolicy</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">allocations</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（3）分发配置文件并重启YARN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# xsync yarn-site.xml</span><br><span class="line">[root@hadoop102 hadoop]# xsync fair-scheduler.xml</span><br><span class="line"></span><br><span class="line">[root@hadoop103 hadoop-3.1.3]# sbin/stop-yarn.sh</span><br><span class="line">[root@hadoop103 hadoop-3.1.3]# sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-06_21-21-40.png" alt="Snipaste_2023-10-06_21-21-40"></p>
<h5 id="3-测试提交任务"><a href="#3-测试提交任务" class="headerlink" title="3. 测试提交任务"></a>3. 测试提交任务</h5><p>（1）提交任务时指定队列test</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar pi -Dmapreduce.job.queuename=root.test 1 1</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-06_21-25-54.png" alt="Snipaste_2023-10-06_21-25-54"></p>
<h4 id="6-3-6-Tool接口案例"><a href="#6-3-6-Tool接口案例" class="headerlink" title="6.3.6 Tool接口案例"></a>6.3.6 Tool接口案例</h4><p>使用-D参数动态修改程序时可能会出错，因为会错把该设置当作传入的数据输入路径（第一个参数），使用Tool接口才能安全实现动态修改参数的功能</p>
<p>（1）新建Maven工程YarnDemo，在pom.xml文件中添加以下依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）创建com.atguigu.yarn包</p>
<p>（3）创建WordCount类，使其实现Tool接口，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> <span class="keyword">implements</span> <span class="title class_">Tool</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Configuration conf;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//核心驱动（conf需要传入）</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(WordCountDriver.class);</span><br><span class="line"></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        job.setReducerClass(WordCountReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span>: <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setConf</span><span class="params">(Configuration conf)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.conf = conf;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Configuration <span class="title function_">getConf</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> conf;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//mapper</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">WordCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">            String[] words = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (String word : words)&#123;</span><br><span class="line">                outK.set(word);</span><br><span class="line"></span><br><span class="line">                context.write(outK, outV);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//reducer</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">WordCountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (IntWritable value: values)&#123;</span><br><span class="line">                sum += value.get();</span><br><span class="line">            &#125;</span><br><span class="line">            outV.set(sum);</span><br><span class="line"></span><br><span class="line">            context.write(key, outV);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）创建WordCountDriver类，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Tool tool;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//1,创建配置文件</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.判断是否有Tool接口</span></span><br><span class="line">        <span class="keyword">switch</span> (args[<span class="number">0</span>])&#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;wordcount&quot;</span>:</span><br><span class="line">                tool = <span class="keyword">new</span> <span class="title class_">WordCount</span>();</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;No such tool : &quot;</span> + args[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.使用ToolRunner执行程序</span></span><br><span class="line">        <span class="comment">//Arrays.copyOfRange将原数组中的元素放到新数组中</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">run</span> <span class="operator">=</span> ToolRunner.run(conf, tool, Arrays.copyOfRange(args, <span class="number">1</span>, args.length));</span><br><span class="line"></span><br><span class="line">        System.exit(run);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（5）将程序打包，将jar包重命名为YarnDemo.jar，最后将jar包上传至Hadoop的安装目录下</p>
<img src="Snipaste_2023-10-07_12-56-34.png" alt="Snipaste_2023-10-07_12-56-34" style="zoom:50%;">

<img src="Snipaste_2023-10-07_12-57-57.png" alt="Snipaste_2023-10-07_12-57-57" style="zoom:50%;">

<p>（6）向集群提交jar包，带-D参数的情况，此时不会报错了</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop-3.1.3]# yarn jar YarnDemo.jar com.atguigu.yarn.WordCountDriver wordcount -Dmapreduce.job.queuename=root.test /input /output4</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-07_13-08-37.png" alt="Snipaste_2023-10-07_13-08-37" style="zoom:50%;">

<img src="Snipaste_2023-10-07_13-09-10.png" alt="Snipaste_2023-10-07_13-09-10" style="zoom: 33%;">

<p>测试完YARN后恢复到快照前的状态。</p>
<h2 id="第七章-高可用HA"><a href="#第七章-高可用HA" class="headerlink" title="第七章 高可用HA"></a>第七章 高可用HA</h2><h3 id="7-1-ZooKeeper详解"><a href="#7-1-ZooKeeper详解" class="headerlink" title="7.1  ZooKeeper详解"></a>7.1  ZooKeeper详解</h3><p>见《zookeeper框架学习笔记》</p>
<h3 id="7-2-HA概述"><a href="#7-2-HA概述" class="headerlink" title="7.2  HA概述"></a>7.2  HA概述</h3><h4 id="7-2-1-什么是HA"><a href="#7-2-1-什么是HA" class="headerlink" title="7.2.1 什么是HA"></a>7.2.1 什么是HA</h4><p>所谓 HA（High Availablity），即高可用（7*24 小时不中断服务）。实现高可用最关键的策略是消除单点故障。HA 严格来说应该分成各个组件的 HA机制：**HDFS 的 HA **和 <strong>YARN 的 HA</strong>。</p>
<p>NameNode 主要在以下两个方面影响 HDFS 集群：</p>
<ul>
<li>NameNode 机器发生意外，如宕机，集群将无法使用，直到管理员重启</li>
<li>NameNode 机器需要升级，包括软件、硬件升级，此时集群也将无法使用</li>
</ul>
<p>HDFS HA 功能通过配置多个 NameNodes(Active&#x2F;Standby)实现在集群中对 NameNode 的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可通过此种方式将 NameNode 很快的切换到另外一台机器。</p>
<h4 id="7-2-2-HDFS-HA的工作机制"><a href="#7-2-2-HDFS-HA的工作机制" class="headerlink" title="7.2.2 HDFS HA的工作机制"></a>7.2.2 HDFS HA的工作机制</h4><p>在配置多个NN实现HA前，HDFS通过SecondaryNameNode机制保障NN的正常运行及宕机重启。在配置了多个NN后，我们需要回答以下几个问题：</p>
<p><strong>（1）如何保证多个NN的数据一致性</strong></p>
<p>FsImage：其中一个NN负责生成快照文件FsImage，其他NN拉取同步；</p>
<p>Edits：通过引进新的集群角色日志节点JournalNode，保证多个NN中的编辑日志文件EditLog的数据一致性。</p>
<p>当FsImage文件与EditLog文件都能保持一致时，NN可以提供相同的元数据管理服务。在备用NN接管工作后，会加载所有现有FsImage文件和EditLog文件，实现状态同步。</p>
<p><strong>（2）如何使多个NN中的一个处于Active状态，其他处于Standby状态</strong></p>
<p>同时有两个NN处于Active状态对于Hadoop集群来说是致命的，这种现象称为<strong>脑裂</strong>，应该避免。</p>
<p>Hadoop提供了一种称为<strong>故障转移控制器</strong>的监控进程，它可以在每一个NN上启动，时刻监控NN的状态。</p>
<p><strong>ZKFC</strong>是一种常用的故障转移控制器，是基于ZooKeeper实现的，当ZKFC运行在处于Active状态的NN上时，会<strong>在发现其状态不正常</strong>时向ZooKeeper中写入数据。当ZKFC运行在处于Standby状态的NN上时，会从ZooKeeper中读取数据，从而感知处于Active状态的NN是否在正常工作，以便顺利完成故障转移工作。</p>
<p>备用NN在感知到处于Active状态的NN出现异常后，通过以下步骤实现故障自动转移：</p>
<p>①通过SSH远程杀死处于Active状态的NN进程</p>
<p>②撤销处于Active状态的NN访问共享存储目录的权限</p>
<p>③通过远程管理命令屏蔽相应的网络接口</p>
<p>④通过一个特定的供电单元对相应主机进行断点操作</p>
<p><strong>（3）HA架构中不包含SecondaryNameNode，那么定期合并FsImage文件和EditLog文件的工作由谁负责</strong></p>
<p>备用NN中包含SecondaryNameNode的角色，处于Standby状态的NN会定时为处于Active状态的NN合并FsImage文件和EditLog文件</p>
<h3 id="7-3-Hadoop-HA集群的搭建"><a href="#7-3-Hadoop-HA集群的搭建" class="headerlink" title="7.3 Hadoop HA集群的搭建"></a>7.3 Hadoop HA集群的搭建</h3><h4 id="7-3-1-HDFS-HA手动故障转移"><a href="#7-3-1-HDFS-HA手动故障转移" class="headerlink" title="7.3.1 HDFS HA手动故障转移"></a>7.3.1 HDFS HA手动故障转移</h4><img src="Snipaste_2023-11-06_19-13-03.png" alt="Snipaste_2023-11-06_19-13-03" style="zoom:50%;">

<p>高可用集群规划：</p>
<img src="Snipaste_2023-11-06_19-14-06.png" alt="Snipaste_2023-11-06_19-14-06" style="zoom:50%;">

<p>（1）在opt目录下创建一个ha文件夹，用于安装高可用Hadoop HA集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt</span><br><span class="line">[root@hadoop102 opt]# mkdir ha</span><br><span class="line">[root@hadoop102 opt]# chown atguigu:atguigu /opt/ha</span><br></pre></td></tr></table></figure>

<p>（2）将&#x2F;opt&#x2F;module&#x2F;目录下的hadoop-3.1.3复制到&#x2F;opt&#x2F;ha目录下，并且删除data和log目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 opt]# cp -r /opt/module/hadoop-3.1.3 /opt/ha/</span><br><span class="line">[root@hadoop102 opt]# rm -rf /opt/ha/hadoop-3.1.3/data/</span><br><span class="line">[root@hadoop102 opt]# rm -rf /opt/ha/hadoop-3.1.3/logs/</span><br></pre></td></tr></table></figure>

<p>（3）修改配置文件core-site.xml，代码如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 把多个 NameNode 的地址组装成一个集群 mycluster --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定 hadoop 运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/ha/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（4）修改配置文件hdfs-site.xml，将hadoop102、hadoop103和hadoop104节点服务器中NN分别命名为nn1、nn2和nn3</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode 数据存储目录 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- DataNode 数据存储目录 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- JournalNode 数据存储目录 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 完全分布式集群名称 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 集群中 NameNode 节点都有哪些 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2,nn3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode 的 RPC 通信地址 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- NameNode 的 http 通信地址 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 NameNode 元数据在 JournalNode 上的存放位置 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hadoop102:8485;hadoop103:8485;hadoop104:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 访问代理类：client 用于确定哪个 NameNode 为 Active --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 使用隔离机制时需要 ssh 秘钥登录--&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/atguigu/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（5）修改完成配置之后，将配置好的hadoop-3.1.3分发到其他节点中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# xsync /opt/ha/hadoop-3.1.3</span><br></pre></td></tr></table></figure>

<p>（6）修改环境变量，将HADOOP_HOME环境变量放到HA目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">老的</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">新的</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/ha/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>source一下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# source /etc/profile</span><br></pre></td></tr></table></figure>

<p>103和104都要做</p>
<p>（7）在各个JournalNode上执行以下命令，启动JournalNode服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# hdfs --daemon start journalnode</span><br><span class="line">[root@hadoop103 ha]# hdfs --daemon start journalnode</span><br><span class="line">[root@hadoop104 ~]# hdfs --daemon start journalnode</span><br></pre></td></tr></table></figure>

<p>（8）在hadoop102节点服务器上对NN进行格式化并启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# hdfs namenode -format</span><br><span class="line">[root@hadoop102 hadoop]# hdfs --daemon start namenode</span><br></pre></td></tr></table></figure>

<p>（9）在hadoop103和104节点服务器中同步hadoop102节点服务器中的NN的元数据信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 ha]# hdfs namenode -bootstrapStandby</span><br><span class="line">[root@hadoop104 ~]# hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure>

<p>（10）分别在hadoop103和104上启动NN</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 ha]# hdfs --daemon start namenode</span><br><span class="line">[root@hadoop104 ~]# hdfs --daemon start namenode</span><br></pre></td></tr></table></figure>

<p>（11）分别登录3台节点服务器中NN的web端页面，可以看到，3台节点服务器中的NameNode都处于Standby状态</p>
<img src="Snipaste_2023-11-06_20-05-13.png" alt="Snipaste_2023-11-06_20-05-13" style="zoom:33%;">

<img src="Snipaste_2023-11-06_20-05-23.png" alt="Snipaste_2023-11-06_20-05-23" style="zoom:33%;">

<img src="Snipaste_2023-11-06_20-05-36.png" alt="Snipaste_2023-11-06_20-05-36" style="zoom:33%;">

<p>（12）在所有节点服务器上启动DataNode</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]#  hdfs --daemon start datanode</span><br><span class="line">[root@hadoop103 ha]# hdfs --daemon start datanode</span><br><span class="line">[root@hadoop104 ~]# hdfs --daemon start datanode</span><br></pre></td></tr></table></figure>

<p>（13）将nn1的状态切换为Active</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# hdfs haadmin -transitionToActive nn1</span><br></pre></td></tr></table></figure>

<p>（14）查看nn1是否处于Active状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# hdfs haadmin -getServiceState nn1</span><br><span class="line">active</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">5584 JournalNode</span><br><span class="line">6643 Jps</span><br><span class="line">5820 NameNode</span><br><span class="line">6316 DataNode</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">5938 Jps</span><br><span class="line">5348 NameNode</span><br><span class="line">5017 JournalNode</span><br><span class="line">5738 DataNode</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">4486 JournalNode</span><br><span class="line">5191 DataNode</span><br><span class="line">4794 NameNode</span><br><span class="line">5391 Jps</span><br></pre></td></tr></table></figure>

<h4 id="7-3-2-HDFS-HA自动故障转移"><a href="#7-3-2-HDFS-HA自动故障转移" class="headerlink" title="7.3.2 HDFS HA自动故障转移"></a>7.3.2 HDFS HA自动故障转移</h4><p>自动故障转移为 HDFS 部署增加了两个新组件：ZooKeeper 和 ZKFailoverController（ZKFC）进程，其中，ZooKeeper会维护NN的状态数据，并且通知ZKFC这些数据的变化情况。</p>
<p><img src="Snipaste_2023-11-06_20-27-43.png" alt="Snipaste_2023-11-06_20-27-43"></p>
<p>集群规划：</p>
<img src="Snipaste_2023-11-06_20-35-08.png" alt="Snipaste_2023-11-06_20-35-08" style="zoom:50%;">

<p>具体步骤如下：</p>
<p>（1）修改配置文件</p>
<p>在 hdfs-site.xml 中增加，启用HDFS HA自动故障转移功能</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 启用 nn 故障自动转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>在 core-site.xml 文件中增加，指定ZooKeeper服务器的地址和端口号</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定 zkfc 要连接的 zkServer 地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>分发修改后的配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 etc]# xsync hadoop/</span><br></pre></td></tr></table></figure>

<p>（2）启动</p>
<p>关闭所有的HDFS服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# stop-dfs.sh</span><br><span class="line">[root@hadoop102 ~]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">9036 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">7348 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">6561 Jps</span><br></pre></td></tr></table></figure>

<p>启动ZooKeeper集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# zk.sh start</span><br></pre></td></tr></table></figure>

<p>启动zk集群后，初始化HA在ZooKeeper集群中的状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>

<p>再次启动HDFS服务，代码如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# start-dfs.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">9105 QuorumPeerMain</span><br><span class="line">12035 DFSZKFailoverController</span><br><span class="line">11397 NameNode</span><br><span class="line">11814 JournalNode</span><br><span class="line">12150 Jps</span><br><span class="line">11547 DataNode</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">8352 DataNode</span><br><span class="line">8674 Jps</span><br><span class="line">8262 NameNode</span><br><span class="line">7415 QuorumPeerMain</span><br><span class="line">8456 JournalNode</span><br><span class="line">8586 DFSZKFailoverController</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">7570 DataNode</span><br><span class="line">7874 Jps</span><br><span class="line">6627 QuorumPeerMain</span><br><span class="line">7480 NameNode</span><br><span class="line">7674 JournalNode</span><br><span class="line">7805 DFSZKFailoverController</span><br></pre></td></tr></table></figure>

<p>**注意：目前为止集群启动脚本为：zk.sh start —–&gt; start-dfs.sh **</p>
<p>此时去查看3台节点服务器中NN的Web端页面，查看NN状态，可以看到，自动地102NN处于Active状态，103和104NN处于Standby状态。</p>
<img src="Snipaste_2023-11-06_21-26-10.png" alt="Snipaste_2023-11-06_21-26-10" style="zoom: 33%;">

<img src="Snipaste_2023-11-06_21-26-20.png" alt="Snipaste_2023-11-06_21-26-20" style="zoom:33%;">

<img src="Snipaste_2023-11-06_21-26-27.png" alt="Snipaste_2023-11-06_21-26-27" style="zoom:33%;">

<p>上传文件测试：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将README.md文件上传至根目录/</span></span><br><span class="line">[root@hadoop102 zookeeper-3.5.7]# hadoop fs -put README.md /</span><br><span class="line">2023-11-06 22:03:59,796 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<p>上传成功：</p>
<img src="Snipaste_2023-11-06_22-05-32.png" alt="Snipaste_2023-11-06_22-05-32" style="zoom:50%;">

<h4 id="7-3-3-YARN-HA"><a href="#7-3-3-YARN-HA" class="headerlink" title="7.3.3 YARN HA"></a>7.3.3 YARN HA</h4><p>YARN HA配置多个ResourceManager，其中一个ResourceManager处于Active状态，其他ResourceManager处于Standby状态，处于Active状态的ResourceManager将状态写入ZooKeeper，当其他备用ResourceManager切换状态时，可以直接从ZooKeeper中读取，从而继续进行任务和资源调度。</p>
<img src="Snipaste_2023-11-07_12-45-56.png" alt="Snipaste_2023-11-07_12-45-56" style="zoom:33%;">

<p>集群规划：</p>
<img src="Snipaste_2023-11-07_12-48-36.png" alt="Snipaste_2023-11-07_12-48-36" style="zoom:50%;">

<p>具体配置：</p>
<p>（1）修改配置文件yarn-site.xml，将Hadoop102、103、104节点服务器中的ResourceManager分别命名为rm1，rm2和rm3</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/ha/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[root@hadoop102 hadoop]# vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 启用 resourcemanager ha --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 声明两台 resourcemanager 的地址 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster-yarn1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!--指定 resourcemanager 的逻辑列表--&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2,rm3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm1 的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的主机名 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的 web 端地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的内部通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定供 NM 连接的地址 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm2 的配置 ========== --&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 指定 rm2 的主机名 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- ========== rm3 的配置 ========== --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的主机名 --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的 web 端地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 rm1 的内部通信地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定供 NM 连接的地址 --&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 指定 zookeeper 集群的地址 --&gt;</span> </span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 启用自动恢复 --&gt;</span> </span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="comment">&lt;!-- 指定 resourcemanager 的状态信息存储在 zookeeper 集群 --&gt;</span> </span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span>     </span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）将配置文件分发至其他节点服务器中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# xsync yarn-site.xml</span><br></pre></td></tr></table></figure>

<p>（3）启动hadoop集群（HDFS和YARN都启动）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# zk.sh start</span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh start</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">5824 DataNode</span><br><span class="line">6337 DFSZKFailoverController</span><br><span class="line">6946 JobHistoryServer</span><br><span class="line">6579 NodeManager</span><br><span class="line">5430 QuorumPeerMain</span><br><span class="line">6089 JournalNode</span><br><span class="line">7050 Jps</span><br><span class="line">6459 ResourceManager</span><br><span class="line">5676 NameNode</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">6065 ResourceManager</span><br><span class="line">5460 JournalNode</span><br><span class="line">5604 DFSZKFailoverController</span><br><span class="line">5352 DataNode</span><br><span class="line">6233 NodeManager</span><br><span class="line">5147 QuorumPeerMain</span><br><span class="line">5259 NameNode</span><br><span class="line">6463 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">4450 DataNode</span><br><span class="line">4818 ResourceManager</span><br><span class="line">4357 NameNode</span><br><span class="line">4923 NodeManager</span><br><span class="line">4220 QuorumPeerMain</span><br><span class="line">5100 Jps</span><br><span class="line">4558 JournalNode</span><br><span class="line">4702 DFSZKFailoverController</span><br></pre></td></tr></table></figure>

<p>（4）查看rm1的服务状态，是Active状态</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# yarn rmadmin -getServiceState rm1</span><br><span class="line">active</span><br></pre></td></tr></table></figure>

<p>（5）在YARN的Web端页面查看hadoop102:8088，hadoop103:8088，hadoop104:8088的YARN的状态，需要注意的是，无论用户访问哪台节点服务器的8088端口，都会自动跳转到处于Active状态的节点服务器。</p>
<img src="Snipaste_2023-11-07_13-24-21.png" alt="Snipaste_2023-11-07_13-24-21" style="zoom: 33%;">

<h4 id="7-3-4-Hadoop-HA最终规划"><a href="#7-3-4-Hadoop-HA最终规划" class="headerlink" title="7.3.4 Hadoop HA最终规划"></a>7.3.4 Hadoop HA最终规划</h4><table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>NameNode</td>
<td>NameNode</td>
</tr>
<tr>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>Zookeeper</td>
<td>Zookeeper</td>
</tr>
<tr>
<td>ZKFC</td>
<td>ZKFC</td>
<td>ZKFC</td>
</tr>
<tr>
<td>ResourceManager</td>
<td>ResourceManager</td>
<td>ResourceManager</td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<h2 id="高可用和非高可用模式的切换"><a href="#高可用和非高可用模式的切换" class="headerlink" title="高可用和非高可用模式的切换"></a>高可用和非高可用模式的切换</h2><p>如果我想回到原来的非高可用hadoop怎么办？</p>
<p>（1）首先关闭掉所有后台进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">12044 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">10095 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">6898 Jps</span><br></pre></td></tr></table></figure>

<p>（2）修改环境变量（并source）在103和104上做同样的操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">export</span> HADOOP_HOME=/opt/ha/hadoop-3.1.3</span></span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line">[root@hadoop102 ~]# source /etc/profile</span><br></pre></td></tr></table></figure>

<p>（3）启动集群即为非高可用hadoop集群（4-3-3模式）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# myhadoop.sh start</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">13105 Jps</span><br><span class="line">12498 DataNode</span><br><span class="line">12835 NodeManager</span><br><span class="line">12317 NameNode</span><br><span class="line">13023 JobHistoryServer</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">10192 DataNode</span><br><span class="line">10946 Jps</span><br><span class="line">10745 NodeManager</span><br><span class="line">10410 ResourceManager</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">6995 DataNode</span><br><span class="line">7205 NodeManager</span><br><span class="line">7353 Jps</span><br><span class="line">7114 SecondaryNameNode</span><br></pre></td></tr></table></figure>

<p>（4）修改环境变量（并source）在103和104上做同样的操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.1.3</span></span><br><span class="line">export HADOOP_HOME=/opt/ha/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line">[root@hadoop102 ~]# source /etc/profile</span><br></pre></td></tr></table></figure>

<p>（5）启动集群即为高可用hadoop集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先启动zk</span></span><br><span class="line">[root@hadoop102 ~]# zk.sh start</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再启动高可用hadoop</span></span><br><span class="line">[root@hadoop102 ~]# myhadoop.sh start</span><br><span class="line">[root@hadoop102 ~]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">5824 DataNode</span><br><span class="line">6337 DFSZKFailoverController</span><br><span class="line">6946 JobHistoryServer</span><br><span class="line">6579 NodeManager</span><br><span class="line">5430 QuorumPeerMain</span><br><span class="line">6089 JournalNode</span><br><span class="line">7050 Jps</span><br><span class="line">6459 ResourceManager</span><br><span class="line">5676 NameNode</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">6065 ResourceManager</span><br><span class="line">5460 JournalNode</span><br><span class="line">5604 DFSZKFailoverController</span><br><span class="line">5352 DataNode</span><br><span class="line">6233 NodeManager</span><br><span class="line">5147 QuorumPeerMain</span><br><span class="line">5259 NameNode</span><br><span class="line">6463 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">4450 DataNode</span><br><span class="line">4818 ResourceManager</span><br><span class="line">4357 NameNode</span><br><span class="line">4923 NodeManager</span><br><span class="line">4220 QuorumPeerMain</span><br><span class="line">5100 Jps</span><br><span class="line">4558 JournalNode</span><br><span class="line">4702 DFSZKFailoverController</span><br></pre></td></tr></table></figure>

<h2 id="第八章-生产调优手册"><a href="#第八章-生产调优手册" class="headerlink" title="第八章 生产调优手册"></a>第八章 生产调优手册</h2>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/08/05/Hadoop%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Python金融大数据挖掘与分析" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/14/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/">Python金融大数据挖掘与分析</a>
    </h1>
  

        
        <a href="/2023/07/14/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/" class="archive-article-date">
  	<time datetime="2023-07-14T03:05:11.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-07-14</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Python基础"><a href="#第一章-Python基础" class="headerlink" title="第一章 Python基础"></a>第一章 Python基础</h1><p>略</p>
<h1 id="第二章-金融数据挖掘之爬虫技术基础"><a href="#第二章-金融数据挖掘之爬虫技术基础" class="headerlink" title="第二章 金融数据挖掘之爬虫技术基础"></a>第二章 金融数据挖掘之爬虫技术基础</h1><h2 id="2-1-爬虫技术基础1——网页结构基础"><a href="#2-1-爬虫技术基础1——网页结构基础" class="headerlink" title="2.1 爬虫技术基础1——网页结构基础"></a>2.1 爬虫技术基础1——网页结构基础</h2><h3 id="2-1-1-查看网页源代码——F12键"><a href="#2-1-1-查看网页源代码——F12键" class="headerlink" title="2.1.1 查看网页源代码——F12键"></a>2.1.1 查看网页源代码——F12键</h3><p>在谷歌浏览器中，按F12键弹出网页源码：</p>
<p><img src="Snipaste_2023-07-14_17-25-58.png" alt="Snipaste_2023-07-14_17-25-58"></p>
<h4 id="1-“选择”按钮"><a href="#1-“选择”按钮" class="headerlink" title="1. “选择”按钮"></a>1. “选择”按钮</h4><p>单击“选择”按钮，然后在网页中移动鼠标，鼠标指针所指向的网页元素的颜色会发生变化，“Elements”选项卡里的内容也会随之改变。</p>
<p><img src="Snipaste_2023-07-14_17-30-12.png" alt="Snipaste_2023-07-14_17-30-12"></p>
<h4 id="2-“Elements”选项卡"><a href="#2-“Elements”选项卡" class="headerlink" title="2. “Elements”选项卡"></a>2. “Elements”选项卡</h4><p>“Elements”选项卡里面的内容可以理解为就是网页的源代码，最后爬虫爬到的内容大致就是这样。可以在此处双击将其进行文本编辑。</p>
<p><img src="Snipaste_2023-07-14_17-39-58.png" alt="Snipaste_2023-07-14_17-39-58"></p>
<h3 id="2-1-2-查看网页源代码——右键菜单"><a href="#2-1-2-查看网页源代码——右键菜单" class="headerlink" title="2.1.2 查看网页源代码——右键菜单"></a>2.1.2 查看网页源代码——右键菜单</h3><p>网页空白处右键“查看网页源代码”命令，实战中利用F12键对网页结构进行初步了解，然后再网页上右击选择“查看网页源代码”命令，查看所需内容再网页源代码的位置，或者通过Ctrl+F搜索需要的内容。</p>
<p><img src="Snipaste_2023-07-14_18-00-30.png" alt="Snipaste_2023-07-14_18-00-30"></p>
<p>有时候通过F12键能看到的内容，但是通过查看网页源代码却看不到，这是因为有些网页是动态渲染出来的，例如有些股价信息是动态变化的，股价内容自然不会固定地写到网页源码中，F12看到的是经过渲染后的，更加全面和丰富。</p>
<h3 id="2-1-3-网址构成及http与https协议"><a href="#2-1-3-网址构成及http与https协议" class="headerlink" title="2.1.3 网址构成及http与https协议"></a>2.1.3 网址构成及http与https协议</h3><p>https更安全，最好方法是在浏览器中直接访问，再将地址栏中的内容复制到Python代码中</p>
<h3 id="2-1-4-网页结构初步了解"><a href="#2-1-4-网页结构初步了解" class="headerlink" title="2.1.4 网页结构初步了解"></a>2.1.4 网页结构初步了解</h3><p>结构其实很简单，就是一个大框套着一个小框，一个小框再套着一个小小框，<strong>一般文本内容都</strong>是在最后的小框里。</p>
<p><img src="Snipaste_2023-07-14_19-56-58.png" alt="Snipaste_2023-07-14_19-56-58"></p>
<h2 id="2-2-爬虫技术基础2——网页结构进阶"><a href="#2-2-爬虫技术基础2——网页结构进阶" class="headerlink" title="2.2 爬虫技术基础2——网页结构进阶"></a>2.2 爬虫技术基础2——网页结构进阶</h2><h3 id="2-2-1-HTML基础知识1——我的第一个网页"><a href="#2-2-1-HTML基础知识1——我的第一个网页" class="headerlink" title="2.2.1 HTML基础知识1——我的第一个网页"></a>2.2.1 HTML基础知识1——我的第一个网页</h3><p>HTML（HyperText Markup Language）是一种用于编写网页的标准标记语言</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>hello world<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-14_18-27-58.png" alt="Snipaste_2023-07-14_18-27-58"></p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">h1</span>&gt;</span>这是标题 1<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是标题1下的段落。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">h2</span>&gt;</span>这是标题 2<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.baidu.com&quot;</span>&gt;</span>这是带链接的内容<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-14_18-28-07.png" alt="Snipaste_2023-07-14_18-28-07" style="zoom:43%;">

<h3 id="2-2-2-HTML基础知识2——基础结构"><a href="#2-2-2-HTML基础知识2——基础结构" class="headerlink" title="2.2.2 HTML基础知识2——基础结构"></a>2.2.2 HTML基础知识2——基础结构</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">h1</span>&gt;</span>这是标题 1<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是标题1下的段落。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">h2</span>&gt;</span>这是标题 2<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.baidu.com&quot;</span>&gt;</span>这是带链接的内容<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>前两行的<!DOCTYPE html>与<html>是固定写法，作用是将代码声明为HTML文档。</html></p>
<body>框表示主体信息，是最终展示在网页上的内容。<body>框里的一些小框则是各种具体内容。

<p>&lt;&gt;包围起来的的内容就是标签，例如，<body>读作body标签，通常写完<body>之后，最后得写一个</body>，表示一个框的闭合</body></p>
<h3 id="2-2-3-HTML基础知识3——标题、段落、链接"><a href="#2-2-3-HTML基础知识3——标题、段落、链接" class="headerlink" title="2.2.3 HTML基础知识3——标题、段落、链接"></a>2.2.3 HTML基础知识3——标题、段落、链接</h3><h4 id="1-标签——定义标题"><a href="#1-标签——定义标题" class="headerlink" title="1. 标签——定义标题"></a>1. <h>标签——定义标题</h></h4><p>标题是通过</p><h1>~<h6>标签来定义的，一般格式为：<h1>标题内容</h1>。其中<h1>的字号最大，<h6>的字号最小<p></p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>网页名称<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>这是标题1<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span>&gt;</span>这是标题2<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h3</span>&gt;</span>这是标题3<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-14_19-05-13.png" alt="Snipaste_2023-07-14_19-05-13" style="zoom:43%;">

<h4 id="2-标签——定义段落"><a href="#2-标签——定义段落" class="headerlink" title="2. 标签——定义段落"></a>2. <p>标签——定义段落</p></h4><p>段落是通过</p><p>标签来定义的，一般格式为：</p><p>段落内容</p><p></p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>网页名称<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>这是标题1<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是标题1下的段落。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是标题1下的又一个段落.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span>&gt;</span>这是标题2<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是标题2下的段落。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h3</span>&gt;</span>这是标题3<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-14_19-09-16.png" alt="Snipaste_2023-07-14_19-09-16" style="zoom:43%;">

<h4 id="3-标签——定义链接"><a href="#3-标签——定义链接" class="headerlink" title="3. 标签——定义链接"></a>3. <a>标签——定义链接</a></h4><p>格式：<a href="链接地址">文本内容</a></p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>网页名称<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>这是标题1<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是标题1下的段落。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是标题1下的又一个段落.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span>&gt;</span>这是标题2<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>这是标题2下的段落。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;https://www.alibaba.com&quot;</span>&gt;</span>这是阿里巴巴的网站<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h3</span>&gt;</span>这是标题3<span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-14_19-12-54.png" alt="Snipaste_2023-07-14_19-12-54" style="zoom:43%;">

<p>除了这些标签外，还有一些常用的标签：定义表格的<table>标签、定义序号的<li>标签、定义图片的<img>标签、定义样式的<script>标签等</p>
<h3 id="2-2-4-HTML基础知识4——区块"><a href="#2-2-4-HTML基础知识4——区块" class="headerlink" title="2.2.4 HTML基础知识4——区块"></a>2.2.4 HTML基础知识4——区块</h3><p>区块的最主要表现格式为<div>XXX</div>格式</p>
<p><img src="/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/Snipaste_2023-07-14_19-52-49.png" alt="Snipaste_2023-07-14_19-52-49"></p>
<div>XXX</div>起到了分区的作用

<p><img src="/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/%E5%9B%BE%E7%89%87.png" alt="图片"></p>
<h3 id="2-2-5-HTML基础知识5——类与id"><a href="#2-2-5-HTML基础知识5——类与id" class="headerlink" title="2.2.5 HTML基础知识5——类与id"></a>2.2.5 HTML基础知识5——类与id</h3><h4 id="1-类（class）"><a href="#1-类（class）" class="headerlink" title="1. 类（class）"></a>1. 类（class）</h4><p><img src="/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/%E5%9B%BE%E7%89%8711.png" alt="图片11"></p>
<h4 id="2-id"><a href="#2-id" class="headerlink" title="2. id"></a>2. id</h4><p>id的区分作用则更加细致，每个class（类）可能相同，但是他们的id一般都不会相同</p>
<p><img src="/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/%E5%9B%BE%E7%89%8788.png" alt="图片88"></p>
<h2 id="2-3-初步实战——百度新闻源代码获取"><a href="#2-3-初步实战——百度新闻源代码获取" class="headerlink" title="2.3 初步实战——百度新闻源代码获取"></a>2.3 初步实战——百度新闻源代码获取</h2><p>为了解决网站只认可浏览器发送的请求而不认可python发送的请求的问题，需要设置requests.get()中的headers参数，模拟浏览器访问请求。headers参数提供的是网站访问者的信息，headers中的User-Agent（用户代理）表示是用什么浏览器访问的，其获取方法如下：</p>
<ol>
<li>打开谷歌浏览器</li>
<li>在地址栏输入“about:version”</li>
<li>在打开的界面中找到“用户代理”项，后面的字符就是User-Agent</li>
</ol>
<p><img src="/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/Snipaste_2023-07-14_20-28-21.png" alt="Snipaste_2023-07-14_20-28-21"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/s?rtt=1&amp;bsst=1&amp;cl=2&amp;tn=news&amp;ie=utf-8&amp;word=%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4&#x27;</span></span><br><span class="line"><span class="comment"># res = requests.get(url, headers=headers).content.decode(&#x27;utf-8&#x27;)</span></span><br><span class="line">res = requests.get(url, headers=headers).text</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<p><img src="/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/Snipaste_2023-07-14_20-50-21.png" alt="Snipaste_2023-07-14_20-50-21"></p>
<h2 id="2-4-爬虫技术基础3——正则表达式"><a href="#2-4-爬虫技术基础3——正则表达式" class="headerlink" title="2.4 爬虫技术基础3——正则表达式"></a>2.4 爬虫技术基础3——正则表达式</h2><h3 id="2-4-1-正则表达式基础1——findall-函数"><a href="#2-4-1-正则表达式基础1——findall-函数" class="headerlink" title="2.4.1 正则表达式基础1——findall()函数"></a>2.4.1 正则表达式基础1——findall()函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re  <span class="comment"># 引入正则表达式re库</span></span><br><span class="line">content = <span class="string">&#x27;Hello 123 world 456 华小智Python基础教学135&#x27;</span></span><br><span class="line">result = re.findall(<span class="string">&#x27;\d\d\d&#x27;</span>,content) <span class="comment"># 表示在content中寻找连续的3个数字</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;123&#x27;</span>, <span class="string">&#x27;456&#x27;</span>, <span class="string">&#x27;135&#x27;</span>] <span class="comment"># 运行之后，得到的是一个包含提取出来的信息的列表</span></span><br></pre></td></tr></table></figure>

<p>findall()函数的功能是在原始文本中寻找所有符合匹配规则的文本，其格式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.findall(匹配规则,原始文本)</span><br></pre></td></tr></table></figure>

<img src="Python金融大数据挖掘与分析/Snipaste_2023-07-14_21-34-19.png" alt="Snipaste_2023-07-14_21-34-19" style="zoom:50%;" />

<h3 id="2-4-2-正则表达式基础2——非贪婪匹配之（-）"><a href="#2-4-2-正则表达式基础2——非贪婪匹配之（-）" class="headerlink" title="2.4.2 正则表达式基础2——非贪婪匹配之（.*?）"></a>2.4.2 正则表达式基础2——非贪婪匹配之（.*?）</h3><p>（.*?）用于获取文本A与文本B之间的内容，并不需要知道它的确切长度及格式，但是需要知道它在哪两个内容之间，格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">文本A（.*?）文本B</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">res = <span class="string">&#x27;文本A百度新闻文本B&#x27;</span></span><br><span class="line">source = re.findall(<span class="string">&#x27;文本A(.*?)文本B&#x27;</span>, res)</span><br><span class="line"><span class="built_in">print</span>(source)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;百度新闻&#x27;]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">res = <span class="string">&#x27;文本A百度新闻文本B，新闻标题文本A新浪财经文本B，文本A搜狗新闻文本B新闻网址&#x27;</span></span><br><span class="line">p_source = <span class="string">&#x27;文本A(.*?)文本B&#x27;</span></span><br><span class="line">source = re.findall(p_source, res)</span><br><span class="line"><span class="built_in">print</span>(source)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;百度新闻&#x27;, &#x27;新浪财经&#x27;, &#x27;搜狗新闻&#x27;]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">res = <span class="string">&#x27;&lt;p class=&quot;c-author&quot;&gt;&lt;img***&gt;央视网新闻&amp;nbsp;&amp;nbsp;2019年04月13日 13:33&lt;/p&gt;&#x27;</span></span><br><span class="line">p_info = <span class="string">&#x27;&lt;p class=&quot;c-author&quot;&gt;(.*?)&lt;/p&gt;&#x27;</span></span><br><span class="line">info = re.findall(p_info, res)</span><br><span class="line"><span class="built_in">print</span>(info)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;&lt;img***&gt;央视网新闻&amp;nbsp;&amp;nbsp;2019年04月13日 13:33&#x27;]</span><br></pre></td></tr></table></figure>

<h3 id="2-4-3-正则表达式基础3——非贪婪匹配之"><a href="#2-4-3-正则表达式基础3——非贪婪匹配之" class="headerlink" title="2.4.3 正则表达式基础3——非贪婪匹配之.*?"></a>2.4.3 正则表达式基础3——非贪婪匹配之.*?</h3><p>.*?用于代替两个文本间的所有内容，这其中的内容往往是变化的无规律的，无法写在匹配规则里，或者内容较多</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">文本C.*?文本D</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">res = <span class="string">&#x27;&lt;h3&gt;文本C&lt;变化的网址&gt;文本D新闻标题&lt;/h3&gt;&#x27;</span></span><br><span class="line">p_title = <span class="string">&#x27;&lt;h3&gt;文本C.*?文本D(.*?)&lt;/h3&gt;&#x27;</span></span><br><span class="line">title = re.findall(p_title, res)</span><br><span class="line"><span class="built_in">print</span>(title)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;新闻标题&#x27;]</span><br></pre></td></tr></table></figure>

<p>其中“<h3>文本C.*?文本D”代表“<h3>文本C<变化的网址>文本D”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">res = <span class="string">&#x27;&lt;h3 class=&quot;c-title&quot;&gt;&lt;a href=&quot;网址&quot; data-click=&quot;&#123;一堆英文&#125;&quot;&gt;&lt;em&gt;阿里巴巴&lt;/em&gt;代码竞赛现全球首位AI评委 能为代码质量打分&lt;/a&gt;&#x27;</span></span><br><span class="line">p_title = <span class="string">&#x27;&lt;h3 class=&quot;c-title&quot;&gt;.*?&gt;(.*?)&lt;/a&gt;&#x27;</span></span><br><span class="line">title = re.findall(p_title, res)</span><br><span class="line"><span class="built_in">print</span>(title)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;&lt;em&gt;阿里巴巴&lt;/em&gt;代码竞赛现全球首位AI评委 能为代码质量打分&#x27;]</span><br></pre></td></tr></table></figure>

<img src="Python金融大数据挖掘与分析/88图片.png" alt="88图片" style="zoom:43%;" />

<h3 id="2-4-4-正则表达式基础4——自动考虑换行的修饰符re-S"><a href="#2-4-4-正则表达式基础4——自动考虑换行的修饰符re-S" class="headerlink" title="2.4.4 正则表达式基础4——自动考虑换行的修饰符re.S"></a>2.4.4 正则表达式基础4——自动考虑换行的修饰符re.S</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.findall(匹配规则,原始文本,re.S)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">res = <span class="string">&#x27;&#x27;&#x27;&lt;h3 class=&quot;c-title&quot;&gt;</span></span><br><span class="line"><span class="string"> &lt;a href=&quot;https://baijiahao.baidu.com/s?id=1631161702623128831&amp;amp;wfr=spider&amp;amp;for=pc&quot;</span></span><br><span class="line"><span class="string">    data-click=&quot;&#123;</span></span><br><span class="line"><span class="string">      一堆我们不关心的英文</span></span><br><span class="line"><span class="string">      &#125;&quot;</span></span><br><span class="line"><span class="string">                target=&quot;_blank&quot;</span></span><br><span class="line"><span class="string">    &gt;</span></span><br><span class="line"><span class="string">      &lt;em&gt;阿里巴巴&lt;/em&gt;代码竞赛现全球首位AI评委 能为代码质量打分</span></span><br><span class="line"><span class="string">    &lt;/a&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">p_href = <span class="string">&#x27;&lt;h3 class=&quot;c-title&quot;&gt;.*?&lt;a href=&quot;(.*?)&quot;&#x27;</span></span><br><span class="line">p_title = <span class="string">&#x27;&lt;h3 class=&quot;c-title&quot;&gt;.*?&gt;(.*?)&lt;/a&gt;&#x27;</span></span><br><span class="line">href = re.findall(p_href, res, re.S)</span><br><span class="line">title = re.findall(p_title, res, re.S)</span><br><span class="line"><span class="built_in">print</span>(href)</span><br><span class="line"><span class="built_in">print</span>(title)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清除换行符号</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(title)):</span><br><span class="line">    title[i] = title[i].strip()</span><br><span class="line"><span class="built_in">print</span>(title)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;https://baijiahao.baidu.com/s?id=1631161702623128831&amp;amp;wfr=spider&amp;amp;for=pc&#x27;]</span><br><span class="line">[&#x27;\n      &lt;em&gt;阿里巴巴&lt;/em&gt;代码竞赛现全球首位AI评委 能为代码质量打分\n    &#x27;]</span><br><span class="line">[&#x27;&lt;em&gt;阿里巴巴&lt;/em&gt;代码竞赛现全球首位AI评委 能为代码质量打分&#x27;]</span><br></pre></td></tr></table></figure>

<h3 id="2-4-5-正则表达式基础5——知识点补充"><a href="#2-4-5-正则表达式基础5——知识点补充" class="headerlink" title="2.4.5 正则表达式基础5——知识点补充"></a>2.4.5 正则表达式基础5——知识点补充</h3><h4 id="1-sub-函数"><a href="#1-sub-函数" class="headerlink" title="1. sub()函数"></a>1. sub()函数</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(需要替换的内容,替换值,原字符串)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">title = [<span class="string">&#x27;&lt;em&gt;阿里巴巴&lt;/em&gt;代码竞赛现全球首位AI评委 能为代码质量打分&#x27;</span>]</span><br><span class="line">title[<span class="number">0</span>] = title[<span class="number">0</span>].replace(<span class="string">&#x27;&lt;em&gt;&#x27;</span>,<span class="string">&#x27;&#x27;</span>) <span class="comment"># 注意title是一个列表，虽然只有一个元素，单也要用title[0]才能获得其中的字符串</span></span><br><span class="line">title[<span class="number">0</span>] = title[<span class="number">0</span>].replace(<span class="string">&#x27;&lt;/em&gt;&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="comment"># title[0] = re.sub(&#x27;&lt;em&gt;&#x27;,&#x27;&#x27;,title[0])</span></span><br><span class="line"><span class="comment"># title[0] = re.sub(&#x27;&lt;/em&gt;&#x27;,&#x27;&#x27;,title[0])</span></span><br><span class="line"><span class="built_in">print</span>(title[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">title = [<span class="string">&#x27;&lt;em&gt;阿里巴巴&lt;/em&gt;代码竞赛现全球首位AI评委 能为代码质量打分&#x27;</span>]</span><br><span class="line">title[<span class="number">0</span>] = re.sub(<span class="string">&#x27;&lt;.*?&gt;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, title[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(title[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">阿里巴巴代码竞赛现全球首位AI评委 能为代码质量打分</span><br></pre></td></tr></table></figure>

<h4 id="2-中括号-的用法"><a href="#2-中括号-的用法" class="headerlink" title="2. 中括号[]的用法"></a>2. 中括号[]的用法</h4><p>[ ]的最主要用法是使中括号的内容不再有特殊含义</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">company = <span class="string">&#x27;*华能信托&#x27;</span></span><br><span class="line">company1 = re.sub(<span class="string">&#x27;[*]&#x27;</span>, <span class="string">&#x27;&#x27;</span>, company)</span><br><span class="line"><span class="built_in">print</span>(company1)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">华能信托</span><br></pre></td></tr></table></figure>

<p>用[]让符号变回本来的含义</p>
<h1 id="第三章-金融数据挖掘案例实战1"><a href="#第三章-金融数据挖掘案例实战1" class="headerlink" title="第三章 金融数据挖掘案例实战1"></a>第三章 金融数据挖掘案例实战1</h1><h2 id="3-1-提取百度新闻标题、网址、日期及来源"><a href="#3-1-提取百度新闻标题、网址、日期及来源" class="headerlink" title="3.1 提取百度新闻标题、网址、日期及来源"></a>3.1 提取百度新闻标题、网址、日期及来源</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 百度现在有时有ssl证书认证的问题，这就会导致请求发过去一直没有响应，卡住了（获取不到源代码），解决方法，把https换成http</span></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/s?tn=news&amp;rtt=1&amp;bsst=1&amp;cl=2&amp;wd=阿里巴巴&#x27;</span>  <span class="comment"># 把链接中rtt参数换成4即是按时间排序，默认为1按焦点排序，3.4.1小节也有讲到</span></span><br><span class="line">res = requests.get(url, headers=headers).text  <span class="comment"># 加上headers用来告诉网站这是通过一个浏览器进行的访问</span></span><br><span class="line"><span class="comment"># print(res) # 获取网页源码</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编写正则表达式提取新闻信息</span></span><br><span class="line">p_href = <span class="string">&#x27;&lt;h3 class=&quot;news-title_1YtI1 &quot;&gt;&lt;a href=&quot;(.*?)&quot;&#x27;</span></span><br><span class="line">href = re.findall(p_href, res, re.S)</span><br><span class="line">p_title = <span class="string">&#x27;&lt;h3 class=&quot;news-title_1YtI1 &quot;&gt;.*?&gt;(.*?)&lt;/a&gt;&#x27;</span></span><br><span class="line">title = re.findall(p_title, res, re.S)</span><br><span class="line">p_date = <span class="string">&#x27;&lt;span class=&quot;c-color-gray2 c-font-normal c-gap-right-xsmall&quot; .*?&gt;(.*?)&lt;/span&gt;&#x27;</span></span><br><span class="line">date = re.findall(p_date, res)</span><br><span class="line">p_source = <span class="string">&#x27;&lt;span class=&quot;c-color-gray&quot; .*?&gt;(.*?)&lt;/span&gt;&#x27;</span></span><br><span class="line">source = re.findall(p_source, res)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(title)</span></span><br><span class="line"><span class="comment"># print(href)</span></span><br><span class="line"><span class="comment"># print(date)</span></span><br><span class="line"><span class="comment"># print(source)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(title)):  <span class="comment"># range(len(title)),这里因为知道len(title) = 10，所以也可以写成for i in range(10)</span></span><br><span class="line">    title[i] = title[i].strip()  <span class="comment"># strip()函数用来取消字符串两端的换行或者空格，不过目前（2020-10）并没有换行或空格，所以其实不写这一行也没事</span></span><br><span class="line">    title[i] = re.sub(<span class="string">&#x27;&lt;.*?&gt;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, title[i])  <span class="comment"># 核心，用re.sub()函数来替换不重要的内容</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">str</span>(i + <span class="number">1</span>) + <span class="string">&#x27;.&#x27;</span> + title[i] + <span class="string">&#x27;(&#x27;</span> + source[i] + <span class="string">&#x27; &#x27;</span> + date[i] + <span class="string">&#x27;)&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(href[i])</span><br></pre></td></tr></table></figure>

<img src="Python金融大数据挖掘与分析/Snipaste_2023-07-15_09-18-10.png" alt="Snipaste_2023-07-15_09-18-10" style="zoom:43%;" />

<h2 id="3-2-批量获取多家公司的百度新闻并生成数据报告"><a href="#3-2-批量获取多家公司的百度新闻并生成数据报告" class="headerlink" title="3.2 批量获取多家公司的百度新闻并生成数据报告"></a>3.2 批量获取多家公司的百度新闻并生成数据报告</h2></script></li></table></p></h6></h1></h6></h1></body></body>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">数据科学</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习与深度学习//" class="article-tag-list-link color5">机器学习与深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/07/14/Python%E9%87%91%E8%9E%8D%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%88%86%E6%9E%90/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-MySQL相关知识" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/03/MySQL%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/">MySQL相关知识</a>
    </h1>
  

        
        <a href="/2023/07/03/MySQL%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/" class="archive-article-date">
  	<time datetime="2023-07-03T05:38:15.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-07-03</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-数据库概述及一些相关知识"><a href="#第一章-数据库概述及一些相关知识" class="headerlink" title="第一章 数据库概述及一些相关知识"></a>第一章 数据库概述及一些相关知识</h1><h2 id="1-使用数据库的原因"><a href="#1-使用数据库的原因" class="headerlink" title="1. 使用数据库的原因"></a>1. 使用数据库的原因</h2><p>持久化：含义是把数据保存到可掉电式存储设备中<strong>以供之后使用</strong>，将内存中的数据保存在<strong>硬盘</strong>上加以“固化”，持久化的主要作用是<strong>将内存中的数据存储在关系型数据库中</strong>。</p>
<p>数据库能更好地处理异质性数据。</p>
<h2 id="2-数据库与数据库管理系统"><a href="#2-数据库与数据库管理系统" class="headerlink" title="2. 数据库与数据库管理系统"></a>2. 数据库与数据库管理系统</h2><h3 id="2-1-数据库的相关概念"><a href="#2-1-数据库的相关概念" class="headerlink" title="2.1 数据库的相关概念"></a>2.1 数据库的相关概念</h3><p><strong>DB：数据库（Database）</strong></p>
<p>即存储数据的“仓库”，其本质是一个文件系统（实打实的文件，数据库文件）。它保存了一系列有组织的数据。</p>
<p><strong>DBMS：数据库管理系统（Database Management System）</strong></p>
<p>是一种操纵和管理数据库的大型软件，用于建立、使用和维护数据库，对数据库进行统一管理和控制。用户通过数据库管理系统访问数据库中表内的结构。</p>
<p><strong>SQL：结构化查询语言（Structured Query Language）</strong></p>
<p>专门用来与数据库通信的语言</p>
<h3 id="2-2-数据库与数据库管理系统的关系"><a href="#2-2-数据库与数据库管理系统的关系" class="headerlink" title="2.2 数据库与数据库管理系统的关系"></a>2.2 数据库与数据库管理系统的关系</h3><p>DBMS可以管理多个数据库。我们一般会针对每一个应用创建一个数据库。为保存应用中实体的数据，一般会在数据库中创建多个表，以保证程序中实体用户的数据。</p>
<img src="webwxgetmsgimg.jpg" alt="webwxgetmsgimg" style="zoom: 50%;">

<h2 id="3-RDBMS与非RDBMS"><a href="#3-RDBMS与非RDBMS" class="headerlink" title="3. RDBMS与非RDBMS"></a>3. RDBMS与非RDBMS</h2><h3 id="3-1-关系型数据库（RDBMS）"><a href="#3-1-关系型数据库（RDBMS）" class="headerlink" title="3.1 关系型数据库（RDBMS）"></a>3.1 关系型数据库（RDBMS）</h3><ul>
<li><p>最古老的数据库类型，关系型数据库模型是把复杂的数据结构归结为简单的二元关系（二维表格形式）。</p>
</li>
<li><p>以行（row）和列（column）的形式存储数据，这一系列的行和列被称为表（table），一组表组成了一个库（database）</p>
</li>
<li><p>表与表之间的数据记录有<strong>关系</strong>（relationship）。现实世界中的各种实体以及实体之间的各种联系均用<strong>关系模型</strong>来表示。</p>
</li>
<li><p>优势：复杂查询，事务支持</p>
</li>
</ul>
<h3 id="3-2-非关系型数据库（非RDBMS）"><a href="#3-2-非关系型数据库（非RDBMS）" class="headerlink" title="3.2 非关系型数据库（非RDBMS）"></a>3.2 非关系型数据库（非RDBMS）</h3><p>可以看成传统关系型数据库的功能阉割版本，基于键值对存储数据，不需要经过SQL层的解析，性能非常高</p>
<h4 id="3-2-1-非关系型数据库举例"><a href="#3-2-1-非关系型数据库举例" class="headerlink" title="3.2.1 非关系型数据库举例"></a>3.2.1 非关系型数据库举例</h4><p><strong>键值型数据库</strong></p>
<p>通过Key-Value键值的方式来存储数据，其中Key和Value可以是简单的对象，也可以是复杂的对象。Key作为唯一标识符，优点是查找速度快。缺点是无法像关系型数据库一样使用条件过滤（比如WHERE），如果不知道去哪里找数据，就要遍历所有的建，这就会消耗大量的计算。其典型使用场景是作为<strong>内存缓存</strong>，<strong>Redis</strong>是最流行的键值型数据库。</p>
<img src="webwxgetmsgimg (1).jpg" alt="webwxgetmsgimg (1)" style="zoom:50%;">

<p><strong>文档型数据库</strong></p>
<p>此类数据库可以存放并获取文档，可以是XML、JSON等格式。在数据库中文档作为处理信息的基本单位，一个文档就相当于一条记录。<strong>MongoDB</strong></p>
<p><strong>搜索引擎数据库</strong></p>
<p>核心原理是“倒排索引”。Elasticsearch</p>
<p><strong>列式数据库</strong></p>
<p>列式数据库是相对于行式存储的数据库，这样做的好处是可以大量降低系统的I&#x2F;O，适合于分布式文件系统，不足之处在于功能相对有限，<strong>HBase</strong></p>
<img src="webwxgetmsgimg (2).jpg" alt="webwxgetmsgimg (2)" style="zoom:50%;">

<p><strong>图形数据库</strong></p>
<p>![webwxgetmsgimg (3)](MySQL相关知识&#x2F;webwxgetmsgimg (3).jpg)</p>
<h2 id="4-关系型数据库设计的原则"><a href="#4-关系型数据库设计的原则" class="headerlink" title="4. 关系型数据库设计的原则"></a>4. 关系型数据库设计的原则</h2><ul>
<li><strong>数据表</strong></li>
<li>将数据放到表中，表再放到库中</li>
<li>一个数据库可以有多个表，每个表都有一个名字，用来表示自己，表名具有唯一性</li>
<li>表，类似java中的“类”</li>
</ul>
<h3 id="4-1-表、记录、字段"><a href="#4-1-表、记录、字段" class="headerlink" title="4.1 表、记录、字段"></a>4.1 表、记录、字段</h3><ul>
<li>E-R（实体-联系）模型[<strong>描述的是表和表之间的关系</strong>]中有三个主要的概念：<strong>实体集</strong>、<strong>属性</strong>、<strong>联系集</strong></li>
<li>一个实体集（class）对应于数据库中的一个表（table），一个实体（instance）则对应于数据库表中的一行（row），也成为一条记录（record）。一个属性对应于数据库表中的一列（column），也称为一个字段。</li>
</ul>
<p>![webwxgetmsgimg (4)](MySQL相关知识&#x2F;webwxgetmsgimg (4).jpg)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ORM思想（Object Relational Mapping）体现</span><br><span class="line">数据库中的一个表 &lt;---------&gt; java中的一个类</span><br><span class="line">表中的一条（行）数据 &lt;---------&gt; 类中的一个对象（或实体）</span><br><span class="line">表中的一个列 &lt;---------&gt; 类中的一个字段、属性（field）</span><br></pre></td></tr></table></figure>

<h3 id="4-2-表的关联关系"><a href="#4-2-表的关联关系" class="headerlink" title="4.2 表的关联关系"></a>4.2 表的关联关系</h3><p>四种：一对一关联、一对多关联、多对多关联、自我引用</p>
<h4 id="4-2-1-一对一"><a href="#4-2-1-一对一" class="headerlink" title="4.2.1 一对一"></a>4.2.1 一对一</h4><p>A表中的一条记录对应B表中的另外一条记录</p>
<img src="webwxgetmsgimg (5).jpg" alt="webwxgetmsgimg (5)" style="zoom:50%;">

<h4 id="4-2-2-一对多关系"><a href="#4-2-2-一对多关系" class="headerlink" title="4.2.2 一对多关系"></a>4.2.2 一对多关系</h4><img src="webwxgetmsgimg (6).jpg" alt="webwxgetmsgimg (6)" style="zoom:50%;">

<h4 id="4-2-3-多对多"><a href="#4-2-3-多对多" class="headerlink" title="4.2.3 多对多"></a>4.2.3 多对多</h4><p>要表示多对多关系，必须创建第三个表，该表通常称为<strong>联接表</strong>，它将多对多关系划分为两个一对多关系，将这两个表的主键都插入到第三个表中。</p>
<img src="webwxgetmsgimg (7).jpg" alt="webwxgetmsgimg (7)" style="zoom:50%;">

<h4 id="4-2-4-自我引用"><a href="#4-2-4-自我引用" class="headerlink" title="4.2.4 自我引用"></a>4.2.4 自我引用</h4><img src="webwxgetmsgimg (8).jpg" alt="webwxgetmsgimg (8)" style="zoom:50%;">

<h1 id="第二章-基本的SELECT语句"><a href="#第二章-基本的SELECT语句" class="headerlink" title="第二章 基本的SELECT语句"></a>第二章 基本的SELECT语句</h1><h2 id="1-SQL分类"><a href="#1-SQL分类" class="headerlink" title="1. SQL分类"></a>1. SQL分类</h2><ul>
<li><strong>DDL（数据定义语言）</strong>，这些语句定义了不同的数据库、表、视图、索引等数据库对象，还可以用来创建、删除、修改<strong>数据库和数据表结构</strong>。（CREATE、DROP、ALTER、RENAME、TRUNCATE等），<strong>作用对象：数据库&#x2F;表</strong></li>
<li><strong>DML（数据操作语言）</strong>，用于添加、删除、更新和查询数据库<strong>记录</strong>（行），并检查数据完整性。（INSERT、DELETE、UPDATE、SELECT（基础，最重要）），<strong>作用对象：行</strong></li>
<li><strong>DCL（数据控制语言）</strong>，用于定义数据库、表、字段（列）、用户的访问权限和安全级别。（GRANT、REVOKE、COMMIT、ROLLBAKE、SAVEPOINT），<strong>作用对象：数据库&#x2F;表&#x2F;列</strong></li>
</ul>
<p>或者把查询语言单列出来：DQL（数据查询语言）</p>
<h2 id="2-SQL语言的规则与规范"><a href="#2-SQL语言的规则与规范" class="headerlink" title="2. SQL语言的规则与规范"></a>2. SQL语言的规则与规范</h2><h3 id="2-1-基本规则"><a href="#2-1-基本规则" class="headerlink" title="2.1 基本规则"></a>2.1 基本规则</h3><ul>
<li>SQL可以写在一行或者多行，各子句分行写，必要时缩进</li>
<li>每条命令以 ；结束</li>
<li>关键字不能缩写也不能分行</li>
<li>列的别名用双引号表示，不建议省略as</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">USE dbtest2;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="number">1002</span>,<span class="string">&#x27;TOM&#x27;</span>);</span><br></pre></td></tr></table></figure>

<h3 id="2-2-SQL大小写规范"><a href="#2-2-SQL大小写规范" class="headerlink" title="2.2 SQL大小写规范"></a>2.2 SQL大小写规范</h3><ul>
<li>Windows中对大小写不敏感</li>
<li>Linux中对大小写敏感</li>
</ul>
<p>数据库名、表名、表别名、字段名、字段别名等都小写</p>
<p>SQL关键字、函数名、绑定变量等都大写。</p>
<h3 id="2-3-注释"><a href="#2-3-注释" class="headerlink" title="2.3 注释"></a>2.3 注释</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 这是一个单行注释，MySQL特有</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">这是一段多行</span></span><br><span class="line"><span class="comment">注释</span></span><br><span class="line"><span class="comment">多行注释</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h3 id="2-4-命名规则（暂时了解）"><a href="#2-4-命名规则（暂时了解）" class="headerlink" title="2.4 命名规则（暂时了解）"></a>2.4 命名规则（暂时了解）</h3><p>![webwxgetmsgimg (9)](MySQL相关知识&#x2F;webwxgetmsgimg (9).jpg)</p>
<h3 id="2-5-数据导入指令"><a href="#2-5-数据导入指令" class="headerlink" title="2.5 数据导入指令"></a>2.5 数据导入指令</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># source 文件的全路径名</span><br><span class="line"># 注意，必须在命令行下</span><br><span class="line">source d:\mysqldb.sql</span><br></pre></td></tr></table></figure>

<h2 id="3-基本的SELECT语句"><a href="#3-基本的SELECT语句" class="headerlink" title="3. 基本的SELECT语句"></a>3. 基本的SELECT语句</h2><h3 id="3-1-SELECT…FROM"><a href="#3-1-SELECT…FROM" class="headerlink" title="3.1 SELECT…FROM"></a>3.1 SELECT…FROM</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.</span>最基本的<span class="keyword">SELECT</span>语句，<span class="keyword">SELECT</span> 字段<span class="number">1</span>(列<span class="number">1</span>)，字段<span class="number">2</span>(列<span class="number">2</span>),....<span class="keyword">FROM</span> 表名</span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span><span class="operator">+</span><span class="number">1</span>,<span class="number">3</span><span class="operator">*</span><span class="number">2</span>;</span><br><span class="line"># 等价于</span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span><span class="operator">+</span><span class="number">1</span>,<span class="number">3</span><span class="operator">*</span><span class="number">2</span> <span class="keyword">FROM</span> dual;# dual:伪表</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-44-55.png" alt="Snipaste_2023-07-04_15-44-55" style="zoom:43%;">

<img src="Snipaste_2023-07-04_15-45-35.png" alt="Snipaste_2023-07-04_15-45-35" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> employees;# <span class="operator">*</span>表示所有的字段（列）</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees; # 选择特定的列</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-46-53.png" alt="Snipaste_2023-07-04_15-46-53" style="zoom:43%;">

<h3 id="3-2-列的别名"><a href="#3-2-列的别名" class="headerlink" title="3.2 列的别名"></a>3.2 列的别名</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 可以直接在原列名之后写上别名，也可以加一个关键字<span class="keyword">AS</span>（alias），也可以将别名用&quot;&quot;引起来，用&quot;&quot;是为了防止有点别名中有空格引起歧义</span><br><span class="line"><span class="keyword">SELECT</span> employee_id emp_id,last_name <span class="keyword">AS</span> lname,department_id &quot;部门id&quot;,salary<span class="operator">*</span><span class="number">12</span> &quot;annual_sal&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-48-38.png" alt="Snipaste_2023-07-04_15-48-38" style="zoom:43%;">

<h3 id="3-3-去除重复行"><a href="#3-3-去除重复行" class="headerlink" title="3.3 去除重复行"></a>3.3 去除重复行</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 默认情况下，查询会返回全部行，包括重复行,在<span class="keyword">SELECT</span>语句中使用关键字<span class="keyword">DISTINCT</span>去除重复行</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> department_id</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br><span class="line"># 仅仅是没有报错，但是没有实际意义</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> department_id,salary</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-50-03.png" alt="Snipaste_2023-07-04_15-50-03" style="zoom:43%;">

<h3 id="3-4-空值参与运算"><a href="#3-4-空值参与运算" class="headerlink" title="3.4 空值参与运算"></a>3.4 空值参与运算</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span>空值参与运算</span><br><span class="line"># 空值：<span class="keyword">null</span>;空值不等于<span class="string">&#x27;&#x27;</span>或<span class="number">0</span>，空字符串长度为<span class="number">0</span>，空值长度是空，在MySQL中，空值是占用空间的</span><br><span class="line"># 所有运算符或列值遇到<span class="keyword">null</span>值，运算结果都为<span class="keyword">null</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,salary &quot;月工资&quot;,salary<span class="operator">*</span>(<span class="number">1</span> <span class="operator">+</span> commission_pct)<span class="operator">*</span><span class="number">12</span> &quot;年工资&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-51-10.png" alt="Snipaste_2023-07-04_15-51-10" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 实际问题的解决方案，引入IFNULL</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,salary &quot;月工资&quot;,salary<span class="operator">*</span>(<span class="number">1</span> <span class="operator">+</span> IFNULL(commission_pct,<span class="number">0</span>))<span class="operator">*</span><span class="number">12</span> &quot;年工资&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-52-10.png" alt="Snipaste_2023-07-04_15-52-10" style="zoom:43%;">

<h3 id="3-5-着重号"><a href="#3-5-着重号" class="headerlink" title="3.5 着重号"></a>3.5 着重号</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 当表中的字段、表名和保留字、数据库系统或者常用方法冲突的时候，用``（着重号）引起来</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> `<span class="keyword">order</span>`;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-53-12.png" alt="Snipaste_2023-07-04_15-53-12" style="zoom:43%;">

<h3 id="3-6-查询常数"><a href="#3-6-查询常数" class="headerlink" title="3.6 查询常数"></a>3.6 查询常数</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 效果为在<span class="keyword">SELECT</span>查询结果中增加一列固定的常数列。这列的取值是我们制定的，而不是从数据表中动态取出的</span><br><span class="line"># 一般来说我们只从一个表中查询数据，通常不需要增加一个固定的常数列，单如果我们想整合不同的数据源</span><br><span class="line"># ，用常数列作为这个表的标记，就需要查询常数</span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">&#x27;阿里巴巴&#x27;</span>,<span class="number">618</span>,employee_id,last_name</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-54-12.png" alt="Snipaste_2023-07-04_15-54-12" style="zoom:43%;">

<h2 id="4-显示表结构"><a href="#4-显示表结构" class="headerlink" title="4. 显示表结构"></a>4. 显示表结构</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">DESC</span>或<span class="keyword">DESCRIBE</span></span><br><span class="line"><span class="keyword">DESC</span> employees; # 显示了表中字段的详细信息</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_15-55-09.png" alt="Snipaste_2023-07-04_15-55-09" style="zoom:43%;">

<h2 id="5-过滤数据"><a href="#5-过滤数据" class="headerlink" title="5. 过滤数据"></a>5. 过滤数据</h2><p>语法：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> 字段<span class="number">1</span>,字段<span class="number">2</span></span><br><span class="line"><span class="keyword">FROM</span> 表名</span><br><span class="line"><span class="keyword">WHERE</span> 过滤条件</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查询<span class="number">90</span>号部门的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"># 过滤条件，必须紧挨在在<span class="keyword">FROM</span>的后面</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">90</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-04_18-07-28.png" alt="Snipaste_2023-07-04_18-07-28"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询last_name为<span class="string">&#x27;King&#x27;</span>的员工的信息</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="operator">=</span> <span class="string">&#x27;King&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-04_18-08-09.png" alt="Snipaste_2023-07-04_18-08-09"></p>
<h1 id="第三章-运算符"><a href="#第三章-运算符" class="headerlink" title="第三章 运算符"></a>第三章 运算符</h1><h2 id="1-算术运算符"><a href="#1-算术运算符" class="headerlink" title="1. 算术运算符"></a>1. 算术运算符</h2><p><img src="webwxgetmsgim111g.jpg" alt="webwxgetmsgim111g"></p>
<h3 id="1-1-加法与减法运算符"><a href="#1-1-加法与减法运算符" class="headerlink" title="1.1 加法与减法运算符"></a>1.1 加法与减法运算符</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="number">100</span>, <span class="number">100</span> <span class="operator">+</span> <span class="number">0</span>, <span class="number">100</span> <span class="operator">-</span> <span class="number">0</span>, <span class="number">100</span> <span class="operator">+</span> <span class="number">50</span>, <span class="number">100</span> <span class="operator">+</span> <span class="number">50</span> <span class="operator">*</span> <span class="number">30</span>, <span class="number">100</span> <span class="operator">+</span> <span class="number">35.5</span>, <span class="number">100</span> <span class="operator">-</span> <span class="number">35.5</span></span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-04_20-53-52.png" alt="Snipaste_2023-07-04_20-53-52"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="number">100</span> <span class="operator">+</span> <span class="string">&#x27;1&#x27;</span>  # 在MySQL中表示数相加,此时会将字符串转换为数值（隐式转换）</span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_20-54-28.png" alt="Snipaste_2023-07-04_20-54-28" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="number">100</span> <span class="operator">+</span> <span class="string">&#x27;a&#x27;</span>  # 这里的字符视为<span class="number">0</span></span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_20-55-13.png" alt="Snipaste_2023-07-04_20-55-13" style="zoom:43%;">

<p>![webwxgetmsgimg (10)](MySQL相关知识&#x2F;webwxgetmsgimg (10).jpg)</p>
<h3 id="1-2乘法与除法运算"><a href="#1-2乘法与除法运算" class="headerlink" title="1.2乘法与除法运算"></a>1.2乘法与除法运算</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  <span class="number">100</span>, <span class="number">100</span> <span class="operator">*</span> <span class="number">1</span>, <span class="number">100</span> <span class="operator">*</span> <span class="number">1.0</span>, <span class="number">100</span> <span class="operator">/</span> <span class="number">1.0</span>, <span class="number">100</span> <span class="operator">/</span> <span class="number">2</span>, <span class="number">100</span> <span class="operator">+</span> <span class="number">2</span> <span class="operator">*</span> <span class="number">5</span> <span class="operator">/</span> <span class="number">2</span>, <span class="number">100</span> <span class="operator">/</span> <span class="number">3</span>, <span class="number">100</span> DIV <span class="number">0</span></span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-04_21-03-03.png" alt="Snipaste_2023-07-04_21-03-03"></p>
<p>![webwxgetmsgimg (11)](MySQL相关知识&#x2F;webwxgetmsgimg (11).jpg)</p>
<h3 id="1-3-求模（余）运算"><a href="#1-3-求模（余）运算" class="headerlink" title="1.3 求模（余）运算"></a>1.3 求模（余）运算</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="number">12</span> <span class="operator">%</span> <span class="number">3</span>, <span class="number">12</span> <span class="operator">%</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_21-08-29.png" alt="Snipaste_2023-07-04_21-08-29" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 查询员工id为偶数的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="operator">%</span> <span class="number">2</span> <span class="operator">=</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_21-09-20.png" alt="Snipaste_2023-07-04_21-09-20" style="zoom:43%;">

<h2 id="2-比较运算符"><a href="#2-比较运算符" class="headerlink" title="2. 比较运算符"></a>2. 比较运算符</h2><p><img src="webwxgetmsgim111g.jpg" alt="webwxgetmsgim111g"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span><span class="operator">=</span><span class="number">2</span>, <span class="number">1</span><span class="operator">!=</span><span class="number">2</span>, <span class="number">1</span><span class="operator">=</span><span class="string">&#x27;1&#x27;</span>,<span class="number">1</span><span class="operator">=</span><span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span><span class="operator">=</span><span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;a&#x27;</span><span class="operator">=</span><span class="string">&#x27;b&#x27;</span></span><br><span class="line"><span class="keyword">FROM</span> dual;# 结果依次为<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">0</span><span class="operator">=</span><span class="string">&#x27;a&#x27;</span> # <span class="string">&#x27;a&#x27;</span>看作<span class="number">0</span></span><br><span class="line"><span class="keyword">FROM</span> dual;# 结果为<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span><span class="operator">=</span><span class="keyword">NULL</span>, <span class="keyword">NULL</span><span class="operator">=</span><span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">FROM</span> dual;# 结果依次为<span class="keyword">null</span>,<span class="keyword">null</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">=</span> <span class="number">6000</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_21-35-24.png" alt="Snipaste_2023-07-04_21-35-24" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># <span class="operator">&lt;=&gt;</span>安全等于，为了解决对<span class="keyword">NULL</span>进行判断的问题，在两个操作数均为<span class="keyword">NULL</span>时，其返回值为<span class="number">1</span></span><br><span class="line"># 当只有一个操作数为<span class="keyword">NULL</span>时，其返回值为<span class="number">0</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">&#x27;&#x27;</span><span class="operator">&lt;=&gt;</span><span class="keyword">NULL</span>, <span class="keyword">NULL</span><span class="operator">&lt;=&gt;</span><span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">FROM</span> dual;# 结果依次为<span class="number">0</span>,<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,commission_pct</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> commission_pct <span class="operator">=</span> <span class="keyword">NULL</span>;# 此时执行不会有任何结果</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,commission_pct</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> commission_pct <span class="operator">&lt;=&gt;</span> <span class="keyword">NULL</span>;</span><br><span class="line"># 或 <span class="keyword">WHERE</span> commission_pct <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_21-36-46.png" alt="Snipaste_2023-07-04_21-36-46" style="zoom:43%;">

<p>![webwxgetmsgimg (12)](MySQL相关知识&#x2F;webwxgetmsgimg (12).jpg)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#① <span class="keyword">IS</span> <span class="keyword">NULL</span>\<span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>\ISNULL</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,commission_pct</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> commission_pct <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br><span class="line"># <span class="keyword">WHERE</span> commission_pct <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,commission_pct</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> ISNULL(commission_pct);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_12-03-11.png" alt="Snipaste_2023-07-05_12-03-11" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># ②LESAT()\GREATEST最大<span class="operator">/</span>小值</span><br><span class="line"># 当参数是整数或者浮点数时，LEAST(GREATEST)将返回其中最小(大)的值；当参数为字符串的时候，返回字母表</span><br><span class="line"># 中顺序最靠前(后)的字符；当比较值中有<span class="keyword">NULL</span>时，返回<span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">SELECT</span> LEAST(<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>), LEAST(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>), LEAST(<span class="number">1</span>,<span class="keyword">NULL</span>,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# 结果依次为<span class="number">0</span>,a,<span class="keyword">null</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> GREATEST(<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>), GREATEST(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>), GREATEST(<span class="number">1</span>,<span class="keyword">NULL</span>,<span class="number">2</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# 结果依次为<span class="number">2</span>,c,<span class="keyword">null</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> LEAST(first_name, last_name), LEAST(LENGTH(first_name), LENGTH(last_name))</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_12-04-09.png" alt="Snipaste_2023-07-05_12-04-09" style="zoom: 33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># ③<span class="keyword">BETWEEN</span> <span class="keyword">AND</span>(包含边界)(范围查找)</span><br><span class="line"># 查询工资在<span class="number">6000</span>到<span class="number">8000</span>的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="keyword">BETWEEN</span> <span class="number">6000</span> <span class="keyword">AND</span> <span class="number">8000</span>;</span><br><span class="line"># <span class="keyword">WHERE</span> salary <span class="operator">&gt;=</span> <span class="number">6000</span> <span class="operator">&amp;&amp;</span> salary <span class="operator">&lt;=</span> <span class="number">8000</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_12-05-07.png" alt="Snipaste_2023-07-05_12-05-07" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查询工资不在<span class="number">6000</span>到<span class="number">8000</span>的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="keyword">NOT</span> <span class="keyword">BETWEEN</span> <span class="number">6000</span> <span class="keyword">AND</span> <span class="number">8000</span>;</span><br><span class="line"># <span class="keyword">WHERE</span> salary <span class="operator">&lt;</span> <span class="number">6000</span> <span class="operator">||</span> salary <span class="operator">&gt;</span> <span class="number">8000</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_12-05-48.png" alt="Snipaste_2023-07-05_12-05-48" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># ④<span class="keyword">IN</span> (<span class="keyword">set</span>)\<span class="keyword">NOT</span> <span class="keyword">IN</span> (<span class="keyword">set</span>)(离散值查找)</span><br><span class="line"># 查询部门为<span class="number">10</span>，<span class="number">20</span>，<span class="number">30</span>的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> last_name, salary, department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_16-01-48.png" alt="Snipaste_2023-07-05_16-01-48" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询工资不是<span class="number">6000</span>、<span class="number">7000</span>、<span class="number">8000</span>的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> last_name, salary, department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="keyword">NOT</span> <span class="keyword">IN</span> (<span class="number">6000</span>,<span class="number">7000</span>,<span class="number">8000</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_16-02-49.png" alt="Snipaste_2023-07-05_16-02-49" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># ⑤<span class="keyword">LIKE</span>：模糊查询</span><br><span class="line"># 主要用来匹配字符串，满足返回<span class="number">1</span>，否则返回<span class="number">0</span>。如果给定的值或匹配条件为<span class="keyword">NULL</span>，则返回结果为<span class="keyword">NULL</span></span><br><span class="line"># “<span class="operator">%</span>”：匹配<span class="number">0</span>个或多个字符</span><br><span class="line"># “_”：只能匹配一个字符</span><br><span class="line"># 查询last_name中包含字符’a‘的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;%a%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_16-03-33.png" alt="Snipaste_2023-07-05_16-03-33" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询last_name中以字符’a‘开头的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;a%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_16-04-14.png" alt="Snipaste_2023-07-05_16-04-14" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询last_name中包含字符’a‘且包含字符<span class="string">&#x27;e&#x27;</span>的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;%a%&#x27;</span> <span class="keyword">AND</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;%e%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_16-05-59.png" alt="Snipaste_2023-07-05_16-05-59" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询第二个字符是<span class="string">&#x27;a&#x27;</span>的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;_a%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_16-06-48.png" alt="Snipaste_2023-07-05_16-06-48" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 查询第二个字符是<span class="string">&#x27;_&#x27;</span>且第三个字符是<span class="string">&#x27;a&#x27;</span>的员工信息，需要使用转义字符</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;_\_a%&#x27;</span>;</span><br><span class="line">#(了解，用其他字符表示转义字符)</span><br><span class="line"># <span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;_$_a%&#x27;</span> <span class="keyword">ESCAPE</span> <span class="string">&#x27;$&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_16-07-28.png" alt="Snipaste_2023-07-05_16-07-28" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># ⑥ REGEXP\RLIKE:正则表达式</span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">&#x27;shkstart&#x27;</span> REGEXP <span class="string">&#x27;^s&#x27;</span>, <span class="string">&#x27;shkstart&#x27;</span> REGEXP <span class="string">&#x27;t$&#x27;</span>, <span class="string">&#x27;shkstart&#x27;</span> REGEXP <span class="string">&#x27;hk&#x27;</span></span><br><span class="line"><span class="keyword">FROM</span> dual; # 查询结果依次为<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">&#x27;atguigu&#x27;</span> REGEXP <span class="string">&#x27;gu.gu&#x27;</span>, <span class="string">&#x27;atguigu&#x27;</span> REGEXP <span class="string">&#x27;[ab]&#x27;</span></span><br><span class="line"><span class="keyword">FROM</span> dual; # 查询结果以此为<span class="number">1</span>,<span class="number">1</span></span><br></pre></td></tr></table></figure>

<h2 id="3-逻辑运算符"><a href="#3-逻辑运算符" class="headerlink" title="3. 逻辑运算符"></a>3. 逻辑运算符</h2><p>![webwxgetmsgimg (13)](MySQL相关知识&#x2F;webwxgetmsgimg (13).jpg)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.</span>逻辑运算符 <span class="keyword">NOT</span>,<span class="keyword">AND</span>,<span class="keyword">OR</span>,XOR(追求的是异)</span><br><span class="line"><span class="keyword">SELECT</span> last_name, salary, department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"># <span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">10</span> <span class="keyword">OR</span> department_id <span class="operator">=</span> <span class="number">20</span>;</span><br><span class="line"># <span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">50</span> <span class="keyword">AND</span> salary <span class="operator">&gt;</span> <span class="number">60</span>;</span><br><span class="line"># <span class="keyword">WHERE</span> salary <span class="keyword">NOT</span> <span class="keyword">BETWEEN</span> <span class="number">6000</span> <span class="keyword">AND</span> <span class="number">8000</span>;</span><br><span class="line"># <span class="keyword">WHERE</span> commission_pct <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">50</span> XOR salary <span class="operator">&gt;</span> <span class="number">6000</span>;</span><br><span class="line"># 注意：<span class="keyword">AND</span>的优先级高于<span class="keyword">OR</span></span><br></pre></td></tr></table></figure>

<h2 id="4-位运算符"><a href="#4-位运算符" class="headerlink" title="4. 位运算符"></a>4. 位运算符</h2><p>![webwxgetmsgimg (14)](MySQL相关知识&#x2F;webwxgetmsgimg (14).jpg)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span>位运算符 <span class="operator">&amp;</span>,<span class="operator">|</span>,<span class="operator">^</span>,<span class="operator">~</span>,<span class="operator">&gt;&gt;</span>,<span class="operator">&lt;&lt;</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">12</span> <span class="operator">&amp;</span> <span class="number">5</span>, <span class="number">12</span> <span class="operator">|</span> <span class="number">5</span>, <span class="number">12</span> <span class="operator">^</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">FROM</span> dual; # 查询结果依次为<span class="number">4</span>,<span class="number">13</span>,<span class="number">9</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">10</span> <span class="operator">&amp;</span> <span class="operator">~</span><span class="number">1</span></span><br><span class="line"><span class="keyword">FROM</span> dual; # 查询结果为<span class="number">10</span></span><br><span class="line"># 在一定范围内满足：每向左移动<span class="number">1</span>位，相当于乘以<span class="number">2</span>；每向右移动<span class="number">1</span>位，相当于除以<span class="number">2</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">4</span> <span class="operator">&lt;&lt;</span> <span class="number">1</span>, <span class="number">8</span> <span class="operator">&gt;&gt;</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">FROM</span> dual; # 查询结果分别为<span class="number">8</span>,<span class="number">4</span></span><br></pre></td></tr></table></figure>

<h1 id="第四章-排序与分页"><a href="#第四章-排序与分页" class="headerlink" title="第四章 排序与分页"></a>第四章 排序与分页</h1><h2 id="1-排序数据"><a href="#1-排序数据" class="headerlink" title="1. 排序数据"></a>1. 排序数据</h2><p>使用<strong>ORFER BY</strong>子句排序</p>
<p>ASC（升序），DESC（降序）</p>
<p><strong>ORDER BY子句在SELECT语句的结尾</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 按照salary从高到低的顺序显示员工信息</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-27-31.png" alt="Snipaste_2023-07-05_21-27-31" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 我们可以使用列的别名进行排序,列的别名只能在<span class="keyword">ORDER</span> <span class="keyword">BY</span>中使用，不能在<span class="keyword">WHERE</span>中使用</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, salary, salary <span class="operator">*</span> <span class="number">12</span> annual_sal</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> annual_sal;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-28-24.png" alt="Snipaste_2023-07-05_21-28-24" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 强调格式：<span class="keyword">WHERE</span>需要声明在<span class="keyword">FROM</span>后，<span class="keyword">ORDER</span> <span class="keyword">BY</span>之前</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, salary, department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (<span class="number">50</span>,<span class="number">60</span>,<span class="number">70</span>)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> department_id <span class="keyword">DESC</span> ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-29-08.png" alt="Snipaste_2023-07-05_21-29-08" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 二级排序(多列排序)</span><br><span class="line"># 显示员工信息，按照department_id的降序排列，如果相同则按照salary的升序排列</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, salary, department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> department_id <span class="keyword">DESC</span> ,salary <span class="keyword">ASC</span> ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-29-58.png" alt="Snipaste_2023-07-05_21-29-58" style="zoom:43%;">

<h2 id="2-分页"><a href="#2-分页" class="headerlink" title="2. 分页"></a>2. 分页</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span>分页</span><br><span class="line"># <span class="number">2.1</span> 使用LIMIT实现数据的分页显示</span><br><span class="line"># 查询返回的记录太多了，需要实现分页</span><br><span class="line"># 表里有<span class="number">4</span>条数据，只想要显示第<span class="number">2</span>，<span class="number">3</span>条数据怎么办？</span><br><span class="line"># 每页显示pageSize条记录，此时显示第pageNo页</span><br><span class="line"># 分页显示公式：（当前页数<span class="number">-1</span>）<span class="operator">*</span>每条页数，每条页数</span><br><span class="line"># LIMIT (pageNo<span class="number">-1</span>)<span class="operator">*</span>pageSize, pageSize;</span><br><span class="line"># 每页显示<span class="number">20</span>条记录，现在显示第<span class="number">3</span>页</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line">LIMIT <span class="number">40</span>,<span class="number">20</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-31-59.png" alt="Snipaste_2023-07-05_21-31-59" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.2</span> WHERE.....ORDER BY....LIMIT声明顺序</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> <span class="number">6000</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-32-41.png" alt="Snipaste_2023-07-05_21-32-41" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 表中有<span class="number">107</span>条数据，我们只想要显示第<span class="number">32</span>、<span class="number">33</span>条数据怎么办？</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line">LIMIT <span class="number">31</span>,<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">2.3</span> MySQL8<span class="number">.0</span>新特性：LIMIT..OFFSET..</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line">LIMIT <span class="number">2</span> <span class="keyword">OFFSET</span> <span class="number">31</span>;# 等价于LIMIT <span class="number">31</span>,<span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-33-36.png" alt="Snipaste_2023-07-05_21-33-36" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查询员工表中工资最高的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">DESC</span></span><br><span class="line">LIMIT  <span class="number">0</span>,<span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-34-11.png" alt="Snipaste_2023-07-05_21-34-11" style="zoom:43%;">

<h1 id="第五章-多表查询"><a href="#第五章-多表查询" class="headerlink" title="第五章 多表查询"></a>第五章 多表查询</h1><p>多表查询、也称为关联查询，指两个或更多表一起完成查询操作</p>
<h2 id="1-熟悉多个表"><a href="#1-熟悉多个表" class="headerlink" title="1. 熟悉多个表"></a>1. 熟悉多个表</h2><p>![webwxgetmsgimg (15)](MySQL相关知识&#x2F;webwxgetmsgimg (15).jpg)</p>
<h2 id="2-笛卡尔积的理解"><a href="#2-笛卡尔积的理解" class="headerlink" title="2. 笛卡尔积的理解"></a>2. 笛卡尔积的理解</h2><p>笛卡尔积的错误会在下面条件下产生：</p>
<ul>
<li>省略多个表的连接条件（或关联条件）</li>
<li>连接条件（或关联条件）无效</li>
<li>所有表中的所有行互相连接</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span> 出现笛卡尔积的错误</span><br><span class="line"># 错误原因：缺少多表的连接条件</span><br><span class="line"># 多表查询如何实现？</span><br><span class="line"># 错误的实现方式：每个员工都与每个部门匹配了一遍</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, department_name</span><br><span class="line"># <span class="keyword">FROM</span> employees, departments;# 查询了<span class="number">107</span><span class="operator">*</span><span class="number">27</span><span class="operator">=</span><span class="number">2889</span>条记录</span><br><span class="line"><span class="keyword">FROM</span> employees <span class="keyword">CROSS</span> <span class="keyword">JOIN</span> departments;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> employees;# <span class="number">107</span>条记录</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> departments; # <span class="number">27</span>条记录</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.</span><span class="operator">/</span><span class="number">4.</span><span class="operator">/</span><span class="number">5.</span>多表查询的正确方式：需要有连接条件,如果查询语句中出现了多个表中都存在的字段、则必须指明此字段所在的表</span><br><span class="line"># 建议：从<span class="keyword">sql</span>优化的角度，建议多表查询前，每个字段都指明其所在的表</span><br><span class="line"># 可以给表起别名，在<span class="keyword">SELECT</span>和<span class="keyword">WHERE</span>中使用表的别名,一旦起了别名就必须要使用</span><br><span class="line"></span><br><span class="line"># SQL92写法</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id,d.department_name,e.department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e,departments d</span><br><span class="line"># 两个表的连接条件</span><br><span class="line"><span class="keyword">WHERE</span> e.department_id <span class="operator">=</span> d.department_id;</span><br><span class="line"></span><br><span class="line">#SQL99写法</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id,d.department_name,e.department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_17-34-39.png" alt="Snipaste_2023-07-06_17-34-39" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.</span>结论：如果有n个表，需要有至少n<span class="number">-1</span>个连接条件，否则就会出现笛卡尔积的错误</span><br><span class="line"># 查询员工的employee_id,last_name,department_name,city</span><br><span class="line"># SQL92写法</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, e.last_name, d.department_name, l.city</span><br><span class="line"><span class="keyword">FROM</span> employees e, departments d, locations l</span><br><span class="line"><span class="keyword">WHERE</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">AND</span> d.location_id <span class="operator">=</span> l.location_id;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># SQL99写法</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, e.last_name, d.department_name, l.city</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">JOIN</span> locations l </span><br><span class="line"><span class="keyword">ON</span> d.location_id <span class="operator">=</span> l.location_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_17-42-21.png" alt="Snipaste_2023-07-06_17-42-21" style="zoom:43%;">

<h2 id="3-多表查询的分类"><a href="#3-多表查询的分类" class="headerlink" title="3. 多表查询的分类"></a>3. 多表查询的分类</h2><h3 id="3-1-等值连接-VS-非等值连接"><a href="#3-1-等值连接-VS-非等值连接" class="headerlink" title="3.1 等值连接 VS 非等值连接"></a>3.1 等值连接 VS 非等值连接</h3><p>以下均采用SQL99写法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 等值连接</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, e.last_name, d.department_name, l.city</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">JOIN</span> locations l</span><br><span class="line"><span class="keyword">ON</span> d.location_id <span class="operator">=</span> l.location_id;</span><br><span class="line"></span><br><span class="line"># 非等值连接</span><br><span class="line"><span class="keyword">SELECT</span> e.last_name, e.salary, j.grade_level</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> job_grades j</span><br><span class="line"><span class="keyword">ON</span> e.salary <span class="keyword">BETWEEN</span> j.lowest_sal <span class="keyword">AND</span> j.highest_sal;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-自连接-VS-非自连接"><a href="#3-2-自连接-VS-非自连接" class="headerlink" title="3.2 自连接 VS 非自连接"></a>3.2 自连接 VS 非自连接</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 非自连接（不同表之间）</span><br><span class="line"># 自连接(自己连接自己)</span><br><span class="line"># 查询员工id，员工姓名及其管理者的id和姓名</span><br><span class="line"><span class="keyword">SELECT</span> emp.employee_id, emp.last_name, mgr.employee_id,mgr.last_name</span><br><span class="line"><span class="keyword">FROM</span> employees emp, employees mgr</span><br><span class="line"><span class="keyword">WHERE</span> emp.manager_id <span class="operator">=</span> mgr.employee_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_21-19-05.png" alt="Snipaste_2023-07-06_21-19-05" style="zoom:43%;">

<h3 id="3-3-内连接-VS-外连接"><a href="#3-3-内连接-VS-外连接" class="headerlink" title="3.3 内连接 VS 外连接"></a>3.3 内连接 VS 外连接</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 内连接语法</span><br><span class="line"><span class="keyword">SELECT</span> 字段列表</span><br><span class="line"><span class="keyword">FROM</span> A表 <span class="keyword">JOIN</span> B表</span><br><span class="line"><span class="keyword">ON</span> 关联条件</span><br><span class="line">[<span class="keyword">JOIN</span> C表</span><br><span class="line"><span class="keyword">ON</span> 关联条件</span><br><span class="line"><span class="keyword">JOIN</span> D表</span><br><span class="line"><span class="keyword">ON</span> 关联条件</span><br><span class="line">......]</span><br><span class="line"><span class="keyword">WHERE</span> 等其他子句;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 内连接</span><br><span class="line"><span class="keyword">SELECT</span> e.last_name, d.department_name, l.city</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">JOIN</span> locations l</span><br><span class="line"><span class="keyword">ON</span> d.location_id <span class="operator">=</span> l.location_id;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 外连接：合并具有同一列的两个以上的表的行，结果集中除了包含一个表与另一个表匹配的行之外，</span><br><span class="line">#       还查询到了左表 或 右表中不匹配的行</span><br><span class="line">        # 外连接的分类：左外连接、右外连接、满外连接</span><br><span class="line"># 左外连接语法</span><br><span class="line">#实现查询结果是A</span><br><span class="line"><span class="keyword">SELECT</span> 字段列表</span><br><span class="line"><span class="keyword">FROM</span> A表 <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> B表</span><br><span class="line"><span class="keyword">ON</span> 关联条件</span><br><span class="line"><span class="keyword">WHERE</span> 等其他子句;</span><br><span class="line"></span><br><span class="line"># 右外连接语法</span><br><span class="line">#实现查询结果是B</span><br><span class="line"><span class="keyword">SELECT</span> 字段列表</span><br><span class="line"><span class="keyword">FROM</span> A表 <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> B表</span><br><span class="line"><span class="keyword">ON</span> 关联条件</span><br><span class="line"><span class="keyword">WHERE</span> 等其他子句;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查询“所有”员工的last_name,department_name信息</span><br><span class="line"># 内连接</span><br><span class="line"><span class="keyword">SELECT</span> e.last_name, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_21-29-22.png" alt="Snipaste_2023-07-06_21-29-22" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 左外连接</span><br><span class="line"><span class="keyword">SELECT</span> e.last_name, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_21-30-36.png" alt="Snipaste_2023-07-06_21-30-36" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 右外连接</span><br><span class="line"><span class="keyword">SELECT</span> e.last_name, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_21-31-21.png" alt="Snipaste_2023-07-06_21-31-21" style="zoom:43%;">

<h2 id="4-UNION的使用"><a href="#4-UNION的使用" class="headerlink" title="4. UNION的使用"></a>4. UNION的使用</h2><p><strong>合并查询结果</strong> 利用UNION关键字，可以给出多条SELECT语句，并将它们的结果组合成单个结果集。合并时，两个表对应的列数和数据类型必须相同，并且相互对应。各个SELECT语句之间使用UNION或UNION ALL关键字分隔。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 语法格式</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">column</span>,... <span class="keyword">FROM</span> table1</span><br><span class="line"><span class="keyword">UNION</span> [<span class="keyword">ALL</span>]</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">column</span>,... <span class="keyword">FROM</span> table2</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">UNION</span>：会执行去重的操作</span><br><span class="line"># <span class="keyword">UNION</span> <span class="keyword">ALL</span>：不会执行去重的操作</span><br><span class="line"># 如果明确知道合并数据后的结果数据不存在重复数据，或者不需要去除重复的数据，则尽量使用<span class="keyword">UNION</span> <span class="keyword">ALL</span>语句，以提高数据查询的效率。</span><br></pre></td></tr></table></figure>

<h2 id="5-七种JOIN的实现"><a href="#5-七种JOIN的实现" class="headerlink" title="5. 七种JOIN的实现"></a>5. 七种JOIN的实现</h2><img src="Snipaste_2023-07-06_21-57-46.png" alt="Snipaste_2023-07-06_21-57-46" style="zoom: 40%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1</span>：左外连接</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br><span class="line"></span><br><span class="line"># <span class="number">2</span>：右外连接</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>：内连接</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>：</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> d.department_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">5</span>：</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> e.department_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">6</span>：满外连接</span><br><span class="line"># 方式<span class="number">1</span>：<span class="number">1</span> <span class="keyword">UNION</span> <span class="keyword">ALL</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> e.department_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br><span class="line"># 方式<span class="number">2</span>：<span class="number">4</span> <span class="keyword">UNION</span> <span class="keyword">ALL</span> <span class="number">2</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> d.department_id <span class="keyword">IS</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br><span class="line"></span><br><span class="line"># <span class="number">7</span>：<span class="number">4</span> <span class="keyword">UNION</span> <span class="keyword">ALL</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> d.department_id <span class="keyword">IS</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> e.department_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>

<h2 id="6-SQL99语法新特性（了解）"><a href="#6-SQL99语法新特性（了解）" class="headerlink" title="6. SQL99语法新特性（了解）"></a>6. SQL99语法新特性（了解）</h2><h3 id="6-1-自然连接"><a href="#6-1-自然连接" class="headerlink" title="6.1 自然连接"></a>6.1 自然连接</h3><p>自然连接会帮你自动查询两张连接表中“所有相同”的字段，然后进行等值连接</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> e.employee_id, e.last_name, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">NATURAL</span> <span class="keyword">JOIN</span> departments d;</span><br><span class="line"># 等价于：</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, e.last_name, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">AND</span> e.manager_id <span class="operator">=</span> d.manager_id;</span><br></pre></td></tr></table></figure>

<h3 id="6-2-USING连接"><a href="#6-2-USING连接" class="headerlink" title="6.2 USING连接"></a>6.2 USING连接</h3><p>使用 USING 指定数据表里的 同名字段 进行等值连接。但是只能配合JOIN一起使用</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> e.employee_id,e.last_name,d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">USING</span> (department_id);</span><br><span class="line"># 等价于：</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id, e.last_name, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br></pre></td></tr></table></figure>

<h1 id="第六章-单行函数"><a href="#第六章-单行函数" class="headerlink" title="第六章 单行函数"></a>第六章 单行函数</h1><h2 id="1-两种SQL函数"><a href="#1-两种SQL函数" class="headerlink" title="1. 两种SQL函数"></a>1. 两种SQL函数</h2><p>单行函数 、 聚合函数（或分组函数） </p>
<p><img src="%E5%9B%BE11%E7%89%87.png" alt="图11片"></p>
<p><strong>单行函数</strong></p>
<ul>
<li>操作数据对象</li>
<li>接受参数返回一个结果</li>
<li><strong>只对一行进行变换</strong></li>
<li><strong>每行返回一个结果</strong></li>
<li>可以嵌套</li>
<li>参数可以是一列或一个值</li>
</ul>
<h2 id="2-数值函数"><a href="#2-数值函数" class="headerlink" title="2. 数值函数"></a>2. 数值函数</h2><h3 id="2-1-基本函数"><a href="#2-1-基本函数" class="headerlink" title="2.1 基本函数"></a>2.1 基本函数</h3><p><img src="Snipaste_2023-07-08_16-29-37.png" alt="Snipaste_2023-07-08_16-29-37"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 基本操作</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">ABS</span>(<span class="number">-123</span>),<span class="built_in">ABS</span>(<span class="number">32</span>),SIGN(<span class="number">-23</span>),SIGN(<span class="number">43</span>),PI(),<span class="built_in">CEIL</span>(<span class="number">32.32</span>),<span class="built_in">CEILING</span>(<span class="number">-43.32</span>),<span class="built_in">FLOOR</span>(<span class="number">32.32</span>),<span class="built_in">FLOOR</span>(<span class="number">-43.23</span>),<span class="built_in">MOD</span>(<span class="number">12</span>,<span class="number">5</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# 查询结果分别为<span class="number">123</span>，<span class="number">32</span>，<span class="number">-1</span>，<span class="number">1</span>，<span class="number">3.141593</span>，<span class="number">33</span>，<span class="number">-43</span>，<span class="number">32</span>，<span class="number">-44</span>，<span class="number">2</span></span><br><span class="line"># 取随机数</span><br><span class="line"><span class="keyword">SELECT</span> RAND(),RAND(),RAND(<span class="number">10</span>),RAND(<span class="number">10</span>),RAND(<span class="number">-1</span>),RAND(<span class="number">-1</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# RAND()得到的随机数是在<span class="number">0</span><span class="operator">~</span><span class="number">1</span>以内的，RAND(参数)表示每次取的随机数相同</span><br><span class="line"># 四舍五入，截断操作</span><br><span class="line"><span class="keyword">SELECT</span> ROUND(<span class="number">123.456</span>),ROUND(<span class="number">123.554</span>),ROUND(<span class="number">123.456</span>,<span class="number">0</span>),ROUND(<span class="number">123.456</span>,<span class="number">1</span>),ROUND(<span class="number">123.456</span>,<span class="number">2</span>),ROUND(<span class="number">123.456</span>,<span class="number">-1</span>),ROUND(<span class="number">153.234</span>,<span class="number">-2</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# 查询结果分别为<span class="number">123</span>，<span class="number">124</span>，<span class="number">123</span>，<span class="number">123.5</span>，<span class="number">123.46</span>，<span class="number">120</span>，<span class="number">200</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">TRUNCATE</span>(<span class="number">123.456</span>,<span class="number">0</span>),<span class="keyword">TRUNCATE</span>(<span class="number">123.497</span>,<span class="number">1</span>),<span class="keyword">TRUNCATE</span>(<span class="number">129.45</span>,<span class="number">-1</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# 查询结果分别为<span class="number">123</span>，<span class="number">123.4</span>，<span class="number">120</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">TRUNCATE</span>(employee_id,<span class="number">-1</span>) &quot;操作后的employee_id&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-34-28.png" alt="Snipaste_2023-07-08_16-34-28" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 单行函数可以嵌套</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">TRUNCATE</span>(ROUND(<span class="number">123.456</span>,<span class="number">2</span>),<span class="number">0</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">123</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">TRUNCATE</span>(ROUND(employee_id,<span class="number">2</span>),<span class="number">0</span>) &quot;操作后的employee_id&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-35-40.png" alt="Snipaste_2023-07-08_16-35-40" style="zoom:43%;">

<h3 id="2-2-角度与弧度互换函数"><a href="#2-2-角度与弧度互换函数" class="headerlink" title="2.2 角度与弧度互换函数"></a><strong>2.2</strong> <strong>角度与弧度互换函数</strong></h3><p><img src="Snipaste_2023-07-08_16-36-26.png" alt="Snipaste_2023-07-08_16-36-26"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> RADIANS(<span class="number">30</span>),RADIANS(<span class="number">45</span>),RADIANS(<span class="number">60</span>),RADIANS(<span class="number">90</span>),DEGREES(pi()<span class="operator">/</span><span class="number">6</span>),DEGREES(pi()<span class="operator">/</span><span class="number">4</span>),DEGREES(pi()<span class="operator">/</span><span class="number">3</span>),DEGREES(pi()<span class="operator">/</span><span class="number">2</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-三角函数"><a href="#2-3-三角函数" class="headerlink" title="2.3 三角函数"></a><strong>2.3</strong> <strong>三角函数</strong></h3><p><img src="Snipaste_2023-07-08_16-38-29.png" alt="Snipaste_2023-07-08_16-38-29"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 三角函数</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">SIN</span>(RADIANS(<span class="number">30</span>)),<span class="built_in">COS</span>(RADIANS(<span class="number">30</span>)),<span class="built_in">TAN</span>(RADIANS(<span class="number">45</span>))</span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-指数与对数"><a href="#2-4-指数与对数" class="headerlink" title="2.4 指数与对数"></a><strong>2.4</strong> <strong>指数与对数</strong></h3><p><img src="Snipaste_2023-07-08_16-39-20.png" alt="Snipaste_2023-07-08_16-39-20"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 指数和对数</span><br><span class="line"><span class="keyword">SELECT</span> POW(<span class="number">2</span>,<span class="number">5</span>),POW(<span class="number">2</span>,<span class="number">4</span>),<span class="built_in">EXP</span>(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">32</span>，<span class="number">16</span>，<span class="number">7.389056</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">LN</span>(<span class="built_in">EXP</span>(<span class="number">2</span>)),LOG2(<span class="number">4</span>),<span class="built_in">LOG</span>(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">2</span>，<span class="number">2</span>，<span class="number">2</span></span><br><span class="line"><span class="keyword">SELECT</span> POW(employee_id,<span class="number">1.25</span>) &quot;操作后的employee_id&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<h3 id="2-5-进制间的转换"><a href="#2-5-进制间的转换" class="headerlink" title="2.5 进制间的转换"></a><strong>2.5</strong> <strong>进制间的转换</strong></h3><p><img src="Snipaste_2023-07-08_16-40-43.png" alt="Snipaste_2023-07-08_16-40-43"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 进制间的转换</span><br><span class="line"><span class="keyword">SELECT</span> BIN(<span class="number">10</span>),HEX(<span class="number">10</span>),OCT(<span class="number">10</span>),CONV(<span class="number">1011</span>,<span class="number">2</span>,<span class="number">8</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">1010</span>，A，<span class="number">12</span>，<span class="number">13</span></span><br><span class="line"><span class="keyword">SELECT</span> CONV(employee_id,<span class="number">10</span>,<span class="number">16</span>) &quot;操作后的employee_id&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-42-08.png" alt="Snipaste_2023-07-08_16-42-08" style="zoom:43%;">

<h2 id="3-字符串函数"><a href="#3-字符串函数" class="headerlink" title="3. 字符串函数"></a>3. 字符串函数</h2><p><img src="Snipaste_2023-07-08_16-45-41.png" alt="Snipaste_2023-07-08_16-45-41"></p>
<p><img src="Snipaste_2023-07-08_16-46-36.png" alt="Snipaste_2023-07-08_16-46-36"></p>
<p><img src="Snipaste_2023-07-08_16-47-01.png" alt="Snipaste_2023-07-08_16-47-01"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ASCII(<span class="string">&#x27;A&#x27;</span>),<span class="keyword">CHAR_LENGTH</span>(<span class="string">&#x27;hello&#x27;</span>),<span class="keyword">CHAR_LENGTH</span>(<span class="string">&#x27;我们&#x27;</span>),LENGTH(<span class="string">&#x27;hello&#x27;</span>),LENGTH(<span class="string">&#x27;我们&#x27;</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">65</span>，<span class="number">5</span>，<span class="number">2</span>，<span class="number">5</span>，<span class="number">6</span></span><br><span class="line"><span class="keyword">SELECT</span> LENGTH(last_name) &quot;姓名的长度&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-48-27.png" alt="Snipaste_2023-07-08_16-48-27" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># xxx worked <span class="keyword">for</span> yyy</span><br><span class="line"><span class="keyword">SELECT</span> CONCAT(emp.last_name,<span class="string">&#x27; worked for &#x27;</span>,mgr.last_name) &quot;details&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees emp <span class="keyword">JOIN</span> employees mgr</span><br><span class="line"><span class="keyword">WHERE</span> emp.manager_id <span class="operator">=</span> mgr.employee_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-49-12.png" alt="Snipaste_2023-07-08_16-49-12" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CONCAT_WS(<span class="string">&#x27;-&#x27;</span>,employee_id,last_name,first_name) &quot;操作后的员工号-姓-名&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-50-06.png" alt="Snipaste_2023-07-08_16-50-06" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 字符串的索引是从<span class="number">1</span>开始的</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">INSERT</span>(last_name,<span class="number">2</span>,<span class="number">2</span>,CONCAT(<span class="string">&#x27;-&#x27;</span>,employee_id,<span class="string">&#x27;-&#x27;</span>)) &quot;插入后的last_name&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-50-56.png" alt="Snipaste_2023-07-08_16-50-56" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> REPLACE(last_name,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>) &quot;把所有员工的姓中字母a替换为字母b&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-51-43.png" alt="Snipaste_2023-07-08_16-51-43" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">UPPER</span>(last_name) &quot;大写的last_name&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-52-26.png" alt="Snipaste_2023-07-08_16-52-26" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">LEFT</span>(last_name,<span class="number">2</span>),<span class="keyword">RIGHT</span>(last_name,<span class="number">3</span>)</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-53-45.png" alt="Snipaste_2023-07-08_16-53-45" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># LPAD：实现右对齐效果</span><br><span class="line"># RPAD：实现左对齐效果</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,LPAD(salary,<span class="number">10</span>,<span class="string">&#x27;*&#x27;</span>),RPAD(salary,<span class="number">10</span>,<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-54-18.png" alt="Snipaste_2023-07-08_16-54-18" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">TRIM</span>(<span class="string">&#x27;       hello    &#x27;</span>),<span class="built_in">TRIM</span>(<span class="string">&#x27;o&#x27;</span> <span class="keyword">FROM</span> <span class="string">&#x27;oohello&#x27;</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# hello，hell</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> REPEAT(employee_id,<span class="number">3</span>) &quot;重复三次employee_id&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-56-18.png" alt="Snipaste_2023-07-08_16-56-18" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> STRCMP(last_name,first_name) &quot;比较姓和名的字符串大小&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;# 返回<span class="number">1</span>代表前面的数大，返回<span class="number">-1</span>代表后面的数大,返回<span class="number">0</span>代表一样大</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-56-51.png" alt="Snipaste_2023-07-08_16-56-51" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> SUBSTR(last_name,<span class="number">2</span>,<span class="number">2</span>) &quot;返回子字符串&quot;, LOCATE(<span class="string">&#x27;a&#x27;</span>,last_name) &quot;字母a在last_name中首次出现的位置&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-57-19.png" alt="Snipaste_2023-07-08_16-57-19" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> REVERSE(last_name) &quot;字符串反转&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-57-49.png" alt="Snipaste_2023-07-08_16-57-49" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> employee_id, <span class="built_in">NULLIF</span>(LENGTH(last_name), LENGTH(first_name)) &quot;compare&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_16-58-21.png" alt="Snipaste_2023-07-08_16-58-21" style="zoom:43%;">

<h2 id="4-日期和时间函数"><a href="#4-日期和时间函数" class="headerlink" title="4.日期和时间函数"></a>4.<strong>日期和时间函数</strong></h2><h3 id="4-1-获取日期、时间"><a href="#4-1-获取日期、时间" class="headerlink" title="4.1 获取日期、时间"></a><strong>4.1</strong> <strong>获取日期、时间</strong></h3><p><img src="Snipaste_2023-07-08_16-59-44.png" alt="Snipaste_2023-07-08_16-59-44"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> CURDATE(),CURTIME(),NOW(),SYSDATE()</span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-08_17-03-56.png" alt="Snipaste_2023-07-08_17-03-56"></p>
<h3 id="4-2-日期与时间戳的转换"><a href="#4-2-日期与时间戳的转换" class="headerlink" title="4.2 日期与时间戳的转换"></a><strong>4.2</strong> <strong>日期与时间戳的转换</strong></h3><p><img src="Snipaste_2023-07-08_17-04-39.png" alt="Snipaste_2023-07-08_17-04-39"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> UNIX_TIMESTAMP(<span class="string">&#x27;2022-10-22 12:23:43&#x27;</span>),FROM_UNIXTIME(<span class="number">2345656611</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">1666412623</span>,<span class="number">2044</span><span class="number">-05</span><span class="number">-01</span> <span class="number">03</span>:<span class="number">16</span>:<span class="number">51</span></span><br></pre></td></tr></table></figure>

<h3 id="4-3-获取月份、星期、星期数、天数等函数"><a href="#4-3-获取月份、星期、星期数、天数等函数" class="headerlink" title="4.3 获取月份、星期、星期数、天数等函数"></a><strong>4.3</strong> <strong>获取月份、星期、星期数、天数等函数</strong></h3><p><img src="Snipaste_2023-07-08_17-09-39.png" alt="Snipaste_2023-07-08_17-09-39"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">YEAR</span>(CURDATE()),<span class="keyword">MONTH</span>(CURDATE()),<span class="keyword">DAY</span>(CURDATE()),</span><br><span class="line"><span class="keyword">HOUR</span>(CURTIME()),<span class="keyword">MINUTE</span>(NOW()),<span class="keyword">SECOND</span>(SYSDATE())</span><br><span class="line"><span class="keyword">FROM</span> DUAL;# <span class="number">2023</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">17</span>,<span class="number">6</span>,<span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> MONTHNAME(<span class="string">&#x27;2021-10-26&#x27;</span>),DAYNAME(<span class="string">&#x27;2021-10-26&#x27;</span>),WEEKDAY(<span class="string">&#x27;2021-10-26&#x27;</span>),</span><br><span class="line">QUARTER(CURDATE()),WEEK(CURDATE()),DAYOFYEAR(NOW()),</span><br><span class="line">DAYOFMONTH(NOW()),DAYOFWEEK(NOW())</span><br><span class="line"><span class="keyword">FROM</span> DUAL;# October,Tuesday,<span class="number">1</span>,<span class="number">3</span>,<span class="number">27</span>,<span class="number">189</span>,<span class="number">8</span>,<span class="number">7</span></span><br></pre></td></tr></table></figure>

<h3 id="4-4-日期的操作函数"><a href="#4-4-日期的操作函数" class="headerlink" title="4.4 日期的操作函数"></a><strong>4.4</strong> <strong>日期的操作函数</strong></h3><p><img src="Snipaste_2023-07-08_17-10-39.png" alt="Snipaste_2023-07-08_17-10-39"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">EXTRACT</span>(<span class="keyword">SECOND</span> <span class="keyword">FROM</span> NOW())</span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<h3 id="4-5-时间和秒钟转换的函数"><a href="#4-5-时间和秒钟转换的函数" class="headerlink" title="4.5 时间和秒钟转换的函数"></a><strong>4.5</strong> <strong>时间和秒钟转换的函数</strong></h3><p><img src="Snipaste_2023-07-08_17-11-40.png" alt="Snipaste_2023-07-08_17-11-40"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> TIME_TO_SEC(CURTIME()),SEC_TO_TIME(<span class="number">87664</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">61922</span>,<span class="number">24</span>:<span class="number">21</span>:<span class="number">04</span></span><br></pre></td></tr></table></figure>

<h3 id="4-6-计算日期和时间的函数"><a href="#4-6-计算日期和时间的函数" class="headerlink" title="4.6 计算日期和时间的函数"></a><strong>4.6</strong> <strong>计算日期和时间的函数</strong></h3><p><img src="Snipaste_2023-07-08_17-13-01.png" alt="Snipaste_2023-07-08_17-13-01"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> NOW(),DATE_ADD(NOW(),<span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">YEAR</span> )</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">2023</span><span class="number">-07</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">13</span>:<span class="number">57</span>,<span class="number">2024</span><span class="number">-07</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">13</span>:<span class="number">57</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> DATE_ADD(hire_date,<span class="type">INTERVAL</span> <span class="number">1</span> <span class="keyword">YEAR</span> )</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-14-44.png" alt="Snipaste_2023-07-08_17-14-44" style="zoom:50%;">

<p><img src="Snipaste_2023-07-08_17-15-46.png" alt="Snipaste_2023-07-08_17-15-46"></p>
<h3 id="4-7-日期的格式化与解析"><a href="#4-7-日期的格式化与解析" class="headerlink" title="4.7 日期的格式化与解析"></a><strong>4.7</strong> <strong>日期的格式化与解析</strong></h3><p><img src="Snipaste_2023-07-08_17-17-31.png" alt="Snipaste_2023-07-08_17-17-31"></p>
<p>上述 非GET_FORMAT 函数中fmt参数常用的格式符：</p>
<p><img src="Snipaste_2023-07-08_17-18-43.png" alt="Snipaste_2023-07-08_17-18-43"></p>
<p>GET_FORMAT函数中date_type和format_type参数取值如下：</p>
<p><img src="Snipaste_2023-07-08_17-19-23.png" alt="Snipaste_2023-07-08_17-19-23"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> DATE_FORMAT(CURDATE(),<span class="string">&#x27;%Y-%M-%D&#x27;</span>),DATE_FORMAT(CURDATE(),<span class="string">&#x27;%Y-%m-%d&#x27;</span>),</span><br><span class="line">       TIME_FORMAT(CURTIME(),<span class="string">&#x27;%H:%i:%S&#x27;</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">2023</span><span class="operator">-</span>July<span class="number">-8</span>th,<span class="number">2023</span><span class="number">-07</span><span class="number">-08</span>,<span class="number">17</span>:<span class="number">16</span>:<span class="number">27</span></span><br><span class="line"># 最好这么写</span><br><span class="line"><span class="keyword">SELECT</span> DATE_FORMAT(CURDATE(),GET_FORMAT(<span class="type">DATE</span>,<span class="string">&#x27;ISO&#x27;</span>))</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">2023</span><span class="number">-07</span><span class="number">-08</span></span><br><span class="line"><span class="keyword">SELECT</span> TIME_FORMAT(CURTIME(),GET_FORMAT(<span class="type">TIME</span>,<span class="string">&#x27;ISO&#x27;</span>))</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">17</span>:<span class="number">17</span>:<span class="number">03</span></span><br></pre></td></tr></table></figure>

<h2 id="5-流程控制函数"><a href="#5-流程控制函数" class="headerlink" title="5. 流程控制函数"></a><strong>5.</strong> <strong>流程控制函数</strong></h2><p><img src="Snipaste_2023-07-08_17-20-46.png" alt="Snipaste_2023-07-08_17-20-46"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.1</span> IF(<span class="keyword">value</span>,value1,value2)</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,IF(salary <span class="operator">&gt;=</span> <span class="number">6000</span>,<span class="string">&#x27;高工资&#x27;</span>,<span class="string">&#x27;低工资&#x27;</span>) &quot;details&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-21-33.png" alt="Snipaste_2023-07-08_17-21-33" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> last_name,commission_pct,IF(commission_pct <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,commission_pct,<span class="number">0</span>) &quot;details&quot;,</span><br><span class="line">       salary <span class="operator">*</span> <span class="number">12</span><span class="operator">*</span> (<span class="number">1</span> <span class="operator">+</span> IF(commission_pct <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,commission_pct,<span class="number">0</span>)) &quot;annual_sal&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-23-03.png" alt="Snipaste_2023-07-08_17-23-03" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.2</span> IFNULL(value1, value2)</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,commission_pct,IFNULL(commission_pct,<span class="number">0</span>) &quot;details&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-24-06.png" alt="Snipaste_2023-07-08_17-24-06" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.3</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> 条件<span class="number">1</span> <span class="keyword">THEN</span> 结果<span class="number">1</span> <span class="keyword">WHEN</span> 条件<span class="number">2</span> <span class="keyword">THEN</span> 结果<span class="number">2</span></span><br><span class="line"># .... [<span class="keyword">ELSE</span> resultn] <span class="keyword">END</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,<span class="keyword">CASE</span> <span class="keyword">WHEN</span> salary <span class="operator">&gt;=</span> <span class="number">15000</span> <span class="keyword">THEN</span> <span class="string">&#x27;高薪&#x27;</span></span><br><span class="line">                             <span class="keyword">WHEN</span> salary <span class="operator">&gt;=</span> <span class="number">10000</span> <span class="keyword">THEN</span> <span class="string">&#x27;潜力股&#x27;</span></span><br><span class="line">                             <span class="keyword">WHEN</span> salary <span class="operator">&gt;=</span> <span class="number">8000</span> <span class="keyword">THEN</span> <span class="string">&#x27;小屌丝&#x27;</span></span><br><span class="line">                             <span class="keyword">ELSE</span> <span class="string">&#x27;草根&#x27;</span> <span class="keyword">END</span> &quot;details&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-38-26.png" alt="Snipaste_2023-07-08_17-38-26" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.4</span> <span class="keyword">CASE</span> expr <span class="keyword">WHEN</span> 常量值<span class="number">1</span> <span class="keyword">THEN</span> 值<span class="number">1</span> <span class="keyword">WHEN</span> 常量值<span class="number">1</span> <span class="keyword">THEN</span></span><br><span class="line"># 值<span class="number">1</span> .... [<span class="keyword">ELSE</span> 值n] <span class="keyword">END</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">查询部门号为 10,20, 30 的员工信息, 若部门号为 10, 则打印其工资的 1.1 倍, 20 号部门, 则打印其</span></span><br><span class="line"><span class="comment">工资的 1.2 倍, 30 号部门打印其工资的 1.3 倍数。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,department_id,</span><br><span class="line">       <span class="keyword">CASE</span> department_id <span class="keyword">WHEN</span> <span class="number">10</span> <span class="keyword">THEN</span> <span class="number">1.1</span><span class="operator">*</span>salary</span><br><span class="line">                          <span class="keyword">WHEN</span> <span class="number">20</span> <span class="keyword">THEN</span> <span class="number">1.2</span><span class="operator">*</span>salary</span><br><span class="line">                          <span class="keyword">WHEN</span> <span class="number">30</span> <span class="keyword">THEN</span> <span class="number">1.3</span><span class="operator">*</span>salary</span><br><span class="line">                          <span class="keyword">END</span> &quot;details&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>);</span><br><span class="line"># 等价于</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,department_id,</span><br><span class="line">       <span class="keyword">CASE</span> <span class="keyword">WHEN</span> department_id <span class="operator">=</span> <span class="number">10</span> <span class="keyword">THEN</span> <span class="number">1.1</span><span class="operator">*</span>salary</span><br><span class="line">            <span class="keyword">WHEN</span> department_id <span class="operator">=</span> <span class="number">20</span> <span class="keyword">THEN</span> <span class="number">1.2</span><span class="operator">*</span>salary</span><br><span class="line">            <span class="keyword">WHEN</span> department_id <span class="operator">=</span> <span class="number">30</span> <span class="keyword">THEN</span> <span class="number">1.3</span><span class="operator">*</span>salary</span><br><span class="line">            <span class="keyword">END</span> &quot;details&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>);</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-08_17-39-23.png" alt="Snipaste_2023-07-08_17-39-23"></p>
<h2 id="6-加密与解密函数"><a href="#6-加密与解密函数" class="headerlink" title="6. 加密与解密函数"></a><strong>6.</strong> <strong>加密与解密函数</strong></h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> MD5(<span class="string">&#x27;wyh&#x27;</span>),SHA(<span class="string">&#x27;wyh&#x27;</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;#ff9b29f2c15263e6b2c11344ecc05fbf,<span class="number">7236</span>c9fd79b3a7f002a9f55a05d923623eed0779</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-08_17-40-55.png" alt="Snipaste_2023-07-08_17-40-55"></p>
<h2 id="7-MySQL信息函数"><a href="#7-MySQL信息函数" class="headerlink" title="7. MySQL信息函数"></a>7. MySQL信息函数</h2><p><img src="Snipaste_2023-07-08_17-42-03.png" alt="Snipaste_2023-07-08_17-42-03"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> VERSION(),CONNECTION_ID(),DATABASE(),<span class="keyword">USER</span>(),CHARSET(<span class="string">&#x27;王宇涵&#x27;</span>),<span class="keyword">COLLATION</span>(<span class="string">&#x27;王宇涵&#x27;</span>)</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">8.0</span><span class="number">.33</span>,<span class="number">80</span>,atguigudb,root<span class="variable">@localhost</span>,utf8mb4,utf8mb4_0900_ai_ci</span><br></pre></td></tr></table></figure>

<h2 id="8-其他函数"><a href="#8-其他函数" class="headerlink" title="8. 其他函数"></a><strong>8.</strong> <strong>其他函数</strong></h2><p><img src="Snipaste_2023-07-08_17-45-23.png" alt="Snipaste_2023-07-08_17-45-23"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># BENCHMARK()用于测试表达式的执行次效率、</span><br><span class="line"><span class="keyword">SELECT</span> BENCHMARK(<span class="number">10000</span>,MD5(<span class="string">&#x27;wyh&#x27;</span>))</span><br><span class="line"><span class="keyword">FROM</span> dual;</span><br></pre></td></tr></table></figure>

<h1 id="第七章-聚合函数"><a href="#第七章-聚合函数" class="headerlink" title="第七章 聚合函数"></a>第七章 聚合函数</h1><h2 id="1-聚合函数定义"><a href="#1-聚合函数定义" class="headerlink" title="1. 聚合函数定义"></a>1. 聚合函数定义</h2><p>聚合函数作用于一组数据，并对一组数据返回一个值。</p>
<p><strong>聚合函数类型</strong></p>
<ul>
<li><strong>AVG()</strong></li>
<li><strong>SUM()</strong></li>
<li><strong>MAX()</strong></li>
<li><strong>MIN()</strong></li>
<li><strong>COUNT()</strong></li>
</ul>
<p>聚合函数不能嵌套调用。比如不能出现类似“AVG(SUM(字段名称))”形式的调用。</p>
<h2 id="2-常见的几个聚合函数"><a href="#2-常见的几个聚合函数" class="headerlink" title="2. 常见的几个聚合函数"></a>2. 常见的几个聚合函数</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.</span>常见的几个聚合函数</span><br><span class="line"># <span class="number">1.1</span> AVG<span class="operator">/</span>SUM:只适用于数值类型的字段（或变量）</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary),<span class="built_in">SUM</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees;# <span class="number">6461.682243</span>,<span class="number">691400</span></span><br><span class="line"></span><br><span class="line"># <span class="number">1.2</span> MIN<span class="operator">/</span>MAX:适用于数值类型、字符串类型、日期时间类型的字段（或变量）</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">MIN</span>(salary),<span class="built_in">MAX</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees;# <span class="number">2100</span>,<span class="number">24000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">MIN</span>(last_name),<span class="built_in">MAX</span>(last_name),<span class="built_in">MIN</span>(hire_date),<span class="built_in">MAX</span>(hire_date)</span><br><span class="line"><span class="keyword">FROM</span> employees;# Abel, Zlotkey, <span class="number">1987</span><span class="number">-06</span><span class="number">-17</span>, <span class="number">2000</span><span class="number">-04</span><span class="number">-21</span></span><br><span class="line"></span><br><span class="line"># <span class="number">1.3</span> COUNT</span><br><span class="line"># ① 作用：计算指定字段在查询结果中出现的个数（不包含<span class="keyword">NULL</span>值）</span><br><span class="line"><span class="keyword">SELECT</span> salary,<span class="number">100</span></span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(employee_id),<span class="built_in">COUNT</span>(salary),<span class="built_in">COUNT</span>(<span class="number">2</span><span class="operator">*</span>salary),<span class="built_in">COUNT</span>(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">FROM</span> employees; # <span class="number">107</span>,<span class="number">107</span>,<span class="number">107</span>,<span class="number">107</span></span><br><span class="line"># 如果计算表中有多少条记录，如何实现？</span><br><span class="line"># 方式<span class="number">1</span>：<span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line"># 方式<span class="number">2</span>：<span class="built_in">COUNT</span>(<span class="number">1</span>)</span><br><span class="line"># 方式<span class="number">3</span>：<span class="built_in">COUNT</span>(具体字段)：不一定对！</span><br><span class="line"></span><br><span class="line"># ② 注意：计算指定字段出现的个数时，是不计算<span class="keyword">NULL</span>值的</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(commission_pct)</span><br><span class="line"><span class="keyword">FROM</span> employees;# <span class="number">35</span></span><br><span class="line"></span><br><span class="line"># ③ AVG <span class="operator">=</span> SUM <span class="operator">/</span> COUNT</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary),<span class="built_in">SUM</span>(salary)<span class="operator">/</span><span class="built_in">COUNT</span>(salary),<span class="built_in">AVG</span>(commission_pct),<span class="built_in">SUM</span>(commission_pct)<span class="operator">/</span><span class="built_in">COUNT</span>(commission_pct)</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br><span class="line"></span><br><span class="line"># 查询公司中平均奖金率</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">SUM</span>(commission_pct) <span class="operator">/</span> <span class="built_in">COUNT</span>(IFNULL(commission_pct,<span class="number">0</span>)),<span class="built_in">AVG</span>(IFNULL(commission_pct,<span class="number">0</span>))</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br><span class="line"></span><br><span class="line"># 如果需要统计表中的记录数，使用<span class="built_in">COUNT</span>(<span class="operator">*</span>)、<span class="built_in">COUNT</span>(<span class="number">1</span>)、<span class="built_in">COUNT</span>(具体字段)哪个效率更高？</span><br><span class="line"># 如果使用的是MyISAM存储引擎，则三者效率相同，O(<span class="number">1</span>)</span><br><span class="line"># 如果使用的是InnoDB存储引擎，则三者效率：<span class="built_in">COUNT</span>(<span class="operator">*</span>)<span class="operator">=</span><span class="built_in">COUNT</span>(<span class="number">1</span>)<span class="operator">&gt;</span><span class="built_in">COUNT</span>(具体字段)</span><br><span class="line"></span><br><span class="line"># 其他：求方差、标准差、中位数</span><br></pre></td></tr></table></figure>

<p>COUNT(*)返回表中记录总数，适用于<strong>任意数据类型</strong>。</p>
<p>COUNT(expr) 返回<strong>expr</strong> <strong>不为空</strong>的记录总数。</p>
<p>count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。</p>
<h2 id="3-GROUP-BY"><a href="#3-GROUP-BY" class="headerlink" title="3. GROUP BY"></a><strong>3. GROUP BY</strong></h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询各个部门的平均工资、最高工资</span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary),<span class="built_in">MAX</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_08-48-10.png" alt="Snipaste_2023-07-09_08-48-10" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询各个job_id的平均工资</span><br><span class="line"><span class="keyword">SELECT</span> job_id,<span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_08-48-57.png" alt="Snipaste_2023-07-09_08-48-57" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 查询各个department_id,job_id的平均工资</span><br><span class="line"><span class="keyword">SELECT</span> department_id,job_id,<span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id,job_id;</span><br><span class="line"># 或</span><br><span class="line"><span class="keyword">SELECT</span> department_id,job_id,<span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id,department_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_08-49-42.png" alt="Snipaste_2023-07-09_08-49-42" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 结论<span class="number">1</span>：<span class="keyword">SELECT</span>中出现的非组函数字段必须声明在<span class="keyword">GROUP</span> <span class="keyword">BY</span>中，反之<span class="keyword">GROUP</span> <span class="keyword">BY</span>中声明的字段可以不出现在<span class="keyword">SELECT</span>中</span><br><span class="line"></span><br><span class="line"># 结论<span class="number">2</span>：<span class="keyword">GROUP</span> <span class="keyword">BY</span>声明在<span class="keyword">FROM</span>（<span class="keyword">WHERE</span>）后面、<span class="keyword">ORDER</span> <span class="keyword">BY</span>，LIMIT的前面</span><br><span class="line"><span class="keyword">SELECT</span> department_id,job_id,<span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;=</span> <span class="number">5000</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id, department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">&gt;=</span> <span class="number">7000</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_sal</span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"># 结论<span class="number">3</span>：MySQL中<span class="keyword">GROUP</span> <span class="keyword">BY</span>中使用<span class="keyword">WITH</span> <span class="keyword">ROLLUP</span>，使用<span class="keyword">WITH</span> <span class="keyword">ROLLUP</span>时不能使用<span class="keyword">ORDER</span> <span class="keyword">BY</span>，否则排斥</span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id <span class="keyword">WITH</span> <span class="keyword">ROLLUP</span>;# 对整体数据进行AVG运算</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_08-51-05.png" alt="Snipaste_2023-07-09_08-51-05" style="zoom:50%;">

<h2 id="4-HAVING"><a href="#4-HAVING" class="headerlink" title="4. HAVING"></a>4. HAVING</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.</span> <span class="keyword">HAVING</span>的使用（用来过滤数据）</span><br><span class="line"># 要求<span class="number">1</span>：过滤条件中一旦出现聚合（组）函数，过滤条件要从<span class="keyword">WHERE</span>替换为<span class="keyword">HAVING</span>，也就是说<span class="keyword">WHERE</span>语句中不能出现聚合（组）函数</span><br><span class="line"># 要求<span class="number">2</span>：<span class="keyword">HAVING</span>语句必须声明在<span class="keyword">GROUP</span> <span class="keyword">BY</span>语句的后面</span><br><span class="line"># 查询各个部门中最高工资比<span class="number">10000</span>高的部门信息</span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">MAX</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">MAX</span>(salary) <span class="operator">&gt;</span> <span class="number">10000</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_08-52-38.png" alt="Snipaste_2023-07-09_08-52-38" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 要求<span class="number">3</span>：开发中，使用<span class="keyword">HAVING</span>的前提是使用<span class="keyword">GROUP</span> <span class="keyword">BY</span>，即<span class="keyword">GROUP</span> <span class="keyword">BY</span>和<span class="keyword">HAVING</span>要一起使用</span><br><span class="line"># 查询部门为<span class="number">10</span>，<span class="number">20</span>，<span class="number">30</span>，<span class="number">40</span>这<span class="number">4</span>个部门中最高工资比<span class="number">10000</span>高的部门信息</span><br><span class="line"># 方式<span class="number">1</span>：推荐使用，执行效率高于方式<span class="number">2</span></span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">MAX</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">MAX</span>(salary) <span class="operator">&gt;</span> <span class="number">10000</span>;</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：</span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">MAX</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">MAX</span>(salary) <span class="operator">&gt;</span> <span class="number">10000</span> <span class="keyword">AND</span> department_id <span class="keyword">IN</span> (<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_08-53-20.png" alt="Snipaste_2023-07-09_08-53-20" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 结论：当过滤条件中用聚合函数时，则此时过滤条件必须声明在<span class="keyword">HAVING</span>中</span><br><span class="line">#      当过滤条件中没有聚合函数时，则此时过滤条件必须声明在<span class="keyword">WHERE</span>中</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> WHERE 与 HAVING的对比</span></span><br><span class="line"><span class="comment"> 1.从适用范围来讲，HAVING的适用范围更广</span></span><br><span class="line"><span class="comment"> 2.如果过滤条件中没有聚合函数，这种情况下，WHERE的执行效率要高于HAVING</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p><strong>区别1</strong>：<strong>WHERE</strong> <strong>可以直接使用表中的字段作为筛选条件，但不能使用分组中的计算函数作为筛选条件；</strong>HAVING<strong>必须要与</strong> <strong>GROUP BY</strong> <strong>配合使用，可以把分组计算的函数和分组字段作为筛选条件。</strong></p>
<p>这决定了，在需要对数据进行分组统计的时候，HAVING 可以完成 WHERE 不能完成的任务。这是因为，在查询语法结构中，WHERE 在 GROUP BY 之前，所以无法对分组结果进行筛选。HAVING 在 GROUP BY 之后，可以使用分组字段和分组中的计算函数，对分组的结果集进行筛选，这个功能是 WHERE 无法完成的。另外，WHERE排除的记录不再包括在分组中。</p>
<p><strong>区别2</strong>：<strong>如果需要通过连接从关联表中获取需要的数据</strong>，<strong>WHERE</strong> <strong>是先筛选后连接，而</strong> <strong>HAVING</strong> <strong>是先连接</strong>后筛选。 这一点，就决定了在关联查询中，WHERE 比 HAVING 更高效。因为 WHERE 可以先筛选，用一个筛选后的较小数据集和关联表进行连接，这样占用的资源比较少，执行效率也比较高。HAVING 则需要先把结果集准备好，也就是用未被筛选的数据集进行关联，然后对这个大的数据集进行筛选，这样占用的资源就比较多，执行效率也较低。</p>
<h2 id="5-SQL底层执行原理"><a href="#5-SQL底层执行原理" class="headerlink" title="5. SQL底层执行原理"></a>5. SQL底层执行原理</h2><h3 id="5-1-SELECT语句的完整结构"><a href="#5-1-SELECT语句的完整结构" class="headerlink" title="5.1 SELECT语句的完整结构"></a>5.1 SELECT语句的完整结构</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> SELECT .........(存在聚合函数)</span></span><br><span class="line"><span class="comment"> FROM...(LEFT/RIGHT)JOIN...ON 多表的连接条件</span></span><br><span class="line"><span class="comment"> [(LEFT/RIGHT)JOIN...ON ]</span></span><br><span class="line"><span class="comment"> WHERE 不包含聚合函数的过滤条件</span></span><br><span class="line"><span class="comment"> GROUP BY......</span></span><br><span class="line"><span class="comment"> HAVING 包含聚合函数的过滤条件</span></span><br><span class="line"><span class="comment"> ORDER BY.....(ASC/DESC)</span></span><br><span class="line"><span class="comment"> LIMIT.......;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<h3 id="5-2-SQL语句的执行过程"><a href="#5-2-SQL语句的执行过程" class="headerlink" title="5.2 SQL语句的执行过程"></a>5.2 SQL语句的执行过程</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">FROM</span><span class="comment">--&gt;ON--&gt;(LEFT/RIGHT)JOIN--&gt;WHERE--&gt;GROUP BY--&gt;HAVING--&gt;SELECT--&gt;DISTINCT--&gt;ORDER BY--&gt;LIMIT</span></span><br></pre></td></tr></table></figure>

<h1 id="第八章-子查询"><a href="#第八章-子查询" class="headerlink" title="第八章 子查询"></a>第八章 子查询</h1><h2 id="1-需求分析与问题解决"><a href="#1-需求分析与问题解决" class="headerlink" title="1. 需求分析与问题解决"></a>1. 需求分析与问题解决</h2><h3 id="1-1-实际问题"><a href="#1-1-实际问题" class="headerlink" title="1.1 实际问题"></a>1.1 实际问题</h3><p>谁的工资比Abel高？</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">1</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="operator">=</span> <span class="string">&#x27;Abel&#x27;</span>;# <span class="number">11000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> <span class="number">11000</span>;</span><br><span class="line"># 以上写效率低</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：自连接</span><br><span class="line"><span class="keyword">SELECT</span> e2.last_name,e2.salary</span><br><span class="line"><span class="keyword">FROM</span> employees e1 <span class="keyword">JOIN</span> employees e2</span><br><span class="line"><span class="keyword">ON</span> e2.salary <span class="operator">&gt;</span> e1.salary</span><br><span class="line"><span class="keyword">AND</span> e1.last_name <span class="operator">=</span> <span class="string">&#x27;Abel&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">3</span>：子查询</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> salary</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> last_name <span class="operator">=</span> <span class="string">&#x27;Abel&#x27;</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-35-28.png" alt="Snipaste_2023-07-12_22-35-28" style="zoom:50%;">

<h3 id="1-2-子查询的基本使用"><a href="#1-2-子查询的基本使用" class="headerlink" title="1.2 子查询的基本使用"></a>1.2 子查询的基本使用</h3><ul>
<li>子查询（内查询）在主查询之前一次执行完成。</li>
<li>子查询的结果被主查询（外查询）使用 。</li>
</ul>
<p><strong>注意事项</strong></p>
<ul>
<li>子查询要包含在括号内</li>
<li>将子查询放在比较条件的右侧</li>
<li>单行操作符对应单行子查询，多行操作符对应多行子查询</li>
</ul>
<h3 id="1-3-子查询的分类"><a href="#1-3-子查询的分类" class="headerlink" title="1.3 子查询的分类"></a>1.3 子查询的分类</h3><p><strong>分类方式1</strong></p>
<p>我们按内查询的结果返回一条还是多条记录，将子查询分为 <strong>单行子查询 、 多行子查询</strong></p>
<p><strong>分类方式2</strong></p>
<p>我们按内查询是否被执行多次，将子查询划分为 相关(或关联)子查询 和 不相关(或非关联)子查询 。子查询从数据表中查询了数据结果，如果这个数据结果只执行一次，然后这个数据结果作为主查询的条件进行执行，那么这样的子查询叫做<strong>不相关子查询</strong>。</p>
<p>同样，如果子查询需要执行多次，即采用循环的方式，先从外部查询开始，每次都传入子查询进行查询，然后再将结果反馈给外部，这种嵌套的执行方式就称为<strong>相关子查询</strong>。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 相关子查询，如，查询工资大于本部门平均工资的员工信息</span></span><br><span class="line"><span class="comment"> 不相关子查询，如，查询工资大于本公司平均工资的员工信息</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"># 子查询编写技巧：①从里往外写。②从外往里写</span><br><span class="line"># 子查询语句可以放到很多地方，这就意味着子查询语句结果可以是单行单列，</span><br><span class="line"># 单行多列，多行单列，多行多列都可以</span><br></pre></td></tr></table></figure>

<h2 id="2-单行子查询"><a href="#2-单行子查询" class="headerlink" title="2. 单行子查询"></a>2. 单行子查询</h2><h3 id="2-1-单行操作符"><a href="#2-1-单行操作符" class="headerlink" title="2.1 单行操作符"></a>2.1 单行操作符</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&lt;</span>,<span class="operator">&gt;</span>,<span class="operator">=</span>,<span class="operator">&lt;=</span>,<span class="operator">&gt;=</span>,<span class="operator">!=</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 题目<span class="number">1</span>：查询工资大于<span class="number">149</span>号员工工资的员工的信息</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> salary</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">149</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-45-08.png" alt="Snipaste_2023-07-12_22-45-08" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 题目<span class="number">2</span>：返回job_id与<span class="number">141</span>号员工相同，salary比<span class="number">143</span>号员工多的员工姓名，job_id和工资</span><br><span class="line"><span class="keyword">SELECT</span> last_name,job_id,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> job_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> job_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">141</span></span><br><span class="line">    ) <span class="keyword">AND</span> salary <span class="operator">&gt;</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> salary</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">143</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-45-54.png" alt="Snipaste_2023-07-12_22-45-54" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 题目<span class="number">3</span>：返回公司工资最少的员工的last_name,job_id和salary</span><br><span class="line"><span class="keyword">SELECT</span> last_name,job_id,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-46-33.png" alt="Snipaste_2023-07-12_22-46-33" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 题目<span class="number">4</span>：查询与<span class="number">141</span>号员工的manager_id和department_id相同的</span><br><span class="line"># 其他员工的employee_id,manager_id,department_id</span><br><span class="line"># 方式<span class="number">1</span>：</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,manager_id,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> manager_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">141</span></span><br><span class="line">    ) <span class="keyword">AND</span> department_id <span class="operator">=</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> department_id</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">141</span></span><br><span class="line">    ) <span class="keyword">AND</span> employee_id <span class="operator">!=</span> <span class="number">141</span>;</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：了解</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,manager_id,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> (manager_id,department_id) <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> manager_id,department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">141</span> # 此子查询语句有两列，不常用</span><br><span class="line">    ) <span class="keyword">AND</span> employee_id <span class="operator">!=</span> <span class="number">141</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-47-20.png" alt="Snipaste_2023-07-12_22-47-20" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 题目<span class="number">5</span>：查询最低工工资大于<span class="number">110</span>号部门最低工资的部门id和其最低工资</span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">MIN</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">MIN</span>(salary) <span class="operator">&gt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">110</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-48-10.png" alt="Snipaste_2023-07-12_22-48-10" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 题目6：显式员工的employee_id,last_name和location</span></span><br><span class="line"><span class="comment"> 其中，若员工department_id与location_id为1800的department_id相同</span></span><br><span class="line"><span class="comment"> 则location为‘Canada’，其余则为&#x27;USA&#x27;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,</span><br><span class="line">       (IF(department_id <span class="operator">=</span> (<span class="keyword">SELECT</span> department_id <span class="keyword">FROM</span> departments <span class="keyword">WHERE</span> location_id <span class="operator">=</span> <span class="number">1800</span>), <span class="string">&#x27;Canada&#x27;</span>, <span class="string">&#x27;USA&#x27;</span>)) &quot;location&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-49-13.png" alt="Snipaste_2023-07-12_22-49-13" style="zoom:50%;">

<h3 id="2-2-子查询中的空值问题"><a href="#2-2-子查询中的空值问题" class="headerlink" title="2.2 子查询中的空值问题"></a>2.2 子查询中的空值问题</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> last_name,job_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> job_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> job_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> last_name <span class="operator">=</span> <span class="string">&#x27;Haas&#x27;</span></span><br><span class="line">    );# 公司中没有<span class="string">&#x27;Hass&#x27;</span>这个人</span><br></pre></td></tr></table></figure>

<h3 id="2-3-非法使用子查询"><a href="#2-3-非法使用子查询" class="headerlink" title="2.3 非法使用子查询"></a>2.3 非法使用子查询</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># Subquery <span class="keyword">returns</span> more than <span class="number">1</span> <span class="type">row</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    );</span><br><span class="line"># 改成多行子查询</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-51-15.png" alt="Snipaste_2023-07-12_22-51-15" style="zoom:50%;">

<h2 id="3-多行子查询"><a href="#3-多行子查询" class="headerlink" title="3. 多行子查询"></a>3. 多行子查询</h2><h3 id="3-1-多行比较操作符"><a href="#3-1-多行比较操作符" class="headerlink" title="3.1 多行比较操作符"></a>3.1 多行比较操作符</h3><p><img src="Snipaste_2023-07-12_22-53-18.png" alt="Snipaste_2023-07-12_22-53-18"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">IN</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">ANY</span> <span class="operator">/</span> <span class="keyword">ALL</span></span><br><span class="line"># 题目：返回其他job_id中比job_id为<span class="string">&#x27;IT_PROG&#x27;</span>部门任一工资低的员工</span><br><span class="line"># 的员工号、姓名、job_id以及salary</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> job_id <span class="operator">!=</span> <span class="string">&#x27;IT_PROG&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> salary <span class="operator">&lt;</span> <span class="keyword">ANY</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> salary</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> job_id <span class="operator">=</span> <span class="string">&#x27;IT_PROG&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-54-35.png" alt="Snipaste_2023-07-12_22-54-35" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 题目：返回其他job_id中比job_id为<span class="string">&#x27;IT_PROG&#x27;</span>部门所有工资低的员工</span><br><span class="line"># 的员工号、姓名、job_id以及salary</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> job_id <span class="operator">!=</span> <span class="string">&#x27;IT_PROG&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> salary <span class="operator">&lt;</span> <span class="keyword">ALL</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> salary</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> job_id <span class="operator">=</span> <span class="string">&#x27;IT_PROG&#x27;</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-55-12.png" alt="Snipaste_2023-07-12_22-55-12" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 题目：查询平均工资最低的部门id</span><br><span class="line"># MySQL中，聚合函数是不能嵌套使用的</span><br><span class="line"># 方式<span class="number">1</span>：</span><br><span class="line"><span class="keyword">SELECT</span> department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(avg_sal)</span><br><span class="line">    <span class="keyword">FROM</span> (</span><br><span class="line">         <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">         <span class="keyword">FROM</span> employees</span><br><span class="line">         <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">             ) t_dept_avg_sal</span><br><span class="line">    );# <span class="number">50</span></span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：</span><br><span class="line"><span class="keyword">SELECT</span> department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">&lt;=</span> <span class="keyword">ALL</span>(</span><br><span class="line">     <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">     <span class="keyword">FROM</span> employees</span><br><span class="line">     <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    );# <span class="number">50</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 因为MySQL中不能使用聚合函数嵌套，可以利用一些多行子查询操作符替代，注意：对应范围一定相同，具体问题具体分析</span><br><span class="line"># <span class="operator">&lt;=</span><span class="keyword">ALL</span>(字段) 等价于 <span class="operator">&lt;=</span>(<span class="built_in">MIN</span>(字段))，字段是表的节选字段</span><br><span class="line"># <span class="operator">&lt;=</span><span class="keyword">ALL</span>(字段) 等价于 <span class="operator">=</span>(<span class="built_in">MIN</span>(字段))，字段是表的全部字段</span><br><span class="line"># <span class="operator">&gt;=</span> <span class="keyword">ALL</span>(字段) 等价于 <span class="operator">&gt;=</span>(<span class="built_in">MAX</span>(字段))，字段是表的节选字段</span><br><span class="line"># <span class="operator">&gt;=</span> <span class="keyword">ALL</span>(字段) 等价于 <span class="operator">=</span>(<span class="built_in">MAX</span>(字段))，字段是表的全部字段</span><br><span class="line"></span><br><span class="line"># <span class="operator">&lt;=</span> <span class="keyword">ANY</span>(字段) 等价于 <span class="operator">&lt;=</span>(<span class="built_in">MAX</span>(字段))</span><br><span class="line"># <span class="operator">&gt;=</span> <span class="keyword">ANY</span>(字段) 等价于 <span class="operator">&gt;=</span>(<span class="built_in">MIN</span>(字段))</span><br></pre></td></tr></table></figure>

<h3 id="3-2-空值问题"><a href="#3-2-空值问题" class="headerlink" title="3.2 空值问题"></a>3.2 空值问题</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="keyword">NOT</span> <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">#     <span class="keyword">WHERE</span> manager_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> 内查询有空值</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<h2 id="4-相关子查询"><a href="#4-相关子查询" class="headerlink" title="4. 相关子查询"></a>4. 相关子查询</h2><p>如果子查询的执行依赖于外部查询，通常情况下都是因为子查询中的表用到了外部的表，并进行了条件关联，因此每执行一次外部查询，子查询都要重新计算一次，这样的子查询就称之为 关联子查询 。</p>
<h3 id="4-1-例子"><a href="#4-1-例子" class="headerlink" title="4.1 例子"></a>4.1 例子</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 回顾：查询员工中工资大于公司平均工资的员工的last_name,salary和其department_id</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-58-23.png" alt="Snipaste_2023-07-12_22-58-23" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 题目：查询员工中工资大于本部门平均工资的员工的last_name和其department_id</span><br><span class="line"># 方式<span class="number">1</span>：使用相关子查询</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e1</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees e2</span><br><span class="line">    <span class="keyword">WHERE</span> department_id <span class="operator">=</span> e1.department_id</span><br><span class="line">    );</span><br><span class="line"># 方式<span class="number">2</span>：在<span class="keyword">FROM</span>中使用子查询</span><br><span class="line"># 先查询各个部门的平均工资</span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id;# Q1</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> e.last_name,e.salary,e.department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary) &quot;avg_sal&quot;</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    ) t_dept_avg_sal</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> t_dept_avg_sal.department_id</span><br><span class="line"><span class="keyword">WHERE</span> e.salary <span class="operator">&gt;</span> t_dept_avg_sal.avg_sal;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-59-12.png" alt="Snipaste_2023-07-12_22-59-12" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 题目：查询员工的id,salary,按照department_name排序</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,salary</span><br><span class="line"><span class="keyword">FROM</span> employees e</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_name</span><br><span class="line">    <span class="keyword">FROM</span> departments d</span><br><span class="line">    <span class="keyword">WHERE</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line">             );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_22-59-48.png" alt="Snipaste_2023-07-12_22-59-48" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 题目：若employees表中employee_id与job_history表中employee_id</span><br><span class="line"># 相同的数目不小于<span class="number">2</span>，输出这些相同id的员工的employee_id,last_name和其job_id</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,job_id</span><br><span class="line"><span class="keyword">FROM</span> employees e</span><br><span class="line"><span class="keyword">WHERE</span> <span class="number">2</span> <span class="operator">&lt;=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line">    <span class="keyword">FROM</span> job_history j</span><br><span class="line">    <span class="keyword">WHERE</span> e.employee_id <span class="operator">=</span> j.employee_id</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-01-04.png" alt="Snipaste_2023-07-12_23-01-04" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 结论：在查询结构中，除了<span class="keyword">GROUP</span> <span class="keyword">BY</span>和LIMIT之外，其他位置都可以声明子查询</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> SELECT .........(存在聚合函数)</span></span><br><span class="line"><span class="comment"> FROM...(LEFT/RIGHT)JOIN...ON 多表的连接条件</span></span><br><span class="line"><span class="comment"> [(LEFT/RIGHT)JOIN...ON ]</span></span><br><span class="line"><span class="comment"> WHERE 不包含聚合函数的过滤条件</span></span><br><span class="line"><span class="comment"> GROUP BY......</span></span><br><span class="line"><span class="comment"> HAVING 包含聚合函数的过滤条件</span></span><br><span class="line"><span class="comment"> ORDER BY.....(ASC/DESC)</span></span><br><span class="line"><span class="comment"> LIMIT.......;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<h3 id="4-2-EXISTS-与-NOT-EXISTS关键字"><a href="#4-2-EXISTS-与-NOT-EXISTS关键字" class="headerlink" title="4.2 EXISTS 与 NOT EXISTS关键字"></a>4.2 <strong>EXISTS</strong> <strong>与</strong> <strong>NOT EXISTS</strong>关键字</h3><p>关联子查询通常也会和 EXISTS操作符一起来使用，用来检查在子查询中是否存在满足条件的行。</p>
<p><strong>如果在子查询中不存在满足条件的行：</strong></p>
<ul>
<li>条件返回 FALSE</li>
<li>继续在子查询中查找</li>
</ul>
<p><strong>如果在子查询中存在满足条件的行：</strong></p>
<ul>
<li>不在子查询中继续查找</li>
<li>条件返回 TRUE</li>
</ul>
<p>NOT EXISTS关键字表示如果不存在某种条件，则返回TRUE，否则返回FALSE。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 题目：查询公司管理者的employee_id,last_name,job_id,department_id信息</span><br><span class="line"># 方式<span class="number">1</span>：自连接</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> mgr.employee_id,mgr.last_name,mgr.job_id,mgr.department_id</span><br><span class="line"><span class="keyword">FROM</span> employees emp <span class="keyword">JOIN</span> employees mgr</span><br><span class="line"><span class="keyword">ON</span> emp.manager_id <span class="operator">=</span> mgr.employee_id;</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：子查询，更易懂</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,job_id,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">3</span>：使用EXIST</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,job_id,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e1</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">EXISTS</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line">    <span class="keyword">FROM</span> employees e2</span><br><span class="line">    <span class="keyword">WHERE</span> e1.employee_id <span class="operator">=</span> e2.manager_id</span><br><span class="line">          );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-07-12.png" alt="Snipaste_2023-07-12_23-07-12" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 题目：查询departments表中，不存在于employees表中的部门的department_id和department_name</span><br><span class="line"># 方式<span class="number">1</span>：</span><br><span class="line"><span class="keyword">SELECT</span> d.department_id,d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> e.department_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;# 不存在于employees表</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：</span><br><span class="line"><span class="keyword">SELECT</span> department_id,department_name</span><br><span class="line"><span class="keyword">FROM</span> departments d</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line">    <span class="keyword">FROM</span> employees e</span><br><span class="line">    <span class="keyword">WHERE</span> d.department_id <span class="operator">=</span> e.department_id</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-11-54.png" alt="Snipaste_2023-07-12_23-11-54" style="zoom:50%;">

<h1 id="第九章-创建和管理表"><a href="#第九章-创建和管理表" class="headerlink" title="第九章 创建和管理表"></a>第九章 创建和管理表</h1><h2 id="1-创建和管理数据库"><a href="#1-创建和管理数据库" class="headerlink" title="1. 创建和管理数据库"></a>1. 创建和管理数据库</h2><h3 id="1-1-如何创建数据库"><a href="#1-1-如何创建数据库" class="headerlink" title="1.1 如何创建数据库"></a>1.1 如何创建数据库</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">1</span></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE mytest1; # 创建的此数据库使用的是默认的字符集</span><br><span class="line"># 查看创建数据库的结构</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> DATABASE mytest1;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">2</span>：显式了指明了要创建的数据库的字符集</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE mytest2 <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;gbk&#x27;</span>;</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> DATABASE mytest2;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">3</span>(推荐)：如果要创建的数据库已经存在，则创建不成功，但不会报错</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> mytest2 <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;gbk&#x27;</span>;</span><br><span class="line"># 如果要创建的数据库不存在，则创建成功</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> mytest3 <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="1-2-管理数据库"><a href="#1-2-管理数据库" class="headerlink" title="1.2 管理数据库"></a>1.2 管理数据库</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 查看当前连接中的数据库都有哪些</span><br><span class="line"><span class="keyword">SHOW</span> DATABASES ;</span><br><span class="line"># 切换数据库</span><br><span class="line">USE mytest2;</span><br><span class="line"># 查看当前数据库中保存的数据表</span><br><span class="line"><span class="keyword">SHOW</span> TABLES ;</span><br><span class="line"># 查看当前使用的数据库</span><br><span class="line"><span class="keyword">SELECT</span> DATABASE() <span class="keyword">FROM</span> dual;</span><br><span class="line"># 查看指定数据库下保存的数据表</span><br><span class="line"><span class="keyword">SHOW</span> TABLES <span class="keyword">FROM</span> mysql;</span><br></pre></td></tr></table></figure>

<h3 id="1-3-修改数据库（一般不会改）"><a href="#1-3-修改数据库（一般不会改）" class="headerlink" title="1.3 修改数据库（一般不会改）"></a>1.3 修改数据库（一般不会改）</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 更改数据库字符集</span><br><span class="line"><span class="keyword">ALTER</span> DATABASE mytest2 <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="1-4-删除数据库（一般不会删）"><a href="#1-4-删除数据库（一般不会删）" class="headerlink" title="1.4 删除数据库（一般不会删）"></a>1.4 删除数据库（一般不会删）</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">1</span>：</span><br><span class="line"><span class="keyword">DROP</span> DATABASE mytest1;</span><br><span class="line"># 方式<span class="number">2</span>：（推荐）。如果要删除的数据库存在，则删除成功。如果不存在，则默默结束，不会报错</span><br><span class="line"><span class="keyword">DROP</span> DATABASE IF <span class="keyword">EXISTS</span> mytest1;</span><br></pre></td></tr></table></figure>

<h2 id="2-如何创建数据表"><a href="#2-如何创建数据表" class="headerlink" title="2.如何创建数据表"></a>2.如何创建数据表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">1</span>：“白手起家”方式</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> myemp1(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    emp_name <span class="type">VARCHAR</span>(<span class="number">15</span>),# 使用<span class="type">VARCHAR</span>来定义字符串，必须在使用<span class="type">VARCHAR</span>时指明其长度</span><br><span class="line">    hire_date <span class="type">DATE</span></span><br><span class="line">);</span><br><span class="line"># 查看表结构</span><br><span class="line"><span class="keyword">DESC</span> myemp1;</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：基于现有的表，同时导入数据</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> myemp2</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> myemp2;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 说明<span class="number">1</span>：查询语句中字段的别名，可以作为新创建的表的字段的名称</span><br><span class="line"># 说明<span class="number">2</span>：此时查询语句可以比较丰富</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> myemp3</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id emp_id,e.last_name lname,d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 练习<span class="number">1</span>：创建一个表employee_copy,实现对employee表的复制，包括表数据</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employee_copy</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br><span class="line"># 练习<span class="number">2</span>：创建一个表employee_blank,实现对employee表的复制，不包括表数据</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employee_blank</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> <span class="number">1</span> <span class="operator">=</span> <span class="number">2</span>; # 空表</span><br></pre></td></tr></table></figure>

<h2 id="3-修改表（ALTER-TABLE）"><a href="#3-修改表（ALTER-TABLE）" class="headerlink" title="3. 修改表（ALTER   TABLE）"></a>3. 修改表（ALTER   TABLE）</h2><h3 id="3-1-添加一个字段（列）"><a href="#3-1-添加一个字段（列）" class="headerlink" title="3.1 添加一个字段（列）"></a>3.1 添加一个字段（列）</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> myemp1</span><br><span class="line"><span class="keyword">ADD</span> salary <span class="keyword">DOUBLE</span>(<span class="number">10</span>,<span class="number">2</span>); # 默认添加到表中的最后一个字段的位置</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> myemp1</span><br><span class="line"><span class="keyword">ADD</span> phone_number <span class="type">VARCHAR</span>(<span class="number">20</span>) <span class="keyword">FIRST</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> myemp1</span><br><span class="line"><span class="keyword">ADD</span> email <span class="type">VARCHAR</span>(<span class="number">45</span>) AFTER emp_name;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-修改一个字段（列）：数据类型、长度、默认值（略）"><a href="#3-2-修改一个字段（列）：数据类型、长度、默认值（略）" class="headerlink" title="3.2 修改一个字段（列）：数据类型、长度、默认值（略）"></a>3.2 修改一个字段（列）：数据类型、长度、默认值（略）</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> myemp1</span><br><span class="line">MODIFY emp_name <span class="type">VARCHAR</span>(<span class="number">25</span>);</span><br></pre></td></tr></table></figure>

<h3 id="3-3-重命名一个字段-列"><a href="#3-3-重命名一个字段-列" class="headerlink" title="3.3 重命名一个字段(列)"></a>3.3 重命名一个字段(列)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> myemp1</span><br><span class="line">CHANGE salary monthly_salary <span class="keyword">DOUBLE</span>(<span class="number">10</span>,<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> myemp1</span><br><span class="line">CHANGE email my_email <span class="type">VARCHAR</span>(<span class="number">50</span>);</span><br></pre></td></tr></table></figure>

<h3 id="3-4-删除一个字段-列"><a href="#3-4-删除一个字段-列" class="headerlink" title="3.4 删除一个字段(列)"></a>3.4 删除一个字段(列)</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> myemp1</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">COLUMN</span> my_email;</span><br></pre></td></tr></table></figure>

<h2 id="4-重命名表"><a href="#4-重命名表" class="headerlink" title="4.重命名表"></a>4.重命名表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RENAME <span class="keyword">TABLE</span> myemp1</span><br><span class="line"><span class="keyword">TO</span> myemp11;</span><br><span class="line"><span class="keyword">DESC</span> myemp11;</span><br></pre></td></tr></table></figure>

<h2 id="5-删除表-不能回滚"><a href="#5-删除表-不能回滚" class="headerlink" title="5.删除表(不能回滚)"></a>5.删除表(不能回滚)</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 同时删除表结构和表中数据，且释放表空间</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> IF <span class="keyword">EXISTS</span> myemp2;</span><br></pre></td></tr></table></figure>

<h2 id="6-清空表"><a href="#6-清空表" class="headerlink" title="6. 清空表"></a>6. 清空表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 只删除表中数据，但是表结构保留</span><br><span class="line"><span class="keyword">TRUNCATE</span> <span class="keyword">TABLE</span> employee_copy;</span><br></pre></td></tr></table></figure>

<h2 id="7-DCL中COMMIT和ROLLBACK"><a href="#7-DCL中COMMIT和ROLLBACK" class="headerlink" title="7.DCL中COMMIT和ROLLBACK"></a>7.DCL中COMMIT和ROLLBACK</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">COMMIT</span>：提交数据。一旦执行<span class="keyword">COMMIT</span>，则数据就被永久的保存在了数据库中，意味着数据不可以回滚</span><br><span class="line"># <span class="keyword">ROLLBACK</span>：回滚数据，一旦执行<span class="keyword">ROLLBACK</span>，则可以实现数据的回滚，回滚到最近的一次<span class="keyword">COMMIT</span>之后</span><br></pre></td></tr></table></figure>

<h2 id="8-对比TRUNCATE-TABLE和DELETE-FROM"><a href="#8-对比TRUNCATE-TABLE和DELETE-FROM" class="headerlink" title="8.对比TRUNCATE TABLE和DELETE FROM"></a>8.对比TRUNCATE TABLE和DELETE FROM</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 相同点：都可以实现对表中所有数据的删除，同时保留表结构</span><br><span class="line"># 不同点：</span><br><span class="line">#      <span class="keyword">TRUNCATE</span> <span class="keyword">TABLE</span>：一旦执行此操作，表数据全部清除，同时，数据是不可以回滚的</span><br><span class="line">#      <span class="keyword">DELETE</span> <span class="keyword">FROM</span>：一旦执行此操作，表数据可以全部清除（不带<span class="keyword">WHERE</span>）。同时，数据是可以实现回滚的</span><br></pre></td></tr></table></figure>

<h2 id="9-DDL和DML的说明"><a href="#9-DDL和DML的说明" class="headerlink" title="9.DDL和DML的说明"></a>9.DDL和DML的说明</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">DDL： CREATE 、 DROP 、 ALTER</span></span><br><span class="line"><span class="comment">DML：INSERT 、 DELETE 、 UPDATE 、 SELECT</span></span><br><span class="line"><span class="comment">①DDL的操作一旦执行，就不可回滚，指令SET autocommit = FALSE对DDL操作是失效</span></span><br><span class="line"><span class="comment">②DML的操作默认情况下，一旦执行也是不可回滚的。但是如果在执行DML之前执行了，</span></span><br><span class="line"><span class="comment">SET autocommit = FALSE，则执行的DML操作就可以实现回滚</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> myemp4</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id emp_id,e.last_name lname,d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> myemp4;</span><br><span class="line"><span class="keyword">SET</span> autocommit <span class="operator">=</span> <span class="literal">FALSE</span>;</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> myemp4;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> myemp4;</span><br><span class="line"><span class="keyword">ROLLBACK</span>;# 回滚操作</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> myemp4;</span><br></pre></td></tr></table></figure>

<h2 id="10-测试MySQL8-0的新特性：DDL的原子化"><a href="#10-测试MySQL8-0的新特性：DDL的原子化" class="headerlink" title="10.测试MySQL8.0的新特性：DDL的原子化"></a>10.测试MySQL8.0的新特性：DDL的原子化</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE mytest;</span><br><span class="line"></span><br><span class="line">USE mytest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> book1(</span><br><span class="line">    book_id <span class="type">INT</span>,</span><br><span class="line">    book_name <span class="type">VARCHAR</span>(<span class="number">255</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> TABLES ;</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> book1,book2; # 原子性：该事务依次删除book1和book2，由于没有book2系统报错，操作回滚，结果是book1没有被删</span><br></pre></td></tr></table></figure>

<h1 id="第十章-数据处理之增删改"><a href="#第十章-数据处理之增删改" class="headerlink" title="第十章 数据处理之增删改"></a>第十章 数据处理之增删改</h1><h2 id="1-插入数据"><a href="#1-插入数据" class="headerlink" title="1. 插入数据"></a>1. 插入数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">0.</span>创建表emp1</span><br><span class="line">USE atguigudb;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> emp1(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    hire_date <span class="type">DATE</span>,</span><br><span class="line">    salary <span class="keyword">DOUBLE</span>(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_17-09-13.png" alt="Snipaste_2023-07-18_17-09-13" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">1</span>：一条一条添加数据</span><br><span class="line"># ① 没有指明添加的字段，必须按照声明的字段顺序依次添加</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp1</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="string">&#x27;2000-12-21&#x27;</span>,<span class="number">3400</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_17-13-37.png" alt="Snipaste_2023-07-18_17-13-37" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># ② 指明要添加的字段，此时添加顺序按照指明的来(推荐)</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp1(id,hire_date,salary,name)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">&#x27;1999-09-09&#x27;</span>,<span class="number">4000</span>,<span class="string">&#x27;Jerry&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_17-20-18.png" alt="Snipaste_2023-07-18_17-20-18" style="zoom: 50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 说明：没有进行赋值的hire_date的值为<span class="keyword">null</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp1(id,salary,name)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">3</span>,<span class="number">4500</span>,<span class="string">&#x27;shk&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_17-21-58.png" alt="Snipaste_2023-07-18_17-21-58" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># ③ 同时插入多条记录</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp1(id,name,salary)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">4</span>,<span class="string">&#x27;Jim&#x27;</span>,<span class="number">5000</span>),(<span class="number">5</span>,<span class="string">&#x27;马云&#x27;</span>,<span class="number">5500</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_18-05-36.png" alt="Snipaste_2023-07-18_18-05-36" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">2</span>：将查询结果插入到表中</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp1(id,name,salary,hire_date)</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary,hire_date # 查询的字段一定要与添加到表的字段一一对应</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (<span class="number">60</span>,<span class="number">70</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br><span class="line"></span><br><span class="line"># 说明：emp1表中要添加数据的字段的长度不能低于employees表中查询的字段的长度。</span><br><span class="line"># 如果低于，就有添加不成功的风险</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_18-32-18.png" alt="Snipaste_2023-07-18_18-32-18" style="zoom:50%;">

<h2 id="2-更新数据（或修改数据）"><a href="#2-更新数据（或修改数据）" class="headerlink" title="2.更新数据（或修改数据）"></a>2.更新数据（或修改数据）</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span>更新数据（或修改数据）</span><br><span class="line"># UPDATE.....SET....WHERE...</span><br><span class="line"># 可以实现批量的数据修改</span><br><span class="line"><span class="keyword">UPDATE</span> emp1</span><br><span class="line"><span class="keyword">SET</span> hire_date <span class="operator">=</span> CURDATE()</span><br><span class="line"><span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_19-07-58.png" alt="Snipaste_2023-07-18_19-07-58" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 同时修改一条数据的多个字段</span><br><span class="line"><span class="keyword">UPDATE</span> emp1</span><br><span class="line"><span class="keyword">SET</span> hire_date <span class="operator">=</span> CURDATE(),salary <span class="operator">=</span> <span class="number">6000</span></span><br><span class="line"><span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_22-04-19.png" alt="Snipaste_2023-07-18_22-04-19" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 题目：将表中姓名中包含字符a的提薪<span class="number">20</span><span class="operator">%</span></span><br><span class="line"><span class="keyword">UPDATE</span> emp1</span><br><span class="line"><span class="keyword">SET</span> salary <span class="operator">=</span> salary<span class="operator">*</span>(<span class="number">1</span><span class="operator">+</span><span class="number">0.2</span>)</span><br><span class="line"><span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;%a%&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_22-26-10.png" alt="Snipaste_2023-07-18_22-26-10" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 修改数据时，是可能存在不成功的情况的（可能是由于约束的影响造成的）</span><br></pre></td></tr></table></figure>

<h2 id="3-删除数据"><a href="#3-删除数据" class="headerlink" title="3. 删除数据"></a>3. 删除数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">DELETE</span> FROM...WHERE...</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> emp1</span><br><span class="line"><span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_22-35-01.png" alt="Snipaste_2023-07-18_22-35-01" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 在删除数据时，也有可能因为约束的影响导致删除失败</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 小结：DML操作默认情况下，执行完以后都会自动提交数据</span><br><span class="line"># 如果希望执行完以后不自动提交数据，则需要使用<span class="keyword">SET</span> autocommit <span class="operator">=</span> <span class="literal">FALSE</span></span><br></pre></td></tr></table></figure>

<h2 id="4-MySQL8新特性：计算列"><a href="#4-MySQL8新特性：计算列" class="headerlink" title="4. MySQL8新特性：计算列"></a>4. MySQL8新特性：计算列</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 计算列：简单来说就是某一列的值是通过别的列计算得来的</span><br><span class="line"># 在MySQL <span class="number">8.0</span>中，<span class="keyword">CREATE</span> <span class="keyword">TABLE</span> 和 <span class="keyword">ALTER</span> <span class="keyword">TABLE</span> 中都支持增加计算列</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">USE atguigudb;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test1(</span><br><span class="line">    a <span class="type">INT</span>,</span><br><span class="line">    b <span class="type">INT</span>,</span><br><span class="line">    c <span class="type">INT</span> GENERATED ALWAYS <span class="keyword">AS</span> (a<span class="operator">+</span>b) VIRTUAL # c即为计算列</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test1(a,b)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">10</span>,<span class="number">20</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_22-51-04.png" alt="Snipaste_2023-07-18_22-51-04" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> test1</span><br><span class="line"><span class="keyword">SET</span> a <span class="operator">=</span> <span class="number">100</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-18_22-52-07.png" alt="Snipaste_2023-07-18_22-52-07" style="zoom:50%;">

<h2 id="5-综合案例"><a href="#5-综合案例" class="headerlink" title="5. 综合案例"></a>5. 综合案例</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1</span>、创建数据库test01_library</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test01_library <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span>;</span><br><span class="line">USE test01_library;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2</span>、创建表 books，表结构如下：</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">字段名      字段说明      数据类型</span></span><br><span class="line"><span class="comment">id          书编号        INT</span></span><br><span class="line"><span class="comment">name         书名     VARCHAR(50)</span></span><br><span class="line"><span class="comment">authors      作者     VARCHAR(100)</span></span><br><span class="line"><span class="comment">price        价格        FLOAT</span></span><br><span class="line"><span class="comment">pubdate     出版日期      YEAR</span></span><br><span class="line"><span class="comment">note         说明     VARCHAR(100)</span></span><br><span class="line"><span class="comment">num          库存         INT</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> books(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    authors <span class="type">VARCHAR</span>(<span class="number">100</span>),</span><br><span class="line">    price <span class="type">FLOAT</span>,</span><br><span class="line">    pubdate <span class="keyword">YEAR</span>,</span><br><span class="line">    note <span class="type">VARCHAR</span>(<span class="number">100</span>),</span><br><span class="line">    num <span class="type">INT</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-14-11.png" alt="Snipaste_2023-07-19_11-14-11" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">id  name             authors       price  pubdate   note    num</span></span><br><span class="line"><span class="comment">1   Tal of AAA        Dickes        23     1995     novel    11</span></span><br><span class="line"><span class="comment">2   EmmaT           Jane lura       35     1993     joke     22</span></span><br><span class="line"><span class="comment">3   Story of Jane    Jane Tim       40     2001     novel     0</span></span><br><span class="line"><span class="comment">4   Lovey Day      George Byron     20     2005     novel    30</span></span><br><span class="line"><span class="comment">5   Old land       Honore Blade     30     2010     law       0</span></span><br><span class="line"><span class="comment">6   The Battle      Upton Sara      30     1999     medicine 40</span></span><br><span class="line"><span class="comment">7   Rose Hood    Richard haggard    28     2008     cartoon  28</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> </span><br><span class="line"># <span class="number">3</span>、向books表中插入记录</span><br><span class="line"># <span class="number">1</span>）不指定字段名称，插入第一条记录</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> books</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;Tal of AAA&#x27;</span>,<span class="string">&#x27;Dickes&#x27;</span>,<span class="number">23</span>,<span class="string">&#x27;1995&#x27;</span>,<span class="string">&#x27;novel&#x27;</span>,<span class="number">11</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-31-10.png" alt="Snipaste_2023-07-19_11-31-10" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2</span>）指定所有字段名称，插入第二记录</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> books(id,name,authors,price,pubdate,note,num)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">&#x27;EmmaT&#x27;</span>,<span class="string">&#x27;Jane lura&#x27;</span>,<span class="number">35</span>,<span class="string">&#x27;1993&#x27;</span>,<span class="string">&#x27;joke&#x27;</span>,<span class="number">22</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-34-27.png" alt="Snipaste_2023-07-19_11-34-27" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3</span>）同时插入多条记录（剩下的所有记录）</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> books(id,name,authors,price,pubdate,note,num)</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">3</span>,<span class="string">&#x27;Story of Jane&#x27;</span>,<span class="string">&#x27;Jane Tim&#x27;</span>,<span class="number">40</span>,<span class="number">2001</span>,<span class="string">&#x27;novel&#x27;</span>,<span class="number">0</span>),</span><br><span class="line">(<span class="number">4</span>,<span class="string">&#x27;Lovey Day&#x27;</span>,<span class="string">&#x27;George Byron&#x27;</span>,<span class="number">20</span>,<span class="number">2005</span>,<span class="string">&#x27;novel&#x27;</span>,<span class="number">30</span>),</span><br><span class="line">(<span class="number">5</span>,<span class="string">&#x27;Old land&#x27;</span>,<span class="string">&#x27;Honore Blade&#x27;</span>,<span class="number">30</span>,<span class="number">2010</span>,<span class="string">&#x27;Law&#x27;</span>,<span class="number">0</span>),</span><br><span class="line">(<span class="number">6</span>,<span class="string">&#x27;The Battle&#x27;</span>,<span class="string">&#x27;Upton Sara&#x27;</span>,<span class="number">30</span>,<span class="number">1999</span>,<span class="string">&#x27;medicine&#x27;</span>,<span class="number">40</span>),</span><br><span class="line">(<span class="number">7</span>,<span class="string">&#x27;Rose Hood&#x27;</span>,<span class="string">&#x27;Richard haggard&#x27;</span>,<span class="number">28</span>,<span class="number">2008</span>,<span class="string">&#x27;cartoon&#x27;</span>,<span class="number">28</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-37-06.png" alt="Snipaste_2023-07-19_11-37-06" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4</span>、将小说类型(novel)的书的价格都增加<span class="number">5</span>。</span><br><span class="line"><span class="keyword">UPDATE</span> books</span><br><span class="line"><span class="keyword">SET</span> price <span class="operator">=</span> price <span class="operator">+</span> <span class="number">5</span></span><br><span class="line"><span class="keyword">WHERE</span> note <span class="operator">=</span> <span class="string">&#x27;novel&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-39-21.png" alt="Snipaste_2023-07-19_11-39-21" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5</span>、将名称为EmmaT的书的价格改为<span class="number">40</span>，并将说明改为drama。</span><br><span class="line"><span class="keyword">UPDATE</span> books</span><br><span class="line"><span class="keyword">SET</span> price <span class="operator">=</span> <span class="number">40</span>, note <span class="operator">=</span> <span class="string">&#x27;drama&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> name <span class="operator">=</span> <span class="string">&#x27;EmmaT&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-51-11.png" alt="Snipaste_2023-07-19_11-51-11" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6</span>、删除库存为<span class="number">0</span>的记录。（为保证下述操作数据的完备性，这里的删除操作不执行）</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">WHERE</span> num <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> books;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">7</span>、统计书名中包含a字母的书</span><br><span class="line"><span class="keyword">SELECT</span> name</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;%a%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-56-20.png" alt="Snipaste_2023-07-19_11-56-20" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">8</span>、统计书名中包含a字母的书的数量和库存总量</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>), <span class="built_in">SUM</span>(num)</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;%a%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-58-03.png" alt="Snipaste_2023-07-19_11-58-03" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">9</span>、找出“novel”类型的书，按照价格降序排列</span><br><span class="line"><span class="keyword">SELECT</span> name,note,price</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">WHERE</span> note <span class="operator">=</span> <span class="string">&#x27;novel&#x27;</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> price <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_11-59-56.png" alt="Snipaste_2023-07-19_11-59-56" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">10</span>、查询图书信息，按照库存量降序排列，如果库存量相同的按照note升序排列</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> num <span class="keyword">DESC</span> ,note <span class="keyword">ASC</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_12-01-38.png" alt="Snipaste_2023-07-19_12-01-38" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">11</span>、按照note分类统计书的数量</span><br><span class="line"><span class="keyword">SELECT</span> note,<span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> note;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_12-17-27.png" alt="Snipaste_2023-07-19_12-17-27" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">12</span>、按照note分类统计书的库存量，显示库存量超过<span class="number">30</span>本的</span><br><span class="line"><span class="keyword">SELECT</span> note,<span class="built_in">SUM</span>(num)</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> note</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">SUM</span>(num) <span class="operator">&gt;</span> <span class="number">30</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_17-16-32.png" alt="Snipaste_2023-07-19_17-16-32" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">13</span>、查询所有图书，每页显示<span class="number">5</span>本，显示第二页</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line">LIMIT <span class="number">5</span>,<span class="number">5</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_17-49-29.png" alt="Snipaste_2023-07-19_17-49-29" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">14</span>、按照note分类统计书的库存量，显示库存量最多的</span><br><span class="line"><span class="keyword">SELECT</span> note,<span class="built_in">SUM</span>(num) sum_num</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> note</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> sum_num <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-19-15.png" alt="Snipaste_2023-07-19_18-19-15" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">15</span>、查询书名达到<span class="number">10</span>个字符的书，不包括里面的空格</span><br><span class="line"><span class="keyword">SELECT</span> name</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">CHAR_LENGTH</span>(REPLACE(name,<span class="string">&#x27; &#x27;</span>,<span class="string">&#x27;&#x27;</span>)) <span class="operator">&gt;=</span> <span class="number">10</span>;# Story <span class="keyword">of</span> Jane</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">16</span>、查询书名和类型，其中note值为novel显示小说，law显示法律，medicine显示医药，cartoon显示卡通，</span><br><span class="line"># joke显示笑话</span><br><span class="line"><span class="keyword">SELECT</span> name &quot;书名&quot;,<span class="keyword">CASE</span> note  <span class="keyword">WHEN</span> <span class="string">&#x27;novel&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;小说&#x27;</span></span><br><span class="line">                                  <span class="keyword">WHEN</span> <span class="string">&#x27;law&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;法律&#x27;</span></span><br><span class="line">                                  <span class="keyword">WHEN</span> <span class="string">&#x27;medicine&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;医药&#x27;</span></span><br><span class="line">                                  <span class="keyword">WHEN</span> <span class="string">&#x27;cartoon&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;卡通&#x27;</span></span><br><span class="line">                                  <span class="keyword">WHEN</span> <span class="string">&#x27;joke&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;笑话&#x27;</span></span><br><span class="line">                                  <span class="keyword">ELSE</span> <span class="string">&#x27;其他&#x27;</span></span><br><span class="line">                                  <span class="keyword">END</span> &quot;类型&quot;</span><br><span class="line"><span class="keyword">FROM</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-20-20.png" alt="Snipaste_2023-07-19_18-20-20" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">17</span>、查询书名、库存，其中num值超过<span class="number">30</span>本的，显示滞销，大于<span class="number">0</span>并低于<span class="number">10</span>的，显示畅销，为<span class="number">0</span>的显示需要无货</span><br><span class="line"><span class="keyword">SELECT</span> name &quot;书名&quot;,<span class="keyword">CASE</span> <span class="keyword">WHEN</span> num <span class="operator">&gt;</span> <span class="number">30</span> <span class="keyword">THEN</span> <span class="string">&#x27;滞销&#x27;</span></span><br><span class="line">                        <span class="keyword">WHEN</span> num <span class="operator">&gt;</span> <span class="number">0</span> <span class="keyword">AND</span> num <span class="operator">&lt;</span> <span class="number">10</span> <span class="keyword">THEN</span> <span class="string">&#x27;畅销&#x27;</span></span><br><span class="line">                        <span class="keyword">WHEN</span> num <span class="operator">=</span> <span class="number">0</span> <span class="keyword">THEN</span> <span class="string">&#x27;无货&#x27;</span></span><br><span class="line">                        <span class="keyword">ELSE</span> <span class="string">&#x27;正常&#x27;</span></span><br><span class="line">                        <span class="keyword">END</span> &quot;库存&quot;</span><br><span class="line"><span class="keyword">FROM</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-20-20.png" alt="Snipaste_2023-07-19_18-20-20" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">18</span>、统计每一种note的库存量，并合计总量</span><br><span class="line"><span class="keyword">SELECT</span> IFNULL(note,<span class="string">&#x27;合计库存总量&#x27;</span>) <span class="keyword">AS</span> note,<span class="built_in">SUM</span>(num)</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> note <span class="keyword">WITH</span> <span class="keyword">ROLLUP</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-21-13.png" alt="Snipaste_2023-07-19_18-21-13" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">19</span>、统计每一种note的数量，并合计总量</span><br><span class="line"><span class="keyword">SELECT</span> IFNULL(note,<span class="string">&#x27;合计总量&#x27;</span>) <span class="keyword">AS</span> note,<span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> note <span class="keyword">WITH</span> <span class="keyword">ROLLUP</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-21-41.png" alt="Snipaste_2023-07-19_18-21-41" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">20</span>、统计库存量前三名的图书</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> num <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">3</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-22-10.png" alt="Snipaste_2023-07-19_18-22-10" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">21</span>、找出最早出版的一本书</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> pubdate</span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-22-35.png" alt="Snipaste_2023-07-19_18-22-35" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">22</span>、找出novel中价格最高的一本书</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">WHERE</span> note <span class="operator">=</span> <span class="string">&#x27;novel&#x27;</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> price <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-23-18.png" alt="Snipaste_2023-07-19_18-23-18" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">23</span>、找出书名中字数最多的一本书，不含空格</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> books</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">CHAR_LENGTH</span>(REPLACE(name,<span class="string">&#x27; &#x27;</span>,<span class="string">&#x27;&#x27;</span>)) <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_18-23-44.png" alt="Snipaste_2023-07-19_18-23-44" style="zoom:33%;">

<h1 id="第十一章-MySQL数据类型精讲"><a href="#第十一章-MySQL数据类型精讲" class="headerlink" title="第十一章 MySQL数据类型精讲"></a>第十一章 MySQL数据类型精讲</h1><h2 id="1-MySQL中的数据类型"><a href="#1-MySQL中的数据类型" class="headerlink" title="1. MySQL中的数据类型"></a>1. MySQL中的数据类型</h2><p><img src="Snipaste_2023-07-20_10-53-14.png" alt="Snipaste_2023-07-20_10-53-14"></p>
<p>常见数据类型的属性，如下：</p>
<p><img src="Snipaste_2023-07-20_10-53-57.png" alt="Snipaste_2023-07-20_10-53-57"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">1.</span> 关于属性：</span><br><span class="line"># <span class="type">CHARACTER</span> <span class="keyword">SET</span> name</span><br><span class="line"># 创建数据库时指定字符集</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> dbtest12 <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> DATABASE dbtest12;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建表的时候，指明表的字符集</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> temp(</span><br><span class="line">    id <span class="type">INT</span></span><br><span class="line">) <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> temp;</span><br><span class="line"></span><br><span class="line"># 创建表、指明表中的字段时，可以指定字段的字符集</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> temp1(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> temp1;</span><br></pre></td></tr></table></figure>

<h2 id="2-整数类型"><a href="#2-整数类型" class="headerlink" title="2. 整数类型"></a>2. 整数类型</h2><h3 id="2-1-类型介绍"><a href="#2-1-类型介绍" class="headerlink" title="2.1 类型介绍"></a>2.1 类型介绍</h3><p>整数类型一共有 5 种，包括 TINYINT、SMALLINT、MEDIUMINT、INT（INTEGER）和 BIGINT。它们的区别如下表所示：</p>
<p><img src="Snipaste_2023-07-20_10-55-09.png" alt="Snipaste_2023-07-20_10-55-09"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span> 整形数据类型</span><br><span class="line">USE dbtest12;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_int1(</span><br><span class="line">    f1 TINYINT,</span><br><span class="line">    f2 <span class="type">SMALLINT</span>,</span><br><span class="line">    f3 MEDIUMINT,</span><br><span class="line">    f4 <span class="type">INT</span>,</span><br><span class="line">    f5 <span class="type">BIGINT</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> test_int1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_int1(f1)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">12</span>),(<span class="number">-12</span>),(<span class="number">-128</span>),(<span class="number">127</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_int1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_10-56-03.png" alt="Snipaste_2023-07-20_10-56-03" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#  Data truncation: <span class="keyword">Out</span> <span class="keyword">of</span> <span class="keyword">range</span> <span class="keyword">value</span> <span class="keyword">for</span> <span class="keyword">column</span> <span class="string">&#x27;f1&#x27;</span> <span class="keyword">at</span> <span class="type">row</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_int1(f1)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">128</span>);# 超出范围，插入失败</span><br></pre></td></tr></table></figure>

<h3 id="2-2-可选属性"><a href="#2-2-可选属性" class="headerlink" title="2.2 可选属性"></a>2.2 可选属性</h3><p><strong>整数类型的可选属性有三个：</strong></p>
<h4 id="2-2-1-M"><a href="#2-2-1-M" class="headerlink" title="2.2.1 M"></a>2.2.1 M</h4><p>M : 表示显示宽度，M的取值范围是(0, 255)。例如，int(5)：当数据宽度小于5位的时候在数字前面需要用字符填满宽度。该项功能需要配合“ ZEROFILL ”使用，表示用“0”填满宽度，否则指定显示宽度无效。</p>
<p>如果设置了显示宽度，那么插入的数据宽度超过显示宽度限制，会不会截断或插入失败？</p>
<p>答案：不会对插入的数据有任何影响，还是按照类型的实际宽度进行保存，即 显示宽度与类型可以存储的值范围无关 。<strong>从</strong>MySQL 8.0.17<strong>开始，整数数据类型不推荐使用显示宽度属性。</strong>整型数据类型可以在定义表结构时指定所需要的显示宽度，如果不指定，则系统为每一种类型指定默认的宽度值。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 在MySQL8中不推荐使用宽度属性</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_int2(</span><br><span class="line">f1 <span class="type">INT</span>,</span><br><span class="line">f2 <span class="type">INT</span>(<span class="number">5</span>),# 没有配合ZEROFILL，指定宽度无效</span><br><span class="line">f3 <span class="type">INT</span>(<span class="number">5</span>) ZEROFILL</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_int2(f1,f2,f3)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">123</span>,<span class="number">123</span>,<span class="number">123</span>),(<span class="number">123456</span>,<span class="number">123456</span>,<span class="number">123456</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_int2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_11-11-55.png" alt="Snipaste_2023-07-20_11-11-55" style="zoom:33%;">

<h4 id="2-2-2-UNSIGNED"><a href="#2-2-2-UNSIGNED" class="headerlink" title="2.2.2 UNSIGNED"></a>2.2.2 UNSIGNED</h4><p>UNSIGNED : 无符号类型（非负），所有的整数类型都有一个可选的属性UNSIGNED（无符号属性），无符号整数类型的最小取值为0。所以，如果需要在MySQL数据库中保存非负整数值时，可以将整数类型设置为无符号类型。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_int3(</span><br><span class="line">    f1 <span class="type">INT</span> UNSIGNED</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_int3</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">245666</span>);# 成功插入</span><br><span class="line"></span><br><span class="line"># Data truncation: <span class="keyword">Out</span> <span class="keyword">of</span> <span class="keyword">range</span> <span class="keyword">value</span> <span class="keyword">for</span> <span class="keyword">column</span> <span class="string">&#x27;f1&#x27;</span> <span class="keyword">at</span> <span class="type">row</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_int3</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">-78</span>);# 插入失败</span><br></pre></td></tr></table></figure>

<h4 id="2-2-3-ZEROFILL"><a href="#2-2-3-ZEROFILL" class="headerlink" title="2.2.3 ZEROFILL"></a>2.2.3 ZEROFILL</h4><p>ZEROFILL : 0填充,（如果某列是ZEROFILL，那么MySQL会自动为当前列添加UNSIGNED属性），如果指定了ZEROFILL只是表示不够M位时，用0在左边填充，如果超过M位，只要不超过数据存储范围即可。</p>
<h3 id="2-3-适用场景"><a href="#2-3-适用场景" class="headerlink" title="2.3 适用场景"></a>2.3 适用场景</h3><p>TINYINT ：一般用于<strong>枚举</strong>数据，比如系统设定取值范围很小且固定的场景。</p>
<p>SMALLINT ：可以用于较小范围的统计数据，比如统计工厂的固定资产库存数量等。</p>
<p>MEDIUMINT ：用于较大整数的计算，比如车站每日的客流量等。</p>
<p>INT、INTEGER ：取值范围足够大，一般情况下不用考虑超限问题，<strong>用得最多</strong>。比如商品编号。</p>
<p>BIGINT ：只有当你处理特别巨大的整数时才会用到。比如双十一的交易量、大型门户网站点击量、<strong>证券公司衍生产品持仓</strong>等。</p>
<h3 id="2-4-如何选择"><a href="#2-4-如何选择" class="headerlink" title="2.4 如何选择"></a>2.4 如何选择</h3><p>在评估用哪种整数类型的时候，你需要考虑 存储空间 和 可靠性 的平衡问题：一方 面，用占用字节数少的整数类型可以节省存储空间；另一方面，要是为了节省存储空间， 使用的整数类型取值范围太小，一旦遇到超出取值范围的情况，就可能引起 系统错误 ，影响可靠性。</p>
<p>举个例子，商品编号采用的数据类型是 INT。原因就在于，客户门店中流通的商品种类较多，而且，每天都有旧商品下架，新商品上架，这样不断迭代，日积月累。如果使用 SMALLINT 类型，虽然占用字节数比 INT 类型的整数少，但是却不能保证数据不会超出范围65535。相反，使用 INT，就能确保有足够大的取值范围，不用担心数据超出范围影响可靠性的问题。</p>
<p>你要注意的是，在实际工作中，<strong>系统故障产生的成本远远超过增加几个字段存储空间所产生的成本</strong>。因此，我建议你首先确保数据不会超过取值范围，在这个前提之下，再去考虑如何节省存储空间。</p>
<h2 id="3-浮点类型"><a href="#3-浮点类型" class="headerlink" title="3. 浮点类型"></a>3. 浮点类型</h2><h3 id="3-1-类型介绍"><a href="#3-1-类型介绍" class="headerlink" title="3.1 类型介绍"></a>3.1 类型介绍</h3><p>浮点数和定点数类型的特点是可以 处理小数 ，你可以把整数看成小数的一个特例。因此，浮点数和定点数的使用场景，比整数大多了。 MySQL支持的浮点数类型，分别是 FLOAT、DOUBLE、REAL。</p>
<ul>
<li>FLOAT 表示单精度浮点数；</li>
<li>DOUBLE 表示双精度浮点数；</li>
</ul>
<p><img src="Snipaste_2023-07-20_12-02-14.png" alt="Snipaste_2023-07-20_12-02-14"></p>
<p>FLOAT 占用字节数少，取值范围小；DOUBLE 占用字节数多，取值范围也大。</p>
<p>（以下内容了解即可）</p>
<ul>
<li><p>MySQL允许使用 非标准语法 （其他数据库未必支持，因此如果涉及到数据迁移，则最好不要这么用）： FLOAT(M,D) 或 DOUBLE(M,D) 。这里，M称为 精度 ，D称为 标度 。(M,D)中 M&#x3D;整数位+小数位，D&#x3D;小数位。 D&lt;&#x3D;M&lt;&#x3D;255，0&lt;&#x3D;D&lt;&#x3D;30。例如，定义为FLOAT(5,2)的一个列可以显示为-999.99-999.99。如果超过这个范围会报错。</p>
</li>
<li><p>不管是否显式设置了精度(M,D)，这里MySQL的处理方案如下：</p>
<p>如果存储时，整数部分超出了范围，MySQL就会报错，不允许存这样的值</p>
<p>如果存储时，小数点部分若超出范围，就分以下情况：</p>
<p>​           若四舍五入后，整数部分没有超出范围，则只警告，但能成功操作并四舍五入删除多余的小数位后保存。例如在FLOAT(5,2)列内插入999.009，近似结果是999.01。</p>
<p>​           若四舍五入后，整数部分超出范围，则MySQL报错，并拒绝处理。如FLOAT(5,2)列内插入</p>
<p>999.995和-999.995都会报错。</p>
</li>
<li><p><strong>从</strong>MySQL 8.0.17<strong>开始，</strong>FLOAT(M,D) <strong>和</strong>DOUBLE(M,D)<strong>用法在官方文档中已经明确不推荐使用</strong>，将来可能被移除。另外，关于浮点型FLOAT和DOUBLE的UNSIGNED也不推荐使用了，将来也可能被移除。</p>
</li>
</ul>
<h3 id="3-2-精度误差说明"><a href="#3-2-精度误差说明" class="headerlink" title="3.2 精度误差说明"></a>3.2 精度误差说明</h3><p>MySQL 用 4 个字节存储 FLOAT 类型数据，用 8 个字节来存储 DOUBLE 类型数据。无论哪个，都是采用二进制的方式来进行存储的。比如 9.625，用二进制来表达，就是 1001.101，或者表达成 1.001101×2^3。如果尾数不是 0 或 5（比如 9.624），你就无法用一个二进制数来精确表达。进而，就只好在取值允许的范围内进行四舍五入。</p>
<p>在编程中，如果用到浮点数，要特别注意误差问题，<strong>因为浮点数是不准确的，所以我们要避免使用</strong> <strong>“&#x3D;”</strong> <strong>来</strong> <strong>判断两个数是否相等。</strong>同时，在一些对精确度要求较高的项目中，千万不要使用浮点数，不然会导致结果错误，甚至是造成不可挽回的损失。那么，MySQL 有没有精准的数据类型呢？当然有，这就是定点数类型： <strong>DECIMAL</strong> 。</p>
<h2 id="4-定点数类型"><a href="#4-定点数类型" class="headerlink" title="4. 定点数类型"></a>4. 定点数类型</h2><h3 id="4-1-类型介绍"><a href="#4-1-类型介绍" class="headerlink" title="4.1 类型介绍"></a>4.1 类型介绍</h3><p><img src="Snipaste_2023-07-20_12-45-38.png" alt="Snipaste_2023-07-20_12-45-38"></p>
<p>（金融场景一定用DECIMAL类型）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_decimal1(</span><br><span class="line">f1 <span class="type">DECIMAL</span>,</span><br><span class="line">f2 <span class="type">DECIMAL</span>(<span class="number">5</span>,<span class="number">2</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">DESC</span> test_decimal1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_12-49-31.png" alt="Snipaste_2023-07-20_12-49-31" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_decimal1(f1,f2)</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="number">123.123</span>,<span class="number">123.456</span>); # 存在四舍五入</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_decimal1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_12-52-16.png" alt="Snipaste_2023-07-20_12-52-16" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#<span class="keyword">Out</span> <span class="keyword">of</span> <span class="keyword">range</span> <span class="keyword">value</span> <span class="keyword">for</span> <span class="keyword">column</span> <span class="string">&#x27;f2&#x27;</span> <span class="keyword">at</span> <span class="type">row</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_decimal1(f2)</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="number">1234.34</span>);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># <span class="type">DECIMAL</span>精度检验</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test_double2</span><br><span class="line">MODIFY f1 <span class="type">DECIMAL</span>(<span class="number">5</span>,<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_double2</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">0.47</span>),(<span class="number">0.44</span>),(<span class="number">0.19</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_double2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">SUM</span>(f1)</span><br><span class="line"><span class="keyword">FROM</span> test_double2;# <span class="number">2.20</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_12-56-18.png" alt="Snipaste_2023-07-20_12-56-18" style="zoom:33%;">

<h3 id="4-2-开发中经验"><a href="#4-2-开发中经验" class="headerlink" title="4.2 开发中经验"></a>4.2 开发中经验</h3><p>由于 DECIMAL 数据类型的精准性，在我们的项目中，除了极少数（比如商品编号）用到整数类型外，其他的数值都用的是 DECIMAL，原因就是这个项目所处的零售行业，要求精准，一分钱也不能差。</p>
<h2 id="5-位类型（用的少）"><a href="#5-位类型（用的少）" class="headerlink" title="5. 位类型（用的少）"></a>5. 位类型（用的少）</h2><p><img src="Snipaste_2023-07-20_21-29-49.png" alt="Snipaste_2023-07-20_21-29-49"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_bit1(</span><br><span class="line">f1 BIT,</span><br><span class="line">f2 BIT(<span class="number">5</span>),</span><br><span class="line">f3 BIT(<span class="number">64</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_bit1(f1)</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="number">1</span>);</span><br><span class="line">#Data too long <span class="keyword">for</span> <span class="keyword">column</span> <span class="string">&#x27;f1&#x27;</span> <span class="keyword">at</span> <span class="type">row</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_bit1(f1)</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="number">2</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_bit1(f2)</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="number">23</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_bit1(f1,f2,f3)</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="number">0</span>,<span class="number">31</span>,<span class="number">90</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_bit1;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-20_21-30-47.png" alt="Snipaste_2023-07-20_21-30-47"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> BIN(f1),BIN(f2),BIN(f3)</span><br><span class="line"><span class="keyword">FROM</span> test_bit1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_21-32-23.png" alt="Snipaste_2023-07-20_21-32-23" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 使用b<span class="operator">+</span><span class="number">0</span>查询数据时，可以直接查询出存储的十进制数据的值。</span><br><span class="line"><span class="keyword">SELECT</span> f1 <span class="operator">+</span> <span class="number">0</span>, f2 <span class="operator">+</span> <span class="number">0</span>, f3 <span class="operator">+</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">FROM</span> test_bit1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_21-41-16.png" alt="Snipaste_2023-07-20_21-41-16" style="zoom:33%;">

<h2 id="6-日期与时间类型"><a href="#6-日期与时间类型" class="headerlink" title="6. 日期与时间类型"></a>6. 日期与时间类型</h2><h3 id="6-1-YEAR类型"><a href="#6-1-YEAR类型" class="headerlink" title="6.1 YEAR类型"></a>6.1 YEAR类型</h3><img src="Snipaste_2023-07-20_21-43-11.png" alt="Snipaste_2023-07-20_21-43-11" style="zoom:50%;">

<img src="Snipaste_2023-07-20_21-43-47.png" alt="Snipaste_2023-07-20_21-43-47" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_year(</span><br><span class="line">f1 <span class="keyword">YEAR</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_year</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">2022</span>),(<span class="string">&#x27;2021&#x27;</span>); # 带不带引号均可</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_year;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_22-14-14.png" alt="Snipaste_2023-07-20_22-14-14" style="zoom:33%;">

<h3 id="6-2-DATE类型"><a href="#6-2-DATE类型" class="headerlink" title="6.2 DATE类型"></a>6.2 DATE类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_date1(</span><br><span class="line">f1 <span class="type">DATE</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_date1</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;2022-02-03&#x27;</span>); # 必须加引号</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_date1; # <span class="number">2022</span><span class="number">-02</span><span class="number">-03</span></span><br></pre></td></tr></table></figure>

<h3 id="6-3-TIME类型"><a href="#6-3-TIME类型" class="headerlink" title="6.3 TIME类型"></a>6.3 TIME类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_time1(</span><br><span class="line">f1 <span class="type">TIME</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_time1</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;12:35:09&#x27;</span>),(<span class="string">&#x27;2 12:30:45&#x27;</span>);# <span class="number">2</span>表示天数</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_time1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_22-23-22.png" alt="Snipaste_2023-07-20_22-23-22" style="zoom:50%;">

<h3 id="6-4-DATETIME类型"><a href="#6-4-DATETIME类型" class="headerlink" title="6.4 DATETIME类型"></a>6.4 DATETIME类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># DATETIME在所有日期时间类型中占用的存储空间最大，总共需要<span class="number">8</span>个字节</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_datetime1(</span><br><span class="line">dt DATETIME</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_datetime1</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;2021-09-08 12:45:09&#x27;</span>),(<span class="string">&#x27;2023-07-20 22:27:07&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_datetime1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_22-27-46.png" alt="Snipaste_2023-07-20_22-27-46" style="zoom:50%;">

<h3 id="6-5-TIMESTAMP类型"><a href="#6-5-TIMESTAMP类型" class="headerlink" title="6.5 TIMESTAMP类型"></a>6.5 TIMESTAMP类型</h3><p>TIMESTAMP类型也可以表示日期时间，其显示格式与DATETIME类型相同，都是 YYYY-MM-DD HH:MM:SS ，需要4个字节的存储空间。但是TIMESTAMP存储的时间范围比DATETIME要小很多，只能存储“1970-01-01 00:00:01 UTC”到“2038-01-19 03:14:07 UTC”之间的时间。其中，UTC表示世界统一时间，也叫作世界标准时间。</p>
<p><strong>存储数据的时候需要对当前时间所在的时区进行转换，查询数据的时候再将时间转换回当前的时</strong> <strong>区。因此，使用</strong> <strong>TIMESTAMP</strong> <strong>存储的同一个时间值，在不同的时区查询时会显示不同的时间。</strong></p>
<p><img src="Snipaste_2023-07-20_22-45-24.png" alt="Snipaste_2023-07-20_22-45-24"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> temp_time(</span><br><span class="line">d1 DATETIME,</span><br><span class="line">d2 <span class="type">TIMESTAMP</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> temp_time</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;2022-02-02 22:22:22&#x27;</span>,<span class="string">&#x27;2022-02-02 22:22:22&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> temp_time</span><br><span class="line"><span class="keyword">VALUES</span> (NOW(),NOW());</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> temp_time;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_22-49-03.png" alt="Snipaste_2023-07-20_22-49-03" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#修改当前的时区</span><br><span class="line"><span class="keyword">SET</span> time_zone <span class="operator">=</span> <span class="string">&#x27;+9:00&#x27;</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> temp_time;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-20_22-51-47.png" alt="Snipaste_2023-07-20_22-51-47" style="zoom: 50%;">

<h3 id="6-6-开发中经验"><a href="#6-6-开发中经验" class="headerlink" title="6.6 开发中经验"></a>6.6 开发中经验</h3><p><img src="Snipaste_2023-07-20_22-54-17.png" alt="Snipaste_2023-07-20_22-54-17"></p>
<img src="Snipaste_2023-07-20_22-56-13.png" alt="Snipaste_2023-07-20_22-56-13" style="zoom: 50%;">

<h2 id="7-文本字符串类型"><a href="#7-文本字符串类型" class="headerlink" title="7. 文本字符串类型"></a>7. 文本字符串类型</h2><p><img src="Snipaste_2023-07-21_10-11-43.png" alt="Snipaste_2023-07-21_10-11-43"></p>
<h3 id="7-1-CHAR与VARCHAR类型"><a href="#7-1-CHAR与VARCHAR类型" class="headerlink" title="7.1 CHAR与VARCHAR类型"></a>7.1 CHAR与VARCHAR类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_char1(</span><br><span class="line">c1 <span class="type">CHAR</span>,</span><br><span class="line">c2 <span class="type">CHAR</span>(<span class="number">5</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">DESC</span> test_char1;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_char1(c1)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;a&#x27;</span>); # 长度默认是<span class="number">1</span>个字符</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_char1(c2)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;abcde&#x27;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_char1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-21_21-31-12.png" alt="Snipaste_2023-07-21_21-31-12" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># <span class="type">VARCHAR</span>(M) 定义时， 必须指定 长度M，否则报错</span><br><span class="line"># MySQL5<span class="number">.0</span>版本以上，<span class="type">varchar</span>(<span class="number">20</span>)：指的是<span class="number">20</span>字符。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_varchar3(</span><br><span class="line">NAME <span class="type">VARCHAR</span>(<span class="number">5</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_varchar3</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;阿里巴巴&#x27;</span>),(<span class="string">&#x27;字节跳动&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_varchar3;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-21_21-47-18.png" alt="Snipaste_2023-07-21_21-47-18" style="zoom:33%;">

<p><img src="Snipaste_2023-07-21_21-58-11.png" alt="Snipaste_2023-07-21_21-58-11"></p>
<p><img src="Snipaste_2023-07-21_21-58-38.png" alt="Snipaste_2023-07-21_21-58-38"></p>
<h3 id="7-2-TEXT类型"><a href="#7-2-TEXT类型" class="headerlink" title="7.2 TEXT类型"></a>7.2 TEXT类型</h3><p><img src="Snipaste_2023-07-21_22-01-31.png" alt="Snipaste_2023-07-21_22-01-31"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_text(</span><br><span class="line">tx TEXT</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_text</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;jwjdkjdkjdkjdkjk  &#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">CHAR_LENGTH</span>(tx)</span><br><span class="line"><span class="keyword">FROM</span> test_text; # <span class="number">18</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-21_22-17-23.png" alt="Snipaste_2023-07-21_22-17-23"></p>
<h2 id="8-ENUM类型"><a href="#8-ENUM类型" class="headerlink" title="8. ENUM类型"></a>8. ENUM类型</h2><p><img src="Snipaste_2023-07-21_22-18-53.png" alt="Snipaste_2023-07-21_22-18-53"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_enum(</span><br><span class="line">season ENUM(<span class="string">&#x27;春&#x27;</span>,<span class="string">&#x27;夏&#x27;</span>,<span class="string">&#x27;秋&#x27;</span>,<span class="string">&#x27;冬&#x27;</span>,<span class="string">&#x27;unknow&#x27;</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_enum</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="string">&#x27;春&#x27;</span>),(<span class="string">&#x27;秋&#x27;</span>);</span><br><span class="line"># 忽略大小写</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_enum</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="string">&#x27;UNKNOW&#x27;</span>);</span><br><span class="line"># 允许按照角标的方式获取指定索引位置的枚举值</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_enum</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="string">&#x27;1&#x27;</span>),(<span class="number">3</span>);</span><br><span class="line"># 当ENUM类型的字段没有声明为<span class="keyword">NOT</span> <span class="keyword">NULL</span>时，插入<span class="keyword">NULL</span>也是有效的</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_enum</span><br><span class="line"><span class="keyword">VALUES</span>(<span class="keyword">NULL</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_enum;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-21_22-21-37.png" alt="Snipaste_2023-07-21_22-21-37" style="zoom:50%;">

<h2 id="9-SET类型"><a href="#9-SET类型" class="headerlink" title="9. SET类型"></a>9. SET类型</h2><p><img src="Snipaste_2023-07-21_22-53-00.png" alt="Snipaste_2023-07-21_22-53-00"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_set(</span><br><span class="line">s <span class="keyword">SET</span> (<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_set (s) <span class="keyword">VALUES</span> (<span class="string">&#x27;A&#x27;</span>), (<span class="string">&#x27;A,B&#x27;</span>);</span><br><span class="line">#插入重复的<span class="keyword">SET</span>类型成员时，MySQL会自动删除重复的成员</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_set (s) <span class="keyword">VALUES</span> (<span class="string">&#x27;A,B,C,A&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_set;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-21_22-55-09.png" alt="Snipaste_2023-07-21_22-55-09" style="zoom:50%;">

<h2 id="10-二进制字符串类型"><a href="#10-二进制字符串类型" class="headerlink" title="10. 二进制字符串类型"></a>10. 二进制字符串类型</h2><h3 id="10-1-BINARY与VARBINARY-类型"><a href="#10-1-BINARY与VARBINARY-类型" class="headerlink" title="10.1 BINARY与VARBINARY 类型"></a>10.1 <strong>BINARY</strong>与<strong>VARBINARY</strong> <strong>类型</strong></h3><p><img src="Snipaste_2023-07-22_19-49-50.png" alt="Snipaste_2023-07-22_19-49-50"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 二进制字符串类型主要存储一些二进制数据，比如可以存储图片、音频和视频等二进制数据</span><br><span class="line"># <span class="type">BINARY</span>和<span class="type">VARBINARY</span>类似于<span class="type">CHAR</span>和<span class="type">VARCHAR</span>，只是它们存储的是二进制字符串。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_binary1(</span><br><span class="line">f1 <span class="type">BINARY</span>,</span><br><span class="line">f2 <span class="type">BINARY</span>(<span class="number">3</span>),</span><br><span class="line">f4 <span class="type">VARBINARY</span>(<span class="number">10</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_binary1(f1,f2)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_binary1(f2,f4)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;abc&#x27;</span>,<span class="string">&#x27;alibabjdjd&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_binary1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-22_20-09-21.png" alt="Snipaste_2023-07-22_20-09-21" style="zoom:50%;">

<h3 id="10-2-BLOB类型"><a href="#10-2-BLOB类型" class="headerlink" title="10.2 BLOB类型"></a>10.2 BLOB类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="type">BLOB</span>是一个二进制大对象 ，可以容纳可变数量的数据,可以存储一个二进制的大对象，比如 图片 、 音频 和 视频 等</span><br><span class="line"># 需要注意的是，在实际工作中，往往不会在MySQL数据库中使用<span class="type">BLOB</span>类型存储大对象数据，通常会将图</span><br><span class="line"># 片、音频和视频文件存储到 服务器的磁盘上 ，并将图片、音频和视频的访问路径存储到MySQL中。</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-22_20-12-00.png" alt="Snipaste_2023-07-22_20-12-00"></p>
<p><img src="Snipaste_2023-07-22_20-26-15.png" alt="Snipaste_2023-07-22_20-26-15"></p>
<h2 id="11-JSON类型"><a href="#11-JSON类型" class="headerlink" title="11. JSON类型"></a>11. JSON类型</h2><p><img src="Snipaste_2023-07-22_20-56-19.png" alt="Snipaste_2023-07-22_20-56-19"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test_json(</span><br><span class="line">js json</span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test_json (js)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;&#123;&quot;name&quot;:&quot;songhk&quot;, &quot;age&quot;:18, &quot;address&quot;:&#123;&quot;province&quot;:&quot;beijing&quot;,</span></span><br><span class="line"><span class="string">&quot;city&quot;:&quot;beijing&quot;&#125;&#125;&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test_json;</span><br><span class="line"># 当需要检索JSON类型的字段中数据的某个具体值时，可以使用“<span class="operator">-</span><span class="operator">&gt;</span>”和“<span class="operator">-</span><span class="operator">&gt;&gt;</span>”符号。</span><br><span class="line"><span class="keyword">SELECT</span> js <span class="operator">-</span><span class="operator">&gt;</span> <span class="string">&#x27;$.name&#x27;</span> <span class="keyword">AS</span> NAME,js <span class="operator">-</span><span class="operator">&gt;</span> <span class="string">&#x27;$.age&#x27;</span> <span class="keyword">AS</span> age ,js <span class="operator">-</span><span class="operator">&gt;</span> <span class="string">&#x27;$.address.province&#x27;</span></span><br><span class="line"><span class="keyword">AS</span> province, js <span class="operator">-</span><span class="operator">&gt;</span> <span class="string">&#x27;$.address.city&#x27;</span> <span class="keyword">AS</span> city</span><br><span class="line"><span class="keyword">FROM</span> test_json;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-22_22-01-15.png" alt="Snipaste_2023-07-22_22-01-15" style="zoom:50%;">

<h2 id="12-总结"><a href="#12-总结" class="headerlink" title="12. 总结"></a>12. 总结</h2><p><img src="Snipaste_2023-07-22_22-37-40.png" alt="Snipaste_2023-07-22_22-37-40"></p>
<h1 id="第十二章-约束"><a href="#第十二章-约束" class="headerlink" title="第十二章 约束"></a>第十二章 约束</h1><h2 id="1-约束（constraint）概述"><a href="#1-约束（constraint）概述" class="headerlink" title="1. 约束（constraint）概述"></a>1. 约束（constraint）概述</h2><h3 id="1-1-为什么需要约束"><a href="#1-1-为什么需要约束" class="headerlink" title="1.1 为什么需要约束"></a>1.1 为什么需要约束</h3><p>为了保证数据的完整性</p>
<p><img src="Snipaste_2023-07-23_08-24-25.png" alt="Snipaste_2023-07-23_08-24-25"></p>
<h3 id="1-2-什么是约束"><a href="#1-2-什么是约束" class="headerlink" title="1.2 什么是约束"></a>1.2 什么是约束</h3><p>约束是表级的强制规定。</p>
<p>可以在<strong>创建表时规定约束（通过</strong> <strong>CREATE TABLE</strong> <strong>语句）</strong>，或者在<strong>表创建之后通过</strong> <strong>ALTER TABLE</strong> <strong>语句规定约束</strong>。</p>
<h3 id="1-3-约束的分类"><a href="#1-3-约束的分类" class="headerlink" title="1.3 约束的分类"></a>1.3 约束的分类</h3><p><img src="Snipaste_2023-07-23_08-27-51.png" alt="Snipaste_2023-07-23_08-27-51"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看某个表已有的约束</span><br><span class="line">#information_schema数据库名（系统库）</span><br><span class="line">#table_constraints表名称（专门存储各个表的约束）</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.table_constraints</span><br><span class="line"><span class="keyword">WHERE</span> table_name <span class="operator">=</span> <span class="string">&#x27;employees&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-23_08-46-42.png" alt="Snipaste_2023-07-23_08-46-42"></p>
<h2 id="2-非空NOT-NULL约束"><a href="#2-非空NOT-NULL约束" class="headerlink" title="2. 非空NOT  NULL约束"></a>2. 非空NOT  NULL约束</h2><p><img src="Snipaste_2023-07-23_09-11-09.png" alt="Snipaste_2023-07-23_09-11-09"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE dbtest13;</span><br><span class="line">USE dbtest13;</span><br><span class="line"># 在<span class="keyword">CREATE</span> <span class="keyword">TABLE</span>时添加约束</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test1(</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    email <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> test1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_09-16-57.png" alt="Snipaste_2023-07-23_09-16-57" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在<span class="keyword">ALTER</span> <span class="keyword">TABLE</span>时添加约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test1</span><br><span class="line">MODIFY email <span class="type">VARCHAR</span>(<span class="number">25</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> test1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_09-21-41.png" alt="Snipaste_2023-07-23_09-21-41" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在<span class="keyword">ALTER</span> <span class="keyword">TABLE</span>时删除约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test1</span><br><span class="line">MODIFY email <span class="type">VARCHAR</span>(<span class="number">25</span>) <span class="keyword">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> test1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_09-23-24.png" alt="Snipaste_2023-07-23_09-23-24" style="zoom:33%;">

<h2 id="3-唯一性约束UNIQUE"><a href="#3-唯一性约束UNIQUE" class="headerlink" title="3. 唯一性约束UNIQUE"></a>3. 唯一性约束UNIQUE</h2><p>唯一约束，允许出现多个空值NULL</p>
<p><img src="Snipaste_2023-07-23_09-25-21.png" alt="Snipaste_2023-07-23_09-25-21"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test2(</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">UNIQUE</span>, # 列级约束</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    email <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>),</span><br><span class="line">    # 表级约束，uk_test2_email为约束名</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> uk_test2_email <span class="keyword">UNIQUE</span>(email)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> test2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_09-31-53.png" alt="Snipaste_2023-07-23_09-31-53" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.TABLE_CONSTRAINTS</span><br><span class="line"><span class="keyword">WHERE</span> TABLE_NAME <span class="operator">=</span> <span class="string">&#x27;test2&#x27;</span>;</span><br><span class="line"># 在创建唯一约束的时候，如果不给唯一约束名，就默认和列名相同</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-23_11-01-04.png" alt="Snipaste_2023-07-23_11-01-04"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2(id, last_name, email, salary)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="string">&#x27;TOM@163.com&#x27;</span>,<span class="number">4600</span>);</span><br><span class="line"># Duplicate entry <span class="string">&#x27;1&#x27;</span> <span class="keyword">for</span> key <span class="string">&#x27;test2.id&#x27;</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2(id, last_name, email, salary)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;JIM&#x27;</span>,<span class="string">&#x27;JIM@163.com&#x27;</span>,<span class="number">4200</span>);</span><br><span class="line"># Duplicate entry <span class="string">&#x27;TOM@163.com&#x27;</span> <span class="keyword">for</span> key <span class="string">&#x27;test2.uk_test2_email&#x27;</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2(id, last_name, email, salary)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">&#x27;Peter&#x27;</span>,<span class="string">&#x27;TOM@163.com&#x27;</span>,<span class="number">4100</span>);</span><br><span class="line"># 可以向声明为<span class="keyword">UNIQUE</span>的字段上添加<span class="keyword">NULL</span>值，而且可以多次添加<span class="keyword">NULL</span>值</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2(id, last_name, email, salary)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">&#x27;JIM&#x27;</span>,<span class="keyword">NULL</span>,<span class="number">2300</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2(id, last_name, email, salary)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">3</span>,<span class="string">&#x27;Peter&#x27;</span>,<span class="keyword">NULL</span>,<span class="number">4100</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_11-19-23.png" alt="Snipaste_2023-07-23_11-19-23" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在<span class="keyword">ALTER</span> <span class="keyword">TABLE</span>时添加约束</span><br><span class="line"># 方式<span class="number">1</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test2</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> uk_test2_salary <span class="keyword">UNIQUE</span>(salary);</span><br><span class="line"><span class="keyword">DESC</span> test2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_11-22-28.png" alt="Snipaste_2023-07-23_11-22-28" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">2</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test2</span><br><span class="line">MODIFY last_name <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="keyword">UNIQUE</span>;</span><br><span class="line"><span class="keyword">DESC</span> test2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_11-25-29.png" alt="Snipaste_2023-07-23_11-25-29" style="zoom: 33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 关于复合唯一约束</span><br><span class="line"># 符合约束就是多个字段一起的唯一性，当且仅当多个字段同时对应相同时，才不满足唯一性</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">USER</span>(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    NAME <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    PASSWORD <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    # 表级约束</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> uk_user_name_pwd <span class="keyword">UNIQUE</span>(NAME,PASSWORD)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">USER</span></span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;Tom&#x27;</span>,<span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">USER</span></span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">&#x27;TOM1&#x27;</span>,<span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">USER</span></span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">3</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="string">&#x27;abcd&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">USER</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_11-34-48.png" alt="Snipaste_2023-07-23_11-34-48" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 复合的唯一性案例</span><br><span class="line">#学生表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> student(</span><br><span class="line">    sid <span class="type">int</span>, #学号</span><br><span class="line">    sname <span class="type">varchar</span>(<span class="number">20</span>), #姓名</span><br><span class="line">    tel <span class="type">char</span>(<span class="number">11</span>) <span class="keyword">UNIQUE</span>, #电话</span><br><span class="line">    cardid <span class="type">char</span>(<span class="number">18</span>) <span class="keyword">UNIQUE</span> #身份证号</span><br><span class="line">);</span><br><span class="line">#课程表</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> course(</span><br><span class="line">    cid <span class="type">int</span>, #课程编号</span><br><span class="line">    cname <span class="type">varchar</span>(<span class="number">20</span>) #课程名称</span><br><span class="line">);</span><br><span class="line">#选课表</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student_course(</span><br><span class="line">    id <span class="type">int</span>,</span><br><span class="line">    sid <span class="type">int</span>,</span><br><span class="line">    cid <span class="type">int</span>,</span><br><span class="line">    score <span class="type">int</span>,</span><br><span class="line">    <span class="keyword">UNIQUE</span> (sid,cid) #复合唯一</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">&#x27;张三&#x27;</span>,<span class="string">&#x27;13710011002&#x27;</span>,<span class="string">&#x27;101223199012015623&#x27;</span>);#成功</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student <span class="keyword">values</span>(<span class="number">2</span>,<span class="string">&#x27;李四&#x27;</span>,<span class="string">&#x27;13710011003&#x27;</span>,<span class="string">&#x27;101223199012015624&#x27;</span>);#成功</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course <span class="keyword">values</span>(<span class="number">1001</span>,<span class="string">&#x27;Java&#x27;</span>),(<span class="number">1002</span>,<span class="string">&#x27;MySQL&#x27;</span>);#成功</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student_course <span class="keyword">values</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1001</span>, <span class="number">89</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1002</span>, <span class="number">90</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1001</span>, <span class="number">88</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="number">2</span>, <span class="number">1002</span>, <span class="number">56</span>);#成功</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> student;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_14-54-00.png" alt="Snipaste_2023-07-23_14-54-00" style="zoom: 50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> course;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_14-55-05.png" alt="Snipaste_2023-07-23_14-55-05" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> student_course;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_14-56-35.png" alt="Snipaste_2023-07-23_14-56-35" style="zoom: 50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Duplicate entry <span class="string">&#x27;1-1001&#x27;</span> <span class="keyword">for</span> key <span class="string">&#x27;student_course.sid&#x27;</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> student_course <span class="keyword">values</span> (<span class="number">5</span>, <span class="number">1</span>, <span class="number">1001</span>, <span class="number">88</span>);#失败</span><br></pre></td></tr></table></figure>

<p>删除唯一索引</p>
<p><img src="Snipaste_2023-07-23_14-59-29.png" alt="Snipaste_2023-07-23_14-59-29"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 删除唯一约束</span><br><span class="line"><span class="keyword">DESC</span> test2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_15-50-25.png" alt="Snipaste_2023-07-23_15-50-25" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.TABLE_CONSTRAINTS</span><br><span class="line"><span class="keyword">WHERE</span> TABLE_NAME <span class="operator">=</span> <span class="string">&#x27;test2&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-23_15-53-39.png" alt="Snipaste_2023-07-23_15-53-39"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 如何删除唯一性索引</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test2</span><br><span class="line"><span class="keyword">DROP</span> INDEX last_name;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test2</span><br><span class="line"><span class="keyword">DROP</span> INDEX uk_test2_salary;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test2</span><br><span class="line"><span class="keyword">DROP</span> INDEX uk_test2_email;</span><br><span class="line"><span class="keyword">DESC</span> test2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_15-55-19.png" alt="Snipaste_2023-07-23_15-55-19" style="zoom:33%;">

<h2 id="4-PRIMARY-KEY-约束"><a href="#4-PRIMARY-KEY-约束" class="headerlink" title="4. PRIMARY KEY 约束"></a>4. <strong>PRIMARY KEY</strong> <strong>约束</strong></h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 作用：用来唯一标识表中的一行记录。</span></span><br><span class="line"><span class="comment"> 关键字：primary key</span></span><br><span class="line"><span class="comment"> 特点：主键约束相当于唯一约束+非空约束的组合，主键约束列不允许重复，也不允许出现空值。</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-23_16-23-48.png" alt="Snipaste_2023-07-23_16-23-48"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 添加主键约束</span><br><span class="line"># （<span class="number">1</span>）建表时指定主键约束</span><br><span class="line"># 一个表中最多只能有一个主键约束</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test3(</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY, # 列级约束</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>),</span><br><span class="line">    email <span class="type">VARCHAR</span>(<span class="number">25</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.TABLE_CONSTRAINTS</span><br><span class="line"><span class="keyword">WHERE</span> TABLE_NAME <span class="operator">=</span> <span class="string">&#x27;test3&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-23_16-34-46.png" alt="Snipaste_2023-07-23_16-34-46"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 主键约束的特征：非空且唯一，用于唯一标识表中的一条记录</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test4(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>),</span><br><span class="line">    email <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    #表级约束</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> pk_test5_id <span class="keyword">PRIMARY</span> KEY(id)</span><br><span class="line">); # MySQL的主键名总是<span class="keyword">PRIMARY</span>，就算自己命名了主键约束名也没用</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.TABLE_CONSTRAINTS</span><br><span class="line"><span class="keyword">WHERE</span> TABLE_NAME <span class="operator">=</span> <span class="string">&#x27;test4&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-23_16-35-40.png" alt="Snipaste_2023-07-23_16-35-40"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test4(id, last_name, salary, email)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="number">4500</span>,<span class="string">&#x27;tom@163.com&#x27;</span>);</span><br><span class="line"># Duplicate entry <span class="string">&#x27;1&#x27;</span> <span class="keyword">for</span> key <span class="string">&#x27;test4.PRIMARY&#x27;</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test4(id, last_name, salary, email)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="number">4500</span>,<span class="string">&#x27;tom@163.com&#x27;</span>);</span><br><span class="line"># <span class="keyword">Column</span> <span class="string">&#x27;id&#x27;</span> cannot be <span class="keyword">null</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test4(id, last_name, salary, email)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="keyword">NULL</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="number">4500</span>,<span class="string">&#x27;tom@163.com&#x27;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test4;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_16-55-26.png" alt="Snipaste_2023-07-23_16-55-26" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test5(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    NAME <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    PASSWORD <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    <span class="keyword">PRIMARY</span> KEY (NAME,PASSWORD)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test5</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;Tom&#x27;</span>,<span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test5</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;Tom1&#x27;</span>,<span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line">#  <span class="keyword">Column</span> <span class="string">&#x27;NAME&#x27;</span> cannot be <span class="keyword">null</span></span><br><span class="line"># 如果是多列组合的复合主键约束，那么这些列都不允许为空值，并且组合的值不允许重复</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test5</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="keyword">NULL</span>,<span class="string">&#x27;abc&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test5;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_16-59-44.png" alt="Snipaste_2023-07-23_16-59-44" style="zoom: 50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># （<span class="number">2</span>）建表后增加主键约束</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test6(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>),</span><br><span class="line">    email <span class="type">VARCHAR</span>(<span class="number">25</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test6</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">PRIMARY</span> KEY (id);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 删除主键约束(在实际开发中，不会去删除主键约束！ )</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test6</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">PRIMARY</span> KEY;</span><br></pre></td></tr></table></figure>

<h2 id="5-自增列：AUTO-INCREMENT"><a href="#5-自增列：AUTO-INCREMENT" class="headerlink" title="5. 自增列：AUTO_INCREMENT"></a>5. 自增列：AUTO_INCREMENT</h2><p>某个字段的值自增</p>
<p><img src="Snipaste_2023-07-23_17-12-53.png" alt="Snipaste_2023-07-23_17-12-53"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test7(</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT,</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>)</span><br><span class="line">);</span><br><span class="line"># 开发中，一旦主键作用的字段上声明有AUTO_INCREMENT,则我们在添加数据时，就不要给主键</span><br><span class="line"># 对应的字段去赋值了</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test7(last_name)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;TOM&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test7(last_name)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;MARRY&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test7(last_name)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;WYH&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test7(last_name)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="string">&#x27;JIM&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test7;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-23_17-15-57.png" alt="Snipaste_2023-07-23_17-15-57" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 在<span class="keyword">ALTER</span> <span class="keyword">TABLE</span>时添加</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test8(</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY ,</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>)</span><br><span class="line">);</span><br><span class="line"># 添加主键</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test8</span><br><span class="line">MODIFY id <span class="type">INT</span> AUTO_INCREMENT;</span><br><span class="line"># 删除主键</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test8</span><br><span class="line">MODIFY id <span class="type">INT</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># MySQL <span class="number">8.0</span>新特性—自增变量的持久化</span><br><span class="line"># MySQL <span class="number">8.0</span>将自增主键的计数器持久化到 重做日志 中。每次计数器发生改变，都会将其写入重做日志</span><br><span class="line"># 中。如果数据库重启，InnoDB会根据重做日志中的信息来初始化计数器的内存值。</span><br></pre></td></tr></table></figure>

<h2 id="6-FOREIGN-KEY-约束"><a href="#6-FOREIGN-KEY-约束" class="headerlink" title="6.FOREIGN KEY 约束"></a>6.<strong>FOREIGN KEY</strong> <strong>约束</strong></h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">6.1</span> 作用：限定某个表的字段的引用完整性</span><br><span class="line">    主表的主键即为从表的外键</span><br><span class="line"><span class="number">6.2</span> 关键字：<span class="keyword">FOREIGN</span> KEY</span><br><span class="line"><span class="number">6.3</span> 主表（父表）：被引用的表，被参考的表</span><br><span class="line">    从表（子表）：引用别人的表，参考别人的表</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_08-47-17.png" alt="Snipaste_2023-07-25_08-47-17">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.5</span> 在<span class="keyword">CREATE</span> <span class="keyword">TABLE</span>时添加外键约束</span><br><span class="line"># 主表和从表：父表和子表</span><br><span class="line"># ①先创建主表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> dept1(</span><br><span class="line">    dept_id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY, # 主键约束</span><br><span class="line">    dept_name <span class="type">VARCHAR</span>(<span class="number">15</span>)</span><br><span class="line">);</span><br><span class="line"># ②再创建从表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> emp1(</span><br><span class="line">    emp_id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT,</span><br><span class="line">    emp_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    department_id <span class="type">INT</span>,</span><br><span class="line"></span><br><span class="line">    # 表级约束</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> fk_emp1_dept_id <span class="keyword">FOREIGN</span> KEY (department_id) <span class="keyword">REFERENCES</span> dept1(dept_id)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.TABLE_CONSTRAINTS</span><br><span class="line"><span class="keyword">WHERE</span> TABLE_NAME <span class="operator">=</span> <span class="string">&#x27;emp1&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-25_09-40-58.png" alt="Snipaste_2023-07-25_09-40-58"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.6</span> 演示外键的效果</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> dept1</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">10</span>,<span class="string">&#x27;IT&#x27;</span>);</span><br><span class="line"># 在主表dept1中添加了<span class="number">10</span>号部门以后，我们就可以在从表中添加<span class="number">10</span>号部门的员工</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp1</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1001</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="number">10</span>);</span><br><span class="line"># 外键原因导致删除失败Cannot <span class="keyword">delete</span> <span class="keyword">or</span> <span class="keyword">update</span> a parent <span class="type">row</span>: a <span class="keyword">foreign</span> key <span class="keyword">constraint</span> fails</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> dept1</span><br><span class="line"><span class="keyword">WHERE</span> dept_id <span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line"># 外键原因导致更新失败Cannot <span class="keyword">delete</span> <span class="keyword">or</span> <span class="keyword">update</span> a parent <span class="type">row</span>: a <span class="keyword">foreign</span> key <span class="keyword">constraint</span> fails</span><br><span class="line"><span class="keyword">UPDATE</span> dept1</span><br><span class="line"><span class="keyword">SET</span> dept_id <span class="operator">=</span> <span class="number">20</span></span><br><span class="line"><span class="keyword">WHERE</span> dept_id <span class="operator">=</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.7</span> 在<span class="keyword">ALTER</span> <span class="keyword">TABLE</span>时添加外键约束</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> dept2(</span><br><span class="line">    dept_id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY ,</span><br><span class="line">    dept_name <span class="type">VARCHAR</span>(<span class="number">15</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> emp2(</span><br><span class="line">    emp_id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT,</span><br><span class="line">    emp_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    department_id <span class="type">INT</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp2</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> fk_emp2_dept_id <span class="keyword">FOREIGN</span> KEY(department_id) <span class="keyword">REFERENCES</span> dept2(dept_id);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.TABLE_CONSTRAINTS</span><br><span class="line"><span class="keyword">WHERE</span> TABLE_NAME <span class="operator">=</span> <span class="string">&#x27;emp2&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-25_10-37-23.png" alt="Snipaste_2023-07-25_10-37-23"></p>
<p><img src="Snipaste_2023-07-25_10-41-04.png" alt="Snipaste_2023-07-25_10-41-04"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 约束等级</span><br><span class="line"># 演示：<span class="keyword">on</span> <span class="keyword">update</span> cascade <span class="keyword">on</span> <span class="keyword">delete</span> <span class="keyword">set</span> <span class="keyword">null</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dept(</span><br><span class="line">    did <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY , #部门编号</span><br><span class="line">    dname <span class="type">VARCHAR</span>(<span class="number">50</span>) #部门名称</span><br><span class="line">);</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> emp(</span><br><span class="line">    eid <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY , #员工编号</span><br><span class="line">    ename <span class="type">VARCHAR</span>(<span class="number">5</span>), #员工姓名</span><br><span class="line">    deptid <span class="type">INT</span>, #员工所在的部门</span><br><span class="line">    <span class="keyword">FOREIGN</span> KEY (deptid) <span class="keyword">REFERENCES</span> dept(did) <span class="keyword">ON</span> <span class="keyword">UPDATE</span> CASCADE <span class="keyword">ON</span> <span class="keyword">DELETE</span> <span class="keyword">SET</span> <span class="keyword">NULL</span></span><br><span class="line">    #把修改操作设置为级联修改等级，把删除操作设置为<span class="keyword">set</span> <span class="keyword">null</span>等级</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> dept <span class="keyword">VALUES</span> (<span class="number">1001</span>,<span class="string">&#x27;教学部&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> dept <span class="keyword">VALUES</span> (<span class="number">1002</span>, <span class="string">&#x27;财务部&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> dept <span class="keyword">VALUES</span> (<span class="number">1003</span>, <span class="string">&#x27;咨询部&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;张三&#x27;</span>,<span class="number">1001</span>); #在添加这条记录时，要求部门表有<span class="number">1001</span>部门</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp <span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">&#x27;李四&#x27;</span>,<span class="number">1001</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> emp <span class="keyword">VALUES</span> (<span class="number">3</span>,<span class="string">&#x27;王五&#x27;</span>,<span class="number">1002</span>);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> dept;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_11-08-40.png" alt="Snipaste_2023-07-25_11-08-40" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_11-09-24.png" alt="Snipaste_2023-07-25_11-09-24" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">ON</span> <span class="keyword">UPDATE</span> CASCADE</span><br><span class="line"><span class="keyword">UPDATE</span> dept</span><br><span class="line"><span class="keyword">SET</span> did <span class="operator">=</span> <span class="number">1004</span></span><br><span class="line"><span class="keyword">WHERE</span> did <span class="operator">=</span> <span class="number">1002</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> dept;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_11-11-58.png" alt="Snipaste_2023-07-25_11-11-58" style="zoom:33%;">

<img src="Snipaste_2023-07-25_11-12-10.png" alt="Snipaste_2023-07-25_11-12-10" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">ON</span> <span class="keyword">DELETE</span> <span class="keyword">SET</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> dept</span><br><span class="line"><span class="keyword">WHERE</span> did <span class="operator">=</span> <span class="number">1004</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> dept;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_11-19-54.png" alt="Snipaste_2023-07-25_11-19-54" style="zoom:33%;">

<img src="Snipaste_2023-07-25_11-20-07.png" alt="Snipaste_2023-07-25_11-20-07" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.9</span> 删除外键约束</span><br><span class="line"># 一个表中可以声明有多个外键约束,所以删除外键时需要指明删除哪一个</span><br><span class="line">USE atguigudb;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.TABLE_CONSTRAINTS</span><br><span class="line"><span class="keyword">WHERE</span> TABLE_NAME <span class="operator">=</span> <span class="string">&#x27;employees&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-25_11-27-12.png" alt="Snipaste_2023-07-25_11-27-12"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">USE dbtest13;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp1</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">FOREIGN</span> KEY fk_emp1_dept_id;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 在手动删除外键约束对应的普通索引</span><br><span class="line"><span class="keyword">SHOW</span> INDEX <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-25_11-31-26.png" alt="Snipaste_2023-07-25_11-31-26"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp1</span><br><span class="line"><span class="keyword">DROP</span> INDEX fk_emp1_dept_id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> INDEX <span class="keyword">FROM</span> emp1;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-25_11-32-36.png" alt="Snipaste_2023-07-25_11-32-36"></p>
<p><img src="Snipaste_2023-07-25_11-35-05.png" alt="Snipaste_2023-07-25_11-35-05"></p>
<p><img src="Snipaste_2023-07-25_11-36-14.png" alt="Snipaste_2023-07-25_11-36-14"></p>
<p>（本小节在实际开发中没啥大用哈哈哈哈哈哈）</p>
<h2 id="7-check约束"><a href="#7-check约束" class="headerlink" title="7. check约束"></a>7. check约束</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">check</span>约束</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test10(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>) <span class="keyword">CHECK</span> ( salary <span class="operator">&gt;</span> <span class="number">2000</span> )</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test10</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="number">2500</span>); # <span class="number">2500</span><span class="operator">&gt;</span><span class="number">2000</span>,插入成功</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test10</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">&#x27;TOM2&#x27;</span>,<span class="number">1500</span>); # <span class="number">1500</span><span class="operator">&lt;</span><span class="number">2000</span>,插入失败</span><br><span class="line">#  <span class="keyword">Check</span> <span class="keyword">constraint</span> <span class="string">&#x27;test10_chk_1&#x27;</span> <span class="keyword">is</span> violated.</span><br></pre></td></tr></table></figure>

<h2 id="8-DEFAULT约束"><a href="#8-DEFAULT约束" class="headerlink" title="8. DEFAULT约束"></a>8. DEFAULT约束</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#  <span class="keyword">DEFAULT</span>约束</span><br><span class="line"># 在<span class="keyword">CREATE</span> <span class="keyword">TABLE</span>时添加约束</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test11(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>) <span class="keyword">DEFAULT</span> <span class="number">2000</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test11(id, last_name,salary)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;TOM&#x27;</span>,<span class="number">3000</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test11(id, last_name)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">2</span>,<span class="string">&#x27;TOM2&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> test11;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_13-47-06.png" alt="Snipaste_2023-07-25_13-47-06" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 在<span class="keyword">ALTER</span> <span class="keyword">TABLE</span>时添加<span class="operator">/</span>删除约束</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test12(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">);</span><br><span class="line"># 添加</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test12</span><br><span class="line">MODIFY salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>) <span class="keyword">DEFAULT</span> <span class="number">2000</span>;</span><br><span class="line"># 删除</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> test12</span><br><span class="line">MODIFY salary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<h2 id="9-面试"><a href="#9-面试" class="headerlink" title="9. 面试"></a>9. 面试</h2><p><img src="Snipaste_2023-07-25_13-50-28.png" alt="Snipaste_2023-07-25_13-50-28"></p>
<h1 id="第十三章-视图"><a href="#第十三章-视图" class="headerlink" title="第十三章 视图"></a>第十三章 视图</h1><h2 id="1-常见的数据库对象"><a href="#1-常见的数据库对象" class="headerlink" title="1. 常见的数据库对象"></a>1. 常见的数据库对象</h2><p><img src="Snipaste_2023-07-26_14-00-10.png" alt="Snipaste_2023-07-26_14-00-10"></p>
<h2 id="2-视图概述"><a href="#2-视图概述" class="headerlink" title="2. 视图概述"></a>2. 视图概述</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 1.视图的理解</span></span><br><span class="line"><span class="comment"> ①视图：可以看作一个虚拟表，本身是不存储数据的</span></span><br><span class="line"><span class="comment">        视图的本质，就可以看作是存储起来的SELECT语句</span></span><br><span class="line"><span class="comment"> ②视图中SELECT语句中涉及到的表，称为基表</span></span><br><span class="line"><span class="comment"> ③针对视图做DML操作，会影响到对应的基表中的数据，反之亦然</span></span><br><span class="line"><span class="comment"> ④视图本身的删除，不会影响到基表本身中数据的删除</span></span><br><span class="line"><span class="comment"> ⑤视图的应用场景：针对小型项目，不推荐适用视图，针对大型项目，可以考虑使用视图</span></span><br><span class="line"><span class="comment"> ⑥视图的优点：简化查询；控制数据的访问权限</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<h2 id="3-视图的创建"><a href="#3-视图的创建" class="headerlink" title="3. 视图的创建"></a>3. 视图的创建</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 准备工作</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE dbtest14;</span><br><span class="line">USE dbtest14;</span><br><span class="line"># 从atguigudb下复制两张表到dbtest14下，分别起名为emps和depts</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> emps</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> atguigudb.employees;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> depts</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> atguigudb.departments;</span><br><span class="line"># <span class="number">3.1</span> 针对于单表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp1</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> emps;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_14-04-45.png" alt="Snipaste_2023-07-26_14-04-45" style="zoom: 33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp2</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id emp_id,last_name lname,salary # 给字段创建别名的一种方式</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> <span class="number">8000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_14-36-50.png" alt="Snipaste_2023-07-26_14-36-50" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp3(emp_id,NAME,monthly_sal) # 起别名的另外一种方式</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> <span class="number">8000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp3;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_14-41-42.png" alt="Snipaste_2023-07-26_14-41-42" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp_sal</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp_sal;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_15-49-28.png" alt="Snipaste_2023-07-26_15-49-28" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.2</span> 针对于多表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp_dept</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id,e.department_id,d.department_name</span><br><span class="line"><span class="keyword">FROM</span> emps e <span class="keyword">JOIN</span> depts d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp_dept;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_16-23-15.png" alt="Snipaste_2023-07-26_16-23-15" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 利用视图对数据进行格式化</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp_dept1</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> CONCAT(e.last_name,<span class="string">&#x27;(&#x27;</span>,d.department_name,<span class="string">&#x27;)&#x27;</span>) emp_info</span><br><span class="line"><span class="keyword">FROM</span> emps e <span class="keyword">JOIN</span> depts d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp_dept1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_16-27-12.png" alt="Snipaste_2023-07-26_16-27-12" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.3</span> 基于视图创建视图</span><br><span class="line"># 当我们创建好一张视图之后，还可以在它的基础上继续创建视图。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp4</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name</span><br><span class="line"><span class="keyword">FROM</span> vu_emp1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp4;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_16-31-09.png" alt="Snipaste_2023-07-26_16-31-09" style="zoom:33%;">

<h2 id="4-查看视图"><a href="#4-查看视图" class="headerlink" title="4. 查看视图"></a>4. 查看视图</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span>查看视图</span><br><span class="line"># 语法<span class="number">1</span>：查看数据库的表对象、视图对象</span><br><span class="line"><span class="keyword">SHOW</span> TABLES ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_16-35-02.png" alt="Snipaste_2023-07-26_16-35-02" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 语法<span class="number">2</span>：查看视图的结构</span><br><span class="line"><span class="keyword">DESC</span> vu_emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_16-37-27.png" alt="Snipaste_2023-07-26_16-37-27" style="zoom: 33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> 语法<span class="number">3</span>：查看视图的属性信息</span><br><span class="line">#  查看视图信息（显示数据表的存储引擎、版本、数据行数和数据大小等）</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">TABLE</span> STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;vu_emp1&#x27;</span>;</span><br><span class="line"># 显示的是转置后的效果</span><br><span class="line"># 执行结果显示，注释Comment为<span class="keyword">VIEW</span>，说明该表为视图，其他的信息为<span class="keyword">NULL</span>，说明这是一个虚表。</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_16-43-55.png" alt="Snipaste_2023-07-26_16-43-55" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 语法<span class="number">4</span>：查看视图的详细定义信息</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp1;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-26_16-48-31.png" alt="Snipaste_2023-07-26_16-48-31"></p>
<h2 id="5-更新视图的数据"><a href="#5-更新视图的数据" class="headerlink" title="5. 更新视图的数据"></a>5. 更新视图的数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.</span>更新视图中的数据</span><br><span class="line"># 当视图中的数据发生变化时，数据表中的数据也会发生变化，反之亦然。</span><br><span class="line"># <span class="number">5.1</span> 一般情况，可以更新数据</span><br><span class="line"># 更新视图的数据，会导致基表中数据的修改</span><br><span class="line"><span class="keyword">UPDATE</span> vu_emp1</span><br><span class="line"><span class="keyword">SET</span> salary <span class="operator">=</span> <span class="number">20000</span></span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">101</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_17-06-20.png" alt="Snipaste_2023-07-26_17-06-20" style="zoom: 33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> emps;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_17-07-49.png" alt="Snipaste_2023-07-26_17-07-49" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 更新表中的数据，也会导致视图中的数据的修改</span><br><span class="line"><span class="keyword">UPDATE</span> emps</span><br><span class="line"><span class="keyword">SET</span> salary <span class="operator">=</span> <span class="number">10000</span></span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">101</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> vu_emp1;</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> emps;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_17-10-36.png" alt="Snipaste_2023-07-26_17-10-36" style="zoom:33%;">

<img src="Snipaste_2023-07-26_17-11-07.png" alt="Snipaste_2023-07-26_17-11-07" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.2</span> 不可更新的视图</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-26_17-24-00.png" alt="Snipaste_2023-07-26_17-24-00"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> vu_emp_sal</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id;</span><br><span class="line"># 更新失败,The target <span class="keyword">table</span> vu_emp_sal <span class="keyword">of</span> the <span class="keyword">UPDATE</span> <span class="keyword">is</span> <span class="keyword">not</span> updatable</span><br><span class="line"><span class="keyword">UPDATE</span> dbtest14.vu_emp_sal</span><br><span class="line"><span class="keyword">SET</span> avg_sal <span class="operator">=</span> <span class="number">5000</span></span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">30</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-26_17-28-57.png" alt="Snipaste_2023-07-26_17-28-57"></p>
<h2 id="6-修改删除视图"><a href="#6-修改删除视图" class="headerlink" title="6. 修改删除视图"></a>6. 修改删除视图</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.</span>修改删除视图</span><br><span class="line"># <span class="number">6.1</span> 修改视图</span><br><span class="line"># 视图vu_emp1已经存在了，现在修改它</span><br><span class="line"># 方式<span class="number">1</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> REPLACE <span class="keyword">VIEW</span> vu_emp1</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary,email</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> <span class="number">7000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> vu_emp1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_21-31-14.png" alt="Snipaste_2023-07-26_21-31-14" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 方式<span class="number">2</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> vu_emp1</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary,email</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> <span class="number">7000</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.2</span> 删除视图</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">VIEW</span> vu_emp4;</span><br><span class="line"># 说明：基于视图a、b创建了新的视图c，如果将视图a或者视图b删除，会导致视图c的查询失败。这</span><br><span class="line"># 样的视图c需要手动删除或修改，否则影响使用。</span><br></pre></td></tr></table></figure>

<h1 id="第十四章-存储过程与函数"><a href="#第十四章-存储过程与函数" class="headerlink" title="第十四章 存储过程与函数"></a>第十四章 存储过程与函数</h1><p>（首先明确：阿里巴巴规范中禁止使用存储过程，所以本节内容可以在使用的时候现去看，相关细节去看课件或者书）</p>
<h2 id="1-存储过程"><a href="#1-存储过程" class="headerlink" title="1. 存储过程"></a>1. 存储过程</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">0.</span>准备工作</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE dbtest15;</span><br><span class="line"></span><br><span class="line">USE dbtest15;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employees</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> atguigudb.employees;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> departments</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> atguigudb.departments;</span><br><span class="line"># <span class="number">1.</span>创建存储过程</span><br><span class="line"># 类型<span class="number">1</span>：无参数无返回值</span><br><span class="line"># 举例<span class="number">1</span>：创建存储过程select_all_data(),查看emps表的所有数据</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> select_all_data()</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> employees;</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_10-03-39.png" alt="Snipaste_2023-07-27_10-03-39" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span>存储过程的调用</span><br><span class="line"><span class="keyword">CALL</span> select_all_data();</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_10-05-15.png" alt="Snipaste_2023-07-27_10-05-15" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 举例<span class="number">2</span>：创建存储过程avg_employee_salary(),返回所有员工的平均工资</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> avg_employee_salary()</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">CALL</span> avg_employee_salary();</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_10-20-43.png" alt="Snipaste_2023-07-27_10-20-43" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 举例<span class="number">3</span>：创建存储过程show_max_salary()，用来查看“emps”表的最高薪资值。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> show_max_salary()</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MAX</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">CALL</span> show_max_salary();</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_10-33-34.png" alt="Snipaste_2023-07-27_10-33-34" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 类型<span class="number">2</span>：带<span class="keyword">OUT</span></span><br><span class="line"># 举例<span class="number">4</span>：创建存储过程show_min_salary()，查看“emps”表的最低薪资值。并将最低薪资通过<span class="keyword">OUT</span>参数“ms”</span><br><span class="line"># 输出</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> show_min_salary(<span class="keyword">OUT</span> ms <span class="keyword">DOUBLE</span>)</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(salary) <span class="keyword">INTO</span> ms</span><br><span class="line">    <span class="keyword">FROM</span> employees;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">CALL</span> show_min_salary(<span class="variable">@ms</span>);</span><br><span class="line"></span><br><span class="line"># 查看变量值</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@ms</span>; # <span class="number">2100</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 类型<span class="number">3</span>：带<span class="keyword">IN</span></span><br><span class="line"># 举例<span class="number">5</span>：创建存储过程show_someone_salary()，查看“emps”表的某个员工的薪资，并用<span class="keyword">IN</span>参数empname</span><br><span class="line"># 输入员工姓名。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> show_someone_salary(<span class="keyword">IN</span> empname <span class="type">VARCHAR</span>(<span class="number">20</span>))</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> salary <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> last_name <span class="operator">=</span> empname;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"># 调用方式<span class="number">1</span></span><br><span class="line"><span class="keyword">CALL</span> show_someone_salary(<span class="string">&#x27;Abel&#x27;</span>); # <span class="number">11000</span></span><br><span class="line"># 调用方式<span class="number">2</span></span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@empname</span> <span class="operator">=</span> <span class="string">&#x27;Abel&#x27;</span>;</span><br><span class="line"><span class="keyword">CALL</span> show_someone_salary(<span class="variable">@empname</span>); # <span class="number">11000</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 类型<span class="number">4</span>：带<span class="keyword">IN</span>和<span class="keyword">OUT</span></span><br><span class="line">#举例<span class="number">6</span>：创建存储过程show_someone_salary2()，查看“emps”表的某个员工的薪资，并用<span class="keyword">IN</span>参数empname</span><br><span class="line"># 输入员工姓名，用<span class="keyword">OUT</span>参数empsalary输出员工薪资。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> show_someone_salary2(<span class="keyword">IN</span> empname <span class="type">VARCHAR</span>(<span class="number">20</span>),<span class="keyword">OUT</span> empsalary <span class="type">DECIMAL</span>(<span class="number">10</span>,<span class="number">2</span>))</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> salary <span class="keyword">INTO</span> empsalary</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> last_name <span class="operator">=</span> empname;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">CALL</span> show_someone_salary2(<span class="string">&#x27;Abel&#x27;</span>,<span class="variable">@empsalary</span>); # <span class="number">11000</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@empsalary</span>; # <span class="number">11000</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 类型<span class="number">5</span>：带<span class="keyword">INOUT</span></span><br><span class="line"># 举例<span class="number">7</span>：创建存储过程show_mgr_name()，查询某个员工领导的姓名，并用<span class="keyword">INOUT</span>参数“empname”输入员</span><br><span class="line"># 工姓名，输出领导的姓名。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> show_mgr_name(<span class="keyword">INOUT</span> empname <span class="type">VARCHAR</span>(<span class="number">25</span>))</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> last_name <span class="keyword">INTO</span> empname</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> manager_id</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">WHERE</span> last_name <span class="operator">=</span> empname</span><br><span class="line">        );</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@empname</span> <span class="operator">=</span> <span class="string">&#x27;Abel&#x27;</span>;</span><br><span class="line"><span class="keyword">CALL</span> show_mgr_name(<span class="variable">@empname</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@empname</span>; # Zlotkey</span><br></pre></td></tr></table></figure>

<h2 id="2-存储函数"><a href="#2-存储函数" class="headerlink" title="2. 存储函数"></a>2. 存储函数</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 存储函数的语法分析说明：</span></span><br><span class="line"><span class="comment"> (1)存储函数也就是用户自定义函数</span></span><br><span class="line"><span class="comment"> (2)语法：</span></span><br><span class="line"><span class="comment">CREATE FUNCTION 函数名(参数名 参数类型,...)</span></span><br><span class="line"><span class="comment">RETURNS 返回值类型</span></span><br><span class="line"><span class="comment">[characteristics ...]</span></span><br><span class="line"><span class="comment">BEGIN</span></span><br><span class="line"><span class="comment">   函数体 #函数体中肯定有 RETURN 语句</span></span><br><span class="line"><span class="comment">END</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> 说明：</span></span><br><span class="line"><span class="comment"> ①参数列表：FUNCTION总是默认为IN参数</span></span><br><span class="line"><span class="comment"> ②RETURNS type 语句表示函数返回数据的类型，必须写上，必须有这个返回类型，函数体内也必须有返回值；</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> (3)调用存储函数</span></span><br><span class="line"><span class="comment"> SELECT 函数名(实参列表)</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-27_14-28-49.png" alt="Snipaste_2023-07-27_14-28-49"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 举例<span class="number">1</span>：</span><br><span class="line"># 创建存储函数，名称为email_by_name()，参数定义为空，该函数查询Abel的email，并返回，数据类型为</span><br><span class="line"># 字符串型。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> email_by_name()</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="type">VARCHAR</span>(<span class="number">25</span>)</span><br><span class="line">    <span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">RETURN</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> email <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">WHERE</span> last_name <span class="operator">=</span> <span class="string">&#x27;Abel&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SELECT</span> email_by_name();</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_14-30-35.png" alt="Snipaste_2023-07-27_14-30-35" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 举例<span class="number">2</span>：</span><br><span class="line"># 创建存储函数，名称为email_by_id()，参数传入emp_id，该函数查询emp_id的email，并返回，数据类型</span><br><span class="line"># 为字符串型。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> email_by_id(emp_id <span class="type">INT</span>)</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="type">VARCHAR</span>(<span class="number">25</span>)</span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">RETURN</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> email <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> emp_id</span><br><span class="line">        );</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SELECT</span> email_by_id(<span class="number">100</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_14-34-30.png" alt="Snipaste_2023-07-27_14-34-30" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 举例<span class="number">3</span>：</span><br><span class="line"># 创建存储函数count_by_id()，参数传入dept_id，该函数查询dept_id部门的员工人数，并返回，数据类型</span><br><span class="line"># 为整型。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> count_by_id(dept_id <span class="type">INT</span>)</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="type">INT</span></span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">RETURN</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">WHERE</span> department_id <span class="operator">=</span> dept_id</span><br><span class="line">        );</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@a</span> <span class="operator">=</span> <span class="number">30</span>;</span><br><span class="line"><span class="keyword">SELECT</span> count_by_id(<span class="variable">@a</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_14-38-07.png" alt="Snipaste_2023-07-27_14-38-07" style="zoom:50%;">

<p>对比存储函数和存储过程</p>
<p><img src="Snipaste_2023-07-27_14-39-27.png" alt="Snipaste_2023-07-27_14-39-27"></p>
<h2 id="3-存储过程和函数的查看、修改和删除"><a href="#3-存储过程和函数的查看、修改和删除" class="headerlink" title="3. 存储过程和函数的查看、修改和删除"></a>3. 存储过程和函数的查看、修改和删除</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 存储过程和函数的查看、修改、删除</span><br><span class="line"># 查看</span><br><span class="line"># <span class="number">1.</span> 使用<span class="keyword">SHOW</span> <span class="keyword">CREATE</span>语句查看存储过程和函数的创建信息</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> show_mgr_name;</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> count_by_id;</span><br><span class="line"></span><br><span class="line"># <span class="number">2.</span> 使用<span class="keyword">SHOW</span> STATUS语句查看存储过程和函数的状态信息</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">PROCEDURE</span> STATUS ;</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">FUNCTION</span> STATUS ;</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">PROCEDURE</span> STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;show_max_salary&#x27;</span>;</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">FUNCTION</span> STATUS <span class="keyword">LIKE</span> <span class="string">&#x27;email_by_id&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">3.</span> 从information_schema.Routines表中查看存储过程和函数的信息</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> information_schema.ROUTINES</span><br><span class="line"><span class="keyword">WHERE</span> ROUTINE_NAME <span class="operator">=</span> <span class="string">&#x27;email_by_id&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 修改</span><br><span class="line"># 修改存储过程或函数，不影响存储过程或函数功能，只是修改相关特性（characteristic）。</span><br><span class="line"># 使用<span class="keyword">ALTER</span>语句实现。</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">PROCEDURE</span> show_max_salary</span><br><span class="line"><span class="keyword">SQL</span> SECURITY INVOKER</span><br><span class="line">COMMENT <span class="string">&#x27;查询最高工资&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 删除</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">FUNCTION</span> IF <span class="keyword">EXISTS</span> count_by_id;</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">PROCEDURE</span> IF <span class="keyword">EXISTS</span> show_min_salary;</span><br></pre></td></tr></table></figure>

<p>注意：关于存储过程和存储函数在大厂中使用的少，但在银行和证券公司中会要求使用</p>
<h1 id="第十五章-变量、流程控制和游标"><a href="#第十五章-变量、流程控制和游标" class="headerlink" title="第十五章 变量、流程控制和游标"></a>第十五章 变量、流程控制和游标</h1><h2 id="1-变量"><a href="#1-变量" class="headerlink" title="1. 变量"></a>1. 变量</h2><h3 id="1-1-系统变量"><a href="#1-1-系统变量" class="headerlink" title="1.1 系统变量"></a>1.1 系统变量</h3><p><strong>系统变量分类</strong>：全局系统变量（global）、会话系统变量（session）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.1</span><span class="number">.1</span> 查看系统变量</span><br><span class="line"># 查看全局系统变量</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> VARIABLES ; # <span class="number">633</span></span><br><span class="line"># 查看会话系统变量</span><br><span class="line"><span class="keyword">SHOW</span> SESSION VARIABLES ; # <span class="number">657</span></span><br><span class="line"><span class="keyword">SHOW</span> VARIABLES ;# 默认查询的是会话系统变量</span><br><span class="line"># 查看部分系统变量</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">GLOBAL</span> VARIABLES <span class="keyword">LIKE</span> <span class="string">&#x27;admin_%_&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># <span class="number">1.1</span><span class="number">.2</span> 查看指定的系统变量（系统变量为@@开头）</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@GLOBAL</span>.max_connections; # <span class="number">151</span>,该变量用于限制服务器最大连接数</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@SESSION</span>.character_set_client; # utf8mb4</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@SESSION</span>.pseudo_thread_id; # <span class="number">270</span></span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@character</span>_set_client; # utf8mb4,先查询会话系统变量，再查询全局系统变量</span><br><span class="line"></span><br><span class="line"># <span class="number">1.1</span><span class="number">.3</span> 修改系统变量的值</span><br><span class="line">#  全局系统变量：</span><br><span class="line"># 方式<span class="number">1</span></span><br><span class="line"><span class="keyword">SET</span> @<span class="variable">@GLOBAL</span>.max_connections <span class="operator">=</span> <span class="number">161</span>;</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@GLOBAL</span>.max_connections; # <span class="number">161</span></span><br><span class="line"># 方式<span class="number">2</span></span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">GLOBAL</span> max_connections <span class="operator">=</span> <span class="number">171</span>;</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@GLOBAL</span>.max_connections; # <span class="number">171</span></span><br><span class="line"># 针对于当前的数据库实例是有效的，一旦重启mysql服务就失效了</span><br><span class="line"></span><br><span class="line"># 会话系统变量</span><br><span class="line"># 方式<span class="number">1</span></span><br><span class="line"><span class="keyword">SET</span> @<span class="variable">@SESSION</span>.character_set_client <span class="operator">=</span> <span class="string">&#x27;gbk&#x27;</span>;</span><br><span class="line"><span class="keyword">SELECT</span> @<span class="variable">@SESSION</span>.character_set_client; # gbk</span><br><span class="line"># 方式<span class="number">2</span></span><br><span class="line"><span class="keyword">SET</span> SESSION character_set_client <span class="operator">=</span> <span class="string">&#x27;gbk&#x27;</span>;</span><br><span class="line"></span><br><span class="line"># 针对于当前会话是有效的，一旦结束会话，重新建立起新的会话，则失效。</span><br></pre></td></tr></table></figure>

<h3 id="1-2-用户变量"><a href="#1-2-用户变量" class="headerlink" title="1.2 用户变量"></a>1.2 用户变量</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.2</span> 用户变量</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> ①用户变量：会话用户变量 VS 局部变量</span></span><br><span class="line"><span class="comment"> ②会话用户变量：使用@开头，作用域为当前会话</span></span><br><span class="line"><span class="comment"> ③局部变量：只能使用在存储过程和存储函数中的</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"># <span class="number">1.2</span><span class="number">.1</span> 会话用户变量</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> ①变量的声明和赋值</span></span><br><span class="line"><span class="comment"> #方式1：“=”或“:=”</span></span><br><span class="line"><span class="comment">SET @用户变量 = 值;</span></span><br><span class="line"><span class="comment">SET @用户变量 := 值;</span></span><br><span class="line"><span class="comment">#方式2：“:=” 或 INTO关键字</span></span><br><span class="line"><span class="comment">SELECT @用户变量 := 表达式 [FROM 等子句];</span></span><br><span class="line"><span class="comment">SELECT 表达式 INTO @用户变量 [FROM 等子句];</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> ②使用</span></span><br><span class="line"><span class="comment"> SELECT @变量名</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"># 准备工作</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE dbtest16;</span><br><span class="line">USE dbtest16;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employees</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> atguigudb.employees;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> departments</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> atguigudb.departments;</span><br><span class="line"># 测试</span><br><span class="line"># 方式<span class="number">1</span>：</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@m1</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@m2</span> <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@sum</span> <span class="operator">=</span> <span class="variable">@m1</span> <span class="operator">+</span> <span class="variable">@m2</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@sum</span>;# <span class="number">3</span></span><br><span class="line"># 方式<span class="number">2</span>：</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@count</span> :<span class="operator">=</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> employees; # <span class="number">107</span></span><br><span class="line"># <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">INTO</span> <span class="variable">@count</span> <span class="keyword">FROM</span> employees; 等价语句</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@count</span>; # <span class="number">107</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) <span class="keyword">INTO</span> <span class="variable">@avg</span>_sal <span class="keyword">FROM</span> employees;</span><br><span class="line"># <span class="keyword">SELECT</span> <span class="variable">@avg</span>_sal :<span class="operator">=</span> <span class="built_in">AVG</span>(salary) <span class="keyword">FROM</span> employees; 等价语句</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@avg</span>_sal; # <span class="number">6461.682242990654</span></span><br><span class="line"></span><br><span class="line"># <span class="number">1.2</span><span class="number">.2</span> 局部变量</span><br><span class="line"># 使用<span class="keyword">DECLARE</span>语句定义一个局部变量，其作用域只在BEGIN..END中有效</span><br><span class="line"># 只能放在BEGIN..END中，而且只能放在第一句</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> BEGIN</span></span><br><span class="line"><span class="comment">    #声明局部变量，如果没有DEFAULT子句，初始值为NULL</span></span><br><span class="line"><span class="comment">    DECLARE 变量名1 变量数据类型 [DEFAULT 变量默认值];</span></span><br><span class="line"><span class="comment">    DECLARE 变量名2,变量名3,... 变量数据类型 [DEFAULT 变量默认值];</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    #为局部变量赋值</span></span><br><span class="line"><span class="comment">    SET 变量名1 = 值;</span></span><br><span class="line"><span class="comment">    SELECT 值 INTO 变量名2 [FROM 子句];</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    #查看局部变量的值</span></span><br><span class="line"><span class="comment">    SELECT 变量1,变量2,变量3;</span></span><br><span class="line"><span class="comment">END</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> test_var()</span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    # 声明局部变量</span><br><span class="line">    <span class="keyword">DECLARE</span> a <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">DECLARE</span> b <span class="type">INT</span>;</span><br><span class="line">    <span class="keyword">DECLARE</span> emp_name <span class="type">VARCHAR</span>(<span class="number">25</span>);</span><br><span class="line">    # 赋值</span><br><span class="line">    <span class="keyword">SET</span> a <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">SET</span> b <span class="operator">=</span> <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">SELECT</span> last_name <span class="keyword">INTO</span> emp_name</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">101</span>;</span><br><span class="line">    # 使用</span><br><span class="line">    <span class="keyword">SELECT</span> a,b,emp_name;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"># 调用存储过程</span><br><span class="line"><span class="keyword">CALL</span> test_var();</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-31_17-16-54.png" alt="Snipaste_2023-07-31_17-16-54" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 举例<span class="number">1</span>：声明局部变量，并分别赋值为employees表中employee_id为<span class="number">102</span>的last_name和salary</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> test_pro()</span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">DECLARE</span> emp_name <span class="type">VARCHAR</span>(<span class="number">25</span>);</span><br><span class="line">    <span class="keyword">DECLARE</span> sal <span class="keyword">DOUBLE</span>(<span class="number">10</span>,<span class="number">2</span>) <span class="keyword">DEFAULT</span> <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">SELECT</span> last_name,salary <span class="keyword">INTO</span> emp_name,sal</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">102</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">SELECT</span> emp_name,sal;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"># 调用存储过程</span><br><span class="line"><span class="keyword">CALL</span> test_pro();</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-31_19-13-56.png" alt="Snipaste_2023-07-31_19-13-56" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 举例<span class="number">2</span>：声明两个变量，求和并打印 （分别使用会话用户变量、局部变量的方式实现）</span><br><span class="line"># 方式<span class="number">1</span>：使用会话用户变量</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@v1</span> :<span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@v2</span> :<span class="operator">=</span> <span class="number">20</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@result</span> :<span class="operator">=</span> <span class="variable">@v1</span> <span class="operator">+</span> <span class="variable">@v2</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@result</span>; # <span class="number">30</span></span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：使用局部变量</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> add_value()</span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">DECLARE</span> value1,value2 <span class="type">INT</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">SET</span> value1 :<span class="operator">=</span> <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">SET</span> value2 :<span class="operator">=</span> <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">SET</span> <span class="variable">@sum</span>_val <span class="operator">=</span> value1 <span class="operator">+</span> value2;</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="variable">@sum</span>_val;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CALL</span> add_value(); # <span class="number">110</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 举例<span class="number">3</span>：创建存储过程“different_salary”查询某员工和他领导的薪资差距，并用<span class="keyword">IN</span>参数emp_id接收员工</span><br><span class="line"># id，用<span class="keyword">OUT</span>参数dif_salary输出薪资差距结果。</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> different_salary(<span class="keyword">IN</span> emp_id <span class="type">INT</span>,<span class="keyword">OUT</span> dif_salary <span class="keyword">DOUBLE</span> )</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    # 分析：查询出emp_id员工的工资，查询出emp_id员工的管理者的id，查询出管理者id的工资</span><br><span class="line">    # 计算两个工资的差值</span><br><span class="line">    # 声明变量</span><br><span class="line">    <span class="keyword">DECLARE</span> emp_sal <span class="keyword">DOUBLE</span> <span class="keyword">DEFAULT</span> <span class="number">0.0</span>;# 记录员工的工资</span><br><span class="line">    <span class="keyword">DECLARE</span> mgr_sal <span class="keyword">DOUBLE</span> <span class="keyword">DEFAULT</span> <span class="number">0.0</span>; # 记录管理者的工资</span><br><span class="line">    <span class="keyword">DECLARE</span> mgr_id <span class="type">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>; # 记录管理者的id</span><br><span class="line"></span><br><span class="line">    <span class="keyword">SELECT</span> salary <span class="keyword">INTO</span> emp_sal <span class="keyword">FROM</span> employees <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> emp_id;</span><br><span class="line">    <span class="keyword">SELECT</span> manager_id <span class="keyword">INTO</span> mgr_id <span class="keyword">FROM</span> employees <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> emp_id;</span><br><span class="line">    <span class="keyword">SELECT</span> salary <span class="keyword">INTO</span> mgr_sal <span class="keyword">FROM</span> employees <span class="keyword">WHERE</span> employee_id <span class="operator">=</span> mgr_id;</span><br><span class="line">    <span class="keyword">SET</span> dif_salary <span class="operator">=</span> mgr_sal <span class="operator">-</span> emp_sal;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用存储过程</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@emp</span>_id :<span class="operator">=</span> <span class="number">102</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@dif</span>_sal :<span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">CALL</span> different_salary(<span class="variable">@emp</span>_id,<span class="variable">@dif</span>_sal);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@dif</span>_sal; # <span class="number">7000</span></span><br></pre></td></tr></table></figure>

<h2 id="2-定义条件与处理程序"><a href="#2-定义条件与处理程序" class="headerlink" title="2. 定义条件与处理程序"></a>2. 定义条件与处理程序</h2><h3 id="2-1-案例分析"><a href="#2-1-案例分析" class="headerlink" title="2.1 案例分析"></a>2.1 案例分析</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 2. 定义条件与处理程序</span><br><span class="line"># 定义条件：事先定义程序执行过程中可能遇到的问题</span><br><span class="line"># 处理程序：定义了在遇到问题时应当采取的处理方式，并且并且保证存储过程</span><br><span class="line"># 或函数在遇到警告或错误时能继续执行。</span><br><span class="line"></span><br><span class="line"># 2.1 案例分析</span><br><span class="line">CREATE PROCEDURE UpdateDataNoCondition()</span><br><span class="line">BEGIN</span><br><span class="line">    SET @x = 1;</span><br><span class="line">    UPDATE employees SET email = NULL WHERE last_name = &#x27;Abel&#x27;;</span><br><span class="line">    SET @x = 2;</span><br><span class="line">    UPDATE employees SET email = &#x27;aabbel&#x27; WHERE last_name = &#x27;Abel&#x27;;</span><br><span class="line">    SET @x = 3;</span><br><span class="line">END;</span><br><span class="line"></span><br><span class="line"># 调用存储过程</span><br><span class="line"># 错误代码：1048</span><br><span class="line"># Column &#x27;email&#x27; cannot be null</span><br><span class="line">CALL UpdateDataNoCondition();</span><br><span class="line">SELECT @x; # 1;</span><br></pre></td></tr></table></figure>

<h3 id="2-2-定义条件"><a href="#2-2-定义条件" class="headerlink" title="2.2 定义条件"></a>2.2 定义条件</h3><p><img src="Snipaste_2023-08-07_18-41-09.png" alt="Snipaste_2023-08-07_18-41-09"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 举例1：定义“Field_Not_Be_NULL”错误名与MySQL中违反非空约束的错误类型是“ERROR 1048 (23000)”对</span><br><span class="line"># 应。</span><br><span class="line"></span><br><span class="line">#使用MySQL_error_code</span><br><span class="line">DECLARE Field_Not_Be_NULL CONDITION FOR 1048;</span><br><span class="line">#使用sqlstate_value</span><br><span class="line">DECLARE Field_Not_Be_NULL CONDITION FOR SQLSTATE &#x27;23000&#x27;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 举例2：定义&quot;ERROR 1148(42000)&quot;错误，名称为command_not_allowed。</span><br><span class="line"></span><br><span class="line">#使用MySQL_error_code</span><br><span class="line">DECLARE command_not_allowed CONDITION FOR 1148;</span><br><span class="line">#使用sqlstate_value</span><br><span class="line">DECLARE command_not_allowed CONDITION FOR SQLSTATE &#x27;42000&#x27;;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-定义处理程序"><a href="#2-3-定义处理程序" class="headerlink" title="2.3 定义处理程序"></a>2.3 定义处理程序</h3><p><img src="Snipaste_2023-08-07_21-48-13.png" alt="Snipaste_2023-08-07_21-48-13"></p>
<p>举例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#方法1：捕获sqlstate_value</span><br><span class="line">DECLARE CONTINUE HANDLER FOR SQLSTATE &#x27;42S02&#x27; SET @info = &#x27;NO_SUCH_TABLE&#x27;;</span><br><span class="line">#方法2：捕获mysql_error_value</span><br><span class="line">DECLARE CONTINUE HANDLER FOR 1146 SET @info = &#x27;NO_SUCH_TABLE&#x27;;</span><br><span class="line">#方法3：先定义条件，再调用</span><br><span class="line">DECLARE NO_SUCH_TABLE CONDITION FOR 1146;</span><br><span class="line">DECLARE CONTINUE HANDLER FOR NO_SUCH_TABLE SET @info = &#x27;NO_SUCH_TABLE&#x27;;</span><br><span class="line">#方法4：使用SQLWARNING</span><br><span class="line">DECLARE EXIT HANDLER FOR SQLWARNING SET @info = &#x27;ERROR&#x27;;</span><br><span class="line">#方法5：使用NOT FOUND</span><br><span class="line">DECLARE EXIT HANDLER FOR NOT FOUND SET @info = &#x27;NO_SUCH_TABLE&#x27;;</span><br><span class="line">#方法6：使用SQLEXCEPTION</span><br><span class="line">DECLARE EXIT HANDLER FOR SQLEXCEPTION SET @info = &#x27;ERROR&#x27;;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-案例解决"><a href="#2-4-案例解决" class="headerlink" title="2.4 案例解决"></a>2.4 案例解决</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 重新定义存储过程，体现错误的处理程序</span><br><span class="line">CREATE PROCEDURE UpdateDataNoCondition()</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明处理程序</span><br><span class="line">    DECLARE CONTINUE HANDLER FOR 1048 SET @pro_value = -1;</span><br><span class="line">    SET @x = 1;</span><br><span class="line">    UPDATE employees SET email = NULL WHERE last_name = &#x27;Abel&#x27;;</span><br><span class="line">    SET @x = 2;</span><br><span class="line">    UPDATE employees SET email = &#x27;aabbel&#x27; WHERE last_name = &#x27;Abel&#x27;;</span><br><span class="line">    SET @x = 3;</span><br><span class="line">END;</span><br><span class="line"># 调用存储过程</span><br><span class="line">CALL UpdateDataNoCondition();</span><br><span class="line"># 查看变量</span><br><span class="line">SELECT @x,@pro_value;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-07_22-07-55.png" alt="Snipaste_2023-08-07_22-07-55" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 举例2</span><br><span class="line">#准备工作</span><br><span class="line">ALTER TABLE departments</span><br><span class="line">ADD CONSTRAINT uk_dept_name UNIQUE(department_id);</span><br><span class="line"># 定义存储过程</span><br><span class="line">CREATE PROCEDURE InsertDataWithCondition()</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 处理程序</span><br><span class="line">    DECLARE duplicate_entry CONDITION FOR 1062;</span><br><span class="line">    DECLARE EXIT HANDLER FOR duplicate_entry SET @pro_value = -2;</span><br><span class="line">    SET @x = 1;</span><br><span class="line">    INSERT INTO departments(department_name) VALUES (&#x27;测试&#x27;);</span><br><span class="line">    SET @x = 2;</span><br><span class="line">    INSERT INTO departments(department_name) VALUES (&#x27;测试&#x27;);</span><br><span class="line">    SET @x = 3;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用过程</span><br><span class="line">CALL InsertDataWithCondition();</span><br><span class="line"># 查看变量</span><br><span class="line">SELECT @x,@pro_value;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-07_22-28-14.png" alt="Snipaste_2023-08-07_22-28-14" style="zoom:50%;">

<h2 id="3-流程控制"><a href="#3-流程控制" class="headerlink" title="3. 流程控制"></a>3. 流程控制</h2><h3 id="3-1-分支结构之IF"><a href="#3-1-分支结构之IF" class="headerlink" title="3.1 分支结构之IF"></a>3.1 分支结构之IF</h3><img src="Snipaste_2023-08-08_09-22-09.png" alt="Snipaste_2023-08-08_09-22-09" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 举例1</span><br><span class="line">CREATE PROCEDURE test_if()</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明局部变量</span><br><span class="line">    DECLARE stu_name VARCHAR(15);</span><br><span class="line">    IF stu_name IS NULL</span><br><span class="line">        THEN SELECT &#x27;stu_name is null&#x27;;</span><br><span class="line">    END IF;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">CALL test_if();# stu_name is null</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 举例2</span><br><span class="line">CREATE PROCEDURE test_if1()</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE age INT DEFAULT 20;</span><br><span class="line">    IF age &gt; 40</span><br><span class="line">        THEN SELECT &#x27;中老年&#x27;;</span><br><span class="line">    ELSEIF age &gt; 18</span><br><span class="line">        THEN SELECT &#x27;青壮年&#x27;;</span><br><span class="line">    ELSEIF age &gt; 8</span><br><span class="line">        THEN SELECT &#x27;少年&#x27;;</span><br><span class="line">    ELSE</span><br><span class="line">        SELECT &#x27;婴幼儿&#x27;;</span><br><span class="line">    END IF;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">CALL test_if1(); # 青壮年</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 举例2：声明存储过程“update_salary_by_eid1”，定义IN参数emp_id，输入员工编号。判断该员工</span><br><span class="line"># 薪资如果低于8000元并且入职时间超过5年，就涨薪500元；否则就不变。</span><br><span class="line">CREATE PROCEDURE update_salary_by_eid1(IN emp_id INT)</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明局部变量</span><br><span class="line">    DECLARE emp_sal DOUBLE;</span><br><span class="line">    DECLARE hire_year DOUBLE;</span><br><span class="line">    # 赋值</span><br><span class="line">    SELECT salary INTO emp_sal</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    SELECT DATEDIFF(CURDATE(),hire_date)/365 INTO hire_year</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    # 判断</span><br><span class="line">    IF emp_sal &lt; 8000 AND hire_year &gt;= 5</span><br><span class="line">        THEN UPDATE employees SET salary = salary + 500 WHERE employee_id = emp_id;</span><br><span class="line">    END IF;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 先查询一下入职超过五年且工资低于8000的员工号</span><br><span class="line">SELECT DATEDIFF(CURDATE(),hire_date)/365,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE salary &lt; 8000 AND DATEDIFF(CURDATE(),hire_date)/365 &gt;=5;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_10-10-20.png" alt="Snipaste_2023-08-08_10-10-20" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 调用</span><br><span class="line">CALL update_salary_by_eid1(104);</span><br><span class="line"></span><br><span class="line"># 再查询一下入职超过五年且工资低于8000的员工号</span><br><span class="line">SELECT DATEDIFF(CURDATE(),hire_date)/365,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE salary &lt; 8000 AND DATEDIFF(CURDATE(),hire_date)/365 &gt;=5;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_10-11-21.png" alt="Snipaste_2023-08-08_10-11-21" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 举例3：声明存储过程“update_salary_by_eid2”，定义IN参数emp_id，输入员工编号。判断该员工</span><br><span class="line"># 薪资如果低于9000元并且入职时间超过5年，就涨薪500元；否则就涨薪100元。</span><br><span class="line">CREATE PROCEDURE update_salary_by_eid2(IN emp_id INT)</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明局部变量</span><br><span class="line">    DECLARE emp_sal DOUBLE;</span><br><span class="line">    DECLARE hire_year DOUBLE;</span><br><span class="line">    # 赋值</span><br><span class="line">    SELECT salary INTO emp_sal</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    SELECT DATEDIFF(CURDATE(),hire_date)/365 INTO hire_year</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    # 判断</span><br><span class="line">    IF emp_sal &lt; 9000 AND hire_year &gt;= 5</span><br><span class="line">        THEN UPDATE employees SET salary = salary + 500 WHERE employee_id = emp_id;</span><br><span class="line">    ELSE</span><br><span class="line">        UPDATE employees SET salary = salary + 100 WHERE employee_id = emp_id;</span><br><span class="line">    END IF;</span><br><span class="line">end;</span><br><span class="line"># 查询一下</span><br><span class="line">SELECT DATEDIFF(CURDATE(),hire_date)/365,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id IN (103,104);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_10-27-17.png" alt="Snipaste_2023-08-08_10-27-17" style="zoom: 50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 调用</span><br><span class="line">CALL update_salary_by_eid2(103);</span><br><span class="line">CALL update_salary_by_eid2(104);</span><br><span class="line"></span><br><span class="line"># 再查询一下</span><br><span class="line">SELECT DATEDIFF(CURDATE(),hire_date)/365,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id IN (103,104);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_10-28-16.png" alt="Snipaste_2023-08-08_10-28-16" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># 举例4：声明存储过程“update_salary_by_eid3”，定义IN参数emp_id，输入员工编号。判断该员工</span><br><span class="line"># 薪资如果低于9000元，就更新薪资为9000元；薪资如果大于等于9000元且低于10000的，但是奖金</span><br><span class="line"># 比例为NULL的，就更新奖金比例为0.01；其他的涨薪100元。</span><br><span class="line">CREATE PROCEDURE update_salary_by_eid3(IN emp_id INT)</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    DECLARE emp_sal DOUBLE;# 记录员工工资</span><br><span class="line">    DECLARE bonus DOUBLE;# 记录员工的奖金率</span><br><span class="line"></span><br><span class="line">    # 赋值</span><br><span class="line">    SELECT salary INTO emp_sal</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    SELECT commission_pct INTO bonus</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    # 判断</span><br><span class="line">    IF emp_sal &lt; 9000</span><br><span class="line">        THEN UPDATE employees SET salary = 9000 WHERE employee_id = emp_id;</span><br><span class="line">    ELSEIF emp_sal &lt; 10000 AND bonus IS NULL</span><br><span class="line">        THEN UPDATE employees SET commission_pct = 0.01 WHERE employee_id = emp_id;</span><br><span class="line">    ELSE</span><br><span class="line">        UPDATE employees SET salary = salary + 100 WHERE employee_id = emp_id;</span><br><span class="line">    END IF;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 查询一下</span><br><span class="line">SELECT commission_pct,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id IN (102,103,104);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_10-51-59.png" alt="Snipaste_2023-08-08_10-51-59" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 调用</span><br><span class="line">CALL update_salary_by_eid3(102);</span><br><span class="line">CALL update_salary_by_eid3(103);</span><br><span class="line">CALL update_salary_by_eid3(104);</span><br><span class="line"></span><br><span class="line"># 再查询一下</span><br><span class="line">SELECT commission_pct,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id IN (102,103,104);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_10-53-17.png" alt="Snipaste_2023-08-08_10-53-17" style="zoom:50%;">

<h3 id="3-2-分支结构之CASE"><a href="#3-2-分支结构之CASE" class="headerlink" title="3.2 分支结构之CASE"></a>3.2 分支结构之CASE</h3><p><img src="Snipaste_2023-08-08_11-04-43.png" alt="Snipaste_2023-08-08_11-04-43"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 举例1</span><br><span class="line">CREATE PROCEDURE test_case()</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE var INT DEFAULT 2;</span><br><span class="line"></span><br><span class="line">    CASE var</span><br><span class="line">        WHEN 1 THEN SELECT &#x27;var = 1&#x27;;</span><br><span class="line">        WHEN 2 THEN SELECT &#x27;var = 2&#x27;;</span><br><span class="line">        WHEN 3 THEN SELECT &#x27;var = 3&#x27;;</span><br><span class="line">        ELSE SELECT &#x27;other value&#x27;;</span><br><span class="line">    END CASE;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">CALL test_case(); # var = 2</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 举例2：声明存储过程“update_salary_by_eid4”，定义IN参数emp_id，输入员工编号。判断该员工</span><br><span class="line"># 薪资如果低于9000元，就更新薪资为9000元；薪资大于等于9000元且低于10000的，但是奖金比例</span><br><span class="line"># 为NULL的，就更新奖金比例为0.01；其他的涨薪100元。</span><br><span class="line">CREATE PROCEDURE update_salary_by_eid4(IN emp_id INT)</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明局部变量</span><br><span class="line">    DECLARE emp_sal DOUBLE;</span><br><span class="line">    DECLARE bonus DOUBLE;</span><br><span class="line"></span><br><span class="line">    # 局部变量赋值</span><br><span class="line">    SELECT salary INTO emp_sal</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    SELECT commission_pct INTO bonus</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    CASE</span><br><span class="line">        WHEN emp_sal &lt; 9000 THEN UPDATE employees SET salary = 9000 WHERE employee_id = emp_id;</span><br><span class="line">        WHEN emp_sal &lt; 10000 AND bonus IS NULL THEN UPDATE employees SET commission_pct = 0.01 WHERE employee_id = emp_id;</span><br><span class="line">        ELSE UPDATE employees SET salary = salary + 100 WHERE employee_id = emp_id;</span><br><span class="line">        END CASE;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 查询一下</span><br><span class="line">SELECT commission_pct,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id IN (103,104,105);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_21-42-47.png" alt="Snipaste_2023-08-08_21-42-47" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 调用过程</span><br><span class="line">CALL update_salary_by_eid4(103);</span><br><span class="line">CALL update_salary_by_eid4(104);</span><br><span class="line">CALL update_salary_by_eid4(105);</span><br><span class="line"></span><br><span class="line"># 再查询一下</span><br><span class="line">SELECT commission_pct,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id IN (103,104,105);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_21-44-04.png" alt="Snipaste_2023-08-08_21-44-04" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 举例3：声明存储过程update_salary_by_eid5，定义IN参数emp_id，输入员工编号。判断该员工的</span><br><span class="line"># 入职年限，如果是0年，薪资涨50；如果是1年，薪资涨100；如果是2年，薪资涨200；如果是3年，</span><br><span class="line"># 薪资涨300；如果是4年，薪资涨400；其他的涨薪500。</span><br><span class="line">CREATE PROCEDURE update_salary_by_eid5(IN emp_id INT)</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明局部变量</span><br><span class="line">    DECLARE hire_year INT;</span><br><span class="line"></span><br><span class="line">    # 赋值</span><br><span class="line">    SELECT ROUND(DATEDIFF(CURDATE(),hire_date)/365) INTO hire_year</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = emp_id;</span><br><span class="line"></span><br><span class="line">    # 判断</span><br><span class="line">    CASE hire_year</span><br><span class="line">        WHEN 0 THEN UPDATE employees SET salary = salary + 50 WHERE employee_id = emp_id;</span><br><span class="line">        WHEN 1 THEN UPDATE employees SET salary = salary + 100 WHERE employee_id = emp_id;</span><br><span class="line">        WHEN 2 THEN UPDATE employees SET salary = salary + 200 WHERE employee_id = emp_id;</span><br><span class="line">        WHEN 3 THEN UPDATE employees SET salary = salary + 300 WHERE employee_id = emp_id;</span><br><span class="line">        WHEN 4 THEN UPDATE employees SET salary = salary + 400 WHERE employee_id = emp_id;</span><br><span class="line">        ELSE UPDATE employees SET salary = salary + 500 WHERE employee_id = emp_id;</span><br><span class="line">    END CASE;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 查询一下</span><br><span class="line">SELECT hire_date,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id = 101;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_22-37-17.png" alt="Snipaste_2023-08-08_22-37-17" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 调用</span><br><span class="line">CALL update_salary_by_eid5(101);</span><br><span class="line"></span><br><span class="line"># 再查询一下</span><br><span class="line">SELECT hire_date,employee_id,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE employee_id = 101;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-08_22-38-17.png" alt="Snipaste_2023-08-08_22-38-17" style="zoom:50%;">

<h3 id="3-3-循环结构之LOOP"><a href="#3-3-循环结构之LOOP" class="headerlink" title="3.3 循环结构之LOOP"></a>3.3 循环结构之LOOP</h3><p>LOOP循环语句用来重复执行某些语句。LOOP内的语句一直重复执行直到循环被退出（使用LEAVE子句），跳出循环过程。</p>
<p>LOOP语句的基本格式如下：</p>
<img src="Snipaste_2023-08-09_08-41-21.png" alt="Snipaste_2023-08-09_08-41-21" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 举例1：</span><br><span class="line">CREATE PROCEDURE test_loop()</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明局部变量</span><br><span class="line">    DECLARE num INT DEFAULT 1;</span><br><span class="line"></span><br><span class="line">    loop_label:LOOP</span><br><span class="line">        SET num = num + 1;</span><br><span class="line">        IF num &gt;= 10 THEN LEAVE loop_label;</span><br><span class="line">        END IF;</span><br><span class="line">    end loop loop_label;</span><br><span class="line"></span><br><span class="line">    # 查看num</span><br><span class="line">    SELECT num;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">CALL test_loop(); # 10</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># 举例2：当市场环境变好时，公司为了奖励大家，决定给大家涨工资。声明存储过程</span><br><span class="line"># “update_salary_loop()”，声明OUT参数num，输出循环次数。存储过程中实现循环给大家涨薪，薪资涨为</span><br><span class="line"># 原来的1.1倍。直到全公司的平均薪资达到12000结束。并统计循环次数。</span><br><span class="line">CREATE PROCEDURE update_salary_loop(OUT num INT)</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    DECLARE avg_sal DOUBLE; # 记录员工的平均工资</span><br><span class="line">    DECLARE loop_count INT DEFAULT 0; #记录循环的次数</span><br><span class="line"></span><br><span class="line">    # 获取员工的平均工资</span><br><span class="line">    SELECT AVG(salary) INTO avg_sal FROM employees;</span><br><span class="line"></span><br><span class="line">    loop_lab:LOOP</span><br><span class="line">        # 结束循环的条件</span><br><span class="line">        IF avg_sal &gt;= 12000</span><br><span class="line">            THEN LEAVE loop_lab;</span><br><span class="line">        END IF;</span><br><span class="line"></span><br><span class="line">        # 如果低于12000，更新员工的工资</span><br><span class="line">        UPDATE employees SET salary = salary * 1.1;</span><br><span class="line"></span><br><span class="line">        # 更新avg_sal变量的值</span><br><span class="line">        SELECT AVG(salary) INTO avg_sal FROM employees;</span><br><span class="line"></span><br><span class="line">        # 记录循环次数</span><br><span class="line">        SET loop_count = loop_count + 1;</span><br><span class="line"></span><br><span class="line">    end loop loop_lab;</span><br><span class="line"></span><br><span class="line">    # 给num赋值</span><br><span class="line">    SET num = loop_count;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 查询一下</span><br><span class="line">SELECT AVG(salary) FROM employees; # 6536.448598</span><br><span class="line"># 调用</span><br><span class="line">CALL update_salary_loop(@num);</span><br><span class="line">SELECT @num; # 7</span><br><span class="line"># 再查询一下</span><br><span class="line">SELECT AVG(salary) FROM employees; # 12737.69</span><br></pre></td></tr></table></figure>

<h3 id="3-4-循环结构之-WHILE"><a href="#3-4-循环结构之-WHILE" class="headerlink" title="3.4  循环结构之 WHILE"></a>3.4  <strong>循环结构之</strong> <strong>WHILE</strong></h3><p><img src="Snipaste_2023-08-09_09-17-55.png" alt="Snipaste_2023-08-09_09-17-55"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 举例1</span><br><span class="line">CREATE PROCEDURE test_while()</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE num INT DEFAULT 1;</span><br><span class="line"></span><br><span class="line">    WHILE num &lt;= 10 DO</span><br><span class="line">        # 循环体略</span><br><span class="line">        # 迭代条件</span><br><span class="line">        SET num = num + 1;</span><br><span class="line">    end while;</span><br><span class="line"></span><br><span class="line">    SELECT num;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line">CALL test_while(); # 11</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># 举例2：市场环境不好时，公司为了渡过难关，决定暂时降低大家的薪资。声明存储过程</span><br><span class="line"># “update_salary_while()”，声明OUT参数num，输出循环次数。存储过程中实现循环给大家降薪，薪资降</span><br><span class="line"># 为原来的90%。直到全公司的平均薪资达到5000结束。并统计循环次数。</span><br><span class="line">CREATE PROCEDURE update_salary_while(OUT num INT)</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    DECLARE avg_sal DOUBLE; # 记录平均工资</span><br><span class="line">    DECLARE while_count INT DEFAULT 0; # 记录循环次数</span><br><span class="line"></span><br><span class="line">    # 赋值</span><br><span class="line">    SELECT AVG(salary) INTO avg_sal FROM employees;</span><br><span class="line"></span><br><span class="line">    WHILE avg_sal &gt; 5000 DO</span><br><span class="line">        SET while_count = while_count + 1;</span><br><span class="line">        UPDATE employees SET salary = salary * 0.9;</span><br><span class="line">        SELECT AVG(salary) INTO avg_sal FROM employees;</span><br><span class="line">    end while;</span><br><span class="line"></span><br><span class="line">    # 给num赋值</span><br><span class="line">    SET num = while_count;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 先查询一下</span><br><span class="line">SELECT AVG(salary) FROM employees; # 12737.69</span><br><span class="line"># 调用</span><br><span class="line">CALL update_salary_while(@num);</span><br><span class="line">SELECT @num; # 9</span><br><span class="line"># 再查询一下</span><br><span class="line">SELECT AVG(salary) FROM employees; # 4934.842336</span><br></pre></td></tr></table></figure>

<h3 id="3-5-循环结构之REPEAT"><a href="#3-5-循环结构之REPEAT" class="headerlink" title="3.5 循环结构之REPEAT"></a>3.5 循环结构之REPEAT</h3><p>REPEAT语句创建一个带条件判断的循环过程。与WHILE循环不同的是，REPEAT 循环首先会执行一次循环，然后在 UNTIL 中进行表达式的判断，如果满足条件就退出，即 END REPEAT；如果条件不满足，则会就继续执行循环，直到满足退出条件为止。</p>
<p>REPEAT语句的基本格式如下：</p>
<p><img src="Snipaste_2023-08-09_11-02-28.png" alt="Snipaste_2023-08-09_11-02-28"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 举例1：</span><br><span class="line">CREATE PROCEDURE test_repeat()</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    DECLARE num INT DEFAULT 0;</span><br><span class="line"></span><br><span class="line">    REPEAT</span><br><span class="line">        SET num = num + 1;</span><br><span class="line">    until  num &gt;= 10</span><br><span class="line">    end repeat;</span><br><span class="line"></span><br><span class="line">    SELECT num;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line">CALL test_repeat(); # 10</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 举例2：当市场环境变好时，公司为了奖励大家，决定给大家涨工资。声明存储过程</span><br><span class="line"># “update_salary_repeat()”，声明OUT参数num，输出循环次数。存储过程中实现循环给大家涨薪，薪资涨</span><br><span class="line"># 为原来的1.15倍。直到全公司的平均薪资达到13000结束。并统计循环次数。</span><br><span class="line">CREATE PROCEDURE update_salary_repeat(OUT num INT)</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    DECLARE avg_sal DOUBLE; # 记录平均工资</span><br><span class="line">    DECLARE repeat_count INT DEFAULT 0; # 记录循环次数</span><br><span class="line"></span><br><span class="line">    # 赋值</span><br><span class="line">    SELECT AVG(salary) INTO avg_sal FROM employees;</span><br><span class="line"></span><br><span class="line">    REPEAT</span><br><span class="line">        SET repeat_count = repeat_count + 1;</span><br><span class="line">        UPDATE employees SET salary = salary * 1.15;</span><br><span class="line">        SELECT AVG(salary) INTO avg_sal FROM employees;</span><br><span class="line">    until avg_sal &gt;= 13000</span><br><span class="line">    end repeat;</span><br><span class="line"></span><br><span class="line">    # 给num赋值</span><br><span class="line">    SET num = repeat_count;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 先查询一下</span><br><span class="line">SELECT AVG(salary) FROM employees; # 4934.842336</span><br><span class="line"># 调用</span><br><span class="line">CALL update_salary_repeat(@num);</span><br><span class="line">SELECT @num; # 7</span><br><span class="line"># 再查询一下</span><br><span class="line">SELECT AVG(salary) FROM employees; # 13126.774019</span><br></pre></td></tr></table></figure>

<p><strong>对比三种循环</strong></p>
<ol>
<li>这三种循环都可以省略名称，但如果循环中添加了循环控制语句（LEAVE或ITERATE）则必须添加名称。</li>
<li>LOOP：一般用于实现简单的“死”循环</li>
<li>WHILE：先判断后执行</li>
<li>REPEAT：先执行后判断，至少执行一次</li>
</ol>
<h3 id="3-6-跳转语句之LEAVE语句（相当于JAVA中的BREAK）"><a href="#3-6-跳转语句之LEAVE语句（相当于JAVA中的BREAK）" class="headerlink" title="3.6 跳转语句之LEAVE语句（相当于JAVA中的BREAK）"></a>3.6 跳转语句之LEAVE语句（相当于JAVA中的BREAK）</h3><p><img src="Snipaste_2023-08-09_11-53-29.png" alt="Snipaste_2023-08-09_11-53-29"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line">举例1：创建存储过程 “leave_begin()”，声明INT类型的IN参数num。给BEGIN...END加标记名，并在</span><br><span class="line">BEGIN...END中使用IF语句判断num参数的值。</span><br><span class="line">如果num&lt;=0，则使用LEAVE语句退出BEGIN...END；</span><br><span class="line">如果num=1，则查询“employees”表的平均薪资；</span><br><span class="line">如果num=2，则查询“employees”表的最低薪资；</span><br><span class="line">如果num&gt;2，则查询“employees”表的最高薪资。</span><br><span class="line">IF语句结束后查询“employees”表的总人数。</span><br><span class="line"> */</span><br><span class="line">CREATE PROCEDURE leave_begin(IN num INT)</span><br><span class="line">begin_label:BEGIN</span><br><span class="line">    IF num &lt;= 0</span><br><span class="line">        THEN LEAVE begin_label;</span><br><span class="line">    ELSEIF num = 1</span><br><span class="line">        THEN SELECT AVG(salary) FROM employees;</span><br><span class="line">    ELSEIF num = 2</span><br><span class="line">        THEN SELECT MIN(salary) FROM employees;</span><br><span class="line">    ELSE</span><br><span class="line">        SELECT MAX(salary) FROM employees;</span><br><span class="line">    END IF;</span><br><span class="line"></span><br><span class="line">    # 查询总人数</span><br><span class="line">    SELECT COUNT(*) FROM employees;</span><br><span class="line"></span><br><span class="line">end begin_label;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">CALL leave_begin(2);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-09_13-44-35.png" alt="Snipaste_2023-08-09_13-44-35" style="zoom:50%;">

<img src="Snipaste_2023-08-09_13-44-41.png" alt="Snipaste_2023-08-09_13-44-41" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 举例2：当市场环境不好时，公司为了渡过难关，决定暂时降低大家的薪资。声明存储过程“leave_while()”，声明</span><br><span class="line">OUT参数num，输出循环次数，存储过程中使用WHILE循环给大家降低薪资为原来薪资的90%，直到全公</span><br><span class="line">司的平均薪资小于等于10000，并统计循环次数。</span><br><span class="line"> */</span><br><span class="line">CREATE PROCEDURE leave_while(OUT num INT)</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE avg_sal DOUBLE; # 记录平均工资</span><br><span class="line">    DECLARE while_count INT DEFAULT 0; # 记录循环次数</span><br><span class="line"></span><br><span class="line">    SELECT AVG(salary) INTO avg_sal FROM employees;</span><br><span class="line"></span><br><span class="line">    while_label:WHILE TRUE DO</span><br><span class="line">        IF avg_sal &lt;= 10000</span><br><span class="line">            THEN LEAVE while_label;</span><br><span class="line">        END IF;</span><br><span class="line"></span><br><span class="line">        UPDATE employees SET salary = salary * 0.9;</span><br><span class="line">        SELECT AVG(salary) INTO avg_sal FROM employees;</span><br><span class="line">        SET while_count = while_count + 1;</span><br><span class="line"></span><br><span class="line">    end while while_label;</span><br><span class="line"></span><br><span class="line">    # 赋值</span><br><span class="line">    SET num = while_count;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 先查询一下</span><br><span class="line">SELECT AVG(salary) FROM employees; # 13126.774019</span><br><span class="line"># 调用</span><br><span class="line">CALL leave_while(@num);</span><br><span class="line">SELECT @num; # 3</span><br><span class="line"># 再查询一下</span><br><span class="line">SELECT AVG(salary) FROM employees; # 9569.418598</span><br></pre></td></tr></table></figure>

<h3 id="3-7-跳转语句之ITERATE语句（相当于JAVA中的CONTINUE）"><a href="#3-7-跳转语句之ITERATE语句（相当于JAVA中的CONTINUE）" class="headerlink" title="3.7 跳转语句之ITERATE语句（相当于JAVA中的CONTINUE）"></a>3.7 跳转语句之ITERATE语句（相当于JAVA中的CONTINUE）</h3><p><img src="Snipaste_2023-08-09_18-10-07.png" alt="Snipaste_2023-08-09_18-10-07"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 举例1： 定义局部变量num，初始值为0。循环结构中执行num + 1操作。</span><br><span class="line">如果num &lt; 10，则继续执行循环；</span><br><span class="line">如果num &gt; 15，则退出循环结构；</span><br><span class="line"> */</span><br><span class="line">CREATE PROCEDURE test_iterate()</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE num INT DEFAULT 0;</span><br><span class="line">    my_loop:LOOP</span><br><span class="line">        # 赋值</span><br><span class="line">        SET num = num + 1;</span><br><span class="line">        IF num &lt; 10</span><br><span class="line">            THEN ITERATE my_loop;</span><br><span class="line">        ELSEIF num &gt; 15</span><br><span class="line">            THEN LEAVE my_loop;</span><br><span class="line">        END IF;</span><br><span class="line"></span><br><span class="line">        SELECT &#x27;abc&#x27;;</span><br><span class="line"></span><br><span class="line">    end loop my_loop;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line">CALL test_iterate(); # 输出5次&#x27;abc&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="4-游标"><a href="#4-游标" class="headerlink" title="4. 游标"></a>4. 游标</h2><h3 id="4-1-什么是游标（光标）"><a href="#4-1-什么是游标（光标）" class="headerlink" title="4.1 什么是游标（光标）"></a>4.1 什么是游标（光标）</h3><p><img src="Snipaste_2023-08-09_18-36-33.png" alt="Snipaste_2023-08-09_18-36-33"></p>
<h3 id="4-2-使用游标的步骤"><a href="#4-2-使用游标的步骤" class="headerlink" title="4.2 使用游标的步骤"></a>4.2 使用游标的步骤</h3><p>游标必须在声明处理程序之前被声明，并且变量和条件还必须在声明游标或处理程序之前被声明。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 游标使用的步骤</span><br><span class="line"> ①声明游标</span><br><span class="line"> ②打开游标</span><br><span class="line"> ③使用游标（从游标中获取数据）</span><br><span class="line"> ④关闭游标</span><br><span class="line"> */</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 举例：创建存储过程“get_count_by_limit_total_salary()”，声明IN参数 limit_total_salary，DOUBLE类型；声明</span><br><span class="line">OUT参数total_count，INT类型。函数的功能可以实现累加薪资最高的几个员工的薪资值，直到薪资总和</span><br><span class="line">达到limit_total_salary参数的值，返回累加的人数给total_count。</span><br><span class="line"> */</span><br><span class="line">CREATE PROCEDURE get_count_by_limit_total_salary(IN limit_total_salary DOUBLE, OUT total_count INT)</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明局部变量</span><br><span class="line">    DECLARE sum_sal DOUBLE DEFAULT 0.0; # 记录累加的工资总额</span><br><span class="line">    DECLARE emp_sal DOUBLE;# 记录某一个员工的工资</span><br><span class="line">    DECLARE emp_count INT DEFAULT 0; # 记录累加的人数</span><br><span class="line"></span><br><span class="line">    # 1.声明游标</span><br><span class="line">    DECLARE emp_cursor CURSOR FOR SELECT salary FROM employees ORDER BY salary DESC;</span><br><span class="line">    # 2.打开游标</span><br><span class="line">    OPEN emp_cursor;</span><br><span class="line"></span><br><span class="line">    REPEAT</span><br><span class="line">        # 3.使用游标</span><br><span class="line">        FETCH emp_cursor INTO emp_sal;</span><br><span class="line">        SET sum_sal = sum_sal + emp_sal;</span><br><span class="line">        SET emp_count = emp_count + 1;</span><br><span class="line">    until sum_sal &gt;= limit_total_salary</span><br><span class="line">    end repeat;</span><br><span class="line"></span><br><span class="line">    SET total_count = emp_count;</span><br><span class="line"></span><br><span class="line">    # 4.关闭游标</span><br><span class="line">    CLOSE emp_cursor;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">CALL get_count_by_limit_total_salary(200000,@total_count);</span><br><span class="line">SELECT @total_count; # 10</span><br></pre></td></tr></table></figure>

<h1 id="第十六章-触发器"><a href="#第十六章-触发器" class="headerlink" title="第十六章 触发器"></a>第十六章 触发器</h1><p><strong>注意：触发器和表是高度耦合的</strong></p>
<h2 id="1-触发器概念"><a href="#1-触发器概念" class="headerlink" title="1. 触发器概念"></a>1. 触发器概念</h2><p><img src="Snipaste_2023-08-10_21-00-16.png" alt="Snipaste_2023-08-10_21-00-16"></p>
<h2 id="2-触发器的创建"><a href="#2-触发器的创建" class="headerlink" title="2. 触发器的创建"></a>2. 触发器的创建</h2><h3 id="2-1-创建触发器语法"><a href="#2-1-创建触发器语法" class="headerlink" title="2.1 创建触发器语法"></a>2.1 创建触发器语法</h3><p><img src="Snipaste_2023-08-10_21-02-32.png" alt="Snipaste_2023-08-10_21-02-32"></p>
<p><img src="Snipaste_2023-08-10_21-02-48.png" alt="Snipaste_2023-08-10_21-02-48"></p>
<h3 id="2-2-代码举例"><a href="#2-2-代码举例" class="headerlink" title="2.2 代码举例"></a>2.2 代码举例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># 举例1</span><br><span class="line"># 零、准备工作</span><br><span class="line">CREATE DATABASE dbtest17;</span><br><span class="line">USE dbtest17;</span><br><span class="line"># ①创建数据表</span><br><span class="line">CREATE TABLE test_trigger (</span><br><span class="line">    id INT PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">    t_note VARCHAR(30)</span><br><span class="line">);</span><br><span class="line">CREATE TABLE test_trigger_log (</span><br><span class="line">    id INT PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">    t_log VARCHAR(30)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"># ② 查看表数据</span><br><span class="line">SELECT * FROM test_trigger; # 空</span><br><span class="line">SELECT * FROM test_trigger_log; # 空</span><br><span class="line"></span><br><span class="line"># ③创建触发器</span><br><span class="line"># 创建名称为before_insert_test_tri的触发器，向test_trigger数据表插入数据之前，向</span><br><span class="line"># test_trigger_log数据表中插入before_insert的日志信息。</span><br><span class="line">CREATE TRIGGER before_insert_test_tri</span><br><span class="line">BEFORE INSERT ON test_trigger</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    INSERT INTO test_trigger_log(t_log)</span><br><span class="line">    VALUES (&#x27;before insert...&#x27;);</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># ④测试</span><br><span class="line">INSERT INTO test_trigger(t_note)</span><br><span class="line">VALUES (&#x27;TOM&#x27;);</span><br><span class="line"></span><br><span class="line">SELECT * FROM test_trigger;</span><br><span class="line">SELECT * FROM test_trigger_log;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-10_21-25-04.png" alt="Snipaste_2023-08-10_21-25-04" style="zoom:50%;">

<img src="Snipaste_2023-08-10_21-25-12.png" alt="Snipaste_2023-08-10_21-25-12" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 举例2：</span><br><span class="line"># 创建名称为after_insert_test_tri的触发器，向test_trigger数据表插入数据之后，向test_trigger_log数据表中插</span><br><span class="line"># 入after_insert的日志信息。</span><br><span class="line">CREATE TRIGGER after_insert_test_tri</span><br><span class="line">AFTER INSERT ON test_trigger</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    INSERT INTO test_trigger_log(t_log)</span><br><span class="line">    VALUES (&#x27;after insert...&#x27;);</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line">INSERT INTO test_trigger(t_note)</span><br><span class="line">VALUES (&#x27;JIM&#x27;);</span><br><span class="line"></span><br><span class="line">SELECT * FROM test_trigger;</span><br><span class="line">SELECT * FROM test_trigger_log;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-10_21-32-25.png" alt="Snipaste_2023-08-10_21-32-25" style="zoom:50%;">

<img src="Snipaste_2023-08-10_21-32-35.png" alt="Snipaste_2023-08-10_21-32-35" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 举例3：</span><br><span class="line"># 定义触发器“salary_check_trigger”，基于员工表“employees”的INSERT事件，在INSERT之前检查</span><br><span class="line"># 将要添加的新员工薪资是否大于他领导的薪资，如果大于领导薪资，则报sqlstate_value为&#x27;HY000&#x27;的错</span><br><span class="line"># 误，从而使得添加失败。</span><br><span class="line"></span><br><span class="line"># 准备工作：</span><br><span class="line">CREATE TABLE employees</span><br><span class="line">AS</span><br><span class="line">SELECT * FROM atguigudb.employees;</span><br><span class="line"></span><br><span class="line">CREATE TABLE departments</span><br><span class="line">AS</span><br><span class="line">SELECT * FROM atguigudb.departments;</span><br><span class="line"></span><br><span class="line">CREATE TRIGGER salary_check_trigger</span><br><span class="line">BEFORE INSERT ON employees</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE mgr_sal DOUBLE;</span><br><span class="line"></span><br><span class="line">    SELECT salary INTO mgr_sal</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE employee_id = NEW.manager_id; # NEW表示新插入的一行</span><br><span class="line"></span><br><span class="line">    IF NEW.salary &gt; mgr_sal</span><br><span class="line">        THEN SIGNAL SQLSTATE &#x27;HY000&#x27; SET MESSAGE_TEXT = &#x27;薪酬高于领导薪资错误&#x27;;</span><br><span class="line">    END IF;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 测试</span><br><span class="line">INSERT INTO employees(employee_id, last_name, email, hire_date, job_id, salary, manager_id)</span><br><span class="line">VALUES (301,&#x27;TOM&#x27;,&#x27;TOM@126.com&#x27;,CURDATE(),&#x27;AD_VP&#x27;,10000,103);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-10_21-47-54.png" alt="Snipaste_2023-08-10_21-47-54" style="zoom:50%;">

<h2 id="3-查看和删除触发器"><a href="#3-查看和删除触发器" class="headerlink" title="3. 查看和删除触发器"></a>3. 查看和删除触发器</h2><h3 id="3-1-查看触发器"><a href="#3-1-查看触发器" class="headerlink" title="3.1 查看触发器"></a>3.1 查看触发器</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 方式1：查看当前数据库的所有触发器的定义</span><br><span class="line">SHOW TRIGGERS;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-11_10-27-10.png" alt="Snipaste_2023-08-11_10-27-10" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 方式2：查看当前数据库中某个触发器的定义</span><br><span class="line">SHOW CREATE TRIGGER salary_check_trigger;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-08-11_10-38-27.png" alt="Snipaste_2023-08-11_10-38-27"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 方式3：从系统库information_schema的TRIGGERS表中查询“salary_check_trigger”触发器的信息。</span><br><span class="line">SELECT * FROM information_schema.TRIGGERS;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-08-11_10-40-22.png" alt="Snipaste_2023-08-11_10-40-22"></p>
<h3 id="3-2-删除触发器"><a href="#3-2-删除触发器" class="headerlink" title="3.2 删除触发器"></a>3.2 删除触发器</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DROP TRIGGER IF EXISTS after_insert_test_tri;</span><br></pre></td></tr></table></figure>

<h1 id="第十七章-MySQL8其他新特性"><a href="#第十七章-MySQL8其他新特性" class="headerlink" title="第十七章 MySQL8其他新特性"></a>第十七章 MySQL8其他新特性</h1><h2 id="1-新特性1：窗口函数"><a href="#1-新特性1：窗口函数" class="headerlink" title="1. 新特性1：窗口函数"></a>1. 新特性1：窗口函数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 1.1 演示窗口函数的效果</span><br><span class="line">CREATE TABLE sales(</span><br><span class="line">    id INT PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">    city VARCHAR(15),</span><br><span class="line">    county VARCHAR(15),</span><br><span class="line">    sales_value DECIMAL</span><br><span class="line">);</span><br><span class="line">INSERT INTO sales(city,county,sales_value)</span><br><span class="line">VALUES</span><br><span class="line">(&#x27;北京&#x27;,&#x27;海淀&#x27;,10.00),</span><br><span class="line">(&#x27;北京&#x27;,&#x27;朝阳&#x27;,20.00),</span><br><span class="line">(&#x27;上海&#x27;,&#x27;黄埔&#x27;,30.00),</span><br><span class="line">(&#x27;上海&#x27;,&#x27;长宁&#x27;,10.00);</span><br><span class="line"></span><br><span class="line">SELECT * FROM sales;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_09-13-59.png" alt="Snipaste_2023-08-13_09-13-59" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 需求：现在计算这个网站在每个城市的销售总额、在全国的销售总额、每个区的销售额占所在城市销售</span><br><span class="line">额中的比率，以及占总销售额中的比率。</span><br><span class="line"> */</span><br><span class="line"> </span><br><span class="line"> # 实现方式1：传统方法</span><br><span class="line"> </span><br><span class="line"> # 第一步：计算总销售金额，并存入临时表 a：</span><br><span class="line">CREATE TEMPORARY TABLE a -- 创建临时表</span><br><span class="line">SELECT SUM(sales_value) AS sales_value -- 计算总计金额</span><br><span class="line">FROM sales;</span><br><span class="line"></span><br><span class="line">SELECT * FROM a;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_09-15-15.png" alt="Snipaste_2023-08-13_09-15-15" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 第二步，计算每个城市的销售总额并存入临时表 b：</span><br><span class="line">CREATE TEMPORARY TABLE b -- 创建临时表</span><br><span class="line">SELECT city,SUM(sales_value) AS sales_value -- 计算城市销售合计</span><br><span class="line">FROM sales</span><br><span class="line">GROUP BY city;</span><br><span class="line"></span><br><span class="line">SELECT * FROM b;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_09-16-57.png" alt="Snipaste_2023-08-13_09-16-57" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 第三步，计算各区的销售占所在城市的总计金额的比例，和占全部销售总计金额的比例。我们可以通过</span><br><span class="line"># 下面的连接查询获得需要的结果：</span><br><span class="line">SELECT s.city AS 城市,s.county AS 区,s.sales_value AS 区销售额,</span><br><span class="line">b.sales_value AS 市销售额,s.sales_value/b.sales_value AS 市比率,</span><br><span class="line">a.sales_value AS 总销售额,s.sales_value/a.sales_value AS 总比率</span><br><span class="line">FROM sales s</span><br><span class="line">JOIN b ON (s.city=b.city) -- 连接市统计结果临时表</span><br><span class="line">JOIN a -- 连接总计金额临时表</span><br><span class="line">ORDER BY s.city,s.county;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_09-29-33.png" alt="Snipaste_2023-08-13_09-29-33" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 实现方式2：窗口函数</span><br><span class="line">SELECT city AS 城市,county AS 区,sales_value AS 区销售额,</span><br><span class="line">SUM(sales_value) OVER(PARTITION BY city) AS 市销售额, -- 计算市销售额</span><br><span class="line">sales_value/SUM(sales_value) OVER(PARTITION BY city) AS 市比率,</span><br><span class="line">SUM(sales_value) OVER() AS 总销售额, -- 计算总销售额</span><br><span class="line">sales_value/SUM(sales_value) OVER() AS 总比率</span><br><span class="line">FROM sales</span><br><span class="line">ORDER BY city,county;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_09-29-33.png" alt="Snipaste_2023-08-13_09-29-33" style="zoom:50%;">

<hr>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 2. 介绍窗口函数(介于单行函数和分组函数之间。使用窗口函数后，记录条数不变，且分组显示)</span><br><span class="line"># 准备工作</span><br><span class="line">CREATE TABLE goods(</span><br><span class="line">    id INT PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">    category_id INT,</span><br><span class="line">    category VARCHAR(15),</span><br><span class="line">    NAME VARCHAR(30),</span><br><span class="line">    price DECIMAL(10,2),</span><br><span class="line">    stock INT,</span><br><span class="line">    upper_time DATETIME</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">INSERT INTO goods(category_id,category,NAME,price,stock,upper_time)</span><br><span class="line">VALUES</span><br><span class="line">(1, &#x27;女装/女士精品&#x27;, &#x27;T恤&#x27;, 39.90, 1000, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(1, &#x27;女装/女士精品&#x27;, &#x27;连衣裙&#x27;, 79.90, 2500, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(1, &#x27;女装/女士精品&#x27;, &#x27;卫衣&#x27;, 89.90, 1500, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(1, &#x27;女装/女士精品&#x27;, &#x27;牛仔裤&#x27;, 89.90, 3500, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(1, &#x27;女装/女士精品&#x27;, &#x27;百褶裙&#x27;, 29.90, 500, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(1, &#x27;女装/女士精品&#x27;, &#x27;呢绒外套&#x27;, 399.90, 1200, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(2, &#x27;户外运动&#x27;, &#x27;自行车&#x27;, 399.90, 1000, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(2, &#x27;户外运动&#x27;, &#x27;山地自行车&#x27;, 1399.90, 2500, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(2, &#x27;户外运动&#x27;, &#x27;登山杖&#x27;, 59.90, 1500, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(2, &#x27;户外运动&#x27;, &#x27;骑行装备&#x27;, 399.90, 3500, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(2, &#x27;户外运动&#x27;, &#x27;运动外套&#x27;, 799.90, 500, &#x27;2020-11-10 00:00:00&#x27;),</span><br><span class="line">(2, &#x27;户外运动&#x27;, &#x27;滑板&#x27;, 499.90, 1200, &#x27;2020-11-10 00:00:00&#x27;);</span><br><span class="line"></span><br><span class="line">SELECT * FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_09-56-29.png" alt="Snipaste_2023-08-13_09-56-29" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 下面针对goods表中的数据来验证每个窗口函数的功能。</span><br><span class="line"># ①序号函数</span><br><span class="line"># ROW_NUMBER()函数能够对数据中的序号进行顺序显示。</span><br><span class="line"># ROW_NUMBER()函数</span><br><span class="line"># 举例：查询 goods 数据表中每个商品分类下价格降序排列的各个商品信息。</span><br><span class="line">SELECT ROW_NUMBER() over (PARTITION BY category_id ORDER BY price DESC ) AS row_num,</span><br><span class="line">       id, category_id, category, NAME, price, stock</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-08-13_10-02-20.png" alt="Snipaste_2023-08-13_10-02-20"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 举例：查询 goods 数据表中每个商品分类下价格最高的3种商品信息。</span><br><span class="line">SELECT *</span><br><span class="line">FROM (</span><br><span class="line">     SELECT ROW_NUMBER() over (PARTITION BY category_id ORDER BY price DESC ) AS row_num,</span><br><span class="line">       id, category_id, category, NAME, price, stock</span><br><span class="line">     FROM goods</span><br><span class="line">         ) t</span><br><span class="line">WHERE row_num &lt;= 3;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-08-13_10-15-16.png" alt="Snipaste_2023-08-13_10-15-16"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># RANK()函数（显示重复号，且跳过重复号）</span><br><span class="line"># 使用RANK()函数能够对序号进行并列排序，并且会跳过重复的序号，比如序号为1、1、3。</span><br><span class="line"># 举例：使用RANK()函数获取 goods 数据表中各类别的价格从高到低排序的各商品信息。</span><br><span class="line">SELECT RANK() over (PARTITION BY category_id ORDER BY price DESC ) AS row_num,</span><br><span class="line">       id, category_id, category, NAME, price, stock</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_10-34-01.png" alt="Snipaste_2023-08-13_10-34-01" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># DENSE_RANK()函数（显示重复号，但不跳过重复号）</span><br><span class="line"># DENSE_RANK()函数对序号进行并列排序，并且不会跳过重复的序号，比如序号为1、1、2。</span><br><span class="line"># 举例：使用DENSE_RANK()函数获取 goods 数据表中各类别的价格从高到低排序的各商品信息。</span><br><span class="line">SELECT DENSE_RANK() over (PARTITION BY category_id ORDER BY price DESC ) AS row_num,</span><br><span class="line">       id, category_id, category, NAME, price, stock</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_10-46-09.png" alt="Snipaste_2023-08-13_10-46-09" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># ②分布函数</span><br><span class="line"># PERCENT_RANK()函数</span><br><span class="line"># PERCENT_RANK()函数是等级值百分比函数。</span><br><span class="line"># 举例：计算 goods 数据表中名称为“女装/女士精品”的类别下的商品的PERCENT_RANK值。</span><br><span class="line">SELECT RANK() over (PARTITION BY category_id ORDER BY price DESC ) AS r,</span><br><span class="line">PERCENT_RANK() over (PARTITION BY category_id ORDER BY price DESC) AS pr,</span><br><span class="line">id, category_id, category, NAME, price, stock</span><br><span class="line">FROM goods</span><br><span class="line">WHERE category_id = 1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_11-05-05.png" alt="Snipaste_2023-08-13_11-05-05" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># CUME_DIST()函数</span><br><span class="line"># CUME_DIST()函数主要用于查询小于或等于某个值的比例</span><br><span class="line"># 举例：查询goods数据表中小于或等于当前价格的比例。</span><br><span class="line">SELECT CUME_DIST() over (PARTITION BY category_id ORDER BY price ASC ) AS cd,</span><br><span class="line">       id, category, NAME, price</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_11-11-11.png" alt="Snipaste_2023-08-13_11-11-11" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># ③前后函数</span><br><span class="line"># LAG(expr,n)函数</span><br><span class="line"># LAG(expr,n)函数返回当前行的前n行的expr的值。</span><br><span class="line"># 举例：查询goods数据表中前一个商品价格与当前商品价格的差值</span><br><span class="line"></span><br><span class="line"># 第一步：查询goods表中id, category, NAME, price以及前一个商品的价格</span><br><span class="line">SELECT id, category, NAME, price, LAG(price,1) over (PARTITION BY category_id ORDER BY price) AS pre_price</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_11-18-00.png" alt="Snipaste_2023-08-13_11-18-00" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 第二步：再查询差值</span><br><span class="line">SELECT id, category, NAME, price, pre_price, price - pre_price AS diff_price</span><br><span class="line">FROM (</span><br><span class="line">     SELECT id, category, NAME, price, LAG(price,1) over (PARTITION BY category_id ORDER BY price) AS pre_price</span><br><span class="line">    FROM goods</span><br><span class="line">         ) t;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_11-22-05.png" alt="Snipaste_2023-08-13_11-22-05" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># LEAD(expr,n)函数</span><br><span class="line"># LEAD(expr,n)函数返回当前行的后n行的expr的值。</span><br><span class="line"># 举例：查询goods数据表中后一个商品价格与当前商品价格的差值。</span><br><span class="line"># 第一步：查询goods表中id, category, NAME, price以及后一个商品的价格</span><br><span class="line">SELECT id, category, NAME, price, LEAD(price,1) over (PARTITION BY category_id ORDER BY price) AS behind_price</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_11-32-43.png" alt="Snipaste_2023-08-13_11-32-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 第二步：再查询差值</span><br><span class="line">SELECT id, category, NAME, behind_price, price, behind_price - price AS diff_price</span><br><span class="line">FROM (</span><br><span class="line">     SELECT id, category, NAME, price, LEAD(price,1) over (PARTITION BY category_id ORDER BY price) AS behind_price</span><br><span class="line">    FROM goods</span><br><span class="line">         ) t;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_15-38-07.png" alt="Snipaste_2023-08-13_15-38-07" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># ④首尾函数</span><br><span class="line"># FIRST_VALUE(expr)函数</span><br><span class="line"># FIRST_VALUE(expr)函数返回第一个expr的值。</span><br><span class="line"># 举例：按照价格排序，查询第1个商品的价格信息。</span><br><span class="line">SELECT id, category,NAME, price, stock, FIRST_VALUE(price) over (PARTITION BY category_id ORDER BY price) AS first_price</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_15-52-43.png" alt="Snipaste_2023-08-13_15-52-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># LAST_VALUE(expr)函数</span><br><span class="line"># LAST_VALUE(expr)函数返回最后一个expr的值。</span><br><span class="line"># 举例：按照价格排序，查询最后一个商品的价格信息。</span><br><span class="line"># 如果按照FIRST_VALUE格式写的话会出现问题，问题是有了ORDER BY参与导致LAST_VALUE函数失去效果，我们这么做：</span><br><span class="line"># 步骤1：先把表按照category_id分窗口且按照price排序后的表搞出来，其中ROW_NUMBER()只是为了搞出这张表而已，没有其他作用</span><br><span class="line">SELECT id,category,NAME, price, stock, ROW_NUMBER() over (PARTITION BY category_id ORDER BY price) AS num</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_16-46-16.png" alt="Snipaste_2023-08-13_16-46-16" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 步骤2：在新搞的表上面进行LEAD函数的使用</span><br><span class="line">SELECT id, category,NAME, price, stock, LAST_VALUE(price) over (PARTITION BY category_id) AS last_price</span><br><span class="line">FROM (</span><br><span class="line">     SELECT id, category_id,category,NAME, price, stock, ROW_NUMBER() over (PARTITION BY category_id ORDER BY price) AS num</span><br><span class="line">     FROM goods</span><br><span class="line">     ) t;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_16-47-11.png" alt="Snipaste_2023-08-13_16-47-11" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># ⑤其他函数</span><br><span class="line"># NTH_VALUE(expr,n)函数</span><br><span class="line"># NTH_VALUE(expr,n)函数返回第n个expr的值</span><br><span class="line"># 举例：查询goods数据表中排名第2和第3的价格信息。</span><br><span class="line">SELECT id, category, NAME, price, NTH_VALUE(price,2) over (PARTITION BY category_id ORDER BY price) AS second_price,</span><br><span class="line">NTH_VALUE(price,3) over (PARTITION BY category_id ORDER BY price) AS third_price</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_17-36-26.png" alt="Snipaste_2023-08-13_17-36-26" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># NTILE(n)函数</span><br><span class="line"># NTILE(n)函数将分区中的有序数据分为n个桶，记录桶编号。</span><br><span class="line"># 举例：将goods表中的商品按照价格分为3组。</span><br><span class="line">SELECT NTILE(3) over (PARTITION BY category_id ORDER BY price) AS nt, id, category, NAME, price</span><br><span class="line">FROM goods;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_17-39-59.png" alt="Snipaste_2023-08-13_17-39-59" style="zoom:50%;">

<p><strong>总结：</strong>窗口函数的特点是可以分组，而且可以在分组内排序。另外，窗口函数不会因为分组而减少原表中的行数，这对我们在原表数据的基础上进行统计和排序非常有用。</p>
<h2 id="2-新特性2：公用表表达式"><a href="#2-新特性2：公用表表达式" class="headerlink" title="2. 新特性2：公用表表达式"></a>2. 新特性2：公用表表达式</h2><p>CTE（Common Table Expressions）可以理解成一个<strong>可以复用的子查询</strong>，当然跟子查询还是有点区别的，CTE可以引用其他CTE，但子查询不能引用其他子查询。所以，可以考虑代替子查询。</p>
<h3 id="2-1-普通公用表表达式"><a href="#2-1-普通公用表表达式" class="headerlink" title="2.1 普通公用表表达式"></a>2.1 普通公用表表达式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WITH CTE名称</span><br><span class="line">AS （子查询）</span><br><span class="line">SELECT|DELETE|UPDATE 语句;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 举例：查询员工所在的部门的详细信息。</span><br><span class="line">CREATE TABLE departments</span><br><span class="line">AS</span><br><span class="line">SELECT * FROM atguigudb.departments;</span><br><span class="line"># 方式1：子查询方法</span><br><span class="line">SELECT * FROM departments</span><br><span class="line">WHERE department_id IN (</span><br><span class="line">    SELECT DISTINCT department_id</span><br><span class="line">    FROM employees</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_18-05-45.png" alt="Snipaste_2023-08-13_18-05-45" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 方法2：公用表表达式</span><br><span class="line">WITH cte_emp</span><br><span class="line">AS (</span><br><span class="line">    SELECT DISTINCT department_id</span><br><span class="line">    FROM employees )</span><br><span class="line">SELECT *</span><br><span class="line">FROM departments d JOIN cte_emp e</span><br><span class="line">ON d.department_id = e.department_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_18-06-24.png" alt="Snipaste_2023-08-13_18-06-24" style="zoom:50%;">

<h3 id="2-2-递归公用表表达式"><a href="#2-2-递归公用表表达式" class="headerlink" title="2.2 递归公用表表达式"></a>2.2 递归公用表表达式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WITH RECURSIVE</span><br><span class="line">CTE名称 AS （子查询）</span><br><span class="line">SELECT|DELETE|UPDATE 语句;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 举例：找出公司employees表中所有的下下属</span><br><span class="line">WITH RECURSIVE cte</span><br><span class="line">AS (</span><br><span class="line">    SELECT employee_id,last_name,manager_id,1 AS n FROM employees WHERE employee_id = 100</span><br><span class="line">    UNION ALL</span><br><span class="line">    SELECT a.employee_id,a.last_name,a.manager_id,n+1 FROM employees AS a JOIN cte</span><br><span class="line">    ON (a.manager_id = cte.employee_id)</span><br><span class="line">    )</span><br><span class="line">SELECT employee_id,last_name FROM cte WHERE n &gt;= 3;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_20-51-46.png" alt="Snipaste_2023-08-13_20-51-46" style="zoom:50%;">













<h1 id="练习题"><a href="#练习题" class="headerlink" title="练习题"></a>练习题</h1><h2 id="01-SELECT基础练习"><a href="#01-SELECT基础练习" class="headerlink" title="01 SELECT基础练习"></a>01 SELECT基础练习</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.</span>查询员工<span class="number">12</span>个月的工资总和(包含奖金)，并起别名为ANNUAL SALARY</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, salary <span class="operator">*</span> <span class="number">12</span> <span class="operator">*</span> (<span class="number">1</span> <span class="operator">+</span> IFNULL(commission_pct,<span class="number">0</span>)) &quot;ANNUAL SALARY&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_18-26-12.png" alt="Snipaste_2023-07-04_18-26-12" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span>查询employees表中去除重复的job_id以后的数据</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> job_id</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_18-26-50.png" alt="Snipaste_2023-07-04_18-26-50" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.</span>查询工资大于<span class="number">12000</span>的员工姓名和工资</span><br><span class="line"><span class="keyword">SELECT</span> last_name, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> <span class="number">12000</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_18-27-23.png" alt="Snipaste_2023-07-04_18-27-23" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span>查询员工号为<span class="number">176</span>的员工的姓名和部门号</span><br><span class="line"><span class="keyword">SELECT</span> last_name, department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="operator">=</span> <span class="number">176</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_18-27-55.png" alt="Snipaste_2023-07-04_18-27-55" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.</span>显示表 departments 的结构，并查询其中的全部数据</span><br><span class="line"><span class="keyword">DESC</span>  departments;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> departments;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-04_18-28-40.png" alt="Snipaste_2023-07-04_18-28-40" style="zoom: 33%;">

<h2 id="02-运算符练习"><a href="#02-运算符练习" class="headerlink" title="02 运算符练习"></a>02 运算符练习</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.</span>选择工资不在<span class="number">5000</span>到<span class="number">12000</span>的员工的姓名和工资</span><br><span class="line"><span class="keyword">SELECT</span> last_name, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="keyword">NOT</span> <span class="keyword">BETWEEN</span> <span class="number">5000</span> <span class="keyword">AND</span> <span class="number">12000</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-38-06.png" alt="Snipaste_2023-07-05_19-38-06" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span>选择在<span class="number">20</span>或<span class="number">50</span>号部门工作的员工姓名和部门号</span><br><span class="line"><span class="keyword">SELECT</span> last_name, department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"># <span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">20</span> <span class="keyword">OR</span> department_id <span class="operator">=</span> <span class="number">50</span>;</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (<span class="number">20</span>, <span class="number">50</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-38-47.png" alt="Snipaste_2023-07-05_19-38-47" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.</span>选择公司中没有管理者的员工姓名及job_id</span><br><span class="line"><span class="keyword">SELECT</span> last_name, job_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"># <span class="keyword">WHERE</span> manager_id <span class="operator">&lt;=&gt;</span> <span class="keyword">NULL</span>;</span><br><span class="line"><span class="keyword">WHERE</span> manager_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-39-23.png" alt="Snipaste_2023-07-05_19-39-23" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span>选择公司中有奖金的员工姓名，工资和奖金级别</span><br><span class="line"><span class="keyword">SELECT</span> last_name, salary, commission_pct</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> commission_pct <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-39-56.png" alt="Snipaste_2023-07-05_19-39-56" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.</span>选择员工姓名的第三个字母是a的员工姓名</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;__a%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-40-50.png" alt="Snipaste_2023-07-05_19-40-50" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.</span>选择姓名中有字母a和k的员工姓名</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;%a%&#x27;</span> <span class="keyword">AND</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;%k%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-41-19.png" alt="Snipaste_2023-07-05_19-41-19" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">7.</span>显示出表 employees 表中 first_name 以 <span class="string">&#x27;e&#x27;</span>结尾的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> first_name,last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> first_name <span class="keyword">LIKE</span> <span class="string">&#x27;%e&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-42-12.png" alt="Snipaste_2023-07-05_19-42-12" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">8.</span>显示出表 employees 部门编号在 <span class="number">80</span><span class="number">-100</span> 之间的姓名、工种</span><br><span class="line"><span class="keyword">SELECT</span> last_name, job_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">BETWEEN</span> <span class="number">80</span> <span class="keyword">AND</span> <span class="number">100</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-42-45.png" alt="Snipaste_2023-07-05_19-42-45" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">9.</span>显示出表 employees 的 manager_id 是 <span class="number">100</span>,<span class="number">101</span>,<span class="number">110</span> 的员工姓名、工资、管理者id</span><br><span class="line"><span class="keyword">SELECT</span> last_name, salary, manager_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> manager_id <span class="keyword">In</span> (<span class="number">100</span>,<span class="number">101</span>,<span class="number">110</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_19-43-23.png" alt="Snipaste_2023-07-05_19-43-23" style="zoom:43%;">

<h2 id="03-排序与分页练习"><a href="#03-排序与分页练习" class="headerlink" title="03 排序与分页练习"></a>03 排序与分页练习</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">1.</span> 查询员工的姓名和部门号和年薪，按年薪降序,按姓名升序显示</span><br><span class="line"><span class="keyword">SELECT</span> last_name, department_id, salary <span class="operator">*</span> <span class="number">12</span> annual_salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> annual_salary <span class="keyword">DESC</span> ,last_name <span class="keyword">ASC</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-32-41.png" alt="Snipaste_2023-07-05_21-32-41" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">2.</span> 选择工资不在 <span class="number">8000</span> 到 <span class="number">17000</span> 的员工的姓名和工资，按工资降序，显示第<span class="number">21</span>到<span class="number">40</span>位置的数据</span><br><span class="line"><span class="keyword">SELECT</span> last_name, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="keyword">NOT</span> <span class="keyword">BETWEEN</span> <span class="number">8000</span> <span class="keyword">AND</span> <span class="number">17000</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">20</span>,<span class="number">20</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-55-12.png" alt="Snipaste_2023-07-05_21-55-12" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">3.</span> 查询邮箱中包含 e 的员工信息，并先按邮箱的字节数降序，再按部门号升序</span><br><span class="line"><span class="keyword">SELECT</span> employee_id, last_name, email, department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> email <span class="keyword">LIKE</span> <span class="string">&#x27;%e%&#x27;</span></span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> LENGTH(email) <span class="keyword">DESC</span> ,department_id <span class="keyword">ASC</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-05_21-57-59.png" alt="Snipaste_2023-07-05_21-57-59" style="zoom:43%;">

<h2 id="04-多表查询"><a href="#04-多表查询" class="headerlink" title="04 多表查询"></a>04 多表查询</h2><p>熟悉几张表：</p>
<p>![webwxgetmsgimg (15)](MySQL相关知识&#x2F;webwxgetmsgimg (15).jpg)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 【题目】</span><br><span class="line"># <span class="number">1.</span>显示“所有员工“的姓名，部门号和部门名称。</span><br><span class="line"><span class="keyword">SELECT</span> e.last_name, e.department_id, d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-30-37.png" alt="Snipaste_2023-07-06_22-30-37" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span>查询<span class="number">90</span>号部门员工的job_id和<span class="number">90</span>号部门的location_id</span><br><span class="line"><span class="keyword">SELECT</span> e.job_id, d.location_id</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> d.department_id <span class="operator">=</span> <span class="number">90</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-39-57.png" alt="Snipaste_2023-07-06_22-39-57" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.</span>选择&quot;所有有奖金的员工&quot;的 last_name , department_name , location_id , city</span><br><span class="line"><span class="keyword">SELECT</span> e.last_name ,e.commission_pct, d.department_name , d.location_id , l.city</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> locations l</span><br><span class="line"><span class="keyword">ON</span> d.location_id <span class="operator">=</span> l.location_id</span><br><span class="line"><span class="keyword">WHERE</span> e.commission_pct <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-41-18.png" alt="Snipaste_2023-07-06_22-41-18" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span>选择city在Toronto工作的员工的 last_name , job_id , department_id , department_name</span><br><span class="line"><span class="keyword">SELECT</span> e.last_name , e.job_id , d.department_id , d.department_name</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">JOIN</span> locations l</span><br><span class="line"><span class="keyword">ON</span> d.location_id <span class="operator">=</span> l.location_id</span><br><span class="line"><span class="keyword">WHERE</span> l.city <span class="operator">=</span> <span class="string">&#x27;Toronto&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-41-57.png" alt="Snipaste_2023-07-06_22-41-57" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.</span>查询员工所在的部门名称、部门地址、姓名、工作、工资，其中员工所在部门的部门名称为’Executive’</span><br><span class="line"><span class="keyword">SELECT</span> d.department_name, l.street_address, e.last_name, e.job_id,e.salary</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">JOIN</span> locations l</span><br><span class="line"><span class="keyword">ON</span> d.location_id <span class="operator">=</span> l.location_id</span><br><span class="line"><span class="keyword">WHERE</span> department_name <span class="operator">=</span> <span class="string">&#x27;Executive&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-42-33.png" alt="Snipaste_2023-07-06_22-42-33" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.</span>选择指定员工的姓名，员工号，以及他的管理者的姓名和员工号，结果类似于下面的格式</span><br><span class="line">employees Emp manager Mgr</span><br><span class="line">kochhar <span class="number">101</span> king <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> emp.last_name &quot;employees&quot;, emp.employee_id &quot;Emp&quot;, mgr.last_name &quot;manager&quot;, mgr.employee_id &quot;Mgr&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees emp <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> employees mgr</span><br><span class="line"><span class="keyword">ON</span> emp.manager_id <span class="operator">=</span> mgr.employee_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-43-15.png" alt="Snipaste_2023-07-06_22-43-15" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">7.</span>查询哪些部门没有员工</span><br><span class="line"><span class="keyword">SELECT</span> d.department_id</span><br><span class="line"><span class="keyword">FROM</span> departments d <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> employees e</span><br><span class="line"><span class="keyword">ON</span> d.department_id <span class="operator">=</span> e.department_id</span><br><span class="line"><span class="keyword">WHERE</span> e.department_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-44-09.png" alt="Snipaste_2023-07-06_22-44-09" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">8.</span> 查询哪个城市没有部门</span><br><span class="line"><span class="keyword">SELECT</span> l.location_id,l.city</span><br><span class="line"><span class="keyword">FROM</span> locations l <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> l.location_id <span class="operator">=</span> d.location_id</span><br><span class="line"><span class="keyword">WHERE</span> d.location_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-44-48.png" alt="Snipaste_2023-07-06_22-44-48" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">9.</span> 查询部门名为 Sales 或 IT 的员工信息</span><br><span class="line"><span class="keyword">SELECT</span> e.employee_id,e.last_name,e.department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line"><span class="keyword">WHERE</span> d.department_name <span class="keyword">IN</span> (<span class="string">&#x27;Sales&#x27;</span>,<span class="string">&#x27;IT&#x27;</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-06_22-45-22.png" alt="Snipaste_2023-07-06_22-45-22" style="zoom:43%;">

<h2 id="05-单行函数"><a href="#05-单行函数" class="headerlink" title="05 单行函数"></a>05 单行函数</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1.</span>显示系统时间(注：日期<span class="operator">+</span>时间)</span><br><span class="line"><span class="keyword">SELECT</span> SYSDATE(),NOW()</span><br><span class="line"><span class="keyword">FROM</span> dual;# <span class="number">2023</span><span class="number">-07</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">48</span>:<span class="number">34</span>,<span class="number">2023</span><span class="number">-07</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">48</span>:<span class="number">34</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">2.</span>查询员工号，姓名，工资，以及工资提高百分之<span class="number">20</span><span class="operator">%</span>后的结果（<span class="keyword">new</span> salary）</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary,salary <span class="operator">*</span> <span class="number">1.2</span> &quot;new salary&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-49-15.png" alt="Snipaste_2023-07-08_17-49-15" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.</span>将员工的姓名按首字母排序，并写出姓名的长度（length）</span><br><span class="line"><span class="keyword">SELECT</span> last_name,LENGTH(last_name) &quot;length&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> last_name <span class="keyword">ASC</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-51-02.png" alt="Snipaste_2023-07-08_17-51-02" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span>查询员工id,last_name,salary，并作为一个列输出，别名为OUT_PUT</span><br><span class="line"><span class="keyword">SELECT</span> CONCAT(employee_id,<span class="string">&#x27;,&#x27;</span>,last_name,<span class="string">&#x27;,&#x27;</span>,salary) &quot;OUT_PUT&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-51-30.png" alt="Snipaste_2023-07-08_17-51-30" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.</span>查询公司各员工工作的年数、工作的天数，并按工作年数的降序排序</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,DATEDIFF(CURDATE(),hire_date)<span class="operator">/</span><span class="number">365</span> &quot;worked_years&quot;,</span><br><span class="line">       DATEDIFF(CURDATE(),hire_date) &quot;worked_days&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> worked_years <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-52-00.png" alt="Snipaste_2023-07-08_17-52-00" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.</span>查询员工姓名，hire_date , department_id，满足以下条件：雇用时间在<span class="number">1997</span>年之后，department_id</span><br><span class="line"># 为<span class="number">80</span> 或 <span class="number">90</span> 或<span class="number">110</span>, commission_pct不为空</span><br><span class="line"><span class="keyword">SELECT</span> last_name,hire_date,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (<span class="number">80</span>,<span class="number">90</span>,<span class="number">110</span>)</span><br><span class="line"><span class="keyword">AND</span> commission_pct <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">AND</span> DATE_FORMAT(hire_date,<span class="string">&#x27;%Y-%m-%d&#x27;</span>) <span class="operator">&gt;=</span> <span class="string">&#x27;1997-01-01&#x27;</span>; #显式转换</span><br><span class="line"># <span class="keyword">AND</span> hire_date <span class="operator">&gt;=</span> <span class="string">&#x27;1997-01-01&#x27;</span>; # 隐式转换</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-52-43.png" alt="Snipaste_2023-07-08_17-52-43" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">7.</span>查询公司中入职超过<span class="number">10000</span>天的员工姓名、入职时间</span><br><span class="line"><span class="keyword">SELECT</span> last_name,hire_date</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> DATEDIFF(CURDATE(),hire_date) <span class="operator">&gt;=</span> <span class="number">10000</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-53-24.png" alt="Snipaste_2023-07-08_17-53-24" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">8.</span>做一个查询，产生下面的结果</span><br><span class="line"># <span class="operator">&lt;</span>last_name<span class="operator">&gt;</span> earns <span class="operator">&lt;</span>salary<span class="operator">&gt;</span> monthly but wants <span class="operator">&lt;</span>salary<span class="operator">*</span><span class="number">3</span><span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">SELECT</span> CONCAT(last_name,<span class="string">&#x27; earns &#x27;</span>,salary,<span class="string">&#x27; monthly but wants &#x27;</span>,salary<span class="operator">*</span><span class="number">3</span>) &quot;Dream Salary&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-54-07.png" alt="Snipaste_2023-07-08_17-54-07" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">9.</span>使用<span class="keyword">case</span><span class="operator">-</span><span class="keyword">when</span>，按照下面的条件：</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">job      grade</span></span><br><span class="line"><span class="comment">AD_PRES   A</span></span><br><span class="line"><span class="comment">ST_MAN    B</span></span><br><span class="line"><span class="comment">IT_PROG   C</span></span><br><span class="line"><span class="comment">SA_REP    D</span></span><br><span class="line"><span class="comment">ST_CLERK  E</span></span><br><span class="line"><span class="comment">产生下面的结果:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name,job_id,<span class="keyword">CASE</span> job_id <span class="keyword">WHEN</span> <span class="string">&#x27;AD_PRES&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;A&#x27;</span></span><br><span class="line">                                    <span class="keyword">WHEN</span> <span class="string">&#x27;ST_MAN&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;B&#x27;</span></span><br><span class="line">                                    <span class="keyword">WHEN</span> <span class="string">&#x27;IT_PROG&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;C&#x27;</span></span><br><span class="line">                                    <span class="keyword">WHEN</span> <span class="string">&#x27;SA_REP&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;D&#x27;</span></span><br><span class="line">                                    <span class="keyword">WHEN</span> <span class="string">&#x27;ST_CLERK&#x27;</span> <span class="keyword">THEN</span> <span class="string">&#x27;E&#x27;</span></span><br><span class="line">                                    <span class="keyword">END</span></span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-08_17-55-20.png" alt="Snipaste_2023-07-08_17-55-20" style="zoom:50%;">

<h2 id="06-聚合函数"><a href="#06-聚合函数" class="headerlink" title="06 聚合函数"></a>06 聚合函数</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">1.</span><span class="keyword">where</span>子句可否使用组函数进行过滤?</span><br><span class="line"># 不可以</span><br><span class="line">#<span class="number">2.</span>查询公司员工工资的最大值，最小值，平均值，总和</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">MAX</span>(salary),<span class="built_in">MIN</span>(salary),<span class="built_in">AVG</span>(salary),<span class="built_in">SUM</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_16-25-03.png" alt="Snipaste_2023-07-09_16-25-03" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">3.</span>查询各job_id的员工工资的最大值，最小值，平均值，总和</span><br><span class="line"><span class="keyword">SELECT</span> job_id,<span class="built_in">MAX</span>(salary),<span class="built_in">MIN</span>(salary),<span class="built_in">AVG</span>(salary),<span class="built_in">SUM</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_16-25-46.png" alt="Snipaste_2023-07-09_16-25-46" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">4.</span>选择具有各个job_id的员工人数</span><br><span class="line"><span class="keyword">SELECT</span> job_id,<span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-09_16-25-46.png" alt="Snipaste_2023-07-09_16-25-46"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.</span>查询员工最高工资和最低工资的差距（DIFFERENCE）</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">MAX</span>(salary) <span class="operator">-</span> <span class="built_in">MIN</span>(salary) &quot;DIFFERENCE&quot;</span><br><span class="line"><span class="keyword">FROM</span> employees; # <span class="number">21900</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.</span>查询各个管理者手下员工的最低工资，其中最低工资不能低于<span class="number">6000</span>，没有管理者的员工不计算在内</span><br><span class="line"><span class="keyword">SELECT</span> manager_id,<span class="built_in">MIN</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> manager_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> manager_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">MIN</span>(salary) <span class="operator">&gt;=</span> <span class="number">6000</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_16-27-06.png" alt="Snipaste_2023-07-09_16-27-06" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">7.</span>查询所有部门的名字，location_id，员工数量和平均工资，并按平均工资降序</span><br><span class="line"><span class="keyword">SELECT</span> d.department_name,d.location_id,<span class="built_in">COUNT</span>(employee_id),<span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> departments d <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> employees e</span><br><span class="line"><span class="keyword">ON</span> d.department_id <span class="operator">=</span> e.department_id</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_name, location_id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="built_in">AVG</span>(salary) <span class="keyword">DESC</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-09_16-27-59.png" alt="Snipaste_2023-07-09_16-27-59"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">8.</span>查询每个工种、每个部门的部门名、工种名和最低工资</span><br><span class="line"><span class="keyword">SELECT</span> d.department_name,e.job_id,<span class="built_in">MIN</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> departments d <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> employees e</span><br><span class="line"><span class="keyword">ON</span> d.department_id <span class="operator">=</span> e.department_id</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> d.department_name, e.job_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-09_16-29-48.png" alt="Snipaste_2023-07-09_16-29-48" style="zoom:50%;">

<h2 id="07-子查询"><a href="#07-子查询" class="headerlink" title="07 子查询"></a>07 子查询</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">1.</span>查询和Zlotkey相同部门的员工姓名和工资</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> last_name <span class="operator">=</span> <span class="string">&#x27;Zlotkey&#x27;</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-15-15.png" alt="Snipaste_2023-07-12_23-15-15" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">2.</span>查询工资比公司平均工资高的员工的员工号，姓名和工资。</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-15-49.png" alt="Snipaste_2023-07-12_23-15-49" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">3.</span>选择工资大于所有JOB_ID <span class="operator">=</span> <span class="string">&#x27;SA_MAN&#x27;</span>的员工的工资的员工的last_name, job_id, salary</span><br><span class="line"><span class="keyword">SELECT</span> last_name,job_id,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> <span class="keyword">ALL</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> salary</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> job_id <span class="operator">=</span> <span class="string">&#x27;SA_MAN&#x27;</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-18-35.png" alt="Snipaste_2023-07-12_23-18-35" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">4.</span>查询和姓名中包含字母u的员工在相同部门的员工的员工号和姓名</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> last_name <span class="keyword">LIKE</span> <span class="string">&#x27;%u%&#x27;</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-19-17.png" alt="Snipaste_2023-07-12_23-19-17" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">5.</span>查询在部门的location_id为<span class="number">1700</span>的部门工作的员工的员工号</span><br><span class="line"><span class="keyword">SELECT</span> employee_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> departments</span><br><span class="line">    <span class="keyword">WHERE</span> location_id <span class="operator">=</span> <span class="number">1700</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-20-26.png" alt="Snipaste_2023-07-12_23-20-26" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">6.</span>查询管理者是King的员工姓名和工资</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> manager_id <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> employee_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> last_name <span class="operator">=</span> <span class="string">&#x27;King&#x27;</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-20-55.png" alt="Snipaste_2023-07-12_23-20-55" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">7.</span>查询工资最低的员工信息: last_name, salary</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-21-24.png" alt="Snipaste_2023-07-12_23-21-24" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">8.</span>查询平均工资最低的部门信息(有难度)</span><br><span class="line"># 方式<span class="number">1</span></span><br><span class="line"># 先查询各个部门的平均工资</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) dept_avgsal</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id;</span><br><span class="line"></span><br><span class="line"># 再查询这些部门平均工资的最低值</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">MIN</span>(dept_avgsal)</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">     <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) dept_avgsal</span><br><span class="line">     <span class="keyword">FROM</span> employees</span><br><span class="line">     <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">         ) avg_sal;</span><br><span class="line"></span><br><span class="line"># 再查看哪一个部门的平均工资是此最低值</span><br><span class="line"><span class="keyword">SELECT</span> department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(dept_avgsal)</span><br><span class="line">    <span class="keyword">FROM</span> (</span><br><span class="line">         <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) dept_avgsal</span><br><span class="line">         <span class="keyword">FROM</span> employees</span><br><span class="line">         <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">             ) avg_sal</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 再查询该部门的部门信息</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> departments</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(dept_avgsal)</span><br><span class="line">        <span class="keyword">FROM</span> (</span><br><span class="line">             <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) dept_avgsal</span><br><span class="line">             <span class="keyword">FROM</span> employees</span><br><span class="line">             <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">                 ) avg_sal</span><br><span class="line">        )</span><br><span class="line">    );</span><br><span class="line"># 方式<span class="number">2</span>：</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> departments</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">&lt;=</span> <span class="keyword">ALL</span>(</span><br><span class="line">         <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) dept_avgsal</span><br><span class="line">         <span class="keyword">FROM</span> employees</span><br><span class="line">         <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">        )</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">3</span>：分页LIMIT的妙用</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> departments</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">         <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) dept_avgsal</span><br><span class="line">         <span class="keyword">FROM</span> employees</span><br><span class="line">         <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">         <span class="keyword">ORDER</span> <span class="keyword">BY</span> dept_avgsal <span class="keyword">ASC</span></span><br><span class="line">         LIMIT <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">4</span>：</span><br><span class="line"><span class="keyword">SELECT</span> d.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> departments d <span class="keyword">JOIN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary) dept_avgsal</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> dept_avgsal <span class="keyword">ASC</span></span><br><span class="line">    LIMIT <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">    ) avg_sal</span><br><span class="line"><span class="keyword">ON</span> d.department_id <span class="operator">=</span> avg_sal.department_id;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-12_23-22-25.png" alt="Snipaste_2023-07-12_23-22-25"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">9.</span>查询平均工资最低的部门信息和该部门的平均工资（相关子查询）</span><br><span class="line"><span class="keyword">SELECT</span> d.<span class="operator">*</span>,(</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees e</span><br><span class="line">    <span class="keyword">WHERE</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">FROM</span> departments d</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> <span class="built_in">MIN</span>(dept_avgsal)</span><br><span class="line">        <span class="keyword">FROM</span> (</span><br><span class="line">             <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) dept_avgsal</span><br><span class="line">             <span class="keyword">FROM</span> employees</span><br><span class="line">             <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">                 ) avg_sal</span><br><span class="line">        )</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-12_23-22-53.png" alt="Snipaste_2023-07-12_23-22-53"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">10.</span>查询平均工资最高的 job 信息</span><br><span class="line"># 方式<span class="number">1</span>：</span><br><span class="line"># 先查询各个job_id的平均工资</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id;</span><br><span class="line">#再查询这些平均工资的最高值</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">MAX</span>(avg_sal)</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">     <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">     <span class="keyword">FROM</span> employees</span><br><span class="line">     <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">         ) t_job_avg_sal;</span><br><span class="line"># 再查看哪一个job_id的平均工资是此最高值</span><br><span class="line"><span class="keyword">SELECT</span> job_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> <span class="built_in">MAX</span>(avg_sal)</span><br><span class="line">        <span class="keyword">FROM</span> (</span><br><span class="line">            <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">            <span class="keyword">FROM</span> employees</span><br><span class="line">            <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">         ) t_job_avg_sal</span><br><span class="line">    );</span><br><span class="line"># 再查询该job_id的信息</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> jobs</span><br><span class="line"><span class="keyword">WHERE</span> job_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> job_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">            <span class="keyword">SELECT</span> <span class="built_in">MAX</span>(avg_sal)</span><br><span class="line">            <span class="keyword">FROM</span> (</span><br><span class="line">                <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">                <span class="keyword">FROM</span> employees</span><br><span class="line">                <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">             ) t_job_avg_sal</span><br><span class="line">        )</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> jobs</span><br><span class="line"><span class="keyword">WHERE</span> job_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> job_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">&gt;=</span> <span class="keyword">ALL</span>(</span><br><span class="line">                <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">                <span class="keyword">FROM</span> employees</span><br><span class="line">                <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">             )</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">3</span>：</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> jobs</span><br><span class="line"><span class="keyword">WHERE</span> job_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> job_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">                <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">                <span class="keyword">FROM</span> employees</span><br><span class="line">                <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">                <span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_sal <span class="keyword">DESC</span></span><br><span class="line">                LIMIT <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">             )</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">4</span>：</span><br><span class="line"><span class="keyword">SELECT</span> j.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> jobs j,(</span><br><span class="line">        <span class="keyword">SELECT</span> job_id,<span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">GROUP</span> <span class="keyword">BY</span> job_id</span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_sal <span class="keyword">DESC</span></span><br><span class="line">        LIMIT <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">        ) t_job_avg_sal</span><br><span class="line"><span class="keyword">WHERE</span> j.job_id <span class="operator">=</span> t_job_avg_sal.job_id;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-12_23-23-31.png" alt="Snipaste_2023-07-12_23-23-31"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">11.</span>查询平均工资高于公司平均工资的部门有哪些?</span><br><span class="line"># 首先查询一下公司的平均工资</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">&gt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-24-03.png" alt="Snipaste_2023-07-12_23-24-03" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">12.</span>查询出公司中所有 manager 的详细信息</span><br><span class="line"># 方式<span class="number">1</span>：自连接</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> mgr.employee_id,mgr.last_name,mgr.job_id,mgr.department_id</span><br><span class="line"><span class="keyword">FROM</span> employees emp <span class="keyword">JOIN</span> employees mgr</span><br><span class="line"><span class="keyword">ON</span> emp.manager_id <span class="operator">=</span> mgr.employee_id;</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：子查询，更易懂</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,job_id,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">3</span>：使用EXIST</span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,job_id,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e1</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">EXISTS</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line">    <span class="keyword">FROM</span> employees e2</span><br><span class="line">    <span class="keyword">WHERE</span> e1.employee_id <span class="operator">=</span> e2.manager_id</span><br><span class="line">          );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-24-35.png" alt="Snipaste_2023-07-12_23-24-35" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">13.</span>各个部门中 最高工资中最低的那个部门的 最低工资是多少?</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">MAX</span>(salary) max_sal</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> max_sal</span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">1</span>;# <span class="number">4400</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">14.</span>查询平均工资最高的部门的 manager 的详细信息: last_name, department_id, email, salary</span><br><span class="line"># 先查询平均工资最高值</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_sal <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">0</span>,<span class="number">1</span>;</span><br><span class="line"># 再查询平均工资最高的部门</span><br><span class="line"><span class="keyword">SELECT</span> department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_sal <span class="keyword">DESC</span></span><br><span class="line">    LIMIT <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">    );</span><br><span class="line"># 再查询该部门的manage_id</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> manager_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_sal <span class="keyword">DESC</span></span><br><span class="line">        LIMIT <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">    );</span><br><span class="line"># 再查询对应manage_id的详细信息</span><br><span class="line"><span class="keyword">SELECT</span> last_name, department_id, email, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> department_id <span class="operator">=</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> department_id</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">        <span class="keyword">HAVING</span> <span class="built_in">AVG</span>(salary) <span class="operator">=</span> (</span><br><span class="line">            <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">            <span class="keyword">FROM</span> employees</span><br><span class="line">            <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">            <span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_sal <span class="keyword">DESC</span></span><br><span class="line">            LIMIT <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name, department_id, email, salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> employee_id <span class="keyword">IN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> manager_id</span><br><span class="line">    <span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary) avg_sal</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">        <span class="keyword">ORDER</span> <span class="keyword">BY</span> avg_sal <span class="keyword">DESC</span></span><br><span class="line">        LIMIT <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">    ) t_dept_avg_sal</span><br><span class="line">    <span class="keyword">WHERE</span> e.department_id <span class="operator">=</span> t_dept_avg_sal.department_id</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-12_23-25-27.png" alt="Snipaste_2023-07-12_23-25-27"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">15.</span> 查询部门的部门号，其中不包括job_id是&quot;ST_CLERK&quot;的部门号</span><br><span class="line"># 查询job_id是&quot;ST_CLERK&quot;的部门号</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> department_id</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> job_id <span class="operator">=</span> <span class="string">&#x27;ST_CLERK&#x27;</span>;</span><br><span class="line"># 查询除了该部门号的其他部门号</span><br><span class="line"><span class="keyword">SELECT</span> department_id</span><br><span class="line"><span class="keyword">FROM</span> departments</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">!=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> department_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> job_id <span class="operator">=</span> <span class="string">&#x27;ST_CLERK&#x27;</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-25-53.png" alt="Snipaste_2023-07-12_23-25-53" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">16.</span> 选择所有没有管理者的员工的last_name</span><br><span class="line"># 方式<span class="number">1</span>：</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees emp</span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>(</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line">    <span class="keyword">FROM</span> employees mgr</span><br><span class="line">    <span class="keyword">WHERE</span> emp.manager_id <span class="operator">=</span> mgr.employee_id</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span>：</span><br><span class="line"><span class="keyword">SELECT</span> last_name</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> manager_id <span class="keyword">IS</span> <span class="keyword">NULL</span>;# King</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">17</span>．查询员工号、姓名、雇用时间、工资，其中员工的管理者为 <span class="string">&#x27;De Haan&#x27;</span></span><br><span class="line"><span class="keyword">SELECT</span> employee_id,last_name,hire_date,salary</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">WHERE</span> manager_id <span class="operator">=</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> employee_id</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">WHERE</span> last_name <span class="operator">=</span> <span class="string">&#x27;De Haan&#x27;</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-07-12_23-27-01.png" alt="Snipaste_2023-07-12_23-27-01"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">18.</span>查询各部门中工资比本部门平均工资高的员工的员工号, 姓名和工资（相关子查询）</span><br><span class="line"># 方式<span class="number">1</span>：使用相关子查询</span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e1</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&gt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">    <span class="keyword">FROM</span> employees e2</span><br><span class="line">    <span class="keyword">WHERE</span> department_id <span class="operator">=</span> e1.department_id</span><br><span class="line">    );</span><br><span class="line"># 方式<span class="number">2</span>：在<span class="keyword">FROM</span>中使用子查询</span><br><span class="line"># 先查询各个部门的平均工资</span><br><span class="line"><span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary)</span><br><span class="line"><span class="keyword">FROM</span> employees</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id;# Q1</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> e.last_name,e.salary,e.department_id</span><br><span class="line"><span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> department_id,<span class="built_in">AVG</span>(salary) &quot;avg_sal&quot;</span><br><span class="line">    <span class="keyword">FROM</span> employees</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> department_id</span><br><span class="line">    ) t_dept_avg_sal</span><br><span class="line"><span class="keyword">ON</span> e.department_id <span class="operator">=</span> t_dept_avg_sal.department_id</span><br><span class="line"><span class="keyword">WHERE</span> e.salary <span class="operator">&gt;</span> t_dept_avg_sal.avg_sal;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-27-33.png" alt="Snipaste_2023-07-12_23-27-33" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">19.</span>查询每个部门下的部门人数大于 <span class="number">5</span> 的部门名称（相关子查询）</span><br><span class="line"><span class="keyword">SELECT</span> department_name</span><br><span class="line"><span class="keyword">FROM</span> departments d</span><br><span class="line"><span class="keyword">WHERE</span> <span class="number">5</span> <span class="operator">&lt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line">    <span class="keyword">FROM</span> employees e</span><br><span class="line">    <span class="keyword">WHERE</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line">    );</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-12_23-28-01.png" alt="Snipaste_2023-07-12_23-28-01" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">20.</span>查询每个国家下的部门个数大于 <span class="number">2</span> 的国家编号（相关子查询）</span><br><span class="line"><span class="keyword">SELECT</span> country_id</span><br><span class="line"><span class="keyword">FROM</span> locations l</span><br><span class="line"><span class="keyword">WHERE</span> <span class="number">2</span> <span class="operator">&lt;</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line">    <span class="keyword">FROM</span> departments d</span><br><span class="line">    <span class="keyword">WHERE</span> l.location_id <span class="operator">=</span> d.location_id</span><br><span class="line">    );# US</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 子查询编写技巧：①从里往外写，②从外往里写</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> 如何选择？</span></span><br><span class="line"><span class="comment"> ①如果子查询相对较简单，建议从外往里写。一旦子查询结构较复杂，则建议从里往外写</span></span><br><span class="line"><span class="comment"> ②如果是相关子查询，通常是从外往里写</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<h2 id="08-创建和管理表"><a href="#08-创建和管理表" class="headerlink" title="08 创建和管理表"></a>08 创建和管理表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">1.</span> 创建数据库test01_office,指明字符集为utf8。并在此数据库下执行下述操作</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test01_office <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span>;</span><br><span class="line"></span><br><span class="line">USE test01_office;</span><br><span class="line"></span><br><span class="line">#<span class="number">2.</span> 创建表dept01</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">字段 类型</span></span><br><span class="line"><span class="comment">id INT(7)</span></span><br><span class="line"><span class="comment">NAME VARCHAR(25)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> dept01(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    NAME <span class="type">VARCHAR</span>(<span class="number">25</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#<span class="number">3.</span> 将表departments中的数据插入新表dept02中</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> dept02</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> atguigudb.departments;</span><br><span class="line"></span><br><span class="line">#<span class="number">4.</span> 创建表emp01</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">字段 类型</span></span><br><span class="line"><span class="comment">id INT(7)</span></span><br><span class="line"><span class="comment">first_name VARCHAR (25)</span></span><br><span class="line"><span class="comment">last_name VARCHAR(25)</span></span><br><span class="line"><span class="comment">dept_id INT(7)</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> emp01(</span><br><span class="line">    id <span class="type">INT</span>(<span class="number">7</span>),</span><br><span class="line">    first_name <span class="type">VARCHAR</span> (<span class="number">25</span>),</span><br><span class="line">    last_name <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    dept_id <span class="type">INT</span>(<span class="number">7</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">#<span class="number">5.</span> 将列last_name的长度增加到<span class="number">50</span></span><br><span class="line"><span class="keyword">DESC</span> emp01;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp01</span><br><span class="line">MODIFY last_name <span class="type">VARCHAR</span>(<span class="number">50</span>);</span><br><span class="line"></span><br><span class="line">#<span class="number">6.</span> 根据表employees创建emp02</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> emp02</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> atguigudb.employees;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> TABLES;</span><br><span class="line"></span><br><span class="line">#<span class="number">7.</span> 删除表emp01</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> emp01;</span><br><span class="line"><span class="keyword">SHOW</span> TABLES;</span><br><span class="line"></span><br><span class="line">#<span class="number">8.</span> 将表emp02重命名为emp01</span><br><span class="line">RENAME <span class="keyword">TABLE</span> emp02 <span class="keyword">TO</span> emp01;</span><br><span class="line"><span class="keyword">SHOW</span> TABLES;</span><br><span class="line"></span><br><span class="line">#<span class="number">9.</span>在表dept02和emp01中添加新列test_column，并检查所作的操作</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp01</span><br><span class="line"><span class="keyword">ADD</span> test_column <span class="type">VARCHAR</span>(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> emp01;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> dept02</span><br><span class="line"><span class="keyword">ADD</span> test_column <span class="type">VARCHAR</span>(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> dept02;</span><br><span class="line"></span><br><span class="line">#<span class="number">10.</span>直接删除表emp01中的列 department_id</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp01</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">COLUMN</span> department_id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> emp01;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1</span>、创建数据库 test02_market</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test02_market <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span>;</span><br><span class="line"></span><br><span class="line">USE test02_market;</span><br><span class="line"># <span class="number">2</span>、创建数据表 customers</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">字段名       数据类型</span></span><br><span class="line"><span class="comment">c_num       int</span></span><br><span class="line"><span class="comment">c_name      varchar(50)</span></span><br><span class="line"><span class="comment">c_contact   varchar(50)</span></span><br><span class="line"><span class="comment">c_city      varchar(50)</span></span><br><span class="line"><span class="comment">c_birth     date</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> customers(</span><br><span class="line">    c_num <span class="type">INT</span>,</span><br><span class="line">    c_name <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    c_contact <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    c_city <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    c_birth <span class="type">date</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SHOW</span> TABLES ;</span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>、将 c_contact 字段移动到 c_birth 字段后面</span><br><span class="line"><span class="keyword">DESC</span> customers;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> customers</span><br><span class="line">MODIFY c_contact <span class="type">VARCHAR</span>(<span class="number">50</span>) AFTER c_birth;</span><br><span class="line"><span class="keyword">DESC</span> customers;</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>、将 c_name 字段数据类型改为 <span class="type">varchar</span>(<span class="number">70</span>)</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> customers</span><br><span class="line">MODIFY c_name <span class="type">VARCHAR</span>(<span class="number">70</span>);</span><br><span class="line"><span class="keyword">DESC</span> customers;</span><br><span class="line"></span><br><span class="line"># <span class="number">5</span>、将c_contact字段改名为c_phone</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> customers</span><br><span class="line">CHANGE c_contact c_phone <span class="type">VARCHAR</span>(<span class="number">50</span>);</span><br><span class="line"><span class="keyword">DESC</span> customers;</span><br><span class="line"></span><br><span class="line"># <span class="number">6</span>、增加c_gender字段到c_name后面，数据类型为<span class="type">char</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> customers</span><br><span class="line"><span class="keyword">ADD</span> c_gender <span class="type">CHAR</span>(<span class="number">1</span>) AFTER c_name;</span><br><span class="line"><span class="keyword">DESC</span> customers;</span><br><span class="line"># <span class="number">7.</span> 将表名改为customers_info</span><br><span class="line">RENAME <span class="keyword">TABLE</span> customers</span><br><span class="line"><span class="keyword">TO</span> customers_info;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> customers_info;</span><br><span class="line"># <span class="number">8</span>、删除字段c_city</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> customers_info</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">COLUMN</span> c_city;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">1</span>、创建数据库test03_company</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> test03_company;</span><br><span class="line"></span><br><span class="line">USE test03_company;</span><br><span class="line"># <span class="number">2</span>、创建表offices</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 字段名         数据类型</span></span><br><span class="line"><span class="comment">officeCode      int</span></span><br><span class="line"><span class="comment">city          varchar(30)</span></span><br><span class="line"><span class="comment">address       varchar(50)</span></span><br><span class="line"><span class="comment">country       varchar(50)</span></span><br><span class="line"><span class="comment">postalCode    varchar(25)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> offices(</span><br><span class="line">    officeCode <span class="type">INT</span>,</span><br><span class="line">    city <span class="type">VARCHAR</span>(<span class="number">30</span>),</span><br><span class="line">    address <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    country <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    postalCode <span class="type">VARCHAR</span>(<span class="number">25</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> offices;</span><br><span class="line"></span><br><span class="line"># <span class="number">3</span>、创建表employees</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 字段名    数据类型</span></span><br><span class="line"><span class="comment">empNum     int</span></span><br><span class="line"><span class="comment">lastName   varchar(50)</span></span><br><span class="line"><span class="comment">firstName  varchar(50)</span></span><br><span class="line"><span class="comment">mobile     varchar(25)</span></span><br><span class="line"><span class="comment">code       int</span></span><br><span class="line"><span class="comment">jobTitle   varchar(50)</span></span><br><span class="line"><span class="comment">birth      date</span></span><br><span class="line"><span class="comment">note       varchar(255)</span></span><br><span class="line"><span class="comment">sex        varchar(5)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> employees(</span><br><span class="line">    empNum <span class="type">INT</span>,</span><br><span class="line">    lastName <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    firstName <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    mobile <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    code <span class="type">INT</span>,</span><br><span class="line">    jobTitle <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    birth <span class="type">DATE</span>,</span><br><span class="line">    note <span class="type">VARCHAR</span>(<span class="number">225</span>),</span><br><span class="line">    sex <span class="type">VARCHAR</span>(<span class="number">5</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> employees;</span><br><span class="line"></span><br><span class="line"># <span class="number">4</span>、将表employees的mobile字段修改到code字段后面</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line">MODIFY mobile <span class="type">VARCHAR</span>(<span class="number">20</span>) AFTER code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> employees;</span><br><span class="line"># <span class="number">5</span>、将表employees的birth字段改名为birthday</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line">CHANGE birth birthday <span class="type">DATE</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> employees;</span><br><span class="line"># <span class="number">6</span>、修改sex字段，数据类型为<span class="type">char</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line">MODIFY sex <span class="type">CHAR</span>(<span class="number">1</span>);</span><br><span class="line"><span class="keyword">DESC</span> employees;</span><br><span class="line"></span><br><span class="line"># <span class="number">7</span>、删除字段note</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">COLUMN</span> note;</span><br><span class="line"><span class="keyword">DESC</span> employees;</span><br><span class="line"></span><br><span class="line"># <span class="number">8</span>、增加字段名favoriate_activity，数据类型为<span class="type">varchar</span>(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line"><span class="keyword">ADD</span> favoriate_activity <span class="type">VARCHAR</span>(<span class="number">100</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> employees;</span><br><span class="line"></span><br><span class="line"># <span class="number">9</span>、将表employees的名称修改为 employees_info</span><br><span class="line">RENAME <span class="keyword">TABLE</span> employees</span><br><span class="line"><span class="keyword">TO</span> employees_info;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> employees_info;</span><br></pre></td></tr></table></figure>

<h2 id="09-数据处理之增删改"><a href="#09-数据处理之增删改" class="headerlink" title="09 数据处理之增删改"></a>09 数据处理之增删改</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">## 练习<span class="number">1</span></span><br><span class="line"></span><br><span class="line">#<span class="number">1.</span> 创建数据库dbtest11</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> dbtest11 <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8&#x27;</span>;</span><br><span class="line">#<span class="number">2.</span> 运行以下脚本创建表my_employees</span><br><span class="line">USE dbtest11;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> my_employees(</span><br><span class="line">id <span class="type">INT</span>(<span class="number">10</span>),</span><br><span class="line">first_name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">last_name <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">userid <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">salary <span class="keyword">DOUBLE</span>(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> users(</span><br><span class="line">id <span class="type">INT</span>,</span><br><span class="line">userid <span class="type">VARCHAR</span>(<span class="number">10</span>),</span><br><span class="line">department_id <span class="type">INT</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">3.</span> 显示表my_employees的结构</span><br><span class="line"><span class="keyword">DESC</span> my_employees;</span><br><span class="line"><span class="keyword">DESC</span> users;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_21-56-06.png" alt="Snipaste_2023-07-19_21-56-06" style="zoom:33%;">

<img src="Snipaste_2023-07-19_21-56-57.png" alt="Snipaste_2023-07-19_21-56-57" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">4.</span> 向my_employees表中插入下列数据</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">ID FIRST_NAME LAST_NAME USERID SALARY</span></span><br><span class="line"><span class="comment">1 patel Ralph Rpatel 895</span></span><br><span class="line"><span class="comment">2 Dancs Betty Bdancs 860</span></span><br><span class="line"><span class="comment">3 Biri Ben Bbiri 1100</span></span><br><span class="line"><span class="comment">4 Newman Chad Cnewman 750</span></span><br><span class="line"><span class="comment">5 Ropeburn Audrey Aropebur 1550</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> # 方式<span class="number">1</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> my_employees</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">1</span>,<span class="string">&#x27;patel&#x27;</span>,<span class="string">&#x27;Ralph&#x27;</span>,<span class="string">&#x27;Rpatel&#x27;</span>,<span class="number">895</span>),</span><br><span class="line">(<span class="number">2</span>,<span class="string">&#x27;Dancs&#x27;</span>,<span class="string">&#x27;Betty&#x27;</span>,<span class="string">&#x27;Bdancs&#x27;</span>,<span class="number">860</span>),</span><br><span class="line">(<span class="number">3</span>,<span class="string">&#x27;Biri&#x27;</span>,<span class="string">&#x27;Ben&#x27;</span>,<span class="string">&#x27;Bbiri&#x27;</span>,<span class="number">1100</span>),</span><br><span class="line">(<span class="number">4</span>,<span class="string">&#x27;Newman&#x27;</span>,<span class="string">&#x27;Chad&#x27;</span>,<span class="string">&#x27;Cnewman&#x27;</span>,<span class="number">750</span>),</span><br><span class="line">(<span class="number">5</span>,<span class="string">&#x27;Ropeburn&#x27;</span>,<span class="string">&#x27;Audrey&#x27;</span>,<span class="string">&#x27;Aropebur&#x27;</span>,<span class="number">1550</span>);</span><br><span class="line"></span><br><span class="line"># 方式<span class="number">2</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> my_employees</span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">1</span>,<span class="string">&#x27;patel&#x27;</span>,<span class="string">&#x27;Ralph&#x27;</span>,<span class="string">&#x27;Rpatel&#x27;</span>,<span class="number">895</span> <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">2</span>,<span class="string">&#x27;Dancs&#x27;</span>,<span class="string">&#x27;Betty&#x27;</span>,<span class="string">&#x27;Bdancs&#x27;</span>,<span class="number">860</span> <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">3</span>,<span class="string">&#x27;Biri&#x27;</span>,<span class="string">&#x27;Ben&#x27;</span>,<span class="string">&#x27;Bbiri&#x27;</span>,<span class="number">1100</span> <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">4</span>,<span class="string">&#x27;Newman&#x27;</span>,<span class="string">&#x27;Chad&#x27;</span>,<span class="string">&#x27;Cnewman&#x27;</span>,<span class="number">750</span> <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="number">5</span>,<span class="string">&#x27;Ropeburn&#x27;</span>,<span class="string">&#x27;Audrey&#x27;</span>,<span class="string">&#x27;Aropebur&#x27;</span>,<span class="number">1550</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> my_employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-01-22.png" alt="Snipaste_2023-07-19_22-01-22" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">5.</span> 向users表中插入数据</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">1 Rpatel 10</span></span><br><span class="line"><span class="comment">2 Bdancs 10</span></span><br><span class="line"><span class="comment">3 Bbiri 20</span></span><br><span class="line"><span class="comment">4 Cnewman 30</span></span><br><span class="line"><span class="comment">5 Aropebur 40</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> users</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">1</span>,<span class="string">&#x27;Rpatel&#x27;</span>,<span class="number">10</span>),</span><br><span class="line">(<span class="number">2</span>,<span class="string">&#x27;Bdancs&#x27;</span>,<span class="number">10</span>),</span><br><span class="line">(<span class="number">3</span>,<span class="string">&#x27;Bbiri&#x27;</span>,<span class="number">20</span>),</span><br><span class="line">(<span class="number">4</span>,<span class="string">&#x27;Cnewman&#x27;</span>,<span class="number">30</span>),</span><br><span class="line">(<span class="number">5</span>,<span class="string">&#x27;Aropebur&#x27;</span>,<span class="number">40</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> users;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-03-54.png" alt="Snipaste_2023-07-19_22-03-54" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">6.</span> 将<span class="number">3</span>号员工的last_name修改为“drelxer”</span><br><span class="line"><span class="keyword">UPDATE</span> my_employees</span><br><span class="line"><span class="keyword">SET</span> last_name <span class="operator">=</span> <span class="string">&#x27;drelxer&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> my_employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-11-40.png" alt="Snipaste_2023-07-19_22-11-40" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">7.</span> 将所有工资少于<span class="number">900</span>的员工的工资修改为<span class="number">1000</span></span><br><span class="line"><span class="keyword">UPDATE</span> my_employees</span><br><span class="line"><span class="keyword">SET</span> salary <span class="operator">=</span> <span class="number">1000</span></span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="operator">&lt;</span> <span class="number">900</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> my_employees;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-13-29.png" alt="Snipaste_2023-07-19_22-13-29" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">8.</span> 将userid为Bbiri的<span class="keyword">user</span>表和my_employees表的记录全部删除</span><br><span class="line"><span class="keyword">DELETE</span> m,u</span><br><span class="line"><span class="keyword">FROM</span> my_employees m</span><br><span class="line"><span class="keyword">JOIN</span> users u</span><br><span class="line"><span class="keyword">ON</span> m.userid <span class="operator">=</span> u.userid</span><br><span class="line"><span class="keyword">WHERE</span> m.userid <span class="operator">=</span> <span class="string">&#x27;Bbiri&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> my_employees;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> users;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-18-29.png" alt="Snipaste_2023-07-19_22-18-29" style="zoom:33%;">

<img src="Snipaste_2023-07-19_22-18-38.png" alt="Snipaste_2023-07-19_22-18-38" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">9.</span> 删除my_employees、users表所有数据</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> my_employees;</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> users;</span><br><span class="line">#<span class="number">10.</span> 检查所作的修正</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> my_employees;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> users;</span><br><span class="line">#<span class="number">11.</span> 清空表my_employees</span><br><span class="line"><span class="keyword">TRUNCATE</span> <span class="keyword">TABLE</span> my_employees;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">## 练习<span class="number">2</span></span><br><span class="line"></span><br><span class="line"># <span class="number">1.</span> 使用现有数据库dbtest11</span><br><span class="line">USE dbtest11;</span><br><span class="line"># <span class="number">2.</span> 创建表格pet</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> 字段名 字段说明 数据类型</span></span><br><span class="line"><span class="comment">name 宠物名称 VARCHAR(20)</span></span><br><span class="line"><span class="comment">owner 宠物主人 VARCHAR(20)</span></span><br><span class="line"><span class="comment">species 种类 VARCHAR(20)</span></span><br><span class="line"><span class="comment">sex 性别 CHAR(1)</span></span><br><span class="line"><span class="comment">birth 出生日期 YEAR</span></span><br><span class="line"><span class="comment">death 死亡日期 YEAR</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> pet(</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">    owner <span class="type">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">    species <span class="type">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">    sex <span class="type">CHAR</span>(<span class="number">1</span>),</span><br><span class="line">    birth <span class="keyword">YEAR</span>,</span><br><span class="line">    death <span class="keyword">YEAR</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> pet;</span><br><span class="line"># <span class="number">3.</span> 添加记录</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> name     owner    species   sex   birth   death</span></span><br><span class="line"><span class="comment">Fluffy    harold    Cat       f    2003    2010</span></span><br><span class="line"><span class="comment">Claws     gwen      Cat       m    2004</span></span><br><span class="line"><span class="comment">Buffy               Dog       f    2009</span></span><br><span class="line"><span class="comment">Fang      benny     Dog       m    2000</span></span><br><span class="line"><span class="comment">bowser    diane     Dog       m    2003    2009</span></span><br><span class="line"><span class="comment">Chirpy              Bird      f    2008</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> pet</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line">(<span class="string">&#x27;Fluffy&#x27;</span>,<span class="string">&#x27;harold&#x27;</span>,<span class="string">&#x27;Cat&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;2003&#x27;</span>,<span class="string">&#x27;2010&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;Claws&#x27;</span>,<span class="string">&#x27;gwen&#x27;</span>,<span class="string">&#x27;Cat&#x27;</span>,<span class="string">&#x27;m&#x27;</span>,<span class="string">&#x27;2004&#x27;</span>,<span class="keyword">NULL</span>),</span><br><span class="line">(<span class="string">&#x27;Buffy&#x27;</span>,<span class="keyword">NULL</span>,<span class="string">&#x27;Dog&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;2009&#x27;</span>,<span class="keyword">NULL</span>),</span><br><span class="line">(<span class="string">&#x27;Fang&#x27;</span>,<span class="string">&#x27;benny&#x27;</span>,<span class="string">&#x27;Dog&#x27;</span>,<span class="string">&#x27;m&#x27;</span>,<span class="string">&#x27;2000&#x27;</span>,<span class="keyword">NULL</span>),</span><br><span class="line">(<span class="string">&#x27;bowser&#x27;</span>,<span class="string">&#x27;diane&#x27;</span>,<span class="string">&#x27;Dog&#x27;</span>,<span class="string">&#x27;m&#x27;</span>,<span class="string">&#x27;2003&#x27;</span>,<span class="string">&#x27;2009&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;Chirpy&#x27;</span>,<span class="keyword">NULL</span>,<span class="string">&#x27;Bird&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;2008&#x27;</span>,<span class="keyword">NULL</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> pet;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-30-01.png" alt="Snipaste_2023-07-19_22-30-01" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span> 添加字段:主人的生日owner_birth <span class="type">DATE</span>类型。</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> pet</span><br><span class="line"><span class="keyword">ADD</span> owner_birth <span class="type">DATE</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> pet;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-31-50.png" alt="Snipaste_2023-07-19_22-31-50" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.</span> 将名称为Claws的猫的主人改为kevin</span><br><span class="line"><span class="keyword">UPDATE</span> pet</span><br><span class="line"><span class="keyword">SET</span> owner <span class="operator">=</span> <span class="string">&#x27;kevin&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> name <span class="operator">=</span> <span class="string">&#x27;Claws&#x27;</span> <span class="keyword">AND</span> species <span class="operator">=</span> <span class="string">&#x27;Cat&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> pet;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-33-55.png" alt="Snipaste_2023-07-19_22-33-55" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.</span> 将没有死的狗的主人改为duck</span><br><span class="line"><span class="keyword">UPDATE</span> pet</span><br><span class="line"><span class="keyword">SET</span> owner <span class="operator">=</span> <span class="string">&#x27;duck&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> death <span class="keyword">IS</span> <span class="keyword">NULL</span> <span class="keyword">AND</span> species <span class="operator">=</span> <span class="string">&#x27;Dog&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> pet;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-35-59.png" alt="Snipaste_2023-07-19_22-35-59" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">7.</span> 查询没有主人的宠物的名字；</span><br><span class="line"><span class="keyword">SELECT</span> name</span><br><span class="line"><span class="keyword">FROM</span> pet</span><br><span class="line"><span class="keyword">WHERE</span> owner <span class="keyword">IS</span> <span class="keyword">NULL</span>; # Chirpy</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">8.</span> 查询已经死了的cat的姓名，主人，以及去世时间；</span><br><span class="line"><span class="keyword">SELECT</span> name,owner,death</span><br><span class="line"><span class="keyword">FROM</span> pet</span><br><span class="line"><span class="keyword">WHERE</span> death <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">AND</span> species <span class="operator">=</span> <span class="string">&#x27;Cat&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-40-14.png" alt="Snipaste_2023-07-19_22-40-14" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">9.</span> 删除已经死亡的狗</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> pet</span><br><span class="line"><span class="keyword">WHERE</span> death <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">AND</span> species <span class="operator">=</span> <span class="string">&#x27;Dog&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> pet;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-41-25.png" alt="Snipaste_2023-07-19_22-41-25" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">## 练习<span class="number">3</span></span><br><span class="line"></span><br><span class="line"># <span class="number">1.</span> 使用已有的数据库dbtest11</span><br><span class="line">USE dbtest11;</span><br><span class="line"># <span class="number">2.</span> 创建表employee，并添加记录</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> id name sex tel addr salary</span></span><br><span class="line"><span class="comment">10001 张一一 男 13456789000 山东青岛 1001.58</span></span><br><span class="line"><span class="comment">10002 刘小红 女 13454319000 河北保定 1201.21</span></span><br><span class="line"><span class="comment">10003 李四 男 0751-1234567 广东佛山 1004.11</span></span><br><span class="line"><span class="comment">10004 刘小强 男 0755-5555555 广东深圳 1501.23</span></span><br><span class="line"><span class="comment">10005 王艳 女 020-1232133 广东广州 1405.16</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employee(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    name <span class="type">VARCHAR</span>(<span class="number">15</span>),</span><br><span class="line">    sex <span class="type">CHAR</span>(<span class="number">1</span>),</span><br><span class="line">    tel <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    addr <span class="type">VARCHAR</span>(<span class="number">35</span>),</span><br><span class="line">    salary <span class="keyword">DOUBLE</span>(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> employee(id,`name`,sex,tel,addr,salary)<span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">10001</span>,<span class="string">&#x27;张一一&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;13456789000&#x27;</span>,<span class="string">&#x27;山东青岛&#x27;</span>,<span class="number">1001.58</span>),</span><br><span class="line">(<span class="number">10002</span>,<span class="string">&#x27;刘小红&#x27;</span>,<span class="string">&#x27;女&#x27;</span>,<span class="string">&#x27;13454319000&#x27;</span>,<span class="string">&#x27;河北保定&#x27;</span>,<span class="number">1201.21</span>),</span><br><span class="line">(<span class="number">10003</span>,<span class="string">&#x27;李四&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;0751-1234567&#x27;</span>,<span class="string">&#x27;广东佛山&#x27;</span>,<span class="number">1004.11</span>),</span><br><span class="line">(<span class="number">10004</span>,<span class="string">&#x27;刘小强&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;0755-5555555&#x27;</span>,<span class="string">&#x27;广东深圳&#x27;</span>,<span class="number">1501.23</span>),</span><br><span class="line">(<span class="number">10005</span>,<span class="string">&#x27;王艳&#x27;</span>,<span class="string">&#x27;男&#x27;</span>,<span class="string">&#x27;020-1232133&#x27;</span>,<span class="string">&#x27;广东广州&#x27;</span>,<span class="number">1405.16</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-45-26.png" alt="Snipaste_2023-07-19_22-45-26" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">3.</span> 查询出薪资在<span class="number">1200</span><span class="operator">~</span><span class="number">1300</span>之间的员工信息。</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> employee</span><br><span class="line"><span class="keyword">WHERE</span> salary <span class="keyword">BETWEEN</span> <span class="number">1200</span> <span class="keyword">AND</span> <span class="number">1300</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-47-47.png" alt="Snipaste_2023-07-19_22-47-47" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">4.</span> 查询出姓“刘”的员工的工号，姓名，家庭住址。</span><br><span class="line"><span class="keyword">SELECT</span> id,name,addr</span><br><span class="line"><span class="keyword">FROM</span> employee</span><br><span class="line"><span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;刘%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-48-16.png" alt="Snipaste_2023-07-19_22-48-16" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5.</span> 将“李四”的家庭住址改为“广东韶关”</span><br><span class="line"><span class="keyword">UPDATE</span> employee</span><br><span class="line"><span class="keyword">SET</span> addr <span class="operator">=</span> <span class="string">&#x27;广东韶关&#x27;</span></span><br><span class="line"><span class="keyword">WHERE</span> name <span class="operator">=</span> <span class="string">&#x27;李四&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-49-42.png" alt="Snipaste_2023-07-19_22-49-42" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">6.</span> 查询出名字中带“小”的员工</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> employee</span><br><span class="line"><span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;%小%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-19_22-50-57.png" alt="Snipaste_2023-07-19_22-50-57" style="zoom:33%;">

<h2 id="10-约束"><a href="#10-约束" class="headerlink" title="10 约束"></a>10 约束</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 基础练习</span><br><span class="line"># 练习<span class="number">1</span></span><br><span class="line"># 已经存在数据库test04_emp，两张表emp2和dept2</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE test04_emp;</span><br><span class="line">use test04_emp;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> emp2(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    emp_name <span class="type">VARCHAR</span>(<span class="number">15</span>)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> dept2(</span><br><span class="line">    id <span class="type">INT</span>,</span><br><span class="line">    dept_name <span class="type">VARCHAR</span>(<span class="number">15</span>)</span><br><span class="line">);</span><br><span class="line">#<span class="number">1.</span>向表emp2的id列中添加<span class="keyword">PRIMARY</span> KEY约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp2</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> <span class="keyword">PRIMARY</span> KEY (id);</span><br><span class="line">#<span class="number">2.</span> 向表dept2的id列中添加<span class="keyword">PRIMARY</span> KEY约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> dept2</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> <span class="keyword">PRIMARY</span> KEY (id);</span><br><span class="line">#<span class="number">3.</span> 向表emp2中添加列dept_id，并在其中定义<span class="keyword">FOREIGN</span> KEY约束，与之相关联的列是dept2表中的id列。</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp2</span><br><span class="line"><span class="keyword">ADD</span> dept_id <span class="type">INT</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> emp2</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> fk_emp2_deptid <span class="keyword">FOREIGN</span> KEY (dept_id) <span class="keyword">REFERENCES</span> dept2(id);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 练习<span class="number">2</span></span><br><span class="line"># 承接《第<span class="number">11</span>章_数据处理之增删改》的综合案例。</span><br><span class="line">USE test01_library;</span><br><span class="line"><span class="keyword">DESC</span> books;</span><br><span class="line"># <span class="number">3</span>、使用<span class="keyword">ALTER</span>语句给books按如下要求增加相应的约束</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_21-31-52.png" alt="Snipaste_2023-07-25_21-31-52" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 练习<span class="number">2</span></span><br><span class="line"># 承接《第<span class="number">11</span>章_数据处理之增删改》的综合案例。</span><br><span class="line">USE test01_library;</span><br><span class="line"><span class="keyword">DESC</span> books;</span><br><span class="line"># <span class="number">3</span>、使用<span class="keyword">ALTER</span>语句给books按如下要求增加相应的约束</span><br><span class="line"># 给id加主键约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> books</span><br><span class="line"><span class="keyword">ADD</span> <span class="keyword">CONSTRAINT</span> <span class="keyword">PRIMARY</span> KEY (id);</span><br><span class="line"># 给id加自增约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> books</span><br><span class="line">MODIFY id <span class="type">INT</span> AUTO_INCREMENT;</span><br><span class="line"># 或者一起来：</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> books</span><br><span class="line">MODIFY id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT;</span><br><span class="line">#给name等字段增加非空约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> books</span><br><span class="line">MODIFY name <span class="type">VARCHAR</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> books</span><br><span class="line">MODIFY authors <span class="type">VARCHAR</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> books</span><br><span class="line">MODIFY price <span class="type">FLOAT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> ;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> books</span><br><span class="line">MODIFY pubdate <span class="keyword">YEAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> ;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> books</span><br><span class="line">MODIFY num <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> ;</span><br><span class="line"></span><br><span class="line"><span class="keyword">DESC</span> books;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_21-38-53.png" alt="Snipaste_2023-07-25_21-38-53" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 练习<span class="number">3</span></span><br><span class="line">#<span class="number">1.</span> 创建数据库test04_company</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE test04_company;</span><br><span class="line">#<span class="number">2.</span> 按照下表给出的表结构在test04_company数据库中创建两个数据表offices和employees</span><br><span class="line">USE test04_company;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-25_22-25-38.png" alt="Snipaste_2023-07-25_22-25-38" style="zoom: 33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> offices(</span><br><span class="line">    officeCode <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY ,</span><br><span class="line">    city <span class="type">VARCHAR</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    address <span class="type">VARCHAR</span>(<span class="number">50</span>),</span><br><span class="line">    country <span class="type">VARCHAR</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    postalCode <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="keyword">UNIQUE</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> employees(</span><br><span class="line">    employeeNumber <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT,</span><br><span class="line">    lastName <span class="type">VARCHAR</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    firstName <span class="type">VARCHAR</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    mobile <span class="type">VARCHAR</span>(<span class="number">25</span>) <span class="keyword">UNIQUE</span> ,</span><br><span class="line">    officeCode <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    jobTitle <span class="type">VARCHAR</span>(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    birth DATETIME <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line">    note <span class="type">VARCHAR</span>(<span class="number">225</span>) ,</span><br><span class="line">    sex <span class="type">VARCHAR</span>(<span class="number">25</span>),</span><br><span class="line">    <span class="keyword">CONSTRAINT</span> fk_emp_ofCode <span class="keyword">FOREIGN</span> KEY (officeCode) <span class="keyword">REFERENCES</span> offices(officeCode)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">3.</span> 将表employees的mobile字段修改到officeCode字段后面</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line">MODIFY mobile <span class="type">VARCHAR</span>(<span class="number">25</span>) AFTER officeCode;</span><br><span class="line"></span><br><span class="line">#<span class="number">4.</span> 将表employees的birth字段改名为employee_birth</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line">CHANGE birth employee_birth DATETIME;</span><br><span class="line"></span><br><span class="line">#<span class="number">5.</span> 修改sex字段，数据类型为<span class="type">CHAR</span>(<span class="number">1</span>)，非空约束</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line">MODIFY sex <span class="type">CHAR</span>(<span class="number">1</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ;</span><br><span class="line"></span><br><span class="line">#<span class="number">6.</span> 删除字段note</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">COLUMN</span> note;</span><br><span class="line"></span><br><span class="line">#<span class="number">7.</span> 增加字段名favoriate_activity，数据类型为<span class="type">VARCHAR</span>(<span class="number">100</span>)</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line"><span class="keyword">ADD</span> favoriate_activity <span class="type">VARCHAR</span>(<span class="number">100</span>);</span><br><span class="line"></span><br><span class="line">#<span class="number">8.</span> 将表employees名称修改为employees_info</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employees</span><br><span class="line">RENAME employees_info;</span><br></pre></td></tr></table></figure>

<h2 id="11-视图"><a href="#11-视图" class="headerlink" title="11 视图"></a>11 视图</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 练习<span class="number">1</span></span><br><span class="line">USE dbtest14;</span><br><span class="line">#<span class="number">1.</span> 使用表employees创建视图employee_vu，其中包括姓名（LAST_NAME），员工号（EMPLOYEE_ID），部门</span><br><span class="line"># 号(DEPARTMENT_ID)</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> REPLACE <span class="keyword">VIEW</span> employee_vu(lname,emp_id,dept_id)</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name,employee_id,department_id</span><br><span class="line"><span class="keyword">FROM</span> emps;</span><br><span class="line">#<span class="number">2.</span> 显示视图的结构</span><br><span class="line"><span class="keyword">DESC</span> employee_vu;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_22-25-44.png" alt="Snipaste_2023-07-26_22-25-44" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">3.</span> 查询视图中的全部内容</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> employee_vu;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-26_22-27-04.png" alt="Snipaste_2023-07-26_22-27-04" style="zoom:33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">4.</span> 将视图中的数据限定在部门号是<span class="number">80</span>的范围内</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> REPLACE <span class="keyword">VIEW</span> employee_vu(lname,emp_id,dept_id)</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name,employee_id,department_id</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> department_id <span class="operator">=</span> <span class="number">80</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># 练习<span class="number">2</span></span><br><span class="line">#<span class="number">1.</span> 创建视图emp_v1,要求查询电话号码以‘<span class="number">011</span>’开头的员工姓名和工资、邮箱</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> REPLACE <span class="keyword">VIEW</span> emp_v1</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name,salary,email</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> phone_number <span class="keyword">LIKE</span> <span class="string">&#x27;011%&#x27;</span>;</span><br><span class="line"></span><br><span class="line">#<span class="number">2.</span> 要求将视图 emp_v1 修改为查询电话号码以‘<span class="number">011</span>’开头的并且邮箱中包含 e 字符的员工姓名和邮箱、电话号码</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">OR</span> REPLACE <span class="keyword">VIEW</span> emp_v1</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> last_name,email,phone_number,salary</span><br><span class="line"><span class="keyword">FROM</span> emps</span><br><span class="line"><span class="keyword">WHERE</span> phone_number <span class="keyword">LIKE</span> <span class="string">&#x27;011%&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> email <span class="keyword">LIKE</span> <span class="string">&#x27;%e%&#x27;</span>;</span><br><span class="line"></span><br><span class="line">#<span class="number">3.</span> 向 emp_v1 插入一条记录，是否可以？</span><br><span class="line"># 失败，Field <span class="keyword">of</span> <span class="keyword">view</span> <span class="string">&#x27;dbtest14.emp_v1&#x27;</span> underlying <span class="keyword">table</span> doesn<span class="string">&#x27;t have a default value</span></span><br><span class="line"><span class="string">INSERT INTO emp_v1</span></span><br><span class="line"><span class="string">VALUES (&#x27;</span>TOM<span class="string">&#x27;,&#x27;</span>TOM<span class="variable">@126</span><span class="string">&#x27;,&#x27;</span><span class="number">01012345</span><span class="string">&#x27;);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#4. 修改emp_v1中员工的工资，每人涨薪1000</span></span><br><span class="line"><span class="string">UPDATE emp_v1</span></span><br><span class="line"><span class="string">SET salary = salary + 1000;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#5. 删除emp_v1中姓名为Olsen的员工</span></span><br><span class="line"><span class="string">DELETE FROM emp_v1</span></span><br><span class="line"><span class="string">WHERE last_name = &#x27;</span>Olsen<span class="string">&#x27;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#6. 创建视图emp_v2，要求查询部门的最高工资高于 12000 的部门id和其最高工资</span></span><br><span class="line"><span class="string">CREATE OR REPLACE VIEW emp_v2(dept_id,max_sal)</span></span><br><span class="line"><span class="string">AS</span></span><br><span class="line"><span class="string">SELECT department_id,MAX(salary)</span></span><br><span class="line"><span class="string">FROM emps</span></span><br><span class="line"><span class="string">GROUP BY department_id</span></span><br><span class="line"><span class="string">HAVING MAX(salary) &gt; 12000;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#7. 向 emp_v2 中插入一条记录，是否可以？</span></span><br><span class="line"><span class="string"># 失败，The target table emp_v2 of the INSERT is not insertable-into</span></span><br><span class="line"><span class="string">INSERT INTO emp_v2(dept_id, max_sal)</span></span><br><span class="line"><span class="string">VALUES (4000,20000);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#8. 删除刚才的emp_v2 和 emp_v1</span></span><br><span class="line"><span class="string">DROP VIEW IF EXISTS emp_v1,emp_v2;</span></span><br></pre></td></tr></table></figure>

<h2 id="12-存储过程和存储函数"><a href="#12-存储过程和存储函数" class="headerlink" title="12 存储过程和存储函数"></a>12 存储过程和存储函数</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 存储过程练习</span><br><span class="line">#<span class="number">0.</span>准备工作</span><br><span class="line"><span class="keyword">CREATE</span> DATABASE test15_pro_func;</span><br><span class="line">USE test15_pro_func;</span><br><span class="line">#<span class="number">1.</span> 创建存储过程insert_user(),实现传入用户名和密码，插入到admin表中</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> admin(</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT,</span><br><span class="line">    user_name <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    pwd <span class="type">VARCHAR</span>(<span class="number">25</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> insert_user(<span class="keyword">IN</span> user_name <span class="type">VARCHAR</span>(<span class="number">15</span>), <span class="keyword">IN</span> pwd <span class="type">VARCHAR</span>(<span class="number">25</span>))</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">INSERT</span> <span class="keyword">INTO</span> admin(user_name, pwd)</span><br><span class="line">    <span class="keyword">VALUES</span> (user_name,pwd);</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">CALL</span> insert_user(<span class="string">&#x27;TOM&#x27;</span>,<span class="string">&#x27;abc123&#x27;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> admin;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_21-51-55.png" alt="Snipaste_2023-07-27_21-51-55" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">2.</span> 创建存储过程get_phone(),实现传入女神编号，返回女神姓名和女神电话</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> beauty(</span><br><span class="line">    id <span class="type">INT</span> <span class="keyword">PRIMARY</span> KEY AUTO_INCREMENT,</span><br><span class="line">    NAME <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    phone <span class="type">VARCHAR</span>(<span class="number">15</span>) <span class="keyword">UNIQUE</span>,</span><br><span class="line">    birth <span class="type">DATE</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> beauty(NAME,phone,birth)</span><br><span class="line"><span class="keyword">VALUES</span></span><br><span class="line">(<span class="string">&#x27;朱茵&#x27;</span>,<span class="string">&#x27;13201233453&#x27;</span>,<span class="string">&#x27;1982-02-12&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;孙燕姿&#x27;</span>,<span class="string">&#x27;13501233653&#x27;</span>,<span class="string">&#x27;1980-12-09&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;田馥甄&#x27;</span>,<span class="string">&#x27;13651238755&#x27;</span>,<span class="string">&#x27;1983-08-21&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;邓紫棋&#x27;</span>,<span class="string">&#x27;17843283452&#x27;</span>,<span class="string">&#x27;1991-11-12&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;刘若英&#x27;</span>,<span class="string">&#x27;18635575464&#x27;</span>,<span class="string">&#x27;1989-05-18&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;杨超越&#x27;</span>,<span class="string">&#x27;13761238755&#x27;</span>,<span class="string">&#x27;1994-05-11&#x27;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> beauty;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> get_phone(<span class="keyword">IN</span> id <span class="type">INT</span>, <span class="keyword">OUT</span> name <span class="type">VARCHAR</span>(<span class="number">15</span>),<span class="keyword">OUT</span> phone <span class="type">VARCHAR</span>(<span class="number">15</span>))</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> b.NAME,b.phone <span class="keyword">INTO</span> name,phone</span><br><span class="line">    <span class="keyword">FROM</span> beauty b</span><br><span class="line">    <span class="keyword">WHERE</span> b.id <span class="operator">=</span> id;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">CALL</span> get_phone(<span class="number">1</span>,<span class="variable">@name</span>,<span class="variable">@phone</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@name</span>,<span class="variable">@phone</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_22-03-58.png" alt="Snipaste_2023-07-27_22-03-58" style="zoom: 50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">3.</span> 创建存储过程date_diff()，实现传入两个女神生日，返回日期间隔大小</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> date_diff(<span class="keyword">IN</span> birth1 <span class="type">DATE</span>,<span class="keyword">IN</span> birth2 <span class="type">DATE</span>,<span class="keyword">OUT</span> sum_date <span class="type">INT</span>)</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> DATEDIFF(birth1,birth2) <span class="keyword">INTO</span> sum_date;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@birth1</span> <span class="operator">=</span> <span class="string">&#x27;1992-09-08&#x27;</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@birth2</span> <span class="operator">=</span> <span class="string">&#x27;1992-09-18&#x27;</span>;</span><br><span class="line"><span class="keyword">CALL</span> date_diff(<span class="variable">@birth1</span>,<span class="variable">@birth2</span>,<span class="variable">@sum</span>_date);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@sum</span>_date;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_22-09-58.png" alt="Snipaste_2023-07-27_22-09-58" style="zoom: 50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">4.</span> 创建存储过程format_date(),实现传入一个日期，格式化成xx年xx月xx日并返回</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> format_date(<span class="keyword">IN</span> my_date <span class="type">DATE</span>,<span class="keyword">OUT</span> str_date <span class="type">VARCHAR</span>(<span class="number">25</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> DATE_FORMAT(my_date,<span class="string">&#x27;%y年%m月%d日&#x27;</span>) <span class="keyword">INTO</span> str_date;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CALL</span> format_date(CURDATE(),<span class="variable">@str</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@str</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_22-39-21.png" alt="Snipaste_2023-07-27_22-39-21" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">5.</span> 创建存储过程beauty_limit()，根据传入的起始索引和条目数，查询女神表的记录</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> beauty_limit(<span class="keyword">IN</span> start_index <span class="type">INT</span>,<span class="keyword">IN</span> size <span class="type">INT</span>)</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line">    <span class="keyword">FROM</span> beauty</span><br><span class="line">    LIMIT start_index,size;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CALL</span> beauty_limit(<span class="number">1</span>,<span class="number">3</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_22-42-12.png" alt="Snipaste_2023-07-27_22-42-12" style="zoom: 50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#创建带<span class="keyword">inout</span>模式参数的存储过程</span><br><span class="line">#<span class="number">6.</span> 传入a和b两个值，最终a和b都翻倍并返回</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> add_double(<span class="keyword">INOUT</span> a <span class="type">INT</span>,<span class="keyword">INOUT</span> b <span class="type">INT</span>)</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">SET</span> a <span class="operator">=</span> a<span class="operator">*</span><span class="number">2</span>;</span><br><span class="line">    <span class="keyword">SET</span> b <span class="operator">=</span> b<span class="operator">*</span><span class="number">2</span>;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@a</span> <span class="operator">=</span> <span class="number">3</span>,<span class="variable">@b</span> <span class="operator">=</span> <span class="number">5</span>;</span><br><span class="line"><span class="keyword">CALL</span> add_double(<span class="variable">@a</span>,<span class="variable">@b</span>);</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@a</span>,<span class="variable">@b</span>;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-07-27_22-45-08.png" alt="Snipaste_2023-07-27_22-45-08" style="zoom:50%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">7.</span> 删除题目<span class="number">5</span>的存储过程</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">PROCEDURE</span> IF <span class="keyword">EXISTS</span> beauty_limit;</span><br><span class="line">#<span class="number">8.</span> 查看题目<span class="number">6</span>中存储过程的信息</span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> add_double;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 存储函数练习</span><br><span class="line">#<span class="number">0.</span> 准备工作</span><br><span class="line">USE test15_pro_func;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employees</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> atguigudb.`employees`;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> departments</span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> atguigudb.`departments`;</span><br><span class="line">#无参有返回</span><br><span class="line">#<span class="number">1.</span> 创建函数get_count(),返回公司的员工个数</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> get_count()</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="type">INT</span></span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">RETURN</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        );</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SELECT</span> get_count();# <span class="number">107</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#有参有返回</span><br><span class="line">#<span class="number">2.</span> 创建函数ename_salary(),根据员工姓名，返回它的工资</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> ename_salary(emp_name <span class="type">VARCHAR</span>(<span class="number">15</span>))</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="keyword">DOUBLE</span></span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">RETURN</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> salary</span><br><span class="line">        <span class="keyword">FROM</span> employees</span><br><span class="line">        <span class="keyword">WHERE</span> last_name <span class="operator">=</span> emp_name</span><br><span class="line">        );</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SELECT</span> ename_salary(<span class="string">&#x27;Abel&#x27;</span>); # <span class="number">11000</span></span><br><span class="line">#<span class="number">3.</span> 创建函数dept_sal() ,根据部门名，返回该部门的平均工资</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> dept_sal(dept_name <span class="type">VARCHAR</span>(<span class="number">15</span>))</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="keyword">DOUBLE</span></span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">RETURN</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> <span class="built_in">AVG</span>(salary)</span><br><span class="line">        <span class="keyword">FROM</span> employees e <span class="keyword">JOIN</span> departments d</span><br><span class="line">        <span class="keyword">ON</span> e.department_id <span class="operator">=</span> d.department_id</span><br><span class="line">        <span class="keyword">WHERE</span> d.department_name <span class="operator">=</span> dept_name</span><br><span class="line">        );</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SELECT</span> dept_sal(<span class="string">&#x27;Marketing&#x27;</span>); # <span class="number">9500</span></span><br><span class="line">#<span class="number">4.</span> 创建函数add_float()，实现传入两个<span class="type">float</span>，返回二者之和</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">FUNCTION</span> add_float(float1 <span class="type">FLOAT</span>,float2 <span class="type">FLOAT</span>)</span><br><span class="line"><span class="keyword">RETURNS</span> <span class="type">FLOAT</span></span><br><span class="line"><span class="keyword">DETERMINISTIC</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="keyword">RETURN</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> float1 <span class="operator">+</span> float2</span><br><span class="line">        );</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"># 调用</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@v1</span> <span class="operator">=</span> <span class="number">12.2</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@v2</span> <span class="operator">=</span> <span class="number">2.3</span>;</span><br><span class="line"><span class="keyword">SELECT</span> add_float(<span class="variable">@v1</span>,<span class="variable">@v2</span>); # <span class="number">14.5</span></span><br></pre></td></tr></table></figure>

<h2 id="13-变量、流程控制与游标"><a href="#13-变量、流程控制与游标" class="headerlink" title="13 变量、流程控制与游标"></a>13 变量、流程控制与游标</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"># 一、变量</span><br><span class="line">#0.准备工作</span><br><span class="line">CREATE DATABASE test16_var_cur;</span><br><span class="line">use test16_var_cur;</span><br><span class="line">CREATE TABLE employees</span><br><span class="line">AS</span><br><span class="line">SELECT * FROM atguigudb.`employees`;</span><br><span class="line">CREATE TABLE departments</span><br><span class="line">AS</span><br><span class="line">SELECT * FROM atguigudb.`departments`;</span><br><span class="line">#无参有返回</span><br><span class="line">#1. 创建函数get_count(),返回公司的员工个数</span><br><span class="line">CREATE FUNCTION get_count()</span><br><span class="line">RETURNS INT</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明局部变量</span><br><span class="line">    DECLARE emp_count INT;</span><br><span class="line">    # 赋值</span><br><span class="line">    SELECT COUNT(*) INTO emp_count FROM employees;</span><br><span class="line"></span><br><span class="line">    RETURN emp_count;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">SELECT get_count(); # 107</span><br><span class="line"></span><br><span class="line">#有参有返回</span><br><span class="line">#2. 创建函数ename_salary(),根据员工姓名，返回它的工资</span><br><span class="line">CREATE FUNCTION ename_salary(emp_name VARCHAR(15))</span><br><span class="line">RETURNS DOUBLE</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    SET @sal = 0;</span><br><span class="line">    # 赋值</span><br><span class="line">    SELECT salary INTO @sal FROM employees WHERE last_name = emp_name;</span><br><span class="line"></span><br><span class="line">    RETURN @sal;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">SELECT ename_salary(&#x27;Abel&#x27;); # 11000</span><br><span class="line"></span><br><span class="line">#3. 创建函数dept_sal() ,根据部门名，返回该部门的平均工资</span><br><span class="line">CREATE FUNCTION dept_sal(dept_name VARCHAR(15))</span><br><span class="line">RETURNS DOUBLE</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE avg_sal DOUBLE;</span><br><span class="line"></span><br><span class="line">    SELECT AVG(salary) INTO avg_sal</span><br><span class="line">    FROM employees e JOIN departments d</span><br><span class="line">    ON e.department_id = d.department_id</span><br><span class="line">    WHERE d.department_name = dept_name;</span><br><span class="line"></span><br><span class="line">    RETURN avg_sal;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">SELECT dept_sal(&#x27;Marketing&#x27;); # 9500</span><br><span class="line"></span><br><span class="line">#4. 创建函数add_float()，实现传入两个float，返回二者之和</span><br><span class="line">CREATE FUNCTION add_float(value1 FLOAT,value2 FLOAT)</span><br><span class="line">RETURNS FLOAT</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    DECLARE sum_val FLOAT;</span><br><span class="line">    SET sum_val = value1 + value2;</span><br><span class="line">    RETURN sum_val;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">SET @v1 := 12.2;</span><br><span class="line">SET @v2 := 2.3;</span><br><span class="line">SELECT add_float(@v1,@v2); # 14.5</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># 二、流程控制</span><br><span class="line">#1. 创建函数test_if_case()，实现传入成绩，如果成绩&gt;90,返回A，如果成绩&gt;80,返回B，如果成绩&gt;60,返回</span><br><span class="line"># C，否则返回D</span><br><span class="line">#要求：分别使用if结构和case结构实现</span><br><span class="line"># 方式1：</span><br><span class="line">CREATE FUNCTION test_if_case1(score DOUBLE)</span><br><span class="line">RETURNS CHAR</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    DECLARE score_level CHAR;</span><br><span class="line">    IF score &gt; 90</span><br><span class="line">        THEN SET score_level = &#x27;A&#x27;;</span><br><span class="line">    ELSEIF score &gt; 80</span><br><span class="line">        THEN SET score_level = &#x27;B&#x27;;</span><br><span class="line">    ELSEIF score &gt; 60</span><br><span class="line">        THEN SET score_level = &#x27;C&#x27;;</span><br><span class="line">    ELSE</span><br><span class="line">        SET score_level = &#x27;D&#x27;;</span><br><span class="line">    END IF;</span><br><span class="line">    # 返回</span><br><span class="line">    RETURN score_level;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line"></span><br><span class="line"># 方式2：</span><br><span class="line">CREATE FUNCTION test_if_case2(score DOUBLE)</span><br><span class="line">RETURNS CHAR</span><br><span class="line">DETERMINISTIC</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    DECLARE score_level CHAR;</span><br><span class="line">    CASE</span><br><span class="line">    WHEN score &gt; 90 THEN SET score_level = &#x27;A&#x27;;</span><br><span class="line">    WHEN score &gt; 80 THEN SET score_level = &#x27;B&#x27;;</span><br><span class="line">    WHEN score &gt; 60 THEN SET score_level = &#x27;C&#x27;;</span><br><span class="line">    ELSE SET score_level = &#x27;D&#x27;;</span><br><span class="line">    END CASE;</span><br><span class="line"></span><br><span class="line">    # 返回</span><br><span class="line">    RETURN score_level;</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">SELECT test_if_case2(98); # A</span><br><span class="line"></span><br><span class="line">#2. 创建存储过程test_if_pro()，传入工资值，如果工资值&lt;3000,则删除工资为此值的员工，如果3000 &lt;= 工</span><br><span class="line"># 资值 &lt;= 5000,则修改此工资值的员工薪资涨1000，否则涨工资500</span><br><span class="line">CREATE PROCEDURE test_if_pro(IN sal DOUBLE)</span><br><span class="line">BEGIN</span><br><span class="line">    IF sal &lt; 3000</span><br><span class="line">        THEN DELETE FROM employees WHERE salary = sal;</span><br><span class="line">    ELSEIF sal &lt;= 5000</span><br><span class="line">        THEN UPDATE employees SET salary = salary + 1000 WHERE salary = sal;</span><br><span class="line">    ELSE</span><br><span class="line">        UPDATE employees SET salary = salary + 500 WHERE salary = sal;</span><br><span class="line">    END IF;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line"># 调用</span><br><span class="line">CALL test_if_pro(2500);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#3. 创建存储过程insert_data(),传入参数为 IN 的 INT 类型变量 insert_count,实现向admin表中批量插</span><br><span class="line"># 入insert_count条记录</span><br><span class="line">CREATE TABLE admin(</span><br><span class="line">    id INT PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">    user_name VARCHAR(25) NOT NULL,</span><br><span class="line">    user_pwd VARCHAR(35) NOT NULL</span><br><span class="line">);</span><br><span class="line">SELECT * FROM admin;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-10_19-55-46.png" alt="Snipaste_2023-08-10_19-55-46" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 调用</span><br><span class="line">CALL insert_data(100); # 循环插入一百条记录</span><br><span class="line">SELECT * FROM admin;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-10_19-56-40.png" alt="Snipaste_2023-08-10_19-56-40" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"># 三、游标的使用</span><br><span class="line">/*创建存储过程update_salary()，参数1为 IN 的INT型变量dept_id，表示部门id；参数2为 IN的INT型变量</span><br><span class="line">change_sal_count，表示要调整薪资的员工个数。查询指定id部门的员工信息，按照salary升序排列，根</span><br><span class="line">据hire_date的情况，调整前change_sal_count个员工的薪资，详情如下。</span><br><span class="line"></span><br><span class="line">hire_date                                    salary</span><br><span class="line">hire_date &lt; 1995                         salary = salary*1.2</span><br><span class="line">hire_date &gt;=1995 and hire_date &lt;= 1998   salary = salary*1.15</span><br><span class="line">hire_date &gt; 1998 and hire_date &lt;= 2001   salary = salary *1.10</span><br><span class="line">hire_date &gt; 2001                         salary = salary * 1.05</span><br><span class="line"> */</span><br><span class="line">CREATE PROCEDURE update_salary(IN dept_id INT,IN change_sal_count INT)</span><br><span class="line">BEGIN</span><br><span class="line">    # 声明变量</span><br><span class="line">    DECLARE emp_id INT; # 记录员工ID</span><br><span class="line">    DECLARE emp_hire_date DATE; # 记录员工入职时间</span><br><span class="line">    DECLARE init_count INT DEFAULT 1; # 表示循环结构的初始化条件</span><br><span class="line">    DECLARE add_sal_rate DOUBLE; # 记录涨薪的比例</span><br><span class="line">    # 声明游标</span><br><span class="line">    DECLARE emp_cursor CURSOR FOR SELECT employee_id,hire_date</span><br><span class="line">    FROM employees</span><br><span class="line">    WHERE department_id = dept_id</span><br><span class="line">    ORDER BY salary;</span><br><span class="line">    # 打开游标</span><br><span class="line">    OPEN emp_cursor;</span><br><span class="line"></span><br><span class="line">    WHILE init_count &lt;= change_sal_count DO</span><br><span class="line">        # 使用游标</span><br><span class="line">        # 获取涨薪的比例</span><br><span class="line">        FETCH emp_cursor INTO emp_id,emp_hire_date;</span><br><span class="line">        IF (YEAR(emp_hire_date) &lt; 1995)</span><br><span class="line">            THEN SET add_sal_rate = 1.2;</span><br><span class="line">        ELSEIF (YEAR(emp_hire_date) &lt;= 1998)</span><br><span class="line">            THEN SET add_sal_rate = 1.15;</span><br><span class="line">        ELSEIF (YEAR(emp_hire_date) &lt;= 2001)</span><br><span class="line">            THEN SET add_sal_rate = 1.10;</span><br><span class="line">        ELSE</span><br><span class="line">            SET add_sal_rate = 1.05;</span><br><span class="line">        END IF;</span><br><span class="line">        # 涨薪操作</span><br><span class="line">        UPDATE employees SET salary = salary * add_sal_rate</span><br><span class="line">        WHERE employee_id = emp_id;</span><br><span class="line">        # 迭代条件的更新</span><br><span class="line">        SET init_count = init_count + 1;</span><br><span class="line">    end while;</span><br><span class="line"></span><br><span class="line">    # 关闭游标</span><br><span class="line">    CLOSE emp_cursor;</span><br><span class="line"></span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line">SELECT employee_id,hire_date,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id = 50</span><br><span class="line">ORDER BY salary;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-10_20-31-36.png" alt="Snipaste_2023-08-10_20-31-36" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CALL update_salary(50,3);</span><br><span class="line"></span><br><span class="line">SELECT employee_id,hire_date,salary</span><br><span class="line">FROM employees</span><br><span class="line">WHERE department_id = 50</span><br><span class="line">ORDER BY salary;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-10_20-33-09.png" alt="Snipaste_2023-08-10_20-33-09" style="zoom:50%;">

<h2 id="14-触发器"><a href="#14-触发器" class="headerlink" title="14 触发器"></a>14 触发器</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 练习1：</span><br><span class="line">#0. 准备工作</span><br><span class="line">CREATE DATABASE test17_trigger;</span><br><span class="line">USE test17_trigger;</span><br><span class="line"></span><br><span class="line">CREATE TABLE emps</span><br><span class="line">AS</span><br><span class="line">SELECT employee_id,last_name,salary</span><br><span class="line">FROM atguigudb.`employees`;</span><br><span class="line">#1. 复制一张emps表的空表emps_back，只有表结构，不包含任何数据</span><br><span class="line">CREATE TABLE emps_back</span><br><span class="line">AS</span><br><span class="line">SELECT * FROM emps</span><br><span class="line">WHERE 1=2;</span><br><span class="line">#2. 查询emps_back表中的数据</span><br><span class="line">SELECT * FROM emps_back;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-11_12-16-01.png" alt="Snipaste_2023-08-11_12-16-01" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#3. 创建触发器emps_insert_trigger，每当向emps表中添加一条记录时，同步将这条记录添加到emps_back表中</span><br><span class="line">CREATE TRIGGER emps_insert_trigger</span><br><span class="line">AFTER INSERT ON emps</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    # 将新添加到emps表中的记录添加到emps_back表中</span><br><span class="line">    INSERT INTO emps_back(employee_id, last_name, salary)</span><br><span class="line">    VALUES (NEW.employee_id,NEW.last_name,NEW.salary);</span><br><span class="line">end;</span><br><span class="line"></span><br><span class="line">#4. 验证触发器是否起作用</span><br><span class="line">INSERT INTO emps(employee_id, last_name, salary)</span><br><span class="line">VALUES (300,&#x27;TOM&#x27;,3400);</span><br><span class="line">INSERT INTO emps(employee_id, last_name, salary)</span><br><span class="line">VALUES (301,&#x27;TOM1&#x27;,3600);</span><br><span class="line"></span><br><span class="line">SELECT * FROM emps_back;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-11_12-25-06.png" alt="Snipaste_2023-08-11_12-25-06" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># 练习2：</span><br><span class="line">#0. 准备工作：使用练习1中的emps表</span><br><span class="line">#1. 复制一张emps表的空表emps_back1，只有表结构，不包含任何数据</span><br><span class="line">CREATE TABLE emps_back1</span><br><span class="line">AS</span><br><span class="line">SELECT *</span><br><span class="line">FROM emps</span><br><span class="line">WHERE 1=2;</span><br><span class="line">#2. 查询emps_back1表中的数据</span><br><span class="line">SELECT * FROM emps_back1; # 空</span><br><span class="line">#3. 创建触发器emps_del_trigger，每当向emps表中删除一条记录时，同步将删除的这条记录添加到</span><br><span class="line"># emps_back1表中</span><br><span class="line">CREATE TRIGGER emps_del_trigger</span><br><span class="line">BEFORE DELETE ON emps</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    # 将emps表中删除的记录，添加到emps_back1表中</span><br><span class="line">    INSERT INTO emps_back1(employee_id, last_name, salary)</span><br><span class="line">    VALUES (OLD.employee_id,OLD.last_name,OLD.salary);</span><br><span class="line">end;</span><br><span class="line">#4. 验证触发器是否起作用</span><br><span class="line">DELETE FROM emps</span><br><span class="line">WHERE employee_id = 101;</span><br><span class="line">DELETE FROM emps</span><br><span class="line">WHERE employee_id = 102;</span><br><span class="line">SELECT * FROM emps_back1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-11_12-36-56.png" alt="Snipaste_2023-08-11_12-36-56" style="zoom:50%;">

<p><strong>总结：AFTER用NEW，BEFORE用OLD</strong></p>
<h2 id="15-窗口函数"><a href="#15-窗口函数" class="headerlink" title="15 窗口函数"></a>15 窗口函数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE test18_mysql18;</span><br><span class="line">USE test18_mysql18;</span><br><span class="line">#1. 创建students数据表，如下</span><br><span class="line">CREATE TABLE students(</span><br><span class="line">    id INT PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">    student VARCHAR(15),</span><br><span class="line">    points TINYINT</span><br><span class="line">);</span><br><span class="line">#2. 向表中添加数据如下</span><br><span class="line">INSERT INTO students(student,points)</span><br><span class="line">VALUES</span><br><span class="line">(&#x27;张三&#x27;,89),</span><br><span class="line">(&#x27;李四&#x27;,77),</span><br><span class="line">(&#x27;王五&#x27;,88),</span><br><span class="line">(&#x27;赵六&#x27;,90),</span><br><span class="line">(&#x27;孙七&#x27;,90),</span><br><span class="line">(&#x27;周八&#x27;,88);</span><br><span class="line"></span><br><span class="line">SELECT * FROM students;</span><br><span class="line">#3. 分别使用RANK()、DENSE_RANK() 和 ROW_NUMBER()函数对学生成绩降序排列情况进行显示</span><br><span class="line"># 方式1：</span><br><span class="line">SELECT ROW_NUMBER() over (ORDER BY points DESC) AS 排序1,</span><br><span class="line">       RANK() over (ORDER BY points DESC) AS 排序2,</span><br><span class="line">       DENSE_RANK() over (ORDER BY points DESC) AS 排序3,</span><br><span class="line">       student,points</span><br><span class="line">FROM students;</span><br><span class="line"></span><br><span class="line"># # 方式2：</span><br><span class="line">SELECT ROW_NUMBER() over w AS 排序1,</span><br><span class="line">       RANK() over w AS 排序2,</span><br><span class="line">       DENSE_RANK() over w AS 排序3,</span><br><span class="line">       student,points</span><br><span class="line">FROM students WINDOW w AS (ORDER BY points DESC);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-08-13_21-02-44.png" alt="Snipaste_2023-08-13_21-02-44" style="zoom:50%;">

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/07/03/MySQL%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-代码随想录总结" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/05/29/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%E6%80%BB%E7%BB%93/">代码随想录总结</a>
    </h1>
  

        
        <a href="/2023/05/29/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%E6%80%BB%E7%BB%93/" class="archive-article-date">
  	<time datetime="2023-05-29T11:56:52.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-05-29</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">java</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/05/29/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95%E6%80%BB%E7%BB%93/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/">Next &amp;raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2024 John Doe
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">常用算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据科学</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">面试</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">聚宽</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">随笔</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">项目</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">推荐系统</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据仓库</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">贝叶斯</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">因子投资</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">NLP基础</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">考试</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://www.csdn.net/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>CSDN</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.zhihu.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>知乎</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.huaweicloud.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>华为云</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.aliyun.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>阿里云</a>
            </li>
          
            <li class="search-li">
              <a href="https://leetcode.cn/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>力扣</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.joinquant.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>聚宽</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">我叫王宇涵，东北人，本科和硕士分别毕业于哈尔滨工程大学和大连理工大学，2024年秋招拿到快手、百度、京东、科大讯飞、度小满、华为、荣耀、360等十余家企业offer，目前就职于快手数据平台部，担任数据研发工程师，专注于商业化广告业务。热爱大数据平台开发与数仓开发，技术栈包括但不限于Java、数仓建模、Hadoop、Hive、Spark、Flink、Clickhouse、Doris、数据湖、数据治理等。会不定期分享一些技术文章、业务知识、面试心得和读书笔记。</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>