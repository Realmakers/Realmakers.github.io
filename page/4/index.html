<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://example.com">
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div> 
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/123.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/categories">分类</a></li>
	        
			</ul>
		</nav>
		<nav>
			总文章数 51
		</nav>		
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
		        
					<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
		        
					<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>



    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/123.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
			        
						<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
			        
						<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/categories">分类</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-贝叶斯在量化投资中的应用" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%9C%A8%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/">贝叶斯在量化投资中的应用</a>
    </h1>
  

        
        <a href="/2023/02/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%9C%A8%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/" class="archive-article-date">
  	<time datetime="2023-02-14T08:23:18.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-14</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-贝叶斯方法在量化投资中的应用"><a href="#1-贝叶斯方法在量化投资中的应用" class="headerlink" title="1. 贝叶斯方法在量化投资中的应用"></a>1. 贝叶斯方法在量化投资中的应用</h1><h2 id="1-1-股票分类"><a href="#1-1-股票分类" class="headerlink" title="1.1 股票分类"></a>1.1 股票分类</h2><ul>
<li>构造投资组合的方法是买入好的 股票(未来收益率高)或卖出(空) 差的股票(未来收益率为负)</li>
<li>如何甄别好坏的股票——对股票进行分类或者打分（贝叶斯分类器）</li>
<li>具体做法：我们之前通过股票多因子的打分（多因子的PCA分析）从沪深300中进行选股，还可以进行多维贝叶斯选股</li>
</ul>
<h2 id="1-2-市场趋势识别"><a href="#1-2-市场趋势识别" class="headerlink" title="1.2 市场趋势识别"></a>1.2 市场趋势识别</h2><ul>
<li>有些投资策略在单边下跌行情中会无效， 因而，需要识别市场趋 势是上涨、下跌，还是震荡。</li>
</ul>
<h2 id="1-3-波动率估计"><a href="#1-3-波动率估计" class="headerlink" title="1.3 波动率估计"></a>1.3 波动率估计</h2><h2 id="1-4-投资组合风险"><a href="#1-4-投资组合风险" class="headerlink" title="1.4 投资组合风险"></a>1.4 投资组合风险</h2><h1 id="2-《人工智能选股之朴素贝叶斯模型——华泰金工林晓明团队》研报分析"><a href="#2-《人工智能选股之朴素贝叶斯模型——华泰金工林晓明团队》研报分析" class="headerlink" title="2. 《人工智能选股之朴素贝叶斯模型——华泰金工林晓明团队》研报分析"></a>2. 《人工智能选股之朴素贝叶斯模型——华泰金工林晓明团队》研报分析</h1><blockquote>
<p><strong>本报告对朴素贝叶斯模型及线性判别分析、二次判别分析进行系统测试</strong></p>
<p><strong>朴素贝叶斯模型构建细节：月频滚动训练，结合基于时间序列的交叉验证</strong></p>
<p><strong>朴素贝叶斯在指数成份内（沪深300和中证500）选股效果较好，线性判别分析全A选股效果较好</strong></p>
<p><strong>线性判别分析法的分类效果最佳，其在某种意义下等价于线性回归</strong> </p>
</blockquote>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color4">贝叶斯</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/量化交易//" class="article-tag-list-link color5">量化交易</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/14/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%9C%A8%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-聚宽因子分析教程" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/07/%E8%81%9A%E5%AE%BD%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90%E6%95%99%E7%A8%8B/">聚宽因子分析教程</a>
    </h1>
  

        
        <a href="/2023/02/07/%E8%81%9A%E5%AE%BD%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90%E6%95%99%E7%A8%8B/" class="archive-article-date">
  	<time datetime="2023-02-07T13:52:09.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-07</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-因子定义和计算"><a href="#1-因子定义和计算" class="headerlink" title="1. 因子定义和计算"></a>1. 因子定义和计算</h1><h2 id="1-1-因子计算"><a href="#1-1-因子计算" class="headerlink" title="1.1 因子计算"></a>1.1 因子计算</h2><p>在回测以及研究中， 可以通过调用jqfactor中的 calc_factors 函数来计算单因子分析中定义的因子值。</p>
<p>为了便于理解，将因子计算部分置于因子定义前面。</p>
<blockquote>
<p>函数：calc_factors（）因子计算，置于因子定义前面</p>
</blockquote>
<p><img src="Snipaste_2023-02-13_18-02-07.png" alt="Snipaste_2023-02-13_18-02-07"></p>
<h2 id="1-2-因子定义"><a href="#1-2-因子定义" class="headerlink" title="1.2 因子定义"></a>1.2 因子定义</h2><p><img src="Snipaste_2023-02-13_18-08-08.png" alt="Snipaste_2023-02-13_18-08-08"></p>
<p><strong>dependencies 中可以使用的基础因子</strong></p>
<table>
<thead>
<tr>
<th align="left">数据</th>
<th align="left">说明</th>
<th align="left">示例</th>
</tr>
</thead>
<tbody><tr>
<td align="left">价量信息</td>
<td align="left">包含open\close\high\low\money\volume 字段 当use_real_price&#x3D;True时使用动态复权数据 , 为False时使用后复权数据</td>
<td align="left">dependencies&#x3D;[‘open’]</td>
</tr>
<tr>
<td align="left">聚宽因子库数据</td>
<td align="left">包含质量因子、基础因子、情绪因子、成长因子、风险因子、每股因子等数百个因子数据 详细的因子列表请参考<a target="_blank" rel="noopener" href="https://www.joinquant.com/help/api/help?name=factor_values">因子库</a></td>
<td align="left">质量因子: 营业周期、市场杠杆 dependencies &#x3D; [‘OperatingCycle’,’MLEV’]</td>
</tr>
<tr>
<td align="left">单季度财务指标因子</td>
<td align="left">每日可看到的最新单季度财务指标。包含市值数据（valuation）、资产负债数据（balance）、现金流数据（cash_flow）、利润数据（income）、财务指标数据（indicator）。 可以直接使用该指标的名称获取数据。详细的指标列表请参考：<a target="_blank" rel="noopener" href="https://www.joinquant.com/data/dict/fundamentals">股票财务数据</a></td>
<td align="left">获取利润表（income）中的营业收入（operating_revenue）数据 dependencies &#x3D; [‘operating_revenue’]</td>
</tr>
<tr>
<td align="left">前 N 季度的财务数据</td>
<td align="left">前1-8季度的单季度财务指标。 包含资产负债数据（balance）、现金流数据（cash_flow）、利润数据（income）、财务指标数据（indicator）。 可以通过在因子后加『_1』的方式， 获取前几个季度的财务指标。 详细的指标列表请参考：<a target="_blank" rel="noopener" href="https://www.joinquant.com/data/dict/fundamentals">股票财务数据</a></td>
<td align="left">某公司于6月23日发布半年报，当前的逻辑时间是6月24日 operating_revenue 表示第二季度的营业收入 operating_revenue_1 表示第一季度的营业收入。</td>
</tr>
<tr>
<td align="left">过去五年的年度财务数据</td>
<td align="left">过去五年的年度财务数据 包含资产负债数据（balance）、现金流数据（cash_flow）、利润数据（income）、财务指标数据（indicator）。 可以通过在因子后加『_y1』的方式， 获取前几年的财务指标。 详细的指标列表请参考：<a target="_blank" rel="noopener" href="https://www.joinquant.com/data/dict/fundamentals">股票财务数据</a></td>
<td align="left">当前的逻辑时间是2016年9月24日 operating_revenue_y 表示当前时间可以看到的最新年度营业收入数据，即2015年的营业收入数据 operating_revenue_y1 表示2014年的营业收入数据。</td>
</tr>
<tr>
<td align="left">行业因子</td>
<td align="left">包含证监会行业分类、聚宽一、二级行业分类以及申万一、二、三级行业分类。 因子名称是行业代码， 因子值是一个哑变量，如果某股票属于某行业， 则返回1， 否则， 返回0。 详细的行业列表请参考<a target="_blank" rel="noopener" href="https://www.joinquant.com/data/dict/plateData">行业数据</a></td>
<td align="left">获取聚宽一级能源行业因子 dependencies &#x3D; [‘HY001’]</td>
</tr>
<tr>
<td align="left">概念因子</td>
<td align="left">因子的名称是概念代码，因子值是一个哑变量， 如果某股票属于某个概念，则返回1； 否则，返回0。 详细的概念列表请参考<a target="_blank" rel="noopener" href="https://www.joinquant.com/data/dict/plateData">概念数据</a></td>
<td align="left">获取智能电网概念因子 dependencies &#x3D; [‘GN028’]</td>
</tr>
<tr>
<td align="left">指数因子</td>
<td align="left">因子名称是指数代码， 因子值是一个哑变量， 如果某股票属于某个指数，则返回1； 否则，返回0。 详细的指数列表请参考<a target="_blank" rel="noopener" href="https://www.joinquant.com/data/dict/indexData">指数数据</a></td>
<td align="left">获取沪深300指数因子 dependencies &#x3D; [‘000300.XSHG’]</td>
</tr>
<tr>
<td align="left">资金流因子</td>
<td align="left">即 <a target="_blank" rel="noopener" href="https://www.joinquant.com/api#jqdatagetmoneyflow-%E8%8E%B7%E5%8F%96%E8%B5%84%E9%87%91%E6%B5%81%E4%BF%A1%E6%81%AF">get_money_flow</a> API 查询的数据。 可以使用的字段包括：change_pct(涨跌幅(%)、net_amount_main(主力净额(万))、net_pct_main(主力净占比(%))、net_amount_xl(超大单净额(万))、net_pct_xl(超大单净占比(%))、net_amount_l(大单净额(万))、net_pct_l(大单净占比(%))、net_amount_m(中单净额(万))、net_pct_m(中单净占比(%))、net_amount_s(小单净额(万))、net_pct_s(小单净占比(%))</td>
<td align="left">获取主力净占比因子 dependencies &#x3D; [‘net_pct_main’]</td>
</tr>
</tbody></table>
<p><strong>calc 的参数</strong></p>
<p>在 calc 中， 可以通过 data 参数获取通过 max_window 和 dependencies 定义的数据。 data 是一个 dict， key 是 dependencies 中的因子名称， value 是pandas.DataFrame。</p>
<ul>
<li>DataFrame 的 column 是股票代码;</li>
<li>DataFrame 的 index 是一个时间序列，结束时间是当前时间， 长度是 max_window;</li>
</ul>
<p><strong>calc 的返回值</strong></p>
<p>需要保证返回一个pandas.Series, index 股票代码， value 是因子值。</p>
<p>注意：当 max_window 设置为1时，返回的是一个<strong>1行N列</strong>的 dataframe。需要使用dataframe.iloc[0] 或 dataframe.mean() 的方式转换为一个 Series。</p>
<h3 id><a href="#" class="headerlink" title></a></h3>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">因子投资</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/量化交易//" class="article-tag-list-link color5">量化交易</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/07/%E8%81%9A%E5%AE%BD%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90%E6%95%99%E7%A8%8B/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-量化交易教程（基于聚宽平台）" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/07/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E6%95%99%E7%A8%8B%EF%BC%88%E5%9F%BA%E4%BA%8E%E8%81%9A%E5%AE%BD%E5%B9%B3%E5%8F%B0%EF%BC%89/">量化交易教程（基于聚宽平台）</a>
    </h1>
  

        
        <a href="/2023/02/07/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E6%95%99%E7%A8%8B%EF%BC%88%E5%9F%BA%E4%BA%8E%E8%81%9A%E5%AE%BD%E5%B9%B3%E5%8F%B0%EF%BC%89/" class="archive-article-date">
  	<time datetime="2023-02-07T13:52:09.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-07</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-初识量化交易"><a href="#1-初识量化交易" class="headerlink" title="1. 初识量化交易"></a>1. 初识量化交易</h1><hr>
<h3 id="1-1-量化交易是做什么？"><a href="#1-1-量化交易是做什么？" class="headerlink" title="1.1 量化交易是做什么？"></a>1.1 量化交易是做什么？</h3><ul>
<li><p>量化交易是指借助现代统计学和数学的方法，利用计算机技术来进行交易的证券投资方式。便于理解的说，量化交易主要是做这样的事：</p>
</li>
<li><p><strong>从一个灵感开始</strong></p>
<ul>
<li><p>灵感就是指那些你想验证的可能会盈利的方法，比如银行股可能是良好的投资品种、一旦跨过20日均线后股价会继续涨、流传许久的羊驼交易法等等。灵感获取的方式可以是阅读、听人说、自己悟等等。</p>
</li>
<li><p>这里我们以一个简单的情况为例进行讲解。比如你的灵感是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果股价显著低于近几日的平均价，则买入</span><br><span class="line">如果股价显著高于近几日的平均价，则卖出</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>现在，你想知道这样操作究竟会不会赚钱？</p>
</li>
<li><p><strong>把灵感细化成明确的可执行的交易策略</strong></p>
<ul>
<li><p>一般灵感都很模糊，需要将其细化成明确的可执行的策略，目的是为了能得到确定的结果，以及为后续程序化准备。比如，你通过阅读了解到索罗斯的反身性概念，想将它应用到股市，这个反身性就很模糊，就需要明确什么条件下买卖，买卖什么品种，买卖多少量等，从而形成一个明确的交易策略，让不同人根据你的描述在相同情形下都能做出相同的操作。</p>
</li>
<li><p>继续以之前那个关于平均价的灵感为例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果股价显著低于近几日的平均价，则买入</span><br><span class="line">如果股价显著高于近几日的平均价，则卖出</span><br></pre></td></tr></table></figure>
</li>
<li><p>显然它是不够明确的。比如多低叫显著低于？多高叫显著高于？近几日究竟是几日？买入卖出是买卖多少？我们把它细化：</p>
<p>如果股价低于近20日平均价10%，则用全部可用资金买入<br>如果股价高于近20日平均价10%，则卖出全部所持的该股票</p>
</li>
<li><p>还有一点不明确的地方，买卖哪个股票呢？我们认为这个交易方法盈利与否应该跟交易哪个股票关系不大，但st股票除外（知道st股票是一类有风险特别大的股票就好，详情请百度），所以股票的选择范围是除st股外的国内A股的所有股票。所以我们进一步细化：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">每个交易日监测是除st股外的国内A股的所有股票的股价</span><br><span class="line">如果股价低于近20日平均价10%，则用全部可用资金买入该股票</span><br><span class="line">如果股价高于近20日平均价10%，则卖出全部所持有的该股票</span><br></pre></td></tr></table></figure>
</li>
<li><p>现在我们基本已经把之前的灵感细化成明确的可执行的<strong>交易策略</strong>。当然，可能还有些地方不够明确，也可能有些细节还不确定要改动，这些可以随时想到随时再改，不必一次做到完美。</p>
</li>
</ul>
</li>
<li><p><strong>把策略转成程序</strong></p>
<ul>
<li><p>就是把明确后的策略通过编程转成程序，好让计算机能根据历史数据模拟执行该策略，以及能根据实际行情进行反应并模拟交易或真实交易。</p>
</li>
<li><p>简言之，就是把刚刚的策略翻译成计算机可识别的代码语言，即把这个：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">每个交易日监测是除st股外的国内A股的所有股票的股价</span><br><span class="line">如果股价低于近20日平均价10%，则用全部可用资金买入该股票</span><br><span class="line">如果股价高于近20日平均价10%，则卖出全部所持有的该股票</span><br></pre></td></tr></table></figure>
</li>
<li><p>写成类似这样的代码（下面的代码并不完全符合，只是展示下大概的样子）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    g.security = [<span class="string">&#x27;002043.XSHE&#x27;</span>,<span class="string">&#x27;002582.XSHE&#x27;</span>]</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_data</span>(<span class="params">context, data</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> g.security:</span><br><span class="line">        last_price = data[i].close</span><br><span class="line">        average_price = data[i].mavg(<span class="number">20</span>, <span class="string">&#x27;close&#x27;</span>)</span><br><span class="line">        cash = context.portfolio.cash</span><br><span class="line">        <span class="keyword">if</span> last_price &gt; average_price:</span><br><span class="line">            order_value(i, cash)</span><br><span class="line">        <span class="keyword">elif</span> last_price &lt; average_price:</span><br><span class="line">            order_target(i, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>这样一来，就把刚才细化好策略转成了代码程序，计算机就能运行了。这个过程你可以理解成用计算机能听懂的语言（代码），把你的策略告诉给计算机了。</p>
</li>
</ul>
</li>
<li><p><strong>检验策略效果</strong></p>
<ul>
<li>现在计算机理解了你的策略，你现在可以借助计算机的力量来验证你的策略了。基本的检验策略方法有<strong>回测</strong>和<strong>模拟交易</strong>两种方法。</li>
<li>回测是让计算机能根据一段时间的<strong>历史数据</strong>模拟执行该策略，根据结果评价并改进策略。继续之前的那个均价的策略例子的话就是这样的：<ul>
<li>设定初始的虚拟资产比如500000元、一个时期比如20060101到20160101，把这一时期的各种数据如估计股价行情等发给计算机，计算机会利用这些数据模仿真实的市场，执行你刚才告诉它的策略程序。最后计算机会给你一份报告，根据这个报告你就会知道，在20060101的500000元，按照你的策略交易到20160101，会怎样？一般包括盈亏情况，下单情况，持仓变化，以及一些统计指标等，从而你能据此评估交易策略的好坏。</li>
<li><strong>如果结果不好，则需要分析原因并改进。如果结果不错，则可以考虑用模拟交易进一步验证。</strong></li>
</ul>
</li>
<li>模拟交易是让计算机能根据<strong>实际行情</strong>模拟执行该策略一段时间，根据结果评价并改进策略。与回测不同，回测是用历史数据模拟，模拟交易使用<strong>实际的实时行情</strong>来模拟执行策略的。举例就是这样：<ul>
<li>设定初始的虚拟资产比如500000元，选择开始执行模拟交易的时间点，比如明天。那么从明天开始，股市开始交易，真实的行情数据就会实时地发送到计算机，计算机会利用真实的数据模仿真实的市场，执行你的策略程序。同时，你会得到一份实时更新的报告。这报告类似于回测得到的报告，不同的是会根据实际行情变化<strong>更新</strong>。同样你能据此评估交易策略的好坏。</li>
</ul>
</li>
<li>可见，回测是用历史数据模拟执行策略，模拟交易是用未来的实际行情模拟执行策略。如果策略在回测与模拟交易的表现<strong>都</strong>非常好，你可以考虑进行完全真实的真金白银的实盘交易。</li>
</ul>
</li>
<li><p><strong>进行实盘交易并不断维护修正</strong></p>
<ul>
<li>实盘交易就是让计算机能自动根据实际行情，用真金白银自动执行策略，进行下单交易。注意，这时不再是用虚拟资产模拟交易，亏损和盈利都是真钱。实盘交易一般也会给出一份类似模拟交易的会不断更新的报告，从而不断要观察策略的实盘表现并及时调整与改进策略，使之持续平稳盈利。</li>
</ul>
</li>
</ul>
<h3 id="1-2-量化交易的价值何在？"><a href="#1-2-量化交易的价值何在？" class="headerlink" title="1.2 量化交易的价值何在？"></a>1.2 量化交易的价值何在？</h3><ul>
<li>量化交易的价值有很多，只提下最突出的价值所在。</li>
<li><strong>可以利用大量历史数据检验策略，效率提升百倍</strong>。当我们想验证交易策略的时候，一个基本的想法是想知道它在历史上表现如何，这往往需要大量的历史数据与计算量，量化交易做一次回测可能几分钟就可以得到结果了，相比于传统人工做法效率的提升是成百倍的。</li>
<li><strong>更科学更客观的衡量交易策略的效果</strong>。比如一个关于某技术指标的策略，人工的进行了10个交易日的验证，效果都不错，但这就能说明这指标不错吗？不，10次太少了，你需要更多的验证，比如1000个交易日，人工验证不可行，量化交易则又快又准。而且量化交易还可以利用数学与统计学自动给出客观的结果，比如年化收益率、最大回撤率、夏普比率等。</li>
<li><strong>全市场实时捕捉交易机会</strong>。当你知道一个盈利条件，当股价一旦满足这条件，你就可以操作盈利。问题是，市场几千个股票，股价时时刻刻都在变动，你能盯住几个，你会错失多少个机会。但量化交易可以利用计算机全市场实时盯盘，可以不错过任何交易机会，加倍你的盈利能力。</li>
<li><strong>更多的盈利机会</strong>。量化交易可以利用计算机对海量数据分析得到常人难以发现的盈利机会，而且有些机会只有量化交易才能利用。比如你发现一种交易方法，其特点是盈亏的额度相等，但盈利的概率是55%，亏损概率45%。首先这种小差距的概率规律，非量化交易不能发现，其次，要利用这个规律盈利需要大量次数的交易才能稳定盈利，这也非量化交易不可。</li>
</ul>
<h3 id="1-3-做量化交易需要什么？"><a href="#1-3-做量化交易需要什么？" class="headerlink" title="1.3 做量化交易需要什么？"></a>1.3 做量化交易需要什么？</h3><ul>
<li>通常一个投资者做量化交易所需要做的准备，就如同让一个农民自己去造一个大型收割机，而且还是从挖矿开始做起，极度困难，所以量化交易最初在金融与科技最为发达的美国由少数顶级精英发起的。</li>
<li><strong>要有各种数据</strong>。要有能方便使用的各种投资相关的数据。这要考虑到各种数据的收集、存储、清洗、更新，以及数据取用时的便捷、速度、稳定。</li>
<li><strong>还要有一套量化交易的系统</strong>，要有能编写策略、执行策略、评测策略的系统。这要考虑到系统对各种策略编写的支持、系统进行回测与模拟的高仿真、系统执行策略的高速、系统评测策略的科学可靠全方面。</li>
<li>可能有人会问，做投资之前难道要学当程序员吗？曾经是，但现在量化交易的门槛已大大降低。</li>
</ul>
<h3 id="1-4-聚宽是什么？"><a href="#1-4-聚宽是什么？" class="headerlink" title="1.4 聚宽是什么？"></a>1.4 聚宽是什么？</h3><ul>
<li>聚宽是一家量化交易平台，为投资者提供做量化交易的工具与服务，帮助投资者更好地做量化交易。也就是说，在聚宽量化交易平台，“大型收割机”已经为你准备好了，不需要你自己造了，你只需要学会使用它。</li>
<li><strong>聚宽让做量化交易的成本极大降低</strong><ol>
<li>提供多种优质的便于取用的数据</li>
<li>提供投资研究功能，便于自由地统计、研究、学习等</li>
<li>提供多种的策略评价指标与评价维度</li>
<li>支持多种策略的编写、回测、模拟、实盘</li>
</ol>
</li>
<li><strong>聚宽让量化交易的成长之路更为平坦</strong><ol>
<li>在社区可以分享交流量化交易的心得与疑惑</li>
<li>在量化课堂可学习量化交易相关的各种知识</li>
<li>在策略擂台可以策略pk展现风采证明自己</li>
<li>在大赛专区可以获取社会量化比赛资讯</li>
<li>在策略商城可以上架策略供他人付费订阅</li>
<li>在基金经理孵化训练营则助力快速成长为一名职业基金经理</li>
</ol>
</li>
</ul>
<h1 id="2-量化交易策略基本框架"><a href="#2-量化交易策略基本框架" class="headerlink" title="2. 量化交易策略基本框架"></a>2. 量化交易策略基本框架</h1><hr>
<h3 id="2-1-从一个非常简单的交易策略开始"><a href="#2-1-从一个非常简单的交易策略开始" class="headerlink" title="2.1 从一个非常简单的交易策略开始"></a>2.1 从一个非常简单的交易策略开始</h3><ul>
<li><p>先看一个非常简单的交易策略：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">每天买100股的平安银行。</span><br></pre></td></tr></table></figure>
</li>
<li><p>为了让这个策略能让计算机执行，首先，要使策略符合<strong>“初始化+周期循环”</strong>框架，像这样：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">初始化：选定要交易的股票为平安银行</span><br><span class="line">每天循环：买100股的平安银行</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-2-什么是“初始化-周期循环”框架？"><a href="#2-2-什么是“初始化-周期循环”框架？" class="headerlink" title="2.2 什么是“初始化+周期循环”框架？"></a>2.2 什么是“初始化+周期循环”框架？</h3><ul>
<li>为了将投资灵感高效地转化成计算机可执行的量化策略，必须基于一种模式来写，框架就是指这种模式。而此框架包含两个部分即初始化与周期循环：</li>
<li><strong>初始化</strong>即指策略最开始运行前要做的事。比如，<strong>准备好要交易的股票</strong>。</li>
<li><strong>周期循环</strong>即指策略开始后，随着时间一周期一周期地流逝时，每个周期要做的事。如例中，周期为天，周期循环的则是每天买100股的平安银行。</li>
<li>能帮助你理解这一框架的是，其实人本身日常做交易就是符合“初始化+周期循环”框架的，初始化就是已存在人脑的交易思想与知识，周期循环就是每天或每分钟地查看行情、判断、下单等行为。</li>
</ul>
<h3 id="2-3-如何把策略变成计算机可执行的程序"><a href="#2-3-如何把策略变成计算机可执行的程序" class="headerlink" title="2.3 如何把策略变成计算机可执行的程序?"></a>2.3 如何把策略变成计算机可执行的程序?</h3><ul>
<li>通过编程将策略写成计算机可识别的代码，具体说，我们这里是用python这门编程语言。</li>
<li>另外可以用聚宽的<strong>向导式策略生成器</strong>，这种方法是不需编程的，但灵活性上难免是远不如写代码的。</li>
</ul>
<h3 id="2-4-那么如何将策略写成代码？"><a href="#2-4-那么如何将策略写成代码？" class="headerlink" title="2.4 那么如何将策略写成代码？"></a>2.4 那么如何将策略写成代码？</h3><ul>
<li><p>这并非三言两语就能说清，尤其是对于没有编程基础的人。所以我们将通过后续的内容逐步地介绍。首先我们将学习“初始化+周期循环”框架代码的写法。</p>
</li>
<li><p>写法一</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def initialize(context):</span><br><span class="line">    这里是用来写初始化代码的地方,例子中就是选定要交易的股票为平安银行</span><br><span class="line">  </span><br><span class="line">def handle_data(context,data):</span><br><span class="line">    这里是用来写周期循环代码的地方,例子中就是买100股的平安银行</span><br></pre></td></tr></table></figure>
</li>
<li><p>写法二</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def initialize(context):</span><br><span class="line">    run_daily(period,time=&#x27;every_bar&#x27;)</span><br><span class="line">    这里是用来写初始化代码的地方,例子中就是选定要交易的股票为平安银行</span><br><span class="line">  </span><br><span class="line">def period(context):</span><br><span class="line">    这里是用来写周期循环代码的地方,例子中就是买100股的平安银行</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>代码应该往哪里写？</strong></p>
<ul>
<li>来到聚宽网站后，通过导航栏-我的策略-我的策略进入策略列表，点击新建策略-</li>
</ul>
</li>
</ul>
<p><img src="db4a31251b639b7f9e1ddc93c42e1668.png" alt="db4a31251b639b7f9e1ddc93c42e1668"></p>
<ul>
<li>进入策略编辑页，左侧就是策略代码编辑区域，初始会默认给你提供代码模板，全删除后写入我们的代码就好了。</li>
</ul>
<p><img src="88b68d191aa903ebffb80748652cca83.png" alt="88b68d191aa903ebffb80748652cca83"></p>
<ul>
<li><strong>两种写法用哪个好？</strong><ul>
<li>写法一是从前的老写法，将逐步弃用，写法二是聚宽系统改进后的新写法，<strong>推荐使用写法二</strong>。</li>
<li><strong>def、context等都是什么意思？</strong></li>
<li>其实是在调用聚宽提供好的函数，展开讲很复杂，不理解的话先记住，后面的学习内容会让你理解。</li>
</ul>
</li>
</ul>
<h3 id="2-5-框架写成代码了，那例子的完整的代码该怎么写呢？"><a href="#2-5-框架写成代码了，那例子的完整的代码该怎么写呢？" class="headerlink" title="2.5 框架写成代码了，那例子的完整的代码该怎么写呢？"></a>2.5 框架写成代码了，那例子的完整的代码该怎么写呢？</h3><ul>
<li><p>剩下的两行代码这么写。完全理解需要学习后续的内容，此处不要求理解。知道大概什么样子往哪里写即可。</p>
</li>
<li><p>选定要交易的股票为平安银行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g.security = <span class="string">&#x27;000001.XSHE&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>买100股的平安银行（市价单写法）:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">order(g.security, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>以写法二为例把剩下的代码补上后，完整代码为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    g.security = <span class="string">&#x27;000001.XSHE&#x27;</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    order(g.security, <span class="number">100</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-6-那么现在这些代码就可以运行了吗？"><a href="#2-6-那么现在这些代码就可以运行了吗？" class="headerlink" title="2.6 那么现在这些代码就可以运行了吗？"></a>2.6 那么现在这些代码就可以运行了吗？</h3><ul>
<li>是的。以写法二为例，如图把代码写到策略编辑区，设置好<strong>初始资金</strong>与<strong>起止时间</strong>（比如初始资金100000元，起止时间20160601-20161231），<strong>频率</strong>设置成天。点击<strong>编译运行</strong>，运行结束后就可以看到结果了。<br><img src="cdec0ebc16c4154f2a2c3afefd4380ea.png" alt="cdec0ebc16c4154f2a2c3afefd4380ea"></li>
<li>可以看到，若你20160601有初始资金100000元，每个交易日尝试买100股的平安银行，到20161231，你的收益曲线将如图中蓝线般增长。图中红线是基准收益（默认是沪深300指数，代表整个市场增长水平）</li>
<li>接下来，点击<strong>运行回测</strong>，运行结束后就可以看到更为详细的结果，包括下单记录、持仓记录等。<br><img src="84e79235cc475cc440167b3187ef0e74.png" alt="84e79235cc475cc440167b3187ef0e74"></li>
</ul>
<h3 id="2-7-策略出错不能运行？"><a href="#2-7-策略出错不能运行？" class="headerlink" title="2.7 策略出错不能运行？"></a>2.7 策略出错不能运行？</h3><ul>
<li><p>策略不能运行时，日志中会报错并给出一定的提示信息，像这样：<br><img src="b727983b0d591574cb72347335087937.png" alt="b727983b0d591574cb72347335087937"></p>
</li>
<li><p>首先注意，右上角的箭头按钮能展开运行日志。看到日志中，最后一行是错误的提示信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SyntaxError: invalid syntax</span><br><span class="line">  </span><br><span class="line">汉义是 语法错误：不合法的语法。</span><br></pre></td></tr></table></figure>
</li>
<li><p>最后一行之前的是错误的位置信息，<strong>一般只看后面就行</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">File <span class="string">&quot;user_code.py&quot;</span>, line <span class="number">1</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>)</span><br><span class="line">                          ^</span><br></pre></td></tr></table></figure>
</li>
<li><p>意思是文件user_code.py（就是你的策略代码）的第一行，“^”符号指向的位置有错。你到代码中的这个位置看下，会发现少个冒号。</p>
</li>
<li><p>为了顺利运行策略，需要耐心解决错误，但错误的原因极度的复杂多样（所以日志的报错信息也多种多样，不止图上一种），故在此只针对例子讲下新手容易犯的错误：</p>
<ul>
<li>符号要用英文输入法。下图，代码第一行的冒号是中文的，所以出错<br><img src="746647f439f6886eebb672575b7e6183.png" alt="746647f439f6886eebb672575b7e6183"></li>
<li>拼写不要错。下图，security拼写错了<br><img src="751cebab4fc1aba8c657abf492d58693.png" alt="751cebab4fc1aba8c657abf492d58693"></li>
<li>缩进要对齐。下图，缩进没对齐。缩进的时候可以按键盘tab键或四个空格。<br><img src="a186b7520ce9f441cb3f4d4b5df3ebf9.png" alt="a186b7520ce9f441cb3f4d4b5df3ebf9"></li>
</ul>
</li>
<li><p>编程界往往把错误叫bug，而不断调试去除错误的过程叫debug，做量化时也是时常听到的说法，大家应该知道下。</p>
</li>
<li><p>而且debug通常就是要耗费不低于<del>写bug</del>写代码的时间的，所以会debug是很重要的能力，大家平时debug的时候不妨多思考下，如何更有效率的debug。当然，我们后续也会介绍些debug的技巧。</p>
</li>
</ul>
<h3 id="2-8-回测、编译运行、运行回测都是什么意思？"><a href="#2-8-回测、编译运行、运行回测都是什么意思？" class="headerlink" title="2.8 回测、编译运行、运行回测都是什么意思？"></a>2.8 回测、编译运行、运行回测都是什么意思？</h3><ul>
<li>像刚刚那样，用一段时间内的历史的真实行情数据，来验证一个确定的交易策略在这段时间表现如何，这个过程叫<strong>回测</strong>。</li>
<li><strong>运行回测</strong>就是是字面意思，让计算机运行这次回测，运行后会告诉你策略在这段时间表现情况，比如收益率、年化收益率、最大回撤、夏普比率等指标，而且一般也会包括下单记录、持仓记录等。</li>
<li><strong>编译运行</strong>其实也是让计算机运行这次回测，不过相比于点击运行回测，编译运行的结果比运行回测要简单，只有收益率等指标，因此也<strong>速度更快</strong>。所以，当还不必要得到详细的结果时，或只是想调试下策略的代码，看是否无误可运行时，编译运行就比运行回测更方便。</li>
</ul>
<h3 id="2-9-周期循环具体是什么时候开始的呢？"><a href="#2-9-周期循环具体是什么时候开始的呢？" class="headerlink" title="2.9 周期循环具体是什么时候开始的呢？"></a>2.9 周期循环具体是什么时候开始的呢？</h3><ul>
<li>如果策略频率为天，是每个交易日开始生效，从9:30直到15:00（从股市开市到收市），所以例子中是每个交易日9:30开市循环就开始，一天一次地循环执行买入股票的操作。</li>
<li>如果策略频率为分钟，是每个分钟开始时执行，所以例子中的买入股票的操作是每个交易日从9:30:00开始，然后9:31:00，直到14:59:00。接着下一天9:30:00，如此一分钟一次地循环执行的。<br><img src="de883feec9064e658d40b2e4b3031e08.png" alt="de883feec9064e658d40b2e4b3031e08"></li>
<li>虽然频率只有为分钟和每天可选，但通过不同的代码可以实现按周按月周期循环，而且分钟级别里下单时间也是可以自己选的，不过代码的写法则与写法一和写法二那样略有不同，后面会讲到。</li>
</ul>
<h1 id="3-下单、函数、API"><a href="#3-下单、函数、API" class="headerlink" title="3. 下单、函数、API"></a>3. 下单、函数、API</h1><hr>
<ul>
<li><p>我们继续以前文策略代码为例进行讲解，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    g.security = <span class="string">&#x27;000001.XSHE&#x27;</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    order(g.security, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过前文讲解，现在这段代码中就剩这句下单语句还没讲了。为了理解这条语句，需要学习下python中函数的知识。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">order(g.security, 100)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="3-1-函数与API"><a href="#3-1-函数与API" class="headerlink" title="3.1 函数与API"></a>3.1 函数与API</h3><ul>
<li><p>函数是封装好的，可重复使用的 ，用来实现专一功能的代码段。函数能使代码易于维护与交流，提高编写策略的效率。通俗的理解是，把一系列代码指令包起来就是一个函数，起个名字就是函数名，之后用这个函数名，就知道这个名字指代那被包起来的一系列代码指令了。</p>
</li>
<li><p>Python语言自带了许多内建函数，比如之前见过的print()、type()都是Python自带的函数，可以直接用。你也可以自己创建函数自己用，这被叫做自定义函数。比如如下这段框架代码其实就是自定义了一个名为period的函数，该函数内包了一个聚宽系统自带的函数order()：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    order(g.security, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>order()的准确称谓其实是API（application programming interface，即应用程序编程接口），API的含义与函数有所不同，解释起来略复杂。不过实际使用中跟函数几乎没有差别，可以理解成聚宽平台基于python封装而成的函数。在<a target="_blank" rel="noopener" href="https://www.joinquant.com/api">聚宽的API文档</a>中你可以看到除order()外其他API。</p>
</li>
</ul>
<h3 id="3-2-使用一个函数"><a href="#3-2-使用一个函数" class="headerlink" title="3.2 使用一个函数"></a>3.2 使用一个函数</h3><ul>
<li><p>在使用函数的时候，通常需要提供一些参数(也有可能不需要)，函数根据提供的参数，执行一系列的函数作者设计好的操作，往往也会根据提供的参数返回结果（也可能返回为空，即不返回），如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用法: 函数名(参数,参数,......)</span></span><br><span class="line"><span class="comment"># 例子如下：</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 提供了两个参数g.security和100，执行了买入g.security中数据对应的股票100股的操作</span></span><br><span class="line">order(g.security, <span class="number">100</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 提供了一个参数&quot;你好&quot;，执行了打印&quot;你好&quot;的操作</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;你好&quot;</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 提供了一个参数&quot;1&quot;给type()函数，type函数执行了识别&quot;1&quot;数据类型的操作，并返回了&quot;1&quot;数据类型为结果。</span></span><br><span class="line"><span class="comment"># type返回的结果被当做参数提供给了print(),print执行了打印type返回的结果的操作</span></span><br><span class="line"><span class="comment"># type与print的嵌套使用，实现了打印&quot;1&quot;数据类型的操作。</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(<span class="string">&quot;1&quot;</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>可见，函数的功能多种多样，需要参数、返回的结果亦不尽相同，所以具体怎么用需要看函数作者提供的说明文档，或者看函数内的设计代码自己推断。函数内的代码不见得看得到，看到不一定看得懂，想看懂也可能很辛苦。所以一般函数的用法要看函数作者提供的说明文档。</p>
</li>
<li><p>聚宽设计的函数(如前文所说准确叫法是API)的用法都写在API文档里，位置在聚宽网站导航栏-帮助-API文档。</p>
</li>
<li><p>接下来以order为例讲下文档怎么看。在API文档中找到 <a target="_blank" rel="noopener" href="https://www.joinquant.com/api#order-%E6%8C%89%E8%82%A1%E6%95%B0%E4%B8%8B%E5%8D%95">order - 按股数下单</a>的说明，如下：<br><img src="2a775ea7bab17ca524abdac07c9925d1.png" alt="2a775ea7bab17ca524abdac07c9925d1"></p>
</li>
<li><p>可以看到，order可接受的参数有5个,分别是security，amount，style，side，pindex，这五个参数的名字与含义是函数作者设计的。意思是你使用order提供参数的时候，被提供参数将<strong>按提供的顺序依次对应</strong>这5个参数。比如下面的写法就是错误的。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 函数会按顺序把100对应为security，即股票代码，把&quot;000001.XSHE&quot;对应为amount，即要交易的数量。所以就会错。</span></span><br><span class="line">order(<span class="number">100</span>,<span class="string">&quot;000001.XSHE&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>不按顺序提供参数的正确写法如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用等号表示对应关系，参数名写前，要当做参数的变量或数据写在后</span></span><br><span class="line"><span class="comment"># 如下是把100当做amount参数，把&quot;000001.XSHE&quot;当做security参数。</span></span><br><span class="line">order(amount=<span class="number">100</span>,security=<span class="string">&quot;000001.XSHE&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>可以发现有些参数后面有等号，如style&#x3D;None，含义style参数不提供的话，会被默认是None，其他的side&#x3D;’long’, pindex&#x3D;0也是一样的道理，如果不提供会被默认是等号后面的内容。所以前文order()只写了两个参数也不会错。注意，security和amount后面没有等号，即没有默认值，则必须提供参数不能省略。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下两句含义相同</span></span><br><span class="line">order(<span class="string">&quot;000001.XSHE&quot;</span>,<span class="number">100</span>)</span><br><span class="line">order(<span class="string">&quot;000001.XSHE&quot;</span>,<span class="number">100</span>,<span class="literal">None</span>,<span class="string">&#x27;long&#x27;</span>,<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>细说下order的各个参数</p>
<ul>
<li>security 标的代码，数据类型要求是字符串，想知道 基金、期货、指数的代码都是什么，可以在这里看<a target="_blank" rel="noopener" href="https://www.joinquant.com/data">聚宽数据</a>,比如聚宽数据-向下滚动页面-点击指数数据，可以看到各指数的代码。特别的是股票代码目前没有页面，但只需在平时使用的股票代码后面加后缀就好了，<strong>深交所（深交所股票0开头）股票代码后缀为.XSHE,如000001.XSHE,上交所股票代码（上交所股票6开头）后缀为.XSHG 如600000.XSHG。</strong></li>
<li>amount 交易数量, <strong>正数表示买入, 负数表示卖出</strong>，没什么可说的。</li>
<li>style参数决定下的订单是市价单还是限价单，默认是None代表市价单。目前就用默认吧，限价单以后讲。</li>
<li>side参数决定是开空单还是多单，默认为多单，股票只能多单，股指期货等其他品类可以开空单。</li>
<li>pindex参数是在多资金仓位时选择资金仓位的，<strong>股票一般用不到</strong>。</li>
</ul>
</li>
<li><p>根据说明文档，order函数是有返回值的，如果创建订单成功, 则返回Order对象, 失败则返回None。有返回值不一定要用，比如前文的例子都没用到这个返回值，实际上策略做的相当完备的时候才可能用到。一般用法是，根据返回值是否是None，判断是否下单成功，成功时，根据返回值可以查询订单或取消订单等。不过具体实现方法、以及Order对象是什么，还需要学习很多的知识，后续可能会讲到。</p>
</li>
</ul>
<h3 id="3-3-自定义函数"><a href="#3-3-自定义函数" class="headerlink" title="3.3 自定义函数"></a>3.3 自定义函数</h3><ul>
<li><p>Python 定义函数使用 def 关键字，一般格式如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">函数名</span>(<span class="params">参数列表</span>):</span><br><span class="line">    函数体</span><br></pre></td></tr></table></figure>
</li>
<li><p>函数名即为该函数起的名字，函数体即包在函数中的一系列操作的代码，参数列表即使用函数需要提供的参数，比如一个根据圆半径求周长的函数如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据圆半径r求周长l</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yuan</span>(<span class="params">r</span>):</span><br><span class="line">    p=<span class="number">3.14</span></span><br><span class="line">    l=<span class="number">2</span>*p*r</span><br><span class="line">    <span class="keyword">return</span> l</span><br></pre></td></tr></table></figure>
</li>
<li><p>return的含义是结束函数的运行并返回一个值，如上例子中就是返回了算好的周长l。如果return后什么也不写就是返回None即空，如果不写return，函数体运行完后，自动return None。</p>
</li>
<li><p>至此，你应该意识到，函数内部是相对独立的，数据想进来要通过参数传进来，想出去要通过返回值传出去，函数从获得参数到返回值的过程中所产生的数据与变量中没通过返回值传出去的，在函数运行结束后（即返回值后）都将被计算机释放不再存储。如果想函数间通用某变量可以考虑用之前讲的全局变量。</p>
</li>
<li><p>如前文讲使用函数时看到的，可以用等号给参数附加默认值，而且可以用逗号分隔分隔多个参数，例子如下:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据圆半径r求周长l的k分之一</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yuan</span>(<span class="params">r,k=<span class="number">1</span></span>):</span><br><span class="line">    p=<span class="number">3.14</span></span><br><span class="line">    l=<span class="number">2</span>*p*r/k</span><br><span class="line">    <span class="keyword">return</span> l</span><br></pre></td></tr></table></figure>
</li>
<li><p>在返回值的时候可以返回多个变量，例子如下:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据圆半径r求周长l与面积s的k分之一</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yuan</span>(<span class="params">r,k=<span class="number">1</span></span>):</span><br><span class="line">    p=<span class="number">3.14</span></span><br><span class="line">    l=<span class="number">2</span>*p*r/k</span><br><span class="line">    s=p*r*r/k</span><br><span class="line">    <span class="keyword">return</span> l,s</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用自定义函数的方法跟前文讲的使用函数的方法一致，需要说明的是定义函数的代码放的位置，如下：</p>
<p><img src="824f9535c8eb7a1fad15de0041b09e06.png" alt="824f9535c8eb7a1fad15de0041b09e06"></p>
</li>
</ul>
<h3 id="3-4-常用的下单函数"><a href="#3-4-常用的下单函数" class="headerlink" title="3.4 常用的下单函数"></a>3.4 常用的下单函数</h3><ul>
<li><p>常用的下单函数有<strong>四个</strong>，使用方法和order()差不多，可能有人自己看API文档就能学会了。接下来我们分别介绍下基本用法，同样的不讲style，side，pindex这三个参数。</p>
</li>
<li><p><strong>order(security,amount)<strong>，刚刚细讲过，含义是买卖一定数量的（单位：股）股票。security是股票代码，amount是数量，amount为负数时就是代表卖出了，需要知道的是，</strong>国内股票买入最小单位是1手即100股</strong>。例子如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 买入100股平安银行</span></span><br><span class="line">order(<span class="string">&quot;000001.XSHE&quot;</span>,<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 卖出100股平安银行</span></span><br><span class="line">order(<span class="string">&quot;000001.XSHE&quot;</span>,-<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>order_target(security,amount)<strong>，含义是通过买卖，将</strong>股票仓位</strong>调整至一定数量（单位：股）。security是股票代码，amount是数量。例子如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调整平安银行的持股数量至1000股</span></span><br><span class="line"><span class="comment"># 即，如果目前平安银行的持股数量低于1000股就买入，高于就是卖出，不高不低就不动。</span></span><br><span class="line">order_target(<span class="string">&quot;000001.XSHE&quot;</span>,<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>**order_value(security,value)**，含义是买卖一定价值量（单位：元）股票。security是股票代码，value是价值量。value为负数时就是代表卖出了。例子如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 买入10000元的平安银行</span></span><br><span class="line"><span class="comment"># 如果当前股票市价是10元，则代表买入1000股</span></span><br><span class="line"><span class="comment"># 如果除不开系统会自动调整成相近的合理数量。卖出时也会。</span></span><br><span class="line">order_value(<span class="string">&quot;000001.XSHE&quot;</span>,<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># 卖出10000元的平安银行</span></span><br><span class="line"><span class="comment"># 如果当前股票市价是100元，则代表卖出100股</span></span><br><span class="line">order_value(<span class="string">&quot;000001.XSHE&quot;</span>,-<span class="number">10000</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>order_target_value(security,value)<strong>，通过买卖，将</strong>股票仓位</strong>调整至一定价值量（单位：元）。security是股票代码，value是价值量。例子如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调整平安银行的持股价值量至10000元</span></span><br><span class="line"><span class="comment"># 即，如果目前平安银行的持股价值量（按股票市价算）低于10000元就买入，高于就是卖出，不高不低就不动。</span></span><br><span class="line">order_target_value(<span class="string">&quot;000001.XSHE&quot;</span>,<span class="number">10000</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>读者在尝试练习使用这些语句的时候，可以点击运行回测，通过查看回测结果页中的交易详情来看语句的执行效果，同时也可以看下日志。如下：</p>
<p><img src="280dd09ceb2a49d8756fd0986c78d651.png" alt="280dd09ceb2a49d8756fd0986c78d651"><br><img src="8dfe5d0d7c3e76f4df80b926ea94f5f1.png" alt="8dfe5d0d7c3e76f4df80b926ea94f5f1"></p>
</li>
<li><p>股票拆分合并和分红，交易的税费，下单导致成交价向不利的方向波动，这些因素系统都是默认考虑并仿真处理的了，具体的详情以及下的订单系统是如何模拟真实情况撮合成交的，可以看下API文档<a target="_blank" rel="noopener" href="https://www.joinquant.com/api#%E8%AE%A2%E5%8D%95%E5%A4%84%E7%90%86">订单处理</a>。其实新手不用太关注 这些订单处理的细节，不核心，目前也不容易理解，可以等以后自己比较熟悉了再看。</p>
</li>
</ul>
<h1 id="4-读取context中的数据与条件判断"><a href="#4-读取context中的数据与条件判断" class="headerlink" title="4. 读取context中的数据与条件判断"></a>4. 读取context中的数据与条件判断</h1><hr>
<ul>
<li><p>通过前文的讲解，我们已经能理解最开始的那个简单的策略例子，如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    g.security = <span class="string">&#x27;000001.XSHE&#x27;</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    order(g.security, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>接下来，我们将在此基础上进行改进与举例，学习新内容。</p>
</li>
</ul>
<h3 id="4-1-context的结构"><a href="#4-1-context的结构" class="headerlink" title="4.1 context的结构"></a>4.1 context的结构</h3><ul>
<li>context是一个回测系统建立的Context类型的对象，其中存储了如当前策略运行的时间点、所持有的股票、数量、持仓成本等数据。</li>
<li>对象可以理解为特殊类型的变量，对象的结构往往比我们之前见过的list与dict更复杂，被定义好的对象是有名字的，比如context是一个变量，它的变量类型是一个Context类型的对象，就像dict包括key与value，Context类型的对象也包括很多属性，而且可以嵌套另一个种类型的对象，结构见下图。图中只包括了主要与常用的内容，详细介绍可以看API文档：<a target="_blank" rel="noopener" href="https://www.joinquant.com/api#context">Context对象</a></li>
</ul>
<p><img src="3f21926604474d702db5efe2c9154cb1.png" alt="3f21926604474d702db5efe2c9154cb1"></p>
<ul>
<li>关于对象的知识非常复杂繁多，目前我们只需学习如何取用context中的数据就好。</li>
</ul>
<h3 id="4-2-context中的数据取用方法"><a href="#4-2-context中的数据取用方法" class="headerlink" title="4.2 context中的数据取用方法"></a>4.2 context中的数据取用方法</h3><ul>
<li><p>获取对象类型变量内包含的数据方法是用英文句号隔开，而当包含的是另一个对象时，只需在应用英文句号隔开即可，例子如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印可用资金</span></span><br><span class="line"><span class="built_in">print</span>(context.portfolio.available_cash)</span><br><span class="line"><span class="comment"># 打印运行频率</span></span><br><span class="line"><span class="built_in">print</span>(context.run_params.frequency)</span><br><span class="line"><span class="comment"># 打印当前单位时间的开始时间</span></span><br><span class="line"><span class="built_in">print</span>(context.current_dt)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 执行后日志内容如下</span></span><br><span class="line"><span class="comment"># 1000000.0</span></span><br><span class="line"><span class="comment"># day</span></span><br><span class="line"><span class="comment"># 2016-06-01 09:30:00</span></span><br></pre></td></tr></table></figure>

<p><img src="79e1891ccd9745dddaddc9a2cf18fa6a.png" alt="79e1891ccd9745dddaddc9a2cf18fa6a"></p>
</li>
<li><p>当要获取的对象内的数据是另一种有结构的变量类型时，比如dict或list，正常按照该变量类型进一步取用数据即可。例如context.portfolio.positions是一个dict，我们就可以应用之前讲过的dict 的用法来使用它，例子如下，这次给出了完整代码。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># context.portfolio.positions的含义是仓位信息，所以为了让它有数据，需要在取之前买入并持有股票。</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    g.security = <span class="string">&#x27;000001.XSHE&#x27;</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    order(g.security, <span class="number">100</span>)</span><br><span class="line">    <span class="comment"># 打印所有键</span></span><br><span class="line">    <span class="built_in">print</span>(context.portfolio.positions.keys())</span><br><span class="line">    <span class="comment"># 打印所有值</span></span><br><span class="line">    <span class="built_in">print</span>(context.portfolio.positions.values())</span><br><span class="line">    <span class="comment"># 打印g.security的开仓均价</span></span><br><span class="line">    <span class="built_in">print</span>(context.portfolio.positions[g.security].avg_cost)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 执行后日志内容如下</span></span><br><span class="line"><span class="comment"># [&#x27;000001.XSHE&#x27;]</span></span><br><span class="line"><span class="comment"># [UserPosition(&#123;&#x27;avg_cost&#x27;: 8.539999999999997, &#x27;security&#x27;: &#x27;000001.XSHE&#x27;, &#x27;closeable_amount&#x27;: 0, &#x27;price&#x27;: 8.53, &#x27;total_amount&#x27;: 100&#125;)]</span></span><br><span class="line"><span class="comment"># 8.54</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>常用的context数据写法如下，推荐自己动手试下。</p>
<ul>
<li>当前时间 context.current_dt</li>
<li>当前时间的“年-月-日”的字符串格式 context.current_dt.strftime(“%Y-%m-%d”)</li>
<li>前一个交易日 context.previous_date</li>
<li>当前可用资金 context.portfolio.available_cash</li>
<li>持仓价值 context.portfolio.positions_value</li>
<li>累计收益 context.portfolio.returns</li>
<li>当前持有股票 context.portfolio.positions.keys()</li>
<li>当前持有的某股票的开仓均价 context.portfolio.positions[‘xxxxxx.xxxx’].avg_cost</li>
<li>当前持有的某股票的可卖持仓量 context.portfolio.positions[‘xxxxxx.xxxx’].closeable_amount</li>
</ul>
</li>
</ul>
<h3 id="4-3-条件判断"><a href="#4-3-条件判断" class="headerlink" title="4.3 条件判断"></a>4.3 条件判断</h3><ul>
<li><p>能够获取context的数据后，我们会考虑利用这些数据丰富策略的逻辑，但在此之前我们还要学习if条件判断语句，如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果 条件1成立为 True 将执行代码块1</span></span><br><span class="line"><span class="comment"># 如果 条件1不成立为False，将判断条件2</span></span><br><span class="line"><span class="comment"># 如果 条件2成立为 True 将执行代码块2</span></span><br><span class="line"><span class="comment"># 如果 条件2还不成立为False，将执行代码块3</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> 条件<span class="number">1</span>:</span><br><span class="line">    代码块<span class="number">1</span></span><br><span class="line"><span class="keyword">elif</span> 条件<span class="number">2</span>:</span><br><span class="line">    代码块<span class="number">2</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    代码块<span class="number">3</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 注意</span></span><br><span class="line"><span class="comment"># elif 可以有多个连续写</span></span><br><span class="line"><span class="comment"># 且elif和else都可以省略</span></span><br><span class="line"><span class="comment"># 条件判断语句中可以嵌套条件判断语句</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>举几个例子：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印a、b中最大值</span></span><br><span class="line"><span class="keyword">if</span> a&gt;=b:</span><br><span class="line">    <span class="built_in">print</span>(a)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(b)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 判断a的正负性   </span></span><br><span class="line"><span class="keyword">if</span> a&gt;<span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;正&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> a&lt;<span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;负&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> a==<span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;零&#x27;</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 如果当前是2018-05-04，则下单买入100股平安银行</span></span><br><span class="line">date=context.current_dt.strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> date==<span class="string">&#x27;2018-05-04&#x27;</span>:</span><br><span class="line">    order(<span class="string">&#x27;000001.XSHE&#x27;</span>,<span class="number">100</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 判断a大小情况</span></span><br><span class="line"><span class="keyword">if</span> a&gt;<span class="number">0</span>:</span><br><span class="line">    <span class="keyword">if</span> a&lt;<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;a大于0且小于1&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;a大于等于1&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;a小于等于0&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>条件判断语句比较简单，但还需说明的是条件的写法中用到的运算符：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写条件常用运算符：</span></span><br><span class="line"><span class="comment"># &lt; 小于</span></span><br><span class="line"><span class="comment"># &gt; 大于</span></span><br><span class="line"><span class="comment"># &lt;= 小于等于</span></span><br><span class="line"><span class="comment"># &gt;= 大于等于</span></span><br><span class="line"><span class="comment"># == 等于</span></span><br><span class="line"><span class="comment"># != 不等于</span></span><br><span class="line"><span class="comment"># and 与，即and两边条件同为真，则真</span></span><br><span class="line"><span class="comment"># or 或，即or两边条件任意一个为真，则真</span></span><br><span class="line"><span class="comment"># not 非，即not右侧条件为真，则假，not右侧条件为假，则真</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 以判断a是否为0的几个写法为例</span></span><br><span class="line"><span class="comment"># 写法1</span></span><br><span class="line"><span class="keyword">if</span> a!=<span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;否&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;是&#x27;</span>)</span><br><span class="line"><span class="comment"># 写法2    </span></span><br><span class="line"><span class="keyword">if</span> a&gt;<span class="number">0</span> <span class="keyword">or</span> a&lt;<span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;否&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;是&#x27;</span>)</span><br><span class="line"><span class="comment"># 写法2    </span></span><br><span class="line"><span class="keyword">if</span> a&gt;=<span class="number">0</span> <span class="keyword">and</span> a=&lt;<span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;是&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;否&#x27;</span>)</span><br><span class="line"><span class="comment"># 写法3   </span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> a==<span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;否&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;是&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="4-4-止损"><a href="#4-4-止损" class="headerlink" title="4.4 止损"></a>4.4 止损</h3><ul>
<li><p>狭义的止损是指<strong>当亏损达到一定幅度后下单卖出该股票的操作</strong>，目的是减少进一步的亏损。广义则指在狭义的思路上衍生的复杂的减少亏损的方法。更多的情况下指狭义的止损。综合运用前文的讲过的内容我们已经可以实现当亏损达到一定幅度后下单卖出该股票的止损操作了，不妨先自己思考下再继续学习。</p>
</li>
<li><p>通过context的数据可以得到持有股票的成本和现价，从而可以算出该股票的盈亏情况，运用条件判断语句根据盈亏情况从而决定是否卖出股票，从而实现止损操作，代码如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    g.security = <span class="string">&#x27;000001.XSHE&#x27;</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 买入股票</span></span><br><span class="line">    order(g.security, <span class="number">100</span>)</span><br><span class="line">    <span class="comment"># 获得股票持仓成本</span></span><br><span class="line">    cost=context.portfolio.positions[<span class="string">&#x27;000001.XSHE&#x27;</span>].avg_cost</span><br><span class="line">    <span class="comment"># 获得股票现价</span></span><br><span class="line">    price=context.portfolio.positions[<span class="string">&#x27;000001.XSHE&#x27;</span>].price</span><br><span class="line">    <span class="comment"># 计算收益率</span></span><br><span class="line">    ret=price/cost-<span class="number">1</span></span><br><span class="line">    <span class="comment"># 打印日志</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;成本价：%s&#x27;</span> % cost)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;现价：%s&#x27;</span> % price)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;收益率：%s&#x27;</span> % ret)</span><br><span class="line">    <span class="comment"># 如果收益率小于-0.01，即亏损达到1%则卖出股票，幅度可以自己调，一般10%</span></span><br><span class="line">    <span class="keyword">if</span> ret&lt;-<span class="number">0.01</span>:</span><br><span class="line">        order_target(<span class="string">&#x27;000001.XSHE&#x27;</span>,<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;触发止损&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置回测时间为从2017-03-01到2017-03-31，初始资金为100000，频率为天。回测发现会在2017-03-20触发止损。</p>
</li>
</ul>
<h1 id="5-循环、多股票策略"><a href="#5-循环、多股票策略" class="headerlink" title="5. 循环、多股票策略"></a>5. 循环、多股票策略</h1><hr>
<ul>
<li><p>我们继续以如下这个简单的策略为例进行学习在策略中操作多个股票。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    g.security = <span class="string">&#x27;000001.XSHE&#x27;</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    order(g.security, <span class="number">100</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-1-用list数据类型存储多个股票"><a href="#5-1-用list数据类型存储多个股票" class="headerlink" title="5.1 用list数据类型存储多个股票"></a>5.1 用list数据类型存储多个股票</h3><ul>
<li><p>事实上，根据前面的所学我们是可以写多个股票的策略的，无非是把原来单个股票的操作类似地再写几遍，比如下面这个策略就在操作两个股票。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    g.security1 = <span class="string">&#x27;000001.XSHE&#x27;</span></span><br><span class="line">    g.security2 = <span class="string">&#x27;000002.XSHE&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    order(g.security1, <span class="number">100</span>)</span><br><span class="line">    order(g.security2, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>显然的问题是，当股票比较多的时候，就要写很多遍，这样的写法就会很麻烦，看着也会比较乱。因此我们要学习其他的写法。首先我们先学习用list数据类型存储多个股票，如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    <span class="comment"># 把两个股票代码作为list存入g.security中</span></span><br><span class="line">    g.security = [<span class="string">&#x27;000001.XSHE&#x27;</span>,<span class="string">&#x27;000002.XSHE&#x27;</span>]</span><br></pre></td></tr></table></figure>
</li>
<li><p>list数据类型用法前文有讲过，特点是各个元素用逗号隔开后，用中括号把所以元素包起来，比较简单，有疑问不妨去回顾下。接下来是重点内容–循环语句，用它可以方便的批量操作多个股票。</p>
</li>
</ul>
<h3 id="5-2-循环语句"><a href="#5-2-循环语句" class="headerlink" title="5.2 循环语句"></a>5.2 循环语句</h3><ul>
<li><p>for循环可以遍历任何序列的项目，比如一个list，一般用法如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 含义是依次把序列中的元素赋值给for后的变量，并执行循环语句</span></span><br><span class="line"><span class="keyword">for</span> 变量 <span class="keyword">in</span> 一个序列:</span><br><span class="line">    要循环的语句，也叫循环体</span><br></pre></td></tr></table></figure>
</li>
<li><p>说起来略复杂，其实不难，来看个使用for的例子：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> [<span class="string">&#x27;大卫&#x27;</span>,<span class="string">&#x27;查理曼&#x27;</span>,<span class="string">&#x27;凯撒&#x27;</span>,<span class="string">&#x27;亚历山大&#x27;</span>]:</span><br><span class="line">    <span class="built_in">print</span>(k)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 执行后日志如下:</span></span><br><span class="line"><span class="comment"># 大卫</span></span><br><span class="line"><span class="comment"># 查理曼</span></span><br><span class="line"><span class="comment"># 凯撒</span></span><br><span class="line"><span class="comment"># 亚历山大</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 可见，for语句的运行过程是，取出list中第一个元素&#x27;大卫&#x27;并将其赋值给k，然后执行print(k)即在日志中打印k，，此时k中是&#x27;大卫&#x27;，之后，取出list中第二个元素&#x27;查理曼&#x27;并将其赋值给k，然后执行print(k)即在日志中打印k，此时k中是&#x27;查理曼&#x27;，以此类推，直到&#x27;亚历山大&#x27;被打印。</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>使用for语句时有一个常见一起使用的语句range()，它的功能是生成<strong>等差数列</strong>的，用法如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">range</span>(首项,上限,步长)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 首项 就是这个数列的第一项，可省略，省略后默认为0</span></span><br><span class="line"><span class="comment"># 步长 就是数列的公差、间隔，可省略，省略后默认为1</span></span><br><span class="line"><span class="comment"># 上限 是用来限制数列长度的，即数列不得大于或等于上限。不可省略。</span></span><br><span class="line"><span class="comment"># 另外，python2中range产生的是list，但python3中产生的不是list，但可以用list()这个语句把结果转成list类型，比如list(range(1,7,2))。我们策略编辑环境是python3。</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 一个例子</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">7</span>,<span class="number">2</span>):</span><br><span class="line">    <span class="built_in">print</span>(j)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>（<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">7</span>,<span class="number">2</span>)）)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 执行后日志如下:</span></span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line"><span class="comment"># 3</span></span><br><span class="line"><span class="comment"># 5</span></span><br><span class="line"><span class="comment"># [1, 3, 5]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>continue与break是重要的修饰循环执行流程的语句，用法如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># break的作用是写在循环体中用来跳出当前的整个循环过程</span></span><br><span class="line"><span class="comment"># continue的作用是写在循环体中用来跳出当前的这一次的循环过程</span></span><br><span class="line"><span class="comment"># 通过一个例子应该就能明白两者的作用与区别</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 一个简单的循环例子</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="built_in">print</span>(t)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 执行的结果是</span></span><br><span class="line"><span class="comment"># 0</span></span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line"><span class="comment"># 3</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 在例子中使用break。可以看到当循环到2的时候，打印omg后，执行break，终止了整个循环过程，不再继续循环3了，所以omg后就什么都没了。</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">if</span> t == <span class="number">2</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;omg&#x27;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="built_in">print</span>(t)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 执行的结果是</span></span><br><span class="line"><span class="comment"># 0</span></span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line"><span class="comment"># omg</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 在例子中使用continue。可以看到当循环到2的时候，打印omg后，执行continue，跳过了当前正循环的t为2这个循环过程的余下部分，不在继续执行之后的语句(即print(t)，此时t等于2)，而继续循环3了，所以omg后有打印3。</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">if</span> t == <span class="number">2</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;omg&#x27;</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="built_in">print</span>(t)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 执行的结果是</span></span><br><span class="line"><span class="comment"># 0</span></span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line"><span class="comment"># omg</span></span><br><span class="line"><span class="comment"># 3</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-3-写一个简单多股票策略"><a href="#5-3-写一个简单多股票策略" class="headerlink" title="5.3 写一个简单多股票策略"></a>5.3 写一个简单多股票策略</h3><ul>
<li><p>用刚学的知识把之前简单的策略例子改写成多股票版本，如下。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    <span class="comment"># 把两个股票代码作为list存入g.security中</span></span><br><span class="line">    g.security = [<span class="string">&#x27;000001.XSHE&#x27;</span>,<span class="string">&#x27;000002.XSHE&#x27;</span>]</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 每个股票买100股</span></span><br><span class="line">    <span class="keyword">for</span> stk <span class="keyword">in</span> g.security:</span><br><span class="line">        order(stk,<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>其实运用所学的知识已经可以进一步的加入很多东西了，比如在这个多股票的基础上在加入之前讲过的止损。不妨自己先尝试下再看下面的样例代码。样例代码如下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    <span class="comment"># 把两个股票代码作为list存入g.security中</span></span><br><span class="line">    g.security = [<span class="string">&#x27;000001.XSHE&#x27;</span>,<span class="string">&#x27;000002.XSHE&#x27;</span>]</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="keyword">for</span> stk <span class="keyword">in</span> g.security:</span><br><span class="line">        order(stk,<span class="number">100</span>)</span><br><span class="line">        <span class="comment"># 获得股票持仓成本</span></span><br><span class="line">        cost=context.portfolio.positions[stk].avg_cost</span><br><span class="line">        <span class="comment"># 获得股票现价</span></span><br><span class="line">        price=context.portfolio.positions[stk].price</span><br><span class="line">        <span class="comment"># 计算收益率</span></span><br><span class="line">        ret=price/cost-<span class="number">1</span></span><br><span class="line">        <span class="comment"># 如果收益率小于-0.01，即亏损达到1%则卖出股票，幅度可以自己调，一般10%</span></span><br><span class="line">        <span class="keyword">if</span> ret&lt;-<span class="number">0.01</span>:</span><br><span class="line">            order_target(stk,<span class="number">0</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;触发止损&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="6-获取典型常用数据"><a href="#6-获取典型常用数据" class="headerlink" title="6. 获取典型常用数据"></a>6. 获取典型常用数据</h1><hr>
<h3 id="6-1-聚宽数据"><a href="#6-1-聚宽数据" class="headerlink" title="6.1 聚宽数据"></a>6.1 聚宽数据</h3><ul>
<li>在<a target="_blank" rel="noopener" href="https://www.joinquant.com/data">聚宽数据</a>这个页面可以看到聚宽平台集成好的各大类数据，如下图，点击可以查看详情与用法。<br><img src="3f94ab1f15966d9bdff346d904076d92.png" alt="3f94ab1f15966d9bdff346d904076d92"></li>
<li>但实际上可能有些数据要在API文档里才比较容易能找到，比如龙虎榜数据等。这时用ctrl+f进行网页搜索可以快速搜索需要的数据。<br><img src="8f6de683dfcb1b5bfbe7854ab00fdcd3.png" alt="8f6de683dfcb1b5bfbe7854ab00fdcd3"></li>
<li>接下来会介绍几种常用数据的取用方法，这些取用方法比较典型，掌握后能覆盖基本的数据需求以及较容易的学会使用其他数据。</li>
</ul>
<h3 id="6-2-获取指数成分股"><a href="#6-2-获取指数成分股" class="headerlink" title="6.2 获取指数成分股"></a>6.2 获取指数成分股</h3><ul>
<li><p>以免有人不知道指数成分股是什么，简单说明下。为了衡量股市中某一大类股票整体的涨跌情况，通常会用这一类的股票加权平均编制出一个指数，而这些股票则叫做该指数的成分股,一般指数的成分股选取会变动。比如上证指数是用所有上交所的股票编制而成，可以衡量上交所股票整体的涨跌情况，有的股票退市了也就会被剔除成分股。比较常见的指数有上证指数、深证综指、创业板指、沪深300指数、中证500指数、上证50指数等。可以在数据-指数数据-<a target="_blank" rel="noopener" href="https://www.joinquant.com/indexData">指数列表</a>中找到聚宽支持的指数及其指数代码。同样要善用ctrl+f进行搜索。</p>
</li>
<li><p>获取指数成分股需要用到的API为<a target="_blank" rel="noopener" href="https://www.joinquant.com/help/api/help?name=api_old#get_index_stocks-%E8%8E%B7%E5%8F%96%E6%8C%87%E6%95%B0%E6%88%90%E4%BB%BD%E8%82%A1">get_index_stocks</a><br><img src="f1aa1a80675460c4638aee4c1c99f21f.png" alt="f1aa1a80675460c4638aee4c1c99f21f"></p>
</li>
<li><p>之前讲过怎么看API文档以及函数参数的含义，现在应该能直接看说明使用了。补充一个更详细点的例子应该就会用了。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取20180301时，上证50指数（000016.XSHG）成分股</span></span><br><span class="line">t=get_index_stocks(<span class="string">&quot;000016.XSHG&quot;</span>,<span class="string">&quot;2018-03-01&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(t[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(t)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 打印日志如下。股票代码在list中被打印出来前面会带有的u代表是对字符串进行unicode编码（略复杂，不懂没关系），只是显示效果，单独打印t[0]时就没有u。</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 600000.XSHG</span></span><br><span class="line"><span class="comment"># [u&#x27;600000.XSHG&#x27;, u&#x27;600016.XSHG&#x27;, u&#x27;600019.XSHG&#x27;, u&#x27;600028.XSHG&#x27;, u&#x27;600029.XSHG&#x27;, u&#x27;600030.XSHG&#x27;, u&#x27;600036.XSHG&#x27;, u&#x27;600048.XSHG&#x27;, u&#x27;600050.XSHG&#x27;, u&#x27;600104.XSHG&#x27;, u&#x27;600111.XSHG&#x27;, u&#x27;600309.XSHG&#x27;, u&#x27;600340.XSHG&#x27;, u&#x27;600518.XSHG&#x27;, u&#x27;600519.XSHG&#x27;, u&#x27;600547.XSHG&#x27;, u&#x27;600606.XSHG&#x27;, u&#x27;600837.XSHG&#x27;, u&#x27;600887.XSHG&#x27;, u&#x27;600919.XSHG&#x27;, u&#x27;600958.XSHG&#x27;, u&#x27;600999.XSHG&#x27;, u&#x27;601006.XSHG&#x27;, u&#x27;601088.XSHG&#x27;, u&#x27;601166.XSHG&#x27;, u&#x27;601169.XSHG&#x27;, u&#x27;601186.XSHG&#x27;, u&#x27;601211.XSHG&#x27;, u&#x27;601229.XSHG&#x27;, u&#x27;601288.XSHG&#x27;, u&#x27;601318.XSHG&#x27;, u&#x27;601328.XSHG&#x27;, u&#x27;601336.XSHG&#x27;, u&#x27;601390.XSHG&#x27;, u&#x27;601398.XSHG&#x27;, u&#x27;601601.XSHG&#x27;, u&#x27;601628.XSHG&#x27;, u&#x27;601668.XSHG&#x27;, u&#x27;601669.XSHG&#x27;, u&#x27;601688.XSHG&#x27;, u&#x27;601766.XSHG&#x27;, u&#x27;601800.XSHG&#x27;, u&#x27;601818.XSHG&#x27;, u&#x27;601857.XSHG&#x27;, u&#x27;601878.XSHG&#x27;, u&#x27;601881.XSHG&#x27;, u&#x27;601985.XSHG&#x27;, u&#x27;601988.XSHG&#x27;, u&#x27;601989.XSHG&#x27;, u&#x27;603993.XSHG&#x27;]</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-3-获取股票行情数据"><a href="#6-3-获取股票行情数据" class="headerlink" title="6.3 获取股票行情数据"></a>6.3 获取股票行情数据</h3><ul>
<li><p>此处的股票行情数据指</p>
<p>SecurityUnitData</p>
<p>里面的所有基本属性，以下列举类常用字段，详情请看文档。</p>
<ul>
<li>open: 时间段开始时价格</li>
<li>close: 时间段结束时价格</li>
<li>low: 最低价</li>
<li>high: 最高价</li>
<li>volume: 成交的股票数量</li>
<li>money: 成交的金额</li>
<li>factor: 前复权因子</li>
<li>avg: 这段时间的平均价</li>
<li>pre_close: 前一个单位时间结束时的价格</li>
<li>paused: 这只股票是否停牌，是则为1，否则为0</li>
</ul>
</li>
<li><p>history（多只股票，一个字段）</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://www.joinquant.com/api#history">API文档：history</a><br><img src="11111111111111111111111113903.png" alt="11111111111111111111111113903"></p>
</li>
<li><p><strong>可以同时获得多个股票的数据，但只能获得相同的一个数据字段。</strong>如获得 平安银行，建设银行，农业银行这3只股票，前3天的交易额。</p>
</li>
<li><p>默认不跳过不交易日期，由skip_paused参数控制。</p>
</li>
<li><p>df参数控制返回结果的数据类型，默认是True代表dataframe类型，稍后我们会讲到，当df为False时就为之前讲过的dict类型。</p>
</li>
<li><p>fq参数控制复权方式，往往可以不管它直接用默认的前复权即可。复权的含义不难，解释略麻烦，建议自行搜索学习下。</p>
</li>
<li><p>接下来介绍的API还会有skip_paused、df、fq参数，就不再提了。这三个参数新手可以以后慢慢了解，现在不管也没关系，如果不想用dataframe，会把df参数调成False(或0)就行。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子 df=True，返回dataframe类型</span></span><br><span class="line">w=history(count=<span class="number">3</span>, field=<span class="string">&#x27;money&#x27;</span>, security_list=[<span class="string">&#x27;000001.XSHE&#x27;</span>,<span class="string">&#x27;000002.XSHE&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(w)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 结果如下：</span></span><br><span class="line"><span class="comment">#              000001.XSHE   000002.XSHE</span></span><br><span class="line"><span class="comment"># 2016-08-29  5.322954e+08  1.796321e+09</span></span><br><span class="line"><span class="comment"># 2016-08-30  5.618541e+08  2.072873e+09</span></span><br><span class="line"><span class="comment"># 2016-08-31  4.638758e+08  5.748581e+09</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 例子 df=False，返回dict类型</span></span><br><span class="line">w=history(count=<span class="number">3</span>, field=<span class="string">&#x27;money&#x27;</span>, security_list=[<span class="string">&#x27;000001.XSHE&#x27;</span>,<span class="string">&#x27;000002.XSHE&#x27;</span>],df=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(w)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 结果如下：</span></span><br><span class="line"><span class="comment"># &#123;&#x27;000001.XSHE&#x27;: array([  5.32295362e+08,   5.61854066e+08,   4.63875763e+08]), &#x27;000002.XSHE&#x27;: array([  1.79632055e+09,   2.07287325e+09,   5.74858107e+09])&#125;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>attribute_history（一只股票，多个字段）</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://www.joinquant.com/api#attributehistory">API文档：attribute_history</a><br><img src="2222222222222222222222a4864cef.png" alt="2222222222222222222222a4864cef"></p>
</li>
<li><p><strong>只能获取单独一个股票的数据，但可以同时获得多个字段的数据。</strong>如获得 平安银行这一只股票，前3天的交易额，交易量，最高价，最低价等。</p>
</li>
<li><p>默认跳过不交易日期，由skip_paused参数控制。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子</span></span><br><span class="line">w=attribute_history(security=<span class="string">&#x27;000001.XSHE&#x27;</span>,count=<span class="number">3</span>, fields=[<span class="string">&#x27;money&#x27;</span>,<span class="string">&#x27;high&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(w)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 结果如下：</span></span><br><span class="line"><span class="comment">#                    money  high</span></span><br><span class="line"><span class="comment"># 2016-08-29  5.322954e+08  9.31</span></span><br><span class="line"><span class="comment"># 2016-08-30  5.618541e+08  9.33</span></span><br><span class="line"><span class="comment"># 2016-08-31  4.638758e+08  9.36</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Pandas.DataFrame</p>
<ul>
<li><p>返回的财务数据是DataFrame类型，这是一种二维表结构的功能强大的数据类型，常用于数据处理与分析。我们以刚刚的例子介绍下dataframe最常用的获取数据的方法。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个dataframe类型的例子</span></span><br><span class="line">w=attribute_history(security=<span class="string">&#x27;000001.XSHE&#x27;</span>,count=<span class="number">3</span>, fields=[<span class="string">&#x27;money&#x27;</span>,<span class="string">&#x27;high&#x27;</span>,<span class="string">&#x27;open&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(w)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 结果如下：</span></span><br><span class="line"><span class="comment">#                    money  high  open</span></span><br><span class="line"><span class="comment"># 2016-08-30  5.618541e+08  9.33  9.29</span></span><br><span class="line"><span class="comment"># 2016-08-31  4.638758e+08  9.36  9.32</span></span><br><span class="line"><span class="comment"># 2016-09-01  4.548486e+08  9.38  9.35</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>dataframe是一个二维表，包括index（行标签、索引）、columns（列标签）、values（值）三个部分。取用方法如下，注意三个部分的数据类型不是固定的，因此功能很灵活但也更难使用。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取index</span></span><br><span class="line"><span class="built_in">print</span>(w.index)</span><br><span class="line"><span class="comment"># 结果如下，是datatimeindex类型，很特殊，不常用，建议新手回避。</span></span><br><span class="line"><span class="comment"># DatetimeIndex([&#x27;2016-08-30&#x27;, &#x27;2016-08-31&#x27;, &#x27;2016-09-01&#x27;], dtype=&#x27;datetime64[ns]&#x27;, freq=None, tz=None)</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 获取columns</span></span><br><span class="line"><span class="built_in">print</span>(w.columns)</span><br><span class="line"><span class="comment"># 结果如下，是index类型</span></span><br><span class="line"><span class="comment"># Index([u&#x27;money&#x27;, u&#x27;high&#x27;, u&#x27;open&#x27;], dtype=&#x27;object&#x27;)</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 可以用list()将其转成list</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(w.columns))</span><br><span class="line"><span class="comment"># 结果如下</span></span><br><span class="line"><span class="comment"># [&#x27;money&#x27;, &#x27;high&#x27;, &#x27;open&#x27;]</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 获取values</span></span><br><span class="line"><span class="built_in">print</span>(w.values)</span><br><span class="line"><span class="comment"># 结果如下，是一个嵌套的list</span></span><br><span class="line"><span class="comment"># [[  5.61854066e+08   9.33000000e+00   9.29000000e+00]</span></span><br><span class="line"><span class="comment"># [  4.63875763e+08   9.36000000e+00   9.32000000e+00]</span></span><br><span class="line"><span class="comment"># [  4.54848634e+08   9.38000000e+00   9.35000000e+00]]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>选择dataframe某几列</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按标签获取某几列.loc[:,[列标签名,...]]</span></span><br><span class="line"><span class="built_in">print</span>(w.loc[:,[<span class="string">&#x27;open&#x27;</span>,<span class="string">&#x27;high&#x27;</span>]])</span><br><span class="line"><span class="comment"># 结果如下</span></span><br><span class="line"><span class="comment">#             open  high</span></span><br><span class="line"><span class="comment"># 2016-08-29  9.28  9.31</span></span><br><span class="line"><span class="comment"># 2016-08-30  9.29  9.33</span></span><br><span class="line"><span class="comment"># 2016-08-31  9.32  9.36</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 按位置获取某几列.iloc[:,[位置,...]]，位置的含义是第几个，从0开始。下文同。</span></span><br><span class="line"><span class="built_in">print</span>(w.iloc[:,[<span class="number">0</span>,<span class="number">2</span>]])</span><br><span class="line"><span class="comment"># 结果如下</span></span><br><span class="line"><span class="comment">#                    money  open</span></span><br><span class="line"><span class="comment"># 2016-08-29  5.322954e+08  9.28</span></span><br><span class="line"><span class="comment"># 2016-08-30  5.618541e+08  9.29</span></span><br><span class="line"><span class="comment"># 2016-08-31  4.638758e+08  9.32</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># : 即冒号，可以代表全部，iloc或loc都可以。</span></span><br><span class="line"><span class="built_in">print</span>(w.iloc[:,:])</span><br><span class="line"><span class="comment"># 结果如下</span></span><br><span class="line"><span class="comment">#                    money  high  open</span></span><br><span class="line"><span class="comment"># 2016-08-29  5.322954e+08  9.31  9.28</span></span><br><span class="line"><span class="comment"># 2016-08-30  5.618541e+08  9.33  9.29</span></span><br><span class="line"><span class="comment"># 2016-08-31  4.638758e+08  9.36  9.32</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 选择后的数据依然是dataframe类型，用.values可以获取数据。对后文的行情况也成立。</span></span><br><span class="line"><span class="built_in">print</span>(w.iloc[:,[<span class="number">0</span>,<span class="number">2</span>]].values)</span><br><span class="line"><span class="comment"># 结果如下,是个list</span></span><br><span class="line"><span class="comment"># [[  5.61854066e+08   9.29000000e+00]</span></span><br><span class="line"><span class="comment"># [  4.63875763e+08   9.32000000e+00]</span></span><br><span class="line"><span class="comment"># [  4.54848634e+08   9.35000000e+00]]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>选择dataframe某几行</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按标签获取某几行.loc[[行标签名,...],:]</span></span><br><span class="line"><span class="built_in">print</span>(w.loc[[<span class="string">&#x27;2016-08-29&#x27;</span>,<span class="string">&#x27;2016-08-31&#x27;</span>],:])</span><br><span class="line"><span class="comment"># 此处这样写会报错，原因是当前的行标签类型是DatetimeIndex，不是字符串，所以使用标签名时要注意数据类型。而时间类型的数据处理往往非常麻烦，因此行或列标签名是日期情况下建议新手回避，改使用位置获取。</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 按位置获取某几行.iloc[[位置,...],:]</span></span><br><span class="line"><span class="built_in">print</span>(w.iloc[[<span class="number">0</span>,<span class="number">2</span>],:])</span><br><span class="line"><span class="comment"># 结果如下</span></span><br><span class="line"><span class="comment">#                    money  high  open</span></span><br><span class="line"><span class="comment"># 2016-08-29  5.322954e+08  9.31  9.28</span></span><br><span class="line"><span class="comment"># 2016-08-31  4.638758e+08  9.36  9.32</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># : 即冒号，行情况下依然可以代表全部</span></span><br><span class="line"><span class="built_in">print</span>(w.loc[:,:])</span><br><span class="line"><span class="comment"># 结果如下</span></span><br><span class="line"><span class="comment">#                    money  high  open</span></span><br><span class="line"><span class="comment"># 2016-08-29  5.322954e+08  9.31  9.28</span></span><br><span class="line"><span class="comment"># 2016-08-30  5.618541e+08  9.33  9.29</span></span><br><span class="line"><span class="comment"># 2016-08-31  4.638758e+08  9.36  9.32</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>dataframe 行列转置</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 行列转置的意思就是按对角线行列反转，方法是.T</span></span><br><span class="line"><span class="built_in">print</span>(w.T)</span><br><span class="line"><span class="comment"># 结果如下</span></span><br><span class="line"><span class="comment">#          2016-08-29    2016-08-30    2016-08-31</span></span><br><span class="line"><span class="comment"># money  5.322954e+08  5.618541e+08  4.638758e+08</span></span><br><span class="line"><span class="comment"># high   9.310000e+00  9.330000e+00  9.360000e+00</span></span><br><span class="line"><span class="comment"># open   9.280000e+00  9.290000e+00  9.320000e+00</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>回过头来解释下pandas的含义，pandas是一个模块或者叫库，可以让我们直接利用其中包含的已经设计好的函数或数据类型，加快我们的工作效率。pandas主要功能是数据处理与分析，其中dataframe就是属于pandas的，是原生的python语言没有的。随着深入的学习，你会遇到其他的功能模块，一般来说要使用一个模块是要用一行代码加载导入的，但pandas聚宽系统已经自动加载了，不必额外写代码导入了。</p>
</li>
</ul>
</li>
</ul>
<h3 id="6-4-获取股票财务数据"><a href="#6-4-获取股票财务数据" class="headerlink" title="6.4 获取股票财务数据"></a>6.4 获取股票财务数据</h3><ul>
<li><p>股票财务数据这里是指发股票的公司发布的财务报表中的数据。可以在聚宽数据-<a target="_blank" rel="noopener" href="https://www.joinquant.com/data/dict/fundamentals">股票财务数据</a>查看数据详情。</p>
</li>
<li><p>财务报表简称财报，是用来向股东汇报企业经营情况的，上市公司必须按季度公布财报，一年有四季所以财报依发布次序一季报、半年报（也称中报）、三季报、年报，而具体的发布日期在一定期限内即可并非固定，年报要求年度结束四个月内披露，半年报是上半年结束后两个月内，一季报与三季报是季度结束后一个月内。特别的是像总市值、市盈率这种跟股价挂钩的市值数据是每天更新的。</p>
</li>
<li><p>获取股票财务数据需要用到的API为<a target="_blank" rel="noopener" href="https://www.joinquant.com/help/api/help?name=api_old#get_fundamentals-%E6%9F%A5%E8%AF%A2%E8%B4%A2%E5%8A%A1%E6%95%B0%E6%8D%AE">get_fundamentals</a>。这个语句的用法较为复杂，下文对文档进行补充说明，文档还是要看的。<br><img src="3333333333333333333336b.png" alt="3333333333333333333336b"></p>
</li>
<li><p>未来函数是什么？</p>
<ul>
<li>我们做回测去验证策略时，其实是用历史数据去模拟当时的市场从而得知策略在历史上表现如何，但是如果策略利用了历史当时无法得到的信息，往往就会造成回测结果极大失真，这时我们会说这个策略有未来函数。</li>
<li>举一个典型的有未来函数的策略:每天买明天涨停的股票。 事实上你是不能知道明天哪个股票涨停的，所以现实中是不能实现的，但是我们做回测是用的历史数据，所以我们其实是能实现用2012年的数据对这个买明日涨停股的策略做回测的，毕竟现在已经过了2012年，2012年每天哪个股票会涨都是已经知道的了。这样的有未来函数的回测结果肯定是没价值的，因为现实中不能实现，尽管回测结果有时特别喜人。</li>
</ul>
</li>
<li><p>date与statDate的问题</p>
<ul>
<li>传入date时，查询指定日期date 所能看到的最近的数据。 回测时不填则默认值会为回测日期的前一天（模拟现实，避免未来函数）。date参数的要求为格式类似’2015-01-15’的字符串，datetime类型的时间数据也是可以的，不过略复杂不展开。</li>
<li>传入statDate时, 查询 statDate 指定的季度（例如’2015q1’、 ‘2013q4’的字符串）或者年份（如’2015’、’2013’的字符串）的财务数据。这种用法需要注意的地方比较多，请注意文档中提到的问题。</li>
<li>date和statDate参数只能同时传入其中一个。当 date 和 statDate 都不传入时，相当于使用 date 参数，date 的默认值会为回测日期的前一天。文档中提到的回测模块就是指我们编写策略的功能模块，研究模块我们之后会介绍。因此，为方便在回测中使用，date 和 statDate 都不传入。</li>
</ul>
</li>
<li><p>单季度与报告期。</p>
<ul>
<li>之前讲过，财务数据按季度发布，一般财经网站上提供的财务数据是默认按报告期提供的，即每季度统计的周期跨度分别为第一季度、前两个季度、前三个季度、前四个季度（全年）。</li>
<li>而聚宽考虑到量化分析，提供的财务数据全是单季度的，即每季度统计的周期跨度分别为第一季度、第二季度、第三季度、第四季度。</li>
<li>因此，当你发现聚宽财务数据比财经网站的财务数据差的很多时，很可能是单季度与报告期的差别造成的。</li>
</ul>
</li>
<li><p>query_object参数以及快速上手模板</p>
<ul>
<li><p>query_object参数是要求传入一个Query对象用于描述所需的数据，这个东西展开讲相当于一门小的编程语言，麻烦而不必要，这里提供一个快速上手的模板用来产生query_object参数，多数情况下往里套就可以了，例子如下，建议对比文档里的例子看看。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 快速上手模板</span></span><br><span class="line"><span class="comment"># query(表.字段).filter(筛选条件).order_by(排序方法).limit(数量上限)</span></span><br><span class="line"><span class="comment">#比较长的话可以分行写</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>表和字段可以在财务数据文档查看，如下。表和字段可以写多个用逗号隔开，只写表名不写字段代表选择该表的所有字段。注意看含义与单位。</p>
<p><img src="44444444444444444444444444d47486e.png" alt="44444444444444444444444444d47486e"></p>
</li>
<li><p>筛选条件跟讲if判断时用的条件是一样的，多个条件用逗号隔开代表与（and）的关系。特别的是要用复杂的与或非的逻辑关系时，在此处and、or、not是不能用的，要对应的改用&amp;（与）、|（或）、~（非）。</p>
</li>
<li><p>排序的写法比较简单，就是要作为排序标准的字段后面加.desc()即由大到小，或.asc()即由小到大。</p>
</li>
<li><p>数量上限可以自己设置，代表最多返回的数据条数。不过系统强制限制每次最多返回10000条，就算你自己在此处限制比10000多也没用。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子</span></span><br><span class="line"><span class="comment"># 获取 市值表.股票代码，资产负债表.未分配利润</span></span><br><span class="line">q=query(valuation.code,balance.retained_profit</span><br><span class="line"><span class="comment"># 筛选 市值大于100 并且 市盈率小于10</span></span><br><span class="line">).<span class="built_in">filter</span>(valuation.market_cap&gt;<span class="number">100</span>,valuation.pe_ratio &lt; <span class="number">10</span></span><br><span class="line"><span class="comment"># 排序 按市值从大到小排</span></span><br><span class="line">).order_by(valuation.market_cap.desc()</span><br><span class="line"><span class="comment"># 数量 上限10条数据</span></span><br><span class="line">).limit(<span class="number">10</span>)</span><br><span class="line">w=get_fundamentals(q)</span><br><span class="line"><span class="built_in">print</span>(w)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 结果如下：</span></span><br><span class="line"><span class="comment">#           code  retained_profit</span></span><br><span class="line"><span class="comment"># 0  601398.XSHG     8.566400e+11</span></span><br><span class="line"><span class="comment"># 1  601939.XSHG     7.400340e+11</span></span><br><span class="line"><span class="comment"># 2  601288.XSHG     4.644490e+11</span></span><br><span class="line"><span class="comment"># 3  601988.XSHG     5.267460e+11</span></span><br><span class="line"><span class="comment"># 4  600036.XSHG     1.816520e+11</span></span><br><span class="line"><span class="comment"># 5  601328.XSHG     9.208500e+10</span></span><br><span class="line"><span class="comment"># 6  600000.XSHG     1.037620e+11</span></span><br><span class="line"><span class="comment"># 7  600016.XSHG     1.277570e+11</span></span><br><span class="line"><span class="comment"># 8  601166.XSHG     1.573490e+11</span></span><br><span class="line"><span class="comment"># 9  601998.XSHG     1.298680e+11</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="6-5-本地获取聚宽数据-JQData"><a href="#6-5-本地获取聚宽数据-JQData" class="headerlink" title="6.5 本地获取聚宽数据-JQData"></a>6.5 本地获取聚宽数据-JQData</h3><p>申请地址： <a target="_blank" rel="noopener" href="https://www.joinquant.com/default/index/sdk?f=home&m=banner">https://www.joinquant.com/default/index/sdk?f=home&amp;m=banner</a><br>安装方法： <a target="_blank" rel="noopener" href="https://www.joinquant.com/post/12479">https://www.joinquant.com/post/12479</a><br>调用方法：<br>from jqdatasdk import *<br>import jqdatasdk as jq<br>jq.auth(‘手机号’, ‘密码’)<br>df &#x3D; jq.get_price(“000001.XSHE”)<br>print(df)</p>
<p>JQData使用方法<br><a target="_blank" rel="noopener" href="https://www.joinquant.com/data/dict/jqDataSdk">https://www.joinquant.com/data/dict/jqDataSdk</a><br>JQData提供哪些数据及数据更新频率<br><a target="_blank" rel="noopener" href="https://www.joinquant.com/help/api/help?name=JQData#JQData%E6%8F%90%E4%BE%9B%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0%E9%A2%91%E7%8E%87">https://www.joinquant.com/help/api/help?name=JQData#JQData提供哪些数据及数据更新频率</a><br>JQData，jqdatasdk和jqdata的关系<br><a target="_blank" rel="noopener" href="https://www.joinquant.com/help/api/help?name=faq#JQDatajqdatasdk%E5%92%8Cjqdata%E7%9A%84%E5%85%B3%E7%B3%BB">https://www.joinquant.com/help/api/help?name=faq#JQDatajqdatasdk和jqdata的关系</a><br>有关权限和付费问题请咨询管理员微信：jqdata02</p>
<h1 id="7-综合之前所学写一个策略"><a href="#7-综合之前所学写一个策略" class="headerlink" title="7. 综合之前所学写一个策略"></a>7. 综合之前所学写一个策略</h1><hr>
<ul>
<li>通过前文基础知识的学习，本文将引导读者运用所学写成一个策略。如果发现某些知识忘了很正常，回头再看就行，用到什么去学什么学习的效率更高。</li>
</ul>
<h3 id="7-1-灵感细化"><a href="#7-1-灵感细化" class="headerlink" title="7.1 灵感细化"></a>7.1 灵感细化</h3><ul>
<li><p>之前也提到过策略灵感的来源多种多样，可能是通过阅读、通过与人交流、或是通过自己感悟与研究等等。灵感最初可能只是模糊的感觉或疑问，比如“感觉低市盈率的股票好像长期收益更好”、“当股价一旦超过整百的时候会不会更容易继续涨一段”、“这个股票和那个股票的股价数据看起来好像符合某种统计规律”等等。验证灵感的一个基本方法是把灵感细化，写成策略做回测。</p>
</li>
<li><p>现在你听说了这样一件事，<strong>小市值股票过去很长一段时间内收益特别好，但最近不太行了</strong>。你觉得这件事比较有价值，想要写成策略来回测验证下。请思考下，应该写一个什么样的策略来验证这件事呢？</p>
</li>
<li><p>为了验证灵感，我们把灵感细化成内容如下的这样一个策略。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">每天找出市值排名最小的前10只股票作为要买入的股票。</span><br><span class="line">若已持有的股票的市值已经不够小而不在要买入的股票中，则卖出这些股票。</span><br><span class="line">买入要买入的股票，买入金额为当前可用资金的10分之一。</span><br></pre></td></tr></table></figure>
</li>
<li><p>考虑到不一定要选10个股票，股票数量应该是个可以方便调节的变量，因此策略内容改成如下这样更好。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">设定好要交易的股票数量stocksnum </span><br><span class="line">每天找出市值排名最小的前stocksnum只股票作为要买入的股票。</span><br><span class="line">若已持有的股票的市值已经不够小而不在要买入的股票中，则卖出这些股票。</span><br><span class="line">买入要买入的股票，买入金额为当前可用资金的stocksnum分之一。</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="7-2-逐步实现"><a href="#7-2-逐步实现" class="headerlink" title="7.2 逐步实现"></a>7.2 逐步实现</h3><ul>
<li><p>因为最终目的是要写成代码交给计算机回测，因此要逐步把文字的意思用代码实现，首先要把这个策略放到之前讲过的初始化与周期循环的策略框架中，如下。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    <span class="comment"># 代码：设定好要交易的股票数量stocksnum</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 代码：找出市值排名最小的前stocksnum只股票作为要买入的股票</span></span><br><span class="line">    <span class="comment"># 代码：若已持有的股票的市值已经不够小而不在要买入的股票中，则卖出这些股票。</span></span><br><span class="line">    <span class="comment"># 代码：买入要买入的股票，买入金额为可用资金的stocksnum分之一</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>接下来，你只需要逐步的把策略的全部内容用代码实现出来，技巧是把复杂的内容拆分成多个简单的内容，逐步实现，对于不确定的东西print打印出来看看。往下读之前，建议自己独立实现下试试，基本都是用讲过的内容。遇到困难可以看下我下面给出提示，所有提示后面会给出参考代码。</p>
</li>
<li><p>提示</p>
<ul>
<li>代码：设定好要交易的股票数量stocksnum。这句非常简单，需要注意的是要用到之前讲过的<strong>全局变量</strong>。</li>
<li>代码：找出市值排名最小的前stocksnum只股票作为要买入的股票。首先使用get_all_securities（获取所有股票函数）取其index（行标签、索引）得到股票列表。然后，使用获取财务数据的方法找出当前全市场股票中市值最小的前stocksnum个的股票代码。</li>
<li>代码：若已持有的股票的市值已经不够小而不在要买入的股票中，则卖出这些股票。使用context数据获取当前持仓情况，用for循环语句与if判断语句判断股票是否在当前持仓中，用in判断是否一个元素在某list中，用下单API实现卖出操作。</li>
<li>代码：买入要买入的股票，买入金额为可用资金的stocksnum分之一。使用context数据获取当前可用资金总量，用for循环与下单API实现买入每个要买入的股票。</li>
</ul>
</li>
<li><p>参考代码</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    <span class="comment"># 设定好要交易的股票数量stocksnum</span></span><br><span class="line">    g.stocksnum = <span class="number">10</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 代码：找出市值排名最小的前stocksnum只股票作为要买入的股票</span></span><br><span class="line">    <span class="comment"># 获取当天的股票列表</span></span><br><span class="line">    scu = get_all_securities(date= context.current_dt).index.tolist() <span class="comment"># 使用“获取所有当前时间股票”的行标签（实际上就是股票代码）做成一个列表</span></span><br><span class="line">    <span class="comment"># 选出在scu内的市值排名最小的前stocksnum只股票，严格按照query的语法，# query(表valuation.字段).filter(筛选条件).order_by(排序方法).limit(数量上限); 将找到的十只小市值股票代码传给变量q</span></span><br><span class="line">    q=query(valuation.code  <span class="comment"># 只返回（只查询）符合要求的股票代码字段</span></span><br><span class="line">                ).<span class="built_in">filter</span>(</span><br><span class="line">                    valuation.code.in_(scu)  <span class="comment"># 筛选条件股票要来源于我们刚刚创建的股票列表</span></span><br><span class="line">                ).order_by(</span><br><span class="line">                    valuation.market_cap.asc()  <span class="comment"># 按照市值的从小到大排序</span></span><br><span class="line">                ).limit(g.stocksnum)  <span class="comment"># 查询数量上限10</span></span><br><span class="line">    df = get_fundamentals(q) <span class="comment"># 查询财务数据函数，因为query中查询的字段只有股票代码，所以传给参数df的也只有股票代码</span></span><br><span class="line">    <span class="comment"># 选取股票代码并转为list</span></span><br><span class="line">    buylist=<span class="built_in">list</span>(df[<span class="string">&#x27;code&#x27;</span>])  <span class="comment"># 我们的股票池</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 代码：若已持有的股票的市值已经不够小而不在要买入的股票中，则卖出这些股票。</span></span><br><span class="line">    <span class="comment"># 对于每个当下持有的股票进行判断：现在是否已经不在buylist里，如果是则卖出</span></span><br><span class="line">    <span class="keyword">for</span> stock <span class="keyword">in</span> context.portfolio.positions:  <span class="comment"># context.portfolio.positions指账户的仓位信息（一个字典key为股票代码，value为股票信息），这里的stock实际就是遍历仓位信息中的股票代码</span></span><br><span class="line">        <span class="keyword">if</span> stock <span class="keyword">not</span> <span class="keyword">in</span> buylist: <span class="comment">#如果stock不在buylist</span></span><br><span class="line">            order_target(stock, <span class="number">0</span>) <span class="comment">#调整stock的持仓为0，即卖出，stock实际上就是股票代码</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 代码：买入要买入的股票，买入金额为可用资金的stocksnum分之一</span></span><br><span class="line">    <span class="comment"># 将资金分成g.stocksnum份</span></span><br><span class="line">    position_per_stk = context.portfolio.available_cash/g.stocksnum  <span class="comment"># 账户可用资金/10</span></span><br><span class="line">    <span class="comment"># 用position_per_stk大小的g.stocksnum份资金去买buylist中的股票</span></span><br><span class="line">    <span class="keyword">for</span> stock <span class="keyword">in</span> buylist:</span><br><span class="line">        order_value(stock, position_per_stk)</span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上述代码的单元测试</span></span><br><span class="line">a=get_all_securities(date=<span class="string">&#x27;2019-02-07&#x27;</span>).index.tolist()</span><br><span class="line">a</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;000001.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000002.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000004.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000005.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000006.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000007.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000008.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000009.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000010.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000011.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000012.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000014.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000016.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000017.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000018.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000019.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000020.XSHE&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;000021.XSHE&#x27;</span>,</span><br><span class="line"> ………………]</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a=get_all_securities(date= <span class="string">&#x27;2019-02-07&#x27;</span>).index.tolist()</span><br><span class="line">q=query(valuation.code   <span class="comment"># 只返回（只查询）符合要求的股票代码字段</span></span><br><span class="line">                  ).<span class="built_in">filter</span>(</span><br><span class="line">                      valuation.code.in_(a)  <span class="comment"># 筛选条件股票要来源于我们刚刚创建的股票列表</span></span><br><span class="line">                  ).order_by(</span><br><span class="line">                      valuation.market_cap.asc()  <span class="comment"># 按照市值的从小到大排序</span></span><br><span class="line">                  ).limit(<span class="number">10</span>)  <span class="comment"># 查询数量上限10</span></span><br><span class="line">df = get_fundamentals(q) <span class="comment"># 查询财务数据函数</span></span><br><span class="line">df</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="right"></th>
<th align="right">code</th>
</tr>
</thead>
<tbody><tr>
<td align="right">0</td>
<td align="right">002499.XSHE</td>
</tr>
<tr>
<td align="right">1</td>
<td align="right">600260.XSHG</td>
</tr>
<tr>
<td align="right">2</td>
<td align="right">600139.XSHG</td>
</tr>
<tr>
<td align="right">3</td>
<td align="right">600242.XSHG</td>
</tr>
<tr>
<td align="right">4</td>
<td align="right">600311.XSHG</td>
</tr>
<tr>
<td align="right">5</td>
<td align="right">600781.XSHG</td>
</tr>
<tr>
<td align="right">6</td>
<td align="right">002781.XSHE</td>
</tr>
<tr>
<td align="right">7</td>
<td align="right">300330.XSHE</td>
</tr>
<tr>
<td align="right">8</td>
<td align="right">300309.XSHE</td>
</tr>
<tr>
<td align="right">9</td>
<td align="right">002569.XSHE</td>
</tr>
</tbody></table>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a=get_all_securities(date= <span class="string">&#x27;2019-02-07&#x27;</span>).index.tolist()</span><br><span class="line">q=query(valuation    <span class="comment"># 返回符合要求的所有字段</span></span><br><span class="line">                  ).<span class="built_in">filter</span>(</span><br><span class="line">                      valuation.code.in_(a)  <span class="comment"># 筛选条件股票要来源于我们刚刚创建的股票列表</span></span><br><span class="line">                  ).order_by(</span><br><span class="line">                      valuation.market_cap.asc()  <span class="comment"># 按照市值的从小到大排序</span></span><br><span class="line">                  ).limit(<span class="number">10</span>)  <span class="comment"># 查询数量上限10</span></span><br><span class="line">df = get_fundamentals(q) <span class="comment"># 查询财务数据函数</span></span><br><span class="line">df</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="right"></th>
<th align="right">id</th>
<th align="right">code</th>
<th align="right">pubDate</th>
<th align="right">pe_ratio</th>
<th align="right">turnover_ratio</th>
<th align="right">pb_ratio</th>
<th align="right">ps_ratio</th>
<th align="right">pcf_ratio</th>
<th align="right">capitalization</th>
<th align="right">market_cap</th>
<th align="right">circulating_cap</th>
<th align="right">circulating_market_cap</th>
<th align="right">day</th>
<th>pe_ratio_lyr</th>
</tr>
</thead>
<tbody><tr>
<td align="right">0</td>
<td align="right">93418619</td>
<td align="right">002499.XSHE</td>
<td align="right">2023-02-08</td>
<td align="right">-6.1421</td>
<td align="right">NaN</td>
<td align="right">-22.5506</td>
<td align="right">1.6834</td>
<td align="right">29.1708</td>
<td align="right">18900.0000</td>
<td align="right">3.1752</td>
<td align="right">18899.3242</td>
<td align="right">3.1751</td>
<td align="right">2023-02-08</td>
<td>-10.7096</td>
</tr>
<tr>
<td align="right">1</td>
<td align="right">93420403</td>
<td align="right">600260.XSHG</td>
<td align="right">2023-02-08</td>
<td align="right">-0.1863</td>
<td align="right">NaN</td>
<td align="right">-0.2214</td>
<td align="right">0.6897</td>
<td align="right">-15.7960</td>
<td align="right">99488.6094</td>
<td align="right">4.6760</td>
<td align="right">99488.6094</td>
<td align="right">4.6760</td>
<td align="right">2023-02-08</td>
<td>-0.0552</td>
</tr>
<tr>
<td align="right">2</td>
<td align="right">93422822</td>
<td align="right">600139.XSHG</td>
<td align="right">2023-02-08</td>
<td align="right">-3.5879</td>
<td align="right">10.3435</td>
<td align="right">-0.9002</td>
<td align="right">5843.8311</td>
<td align="right">201530.3906</td>
<td align="right">66189.0547</td>
<td align="right">5.3613</td>
<td align="right">66189.0547</td>
<td align="right">5.3613</td>
<td align="right">2023-02-08</td>
<td>-0.8411</td>
</tr>
<tr>
<td align="right">3</td>
<td align="right">93422390</td>
<td align="right">600242.XSHG</td>
<td align="right">2023-02-08</td>
<td align="right">-1.1526</td>
<td align="right">2.0953</td>
<td align="right">-14.9207</td>
<td align="right">18.4809</td>
<td align="right">39.7451</td>
<td align="right">45666.5117</td>
<td align="right">5.9823</td>
<td align="right">45129.4531</td>
<td align="right">5.9120</td>
<td align="right">2023-02-08</td>
<td>-1.2672</td>
</tr>
<tr>
<td align="right">4</td>
<td align="right">93421449</td>
<td align="right">600311.XSHG</td>
<td align="right">2023-02-08</td>
<td align="right">-1.8449</td>
<td align="right">17.3038</td>
<td align="right">-3.4052</td>
<td align="right">0.7653</td>
<td align="right">-145.8034</td>
<td align="right">66560.0000</td>
<td align="right">6.1901</td>
<td align="right">66560.0000</td>
<td align="right">6.1901</td>
<td align="right">2023-02-08</td>
<td>-2.1453</td>
</tr>
<tr>
<td align="right">5</td>
<td align="right">93420755</td>
<td align="right">600781.XSHG</td>
<td align="right">2023-02-08</td>
<td align="right">-0.2780</td>
<td align="right">0.2274</td>
<td align="right">4.1403</td>
<td align="right">0.6731</td>
<td align="right">-52.9425</td>
<td align="right">62715.7500</td>
<td align="right">9.0311</td>
<td align="right">37426.3203</td>
<td align="right">5.3894</td>
<td align="right">2023-02-08</td>
<td>-0.2823</td>
</tr>
<tr>
<td align="right">6</td>
<td align="right">93420844</td>
<td align="right">002781.XSHE</td>
<td align="right">2023-02-08</td>
<td align="right">-0.5129</td>
<td align="right">0.4797</td>
<td align="right">-2.2722</td>
<td align="right">0.5153</td>
<td align="right">-26.8507</td>
<td align="right">22500.0000</td>
<td align="right">9.1125</td>
<td align="right">22392.1445</td>
<td align="right">9.0688</td>
<td align="right">2023-02-08</td>
<td>-0.5214</td>
</tr>
<tr>
<td align="right">7</td>
<td align="right">93419785</td>
<td align="right">300330.XSHE</td>
<td align="right">2023-02-08</td>
<td align="right">-60.6560</td>
<td align="right">NaN</td>
<td align="right">2.5263</td>
<td align="right">3.3798</td>
<td align="right">142.6931</td>
<td align="right">16991.8555</td>
<td align="right">9.2096</td>
<td align="right">16795.4570</td>
<td align="right">9.1031</td>
<td align="right">2023-02-08</td>
<td>90.5919</td>
</tr>
<tr>
<td align="right">8</td>
<td align="right">93421460</td>
<td align="right">300309.XSHE</td>
<td align="right">2023-02-08</td>
<td align="right">-1.1453</td>
<td align="right">19.4870</td>
<td align="right">-0.7860</td>
<td align="right">14.7440</td>
<td align="right">-1337.5052</td>
<td align="right">88612.3750</td>
<td align="right">9.2157</td>
<td align="right">83741.6719</td>
<td align="right">8.7091</td>
<td align="right">2023-02-08</td>
<td>-0.9002</td>
</tr>
<tr>
<td align="right">9</td>
<td align="right">93421590</td>
<td align="right">002569.XSHE</td>
<td align="right">2023-02-08</td>
<td align="right">-11.7480</td>
<td align="right">0.3012</td>
<td align="right">5.3259</td>
<td align="right">5.0566</td>
<td align="right">41.5131</td>
<td align="right">14401.0000</td>
<td align="right">9.4903</td>
<td align="right">13967.5352</td>
<td align="right">9.2046</td>
<td align="right">2023-02-08</td>
<td>29.1500</td>
</tr>
</tbody></table>
<p>可以看到市值的从小到大排列的</p>
<p><img src="3f21926604474d702db5efe2c9154cb1.png" alt="3f21926604474d702db5efe2c9154cb1"></p>
<h3 id="7-3-调整与改进"><a href="#7-3-调整与改进" class="headerlink" title="7.3 调整与改进"></a>7.3 调整与改进</h3><ul>
<li><p>至此这已经是一个完整可运行的策略了，你可以试试看，回测结果应该已经可以一定程度上验证灵感了。不过虽然策略完成，我们却发现现在策略是<strong>每天</strong>进行一次选股并交易，我们觉得这太频繁了，希望能实现通过一个变量period控制操作的周期，即每period天进行一次选股并交易。</p>
</li>
<li><p>依然建议先试着自己做下，提示如下，提示之后是参考代码。</p>
<ul>
<li>像stocksnum那样用全局变量的方式<strong>建立period变量</strong></li>
<li>用一个变量记录策略运行天数</li>
<li>用取余运算配合if判断语句判断是否又经过period天</li>
</ul>
</li>
<li><p>参考代码</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    run_daily(period,time=<span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    <span class="comment"># 设定好要交易的股票数量</span></span><br><span class="line">    g.stocksnum = <span class="number">7</span></span><br><span class="line">    <span class="comment"># 设定交易周期</span></span><br><span class="line">    g.period = <span class="number">13</span></span><br><span class="line">    <span class="comment"># 记录策略进行天数，一开始为0，即还没有运行</span></span><br><span class="line">    g.days = <span class="number">0</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">period</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 判断策略进行天数是否能被轮动频率整除余1，一开始因为g.days为0必然这个式子为0，从而进行交易，之后g.day为1，2，3.....12时式子均不为0，所以不进行交易，直到g.day为13再次进行交易，以此类推，所以交易的周期为13天，即每隔13天才交易一次</span></span><br><span class="line">    <span class="keyword">if</span> g.days % g.period == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 代码：找出市值排名最小的前stocksnum只股票作为要买入的股票</span></span><br><span class="line">    <span class="comment"># 获取当天的股票列表</span></span><br><span class="line">    scu = get_all_securities(date= context.current_dt).index.tolist()</span><br><span class="line">        <span class="comment"># 选出在scu内的市值排名最小的前stocksnum只股票</span></span><br><span class="line">        q=query(valuation.code</span><br><span class="line">                    ).<span class="built_in">filter</span>(</span><br><span class="line">                        valuation.code.in_(scu)</span><br><span class="line">                    ).order_by( </span><br><span class="line">                        valuation.market_cap.asc()</span><br><span class="line">                    ).limit(g.stocksnum)</span><br><span class="line">        df = get_fundamentals(q)</span><br><span class="line">        <span class="comment"># 选取股票代码并转为list</span></span><br><span class="line">        buylist=<span class="built_in">list</span>(df[<span class="string">&#x27;code&#x27;</span>])</span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 代码：若已持有的股票的市值已经不够小而不在要买入的股票中，则卖出这些股票。</span></span><br><span class="line">        <span class="comment"># 对于每个当下持有的股票进行判断：现在是否已经不在buylist里，如果是则卖出</span></span><br><span class="line">        <span class="keyword">for</span> stock <span class="keyword">in</span> context.portfolio.positions:</span><br><span class="line">            <span class="keyword">if</span> stock <span class="keyword">not</span> <span class="keyword">in</span> buylist: <span class="comment">#如果stock不在buylist</span></span><br><span class="line">                order_target(stock, <span class="number">0</span>) <span class="comment">#调整stock的持仓为0，即卖出</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 代码：买入要买入的股票，买入金额为可用资金的stocksnum分之一</span></span><br><span class="line">        <span class="comment"># 将资金分成g.stocksnum份</span></span><br><span class="line">        position_per_stk = context.portfolio.cash/g.stocksnum</span><br><span class="line">        <span class="comment"># 用position_per_stk大小的g.stocksnum份资金去买buylist中的股票</span></span><br><span class="line">        <span class="keyword">for</span> stock <span class="keyword">in</span> buylist:</span><br><span class="line">            order_value(stock, position_per_stk)</span><br><span class="line">    <span class="comment"># 策略进行天数增加1        </span></span><br><span class="line">    g.days = g.days + <span class="number">1</span> </span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="7-4-回测结果"><a href="#7-4-回测结果" class="headerlink" title="7.4 回测结果"></a>7.4 回测结果</h3><ul>
<li>策略初步写完，把g.period设为13，g.stocksnum设为7，初始资金设为100000，频率为天，回测起止日期为20150101-20180627，然后进行回测，回测结果如下：<br><img src="555555555555555da.png" alt="555555555555555da"></li>
<li>可见15年到16年该策略表现貌似不错，但随后17年至今则表现平平。</li>
</ul>
<h1 id="8-策略评价与建立模拟"><a href="#8-策略评价与建立模拟" class="headerlink" title="8. 策略评价与建立模拟"></a>8. 策略评价与建立模拟</h1><hr>
<ul>
<li>在学习了如何编写策略后，我们将介绍下评价策略回测的指标，如何建立模拟交易，以及除回测之外还有哪些需要关注的方面。</li>
</ul>
<h3 id="8-1-策略回测指标"><a href="#8-1-策略回测指标" class="headerlink" title="8.1 策略回测指标"></a>8.1 策略回测指标</h3><ul>
<li>如下图，一个策略回测后会给出一些指标，可以在<a target="_blank" rel="noopener" href="https://joinquant.com/help/api/help?name=api#%E9%A3%8E%E9%99%A9%E6%8C%87%E6%A0%87">API文档：风险指标</a>查看这些指标的公式及基本说明。下文将补充介绍下几个重要指标。<br><img src="6666666666666666c9b984163.png" alt="6666666666666666c9b984163"></li>
<li>策略收益。这是最基础的指标，衡量回测期间策略收益率的，与时间长短相关。</li>
<li>基准收益。基准默认是沪深300指数，所以此指标是回测期间基准收益率的。一般来说，基准收益代表市场整体的收益情况，所以如果策略收益长期低于基准收益，往往意味着策略是失败的。通过set_benchmark()这个API可以自定义基准。</li>
<li><strong>年化收益率</strong>。年化收益率是一个衡量策略盈利能力的重要指标，<strong>越大越好</strong>。刚刚讲的策略收益这个指标是和回测时间长短强相关的，比如一个普通策略运行10年肯定比优秀的策略跑半年策略收益高，但这样就不利于比较策略的盈利能力。因此，通过数学方法，把策略收益统一互相化归为<strong>一年</strong>时间的收益率，比如10年的变为平均每年的收益率，半年的变为以这半年盈利能力运行一年的收益率，如此一来，让策略盈利能力在比较时有了一个大致等同的时间标准。</li>
<li><strong>最大回撤率</strong>。最大回撤率是一个衡量<strong>策略风险</strong>的重要指标，<strong>越小越好</strong>。新手初见这个指标的时候可能会感到一点点的困难，其实这个指标是对应着一个很自然的想法的，比如，你现在要实盘用真钱去跟一个策略操作，而你现在是知道这个策略的过去一段时间的历史收益曲线的，你觉得你的最大亏损率估计是多少？建议读者自己随手画下几条曲线当做历史收益曲线，思考下这个问题。一个经典的回答就是最大回撤率的含义，它的思路是这样的，既然我们还在拿历史数据做回测，说明我们应当还是相信历史对未来有指导意义的，那么我现在实盘用真钱去跟策略操作，接下来我们假设策略收益的未来走势应当是跟历史走势相当的，历史走势有一直涨的时候，也有一直跌的时候，那么我实盘跟策略最大亏损率应该就是，我刚开始跟策略就开始走的跟历史走势中一直跌的那一段那样，而且是一直跌且跌的最多的那段，那么历史走势中一直跌且跌的最多的那段跌跌了多少呢？用人眼一般很容易找到是哪段，而且聚宽的回测图中也标出了，如下图。不过不妨进一步思考下怎么算出最大回撤率，然后看下文档中的公式说明，看你的结果是否正确。当然，初学者知道最大回撤率越小越好可能就够了，但有志者应该借机学习如何思考如何评估风险以及量化风险，因为难度相对不高。<br><img src="77777777777777777755e43b.png" alt="77777777777777777755e43b"></li>
<li><strong>交易次数</strong>。交易次数其实是一个可以初步衡量策略回测结果是否可靠的指标，过少往往意味着回测结果不可靠。试想这样一种情况，别人给你推荐一个策略，策略进行了10年历史数据的回测，年化收益非常高，最大回撤非常小，你很高兴，但仔细一看，交易次数只有2次，此时，你愿意用真金白银去使用这个策略吗？你难免会想可能只是这2次操作运气好而已，这样的回测结果虽好但是不可信不可靠。其实这基于一个简单统计学思想，样本过少，则统计结果不可靠，所以足够多的交易次数才能让回测结果有说服力。目前，回测结果中不能直接看到交易次数了，可以通过回测结果页面的其他指标中的盈利次数与亏损次数相加得到，也可以通过回测结果图表下面的每日买卖大致看出，位置如下图。<br><img src="88888888888888888888252a3.png" alt="88888888888888888888252a3"></li>
<li>Alpha（阿尔法）与Beta（贝塔）。在资本资产定价模型（CAPM）中，投资组合的收益被分为和市场系统风险相关与和市场系统风险无关的两部分，而Beta与Alpha这两个希腊字母则是该模型中的两个重要系数，分别代表这相关部分与无关部分。其实策略持有的股票可以看成一个投资组合，基准收益作为市场系统收益，Beta则是代表相关部分的策略收益相对市场波动的倍率，如Beta为2则代表市场涨1%，相关部分的策略收益波动涨大概2%（统计意义上并非实时精确），beta为负数代表与市场反向变动。而Alpha则代表<strong>独立于市场波动不受其影响的无关部分的策略收益，越大越好</strong>，<strong>所以如果策略年化收益为负但Alpha为正而且很大，说明策略有超过市场的盈利能力，不过策略整体盈利被与市场相关部分拉下来了</strong>（策略和牛逼，大盘很拉）。为了便于理解，Alpha与Beta的含义讲的很粗暴，建议数理基础不错的有志者有空去自学下Alpha与Beta的构造思路与过程。</li>
<li>夏普比率（Sharpe Ratio）。代表所承担的单位风险所带来的收益，<strong>越大越好</strong>。夏普比率是在资本资产定价模型进一步发展得来的，不展开讲。</li>
</ul>
<h3 id="8-2-建立模拟交易"><a href="#8-2-建立模拟交易" class="headerlink" title="8.2 建立模拟交易"></a>8.2 建立模拟交易</h3><ul>
<li>之前讲过回测是用历史数据模拟执行策略，模拟交易是用未来的实际行情模拟执行策略，因此当策略完善的自以为差不多没什么问题时，建议建立一个模拟交易观察一段时间，当作进一步的检验。建立的模拟交易的方法很简单，点击回测结果界面，如下图，右上部红色模拟交易按钮，即可新建模拟交易。<br><img src="9999999999999999999999990c5f.png" alt="9999999999999999999999990c5f"></li>
<li>建立模拟交易成功后，点击聚宽导航栏我的交易，可以看到创建的模拟交易，如下图。<br><img src="1010011001001a1.png" alt="1010011001001a1"></li>
<li>点击右边的微信通知开关，将OFF调到ON，按照指示扫描二维码，绑定微信，就能微信接收交易信号了。当策略买卖操作，微信会收到信号提醒类似下图。自定义消息内容请看<a target="_blank" rel="noopener" href="https://joinquant.com/help/api/help?name=api_old#%E5%8F%91%E9%80%81%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B6%88%E6%81%AF%E2%99%A0">API send_message</a>。<br><img src="23a814dafcae7fa46e55834b0dc0df4c.png" alt="23a814dafcae7fa46e55834b0dc0df4c"></li>
</ul>
<h3 id="8-3-未来函数"><a href="#8-3-未来函数" class="headerlink" title="8.3 未来函数"></a>8.3 未来函数</h3><ul>
<li>未来函数的前文讲过，即指策略利用了历史当时无法得到的信息，造成回测结果极大失真。未来函数排查方法一般是人工查看，<strong>重点看一切跟时间有关的地方</strong>，尤其注意各个API关于时间的默认处理方法。当然有时未来函数隐藏的很隐蔽，而更好但稍花时间的方法是用策略建立模拟交易，一般让模拟交易运行几天，多数未来函数问题都能被发现，因为模拟交易是不可能引入未来数据的，所以往往引入未来函数的策略无法成功运行模拟交易。</li>
<li><strong>需要注意的是有时同一个代码的策略在模拟交易中是没有引入未来函数的，而是在历史回测中引入未来函数</strong>。此时会发现历史回测结果很好，模拟交易也能正常运行，但回测结果是失真的，而模拟交易运行时间长了往往也与回测相去甚远。一个具体的情况是，策略无意中引入了未来信息，导致策略选的股票过去一年中涨的最好的股票买，那么当然用过去一年做回测时效果会很好，但在模拟交易中可能就效果很差。</li>
<li>一条判断策略引入未来函数的经验法则是，<strong>当你发现策略回测收益极高，回撤又极低，而且各个时间段表现都特别好，感觉自己发现了自动印钞机式的交易策略时，则此策略大概率是引入未来函数了：）</strong></li>
</ul>
<h3 id="8-4-运行过慢"><a href="#8-4-运行过慢" class="headerlink" title="8.4 运行过慢"></a>8.4 运行过慢</h3><ul>
<li>策略的运行效率也是需要关注的问题，尽管新手几乎不会遇到，但需要简单了解下，有个意识。有时策略比较复杂，计算量会很大，极端时可能会造成交易延迟，延误买股票的时机，<strong>分钟级策略尤其需要关注下耗时问题</strong>，而相关函数就是<a target="_blank" rel="noopener" href="https://www.joinquant.com/help/api/help?name=api_old#%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E2%99%A0">enable_profile() API文档-性能分析</a></li>
<li>用法就是把enable_profile()这行代码复制粘贴放到策略代码的第一行。然后你成功回测后可以在回测详情页面查看性能分析的结果，如下图，从而可以查看哪行代码耗时比较多，从而有目的性的去改进。<br><img src="402a4a1f3e7773fd22c133d5caea57ba.png" alt="402a4a1f3e7773fd22c133d5caea57ba"></li>
</ul>
<h3 id="8-5-过拟合"><a href="#8-5-过拟合" class="headerlink" title="8.5 过拟合"></a>8.5 过拟合</h3><ul>
<li>过拟合（overfitting）常用于描述这样的情况。策略一般都有一些参数，如持股数量、交易频率等，选择不同的参数，固定的一份历史数据下，策略的回测结果好坏也不同，人们往往会选回测结果最好的参数作为策略的参数使用，但随后若换了一份历史数据（换一个时间段）做回测或随后用现实数据运行模拟或实盘，发现效果远不如之前的回测结果，此时很可能策略的参数过拟合了，或说之前选回测结果最好的参数这一行为使参数过拟合了。<strong>当参数多的时候，更容易发生。</strong></li>
<li>过拟合的核心思想是，过度细致的解读样本数据，从而没有认识到本质的规律，从而使策略或系统失去了普适性，对原样本数据表现极其优异，但对非原样本数据外情况的有效性大大降低。</li>
<li>一个关于帮助理解过拟合的比喻是，老师拿一个试卷（样本数据）考学生（策略），学生成绩不理想，老师要教学生（调整参数），此时老师不是教学生学科原理，而是教学生背试卷的答案（过度拟合），当然结果会导致，当再考同一个试卷时学生肯定表现极度优异，但因为只背了答案而没理解原理，所以当换套题目或应用时学生就表现极差了。</li>
<li>因此在选择并优化策略的参数时，要考虑参数的<strong>鲁棒性</strong>，即<strong>策略好坏对参数变化的敏感性</strong>。对于参数优化与选择对应有复杂最优化理论与鲁棒性测试，对初学者在此问题建议是，控制参数数量，多测几组参数大致看下参数变化对策略的影响，另外考虑进行样本外测试，即用一份样本数据回测挑选参数，用另一份样本数据回测看选择的参数在样本外情况下表现如何。</li>
</ul>
<h3 id="8-6-策略失效"><a href="#8-6-策略失效" class="headerlink" title="8.6 策略失效"></a>8.6 策略失效</h3><ul>
<li>策略一般是有时效的。当你的策略十分完善，并且模拟效果理想，实盘效果也很理想，不要以为策略就会像印钞机一样一直赚钱，<strong>策略可以失效的</strong>，比如当策略运行中出现历史上罕见的情形时往往就要警惕了，比如最大回撤创历史新高，策略收益率不再增加甚至减少等。如何判断策略是否失效以及找出失效的原因并无通法，但策略失效的原因可能有以下几种，可供参考。</li>
<li><strong>策略生效的逻辑基础不再成立</strong>。比如策略的有效性是建立在涨跌停制度下的、或是建立在某行业不断成长前提下的、或是建立在全球某资源持续稀缺前提下的等，当这些制度或前提不再成立，如制度调整、新政发布、科技进步等，那么策略自然也就失效了。因此，理解策略有效的逻辑是十分重要的。(退市规则的变化导致在2017年呼风唤雨的小市值策略面临失效的风险)</li>
<li><strong>操作资金量过大</strong>。更大的操作资金，会导致更大的冲击成本，即使买入时价更高、卖出时价更低，而当操作资金过大使市场流动性不足承载时，冲击成本会极大的变高，大大降低利润，甚至导致亏损。所以策略是有资金容量的，建议逐步增大策略操作资金量。</li>
<li><strong>市场上运行的相似策略过多</strong>。同类相似的策略都想赚市场上的同一份钱，然而这份钱是有限的，所以这些策略彼此间会竞争，导致策略赚钱变难，甚至完全失效赚不到钱。具体的表现可能是要买的股票买不到、想卖的股票卖不到理想价位等。因此，<strong>交易行业是非常注意保密且不适合分享的行业，而有志者则要注重培养自学能力。</strong></li>
<li><strong>市场出现了寄生策略</strong>。当你的策略被发现市场中的有心人发现并足够程度的监测时，他可以写出一个针对你策略的策略，从而寄生在你的策略上，比如在比你买之前买入，在你买后拉升股价后卖。这种针对你策略的寄生策略，往往会压缩你策略的盈利空间，使策略失效。</li>
</ul>
<h3 id="8-7-收益与风险的取舍"><a href="#8-7-收益与风险的取舍" class="headerlink" title="8.7 收益与风险的取舍"></a>8.7 收益与风险的取舍</h3><ul>
<li>往往策略的收益能力与抗风险能力是互相制约不能兼顾的，两者之间如何取舍建议是，<strong>达到基本的收益能力后，极力追求低风险</strong>，<strong>理由是盈利水平往往可以通过增加资金量来提高</strong>。具体的讲就是，策略a是一个年化收益率300%，最大回撤率50%的策略，策略b是一个年化收益率30%，最大回撤率5%的策略，只要给策略b提供相当于策略a的10倍的资金量，两者盈利能力就是一样的，但很难让策略a有像策略b一样的抗风险能力。</li>
</ul>
<h1 id="9-通过聚宽因子看板快速筛选因子"><a href="#9-通过聚宽因子看板快速筛选因子" class="headerlink" title="9. 通过聚宽因子看板快速筛选因子"></a>9. 通过聚宽因子看板快速筛选因子</h1><p>进入因子看板，首先选择如图所示的条件下的因子</p>
<p><img src="Snipaste_2023-03-13_15-29-07.png" alt="Snipaste_2023-03-13_15-29-07"></p>
<p>解释信息：|IC|≥0.05时选股能力较强，IR&gt;0.5时因子的稳定性较强</p>
<p>我们在沪深300，中证500，中证1000的基础科目衍生类因子都找不到|IC|≥0.05的因子</p>
<p>我们接着选择其他类别的因子，如质量类因子，若找到了|IC|≥0.05的因子，再看IR值，如果也满足IR＞0.5，则选择为备选因子。</p>
<p>我们发现找了一圈也没有找到有效的因子，我们把周期换为近三年，因为很难存在长期有效的因子。接着找风险因子-风格因子</p>
<p><img src="Snipaste_2023-03-13_16-34-12.png" alt="Snipaste_2023-03-13_16-34-12"></p>
<p>上图可以看到一个因子叫“残差波动因子”IC均值为-0.061，IR值为-0.469，比较符合要求，点看细看：</p>
<p><img src="Snipaste_2023-03-13_16-38-37.png" alt="Snipaste_2023-03-13_16-38-37"></p>
<p>可以看到，该因子在2015年年中收益率很高，但其最大分位数是明显的反向指标，所以不予考虑。</p>
<p><img src="Snipaste_2023-03-13_16-48-26.png" alt="Snipaste_2023-03-13_16-48-26"></p>
<p>在情绪类因子中我们可以看到5日平均换手率、换手率相对波动率、6日成交金额的标准差是<strong>严格满足</strong>|IC|≥0.05且IR＞0.5的，点看细看：</p>
<p><img src="Snipaste_2023-03-13_17-14-49.png" alt="Snipaste_2023-03-13_17-14-49"></p>
<p>可以看到，近20年，他的最大分位数和最小分位数都没有跑赢指数（不论在沪深300还是中证全指都是这样）</p>
<p>再看5日平均换手率因子：</p>
<p><img src="Snipaste_2023-03-13_17-19-21.png" alt="Snipaste_2023-03-13_17-19-21"></p>
<p>可以看到其最小分位数在某些时刻是跑赢大盘的（即买入换手率因子比较低的股票可以在一段时间跑赢大盘），即逆向投资（这些因子值比较小的时候买入）</p>
<p>接着看技术类指标（没有提及到的指标就是不符合要求的）：</p>
<p><img src="Snipaste_2023-03-13_17-24-50.png" alt="Snipaste_2023-03-13_17-24-50"></p>
<p>可以看到布林线指标符合要求，但细看之后近10年是<strong>明显跑输指数的</strong>，略过。</p>
<h1 id="成长指路"><a href="#成长指路" class="headerlink" title=". 成长指路"></a>. 成长指路</h1><hr>
<ul>
<li>基础知识基本讲完了，本教程也要完结了，最后一篇讲下接下来的学习方向，仅供参考。</li>
</ul>
<h3 id="9-1-自学意识"><a href="#9-1-自学意识" class="headerlink" title="9.1 自学意识"></a>9.1 自学意识</h3><ul>
<li>量化交易是不适合分享的行业，自学必不可少。或奇货可居，或敝帚自珍，有价值的内容很难会被公之于众，所以不要幻想会有特别有价值的系统的学习资源等着你去学，或是指望能把别人公开的东西直接搬来就能赚到钱。诚然，会有幸运的时候，但还是不要指望幸运，那没前途的，绝大多数情况都是大浪淘金式的在各种资讯中寻找着思索着只言片语。因此，自学是一个极其重要的能力，有志者需要对它像量化交易本身一样去重视。</li>
</ul>
<h3 id="9-2-之后去学什么？"><a href="#9-2-之后去学什么？" class="headerlink" title="9.2 之后去学什么？"></a>9.2 之后去学什么？</h3><ul>
<li>首先要自问，之前讲过的内容是否都学会了，比如每篇后的自测与自学内容是否都能回答，当时学的时候不理解的地方现在是否理解等。如果明显感觉一路囫囵吞枣强行跟过来的，不妨回头再看看，再动手练练。当然，也不必太完美主义，毕竟有的坑看着不大但是真的深，不妨暂且搁下。</li>
<li>所以如果感觉学得还可以，就可以先到聚宽的量化课堂去学习下，普遍有讲解有代码，其中重点推荐以下文章。<ul>
<li><a target="_blank" rel="noopener" href="https://www.joinquant.com/post/1398">双均线策略</a></li>
<li><a target="_blank" rel="noopener" href="https://www.joinquant.com/post/1957">彼得·林奇的成功投资</a></li>
<li><a target="_blank" rel="noopener" href="https://joinquant.com/post/1668">Fama-French三因子火锅</a></li>
<li><a target="_blank" rel="noopener" href="https://www.joinquant.com/post/1311">凯利公式，你用对了吗？</a></li>
</ul>
</li>
<li>请尽你所能去读懂这四个文章，你可能会感受到来自数学、编程、金融等方面的知识的不足，可能会感到有之前我没讲过的内容，可能需要你去搜索、去阅读、去询问，可能你会感觉很难搜、很难读、很少有答复，这一切将是刚离开新手村的你将遇到的各种挑战的第一个，而且其实是相对简单的一个，所以哪怕可能会花不少时间，请尽你所能去读懂这四个文章。</li>
<li>当你读懂这四个文章时，你应该可以算是基础入门了，之后就要靠你个人修行了。一个基本的模式是，有一个灵感，然后去研究与实现，在过程中学习新知识，战胜新挑战，最后或成或败都获得新的认识，继续下一个灵感，从而不断前进。当然，你在前进，你渴望的答案可能也在动，就像市场一样不断变动，或向你走来，或离你远去。（题外话：你认为世界是静止的还是运动的，或者说随机是否存在）</li>
<li>特别提下，本教程教的编程知识是非常精简的，所以建议适当简单浏览下python系统的知识，做到以后见到、或想用了知道怎么找即可。<strong>集合、元组、列表生成式</strong>这三个推荐去重点学下，这三个相对常用但看见不懂想搜索可能都想不出关键词。编程参考资料可以看下<a target="_blank" rel="noopener" href="https://joinquant.com/post/10760">这里</a>。</li>
</ul>
<h3 id="9-3-灵感的来源"><a href="#9-3-灵感的来源" class="headerlink" title="9.3 灵感的来源"></a>9.3 灵感的来源</h3><ul>
<li>灵感的最重要来源当然是阅读，本人水平太低就不做具体推荐了，以下列举一些可能的内容来源类别。<ul>
<li>论文</li>
<li>研报</li>
<li>聚宽的量化课堂与社区</li>
<li>知乎量化交易话题下的回答</li>
<li>宽客的博客（多数是国外的）</li>
<li>各类书籍</li>
</ul>
</li>
<li>关于书籍，除了专门讲量化交易的书，稍稍关注些其他领域可能带来全新的视角，比如财务分析、行为金融、数学、统计学、机器学习、甚至心理学、物理学等，据说美国做量化交易还有用到语音识别的。</li>
<li>学习时，建议用批判的眼光去看，保持自身独立思考，警惕盲从。还是那句话，量化交易行业很难有特别有价值的东西出现在大众眼前的。</li>
<li>除了阅读外，直接参与实际市场也是另一种重要的灵感来源，毕竟多数的阅读资源本身的灵感来自市场的，比如市场交易时，市场对时下新闻的反应、对量价走势的瞬时反应、不同股票或人群的反应、你自己的反应等等，你自己不亲身投入这场波云诡谲之中，很难指望事后体会到其中的种种，而这些可能带给你许多灵感。比如比较知名的冰山算法与不少技术指标当时的发明就离不开发明者对市场的了解。</li>
</ul>
<h3 id="9-4-关于职业化"><a href="#9-4-关于职业化" class="headerlink" title="9.4 关于职业化"></a>9.4 关于职业化</h3><ul>
<li>想要入职量化行业，学历门槛往往较高，但别怕，学历不够的有志者不要被吓倒，毕竟人家也不是真要你的毕业证，无非是希望你能知识储量够基础好，学习新东西快有潜力，学历门槛高只是提效手段，你只要向他们证明你同样用相当的能力即可。你应该被录取的理由是什么？怎么把这个理由告诉他们？回答这个问题比量化交易简单，<strong>至少有一个好策略了想入职带他们赚钱</strong>，他们总不会还嫌你学历不够吧，当然，这是一个不必要的界，比如若你有相当的策略实现能力或因子发掘能力可能也可以了，所以建议你结合实际情况认真负责的想想，然后真的去试几次。</li>
<li>那做独立的职业量化交易可不可以呢，也是可以的，很多量化交易团队就几个人，甚至一个人的也有，但毕竟人多效率高不少。 实际上，多数还是从原本公司独立出来的，学生毕业阶段就转独立的职业做量化交易还是少，现金流压力可能比较大，但也是有做的好，后来成立公司的。</li>
<li>聚宽也有能帮助展示策略、证明自身、快速职业化与变现的栏目，而且也会有行业内人士来聚宽，找好策略与人才，比如策略被看中要谈买断、发的文章不错被录取等。注意，保护自己的成果不被无良人士窃取。总之，量化行业是相对公平看中实力的，金子总会发光。</li>
</ul>
<h3 id="完"><a href="#完" class="headerlink" title="完"></a>完</h3>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">因子投资</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/量化交易//" class="article-tag-list-link color5">量化交易</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/07/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E6%95%99%E7%A8%8B%EF%BC%88%E5%9F%BA%E4%BA%8E%E8%81%9A%E5%AE%BD%E5%B9%B3%E5%8F%B0%EF%BC%89/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-关于ChatGPT最优对话语言模型的介绍与感悟" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/05/%E5%85%B3%E4%BA%8EChatGPT%E6%9C%80%E4%BC%98%E5%AF%B9%E8%AF%9D%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%84%9F%E6%82%9F/">关于ChatGPT最优对话语言模型的理解与感悟</a>
    </h1>
  

        
        <a href="/2023/02/05/%E5%85%B3%E4%BA%8EChatGPT%E6%9C%80%E4%BC%98%E5%AF%B9%E8%AF%9D%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%84%9F%E6%82%9F/" class="archive-article-date">
  	<time datetime="2023-02-05T10:30:47.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p><strong>ChatGPT：Optimizing Language Models for Dialogue</strong></p>
<p><strong>ChatGPT的诞生不亚于2016年阿尔法狗战胜李世石对世界的冲击和影响，可以说是一个历史拐点。在过去几年里，深度学习达到瓶颈，CV和NLP形成红海，但是ChatGPT的诞生仿佛又形成了新的AI泡沫，而这个泡沫就如同2016年的阿尔法狗那样，规模之大，影响之大，技术革新之猛烈令人兴奋。目前，微软收购OpenAI，全线产品搭载chatgpt，包括其未来十年发展的重点Azure云服务业务；谷歌豪投三亿美元参战all in阻击gpt；百度据说也即将入坑……而伴随着这一切的背后却是硅谷大裁员和国内互联网公司的低潮期，也许这正是黎明前的黑暗。不可否认的是，由chatgpt所引领的新的时代已经到来了，即将深刻影响投资领域和自然语言处理领域，甚至可能影响数字化转型和云原生的进程。</strong></p>
<p><strong>这种资本的狂欢仿佛让我们看到了当年阿尔法狗热潮下带动的各种人工智能企业的诞生，那时候用概念就能融资并且上市。2015-2020这六年是人工智能的第一次商业浪潮期，只不过受到疫情和经济大萧条影响泡沫破得很快，但也想不到新的泡沫形成的也很快。chatgpt和元宇宙炒冷饭不一样，它很可能会催生并且已经催生新的一轮AI浪潮，而这个浪潮也许只是强人工智能的序幕而已。</strong></p>
</blockquote>
<h1 id="1-预训练语言模型"><a href="#1-预训练语言模型" class="headerlink" title="1. 预训练语言模型"></a>1. 预训练语言模型</h1><p>在自然语言处理领域，直到2018年，一些任务的人类基准才被突破。这一年，<strong>预训练语言模型</strong>诞生了，尽量在2018年之前，自然语言处理的技术包括多任务学习、词嵌入、神经网络模型、Attention等也在迅猛发展，但是相比于深度学习和计算机视觉领域而言，NLP仿佛一直停留在“人工智障”的阶段。也有一些偏激的观点认为，在2018年之前，NLP领域毫无实质性的建树。</p>
<p>NLP领域的突破之所以来得较晚，一个很重要的原因是NLP任务繁多，每一类任务所使用的训练数据和模型不尽相同。在监督学习场景下，每一类NLP任务都需要设计一个特定的模型，并且需要大量的<strong>标注数据</strong>。不同于图片标注，NLP标注任务的难度通常较高，因此，<strong>缺乏大规模标注数据</strong>一直是困扰自然语言处理研究领域的一大难题。</p>
<p>而<strong>预训练语言模型</strong>（Pre-trained Language Model），就是通过对这些<strong>无标签</strong>的数据进行“预训练”，获得一个比较好的语言表示，再将其应用到特定的NLP下游任务中。</p>
<p>随着预训练语言模型的提出，自然语言处理领域也有了突飞猛进的发展。<strong>预训练语言模型的训练方法是，先在大规模文本中训练出通用的语言表示，再用微调（Fine Tune）的方法进行下游任务的领域适应。绝大多数的自然语言处理任务都可以用这种范式取得良好的效果。</strong></p>
<p>2013年，word2vec开启了自然语言预训练的序章。随后，Attention的出现使得模型可以关注更重要的信息，之后的几年，基于上下文的动态词向量表示ELMo，以及使用Self-Attention机制的特征提取器Transformer的提出，将预训练语言模型的效果提升到了新的高度。随后，BERT、RoBERTa、XLNet、T5、ALBERT、GPT-3等模型，从自然语言理解及自然语言生成等角度，不断刷新NLP领域的SOTA（当前最优结果）表现。</p>
<p>预训练语言模型主要分为<strong>自回归</strong>和<strong>自编码</strong>两种不同的模型。自回归模型就是根据句子中前面的模型，预测下一个单词；而自编码模型，则是通过覆盖句中的单词，或者对句子做结构调整，让模型复原单词和次序，从而调节网格参数。ELMo、GPT系列和XLNet属于自回归模型，而BERT、ERINE、RoBERTa等属于自编码模型。</p>
<p>目前，预训练语言模型的通用范式是：</p>
<ol>
<li><strong>基于大规模文本，预训练得出通用的语言表示。</strong></li>
<li><strong>通过微调的方式，将学习到的知识传递到不同的下游任务中。</strong></li>
</ol>
<h1 id="2-BERT与GPT"><a href="#2-BERT与GPT" class="headerlink" title="2.BERT与GPT"></a>2.BERT与GPT</h1><p>由于不同的预训练语言模型的结构不同、优势不同，在实际应用中，需要根据具体的任务选择不同的模型。例如，BERT系列模型更适用于<strong>理解任务</strong>，而GPT（Generative Pre-Training，生成式预训练）系列模型更适用于<strong>生成任务</strong>。</p>
<p>GPT模型的思想是通过<strong>二段式</strong>的训练，以通用语言模型加微调训练的模式完成各项定制任务，即先通过大量无标签的文本训练通用的生成式语言模型，再根据具体的自然语言处理任务，利用标签数据做微调训练。对使用者来说，直接使用训练好的模型参数作为初始状态，用少量的标签数据进行微调，就可以得到<strong>针对特定领域与任务的高性能专用模型</strong>，不仅节省了训练成本，还大幅提高了模型的表现性能，这也是预训练语言模型的魅力所在。</p>
<p>目前大火的chatgpt聊天机器人模型即搭载了GPT-3模型。介绍GPT-3的论文长达72页，包括模型设计思路、理论推导、实验结果和实验设计等内容。GPT-3发展非常迅速，2022年该模型每天生成的词量是2021年的10倍。GPT-3的模型实在过于庞大，参数量达到<strong>1750亿</strong>，即使开源，也因为过大的模型和算力需求，无法作为个人使用的预训练语言模型进行部署。</p>
<p>BERT模型全称为Bidirectional Encoder Representations from Transformers(来自Transformers的双向编码器表示)，是近年来NLP领域公认的里程碑模型。其意义在于：从大量无标记数据集中训练得到的深度模型，可以<strong>显著</strong>提高各项NLP任务的准确率。事实上，BERT刷新了在自然语言推断、问答及命名实体识别任务等11项NLP任务上的表现。本文主要介绍chatgpt，所以关于BERT模型的详细介绍和应用会放在其他博文中介绍。</p>
<h1 id="3-OpenAI与ChatGPT"><a href="#3-OpenAI与ChatGPT" class="headerlink" title="3.OpenAI与ChatGPT"></a>3.OpenAI与ChatGPT</h1><p><img src="Snipaste_2023-02-05_20-27-35.png" alt="Snipaste_2023-02-05_20-27-35"></p>
<p>OpenAI是在美国成立的人工智能实验室，主要目标包括制造“通用”机器人和使用自然语言聊天的聊天机器人，老巢位于爱荷华州，微软投资的数据中心。2019年7月22日，微软投资OpenAI 10亿美元，双方将携手合作替Azure云端平台服务开发人工智能技术。2020年6月11日，OpenAI宣布了GPT-3语言模型，微软于2020年9月22日取得独家授权。</p>
<p>ChatGPT是由人工智能研究实验室OpenAI在2022年11月30日发布的全新聊天机器人模型，一款人工智能技术驱动的自然语言处理工具。它能够通过学习和理解人类的语言来进行对话，还能根据聊天的上下文进行互动，真正像人类一样来聊天交流，甚至能完成撰写邮件、视频脚本、文案、翻译、代码等任务。在OpenAI的官网上，ChatGPT被描述为优化对话的语言模型，是GPT-3.5架构的主力模型。</p>
<img src="Snipaste_2023-02-05_20-28-18.png" alt="Snipaste_2023-02-05_20-28-18" style="zoom: 25%;">

<p>2023年2月2日，微软官方公告表示，旗下所有产品将全线整合ChatGPT，除此前宣布的搜索引擎必应、Office外，微软还将在云计算平台Azure中整合ChatGPT，Azure的OpenAI服务将允许开发者访问AI模型。</p>
<h1 id="4-传统NLP的问题"><a href="#4-传统NLP的问题" class="headerlink" title="4.传统NLP的问题"></a>4.传统NLP的问题</h1><h2 id="4-1-偏见很大"><a href="#4-1-偏见很大" class="headerlink" title="4.1 偏见很大"></a>4.1 偏见很大</h2><p>比如在NLP语料分析中，“我购买了一台华为手机，我的心情是____”，NLP模型可能会回答“失落”，而对苹果手机结果就会相反。再比如“我看到了一个黑人，他可能是____”，NLP模型可能回答“杀人犯或者强奸犯”。这种模型在学习过程中会形成伦理和道德偏见。</p>
<h2 id="4-2-所问非所答"><a href="#4-2-所问非所答" class="headerlink" title="4.2 所问非所答"></a>4.2 所问非所答</h2><p>对于传统的聊天机器人而言，一个简单的问题可能会得到长篇大论的回答，并不符合使用者要求，可能仅仅是对相关语句中出现的词汇的解释。</p>
<h1 id="5-ChatGPT只是起点"><a href="#5-ChatGPT只是起点" class="headerlink" title="5.ChatGPT只是起点"></a>5.ChatGPT只是起点</h1><p>实际上，GPT只是冰山一角，2022年每4天就有一个大模型问世，可能谷歌和facebook背后还有更加出色的NLP预训练模型。不出所料，2022年2月3日，谷歌母公司Alphabet CEO桑达尔表示，谷歌将在“未来几周或几个月”推出类似ChatGPT、基于人工智能的大型语言模型。而微软继续加码预计将GPT-4整合到旗下搜索引擎必应中。值得一提的是，这种大模型对于个人来讲没有办法搭建，需要团队乃至资本的大量涌入，据说光训练一个GPT-3使用了10000个GPU，电费就花费了1200万美元。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">随笔</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/其他//" class="article-tag-list-link color3">其他</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/05/%E5%85%B3%E4%BA%8EChatGPT%E6%9C%80%E4%BC%98%E5%AF%B9%E8%AF%9D%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%84%9F%E6%82%9F/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-个人整理聚宽平台策略代码及回测结果" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/04/%E4%B8%AA%E4%BA%BA%E6%95%B4%E7%90%86%E8%81%9A%E5%AE%BD%E5%B9%B3%E5%8F%B0%E7%AD%96%E7%95%A5%E4%BB%A3%E7%A0%81%E5%8F%8A%E5%9B%9E%E6%B5%8B%E7%BB%93%E6%9E%9C/">个人整理聚宽平台策略代码及回测结果</a>
    </h1>
  

        
        <a href="/2023/02/04/%E4%B8%AA%E4%BA%BA%E6%95%B4%E7%90%86%E8%81%9A%E5%AE%BD%E5%B9%B3%E5%8F%B0%E7%AD%96%E7%95%A5%E4%BB%A3%E7%A0%81%E5%8F%8A%E5%9B%9E%E6%B5%8B%E7%BB%93%E6%9E%9C/" class="archive-article-date">
  	<time datetime="2023-02-04T10:23:31.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-04</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-线性回归"><a href="#1-线性回归" class="headerlink" title="1 线性回归"></a>1 线性回归</h1><h2 id="1-1-代码"><a href="#1-1-代码" class="headerlink" title="1.1 代码"></a>1.1 代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入函数库</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">import</span> jqdata</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个初始化的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">  <span class="comment"># 包括相关参数设置的函数</span></span><br><span class="line">  set_params()</span><br><span class="line">  <span class="comment"># 设置回测环境的函数</span></span><br><span class="line">  set_backtest()</span><br><span class="line">  <span class="comment"># 设置每日运行交易</span></span><br><span class="line">  run_daily(trade, <span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># 定义参数设置的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_params</span>():</span><br><span class="line">    <span class="comment"># 定义初始日期为0</span></span><br><span class="line">    g.days = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 每5天调仓一次</span></span><br><span class="line">    g.refresh_rate = <span class="number">5</span></span><br><span class="line">    <span class="comment"># 最大持股的个数为10个</span></span><br><span class="line">    g.stocknum = <span class="number">10</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 定义回测函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_backtest</span>():</span><br><span class="line">    <span class="comment"># 这里咱们跟大盘，也就是与上证指数来做对比</span></span><br><span class="line">    set_benchmark(<span class="string">&#x27;000001.XSHG&#x27;</span>)</span><br><span class="line">    <span class="comment"># 设置使用真实价格来进行交易</span></span><br><span class="line">    set_option(<span class="string">&#x27;use_real_price&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 设置日志记录订单和报错</span></span><br><span class="line">    log.set_level(<span class="string">&#x27;order&#x27;</span>, <span class="string">&#x27;error&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 接下来就是交易函数了</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">trade</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 如果天数能够被5整除</span></span><br><span class="line">    <span class="comment"># 就运行我们在研究环境中写好的代码</span></span><br><span class="line">    <span class="keyword">if</span> g.days % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 下面的代码是从研究环境中移植过来的</span></span><br><span class="line">        <span class="comment"># 去掉了画图和查看表头的部分</span></span><br><span class="line">        <span class="comment"># 此处不逐行注释了</span></span><br><span class="line">        <span class="comment">#这回咱们就把上证50成分股作为股票池</span></span><br><span class="line">        stocks = get_index_stocks(<span class="string">&#x27;000016.XSHG&#x27;</span>)</span><br><span class="line">        <span class="comment">#用query函数获取股票的代码</span></span><br><span class="line">        q = query(valuation.code,</span><br><span class="line">            <span class="comment">#还有市值</span></span><br><span class="line">            valuation.market_cap,</span><br><span class="line">            <span class="comment">#净资产，用总资产减去总负债</span></span><br><span class="line">            balance.total_assets - balance.total_liability,</span><br><span class="line">            <span class="comment">#再来一个资产负债率的倒数</span></span><br><span class="line">            balance.total_assets/balance.total_liability,</span><br><span class="line">            <span class="comment">#把净利润也考虑进来</span></span><br><span class="line">            income.net_profit,</span><br><span class="line">            <span class="comment">#还有年度收入增长</span></span><br><span class="line">            indicator.inc_revenue_year_on_year,</span><br><span class="line">            <span class="comment">#研发费用</span></span><br><span class="line">            balance.development_expenditure).<span class="built_in">filter</span>(valuation.code.in_(stocks))</span><br><span class="line">            <span class="comment">#将这些数据存入一个数据表中</span></span><br><span class="line">        df = get_fundamentals(q, date = <span class="literal">None</span>)</span><br><span class="line">        <span class="comment">#给数据表指定每列的列名称</span></span><br><span class="line">        df.columns = [<span class="string">&#x27;code&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;mcap&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;na&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;1/DA ratio&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;net income&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;growth&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;RD&#x27;</span>]</span><br><span class="line">        <span class="comment">#把股票代码做成数据表的index</span></span><br><span class="line">        df.index = df[<span class="string">&#x27;code&#x27;</span>].values</span><br><span class="line">        <span class="comment">#然后把原来代码这一列丢弃掉，防止它参与计算</span></span><br><span class="line">        df = df.drop(<span class="string">&#x27;code&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line">        df = df.fillna(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#把除去市值之外的数据作为特征，赋值给X</span></span><br><span class="line">        X = df.drop(<span class="string">&#x27;mcap&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#市值这一列作为目标值，赋值给y</span></span><br><span class="line">        y = df[<span class="string">&#x27;mcap&#x27;</span>]</span><br><span class="line">        <span class="comment">#用0来填补数据中的空值</span></span><br><span class="line">        X = X.fillna(<span class="number">0</span>)</span><br><span class="line">        y = y.fillna(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 下面是机器学习的部分</span></span><br><span class="line">        <span class="comment">#使用线性回归来拟合数据</span></span><br><span class="line">        reg = LinearRegression()</span><br><span class="line">        model = reg.fit(X, y)</span><br><span class="line">        <span class="comment">#将模型预测值存入数据表</span></span><br><span class="line">        predict = pd.DataFrame(reg.predict(X), </span><br><span class="line">                       <span class="comment">#保持和y相同的index，也就是股票的代码</span></span><br><span class="line">                       index = y.index,</span><br><span class="line">                       <span class="comment">#设置一个列名，这个根据你个人爱好就好</span></span><br><span class="line">                       columns = [<span class="string">&#x27;predict_mcap&#x27;</span>])</span><br><span class="line">        <span class="comment">#使用真实的市值，减去模型预测的市值</span></span><br><span class="line">        diff = df[<span class="string">&#x27;mcap&#x27;</span>] - predict[<span class="string">&#x27;predict_mcap&#x27;</span>]</span><br><span class="line">        <span class="comment">#将两者的差存入一个数据表，index还是用股票的代码</span></span><br><span class="line">        diff = pd.DataFrame(diff, index = y.index, columns = [<span class="string">&#x27;diff&#x27;</span>])</span><br><span class="line">        <span class="comment">#将该数据表中的值，按生序进行排列</span></span><br><span class="line">        diff = diff.sort_values(by = <span class="string">&#x27;diff&#x27;</span>, ascending = <span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 下面是执行订单的部分</span></span><br><span class="line">        <span class="comment"># 首先将把市值被低估最多的10只股票存入持仓列表</span></span><br><span class="line">        stockset = <span class="built_in">list</span>(diff.index[:<span class="number">10</span>])</span><br><span class="line">        <span class="comment"># 同时已经持有的股票，存入卖出的列表中</span></span><br><span class="line">        sell_list = <span class="built_in">list</span>(context.portfolio.positions.keys())</span><br><span class="line">        <span class="comment"># 如果某只股票在卖出列表</span></span><br><span class="line">        <span class="keyword">for</span> stock <span class="keyword">in</span> sell_list:</span><br><span class="line">            <span class="comment"># 同时又不在持仓列表中</span></span><br><span class="line">            <span class="keyword">if</span> stock <span class="keyword">not</span> <span class="keyword">in</span> stockset[:g.stocknum]:</span><br><span class="line">                <span class="comment"># 就把这只股票卖出</span></span><br><span class="line">                stock_sell = stock</span><br><span class="line">                <span class="comment"># 卖出后该股票的持仓量为0，也就是直接清仓</span></span><br><span class="line">                order_target_value(stock_sell, <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 如果持仓数量小于我们设置的最大持仓数</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(context.portfolio.positions) &lt; g.stocknum:</span><br><span class="line">            <span class="comment"># 我们就把剩余的现金，平均买入股票</span></span><br><span class="line">            <span class="comment"># 例如持仓8只股票，剩余3万元现金</span></span><br><span class="line">            <span class="comment"># 就买入2只列表中的股票，每只买入的金额上限为1.5万元</span></span><br><span class="line">            num = g.stocknum - <span class="built_in">len</span>(context.portfolio.positions)</span><br><span class="line">            cash = context.portfolio.cash/num</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cash = <span class="number">0</span></span><br><span class="line">            num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> stock <span class="keyword">in</span> stockset[:g.stocknum]:</span><br><span class="line">            <span class="keyword">if</span> stock <span class="keyword">in</span> sell_list:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                stock_buy = stock</span><br><span class="line">                order_target_value(stock_buy, cash)</span><br><span class="line">                num = num - <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 同时天数加1</span></span><br><span class="line">        g.days += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 如果天数不能被5整除</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 不执行交易，直接天数加1</span></span><br><span class="line">        g.days = g.days + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="1-2-回测详情"><a href="#1-2-回测详情" class="headerlink" title="1.2 回测详情"></a>1.2 回测详情</h2><p><img src="Snipaste_2023-02-04_18-28-07.png" alt="Snipaste_2023-02-04_18-28-07"></p>
<p><img src="Snipaste_2023-02-04_18-28-23.png" alt="Snipaste_2023-02-04_18-28-23"></p>
<h1 id="2-随机森林"><a href="#2-随机森林" class="headerlink" title="2 随机森林"></a>2 随机森林</h1><h2 id="2-1-代码"><a href="#2-1-代码" class="headerlink" title="2.1 代码"></a>2.1 代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">8.3.1 回测函数的初始化</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入需要用到的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor <span class="comment"># 随机森林回归</span></span><br><span class="line"><span class="keyword">import</span> jqdata     <span class="comment"># 聚宽平台是数据API</span></span><br><span class="line"><span class="keyword">from</span> jqlib.technical_analysis <span class="keyword">import</span> *    <span class="comment"># 技术指标分析工具</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 包括策略参数的设置</span></span><br><span class="line">    set_params()</span><br><span class="line">    <span class="comment"># 回测条件的设置</span></span><br><span class="line">    set_backtest()</span><br><span class="line">    <span class="comment"># 以及其他变量的设置</span></span><br><span class="line">    set_variables()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义参数设置的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_params</span>():</span><br><span class="line">    <span class="comment"># 首先是调仓频率的设置</span></span><br><span class="line">    g.tc = <span class="number">10</span></span><br><span class="line">    <span class="comment"># 然后是最大持股数的设置，这里设定最大持股个数为6个</span></span><br><span class="line">    g.stocknum = <span class="number">6</span></span><br><span class="line">    <span class="comment"># 设置初始的收益为-0.05</span></span><br><span class="line">    g.ret = -<span class="number">0.05</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义回测函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_backtest</span>():</span><br><span class="line">    <span class="comment"># 基准收益设置为上证指数</span></span><br><span class="line">    set_benchmark(<span class="string">&#x27;000001.XSHG&#x27;</span>)</span><br><span class="line">    <span class="comment"># 设置成交价格为真实价格</span></span><br><span class="line">    set_option(<span class="string">&#x27;use_real_price&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 设置日志记录订单和代码错误</span></span><br><span class="line">    log.set_level(<span class="string">&#x27;order&#x27;</span>, <span class="string">&#x27;error&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置其他变量</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_variables</span>():</span><br><span class="line">    <span class="comment"># 初始天数为0，每运行一天，天数加1</span></span><br><span class="line">    g.days = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 初始交易为False，即不进行交易</span></span><br><span class="line">    g.if_trade = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在这段代码中，我们把调仓频率、最大持股数、对比的基准收益等都设置好了。接下来，我们还可以</span></span><br><span class="line"><span class="string">对每笔交易的滑点和手续费进行设置</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">8.3.2 盘前的准备工作</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在每日开盘之前，我们要让程序做几件事情：首先，判断当日是否是调仓日；其次，设置好交易的滑点</span></span><br><span class="line"><span class="string">和手续费；最后，设置好股票池。要完成这些工作，就要定义新的函数</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数，设置开盘之前需要做的事情</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">before_trading_start</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 如果天数可以被调仓频率整除</span></span><br><span class="line">    <span class="keyword">if</span> g.days%g.tc==<span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 则交易状态变为True，即进行交易</span></span><br><span class="line">        g.if_trade=<span class="literal">True</span></span><br><span class="line">        <span class="comment"># 运行滑点和手续费的计算</span></span><br><span class="line">        set_slip_fee(context)</span><br><span class="line">        <span class="comment"># 股票池设置成沪深300成分股</span></span><br><span class="line">        g.stocks=get_index_stocks(<span class="string">&#x27;000300.XSHG&#x27;</span>)</span><br><span class="line">        <span class="comment"># 运行一个函数，在大的股票池中选择可用的股票</span></span><br><span class="line">        g.feasible_stocks = set_feasible_stocks(g.stocks, context)</span><br><span class="line">    <span class="comment"># 这些工作做完，天数加1</span></span><br><span class="line">    g.days+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在上面的代码中，我们指定before_trading_start函数自动判断是否要进行调仓，且运行交易滑点</span></span><br><span class="line"><span class="string">和手续费的计算set_slip_fee，同时指定运行et_feasible_stocks函数在沪深300成分股中选择可</span></span><br><span class="line"><span class="string">供交易的股票</span></span><br><span class="line"><span class="string">接下来，我们就需要定义et_feasible_stocks和set_slip_fee的具体内容了</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义遴选可交易股票的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_feasible_stocks</span>(<span class="params">initial_stocks, context</span>):</span><br><span class="line">    <span class="comment"># 先创建一个空列表</span></span><br><span class="line">    paused_info = []</span><br><span class="line">    <span class="comment"># 使用get_current_data函数获取数据</span></span><br><span class="line">    current_data = get_current_data()</span><br><span class="line">    <span class="comment"># 在沪深300成分股中遍历</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> initial_stocks:</span><br><span class="line">        <span class="comment"># 把是否停盘的信息添加到先前创建的空列表中</span></span><br><span class="line">        paused_info.append(current_data[i].paused)</span><br><span class="line">    <span class="comment"># 将是否停盘信息存入一个数据表</span></span><br><span class="line">    df_paused_info = pd.DataFrame(&#123;<span class="string">&#x27;paused_info&#x27;</span>:paused_info&#125;,index=initial_stocks)</span><br><span class="line">    <span class="comment"># 选出没有停盘的股票，存入股票列表</span></span><br><span class="line">    stock_list = <span class="built_in">list</span>(df_paused_info.index[df_paused_info.paused_info == <span class="literal">False</span>])</span><br><span class="line">    <span class="comment"># 将这个股票列表进行返回</span></span><br><span class="line">    <span class="keyword">return</span> stock_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在这段代码中，我们使用get_current_data获取股票是否停盘的信息；选出那些没有停盘的股票，并将</span></span><br><span class="line"><span class="string">其放入可交易的股票列表中，下面来定义滑点和手续费</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义set_slip_fee函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_slip_fee</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 将滑点设置为0.02</span></span><br><span class="line">    set_slippage(FixedSlippage(<span class="number">0.02</span>))</span><br><span class="line">    <span class="comment"># 设置买入的手续费为千分之3</span></span><br><span class="line">    <span class="comment"># 设置卖出的手续费为千分之4</span></span><br><span class="line">    <span class="comment"># 每笔交易最少收取5元手续费</span></span><br><span class="line">    set_commission(PerTrade(buy_cost=<span class="number">0.003</span>, sell_cost=<span class="number">0.004</span>, min_cost=<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">到此，我们的准备工作就完成了，接下来要进行的是策略中交易的主体部分</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">8.3.3 策略中的机器学习部分</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 我们使用随机森林进行模型的训练。在此之前，我们还需要定义一个总体的数据处理函数，用于</span></span><br><span class="line"><span class="comment"># 执行各种操作</span></span><br><span class="line"><span class="comment"># 定义handle_data函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_data</span>(<span class="params">context, data</span>):</span><br><span class="line">    <span class="comment"># 如果是调仓日，也就是交易状态为True</span></span><br><span class="line">    <span class="keyword">if</span> g.if_trade == <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 获取买入股票的列表</span></span><br><span class="line">        list_to_buy = stocks_to_buy(context)</span><br><span class="line">        <span class="comment"># 卖出股票的列表</span></span><br><span class="line">        list_to_sell = stocks_to_sell(context, list_to_buy)</span><br><span class="line">        <span class="comment"># 执行卖出操作和买入操作</span></span><br><span class="line">        sell_operation(list_to_sell)</span><br><span class="line">        buy_operation(context, list_to_buy)</span><br><span class="line">    <span class="comment"># 将交易状态改为False</span></span><br><span class="line">    g.if_trade = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在这一步中，我们定义了handle_data函数。在这个函数中，我们需要指定买入的股票stocks_to_buy</span></span><br><span class="line"><span class="string">和要卖出的股票stocks_to_sell，以及买入/卖出操作buy_operation和sell_operation。下面我们</span></span><br><span class="line"><span class="string">把机器学习的部分从研究中迁移过来</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把机器学习的部分迁移过来</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_rff</span>(<span class="params">context, stock_list</span>):</span><br><span class="line">    <span class="comment"># 使用current_dt获取当日的日期</span></span><br><span class="line">    today = context.current_dt</span><br><span class="line">    <span class="comment"># 通过timedelta算出前一天的日期</span></span><br><span class="line">    delta = datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">    yesterday = today - delta</span><br><span class="line">    stocks = get_index_stocks(<span class="string">&#x27;000300.XSHG&#x27;</span>)</span><br><span class="line">    q = query(valuation.code, valuation.market_cap).<span class="built_in">filter</span>(</span><br><span class="line">        valuation.code.in_(stocks))</span><br><span class="line">    dataset = get_fundamentals(q)</span><br><span class="line">    dataset[<span class="string">&#x27;平均差&#x27;</span>] = <span class="built_in">list</span>(DMA(dataset.code, yesterday)[<span class="number">0</span>].values())</span><br><span class="line">    dataset[<span class="string">&#x27;换手率&#x27;</span>] = <span class="built_in">list</span>(HSL(dataset.code, yesterday)[<span class="number">0</span>].values())</span><br><span class="line">    dataset[<span class="string">&#x27;移动平均&#x27;</span>] = <span class="built_in">list</span>(MA(dataset.code, yesterday).values())</span><br><span class="line">    dataset[<span class="string">&#x27;乖离率&#x27;</span>] = <span class="built_in">list</span>(BIAS(dataset.code, yesterday)[<span class="number">0</span>].values())</span><br><span class="line">    dataset[<span class="string">&#x27;动量线&#x27;</span>] = <span class="built_in">list</span>(MTM(dataset.code, yesterday).values())</span><br><span class="line">    dataset.index = dataset.code</span><br><span class="line">    dataset.drop(<span class="string">&#x27;code&#x27;</span>, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    X = dataset.drop(<span class="string">&#x27;market_cap&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">    y = dataset[<span class="string">&#x27;market_cap&#x27;</span>]</span><br><span class="line">    <span class="comment"># 这里使用随机森林来训练模型</span></span><br><span class="line">    reg = RandomForestRegressor(random_state=<span class="number">20</span>)</span><br><span class="line">    reg.fit(X, y)</span><br><span class="line">    <span class="comment"># 找到模型市值比预测值低最多的股票</span></span><br><span class="line">    factor = y - pd.DataFrame(reg.predict(X), index=y.index, columns=[<span class="string">&#x27;market_cap&#x27;</span>])</span><br><span class="line">    factor = factor.sort_index(by = <span class="string">&#x27;market_cap&#x27;</span>, ascending=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 将结果进行返回</span></span><br><span class="line">    <span class="keyword">return</span> factor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在这段代码中，get_rff函数的主要作用是使用随机森林根据股票前一天的因子值训练模型，对股票的市值</span></span><br><span class="line"><span class="string">做出预测，找到实际市值比预测值低最多的股票，并将其存入一个列表中返回。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">8.3.4 定义买入股票和卖出股票的列表</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 下面我们就来根据get_rff函数的返回结果来创建买入股票的列表</span></span><br><span class="line"><span class="comment"># 定义stocks_to_buy函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stocks_to_buy</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 创建一个空列表</span></span><br><span class="line">    list_to_buy=[]</span><br><span class="line">    <span class="comment"># 设置两个时间节点</span></span><br><span class="line">    <span class="comment"># 一个是当日的日期</span></span><br><span class="line">    day1=context.current_dt</span><br><span class="line">    <span class="comment"># 另一个是5天前的日期</span></span><br><span class="line">    day2=day1-datetime.timedelta(days=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 找到这两个时间节点的沪深300指数的收盘价</span></span><br><span class="line">    hs300_close = get_price(<span class="string">&#x27;000300.XSHG&#x27;</span>, day2, day1, fq=<span class="string">&#x27;pre&#x27;</span>)[<span class="string">&#x27;close&#x27;</span>]</span><br><span class="line">    <span class="comment"># 求出这个时间范围内中沪深300的回报率</span></span><br><span class="line">    hs300_ret = hs300_close[-<span class="number">1</span>]/hs300_close[<span class="number">0</span>]-<span class="number">1</span></span><br><span class="line">    <span class="comment"># 如果沪深300的收益比持仓收益高</span></span><br><span class="line">    <span class="keyword">if</span> hs300_ret&gt;g.ret:</span><br><span class="line">        <span class="comment"># 就使用get_rff函数在可变交易股票中找到估值偏低较多的6只股票</span></span><br><span class="line">        factor = get_rff(context, g.feasible_stocks)</span><br><span class="line">        <span class="comment"># 加入买入列表中</span></span><br><span class="line">        list_to_buy = <span class="built_in">list</span>(factor.index[:g.stocknum])</span><br><span class="line">    <span class="comment"># 否则保持买入列表为空</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># 返回买入列表</span></span><br><span class="line">    <span class="keyword">return</span> list_to_buy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这段代码的主要思路是，如果沪深300在最近5天中的收益比我们设置的收益高，说明股市整体上涨</span></span><br><span class="line"><span class="string">，这时就买入随机森林模型选出的股票。否则不进行任何操作</span></span><br><span class="line"><span class="string">同样的，我们还要创建卖出股票的列表</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义stock_to_sell函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stocks_to_sell</span>(<span class="params">context, list_to_buy</span>):</span><br><span class="line">    <span class="comment"># 首先还是空列表</span></span><br><span class="line">    list_to_sell = []</span><br><span class="line">    day1 = context.current_dt</span><br><span class="line">    day2 = day1-datetime.timedelta(days=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 同样与沪深300指数的收益及逆行对比</span></span><br><span class="line">    hs300_close = get_price(<span class="string">&#x27;000300.XSHG&#x27;</span>, day2, day1, fq=<span class="string">&#x27;pre&#x27;</span>)[<span class="string">&#x27;close&#x27;</span>]</span><br><span class="line">    hs300_ret = hs300_close[-<span class="number">1</span>]/hs300_close[<span class="number">0</span>]-<span class="number">1</span></span><br><span class="line">    <span class="comment"># 如果沪深300收益低于初始收益</span></span><br><span class="line">    <span class="keyword">for</span> stock_sell <span class="keyword">in</span> context.portfolio.positions:</span><br><span class="line">        <span class="keyword">if</span> hs300_ret&lt;=g.ret:</span><br><span class="line">            list_to_sell.append(stock_sell)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 或者持仓股票的价格低于平均持仓成本的0.95倍</span></span><br><span class="line">            <span class="keyword">if</span> (context.portfolio.positions[stock_sell].price)/(context.portfolio.positions[stock_sell].avg_cost)&lt;<span class="number">0.95</span> \</span><br><span class="line">                    <span class="keyword">or</span> stock_sell <span class="keyword">not</span> <span class="keyword">in</span> list_to_buy:  <span class="comment"># 或者某只股票不在买入列表</span></span><br><span class="line">                <span class="comment"># 就把该股票添加到卖出列表</span></span><br><span class="line">                list_to_sell.append(stock_sell)</span><br><span class="line">    <span class="comment"># 将卖出列表进行返回</span></span><br><span class="line">    <span class="keyword">return</span> list_to_sell</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在这段代码中，如果沪深300指数在5天内的收益比初始收益低的话，说明整体下行，这时我们就要卖出</span></span><br><span class="line"><span class="string">股票；或者持仓的某只股票价格低于平均持仓成本的0.95倍，抑或是某只股票不再出现在买入列表中，</span></span><br><span class="line"><span class="string">就将它放入卖出列表中</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">8.3.5 定义买入操作和卖出操作</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在我们已经有了买入和卖出股票的列表了，下面就定义买入操作和卖出操作，让程序自动将列表中</span></span><br><span class="line"><span class="comment"># 的股票按照一定的数量进行买入或者卖出的操作</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义卖出操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sell_operation</span>(<span class="params">list_to_sell</span>):</span><br><span class="line">    <span class="comment"># 只要股票出现在卖出股票列表中，就全部卖出</span></span><br><span class="line">    <span class="keyword">for</span> stock_sell <span class="keyword">in</span> list_to_sell:</span><br><span class="line">        order_target_value(stock_sell, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义买入操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">buy_operation</span>(<span class="params">context, list_to_buy</span>):</span><br><span class="line">    <span class="comment"># 如果持仓的股票个数小于最大持仓数</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(context.portfolio.positions) &lt; g.stocknum:</span><br><span class="line">        <span class="comment"># 就平均分配可用资金</span></span><br><span class="line">        num = g.stocknum - <span class="built_in">len</span>(context.portfolio.positions)</span><br><span class="line">        cash = context.portfolio.cash/num</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 否则资金和买入数量都是0</span></span><br><span class="line">        cash = <span class="number">0</span></span><br><span class="line">        num = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 使用资金买入列表中的股票</span></span><br><span class="line">    <span class="keyword">for</span> stock_sell <span class="keyword">in</span> list_to_buy[:num+<span class="number">1</span>]:</span><br><span class="line">        order_target_value(stock_sell, cash)</span><br><span class="line">        num = num -<span class="number">1</span></span><br><span class="line">        <span class="comment"># 直到达到最大持仓数</span></span><br><span class="line">        <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># 如果已经持有6只股票，就什么都不做</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这段代码中，卖出操作是比较容易理解的——只要股票出现在卖出股票列表中，就全部平仓；而买入</span></span><br><span class="line"><span class="string">前要判断一下仓位和现金的数量</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-2-回测详情"><a href="#2-2-回测详情" class="headerlink" title="2.2 回测详情"></a>2.2 回测详情</h2><p>2017.5.20-2020.5.19      ￥100000</p>
<p><img src="Snipaste_2023-02-04_18-32-01.png" alt="Snipaste_2023-02-04_18-32-01"></p>
<h1 id="3-支持向量机"><a href="#3-支持向量机" class="headerlink" title="3 支持向量机"></a>3 支持向量机</h1><h2 id="3-1-代码"><a href="#3-1-代码" class="headerlink" title="3.1 代码"></a>3.1 代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">9.2.1 回测函数的初始化</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入需要用到的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> jqdata     <span class="comment"># 聚宽平台是数据API</span></span><br><span class="line"><span class="keyword">from</span> jqlib.technical_analysis <span class="keyword">import</span> *    <span class="comment"># 技术指标分析工具</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化context函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 包括策略参数的设置</span></span><br><span class="line">    set_params()</span><br><span class="line">    <span class="comment"># 回测条件的设置</span></span><br><span class="line">    set_backtest()</span><br><span class="line">    <span class="comment"># 以及其他变量的设置</span></span><br><span class="line">    set_variables()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义参数设置的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_params</span>():</span><br><span class="line">    <span class="comment"># 首先是调仓频率的设置</span></span><br><span class="line">    g.tc = <span class="number">10</span></span><br><span class="line">    <span class="comment"># 然后是最大持股数的设置，这里设定最大持股个数为5个</span></span><br><span class="line">    g.stocknum = <span class="number">5</span></span><br><span class="line">    <span class="comment"># 设置初始的收益为-0.05</span></span><br><span class="line">    g.ret = -<span class="number">0.05</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义回测函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_backtest</span>():</span><br><span class="line">    <span class="comment"># 基准收益设置为上证指数</span></span><br><span class="line">    set_benchmark(<span class="string">&#x27;000001.XSHG&#x27;</span>)</span><br><span class="line">    <span class="comment"># 设置成交价格为真实价格</span></span><br><span class="line">    set_option(<span class="string">&#x27;use_real_price&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 设置日志记录订单和代码错误</span></span><br><span class="line">    log.set_level(<span class="string">&#x27;order&#x27;</span>, <span class="string">&#x27;error&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置其他变量</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_variables</span>():</span><br><span class="line">    <span class="comment"># 初始天数为0，每运行一天，天数加1</span></span><br><span class="line">    g.days = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 初始交易为False，即不进行交易</span></span><br><span class="line">    g.if_trade = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在这段代码中，我们把调仓频率、最大持股数、对比的基准收益等都设置好了。接下来，我们还可以</span></span><br><span class="line"><span class="string">对每笔交易的滑点和手续费进行设置</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">9.2.2 盘前的准备工作</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在每日开盘之前，我们要让程序做几件事情：首先，判断当日是否是调仓日；其次，设置好交易的滑点</span></span><br><span class="line"><span class="string">和手续费；最后，设置好股票池。要完成这些工作，就要定义新的函数</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数，设置开盘之前需要做的事情</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">before_trading_start</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 如果天数可以被调仓频率整除</span></span><br><span class="line">    <span class="keyword">if</span> g.days%g.tc==<span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 则交易状态变为True，即进行交易</span></span><br><span class="line">        g.if_trade=<span class="literal">True</span></span><br><span class="line">        <span class="comment"># 运行滑点和手续费的计算</span></span><br><span class="line">        set_slip_fee(context)</span><br><span class="line">        <span class="comment"># 股票池设置成沪深300成分股</span></span><br><span class="line">        g.stocks=get_index_stocks(<span class="string">&#x27;000300.XSHG&#x27;</span>)</span><br><span class="line">        <span class="comment"># 运行一个函数，在大的股票池中选择可用的股票</span></span><br><span class="line">        g.feasible_stocks = set_feasible_stocks(g.stocks, context)</span><br><span class="line">    <span class="comment"># 这些工作做完，天数加1</span></span><br><span class="line">    g.days+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在上面的代码中，我们指定before_trading_start函数自动判断是否要进行调仓，且运行交易滑点</span></span><br><span class="line"><span class="string">和手续费的计算set_slip_fee，同时指定运行et_feasible_stocks函数在沪深300成分股中选择可</span></span><br><span class="line"><span class="string">供交易的股票</span></span><br><span class="line"><span class="string">接下来，我们就需要定义et_feasible_stocks和set_slip_fee的具体内容了</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义遴选可交易股票的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_feasible_stocks</span>(<span class="params">initial_stocks, context</span>):</span><br><span class="line">    <span class="comment"># 先创建一个空列表</span></span><br><span class="line">    paused_info = []</span><br><span class="line">    <span class="comment"># 使用get_current_data函数获取数据</span></span><br><span class="line">    current_data = get_current_data()</span><br><span class="line">    <span class="comment"># 在沪深300成分股中遍历</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> initial_stocks:</span><br><span class="line">        <span class="comment"># 把是否停盘的信息添加到先前创建的空列表中</span></span><br><span class="line">        paused_info.append(current_data[i].paused)</span><br><span class="line">    <span class="comment"># 将是否停盘信息存入一个数据表</span></span><br><span class="line">    df_paused_info = pd.DataFrame(&#123;<span class="string">&#x27;paused_info&#x27;</span>:paused_info&#125;,index=initial_stocks)</span><br><span class="line">    <span class="comment"># 选出没有停盘的股票，存入股票列表</span></span><br><span class="line">    stock_list = <span class="built_in">list</span>(df_paused_info.index[df_paused_info.paused_info == <span class="literal">False</span>])</span><br><span class="line">    <span class="comment"># 将这个股票列表进行返回</span></span><br><span class="line">    <span class="keyword">return</span> stock_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在这段代码中，我们使用get_current_data获取股票是否停盘的信息；选出那些没有停盘的股票，并将</span></span><br><span class="line"><span class="string">其放入可交易的股票列表中，下面来定义滑点和手续费</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义set_slip_fee函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_slip_fee</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 将滑点设置为0</span></span><br><span class="line">    set_slippage(FixedSlippage(<span class="number">0</span>))</span><br><span class="line">    <span class="comment"># 设置买入的手续费为千分之3</span></span><br><span class="line">    <span class="comment"># 设置卖出的手续费为千分之4</span></span><br><span class="line">    <span class="comment"># 每笔交易最少收取5元手续费</span></span><br><span class="line">    set_commission(PerTrade(buy_cost=<span class="number">0.003</span>, sell_cost=<span class="number">0.004</span>, min_cost=<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">到此，我们的准备工作就完成了，接下来要进行的是策略中交易的主体部分</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">9.2.3 策略中的机器学习部分</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 我们使用支持向量机进行模型的训练。在此之前，我们还需要定义一个总体的数据处理函数，用于</span></span><br><span class="line"><span class="comment"># 执行各种操作</span></span><br><span class="line"><span class="comment"># 定义handle_data函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">handle_data</span>(<span class="params">context, data</span>):</span><br><span class="line">    <span class="comment"># 如果是调仓日，也就是交易状态为True</span></span><br><span class="line">    <span class="keyword">if</span> g.if_trade == <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 获取买入股票的列表</span></span><br><span class="line">        list_to_buy = stocks_to_buy(context)</span><br><span class="line">        <span class="comment"># 卖出股票的列表</span></span><br><span class="line">        list_to_sell = stocks_to_sell(context, list_to_buy)</span><br><span class="line">        <span class="comment"># 执行卖出操作和买入操作</span></span><br><span class="line">        sell_operation(list_to_sell)</span><br><span class="line">        buy_operation(context, list_to_buy)</span><br><span class="line">    <span class="comment"># 将交易状态改为False</span></span><br><span class="line">    g.if_trade = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">接下来与第八章策略就有所不同了，我们并不是固定好因子去训练模型，而是在每次运行</span></span><br><span class="line"><span class="string">时，都要先用决策树模型计算出特征重要性，这样就可以动态地进行因子选择了</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义机器学习的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_svr</span>(<span class="params">context, stock_list</span>):</span><br><span class="line">    <span class="comment">#加载一些基本面因子数据</span></span><br><span class="line">    q=query(valuation.code, valuation.market_cap, balance.total_current_assets-balance.total_current_liability,</span><br><span class="line">            balance.total_liability-balance.total_assets, (balance.total_liability)/(balance.equities_parent_company_owners),</span><br><span class="line">            (balance.total_assets-balance.total_current_assets)/(balance.total_assets), </span><br><span class="line">            (balance.equities_parent_company_owners)/(balance.total_assets), </span><br><span class="line">            indicator.inc_total_revenue_year_on_year, valuation.turnover_ratio, valuation.pe_ratio,</span><br><span class="line">            valuation.pb_ratio, valuation.ps_ratio, indicator.roa).<span class="built_in">filter</span>(valuation.code.in_(stock_list))</span><br><span class="line">    df = get_fundamentals(q, date=<span class="literal">None</span>)</span><br><span class="line">    <span class="comment"># 把这些因子放入数据表中</span></span><br><span class="line">    df.columns = [<span class="string">&#x27;code&#x27;</span>, <span class="string">&#x27;市值&#x27;</span>, <span class="string">&#x27;净营运资本&#x27;</span>,<span class="string">&#x27;净债务&#x27;</span>,<span class="string">&#x27;产权比率&#x27;</span>,<span class="string">&#x27;非流动资产比率&#x27;</span>,<span class="string">&#x27;股东权益比率&#x27;</span>,<span class="string">&#x27;营收增长率&#x27;</span>,<span class="string">&#x27;换手率&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;PE&#x27;</span>,<span class="string">&#x27;PB&#x27;</span>,<span class="string">&#x27;PS&#x27;</span>,<span class="string">&#x27;总资产收益率&#x27;</span>]</span><br><span class="line">    df.index = df.code.values</span><br><span class="line">    <span class="keyword">del</span>  df[<span class="string">&#x27;code&#x27;</span>]</span><br><span class="line">    <span class="comment"># 我们使用回测当日的日期来计算几个主要时间点</span></span><br><span class="line">    start = context.current_dt</span><br><span class="line">    delta50 = datetime.timedelta(days=<span class="number">50</span>)</span><br><span class="line">    deltal = datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">    today = start-deltal</span><br><span class="line">    preday = start-delta50</span><br><span class="line">    <span class="comment"># 获得最新的技术因子</span></span><br><span class="line">    df[<span class="string">&#x27;动量线&#x27;</span>]=<span class="built_in">list</span>(MTM(df.index, today, timeperiod=<span class="number">10</span>, unit=<span class="string">&#x27;1d&#x27;</span>, include_now=<span class="literal">True</span>,</span><br><span class="line">                        fq_ref_date=<span class="literal">None</span>).values())</span><br><span class="line">    df[<span class="string">&#x27;成交量&#x27;</span>]=<span class="built_in">list</span>(VOL(df.index, today ,M1=<span class="number">10</span>,unit=<span class="string">&#x27;1d&#x27;</span>,include_now=<span class="literal">True</span>,</span><br><span class="line">                        fq_ref_date=<span class="literal">None</span>)[<span class="number">0</span>].values())</span><br><span class="line">    df[<span class="string">&#x27;累计能量线&#x27;</span>]=<span class="built_in">list</span>(OBV(df.index, check_date=today, timeperiod=<span class="number">10</span>).values())</span><br><span class="line">    df[<span class="string">&#x27;资金流量指标&#x27;</span>]=<span class="built_in">list</span>(MFI(df.index, today, timeperiod=<span class="number">10</span>, unit=<span class="string">&#x27;1d&#x27;</span>,</span><br><span class="line">                            include_now=<span class="literal">True</span>, fq_ref_date=<span class="literal">None</span>).values())</span><br><span class="line">    df[<span class="string">&#x27;平均差&#x27;</span>]=<span class="built_in">list</span>(DMA(df.index, today, N1=<span class="number">10</span>, unit=<span class="string">&#x27;1d&#x27;</span>,</span><br><span class="line">                            include_now=<span class="literal">True</span>, fq_ref_date=<span class="literal">None</span>)[<span class="number">0</span>].values())</span><br><span class="line">    df[<span class="string">&#x27;指数移动平均&#x27;</span>]=<span class="built_in">list</span>(EMA(df.index, today, timeperiod=<span class="number">10</span>, unit=<span class="string">&#x27;1d&#x27;</span>,</span><br><span class="line">                            include_now=<span class="literal">True</span>, fq_ref_date=<span class="literal">None</span>).values())</span><br><span class="line">    df[<span class="string">&#x27;移动平均&#x27;</span>]=<span class="built_in">list</span>(MA(df.index, today, timeperiod=<span class="number">10</span>, unit=<span class="string">&#x27;1d&#x27;</span>,</span><br><span class="line">                            include_now=<span class="literal">True</span>, fq_ref_date=<span class="literal">None</span>).values())</span><br><span class="line">    df[<span class="string">&#x27;乖离率&#x27;</span>]=<span class="built_in">list</span>(BIAS(df.index, today, N1=<span class="number">10</span>, unit=<span class="string">&#x27;1d&#x27;</span>, include_now=<span class="literal">True</span>,</span><br><span class="line">                        fq_ref_date=<span class="literal">None</span>)[<span class="number">0</span>].values())</span><br><span class="line">    df.fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    df[<span class="string">&#x27;close1&#x27;</span>]=get_price(stock_list, start_date=today, end_date=today, fq=<span class="string">&#x27;pre&#x27;</span>, panel=<span class="literal">False</span>)[<span class="string">&#x27;close&#x27;</span>].T</span><br><span class="line">    df[<span class="string">&#x27;close2&#x27;</span>]=get_price(stock_list, start_date=preday, end_date=preday, fq=<span class="string">&#x27;pre&#x27;</span>, panel=<span class="literal">False</span>)[<span class="string">&#x27;close&#x27;</span>].T</span><br><span class="line">    <span class="comment"># 用不同的收盘价计算出59天以来的收益</span></span><br><span class="line">    df[<span class="string">&#x27;return&#x27;</span>]=df[<span class="string">&#x27;close1&#x27;</span>]/df[<span class="string">&#x27;close2&#x27;</span>]-<span class="number">1</span></span><br><span class="line">    <span class="comment"># 给出分类标签</span></span><br><span class="line">    df[<span class="string">&#x27;signal&#x27;</span>]=np.where(df[<span class="string">&#x27;return&#x27;</span>]&lt;df[<span class="string">&#x27;return&#x27;</span>].mean(), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 将数据分为特征与标签</span></span><br><span class="line">    x=df.drop(labels=[<span class="string">&#x27;close1&#x27;</span>,<span class="string">&#x27;close2&#x27;</span>,<span class="string">&#x27;return&#x27;</span>,<span class="string">&#x27;signal&#x27;</span>],axis=<span class="number">1</span>) <span class="comment">#  labels=[&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;],axis=1</span></span><br><span class="line">    y=df[[<span class="string">&#x27;signal&#x27;</span>]]</span><br><span class="line">    x=x.fillna(<span class="number">0</span>)</span><br><span class="line">    y=y.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 训练决策树模型</span></span><br><span class="line">    tree=DecisionTreeClassifier()</span><br><span class="line">    tree.fit(x,y)</span><br><span class="line">    model_cs=pd.DataFrame(&#123;<span class="string">&#x27;feature&#x27;</span>:<span class="built_in">list</span>(x.columns),<span class="string">&#x27;importance&#x27;</span>:tree.feature_importances_&#125;).sort_values(<span class="string">&#x27;importance&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># 选出重要性最高的5个特征</span></span><br><span class="line">    features=model_cs[<span class="string">&#x27;feature&#x27;</span>][:<span class="number">5</span>]</span><br><span class="line">    df2=df[features]</span><br><span class="line">    df2[<span class="string">&#x27;市值&#x27;</span>]=df[<span class="string">&#x27;市值&#x27;</span>]</span><br><span class="line">    <span class="comment"># 使用这些特征来训练支持向量机</span></span><br><span class="line">    X=df[features]</span><br><span class="line">    Y=df[<span class="string">&#x27;市值&#x27;</span>]</span><br><span class="line">    X=X.fillna(<span class="number">0</span>)</span><br><span class="line">    Y=Y.fillna(<span class="number">0</span>)</span><br><span class="line">    svr=SVR()</span><br><span class="line">    model = svr.fit(X,Y)</span><br><span class="line">    <span class="comment"># 通过训练好的支持向量机模型找到市值与模型估值的差，并作为新的因子进行返回</span></span><br><span class="line">    factor = Y - pd.DataFrame(svr.predict(X), index=Y.index, columns=[<span class="string">&#x27;市值&#x27;</span>])</span><br><span class="line">    factor = factor.sort_values(by = <span class="string">&#x27;市值&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> factor</span><br><span class="line">    </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">到这里，我们就设置每次回测都要先用决策树判断哪些因子更重要，并使用重要性排前5的因子来训练支持向量机模型。这段代码</span></span><br><span class="line"><span class="string">会返回模型的计算结果，以供我们买入和卖出</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">9.2.4 定义买入股票和卖出股票的列表</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义stocks_to_buy函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stocks_to_buy</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="comment"># 创建一个空列表</span></span><br><span class="line">    list_to_buy=[]</span><br><span class="line">    <span class="comment"># 设置两个时间节点</span></span><br><span class="line">    <span class="comment"># 一个是当日的日期</span></span><br><span class="line">    day1=context.current_dt</span><br><span class="line">    <span class="comment"># 另一个是5天前的日期</span></span><br><span class="line">    day2=day1-datetime.timedelta(days=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 找到这两个时间节点的沪深300指数的收盘价</span></span><br><span class="line">    hs300_close = get_price(<span class="string">&#x27;000300.XSHG&#x27;</span>, day2, day1, fq=<span class="string">&#x27;pre&#x27;</span>)[<span class="string">&#x27;close&#x27;</span>]</span><br><span class="line">    <span class="comment"># 求出这个时间范围内中沪深300的回报率</span></span><br><span class="line">    hs300_ret = hs300_close[-<span class="number">1</span>]/hs300_close[<span class="number">0</span>]-<span class="number">1</span></span><br><span class="line">    <span class="comment"># 如果沪深300的收益比持仓收益高</span></span><br><span class="line">    <span class="keyword">if</span> hs300_ret&gt;g.ret:</span><br><span class="line">        <span class="comment"># 就使用get_rff函数在可变交易股票中找到估值偏低较多的6只股票</span></span><br><span class="line">        factor = get_svr(context, g.feasible_stocks)</span><br><span class="line">        <span class="comment"># 加入买入列表中</span></span><br><span class="line">        list_to_buy = <span class="built_in">list</span>(factor.index[:g.stocknum])</span><br><span class="line">    <span class="comment"># 否则保持买入列表为空</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># 返回买入列表</span></span><br><span class="line">    <span class="keyword">return</span> list_to_buy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这段代码的主要思路是，如果沪深300在最近5天中的收益比我们设置的收益高，说明股市整体上涨</span></span><br><span class="line"><span class="string">，这时就买入支持向量机模型选出的股票。否则不进行任何操作</span></span><br><span class="line"><span class="string">同样的，我们还要创建卖出股票的列表</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义stock_to_sell函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stocks_to_sell</span>(<span class="params">context, list_to_buy</span>):</span><br><span class="line">    <span class="comment"># 首先还是空列表</span></span><br><span class="line">    list_to_sell = []</span><br><span class="line">    day1 = context.current_dt</span><br><span class="line">    day2 = day1-datetime.timedelta(days=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 同样与沪深300指数的收益及逆行对比</span></span><br><span class="line">    hs300_close = get_price(<span class="string">&#x27;000300.XSHG&#x27;</span>, day2, day1, fq=<span class="string">&#x27;pre&#x27;</span>)[<span class="string">&#x27;close&#x27;</span>]</span><br><span class="line">    hs300_ret = hs300_close[-<span class="number">1</span>]/hs300_close[<span class="number">0</span>]-<span class="number">1</span></span><br><span class="line">    <span class="comment"># 如果沪深300收益低于初始收益</span></span><br><span class="line">    <span class="keyword">for</span> stock_sell <span class="keyword">in</span> context.portfolio.positions:</span><br><span class="line">        <span class="keyword">if</span> hs300_ret&lt;=g.ret:</span><br><span class="line">            list_to_sell.append(stock_sell)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 或者持仓股票的价格低于平均持仓成本的0.95倍</span></span><br><span class="line">            <span class="keyword">if</span> (context.portfolio.positions[stock_sell].price)/(context.portfolio.positions[stock_sell].avg_cost)&lt;<span class="number">0.95</span> \</span><br><span class="line">                    <span class="keyword">or</span> stock_sell <span class="keyword">not</span> <span class="keyword">in</span> list_to_buy:  <span class="comment"># 或者某只股票不在买入列表</span></span><br><span class="line">                <span class="comment"># 就把该股票添加到卖出列表</span></span><br><span class="line">                list_to_sell.append(stock_sell)</span><br><span class="line">    <span class="comment"># 将卖出列表进行返回</span></span><br><span class="line">    <span class="keyword">return</span> list_to_sell</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在这段代码中，如果沪深300指数在5天内的收益比初始收益低的话，说明整体下行，这时我们就要卖出</span></span><br><span class="line"><span class="string">股票；或者持仓的某只股票价格低于平均持仓成本的0.95倍，抑或是某只股票不再出现在买入列表中，</span></span><br><span class="line"><span class="string">就将它放入卖出列表中</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">8.3.5 定义买入操作和卖出操作</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在我们已经有了买入和卖出股票的列表了，下面就定义买入操作和卖出操作，让程序自动将列表中</span></span><br><span class="line"><span class="comment"># 的股票按照一定的数量进行买入或者卖出的操作</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义卖出操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sell_operation</span>(<span class="params">list_to_sell</span>):</span><br><span class="line">    <span class="comment"># 只要股票出现在卖出股票列表中，就全部卖出</span></span><br><span class="line">    <span class="keyword">for</span> stock_sell <span class="keyword">in</span> list_to_sell:</span><br><span class="line">        order_target_value(stock_sell, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义买入操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">buy_operation</span>(<span class="params">context, list_to_buy</span>):</span><br><span class="line">    <span class="comment"># 如果持仓的股票个数小于最大持仓数</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(context.portfolio.positions) &lt; g.stocknum:</span><br><span class="line">        <span class="comment"># 就平均分配可用资金</span></span><br><span class="line">        num = g.stocknum - <span class="built_in">len</span>(context.portfolio.positions)</span><br><span class="line">        cash = context.portfolio.cash/num</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 否则资金和买入数量都是0</span></span><br><span class="line">        cash = <span class="number">0</span></span><br><span class="line">        num = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 使用资金买入列表中的股票</span></span><br><span class="line">    <span class="keyword">for</span> stock_sell <span class="keyword">in</span> list_to_buy[:num+<span class="number">1</span>]:</span><br><span class="line">        order_target_value(stock_sell, cash)</span><br><span class="line">        num = num -<span class="number">1</span></span><br><span class="line">        <span class="comment"># 直到达到最大持仓数</span></span><br><span class="line">        <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># 如果已经持有6只股票，就什么都不做</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这段代码中，卖出操作是比较容易理解的——只要股票出现在卖出股票列表中，就全部平仓；而买入</span></span><br><span class="line"><span class="string">前要判断一下仓位和现金的数量</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="3-2-回测详情"><a href="#3-2-回测详情" class="headerlink" title="3.2 回测详情"></a>3.2 回测详情</h2><p>2019.3.6-2020.3.5     ￥100000</p>
<p><img src="Snipaste_2023-02-04_18-33-34.png" alt="Snipaste_2023-02-04_18-33-34"></p>
<h1 id="4-机器学习多因子策略"><a href="#4-机器学习多因子策略" class="headerlink" title="4 机器学习多因子策略"></a>4 机器学习多因子策略</h1><h2 id="4-1-代码"><a href="#4-1-代码" class="headerlink" title="4.1 代码"></a>4.1 代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR  </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV  </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> learning_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">import</span> jqdata</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">context</span>):</span><br><span class="line">    set_params()</span><br><span class="line">    set_backtest()</span><br><span class="line">    run_daily(trade, <span class="string">&#x27;every_bar&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_params</span>():</span><br><span class="line">    g.days = <span class="number">0</span></span><br><span class="line">    g.refresh_rate = <span class="number">10</span></span><br><span class="line">    g.stocknum = <span class="number">10</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_backtest</span>():</span><br><span class="line">    set_benchmark(<span class="string">&#x27;000001.XSHG&#x27;</span>)</span><br><span class="line">    set_option(<span class="string">&#x27;use_real_price&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">    log.set_level(<span class="string">&#x27;order&#x27;</span>, <span class="string">&#x27;error&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">trade</span>(<span class="params">context</span>):</span><br><span class="line">    <span class="keyword">if</span> g.days % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        sample = get_index_stocks(<span class="string">&#x27;000001.XSHG&#x27;</span>, date = <span class="literal">None</span>)</span><br><span class="line">        q = query(valuation.code, valuation.market_cap, balance.total_assets - balance.total_liability,</span><br><span class="line">                  balance.total_assets / balance.total_liability, income.net_profit, income.net_profit + <span class="number">1</span>, </span><br><span class="line">                  indicator.inc_revenue_year_on_year, balance.development_expenditure).<span class="built_in">filter</span>(valuation.code.in_(sample))</span><br><span class="line">        df = get_fundamentals(q, date = <span class="literal">None</span>)</span><br><span class="line">        df.columns = [<span class="string">&#x27;code&#x27;</span>, <span class="string">&#x27;log_mcap&#x27;</span>, <span class="string">&#x27;log_NC&#x27;</span>, <span class="string">&#x27;LEV&#x27;</span>, <span class="string">&#x27;NI_p&#x27;</span>, <span class="string">&#x27;NI_n&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;log_RD&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        df[<span class="string">&#x27;log_mcap&#x27;</span>] = np.log(df[<span class="string">&#x27;log_mcap&#x27;</span>])</span><br><span class="line">        df[<span class="string">&#x27;log_NC&#x27;</span>] = np.log(df[<span class="string">&#x27;log_NC&#x27;</span>])</span><br><span class="line">        df[<span class="string">&#x27;NI_p&#x27;</span>] = np.log(np.<span class="built_in">abs</span>(df[<span class="string">&#x27;NI_p&#x27;</span>]))</span><br><span class="line">        df[<span class="string">&#x27;NI_n&#x27;</span>] = np.log(np.<span class="built_in">abs</span>(df[<span class="string">&#x27;NI_n&#x27;</span>][df[<span class="string">&#x27;NI_n&#x27;</span>]&lt;<span class="number">0</span>]))</span><br><span class="line">        df[<span class="string">&#x27;log_RD&#x27;</span>] = np.log(df[<span class="string">&#x27;log_RD&#x27;</span>])</span><br><span class="line">        df.index = df.code.values</span><br><span class="line">        <span class="keyword">del</span> df[<span class="string">&#x27;code&#x27;</span>]</span><br><span class="line">        df = df.fillna(<span class="number">0</span>)</span><br><span class="line">        df[df&gt;<span class="number">10000</span>] = <span class="number">10000</span></span><br><span class="line">        df[df&lt;-<span class="number">10000</span>] = -<span class="number">10000</span></span><br><span class="line">        industry_set = [<span class="string">&#x27;801010&#x27;</span>, <span class="string">&#x27;801020&#x27;</span>, <span class="string">&#x27;801030&#x27;</span>, <span class="string">&#x27;801040&#x27;</span>, <span class="string">&#x27;801050&#x27;</span>, <span class="string">&#x27;801080&#x27;</span>, <span class="string">&#x27;801110&#x27;</span>, <span class="string">&#x27;801120&#x27;</span>, <span class="string">&#x27;801130&#x27;</span>, </span><br><span class="line">                  <span class="string">&#x27;801140&#x27;</span>, <span class="string">&#x27;801150&#x27;</span>, <span class="string">&#x27;801160&#x27;</span>, <span class="string">&#x27;801170&#x27;</span>, <span class="string">&#x27;801180&#x27;</span>, <span class="string">&#x27;801200&#x27;</span>, <span class="string">&#x27;801210&#x27;</span>, <span class="string">&#x27;801230&#x27;</span>, <span class="string">&#x27;801710&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;801720&#x27;</span>, <span class="string">&#x27;801730&#x27;</span>, <span class="string">&#x27;801740&#x27;</span>, <span class="string">&#x27;801750&#x27;</span>, <span class="string">&#x27;801760&#x27;</span>, <span class="string">&#x27;801770&#x27;</span>, <span class="string">&#x27;801780&#x27;</span>, <span class="string">&#x27;801790&#x27;</span>, <span class="string">&#x27;801880&#x27;</span>,<span class="string">&#x27;801890&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(industry_set)):</span><br><span class="line">            industry = get_industry_stocks(industry_set[i], date = <span class="literal">None</span>)</span><br><span class="line">            s = pd.Series([<span class="number">0</span>]*<span class="built_in">len</span>(df), index=df.index)</span><br><span class="line">            s[<span class="built_in">set</span>(industry) &amp; <span class="built_in">set</span>(df.index)]=<span class="number">1</span></span><br><span class="line">            df[industry_set[i]] = s</span><br><span class="line">            </span><br><span class="line">        X = df[[<span class="string">&#x27;log_NC&#x27;</span>, <span class="string">&#x27;LEV&#x27;</span>, <span class="string">&#x27;NI_p&#x27;</span>, <span class="string">&#x27;NI_n&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;log_RD&#x27;</span>,<span class="string">&#x27;801010&#x27;</span>, <span class="string">&#x27;801020&#x27;</span>, <span class="string">&#x27;801030&#x27;</span>, <span class="string">&#x27;801040&#x27;</span>, <span class="string">&#x27;801050&#x27;</span>, </span><br><span class="line">                <span class="string">&#x27;801080&#x27;</span>, <span class="string">&#x27;801110&#x27;</span>, <span class="string">&#x27;801120&#x27;</span>, <span class="string">&#x27;801130&#x27;</span>, <span class="string">&#x27;801140&#x27;</span>, <span class="string">&#x27;801150&#x27;</span>, <span class="string">&#x27;801160&#x27;</span>, <span class="string">&#x27;801170&#x27;</span>, <span class="string">&#x27;801180&#x27;</span>, <span class="string">&#x27;801200&#x27;</span>, </span><br><span class="line">                <span class="string">&#x27;801210&#x27;</span>, <span class="string">&#x27;801230&#x27;</span>, <span class="string">&#x27;801710&#x27;</span>, <span class="string">&#x27;801720&#x27;</span>, <span class="string">&#x27;801730&#x27;</span>, <span class="string">&#x27;801740&#x27;</span>, <span class="string">&#x27;801750&#x27;</span>, <span class="string">&#x27;801760&#x27;</span>, <span class="string">&#x27;801770&#x27;</span>, <span class="string">&#x27;801780&#x27;</span>, </span><br><span class="line">                <span class="string">&#x27;801790&#x27;</span>, <span class="string">&#x27;801880&#x27;</span>, <span class="string">&#x27;801890&#x27;</span>]]</span><br><span class="line">        Y = df[[<span class="string">&#x27;log_mcap&#x27;</span>]]</span><br><span class="line">        X = X.fillna(<span class="number">0</span>)</span><br><span class="line">        Y = Y.fillna(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        svr = SVR(kernel=<span class="string">&#x27;rbf&#x27;</span>, gamma=<span class="number">0.1</span>) </span><br><span class="line">        model = svr.fit(X, Y)</span><br><span class="line">        factor = Y - pd.DataFrame(svr.predict(X), index = Y.index, columns = [<span class="string">&#x27;log_mcap&#x27;</span>])</span><br><span class="line">        factor = factor.sort_index(by = <span class="string">&#x27;log_mcap&#x27;</span>)</span><br><span class="line">        stockset = <span class="built_in">list</span>(factor.index[:<span class="number">10</span>])</span><br><span class="line">        sell_list = <span class="built_in">list</span>(context.portfolio.positions.keys())</span><br><span class="line">        <span class="keyword">for</span> stock <span class="keyword">in</span> sell_list:</span><br><span class="line">            <span class="keyword">if</span> stock <span class="keyword">not</span> <span class="keyword">in</span> stockset[:g.stocknum]:</span><br><span class="line">                stock_sell = stock</span><br><span class="line">                order_target_value(stock_sell, <span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(context.portfolio.positions) &lt; g.stocknum:</span><br><span class="line">            num = g.stocknum - <span class="built_in">len</span>(context.portfolio.positions)</span><br><span class="line">            cash = context.portfolio.cash/num</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cash = <span class="number">0</span></span><br><span class="line">            num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> stock <span class="keyword">in</span> stockset[:g.stocknum]:</span><br><span class="line">            <span class="keyword">if</span> stock <span class="keyword">in</span> sell_list:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                stock_buy = stock</span><br><span class="line">                order_target_value(stock_buy, cash)</span><br><span class="line">                num = num - <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        g.days += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        g.days = g.days + <span class="number">1</span>    </span><br><span class="line">            </span><br></pre></td></tr></table></figure>

<h2 id="4-2-回测详情"><a href="#4-2-回测详情" class="headerlink" title="4.2 回测详情"></a>4.2 回测详情</h2><p>2019.1.1-2020.6.19    ￥100000</p>
<p><img src="Snipaste_2023-02-04_18-44-25.png" alt="Snipaste_2023-02-04_18-44-25"></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">聚宽</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/量化交易//" class="article-tag-list-link color5">量化交易</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/04/%E4%B8%AA%E4%BA%BA%E6%95%B4%E7%90%86%E8%81%9A%E5%AE%BD%E5%B9%B3%E5%8F%B0%E7%AD%96%E7%95%A5%E4%BB%A3%E7%A0%81%E5%8F%8A%E5%9B%9E%E6%B5%8B%E7%BB%93%E6%9E%9C/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-深入浅出python量化交易实战-part2" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/03/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApython%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E5%AE%9E%E6%88%98-part2/">深入浅出python量化交易实战-part2</a>
    </h1>
  

        
        <a href="/2023/02/03/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApython%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E5%AE%9E%E6%88%98-part2/" class="archive-article-date">
  	<time datetime="2023-02-03T12:56:03.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-03</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="4-1-3-在研究环境中运行代码"><a href="#4-1-3-在研究环境中运行代码" class="headerlink" title="4.1.3 在研究环境中运行代码"></a>4.1.3 在研究环境中运行代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#pandas已经安装好，可以直接导入</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment">#使用get_price函数获得某只股票的数据</span></span><br><span class="line"><span class="comment">#start_date和end_date分别为起始日期与结束日期</span></span><br><span class="line"><span class="comment">#frequency参数是获取数据的周期，daily是日线数据</span></span><br><span class="line">df = get_price(<span class="string">&#x27;601318.XSHG&#x27;</span>,</span><br><span class="line">              start_date = <span class="string">&#x27;2020-01-01&#x27;</span>,</span><br><span class="line">              end_date = <span class="string">&#x27;2020-04-01&#x27;</span>,</span><br><span class="line">              frequency = <span class="string">&#x27;daily&#x27;</span>)</span><br><span class="line"><span class="comment">#检查一下载入情况</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>money</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-01-02</th>
      <td>76.41</td>
      <td>76.61</td>
      <td>77.20</td>
      <td>76.40</td>
      <td>87487727.0</td>
      <td>6.712532e+09</td>
    </tr>
    <tr>
      <th>2020-01-03</th>
      <td>77.22</td>
      <td>76.68</td>
      <td>77.28</td>
      <td>76.41</td>
      <td>66885076.0</td>
      <td>5.137312e+09</td>
    </tr>
    <tr>
      <th>2020-01-06</th>
      <td>76.43</td>
      <td>76.15</td>
      <td>77.28</td>
      <td>76.06</td>
      <td>71546732.0</td>
      <td>5.487968e+09</td>
    </tr>
    <tr>
      <th>2020-01-07</th>
      <td>76.51</td>
      <td>76.64</td>
      <td>76.91</td>
      <td>76.21</td>
      <td>50833053.0</td>
      <td>3.886450e+09</td>
    </tr>
    <tr>
      <th>2020-01-08</th>
      <td>76.48</td>
      <td>75.61</td>
      <td>76.48</td>
      <td>75.17</td>
      <td>70603011.0</td>
      <td>5.347387e+09</td>
    </tr>
  </tbody>
</table>
</div>



<p>在聚宽中的get_price函数，传入的股票代码是用.XSHG扩展名代表上海证券交易所股票，用.XSHE扩展名代表深圳证券交易所股票</p>
<h2 id="4-2-借助财务数据筛选股票"><a href="#4-2-借助财务数据筛选股票" class="headerlink" title="4.2 借助财务数据筛选股票"></a>4.2 借助财务数据筛选股票</h2><h3 id="4-2-1-获取股票的概况"><a href="#4-2-1-获取股票的概况" class="headerlink" title="4.2.1 获取股票的概况"></a>4.2.1 获取股票的概况</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用get_security_info函数可以获取股票概况</span></span><br><span class="line">info = get_security_info(<span class="string">&#x27;601318.XSHG&#x27;</span>)</span><br><span class="line"><span class="comment">#返回的对象包含若干属性</span></span><br><span class="line"><span class="comment">#包括股票名称display_name</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;股票的中文名称：&#x27;</span>,info.display_name)</span><br><span class="line"><span class="comment">#股票简称name</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;股票简称：&#x27;</span>,info.name)</span><br><span class="line"><span class="comment">#股票上市日期start_date</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;股票上市日期：&#x27;</span>,info.start_date)</span><br><span class="line"><span class="comment">#股票退市日期end_date，如未退市则显示2200-01-01</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;股票退市日期：&#x27;</span>,info.end_date)</span><br><span class="line"><span class="comment">#产品类型type，stock代表股票、etf代表ETF基金、index代表指数等</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;产品类型：&#x27;</span>,info.<span class="built_in">type</span>)</span><br><span class="line"><span class="comment">#如果是分级基金，parent可查看母基金</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;产品的母基金：&#x27;</span>,info.parent)</span><br></pre></td></tr></table></figure>

<pre><code>股票的中文名称： 中国平安
股票简称： ZGPA
股票上市日期： 2007-03-01
股票退市日期： 2200-01-01
产品类型： stock
产品的母基金： None
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用get_all_securities可获得全部证券信息</span></span><br><span class="line"><span class="comment">#支持使用切片的方式获得其中部分证券的信息</span></span><br><span class="line">info_all = get_all_securities()[:<span class="number">5</span>]</span><br><span class="line"><span class="comment">#查看获取的信息</span></span><br><span class="line">info_all</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>display_name</th>
      <th>name</th>
      <th>start_date</th>
      <th>end_date</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>000001.XSHE</th>
      <td>平安银行</td>
      <td>PAYH</td>
      <td>1991-04-03</td>
      <td>2200-01-01</td>
      <td>stock</td>
    </tr>
    <tr>
      <th>000002.XSHE</th>
      <td>万科A</td>
      <td>WKA</td>
      <td>1991-01-29</td>
      <td>2200-01-01</td>
      <td>stock</td>
    </tr>
    <tr>
      <th>000004.XSHE</th>
      <td>ST国华</td>
      <td>STGH</td>
      <td>1990-12-01</td>
      <td>2200-01-01</td>
      <td>stock</td>
    </tr>
    <tr>
      <th>000005.XSHE</th>
      <td>ST星源</td>
      <td>STXY</td>
      <td>1990-12-10</td>
      <td>2200-01-01</td>
      <td>stock</td>
    </tr>
    <tr>
      <th>000006.XSHE</th>
      <td>深振业A</td>
      <td>SZYA</td>
      <td>1992-04-27</td>
      <td>2200-01-01</td>
      <td>stock</td>
    </tr>
  </tbody>
</table>
</div>



<p>get_all_securities函数默认获取股票的信息。如果需要获取其他类型的证券信息，则我们需要制定types参数，即get_all_securities(types&#x3D;[‘etf’])</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">info_index = get_all_securities(types=[<span class="string">&#x27;etf&#x27;</span>])[:<span class="number">5</span>]</span><br><span class="line">info_index</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>display_name</th>
      <th>name</th>
      <th>start_date</th>
      <th>end_date</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>159001.XSHE</th>
      <td>货币ETF</td>
      <td>BZJ</td>
      <td>2014-10-20</td>
      <td>2200-01-01</td>
      <td>etf</td>
    </tr>
    <tr>
      <th>159003.XSHE</th>
      <td>招商快线ETF</td>
      <td>ZSKX</td>
      <td>2014-10-20</td>
      <td>2200-01-01</td>
      <td>etf</td>
    </tr>
    <tr>
      <th>159005.XSHE</th>
      <td>汇添富快钱ETF</td>
      <td>TFKQ</td>
      <td>2015-01-13</td>
      <td>2200-01-01</td>
      <td>etf</td>
    </tr>
    <tr>
      <th>159601.XSHE</th>
      <td>A50ETF</td>
      <td>A50ETF</td>
      <td>2021-11-08</td>
      <td>2200-01-01</td>
      <td>etf</td>
    </tr>
    <tr>
      <th>159602.XSHE</th>
      <td>中国A50ETF</td>
      <td>ZGA50ETF</td>
      <td>2021-11-08</td>
      <td>2200-01-01</td>
      <td>etf</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="4-2-2-获取股票的财务数据"><a href="#4-2-2-获取股票的财务数据" class="headerlink" title="4.2.2 获取股票的财务数据"></a>4.2.2 获取股票的财务数据</h3><p>get_fundamentals函数要传入一个query_object。query的原理：在数据库中有一个表格，其中包含若干个字段，使用query可以查询表格中的某个字段，并且可以设置筛选条件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先要创建一个query object对象</span></span><br><span class="line"><span class="comment">#获取平台valuation表中，代码为601318的股票数据</span></span><br><span class="line">q = query(valuation).<span class="built_in">filter</span>(valuation.code==<span class="string">&#x27;601318.XSHG&#x27;</span>)</span><br><span class="line"><span class="comment">#把query object对象传入到get_fundamentals函数</span></span><br><span class="line"><span class="comment">#并制定日期为2020年4月1日</span></span><br><span class="line">df = get_fundamentals(q, <span class="string">&#x27;2020-04-01&#x27;</span>)</span><br><span class="line"><span class="comment">#查看返回的结果</span></span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>code</th>
      <th>pubDate</th>
      <th>pe_ratio</th>
      <th>turnover_ratio</th>
      <th>pb_ratio</th>
      <th>ps_ratio</th>
      <th>pcf_ratio</th>
      <th>capitalization</th>
      <th>market_cap</th>
      <th>circulating_cap</th>
      <th>circulating_market_cap</th>
      <th>day</th>
      <th>pe_ratio_lyr</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>53742808</td>
      <td>601318.XSHG</td>
      <td>2020-04-01</td>
      <td>8.4814</td>
      <td>0.5141</td>
      <td>1.8824</td>
      <td>1.0841</td>
      <td>-278.0137</td>
      <td>1828024.125</td>
      <td>12671.8633</td>
      <td>1083266.5</td>
      <td>7509.2031</td>
      <td>2020-04-01</td>
      <td>8.4814</td>
    </tr>
  </tbody>
</table>
</div>



<p>pe_ratio：<strong>动态市盈率</strong>，<strong>指的是这只股票的市价除以每股收益</strong>。例如，某只股票的每股收益是1元，而某日的股价是10元，则这只股票的动态市盈率就是10.一般来说，<strong>市盈率越低的股票越值得投资</strong>。</p>
<p>turnover_ratio：<strong>换手率</strong>，<strong>指的是这只股票在某个时间内交易的频率</strong>。例如，某只股票一共发行了1亿股，而某天这只股票的成交量是1000万股，则这一天，该股票的换手率是10%。<strong>换手率越高，说明该股票的成交越活越</strong></p>
<p>pb_ratio：<strong>市净率</strong>，<strong>指的是这只股票的价格与每股净资产的比值</strong>，比如，某公司净资产1亿元，发行股票1亿股，也就是说每股净资产为1元；而这只股票某日价格为5元，则该股票的市净率为5.**一般来说，市净率越低越好。</p>
<p>ps+ratio：<strong>市销率</strong>，<strong>指的是这只股票的价格与每股销售收入比值</strong>，例如，某公司的销售收入是2亿元，发行1亿股，每股销售收入为2元，而某日这只股票的市价是8元，则市销率为4，<strong>一般来说，市销率越低越好</strong>。</p>
<p>pcf_ratio：<strong>市现率</strong>，<strong>指的是这只股票的价格与每股现金流的比值</strong>，例如，某公司从事经营活动产生的净现金流是5亿元，该公司发行了1亿股，每股现金流为5元；某日这只股票的价格为10元，则市现率是2.<strong>一般来说，市现率大于0的时候，数值越小越好</strong>。</p>
<p>pe_ratio_lyr：<strong>静态市盈率</strong>，<strong>指的是这只股票的价格与最近公开的每股收益的比值</strong>，它与动态市盈率的区别在于：<strong>动态市盈率是股价除以预期的每股收益，而静态市盈率是股价除以已经实现的每股收益</strong>。</p>
<p>capitalization：股票的总股本</p>
<p>market_cap：流通股本</p>
<p>circulating_cap：</p>
<p>circulating_market_cap：</p>
<h3 id="4-2-3-通过财务指标进行选股"><a href="#4-2-3-通过财务指标进行选股" class="headerlink" title="4.2.3 通过财务指标进行选股"></a>4.2.3 通过财务指标进行选股</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个query object</span></span><br><span class="line"><span class="comment">#制定获取的数据为股票代码</span></span><br><span class="line">q = query(valuation.code,</span><br><span class="line">          <span class="comment">#动态市盈率</span></span><br><span class="line">          valuation.pe_ratio,</span><br><span class="line">          <span class="comment">#市现率</span></span><br><span class="line">          valuation.pcf_ratio,</span><br><span class="line">          <span class="comment">#和换手率</span></span><br><span class="line">         valuation.turnover_ratio)\</span><br><span class="line">.<span class="built_in">filter</span>(</span><br><span class="line">    <span class="comment">#筛选条件为市盈率小于20且大于0</span></span><br><span class="line">    valuation.pe_ratio &lt; <span class="number">20</span>,</span><br><span class="line">        valuation.pe_ratio &gt; <span class="number">0</span>,</span><br><span class="line">        <span class="comment">#市现率大于0且小于20</span></span><br><span class="line">       valuation.pcf_ratio &gt; <span class="number">0</span>,</span><br><span class="line">       valuation.pcf_ratio &lt; <span class="number">20</span>,</span><br><span class="line">        <span class="comment">#换手率大于4%</span></span><br><span class="line">       valuation.turnover_ratio &gt; <span class="number">4</span>)\</span><br><span class="line">.order_by(</span><br><span class="line">    <span class="comment">#按照换手率降序排列</span></span><br><span class="line">    valuation.turnover_ratio.desc())</span><br><span class="line"><span class="comment">#使用get_fundamentals函数获得数据</span></span><br><span class="line">portfolio = get_fundamentals(q, date = <span class="string">&#x27;2020-04-03&#x27;</span>)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">portfolio.head(<span class="number">30</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>code</th>
      <th>pe_ratio</th>
      <th>pcf_ratio</th>
      <th>turnover_ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>002458.XSHE</td>
      <td>8.5327</td>
      <td>15.0275</td>
      <td>9.7450</td>
    </tr>
    <tr>
      <th>1</th>
      <td>600387.XSHG</td>
      <td>7.7496</td>
      <td>4.9772</td>
      <td>7.2717</td>
    </tr>
    <tr>
      <th>2</th>
      <td>300107.XSHE</td>
      <td>10.5846</td>
      <td>11.8711</td>
      <td>5.3762</td>
    </tr>
    <tr>
      <th>3</th>
      <td>002234.XSHE</td>
      <td>5.2662</td>
      <td>17.8631</td>
      <td>5.1201</td>
    </tr>
    <tr>
      <th>4</th>
      <td>002839.XSHE</td>
      <td>10.9746</td>
      <td>14.5165</td>
      <td>4.9225</td>
    </tr>
    <tr>
      <th>5</th>
      <td>000610.XSHE</td>
      <td>18.4441</td>
      <td>11.9632</td>
      <td>4.6329</td>
    </tr>
    <tr>
      <th>6</th>
      <td>603733.XSHG</td>
      <td>19.6847</td>
      <td>7.6782</td>
      <td>4.3345</td>
    </tr>
    <tr>
      <th>7</th>
      <td>002869.XSHE</td>
      <td>8.8296</td>
      <td>6.0086</td>
      <td>4.2709</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="4-3-谁是幕后“大佬”"><a href="#4-3-谁是幕后“大佬”" class="headerlink" title="4.3 谁是幕后“大佬”"></a>4.3 谁是幕后“大佬”</h2><p>问题：是不是所有上市公司的财务报表都能够反映其真实财务状况呢？可能财务会造假，也可能合理调整使其只是看起来好看</p>
<p>此外，虽然换手率确实可以体现交易活跃程度的指标，但是成交活跃也不代表股价一定会涨，可能是大股东在减持套利，或者是主力在出货，那么股价不是反而会跌吗？</p>
<p>故，在持仓前，我们有必要了解一下更多信息，比如大股东是谁、大股东近期增减持的状况，以及主力的资金流向。</p>
<h3 id="4-3-1-找到最大的股东"><a href="#4-3-1-找到最大的股东" class="headerlink" title="4.3.1 找到最大的股东"></a>4.3.1 找到最大的股东</h3><p>查询002458这只股票的十大股东都有谁</p>
<p>在平台上，十大股东的数据是存储在名为STK_SHAREHOLDER_TOP10这张表中，使用query object就可以进行查询</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#从jqdata导入finance包</span></span><br><span class="line"><span class="keyword">from</span> jqdata <span class="keyword">import</span> finance</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#从jqdata导入finance包</span></span><br><span class="line"><span class="keyword">from</span> jqdata <span class="keyword">import</span> finance</span><br><span class="line"><span class="comment">#创建一个query object,</span></span><br><span class="line"><span class="comment">#查询STK_SHAREHOLDER_TOP10表中的code字段</span></span><br><span class="line">q = query(finance.STK_SHAREHOLDER_TOP10.code,</span><br><span class="line">          <span class="comment">#以及shareholder_rank字段</span></span><br><span class="line">         finance.STK_SHAREHOLDER_TOP10.shareholder_rank,</span><br><span class="line">          <span class="comment">#shareholder_name字段</span></span><br><span class="line">         finance.STK_SHAREHOLDER_TOP10.shareholder_name,</span><br><span class="line">          <span class="comment">#shareholder_class字段</span></span><br><span class="line">         finance.STK_SHAREHOLDER_TOP10.shareholder_class,</span><br><span class="line">          <span class="comment">#还有share_ration字段</span></span><br><span class="line">         finance.STK_SHAREHOLDER_TOP10.share_ratio).<span class="built_in">filter</span>(finance.STK_SHAREHOLDER_TOP10.code == <span class="string">&#x27;002458.XSHE&#x27;</span>,</span><br><span class="line">        <span class="comment">#发布市间晚于2020年1月1日</span></span><br><span class="line">       finance.STK_SHAREHOLDER_TOP10.pub_date &gt; <span class="string">&#x27;2020-01-01&#x27;</span>)</span><br><span class="line"><span class="comment">#执行这个query，返回一个dataframe</span></span><br><span class="line">shareholders = finance.run_query(q)</span><br><span class="line"><span class="comment">#查看返回的结果</span></span><br><span class="line">shareholders</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>code</th>
      <th>shareholder_rank</th>
      <th>shareholder_name</th>
      <th>shareholder_class</th>
      <th>share_ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>002458.XSHE</td>
      <td>1</td>
      <td>曹积生</td>
      <td>自然人</td>
      <td>41.64</td>
    </tr>
    <tr>
      <th>1</th>
      <td>002458.XSHE</td>
      <td>2</td>
      <td>迟汉东</td>
      <td>自然人</td>
      <td>3.09</td>
    </tr>
    <tr>
      <th>2</th>
      <td>002458.XSHE</td>
      <td>3</td>
      <td>香港中央结算有限公司</td>
      <td>其他机构</td>
      <td>1.89</td>
    </tr>
    <tr>
      <th>3</th>
      <td>002458.XSHE</td>
      <td>4</td>
      <td>李玲</td>
      <td>自然人</td>
      <td>1.41</td>
    </tr>
    <tr>
      <th>4</th>
      <td>002458.XSHE</td>
      <td>5</td>
      <td>耿培梁</td>
      <td>自然人</td>
      <td>1.16</td>
    </tr>
    <tr>
      <th>5</th>
      <td>002458.XSHE</td>
      <td>6</td>
      <td>中国农业银行股份有限公司-银华内需精选混合型证券投资基金（LOF）</td>
      <td>证券投资基金</td>
      <td>1.09</td>
    </tr>
    <tr>
      <th>6</th>
      <td>002458.XSHE</td>
      <td>7</td>
      <td>东方邦信创业投资有限公司</td>
      <td>风险投资</td>
      <td>1.02</td>
    </tr>
    <tr>
      <th>7</th>
      <td>002458.XSHE</td>
      <td>8</td>
      <td>柳炳兰</td>
      <td>自然人</td>
      <td>0.96</td>
    </tr>
    <tr>
      <th>8</th>
      <td>002458.XSHE</td>
      <td>9</td>
      <td>交通银行股份有限公司-工银瑞信双利债券型证券投资基金</td>
      <td>证券投资基金</td>
      <td>0.88</td>
    </tr>
    <tr>
      <th>9</th>
      <td>002458.XSHE</td>
      <td>10</td>
      <td>李秀国</td>
      <td>自然人</td>
      <td>0.79</td>
    </tr>
    <tr>
      <th>10</th>
      <td>002458.XSHE</td>
      <td>1</td>
      <td>曹积生</td>
      <td>自然人</td>
      <td>41.45</td>
    </tr>
    <tr>
      <th>11</th>
      <td>002458.XSHE</td>
      <td>2</td>
      <td>迟汉东</td>
      <td>自然人</td>
      <td>3.22</td>
    </tr>
    <tr>
      <th>12</th>
      <td>002458.XSHE</td>
      <td>3</td>
      <td>李玲</td>
      <td>自然人</td>
      <td>1.41</td>
    </tr>
    <tr>
      <th>13</th>
      <td>002458.XSHE</td>
      <td>4</td>
      <td>耿培梁</td>
      <td>自然人</td>
      <td>1.29</td>
    </tr>
    <tr>
      <th>14</th>
      <td>002458.XSHE</td>
      <td>5</td>
      <td>中国农业银行股份有限公司-银华内需精选混合型证券投资基金(LOF)</td>
      <td>证券投资基金</td>
      <td>1.03</td>
    </tr>
    <tr>
      <th>15</th>
      <td>002458.XSHE</td>
      <td>6</td>
      <td>柳炳兰</td>
      <td>自然人</td>
      <td>0.96</td>
    </tr>
    <tr>
      <th>16</th>
      <td>002458.XSHE</td>
      <td>7</td>
      <td>香港中央结算有限公司</td>
      <td>其他机构</td>
      <td>0.85</td>
    </tr>
    <tr>
      <th>17</th>
      <td>002458.XSHE</td>
      <td>8</td>
      <td>李秀国</td>
      <td>自然人</td>
      <td>0.78</td>
    </tr>
    <tr>
      <th>18</th>
      <td>002458.XSHE</td>
      <td>9</td>
      <td>任升浩</td>
      <td>自然人</td>
      <td>0.62</td>
    </tr>
    <tr>
      <th>19</th>
      <td>002458.XSHE</td>
      <td>10</td>
      <td>杨玲</td>
      <td>自然人</td>
      <td>0.42</td>
    </tr>
    <tr>
      <th>20</th>
      <td>002458.XSHE</td>
      <td>1</td>
      <td>曹积生</td>
      <td>自然人</td>
      <td>41.25</td>
    </tr>
    <tr>
      <th>21</th>
      <td>002458.XSHE</td>
      <td>2</td>
      <td>迟汉东</td>
      <td>自然人</td>
      <td>3.28</td>
    </tr>
    <tr>
      <th>22</th>
      <td>002458.XSHE</td>
      <td>3</td>
      <td>李玲</td>
      <td>自然人</td>
      <td>1.41</td>
    </tr>
    <tr>
      <th>23</th>
      <td>002458.XSHE</td>
      <td>4</td>
      <td>耿培梁</td>
      <td>自然人</td>
      <td>1.35</td>
    </tr>
    <tr>
      <th>24</th>
      <td>002458.XSHE</td>
      <td>5</td>
      <td>柳炳兰</td>
      <td>自然人</td>
      <td>0.95</td>
    </tr>
    <tr>
      <th>25</th>
      <td>002458.XSHE</td>
      <td>6</td>
      <td>李秀国</td>
      <td>自然人</td>
      <td>0.78</td>
    </tr>
    <tr>
      <th>26</th>
      <td>002458.XSHE</td>
      <td>7</td>
      <td>香港中央结算有限公司</td>
      <td>其他机构</td>
      <td>0.70</td>
    </tr>
    <tr>
      <th>27</th>
      <td>002458.XSHE</td>
      <td>8</td>
      <td>任升浩</td>
      <td>自然人</td>
      <td>0.62</td>
    </tr>
    <tr>
      <th>28</th>
      <td>002458.XSHE</td>
      <td>9</td>
      <td>北京正华宝意控股有限公司</td>
      <td>其他机构</td>
      <td>0.59</td>
    </tr>
    <tr>
      <th>29</th>
      <td>002458.XSHE</td>
      <td>10</td>
      <td>杨玲</td>
      <td>自然人</td>
      <td>0.42</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>90</th>
      <td>002458.XSHE</td>
      <td>10</td>
      <td>杨玲</td>
      <td>自然人</td>
      <td>0.42</td>
    </tr>
    <tr>
      <th>91</th>
      <td>002458.XSHE</td>
      <td>9</td>
      <td>浙商银行股份有限公司-国泰中证畜牧养殖交易型开放式指数证券投资基金</td>
      <td>证券投资基金</td>
      <td>0.44</td>
    </tr>
    <tr>
      <th>92</th>
      <td>002458.XSHE</td>
      <td>8</td>
      <td>任升浩</td>
      <td>自然人</td>
      <td>0.62</td>
    </tr>
    <tr>
      <th>93</th>
      <td>002458.XSHE</td>
      <td>7</td>
      <td>李秀国</td>
      <td>自然人</td>
      <td>0.78</td>
    </tr>
    <tr>
      <th>94</th>
      <td>002458.XSHE</td>
      <td>6</td>
      <td>香港中央结算有限公司</td>
      <td>其他机构</td>
      <td>0.95</td>
    </tr>
    <tr>
      <th>95</th>
      <td>002458.XSHE</td>
      <td>5</td>
      <td>耿培梁</td>
      <td>自然人</td>
      <td>1.05</td>
    </tr>
    <tr>
      <th>96</th>
      <td>002458.XSHE</td>
      <td>4</td>
      <td>柳炳兰</td>
      <td>自然人</td>
      <td>1.25</td>
    </tr>
    <tr>
      <th>97</th>
      <td>002458.XSHE</td>
      <td>3</td>
      <td>李玲</td>
      <td>自然人</td>
      <td>2.01</td>
    </tr>
    <tr>
      <th>98</th>
      <td>002458.XSHE</td>
      <td>2</td>
      <td>迟汉东</td>
      <td>自然人</td>
      <td>2.66</td>
    </tr>
    <tr>
      <th>99</th>
      <td>002458.XSHE</td>
      <td>1</td>
      <td>曹积生</td>
      <td>自然人</td>
      <td>41.14</td>
    </tr>
    <tr>
      <th>100</th>
      <td>002458.XSHE</td>
      <td>10</td>
      <td>浙商银行股份有限公司-国泰中证畜牧养殖交易型开放式指数证券投资基金</td>
      <td>证券投资基金</td>
      <td>0.60</td>
    </tr>
    <tr>
      <th>101</th>
      <td>002458.XSHE</td>
      <td>9</td>
      <td>任升浩</td>
      <td>自然人</td>
      <td>0.62</td>
    </tr>
    <tr>
      <th>102</th>
      <td>002458.XSHE</td>
      <td>8</td>
      <td>李秀国</td>
      <td>自然人</td>
      <td>0.78</td>
    </tr>
    <tr>
      <th>103</th>
      <td>002458.XSHE</td>
      <td>7</td>
      <td>耿培梁</td>
      <td>自然人</td>
      <td>1.05</td>
    </tr>
    <tr>
      <th>104</th>
      <td>002458.XSHE</td>
      <td>6</td>
      <td>香港中央结算有限公司</td>
      <td>其他机构</td>
      <td>1.07</td>
    </tr>
    <tr>
      <th>105</th>
      <td>002458.XSHE</td>
      <td>5</td>
      <td>柳炳兰</td>
      <td>自然人</td>
      <td>1.25</td>
    </tr>
    <tr>
      <th>106</th>
      <td>002458.XSHE</td>
      <td>4</td>
      <td>李玲</td>
      <td>自然人</td>
      <td>2.01</td>
    </tr>
    <tr>
      <th>107</th>
      <td>002458.XSHE</td>
      <td>3</td>
      <td>迟汉东</td>
      <td>自然人</td>
      <td>2.66</td>
    </tr>
    <tr>
      <th>108</th>
      <td>002458.XSHE</td>
      <td>2</td>
      <td>深圳毕升私募证券基金管理有限公司-必胜年年升1号私募基金</td>
      <td>证券投资基金</td>
      <td>2.71</td>
    </tr>
    <tr>
      <th>109</th>
      <td>002458.XSHE</td>
      <td>1</td>
      <td>曹积生</td>
      <td>自然人</td>
      <td>41.14</td>
    </tr>
    <tr>
      <th>110</th>
      <td>002458.XSHE</td>
      <td>10</td>
      <td>香港中央结算有限公司</td>
      <td>其他机构</td>
      <td>0.77</td>
    </tr>
    <tr>
      <th>111</th>
      <td>002458.XSHE</td>
      <td>9</td>
      <td>李秀国</td>
      <td>自然人</td>
      <td>0.78</td>
    </tr>
    <tr>
      <th>112</th>
      <td>002458.XSHE</td>
      <td>8</td>
      <td>中信证券-中信银行-中信证券红利价值一年持有混合型集合资产管理计划</td>
      <td>券商资产管理计划</td>
      <td>1.04</td>
    </tr>
    <tr>
      <th>113</th>
      <td>002458.XSHE</td>
      <td>7</td>
      <td>耿培梁</td>
      <td>自然人</td>
      <td>1.05</td>
    </tr>
    <tr>
      <th>114</th>
      <td>002458.XSHE</td>
      <td>6</td>
      <td>中信建投证券股份有限公司</td>
      <td>券商和上市公司</td>
      <td>1.13</td>
    </tr>
    <tr>
      <th>115</th>
      <td>002458.XSHE</td>
      <td>5</td>
      <td>柳炳兰</td>
      <td>自然人</td>
      <td>1.25</td>
    </tr>
    <tr>
      <th>116</th>
      <td>002458.XSHE</td>
      <td>4</td>
      <td>李玲</td>
      <td>自然人</td>
      <td>2.01</td>
    </tr>
    <tr>
      <th>117</th>
      <td>002458.XSHE</td>
      <td>3</td>
      <td>深圳毕升私募证券基金管理有限公司-必胜年年升1号私募基金</td>
      <td>证券投资基金</td>
      <td>2.11</td>
    </tr>
    <tr>
      <th>118</th>
      <td>002458.XSHE</td>
      <td>2</td>
      <td>迟汉东</td>
      <td>自然人</td>
      <td>2.66</td>
    </tr>
    <tr>
      <th>119</th>
      <td>002458.XSHE</td>
      <td>1</td>
      <td>曹积生</td>
      <td>自然人</td>
      <td>41.14</td>
    </tr>
  </tbody>
</table>
<p>120 rows × 5 columns</p>
</div>



<p>系统返回了是大股东信息，其中shareholder_rank字段是股东的持股排名；shareholder_name字段是股东名称；shareholder_class字段是股东类型；share_ratio字段是股东的持股比例</p>
<h3 id="4-3-2-大股东们增持了还是减持了"><a href="#4-3-2-大股东们增持了还是减持了" class="headerlink" title="4.3.2 大股东们增持了还是减持了"></a>4.3.2 大股东们增持了还是减持了</h3><p>如果大股东对公司未来发展有信心，一般会<strong>增持</strong>公司的股票，以便在未来获取更高的收益；相反，如果大股东认为短期股价已经见顶，则可能会<strong>减持</strong>一些股票，将已经获利的部分进行<strong>套现</strong>。也就是说，如果大股东增持了股票，则股价有可能上涨，反之股价有可能下降。当然，这也不是绝对的——有时候大股东的判断也可能出现失误。</p>
<p>我们可以了解一下大股东们的动作，可以使用query object来查询STK+SHAREHOLDERS_SHARE_CHANGE这张表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个query object</span></span><br><span class="line"><span class="comment">#查询STK_SHAREHOLDERS_SHARE_CHANGE表的code字段</span></span><br><span class="line">q = query(finance.STK_SHAREHOLDERS_SHARE_CHANGE.code,</span><br><span class="line">          <span class="comment">#pub_date字段</span></span><br><span class="line">          finance.STK_SHAREHOLDERS_SHARE_CHANGE.pub_date,</span><br><span class="line">          <span class="comment">#shareholder_name字段</span></span><br><span class="line">         finance.STK_SHAREHOLDERS_SHARE_CHANGE.shareholder_name,</span><br><span class="line">          <span class="comment">#type字段</span></span><br><span class="line">         finance.STK_SHAREHOLDERS_SHARE_CHANGE.<span class="built_in">type</span>,</span><br><span class="line">          <span class="comment">#change_number字段</span></span><br><span class="line">         finance.STK_SHAREHOLDERS_SHARE_CHANGE.change_number,</span><br><span class="line">          <span class="comment">#change_ratio字段</span></span><br><span class="line">         finance.STK_SHAREHOLDERS_SHARE_CHANGE.change_ratio,</span><br><span class="line">          <span class="comment">#after_change_ratio字段</span></span><br><span class="line">         finance.STK_SHAREHOLDERS_SHARE_CHANGE.after_change_ratio).<span class="built_in">filter</span>(finance.STK_SHAREHOLDERS_SHARE_CHANGE.code == <span class="string">&#x27;002458.XSHE&#x27;</span>,</span><br><span class="line">        <span class="comment">#且发布日期晚于2019年9月1日</span></span><br><span class="line">       finance.STK_SHAREHOLDERS_SHARE_CHANGE.pub_date &gt; <span class="string">&#x27;2019-09-01&#x27;</span>)</span><br><span class="line"><span class="comment">#执行这个query，返回一个dataframe</span></span><br><span class="line">shrchg = finance.run_query(q)</span><br><span class="line"><span class="comment">#查看返回的结果</span></span><br><span class="line">shrchg</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>code</th>
      <th>pub_date</th>
      <th>shareholder_name</th>
      <th>type</th>
      <th>change_number</th>
      <th>change_ratio</th>
      <th>after_change_ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>耿培梁</td>
      <td>1</td>
      <td>122000.0</td>
      <td>0.021</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>耿培梁</td>
      <td>1</td>
      <td>719300.0</td>
      <td>0.125</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>耿培梁</td>
      <td>1</td>
      <td>10000.0</td>
      <td>0.002</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>纪永梅</td>
      <td>1</td>
      <td>2100.0</td>
      <td>0.000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>耿培梁</td>
      <td>1</td>
      <td>62000.0</td>
      <td>0.011</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>耿培梁</td>
      <td>1</td>
      <td>234000.0</td>
      <td>0.041</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>耿培梁</td>
      <td>0</td>
      <td>782600.0</td>
      <td>0.136</td>
      <td>1.168</td>
    </tr>
    <tr>
      <th>7</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>纪永梅</td>
      <td>1</td>
      <td>187770.0</td>
      <td>0.033</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>002458.XSHE</td>
      <td>2019-09-25</td>
      <td>耿培梁</td>
      <td>1</td>
      <td>782600.0</td>
      <td>0.136</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>9</th>
      <td>002458.XSHE</td>
      <td>2020-02-22</td>
      <td>赵桂苹</td>
      <td>0</td>
      <td>1000.0</td>
      <td>0.000</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>10</th>
      <td>002458.XSHE</td>
      <td>2022-04-26</td>
      <td>公司2022年员工持股计划</td>
      <td>0</td>
      <td>1204600.0</td>
      <td>0.120</td>
      <td>0.120</td>
    </tr>
  </tbody>
</table>
</div>



<p>从这张表可以看出，系统返回了2019年9月1日以后公布的该股票的大股东增减持数据。其中，在type字段中，0表示增持，1表示减持；change_number字段存储的是增减持的股票数量；change_ratio字段存储的是持股变动数量占总股本的比例；after_change_ratio字段存储的是大股东持股数量变化后持股数量占总股本的比例。</p>
<p>例如，耿培梁这位股东，其增减持比较频繁，其中最引人注目的是其先增持了782600股，接着减持了等量的股票，这有可能是该股东在某个时间段获利套现了。</p>
<h3 id="4-3-3-资金净流入还是净流出"><a href="#4-3-3-资金净流入还是净流出" class="headerlink" title="4.3.3 资金净流入还是净流出"></a>4.3.3 资金净流入还是净流出</h3><p>我们可以获取时效性更高的数据——资金流向数据，以便看到主力的实时动向。</p>
<p>要做到这一点，我们只需要调用平台的get_money_flow函数即可，并指定查询的股票代码、日期和要查看的字段。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#从jgdata中导入全部函数</span></span><br><span class="line"><span class="keyword">from</span> jqdata <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用get_money_flow函数获取002458的资金流向数据</span></span><br><span class="line">mf = get_money_flow(<span class="string">&#x27;002458.XSHE&#x27;</span>,</span><br><span class="line">                   <span class="comment">#截止日期为2020年4月3日</span></span><br><span class="line">                   end_date = <span class="string">&#x27;2020-04-03&#x27;</span>,</span><br><span class="line">                    <span class="comment">#获取字段包括日期</span></span><br><span class="line">                   fields = [<span class="string">&#x27;date&#x27;</span>,</span><br><span class="line">                             <span class="comment">#股票代码</span></span><br><span class="line">                           <span class="string">&#x27;sec_code&#x27;</span>,</span><br><span class="line">                             <span class="comment">#涨跌幅</span></span><br><span class="line">                           <span class="string">&#x27;change_pct&#x27;</span>,</span><br><span class="line">                             <span class="comment">#主力金额，包括超大单和大单</span></span><br><span class="line">                           <span class="string">&#x27;net_amount_main&#x27;</span>,</span><br><span class="line">                             <span class="comment">#主力成交额占总成交额的比例</span></span><br><span class="line">                           <span class="string">&#x27;net_pct_main&#x27;</span>],</span><br><span class="line">                    <span class="comment">#获取10个交易日的数据</span></span><br><span class="line">                   count = <span class="number">10</span>)</span><br><span class="line"><span class="comment">#查看结果</span></span><br><span class="line">mf</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>sec_code</th>
      <th>change_pct</th>
      <th>net_amount_main</th>
      <th>net_pct_main</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2020-03-23</td>
      <td>002458.XSHE</td>
      <td>-9.99</td>
      <td>-11561.8543</td>
      <td>-17.0788</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2020-03-24</td>
      <td>002458.XSHE</td>
      <td>0.53</td>
      <td>-4068.5285</td>
      <td>-7.1877</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2020-03-25</td>
      <td>002458.XSHE</td>
      <td>7.25</td>
      <td>1817.5482</td>
      <td>2.1306</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2020-03-26</td>
      <td>002458.XSHE</td>
      <td>2.36</td>
      <td>-2352.3292</td>
      <td>-2.5584</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2020-03-27</td>
      <td>002458.XSHE</td>
      <td>-0.85</td>
      <td>-5059.1633</td>
      <td>-8.0721</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2020-03-30</td>
      <td>002458.XSHE</td>
      <td>6.96</td>
      <td>4476.8310</td>
      <td>4.2767</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2020-03-31</td>
      <td>002458.XSHE</td>
      <td>8.57</td>
      <td>-2550.2537</td>
      <td>-1.6243</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2020-04-01</td>
      <td>002458.XSHE</td>
      <td>1.00</td>
      <td>-2896.5712</td>
      <td>-1.7715</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2020-04-02</td>
      <td>002458.XSHE</td>
      <td>-1.09</td>
      <td>-10572.1955</td>
      <td>-9.4150</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2020-04-03</td>
      <td>002458.XSHE</td>
      <td>-0.37</td>
      <td>-4050.7753</td>
      <td>-3.4890</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：截至2020年4月3日的10个交易日中，主力资金整体呈现出净流出的状态。尤其在3月23日，主力资金流出超过1.1亿元；4月2日这一天，主力资金流出也超过1亿元。</p>
<p>仔细观察，会发现3月25日这一天，股价上涨了7.25%，主力资金净流入超过1817万元，次日股价上涨了2.36%；同时，在3月30日，股价上涨了6.96%，主力资金净流入超过4476万元，次日股价上涨了8.57%。</p>
<p>这是否意味着如果该股某日股价上涨，且主力资金净流入的话，下一个交易日的股价会上涨呢？假如真的存在这个规律，我们是否可以把这两个数据处理成一个<strong>特征</strong>（或者说一个因子），用来预测股价的涨跌呢？</p>
<p>因子交易的基本思路：将诸多数据通过计算整理成不同因子，并据此制定交易策略。</p>
<h1 id="第五章-因子来了——基本原理和用法"><a href="#第五章-因子来了——基本原理和用法" class="headerlink" title="第五章 因子来了——基本原理和用法"></a>第五章 因子来了——基本原理和用法</h1><h2 id="5-1-“瓦氏因子”了解一下"><a href="#5-1-“瓦氏因子”了解一下" class="headerlink" title="5.1 “瓦氏因子”了解一下"></a>5.1 “瓦氏因子”了解一下</h2><h3 id="5-1-1-获取主力资金流向数据"><a href="#5-1-1-获取主力资金流向数据" class="headerlink" title="5.1.1 获取主力资金流向数据"></a>5.1.1 获取主力资金流向数据</h3><p>在上一章中，我们用get_money_flow函数获取了股票的资金流入&#x2F;流出数据，并且发现了一个可能存在的规律——某日该股票价格上涨，且主力资金净流入的话，次日股价可能上涨；否则股价下跌。</p>
<p>为了进行实验，再次获取股票的资金流入&#x2F;流出数据。为了便于后面训练模型，这次将数据的时间范围扩大至两年</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入jqdata的全部函数</span></span><br><span class="line"><span class="keyword">from</span> jqdata <span class="keyword">import</span> *</span><br><span class="line"><span class="comment">#使用get_money_flow函数获取</span></span><br><span class="line">df = get_money_flow(<span class="string">&#x27;002458.XSHE&#x27;</span>,</span><br><span class="line">                    fields = [<span class="string">&#x27;date&#x27;</span>,</span><br><span class="line">                             <span class="comment">#股票代码</span></span><br><span class="line">                           <span class="string">&#x27;sec_code&#x27;</span>,</span><br><span class="line">                             <span class="comment">#涨跌幅</span></span><br><span class="line">                           <span class="string">&#x27;change_pct&#x27;</span>,</span><br><span class="line">                             <span class="comment">#主力金额，包括超大单和大单</span></span><br><span class="line">                           <span class="string">&#x27;net_amount_main&#x27;</span>,</span><br><span class="line">                             <span class="comment">#主力成交额占总成交额的比例</span></span><br><span class="line">                           <span class="string">&#x27;net_pct_main&#x27;</span>],</span><br><span class="line">                    <span class="comment">#设置好起止日期</span></span><br><span class="line">                    start_date = <span class="string">&#x27;2018-04-09&#x27;</span>,</span><br><span class="line">                    end_date = <span class="string">&#x27;2020-04-08&#x27;</span>)</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>sec_code</th>
      <th>change_pct</th>
      <th>net_amount_main</th>
      <th>net_pct_main</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2018-04-09</td>
      <td>002458.XSHE</td>
      <td>-0.84</td>
      <td>-570.2092</td>
      <td>-8.7478</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018-04-10</td>
      <td>002458.XSHE</td>
      <td>-2.55</td>
      <td>-360.5189</td>
      <td>-4.4665</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2018-04-11</td>
      <td>002458.XSHE</td>
      <td>0.44</td>
      <td>-601.2525</td>
      <td>-6.2953</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2018-04-12</td>
      <td>002458.XSHE</td>
      <td>-1.01</td>
      <td>168.3327</td>
      <td>2.9341</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2018-04-13</td>
      <td>002458.XSHE</td>
      <td>-0.73</td>
      <td>-81.8302</td>
      <td>-1.5589</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="5-1-2-简易特征工程"><a href="#5-1-2-简易特征工程" class="headerlink" title="5.1.2 简易特征工程"></a>5.1.2 简易特征工程</h3><p>下面我们给原始数据增加两个新的字段，其中一个是up_or_down，用来表示当日股价是上涨还是下跌。如果change_pct（涨幅）这个字段为正数，说明股价上涨，则up_or_down用1来表示，反之，用0来表示，代表当日股价下跌。</p>
<p>类似，我们用money_in_out字段表示主力资金净流入还是净流出。如果net_amount_main大于0，说明主力资金净流入，则在money_in_out字段用1表示；反之说明主力资金净流出，money_in_out字段用0表示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#增加一个字段，记录股价上涨还是下跌</span></span><br><span class="line"><span class="comment">#如果股价上涨，则以1标记，否则以0标记</span></span><br><span class="line">df[<span class="string">&#x27;up_or_down&#x27;</span>] = np.where(df[<span class="string">&#x27;change_pct&#x27;</span>]&gt;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment">#在增加一个字段，记录主力资金净流入还是流出</span></span><br><span class="line"><span class="comment">#如果净流入，标记为1，否则标记为0</span></span><br><span class="line">df[<span class="string">&#x27;money_in_out&#x27;</span>] = np.where(df[<span class="string">&#x27;net_amount_main&#x27;</span>]&gt;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>sec_code</th>
      <th>change_pct</th>
      <th>net_amount_main</th>
      <th>net_pct_main</th>
      <th>up_or_down</th>
      <th>money_in_out</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2018-04-09</td>
      <td>002458.XSHE</td>
      <td>-0.84</td>
      <td>-570.2092</td>
      <td>-8.7478</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018-04-10</td>
      <td>002458.XSHE</td>
      <td>-2.55</td>
      <td>-360.5189</td>
      <td>-4.4665</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2018-04-11</td>
      <td>002458.XSHE</td>
      <td>0.44</td>
      <td>-601.2525</td>
      <td>-6.2953</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2018-04-12</td>
      <td>002458.XSHE</td>
      <td>-1.01</td>
      <td>168.3327</td>
      <td>2.9341</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2018-04-13</td>
      <td>002458.XSHE</td>
      <td>-0.73</td>
      <td>-81.8302</td>
      <td>-1.5589</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="5-1-3-“瓦氏因子”的计算"><a href="#5-1-3-“瓦氏因子”的计算" class="headerlink" title="5.1.3 “瓦氏因子”的计算"></a>5.1.3 “瓦氏因子”的计算</h3><p>我们现在有两个新的特征，能够体现股价的涨跌和主力资金的流入&#x2F;流出情况，下面就可以用这两个新的特征来计算“瓦氏因子”</p>
<p><strong>思路</strong>：如果我们把两个特征相乘，则股价上涨，且主力资金净流入时，因子值就是up_or_down乘以money_in_out，也就是1x1&#x3D;1；而其他情况，“瓦氏因子”的数值都为0。例如，股价下跌但主力资金净流入，“瓦氏因子”为0x1，结果为0。同时，为了后面便于训练模型，我们还需要做一个标签（即次日股票上涨还是下跌），存储在next_day字段中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#瓦氏因子来了，用两个自增的字段相乘，得出因子值</span></span><br><span class="line">df[<span class="string">&#x27;factor_wa&#x27;</span>] = df[<span class="string">&#x27;up_or_down&#x27;</span>] * df[<span class="string">&#x27;money_in_out&#x27;</span>]</span><br><span class="line"><span class="comment">#再把次日涨跌作为预测标签存储到‘next_day’字段</span></span><br><span class="line">df[<span class="string">&#x27;next_day&#x27;</span>] = df[<span class="string">&#x27;up_or_down&#x27;</span>].shift(-<span class="number">1</span>)</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>sec_code</th>
      <th>change_pct</th>
      <th>net_amount_main</th>
      <th>net_pct_main</th>
      <th>up_or_down</th>
      <th>money_in_out</th>
      <th>factor_wa</th>
      <th>next_day</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2018-04-09</td>
      <td>002458.XSHE</td>
      <td>-0.84</td>
      <td>-570.2092</td>
      <td>-8.7478</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018-04-10</td>
      <td>002458.XSHE</td>
      <td>-2.55</td>
      <td>-360.5189</td>
      <td>-4.4665</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2018-04-11</td>
      <td>002458.XSHE</td>
      <td>0.44</td>
      <td>-601.2525</td>
      <td>-6.2953</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2018-04-12</td>
      <td>002458.XSHE</td>
      <td>-1.01</td>
      <td>168.3327</td>
      <td>2.9341</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2018-04-13</td>
      <td>002458.XSHE</td>
      <td>-0.73</td>
      <td>-81.8302</td>
      <td>-1.5589</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：“瓦氏因子”字段factor_wa添加成功。例如,2018年4月10日，股价下跌，主力资金净流出，“瓦氏因子”的值是0；2018年4月11日，股价上涨，主力资金还是净流出，“瓦氏因子”还是0.</p>
<p>再看next_day字段，2018年4月11日，股价上涨，因此2018年4月11日这一天的next_day字段中的数值是1；2018年4月12日，股价下跌，因此2018年4月11日这一天的next_day字段中的数值是0.</p>
<h3 id="5-1-4-用添加的“瓦氏因子”的数据训练模型"><a href="#5-1-4-用添加的“瓦氏因子”的数据训练模型" class="headerlink" title="5.1.4 用添加的“瓦氏因子”的数据训练模型"></a>5.1.4 用添加的“瓦氏因子”的数据训练模型</h3><p>来试试在数据集中加入这个因子后，模型的预测准确率是否会提高</p>
<p>下面准备训练模型用的数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#还是请出已经熟悉的KNN算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="comment">#导入数据集拆分工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment">#当然还需要有pandas</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment">#数据集中把日期、股票代码，以及我们添加的特征去掉</span></span><br><span class="line">dataset = df.drop([<span class="string">&#x27;date&#x27;</span>, </span><br><span class="line">                   <span class="string">&#x27;sec_code&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;up_or_down&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;money_in_out&#x27;</span>],</span><br><span class="line">                  axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>change_pct</th>
      <th>net_amount_main</th>
      <th>net_pct_main</th>
      <th>factor_wa</th>
      <th>next_day</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.84</td>
      <td>-570.2092</td>
      <td>-8.7478</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-2.55</td>
      <td>-360.5189</td>
      <td>-4.4665</td>
      <td>0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.44</td>
      <td>-601.2525</td>
      <td>-6.2953</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.01</td>
      <td>168.3327</td>
      <td>2.9341</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.73</td>
      <td>-81.8302</td>
      <td>-1.5589</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>



<p>处理成功，与训练模型无关的字段已经去掉了，只剩下特征和标签了</p>
<p>因为最后一天是没有next_day数据的（因为对于最后一天来说，下一个交易日还没到来），所以我们要去掉最后一行数据；同时，把除标签以外的特征赋给X，把标签付给y；再使用数据集拆分工具，将X和y分别拆分成训练集和验证集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将‘next_day’以外的字段，作为数据集的特征</span></span><br><span class="line">X = dataset.drop([<span class="string">&#x27;next_day&#x27;</span>],axis=<span class="number">1</span>)[:-<span class="number">1</span>]</span><br><span class="line"><span class="comment">#将‘next_day’作为数据集的标签</span></span><br><span class="line">y = dataset[<span class="string">&#x27;next_day&#x27;</span>][:-<span class="number">1</span>]</span><br><span class="line"><span class="comment">#将数据集拆分为训练集与验证集</span></span><br><span class="line">X_train, X_test, y_train, y_test =train_test_split(X, y, random_state = <span class="number">28</span>)</span><br></pre></td></tr></table></figure>

<p>为了便于复现，上面的代码指定random_state为28.这样，即使多次运行代码，输出结果也不会不同</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建KNN分类器，n_neighbors参数依然取95</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">95</span>)</span><br><span class="line"><span class="comment">#使用训练集训练模型</span></span><br><span class="line">knn.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#打印训练集中模型准确率</span></span><br><span class="line"><span class="built_in">print</span>(knn.score(X_train, y_train))</span><br><span class="line"><span class="comment">#打印验证集中模型准确率</span></span><br><span class="line"><span class="built_in">print</span>(knn.score(X_test,y_test))</span><br></pre></td></tr></table></figure>

<pre><code>0.5671232876712329
0.5573770491803278
</code></pre>
<p>可见在添加瓦氏因子后，模型的预测准确率有了提高——同样的参数，模型在验证集中的准确率从54.1%提高到了55.7%</p>
<h3 id="5-1-5-“因子”能干啥"><a href="#5-1-5-“因子”能干啥" class="headerlink" title="5.1.5 “因子”能干啥"></a>5.1.5 “因子”能干啥</h3><p>经过这么多年的研究，因子的计算越来越复杂</p>
<p>总而言之，因子其实解决的就是两个问题：<strong>1.买谁</strong>，<strong>2.什么时候买和什么时候卖</strong>（《打开量化投资的黑箱》中也介绍了）</p>
<p>解决“买谁”这个问题的因子，一般称为<strong>量化选股因子</strong></p>
<p>解决“什么时候买和什么时候卖”这个问题的因子，一般称为<strong>量化择时</strong>因子</p>
<p>也就是说，我们首先要通过选股因子确定投资标的。一旦确定投资标的之后，我们就要研究买卖的时机了，这个时候就可以使用量化择时因子：找到股票可能上涨的时机，并进行买入；找到股票可能下跌的时机，并进行卖出。在这个过程中，我们可以考虑用的因子就非常多了，如比较传统的动量因子、情绪因子，以及比较玄学的Alpha101因子、alpha191因子等</p>
<h2 id="5-2-股票不知道怎么选？因子来帮忙"><a href="#5-2-股票不知道怎么选？因子来帮忙" class="headerlink" title="5.2 股票不知道怎么选？因子来帮忙"></a>5.2 股票不知道怎么选？因子来帮忙</h2><p>选股，即买谁</p>
<h3 id="5-2-1-确定股票池"><a href="#5-2-1-确定股票池" class="headerlink" title="5.2.1 确定股票池"></a>5.2.1 确定股票池</h3><p>沪深300、上证50、中证100、中证200、中证500</p>
<p><strong>沪深300</strong>:从上海证券交易所和深圳证券交易所跳出经营状况良好、规模庞大且流动性非常高的300只股票组成的指数，<strong>体现大盘股的走势</strong></p>
<p><strong>上证50</strong>：上海交易所中规模较大、流动性较高的50只股票组成的指数，<strong>体现超大盘股的走势</strong></p>
<p><strong>中证500</strong>：在沪深两市中，选出市值较高的800只股票，再把沪深300中的股票剔除出去，余下的500只股票组成的指数。体现<strong>中小盘股的走势</strong></p>
<p>这三个指数没有好坏之分，只是风格不同。</p>
<p>中证500虽然代表中小盘股的走势，但是由于A股市场经过这么多年的发展，这些所谓的中小盘股的体量也要比创业板、中小板这些板块上的股票大得多。</p>
<p>所以，我们稳中求进，不管赚不赚到钱，要保证资金的安全，因此选择沪深300成分股作为选股的“股票池”，并结合量化选股因子，找到财务状况最好、发展前景最好的企业的股票，作为未来投资标的</p>
<h3 id="5-2-2-获取沪深两市的全部指数"><a href="#5-2-2-获取沪深两市的全部指数" class="headerlink" title="5.2.2 获取沪深两市的全部指数"></a>5.2.2 获取沪深两市的全部指数</h3><p>在聚宽平台上，我们可以通过get_all_securities函数，查询到全部指数的带啊吗、中文名称、简称、起止日期等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里需要导入聚宽因子库的get_factor_values函数</span></span><br><span class="line"><span class="keyword">from</span> jqfactor <span class="keyword">import</span> get_factor_values</span><br><span class="line"><span class="comment">#当然后面也要用到pandas</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>

<p>思路是选超大盘股，净利润率高，且高速成长的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定get_all_securities的types参数为index</span></span><br><span class="line"><span class="comment">#即可查询全部指数</span></span><br><span class="line">indices = get_all_securities(types=[<span class="string">&#x27;index&#x27;</span>])</span><br><span class="line"><span class="comment">#查看前十条结果</span></span><br><span class="line">indices.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>display_name</th>
      <th>name</th>
      <th>start_date</th>
      <th>end_date</th>
      <th>type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>000001.XSHG</th>
      <td>上证指数</td>
      <td>SZZS</td>
      <td>1991-07-15</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000002.XSHG</th>
      <td>A股指数</td>
      <td>AGZS</td>
      <td>1992-02-21</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000003.XSHG</th>
      <td>B股指数</td>
      <td>BGZS</td>
      <td>1992-02-21</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000004.XSHG</th>
      <td>工业指数</td>
      <td>GYZS</td>
      <td>1993-05-03</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000005.XSHG</th>
      <td>商业指数</td>
      <td>SYZS</td>
      <td>1993-05-03</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000006.XSHG</th>
      <td>地产指数</td>
      <td>DCZS</td>
      <td>1993-05-03</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000007.XSHG</th>
      <td>公用指数</td>
      <td>GYZS</td>
      <td>1993-05-03</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000008.XSHG</th>
      <td>综合指数</td>
      <td>ZHZS</td>
      <td>1993-05-03</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000009.XSHG</th>
      <td>上证380</td>
      <td>SZ380</td>
      <td>2010-11-29</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000010.XSHG</th>
      <td>上证180</td>
      <td>SZ180</td>
      <td>2002-07-01</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000011.XSHG</th>
      <td>基金指数</td>
      <td>JJZS</td>
      <td>2000-06-09</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000012.XSHG</th>
      <td>国债指数</td>
      <td>GZZS</td>
      <td>2003-01-02</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000013.XSHG</th>
      <td>上证企业债指数</td>
      <td>QZZS</td>
      <td>2003-06-09</td>
      <td>2020-12-28</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000015.XSHG</th>
      <td>红利指数</td>
      <td>HLZS</td>
      <td>2005-01-04</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000016.XSHG</th>
      <td>上证50</td>
      <td>SZ50</td>
      <td>2004-01-02</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000017.XSHG</th>
      <td>新综指</td>
      <td>XZZ</td>
      <td>2006-01-04</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000018.XSHG</th>
      <td>180金融</td>
      <td>180JR</td>
      <td>2007-12-10</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000019.XSHG</th>
      <td>治理指数</td>
      <td>ZLZS</td>
      <td>2008-01-02</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000020.XSHG</th>
      <td>中型综指</td>
      <td>ZXZZ</td>
      <td>2008-05-12</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
    <tr>
      <th>000021.XSHG</th>
      <td>180治理</td>
      <td>180ZL</td>
      <td>2008-09-10</td>
      <td>2200-01-01</td>
      <td>index</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="5-2-3-获取股票的市值因子"><a href="#5-2-3-获取股票的市值因子" class="headerlink" title="5.2.3 获取股票的市值因子"></a>5.2.3 获取股票的市值因子</h3><p>获取沪深300成分股的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入聚宽的因子分析库</span></span><br><span class="line"><span class="keyword">from</span> jqfactor <span class="keyword">import</span> analyze_factor</span><br><span class="line"><span class="comment">#使用get_factor_values函数获取上证50成分股的市值</span></span><br><span class="line">factor_mc=get_factor_values(securities=get_index_stocks(<span class="string">&#x27;000016.XSHG&#x27;</span>), factors=[<span class="string">&#x27;market_cap&#x27;</span>],</span><br><span class="line">                  end_date=<span class="string">&#x27;2020-04-30&#x27;</span>,count=<span class="number">1</span>)[<span class="string">&#x27;market_cap&#x27;</span>]</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">factor_mc.T.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2020-04-30 00:00:00</th>
    </tr>
    <tr>
      <th>code</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>600010.XSHG</th>
      <td>4.923184e+10</td>
    </tr>
    <tr>
      <th>600028.XSHG</th>
      <td>5.399776e+11</td>
    </tr>
    <tr>
      <th>600030.XSHG</th>
      <td>3.063646e+11</td>
    </tr>
    <tr>
      <th>600031.XSHG</th>
      <td>1.657582e+11</td>
    </tr>
    <tr>
      <th>600036.XSHG</th>
      <td>8.849644e+11</td>
    </tr>
  </tbody>
</table>
</div>



<p>从表中我们看出，我们使用get_factor_values函数获得了沪深300成分股的在2020年4月30日这一天的市值数据，也就是market_cap。例如，600010在这一天的市值约为492亿元，算得上一个庞然大物了</p>
<h3 id="5-2-4-获取股票的现金流因子"><a href="#5-2-4-获取股票的现金流因子" class="headerlink" title="5.2.4 获取股票的现金流因子"></a>5.2.4 获取股票的现金流因子</h3><p>除了关心股票整体市值外，我们还想了解企业的<strong>现金流与股价的对比关系</strong>，也就是<strong>市现率</strong>这个指标的情况。毕竟大环境不好的情况下，充足的现金流才是保证企业生菜发展的前提。因此，我们来获取一下股票市现率的倒数（<strong>因为市现率越小越好，因此其倒数越大越好</strong>）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#get_factor_values中</span></span><br><span class="line"><span class="comment">#factors参数传入cash_flow_to_price_ratio</span></span><br><span class="line"><span class="comment">#即可获得市现率的倒数</span></span><br><span class="line">factor_cfp = get_factor_values(securities = get_index_stocks(<span class="string">&#x27;000016.XSHG&#x27;</span>),</span><br><span class="line">                           factors = [<span class="string">&#x27;cash_flow_to_price_ratio&#x27;</span>],</span><br><span class="line">                              end_date = <span class="string">&#x27;2020-04-30&#x27;</span>,</span><br><span class="line">                              count = <span class="number">1</span>)[<span class="string">&#x27;cash_flow_to_price_ratio&#x27;</span>]</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">factor_cfp.T.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2020-04-30 00:00:00</th>
    </tr>
    <tr>
      <th>code</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>600010.XSHG</th>
      <td>-0.009713</td>
    </tr>
    <tr>
      <th>600028.XSHG</th>
      <td>-0.046224</td>
    </tr>
    <tr>
      <th>600030.XSHG</th>
      <td>0.270966</td>
    </tr>
    <tr>
      <th>600031.XSHG</th>
      <td>0.001367</td>
    </tr>
    <tr>
      <th>600036.XSHG</th>
      <td>0.219173</td>
    </tr>
  </tbody>
</table>
</div>



<p>使用get_factor_values函数，只要指定factors参数为cash_flow_to_price_ratio，即可获得股票的市现率倒数</p>
<h3 id="5-2-5-获取股票的净利率因子"><a href="#5-2-5-获取股票的净利率因子" class="headerlink" title="5.2.5 获取股票的净利率因子"></a>5.2.5 获取股票的净利率因子</h3><p>看看企业究竟是盈利还是亏损，如果盈利，那么净利润率又是多少</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在get_factor_values函数中</span></span><br><span class="line"><span class="comment">#使用net_profit_ratio作为factors参数</span></span><br><span class="line"><span class="comment">#即可查询到企业的净利润率</span></span><br><span class="line">factor_npr = get_factor_values(securities = get_index_stocks(<span class="string">&#x27;000016.XSHG&#x27;</span>),</span><br><span class="line">                              factors = [<span class="string">&#x27;net_profit_ratio&#x27;</span>],</span><br><span class="line">                              end_date = <span class="string">&#x27;2020-04-30&#x27;</span>,</span><br><span class="line">                              count = <span class="number">1</span>)[<span class="string">&#x27;net_profit_ratio&#x27;</span>]</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">factor_npr.T.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2020-04-30 00:00:00</th>
    </tr>
    <tr>
      <th>code</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>600010.XSHG</th>
      <td>0.002249</td>
    </tr>
    <tr>
      <th>600028.XSHG</th>
      <td>0.011633</td>
    </tr>
    <tr>
      <th>600030.XSHG</th>
      <td>0.275232</td>
    </tr>
    <tr>
      <th>600031.XSHG</th>
      <td>0.144949</td>
    </tr>
    <tr>
      <th>600036.XSHG</th>
      <td>0.345430</td>
    </tr>
  </tbody>
</table>
</div>



<p>我们指定factors参数为net_profit_ratiio，即可用get_factor_values函数获得上市企业的净利润率</p>
<h3 id="5-2-6-获取股票的净利润增长率因子"><a href="#5-2-6-获取股票的净利润增长率因子" class="headerlink" title="5.2.6 获取股票的净利润增长率因子"></a>5.2.6 获取股票的净利润增长率因子</h3><p>对于企业来说，盈利固然重要，比盈利更重要的是，能够持续不断地创造更多的利润，也就是说，企业需要有良好的成长性。衡量成长性的一个重要指标就是净利润的增长率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在get_factor_values函数中</span></span><br><span class="line"><span class="comment">#使用net_profit_growth_rate作为factors参数</span></span><br><span class="line"><span class="comment">#即可查询到企业的净利润增长率</span></span><br><span class="line">factor_npgr = get_factor_values(securities = get_index_stocks(<span class="string">&#x27;000016.XSHG&#x27;</span>),</span><br><span class="line">                               factors = [<span class="string">&#x27;net_profit_growth_rate&#x27;</span>],</span><br><span class="line">                               end_date = <span class="string">&#x27;2020-04-30&#x27;</span>,</span><br><span class="line">                               count = <span class="number">1</span>)[<span class="string">&#x27;net_profit_growth_rate&#x27;</span>]</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">factor_npgr.T.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2020-04-30 00:00:00</th>
    </tr>
    <tr>
      <th>code</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>600010.XSHG</th>
      <td>-0.955338</td>
    </tr>
    <tr>
      <th>600028.XSHG</th>
      <td>-0.560616</td>
    </tr>
    <tr>
      <th>600030.XSHG</th>
      <td>0.094400</td>
    </tr>
    <tr>
      <th>600031.XSHG</th>
      <td>0.285818</td>
    </tr>
    <tr>
      <th>600036.XSHG</th>
      <td>0.146780</td>
    </tr>
  </tbody>
</table>
</div>



<p>当指定factors参数为net_profit_growth_rate时，使用get_factor_values函数即可获取股票的净利润增长率数据</p>
<h2 id="5-3-把诸多因子“打个包”"><a href="#5-3-把诸多因子“打个包”" class="headerlink" title="5.3 把诸多因子“打个包”"></a>5.3 把诸多因子“打个包”</h2><p>至此，我们已经有了4个因子——市值、市现率倒数、净利润率和净利润增长率</p>
<h3 id="5-3-1-将4个因子存入一个DataFrame"><a href="#5-3-1-将4个因子存入一个DataFrame" class="headerlink" title="5.3.1 将4个因子存入一个DataFrame"></a>5.3.1 将4个因子存入一个DataFrame</h3><p>这里的思路是，把4个因子进行降维处理，用一个主成分表示4个因子，这样我们就可以按照主成分的数值高低来选择股票了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#新建一个DataFrame，和前面市值数据保持同样的序号</span></span><br><span class="line">factors = pd.DataFrame(index = factor_mc.T.index)</span><br><span class="line"><span class="comment">#在新的DataFrame中创建4个字段</span></span><br><span class="line"><span class="comment">#分别把市值、市现率倒数、净利润率、净利润增长率存储到其中</span></span><br><span class="line">factors[<span class="string">&#x27;mc&#x27;</span>] = factor_mc.T[<span class="string">&#x27;2020-04-30 00:00:00&#x27;</span>]</span><br><span class="line">factors[<span class="string">&#x27;cfp&#x27;</span>] = factor_cfp.T[<span class="string">&#x27;2020-04-30 00:00:00&#x27;</span>]</span><br><span class="line">factors[<span class="string">&#x27;npr&#x27;</span>] = factor_npr.T[<span class="string">&#x27;2020-04-30 00:00:00&#x27;</span>]</span><br><span class="line">factors[<span class="string">&#x27;npgr&#x27;</span>] = factor_npgr.T[<span class="string">&#x27;2020-04-30 00:00:00&#x27;</span>]</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">factors.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mc</th>
      <th>cfp</th>
      <th>npr</th>
      <th>npgr</th>
    </tr>
    <tr>
      <th>code</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>600010.XSHG</th>
      <td>4.923184e+10</td>
      <td>-0.009713</td>
      <td>0.002249</td>
      <td>-0.955338</td>
    </tr>
    <tr>
      <th>600028.XSHG</th>
      <td>5.399776e+11</td>
      <td>-0.046224</td>
      <td>0.011633</td>
      <td>-0.560616</td>
    </tr>
    <tr>
      <th>600030.XSHG</th>
      <td>3.063646e+11</td>
      <td>0.270966</td>
      <td>0.275232</td>
      <td>0.094400</td>
    </tr>
    <tr>
      <th>600031.XSHG</th>
      <td>1.657582e+11</td>
      <td>0.001367</td>
      <td>0.144949</td>
      <td>0.285818</td>
    </tr>
    <tr>
      <th>600036.XSHG</th>
      <td>8.849644e+11</td>
      <td>0.219173</td>
      <td>0.345430</td>
      <td>0.146780</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="5-3-2-使用PCA提取主成分"><a href="#5-3-2-使用PCA提取主成分" class="headerlink" title="5.3.2 使用PCA提取主成分"></a>5.3.2 使用PCA提取主成分</h3><p>下面开始进行主成分分析的过程，PCA算法，PCA是一种无监督算法，通过<strong>方差</strong>来确定样本<strong>各个特征的重要性</strong>，并且给它们分配不同的权重（<strong>重要性越高的特征，分配的权重也越高</strong>），并根据权重，将高维数据降到低维的过程</p>
<p>为了便于计算，数据中不能有空值，所以要用下面的代码进行处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了计算，先把数据中的空值去掉</span></span><br><span class="line">factors = factors.dropna()</span><br><span class="line"><span class="comment">#检查下是否还有空值</span></span><br><span class="line">factors.isnull().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>mc      0
cfp     0
npr     0
npgr    0
dtype: int64
</code></pre>
<p>经过去除空值操作后，样本的四个因子中均没有空值了</p>
<p>接下来，我们使用PCA来对4个因子进行降维处理，考虑到各个因子的量纲差异比较大，这里先进行数据<strong>缩放</strong>步骤，再进行主成分分析</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#因为各因子数值的量纲差异较大</span></span><br><span class="line"><span class="comment">#需要做一点简单的缩放处理</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment">#导入scikit-learn中的PCA主成分分析工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="comment">#创建StandardScaler实例，会将数据量纲压缩到同一个区间中</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line"><span class="comment">#使用StandardScaler缩放原始的因子值</span></span><br><span class="line">factors_scl = scaler.fit_transform(factors.drop(<span class="string">&#x27;mc&#x27;</span>,axis=<span class="number">1</span>))</span><br><span class="line"><span class="comment">#接下来使用PCA，提取主成分数量指定为1</span></span><br><span class="line">pca = PCA(n_components = <span class="number">1</span>)</span><br><span class="line"><span class="comment">#使用缩放后的数据进行拟合</span></span><br><span class="line">pca.fit(factors_scl)</span><br><span class="line"><span class="comment">#查看pca给各因子分配的权重</span></span><br><span class="line">pca.components_</span><br></pre></td></tr></table></figure>




<pre><code>array([[0.6902996976209287, 0.7021000940348576, -0.17476208233109072]])
</code></pre>
<p>新的代码中给除了市值外的三个因子分配了权重？？？</p>
<h3 id="5-3-3-找到主成分数值最高的股票"><a href="#5-3-3-找到主成分数值最高的股票" class="headerlink" title="5.3.3 找到主成分数值最高的股票"></a>5.3.3 找到主成分数值最高的股票</h3><p>将PCA提取的主成分添加到数据表里，并找到主成分数值最高的几只股票</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在factors数据表中添加一个pca字段</span></span><br><span class="line"><span class="comment">#存储提取出来的主成分</span></span><br><span class="line">factors[<span class="string">&#x27;pca&#x27;</span>] = pca.transform(factors_scl)</span><br><span class="line"><span class="comment">#看一下主成分数值最高的5只股票</span></span><br><span class="line">factors.sort_values(by=<span class="string">&#x27;pca&#x27;</span>, ascending = <span class="literal">False</span>).head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mc</th>
      <th>cfp</th>
      <th>npr</th>
      <th>npgr</th>
      <th>pca</th>
    </tr>
    <tr>
      <th>code</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>601166.XSHG</th>
      <td>3.452670e+11</td>
      <td>0.800000</td>
      <td>0.370036</td>
      <td>0.075121</td>
      <td>4.563748</td>
    </tr>
    <tr>
      <th>601288.XSHG</th>
      <td>1.210941e+12</td>
      <td>0.448029</td>
      <td>0.335705</td>
      <td>0.045967</td>
      <td>2.792800</td>
    </tr>
    <tr>
      <th>601398.XSHG</th>
      <td>1.842620e+12</td>
      <td>0.402414</td>
      <td>0.372866</td>
      <td>0.044122</td>
      <td>2.788498</td>
    </tr>
    <tr>
      <th>600519.XSHG</th>
      <td>1.589970e+12</td>
      <td>0.014857</td>
      <td>0.520656</td>
      <td>0.130552</td>
      <td>1.830660</td>
    </tr>
    <tr>
      <th>600036.XSHG</th>
      <td>8.849644e+11</td>
      <td>0.219173</td>
      <td>0.345430</td>
      <td>0.146780</td>
      <td>1.801488</td>
    </tr>
    <tr>
      <th>601688.XSHG</th>
      <td>1.646504e+11</td>
      <td>0.186306</td>
      <td>0.359591</td>
      <td>0.515651</td>
      <td>1.688506</td>
    </tr>
    <tr>
      <th>600030.XSHG</th>
      <td>3.063646e+11</td>
      <td>0.270966</td>
      <td>0.275232</td>
      <td>0.094400</td>
      <td>1.660772</td>
    </tr>
    <tr>
      <th>601066.XSHG</th>
      <td>2.675470e+11</td>
      <td>0.069972</td>
      <td>0.400202</td>
      <td>0.661239</td>
      <td>1.367239</td>
    </tr>
    <tr>
      <th>600900.XSHG</th>
      <td>3.839000e+11</td>
      <td>0.006233</td>
      <td>0.421832</td>
      <td>-0.078471</td>
      <td>1.279813</td>
    </tr>
    <tr>
      <th>603288.XSHG</th>
      <td>3.319564e+11</td>
      <td>0.012757</td>
      <td>0.272045</td>
      <td>0.183514</td>
      <td>0.468368</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">factors.sort_values(by=<span class="string">&#x27;pca&#x27;</span>, ascending = <span class="literal">False</span>).head(<span class="number">50</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mc</th>
      <th>cfp</th>
      <th>npr</th>
      <th>npgr</th>
      <th>pca</th>
    </tr>
    <tr>
      <th>code</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>601166.XSHG</th>
      <td>3.452670e+11</td>
      <td>0.800000</td>
      <td>0.370036</td>
      <td>0.075121</td>
      <td>4.563748</td>
    </tr>
    <tr>
      <th>601288.XSHG</th>
      <td>1.210941e+12</td>
      <td>0.448029</td>
      <td>0.335705</td>
      <td>0.045967</td>
      <td>2.792800</td>
    </tr>
    <tr>
      <th>601398.XSHG</th>
      <td>1.842620e+12</td>
      <td>0.402414</td>
      <td>0.372866</td>
      <td>0.044122</td>
      <td>2.788498</td>
    </tr>
    <tr>
      <th>600519.XSHG</th>
      <td>1.589970e+12</td>
      <td>0.014857</td>
      <td>0.520656</td>
      <td>0.130552</td>
      <td>1.830660</td>
    </tr>
    <tr>
      <th>600036.XSHG</th>
      <td>8.849644e+11</td>
      <td>0.219173</td>
      <td>0.345430</td>
      <td>0.146780</td>
      <td>1.801488</td>
    </tr>
    <tr>
      <th>601688.XSHG</th>
      <td>1.646504e+11</td>
      <td>0.186306</td>
      <td>0.359591</td>
      <td>0.515651</td>
      <td>1.688506</td>
    </tr>
    <tr>
      <th>600030.XSHG</th>
      <td>3.063646e+11</td>
      <td>0.270966</td>
      <td>0.275232</td>
      <td>0.094400</td>
      <td>1.660772</td>
    </tr>
    <tr>
      <th>601066.XSHG</th>
      <td>2.675470e+11</td>
      <td>0.069972</td>
      <td>0.400202</td>
      <td>0.661239</td>
      <td>1.367239</td>
    </tr>
    <tr>
      <th>600900.XSHG</th>
      <td>3.839000e+11</td>
      <td>0.006233</td>
      <td>0.421832</td>
      <td>-0.078471</td>
      <td>1.279813</td>
    </tr>
    <tr>
      <th>603288.XSHG</th>
      <td>3.319564e+11</td>
      <td>0.012757</td>
      <td>0.272045</td>
      <td>0.183514</td>
      <td>0.468368</td>
    </tr>
    <tr>
      <th>601225.XSHG</th>
      <td>7.540000e+10</td>
      <td>0.054623</td>
      <td>0.210243</td>
      <td>0.054202</td>
      <td>0.336977</td>
    </tr>
    <tr>
      <th>600436.XSHG</th>
      <td>8.461524e+10</td>
      <td>-0.007563</td>
      <td>0.244179</td>
      <td>0.196216</td>
      <td>0.224285</td>
    </tr>
    <tr>
      <th>600276.XSHG</th>
      <td>4.112731e+11</td>
      <td>0.011001</td>
      <td>0.228043</td>
      <td>0.270156</td>
      <td>0.212337</td>
    </tr>
    <tr>
      <th>600585.XSHG</th>
      <td>3.177462e+11</td>
      <td>0.000930</td>
      <td>0.221024</td>
      <td>0.036247</td>
      <td>0.155115</td>
    </tr>
    <tr>
      <th>601012.XSHG</th>
      <td>1.162158e+11</td>
      <td>0.072519</td>
      <td>0.191460</td>
      <td>1.535772</td>
      <td>0.149718</td>
    </tr>
    <tr>
      <th>601088.XSHG</th>
      <td>3.168416e+11</td>
      <td>0.002430</td>
      <td>0.205398</td>
      <td>-0.114188</td>
      <td>0.094109</td>
    </tr>
    <tr>
      <th>600809.XSHG</th>
      <td>9.352370e+10</td>
      <td>0.010427</td>
      <td>0.196036</td>
      <td>0.347873</td>
      <td>0.027626</td>
    </tr>
    <tr>
      <th>603986.XSHG</th>
      <td>8.918960e+10</td>
      <td>0.011579</td>
      <td>0.206477</td>
      <td>1.072090</td>
      <td>0.008121</td>
    </tr>
    <tr>
      <th>603259.XSHG</th>
      <td>1.680351e+11</td>
      <td>0.004414</td>
      <td>0.135661</td>
      <td>-0.261985</td>
      <td>-0.258160</td>
    </tr>
    <tr>
      <th>600406.XSHG</th>
      <td>9.290101e+10</td>
      <td>-0.000548</td>
      <td>0.143026</td>
      <td>0.049815</td>
      <td>-0.275638</td>
    </tr>
    <tr>
      <th>600104.XSHG</th>
      <td>2.208174e+11</td>
      <td>0.115800</td>
      <td>0.035203</td>
      <td>-0.431745</td>
      <td>-0.280734</td>
    </tr>
    <tr>
      <th>600031.XSHG</th>
      <td>1.657582e+11</td>
      <td>0.001367</td>
      <td>0.144949</td>
      <td>0.285818</td>
      <td>-0.283062</td>
    </tr>
    <tr>
      <th>600196.XSHG</th>
      <td>8.619028e+10</td>
      <td>0.016558</td>
      <td>0.127676</td>
      <td>0.167600</td>
      <td>-0.294826</td>
    </tr>
    <tr>
      <th>600309.XSHG</th>
      <td>1.412886e+11</td>
      <td>-0.008723</td>
      <td>0.135728</td>
      <td>-0.212917</td>
      <td>-0.322582</td>
    </tr>
    <tr>
      <th>603260.XSHG</th>
      <td>2.184602e+10</td>
      <td>0.004085</td>
      <td>0.114592</td>
      <td>-0.634253</td>
      <td>-0.332014</td>
    </tr>
    <tr>
      <th>600048.XSHG</th>
      <td>1.937866e+11</td>
      <td>-0.036488</td>
      <td>0.159450</td>
      <td>0.419256</td>
      <td>-0.390291</td>
    </tr>
    <tr>
      <th>601601.XSHG</th>
      <td>2.788377e+11</td>
      <td>0.060415</td>
      <td>0.080259</td>
      <td>0.551656</td>
      <td>-0.396909</td>
    </tr>
    <tr>
      <th>601318.XSHG</th>
      <td>1.361147e+12</td>
      <td>-0.025746</td>
      <td>0.129929</td>
      <td>0.032310</td>
      <td>-0.458331</td>
    </tr>
    <tr>
      <th>600346.XSHG</th>
      <td>9.946248e+10</td>
      <td>0.075258</td>
      <td>0.102152</td>
      <td>3.247378</td>
      <td>-0.513823</td>
    </tr>
    <tr>
      <th>601633.XSHG</th>
      <td>7.356579e+10</td>
      <td>0.047008</td>
      <td>0.036152</td>
      <td>-0.219070</td>
      <td>-0.609874</td>
    </tr>
    <tr>
      <th>600887.XSHG</th>
      <td>1.782581e+11</td>
      <td>0.006231</td>
      <td>0.066561</td>
      <td>-0.121291</td>
      <td>-0.640104</td>
    </tr>
    <tr>
      <th>600893.XSHG</th>
      <td>5.568365e+10</td>
      <td>0.025837</td>
      <td>0.047206</td>
      <td>0.045521</td>
      <td>-0.675210</td>
    </tr>
    <tr>
      <th>600690.XSHG</th>
      <td>1.017201e+11</td>
      <td>-0.001163</td>
      <td>0.056223</td>
      <td>0.096626</td>
      <td>-0.753929</td>
    </tr>
    <tr>
      <th>601888.XSHG</th>
      <td>1.782610e+11</td>
      <td>-0.020879</td>
      <td>0.055983</td>
      <td>-0.553747</td>
      <td>-0.771214</td>
    </tr>
    <tr>
      <th>601628.XSHG</th>
      <td>8.066747e+11</td>
      <td>0.004216</td>
      <td>0.065057</td>
      <td>1.048788</td>
      <td>-0.788644</td>
    </tr>
    <tr>
      <th>600111.XSHG</th>
      <td>3.280659e+10</td>
      <td>0.002373</td>
      <td>0.036874</td>
      <td>0.281116</td>
      <td>-0.863500</td>
    </tr>
    <tr>
      <th>601899.XSHG</th>
      <td>9.922509e+10</td>
      <td>-0.002792</td>
      <td>0.037268</td>
      <td>0.227714</td>
      <td>-0.878680</td>
    </tr>
    <tr>
      <th>603799.XSHG</th>
      <td>3.930505e+10</td>
      <td>-0.012998</td>
      <td>0.015050</td>
      <td>-0.572506</td>
      <td>-0.955305</td>
    </tr>
    <tr>
      <th>600438.XSHG</th>
      <td>6.478950e+10</td>
      <td>-0.056975</td>
      <td>0.065208</td>
      <td>0.165167</td>
      <td>-0.964788</td>
    </tr>
    <tr>
      <th>600010.XSHG</th>
      <td>4.923184e+10</td>
      <td>-0.009713</td>
      <td>0.002249</td>
      <td>-0.955338</td>
      <td>-0.966873</td>
    </tr>
    <tr>
      <th>601669.XSHG</th>
      <td>5.461756e+10</td>
      <td>-0.034690</td>
      <td>0.029359</td>
      <td>-0.019222</td>
      <td>-1.037754</td>
    </tr>
    <tr>
      <th>601857.XSHG</th>
      <td>8.126131e+11</td>
      <td>-0.047949</td>
      <td>0.015447</td>
      <td>-0.486498</td>
      <td>-1.120518</td>
    </tr>
    <tr>
      <th>600028.XSHG</th>
      <td>5.399776e+11</td>
      <td>-0.046224</td>
      <td>0.011633</td>
      <td>-0.560616</td>
      <td>-1.125080</td>
    </tr>
    <tr>
      <th>601919.XSHG</th>
      <td>4.413431e+10</td>
      <td>-0.084415</td>
      <td>0.065301</td>
      <td>1.741214</td>
      <td>-1.264959</td>
    </tr>
    <tr>
      <th>603501.XSHG</th>
      <td>1.679484e+11</td>
      <td>0.010378</td>
      <td>0.068072</td>
      <td>6.033906</td>
      <td>-1.303906</td>
    </tr>
    <tr>
      <th>601668.XSHG</th>
      <td>2.198970e+11</td>
      <td>-0.113691</td>
      <td>0.044307</td>
      <td>0.082724</td>
      <td>-1.324694</td>
    </tr>
    <tr>
      <th>600745.XSHG</th>
      <td>1.199456e+11</td>
      <td>0.028727</td>
      <td>0.041341</td>
      <td>8.109001</td>
      <td>-1.598781</td>
    </tr>
  </tbody>
</table>
</div>



<p>这样，我们就选出了一些基本面数据看起来不错的股票，完成量化选股的步骤</p>
<h1 id="第六章-因子好用吗——有些事需要知道"><a href="#第六章-因子好用吗——有些事需要知道" class="headerlink" title="第六章 因子好用吗——有些事需要知道"></a>第六章 因子好用吗——有些事需要知道</h1><h2 id="6-1-针对投资组合获取因子值"><a href="#6-1-针对投资组合获取因子值" class="headerlink" title="6.1 针对投资组合获取因子值"></a>6.1 针对投资组合获取因子值</h2><p>在第五章中，我们用来选股的因子基本是与<strong>企业的基本面</strong>相关的，这类因子可以归为<strong>价值因子</strong>；除此之外，常用因子还有<strong>动量因子</strong>、<strong>情绪因子</strong>、<strong>波动因子</strong>、<strong>规模因子</strong>、<strong>质量因子</strong>等。这些因子有些可以用来选股，有些可以用来帮助我们寻找买卖时机</p>
<p>下面我们以一个<strong>情绪因子</strong>为例来研究一下与因子有关的评价指标</p>
<h3 id="6-1-1-建立投资组合并设定日期"><a href="#6-1-1-建立投资组合并设定日期" class="headerlink" title="6.1.1 建立投资组合并设定日期"></a>6.1.1 建立投资组合并设定日期</h3><p>我们采用第五章的方法，通过不同的量化选股因子，在不同的股票池中选取若干只股票，这里我们选取基本面比较不错且成交较为活跃的股票，把这些股票存入一个列表，命名为portfolio</p>
<p>注意：这些股票是当时获取的因子数据得出的结果，不具有时效性，只能拿来参考一下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#因为是新建的notebook</span></span><br><span class="line"><span class="comment">#所以重新导入get_factor_values</span></span><br><span class="line"><span class="keyword">from</span> jqfactor <span class="keyword">import</span> get_factor_values</span><br><span class="line"><span class="comment">#导入平台内置的因子分析函数</span></span><br><span class="line"><span class="keyword">from</span> jqfactor <span class="keyword">import</span> analyze_factor</span><br><span class="line"><span class="comment">#导入datetime，为了一会儿方便</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过第5章中的思路</span></span><br><span class="line"><span class="comment">#选出几只股票，做成列表备用</span></span><br><span class="line">portfolio = [<span class="string">&#x27;600519.XSHG&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;600009.XSHG&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;601688.XSHG&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;601166.XSHG&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;601628.XSHG&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;600196.XSHG&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;600855.XSHG&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;601899.XSHG&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;603183.XSHG&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>为了日后方便，我们不需要每次都输入起止日期，可以使用python中的datetime来获取当日的日期，并使用timedelta找到若干天以前的日期（这里选择的是500天），并分别将若干天以前的日期作为起始日期，将当前日期作为截至日期</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用datetime获取当日的日期</span></span><br><span class="line">today = datetime.date.today()</span><br><span class="line"><span class="comment">#把日期的格式转换为需要传入参数的格式</span></span><br><span class="line"><span class="comment">#作为截止日期</span></span><br><span class="line">end_date = <span class="string">&#x27;%s-%s-%s&#x27;</span>%(today.year, today.month, today.day)</span><br><span class="line"><span class="comment">#使用timedelta找到500天前的日期</span></span><br><span class="line">start_date = today - datetime.timedelta(days = <span class="number">500</span>)</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line"><span class="built_in">print</span>(start_date, end_date)</span><br></pre></td></tr></table></figure>

<pre><code>2021-08-15 2022-12-28
</code></pre>
<p>从代码运行结果可以看到，使用datetime和timedelta的组合，获取到start_date为2021年8月15日，end_data为2022年12月28日（做实验时间），这两个变量将会对参数进行传入</p>
<h3 id="6-1-2-获取一个情绪因子"><a href="#6-1-2-获取一个情绪因子" class="headerlink" title="6.1.2 获取一个情绪因子"></a>6.1.2 获取一个情绪因子</h3><p>在确定了<strong>投资组合</strong>和<strong>时间范围</strong>之后，我们就可以来找一个因子进行实验。这里我们选择的因子是成交量的5日指数移动平均<strong>（VEMA5）</strong>.这个因子股票成交量在过去5个交易日中的移动平均值。我们使用get_factor_values函数可获取这个因子的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了和书中数据相同便于分析，这里强行修改start_date和end_date</span></span><br><span class="line">start_date = <span class="string">&#x27;2018-12-8&#x27;</span></span><br><span class="line">end_date = <span class="string">&#x27;2020-4-21&#x27;</span></span><br><span class="line"><span class="comment">#使用get_factor_values获取股票成交量的5日指数移动平均</span></span><br><span class="line"><span class="comment">#股票池参数设置为我们选出的股票</span></span><br><span class="line"><span class="comment">#因子参数设置为“VEMA5”，是平台提供的成交量5日移动平均因子</span></span><br><span class="line"><span class="comment">#起止日期设置为我们计算好的起止日期</span></span><br><span class="line">factor_vema5 = get_factor_values(securities = portfolio,</span><br><span class="line">                                     factors = [<span class="string">&#x27;VEMA5&#x27;</span>],</span><br><span class="line">                                 start_date = start_date,</span><br><span class="line">                                     end_date = end_date,</span><br><span class="line">                                     )[<span class="string">&#x27;VEMA5&#x27;</span>]</span><br><span class="line"><span class="comment">#使用analyze_factor函数进行因子分析</span></span><br><span class="line"><span class="comment">#weight_method参数设置为使用市值“mktcap”来加权计算分位数</span></span><br><span class="line"><span class="comment">#universe参数就设为我们选好的股票池就好</span></span><br><span class="line"><span class="comment">#分位数quantiles设为5（默认值）</span></span><br><span class="line"><span class="comment">#计算收益的周期periods参数分别为1天、5天，和10天</span></span><br><span class="line">far = analyze_factor(factor=factor_vema5, </span><br><span class="line">                     start_date= start_date, </span><br><span class="line">                     end_date= end_date, </span><br><span class="line">                     weight_method=<span class="string">&#x27;mktcap&#x27;</span>, </span><br><span class="line">                     universe = portfolio, </span><br><span class="line">                     quantiles=<span class="number">5</span>, </span><br><span class="line">                     periods=(<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<pre><code>/opt/conda/lib/python3.6/site-packages/jqdata/apis/data.py:159: UserWarning: 不建议继续使用panel（panel将在pandas未来版本不再支持，将来升级pandas后，您的策略会失败），建议 get_price 传入 panel=False 参数
  warnings.warn(&quot;不建议继续使用panel（panel将在pandas未来版本不再支持，将来升级pandas后，您的策略会失败），&quot;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看因子值5个分位对应的3个周期的收益</span></span><br><span class="line">far.mean_return_std_by_quantile</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>period_1</th>
      <th>period_5</th>
      <th>period_10</th>
    </tr>
    <tr>
      <th>factor_quantile</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.000762</td>
      <td>0.000329</td>
      <td>0.000226</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000892</td>
      <td>0.000357</td>
      <td>0.000294</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.001506</td>
      <td>0.000851</td>
      <td>0.000666</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000820</td>
      <td>0.000375</td>
      <td>0.000265</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.000930</td>
      <td>0.000432</td>
      <td>0.000306</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：从表中我们可以看到，程序返回了<strong>因子不同分位</strong>对应的不同周期的<strong>加权平均收益</strong>，在上面的代码中，我们设置的分位数量为5个，因此程序返回的是5个分位的收益情况。</p>
<p>举例，假如我们买入VEMA5因子值在第一分位的股票，则1天周期的加权平均收益是0.000762，而5天周期的加权平均收益是0.000329，10天周期的加权平均收益是0.000226</p>
<h3 id="6-1-3-获取全部的因子分析结果"><a href="#6-1-3-获取全部的因子分析结果" class="headerlink" title="6.1.3 获取全部的因子分析结果"></a>6.1.3 获取全部的因子分析结果</h3><p>除了简单了解各分位因子值对应的加权平均收益之外，我们也可以对因子进行更加全面的了解。create_full_tear_sheet方法可以以图表的形式，直观展现因子的收益，因子的信息系数（IC），换手率等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用create_full_tear_sheet来获取全部的因子分析结果</span></span><br><span class="line"><span class="comment">#这里demeaned参数设置为False，意思是不使用超额收益来进行计算</span></span><br><span class="line"><span class="comment">#group_adjust设置为False，意思是不使用行业中性化来计算收益</span></span><br><span class="line"><span class="comment">#by_group设置为False，意思是不按照行业展示</span></span><br><span class="line"><span class="comment">#turnover_periods是调仓周期，这里设置为None</span></span><br><span class="line"><span class="comment">#avgretplot参数设置的是因子预测的天数</span></span><br><span class="line"><span class="comment">#（5，15）是指向前预测5天，向后预测15天</span></span><br><span class="line"><span class="comment">#std_bar参数的意思是是否显示标准差，这里我们设置为False</span></span><br><span class="line">far.create_full_tear_sheet(demeaned=<span class="literal">False</span>, </span><br><span class="line">                           group_adjust=<span class="literal">False</span>, </span><br><span class="line">                           by_group=<span class="literal">False</span>, </span><br><span class="line">                           turnover_periods=<span class="literal">None</span>, </span><br><span class="line">                           avgretplot=(<span class="number">5</span>, <span class="number">15</span>), </span><br><span class="line">                           std_bar=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<pre><code>分位数统计
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>count %</th>
    </tr>
    <tr>
      <th>factor_quantile</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2.673041e+05</td>
      <td>3.840905e+06</td>
      <td>9.655232e+05</td>
      <td>6.118617e+05</td>
      <td>662</td>
      <td>22.222222</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.515145e+05</td>
      <td>1.144836e+07</td>
      <td>2.560969e+06</td>
      <td>1.246911e+06</td>
      <td>662</td>
      <td>22.222222</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.709980e+06</td>
      <td>1.756855e+07</td>
      <td>6.092334e+06</td>
      <td>3.208800e+06</td>
      <td>331</td>
      <td>11.111111</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.648931e+06</td>
      <td>5.355542e+07</td>
      <td>1.598732e+07</td>
      <td>7.896577e+06</td>
      <td>662</td>
      <td>22.222222</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1.690484e+07</td>
      <td>2.954431e+08</td>
      <td>8.363240e+07</td>
      <td>4.213471e+07</td>
      <td>662</td>
      <td>22.222222</td>
    </tr>
  </tbody>
</table>
</div>


<p>​<br>    ————————-</p>
<pre><code>收益分析
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>period_1</th>
      <th>period_5</th>
      <th>period_10</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Ann. alpha</th>
      <td>-0.123</td>
      <td>-0.162</td>
      <td>-0.174</td>
    </tr>
    <tr>
      <th>beta</th>
      <td>0.934</td>
      <td>0.949</td>
      <td>0.935</td>
    </tr>
    <tr>
      <th>Mean Period Wise Return Top Quantile (bps)</th>
      <td>5.252</td>
      <td>5.167</td>
      <td>5.011</td>
    </tr>
    <tr>
      <th>Mean Period Wise Return Bottom Quantile (bps)</th>
      <td>24.442</td>
      <td>24.549</td>
      <td>25.042</td>
    </tr>
    <tr>
      <th>Mean Period Wise Spread (bps)</th>
      <td>-19.190</td>
      <td>-19.976</td>
      <td>-20.921</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_5.png" alt="output_113_5"></p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_7.png" alt="output_113_7"></p>
<p><img src="output_113_8.png" alt="output_113_8"></p>
<p><img src="output_113_9.png" alt="output_113_9"></p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_11.png" alt="output_113_11"></p>
<p><img src="output_113_12.png" alt="output_113_12"></p>
<p><img src="output_113_13.png" alt="output_113_13"></p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_15.png" alt="output_113_15"></p>
<p><img src="output_113_16.png" alt="output_113_16"></p>
<p><img src="output_113_17.png" alt="output_113_17"></p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_19.png" alt="output_113_19"></p>
<p><img src="output_113_20.png" alt="output_113_20"></p>
<p><img src="output_113_21.png" alt="output_113_21"></p>
<p>​<br>    ————————-</p>
<pre><code>IC 分析
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>period_1</th>
      <th>period_5</th>
      <th>period_10</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>IC Mean</th>
      <td>-0.021</td>
      <td>-0.080</td>
      <td>-0.110</td>
    </tr>
    <tr>
      <th>IC Std.</th>
      <td>0.394</td>
      <td>0.411</td>
      <td>0.432</td>
    </tr>
    <tr>
      <th>IR</th>
      <td>-0.054</td>
      <td>-0.195</td>
      <td>-0.255</td>
    </tr>
    <tr>
      <th>t-stat(IC)</th>
      <td>-0.981</td>
      <td>-3.550</td>
      <td>-4.641</td>
    </tr>
    <tr>
      <th>p-value(IC)</th>
      <td>0.327</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>IC Skew</th>
      <td>0.031</td>
      <td>0.114</td>
      <td>0.225</td>
    </tr>
    <tr>
      <th>IC Kurtosis</th>
      <td>-0.487</td>
      <td>-0.794</td>
      <td>-0.659</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_25.png" alt="output_113_25"></p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_27.png" alt="output_113_27"></p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_29.png" alt="output_113_29"></p>
<p>​<br>    ————————-</p>
<pre><code>换手率分析
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>period_1</th>
      <th>period_10</th>
      <th>period_5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Quantile 1 Mean Turnover</th>
      <td>0.074</td>
      <td>0.226</td>
      <td>0.187</td>
    </tr>
    <tr>
      <th>Quantile 2 Mean Turnover</th>
      <td>0.117</td>
      <td>0.333</td>
      <td>0.261</td>
    </tr>
    <tr>
      <th>Quantile 3 Mean Turnover</th>
      <td>0.161</td>
      <td>0.421</td>
      <td>0.325</td>
    </tr>
    <tr>
      <th>Quantile 4 Mean Turnover</th>
      <td>0.045</td>
      <td>0.109</td>
      <td>0.089</td>
    </tr>
    <tr>
      <th>Quantile 5 Mean Turnover</th>
      <td>0.005</td>
      <td>0.014</td>
      <td>0.008</td>
    </tr>
  </tbody>
</table>
</div>



<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>period_1</th>
      <th>period_5</th>
      <th>period_10</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Mean Factor Rank Autocorrelation</th>
      <td>0.988</td>
      <td>0.963</td>
      <td>0.953</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_34.png" alt="output_113_34"></p>
<p><img src="output_113_35.png" alt="output_113_35"></p>
<p><img src="output_113_36.png" alt="output_113_36"></p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_38.png" alt="output_113_38"></p>
<p><img src="output_113_39.png" alt="output_113_39"></p>
<p><img src="output_113_40.png" alt="output_113_40"></p>
<p>​<br>    ————————-</p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p><img src="output_113_43.png" alt="output_113_43"></p>
<h2 id="6-2-因子收益分析"><a href="#6-2-因子收益分析" class="headerlink" title="6.2 因子收益分析"></a>6.2 因子收益分析</h2><p>如果我们使用这些因子来进行投资，那么我们到底能赚多少钱。这里我们就针对<strong>因子收益</strong>来进行分析。在因子收益分析中，我们主要针对<strong>各分位数的平均收益</strong>、<strong>累计收益</strong>以及<strong>多空组合收益</strong>来进行研究</p>
<h3 id="6-2-1-因子分位统计"><a href="#6-2-1-因子分位统计" class="headerlink" title="6.2.1 因子分位统计"></a>6.2.1 因子分位统计</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(1).png" alt="下载 (1)"></p>
<p>结果分析：在factor_quantile为1这一行，也就是因子值最小分位数中，因子的最小值约为26.7万，最大值约为384万，平均值为96.5万，标准差为61.1万。</p>
<p>通过查看<strong>分位数的情况，我们可以大致了解自己的投资组合中的股票处在哪一个因子值的分位中</strong></p>
<p>注意：这里有5个分位，是因为我们在使用analyze_factor函数时，指定了quantiles参数为5，如果想希望更多因子的分位统计信息，则可自行将quantiles参数的数值设置的大一些</p>
<p><img src="%E4%B8%8B%E8%BD%BD.png" alt="下载"></p>
<p>注意：bps基点，是债券和票据利率该变量的度量单位</p>
<p>结果分析：程序返回的结果包括因子的年化alpha、Beta、最高分位的平均期内收益、最低分位的平均期内收益，以及最高分位平均收益与最低分位平均收益的差。</p>
<p>该因子的年华alpha在1天周期、5天周期和10天周期中都是负数，同时最高分位的平均期内收益要低于最低分位的平均期内收益。也就是说，这个因子的数值越小，收益反而越高。</p>
<p><img src="output_113_5.png" alt="output_113_5"></p>
<p>结果分析：上图是create_full_tear_sheet方法运行结果的一部分，因子处于<strong>第一分位</strong>的投资组合，不管是1天周期、5天周期、10天周期，其平均收益都明显高于另外几个分位。<strong>通过这种情况，我们可以知道，在最近这段时间范围内，5天平均成交量越低的股票，能够带来的收益较高。也就是说，我们需要关注选出的股票中，VEMA5因子数值最低的哪些。</strong></p>
<h3 id="6-2-2-因子加权多空组合累计收益"><a href="#6-2-2-因子加权多空组合累计收益" class="headerlink" title="6.2.2 因子加权多空组合累计收益"></a>6.2.2 因子加权多空组合累计收益</h3><p>我们可以查看因子值加权的多空组合累计收益。简单来说，在选定的时间范围中，根据因子值的变化对投资组合中的股票同时进行做多和做空的操作，所实现的总收益如下图</p>
<p><img src="output_113_7.png" alt="output_113_7"></p>
<p>结果分析：使用因子加权多空组合的方式来进行操作，累计收益的波动还是比较大的。虽然在2020年1月，累计收益超过了30%，但与我们期待的收益相比，还是有很比较大的差距；同时，在某些时间范围内，累计收益的缩水非常严重。这说明，<strong>基于VEMA5因子来进行多空组合的操作，收益情况并不理想。</strong></p>
<p>除了看到1天平均多空组合累计收益之外，我们还可以查看5天平均多空组合累计收益和10天平均多空多空组合累计收益</p>
<p><img src="output_113_8.png" alt="output_113_8"></p>
<p><img src="output_113_9.png" alt="output_113_9"></p>
<p>结果分析：5天和10天相对于1天更加平滑一些，但整体走势是保持一致的</p>
<h3 id="6-2-3-做多最大分位做空最小分位收益"><a href="#6-2-3-做多最大分位做空最小分位收益" class="headerlink" title="6.2.3 做多最大分位做空最小分位收益"></a>6.2.3 做多最大分位做空最小分位收益</h3><p>我们<strong>做多</strong>VEMA5因子值处在<strong>最大分位</strong>的股票，同时<strong>做空</strong>VEMA5因子值处在<strong>最小分位</strong>的股票，收益会如何</p>
<p><img src="output_113_11.png" alt="output_113_11"></p>
<p>结果分析：这样会赔得一塌糊涂。累计收益曲线一路下行，直接亏损39%左右</p>
<p>同时5天和10天的平均累计收益也呈现出类似的情况</p>
<p><img src="output_113_12.png" alt="output_113_12"></p>
<p><img src="output_113_13.png" alt="output_113_13"></p>
<p>是否说明VEMA5因子完全没用？恰恰相反，实际上，是要我们反过来操作——<strong>做多最小分位，作空最大分位</strong>，就可以实现盈利了</p>
<h3 id="6-2-4-分位数累计收益对比"><a href="#6-2-4-分位数累计收益对比" class="headerlink" title="6.2.4 分位数累计收益对比"></a>6.2.4 分位数累计收益对比</h3><p>下面来看一下VEMA5因子在各分位的累计收益情况</p>
<p><img src="output_113_15.png" alt="output_113_15"></p>
<p>结果分析：同前面的分析结果一致，VEMA5因子1分位股票的回报率是最高的，且遥遥领先于其他分位股票的回报率；5分位股票的累计收益是最低的，而2，3，4分位股票的累计收益比较接近。</p>
<p>通过这个现象，我们可以大胆预测，<strong>在过去的一段时间中，某些股票的5日平均成交量降到一定程度后，会有比较高的涨幅</strong>。</p>
<p><img src="output_113_16.png" alt="output_113_16"></p>
<p><img src="output_113_17.png" alt="output_113_17"></p>
<p>结果分析：与1天平均累计收益的情况相仿，各分位的5天平均累计收益和10天平均累计收益也呈现出类似的趋势</p>
<h2 id="6-3-因子IC分析"><a href="#6-3-因子IC分析" class="headerlink" title="6.3 因子IC分析"></a>6.3 因子IC分析</h2><p>IC（信息系数）：某个因子的数值与投资收益的相关系数。</p>
<p>解释：如果你买入一个A因子很高的股票，这只股票带给你的收益也很高，则说明A因子的IC很高；反之，如果你买一个B因子很低的股票，但这只股票带给你的收益反而很高，则说明B因子的IC很低（是个负数）。</p>
<p>因子的IC为-1~+1，不论正负，<strong>只要IC的绝对值比较大</strong>，就说明该因子的预测能力还是比较强的，也就是比较可信</p>
<p>下面我们以VEMA5因子为例来进行因子的IC分析</p>
<h3 id="6-3-1-因子IC分析概况"><a href="#6-3-1-因子IC分析概况" class="headerlink" title="6.3.1 因子IC分析概况"></a>6.3.1 因子IC分析概况</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(2).png" alt="下载 (2)"></p>
<p>IC Mean是因子IC在不同周期的均值。可以看到，VEMA5因子在1天周期中的IC均值是-0.021，在5天周期中的IC均值是-0.08，在10天周期的IC均值是-0.11.从这个数据看，VEMA5还是具备一定的预测能力的，只不过因为其是负值，所以需要<strong>“反向操作”</strong>————因子值低的做多，因子值高的做空。</p>
<h3 id="6-3-2-因子IC时间序列图"><a href="#6-3-2-因子IC时间序列图" class="headerlink" title="6.3.2 因子IC时间序列图"></a>6.3.2 因子IC时间序列图</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(3).png" alt="下载 (3)"></p>
<p>结果分析：在选定的时间范围内，VEMA5因子的IC大部分时间处于小于０的状态，但有部分时间是处于大于０的状态。这说明，因子预测“风格”是会在<strong>不同时期有所转变的</strong>。我们的操作策略也需要根据这种风格有所转变；</p>
<p><strong>当因子IC小于0时，做多低分位，做空高分位。当因子IC大于0时，做空低分位，做多高分位</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(4).png" alt="下载 (4)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(5).png" alt="下载 (5)"></p>
<p>结果分析：VEMA5因子5天IC和10天IC同样是在大部分时间中处于负值的状态，尤其是10天IC更为明显，可以说，VEMA5因子10天IC预测能力要更强一些</p>
<h3 id="6-3-3-因子IC正态分布Q-Q图和月度均值"><a href="#6-3-3-因子IC正态分布Q-Q图和月度均值" class="headerlink" title="6.3.3 因子IC正态分布Q-Q图和月度均值"></a>6.3.3 因子IC正态分布Q-Q图和月度均值</h3><p><img src="output_113_27.png" alt="output_113_27"></p>
<p>Q-Q图用于判断一组样本是否符合正态分布。如果样本在图像中十分接近<strong>y&#x3D;x</strong>这条直线，就说明样本符合<strong>正态分布</strong>，否则会出现左偏或者右偏的情况。</p>
<p>对于<strong>因子的IC</strong>来说，我们自然希望它比较符合正态分布的情况，这样才具备比较不错的<strong>预测能力</strong>，某个因子的IC均值看起来很高，但是出现了非常高的偏度，那么其依然不能够用来帮助我们做投资决策。</p>
<p>VEMA5因子的IC在1天、5天和10天中都比较接近正态分布的情况，这说明VEMA5因子是具备一定的预测能力的。</p>
<p><img src="output_113_29.png" alt="output_113_29"></p>
<p>结果分析：因子的IC<strong>绝对值越高</strong>，说明它的预测能力<strong>越好</strong>，然而，IC不是一成不变的。因此我们希望知道，在哪些时段中，因子的IC绝对值最高。</p>
<p>图中显示的是VEMA5因子的月度均值。其中，颜色越深的部分代表IC在当月的均值绝对值越高。</p>
<p>例如，在2020年4月，10天IC月度均值为-0.69，绝对值超过了0.5，这说明在这个月中，VEMA5因子的预测能力是非常强的</p>
<h2 id="6-4-因子换手率、因子相关性和因子预测能力分析"><a href="#6-4-因子换手率、因子相关性和因子预测能力分析" class="headerlink" title="6.4 因子换手率、因子相关性和因子预测能力分析"></a>6.4 因子换手率、因子相关性和因子预测能力分析</h2><p>既然我们知道因子的预测能力在一年当中哪个月份最强，那就在那个月初找到因子值最高或者最低的股票买入，等到月底的时候卖出不久可以了？<strong>显然不行</strong>，因为股票的因子值<strong>经常发生变化</strong>，或许之前在因子值在1分位的股票，明天同样的因子值就到了5分位，这时候需要<strong>进行调仓</strong>。</p>
<p>在因子值的不同分位，对应持仓股票的变化情况，就是<strong>因子换手率</strong>。因子换手率主要体现的是该因子的<strong>稳定性</strong>————<strong>换手率越低，因子在时间序列层面的持续性越好</strong>。</p>
<p>此外，我们还可以对因子进行自相关性分析。简单来说，如果某股票前一天的某因子值很高，而今天的因子值很低，则在这两天的时间范围内，因子的<strong>自相关性就很低</strong>；如果前一天的因子值很高，而今天的因子值也很高，则在这两天的时间范围内，因子的<strong>自相关性就很高</strong></p>
<h3 id="6-4-1-因子换手率分析"><a href="#6-4-1-因子换手率分析" class="headerlink" title="6.4.1 因子换手率分析"></a>6.4.1 因子换手率分析</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(6).png" alt="下载 (6)"></p>
<p>因子值3分位的换手率高了不少，在1天周期中就达到了16.1%，在10天周期中达到了42.1%，这说明成交量5日平均处于中等水平的股票，其<strong>调仓换股</strong>的次数要更高一些。</p>
<p><img src="output_113_34.png" alt="output_113_34"></p>
<p>结果分析：VEMA5因子的1分位和5分位换手率相对不是很高，尤其是5分位，只在2020年4月才出现了50%左右的换手；1分位换手率在2019-7到2019年年底，换手情况较少。这样来看，VEMA5因子的稳定性还可以</p>
<h3 id="6-4-2-因子自相关性分析"><a href="#6-4-2-因子自相关性分析" class="headerlink" title="6.4.2 因子自相关性分析"></a>6.4.2 因子自相关性分析</h3><p><img src="output_113_38.png" alt="output_113_38"></p>
<p>结果分析：在我们选定的投资组合中，VEMA5因子的<strong>自相关性</strong>是比较高的——整体的自相关系数在1左右，只有在为数不多的时间里，下降到0.9以下，均值为0.988.这说明，在选定的投资组合中，成交量基本保持了<strong>比较稳定</strong>的状态，也印证了VEMA5因子确实是比较稳定的</p>
<p><img src="output_113_39.png" alt="output_113_39"></p>
<p><img src="output_113_40.png" alt="output_113_40"></p>
<p>结果分析：VEMA5滞后5天和10天的自相关系数稍有降低，分别为0.963和0.953.总体来说，自相关系数还是处于比较高的水平。也就是说，在我们选定的投资组合中，VEMA5因子在较短的时间内不会发生太大的变化。</p>
<h3 id="6-4-3-因子预测能力分析"><a href="#6-4-3-因子预测能力分析" class="headerlink" title="6.4.3 因子预测能力分析"></a>6.4.3 因子预测能力分析</h3><p><img src="output_113_43.png" alt="output_113_43"></p>
<p>结果分析：上图直观地展示了VEMA5因子的预测能力，而这种能力体现为<strong>平均累计收益</strong>。</p>
<p>虚线的位置就是<strong>开始使用因子</strong>对投资组合买入的日期，而在之前的5天中，由于没有买入，假设某只股票上涨了100元，但我们没有赚到这本该属于我们的100元。如果以持有该股票为基准的话，我们的收益就是-100元。</p>
<p>假设某个分位的股票涨得越多，我们的“损失”也就越大。</p>
<p>图中可以看出，在前五天中，VEMA5因子3分位的股票带来的平均累计收益是最大的，而4分位的股票带来的平均累计收益最小；但在后15天中，情况发生了变化，1分位的股票带来了最大的平均累计收益，4分位，，，最低。从这个结果看，VEMA5因子的预测能力尚可。假如我们减持做多1分位，那么即便市场风向有所转变，总体来说市场还是会带来正向收益的。</p>
<h1 id="第七章-当因子遇上线性模型"><a href="#第七章-当因子遇上线性模型" class="headerlink" title="第七章 当因子遇上线性模型"></a>第七章 当因子遇上线性模型</h1><h2 id="7-1-什么是线性模型"><a href="#7-1-什么是线性模型" class="headerlink" title="7.1 什么是线性模型"></a>7.1 什么是线性模型</h2><p>线性模型不是某一个算法，而是一类算法的统称。它包括基本的<strong>线性回归</strong>、<strong>岭回归</strong>、<strong>套索回归</strong>，以及用于分类任务的<strong>逻辑回归</strong>等。</p>
<h3 id="7-1-1-准备用于演示的数据"><a href="#7-1-1-准备用于演示的数据" class="headerlink" title="7.1.1 准备用于演示的数据"></a>7.1.1 准备用于演示的数据</h3><p>scikitlearn内置了用来生成实验数据集的工具——make_regression和make_classificasion。前者用来生成<strong>回归</strong>任务数据集，后者用来生成<strong>分类</strong>任务数据集</p>
<p>我们先用make_regression来生成数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先导入线性回归模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="comment">#导入数据集拆分工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment">#为了演示，我们使用scikit-learn内置的数据集生成工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"><span class="comment">#导入numpy和pandas</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment">#导入画图工具</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># SimHei表示简体黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span>  <span class="comment"># 为了正确显示负号</span></span><br><span class="line"><span class="comment">#首先我们使用make_regression生成50个样本</span></span><br><span class="line">X, y = make_regression(n_samples = <span class="number">50</span>, </span><br><span class="line">                       <span class="comment">#为了方便画图，设置特征数量为1</span></span><br><span class="line">                       n_features = <span class="number">1</span>, </span><br><span class="line">                       <span class="comment">#加大噪音，这里设置为40</span></span><br><span class="line">                       <span class="comment">#读者朋友可以自己调节来观察区别</span></span><br><span class="line">                       noise = <span class="number">40</span>,</span><br><span class="line">                       <span class="comment">#指定随机状态便于复现</span></span><br><span class="line">                       <span class="comment">#这个数字读者朋友可以随意设置</span></span><br><span class="line">                      random_state = <span class="number">88</span>)</span><br><span class="line"><span class="comment">#使用matplotlib绘制散点图</span></span><br><span class="line">plt.scatter(X,y, </span><br><span class="line">            <span class="comment">#设置散点的尺寸为70</span></span><br><span class="line">            s = <span class="number">70</span>,</span><br><span class="line">            <span class="comment">#设置散点的颜色为green</span></span><br><span class="line">            c = <span class="string">&#x27;g&#x27;</span>, </span><br><span class="line">            <span class="comment">#为了便于观察，设置边缘的颜色为black</span></span><br><span class="line">            edgecolor = <span class="string">&#x27;k&#x27;</span>, </span><br><span class="line">            <span class="comment">#降低透明度，只是为了美观</span></span><br><span class="line">            alpha = <span class="number">0.6</span>)</span><br><span class="line"><span class="comment">#添加网格</span></span><br><span class="line">plt.grid()</span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_183_0.png" alt="output_183_0"></p>
<p>结果分析：图中横轴对应的是<strong>样本的特征</strong>，纵轴对应的是<strong>样本的目标</strong>。当然，我们<strong>噪音参数</strong>只设置为40，所以我们还是可以很明显地观察到样本的特征与目标之间有<strong>显著的线性相关</strong>关系——样本的分布情况大致呈现为<strong>一条直线</strong>。如果我们把噪音参数调高，则样本的分布会面目全非</p>
<p>下面这行代码可以让我们查看某个样本的特征值与目标值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#可以查看一下第一个样本的特征值与目标值</span></span><br><span class="line"><span class="built_in">print</span>(X[<span class="number">0</span>],y[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[-0.2770237835989297] -74.20883782560651
</code></pre>
<p>结果分析：这里，<strong>特征值</strong>是一个数组（用中括号括起来），而目标值是一个浮点数；</p>
<p>因为n_features参数设置为1，所以样本只有一个特征值（中括号里只有一个数字）；第一个样本的特征值大致是-0.277，而目标值大致是-74.2</p>
<h3 id="7-1-2-来试试最简单的线性回归"><a href="#7-1-2-来试试最简单的线性回归" class="headerlink" title="7.1.2 来试试最简单的线性回归"></a>7.1.2 来试试最简单的线性回归</h3><p>公式为：</p>
<p>y^&#x3D;w1x1+w2x2+w3x3+…+wnxn+b</p>
<p>在这个公式中，y^（读作y-hat）表示模型对于样本目标值的预测。模型要做的工作就是找到<strong>特征值x</strong>前面的<strong>系数w</strong>和<strong>偏差b</strong>，使得样本总体的y^与真实的目标值y的<strong>差距最小</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># SimHei表示简体黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span>  <span class="comment"># 为了正确显示负号</span></span><br><span class="line"><span class="comment">#创建一个线性回归实例</span></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="comment">#使用样本的特征与目标值训练线性回归模型</span></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="comment">#为了对模型进行展示，我们生成一些新的数据</span></span><br><span class="line"><span class="comment">#横轴的数值在-2到2.5之间，数量为100个</span></span><br><span class="line">X_new = np.linspace(-<span class="number">2</span>, <span class="number">2.5</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment">#纵轴是模型对这些新数据点作出的预测值</span></span><br><span class="line"><span class="comment">#因为样本只有1个特征，因此要用reshape来处理一下</span></span><br><span class="line">y_new = lr.predict(X_new.reshape(-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#把make_regression生成的样本用散点画出来</span></span><br><span class="line">plt.scatter(X,y, s = <span class="number">70</span>, c = <span class="string">&#x27;g&#x27;</span>, edgecolor = <span class="string">&#x27;k&#x27;</span>, alpha = <span class="number">0.6</span>)</span><br><span class="line"><span class="comment">#用折线图绘制线性回归模型</span></span><br><span class="line">plt.plot(X_new, y_new, c = <span class="string">&#x27;grey&#x27;</span>, ls = <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"><span class="comment">#添加网格</span></span><br><span class="line">plt.grid()</span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_190_0.png" alt="output_190_0"></p>
<p>结果分析：图中我们可以看到一条“斜着”的虚线，这条虚线就是我们使用<strong>线性回归生成的模型</strong>，直观来看，这条线大致可以表达出样本分布的情况。</p>
<p>为什么这条线的位置在这里呢？这是因为这条直线的位置，<strong>距离所有样本的距离之和，是最小的</strong></p>
<p>直线是有<strong>斜率</strong>和<strong>截距</strong>的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看这条直线的斜率与截距</span></span><br><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[95.33470141581209] -1.7453511239155963
</code></pre>
<p>这条直线的斜率大致是95.33，截距大致是-1.75.</p>
<p>也就是说，方程大概可以表示为：y&#x3D;95.33x-1.75</p>
<p>通过这个方程，我们就可以根据样本的<strong>特征值</strong>来估计它的<strong>目标值</strong>了，举例，假设现在我们有一个样本，它的特征值是3，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#样本的特征值是3，用模型预测它的目标值</span></span><br><span class="line">pre = lr.predict([[<span class="number">3</span>]])</span><br><span class="line"><span class="comment">#查看预测值</span></span><br><span class="line">pre</span><br></pre></td></tr></table></figure>




<pre><code>array([284.25875312352065])
</code></pre>
<p>结果分析：调用模型进行预测的方法还是比较简单的——只要使用.predict方法就可以。从代码运行的结果就可以看到，如果某个样本的特征值是3，则它对应的目标值大致是284.259</p>
<p>注意：为了便于可视化，这里我们设置样本<strong>只有一个特征</strong>，因此模型是一条直线。如果样本的特征更多，或者说维度更高的话，模型将会是一个超平面</p>
<h3 id="7-1-3-使用正则化的线性模型"><a href="#7-1-3-使用正则化的线性模型" class="headerlink" title="7.1.3 使用正则化的线性模型"></a>7.1.3 使用正则化的线性模型</h3><p>线性回归有一定的局限性——对于样本较少，且噪音较大的数据集来说，比较容易出现<strong>过度拟合</strong>的现象。</p>
<p>例如，假如老师让小明统计班里同学家长收入情况，大部分同学家长的年收入在10万元到30万元之间，但有少量同学家长的年收入高达数亿元。这些为数不多的家长的收入数字就是统计学上所讲的<strong>离群值</strong>（outliers），会影响整个班级家长收入数据的分布情况。在这种情况下，要反映整体的真实值水平，我们就可以考虑使用带有<strong>正则化</strong>的模型，对特征进行约束</p>
<p><strong>岭回归</strong>就是使用了正则化的线性模型之一</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入岭回归模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="comment">#为了让大家看到区别，把alpha值调高至50</span></span><br><span class="line">ridge = Ridge(alpha = <span class="number">50</span>)</span><br><span class="line"><span class="comment">#使用make_regression生成的样本训练岭回归模型</span></span><br><span class="line">ridge.fit(X, y)</span><br></pre></td></tr></table></figure>




<pre><code>Ridge(alpha=50, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=None, solver=&#39;auto&#39;, tol=0.001)
</code></pre>
<p>我们对岭回归参数进行了返回。这里除了我们设置alpha为50之外，其他参数都是模型缺省设置</p>
<p>通过图像来看一下岭回归模型与线性回归模型的差异</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用岭回归对X_new作出预测</span></span><br><span class="line">y_new2 = ridge.predict(X_new.reshape(-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#把make_regression生成的样本用散点画出来</span></span><br><span class="line">plt.scatter(X,y, s = <span class="number">70</span>, c = <span class="string">&#x27;g&#x27;</span>, edgecolor = <span class="string">&#x27;k&#x27;</span>, alpha = <span class="number">0.6</span>)</span><br><span class="line"><span class="comment">#绘制线性回归模型</span></span><br><span class="line">plt.plot(X_new, y_new, c = <span class="string">&#x27;grey&#x27;</span>, ls = <span class="string">&#x27;--&#x27;</span>,label = <span class="string">&#x27;Linear Rgression&#x27;</span>)</span><br><span class="line"><span class="comment">#绘制岭回归模型</span></span><br><span class="line">plt.plot(X_new, y_new2, c = <span class="string">&#x27;k&#x27;</span>, ls = <span class="string">&#x27;:&#x27;</span>, label = <span class="string">&#x27;Ridge&#x27;</span>)</span><br><span class="line"><span class="comment">#添加网格</span></span><br><span class="line">plt.grid()</span><br><span class="line"><span class="comment">#添加图注</span></span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_201_0.png" alt="output_201_0"></p>
<p>结果分析：岭回归模型对应的那条线要比线性回归模型的线更<strong>“平”</strong>一点，没有那么陡峭。岭回归模型的斜率要比线性回归模型的斜率更小。换句话说，岭回归模型的特征值前面的<strong>权重要小一些</strong>，这也是正则化带来的结果：<strong>使样本特征值中的噪声对模型预测值的影响更小，从而避免模型出现过度拟合的情况</strong></p>
<p>综上所述，如果样本有若干特征，且每个特征都<strong>比较重要（或者噪声较小）</strong>，那我们应该使用<strong>线性回归</strong>来训练模型；反之，如果样本有些特征<strong>没有那么重要（或者噪声比较大）</strong>，那我们可以考虑使用类似<strong>岭回归</strong>这样带有正则化功能的算法来进行模拟的训练</p>
<p>注意：岭回归模型使用的是<strong>L2正则化</strong>，就是它虽然会对样本特征的系数进行约束，但不会让系数变成0，也就是<strong>不会丢弃任何一个特征</strong>，相对地，使用<strong>L1正则化</strong>的算法，是有可能把特征的系数约束到0的（如套索回归），也就是<strong>会完全丢弃样本的某些特征</strong>。因此，如果样本的某些特征<strong>完全没有用的话</strong>，就可以考虑使用套索回归来进行模型的训练</p>
<h2 id="7-2-用线性模型搞搞交易策略"><a href="#7-2-用线性模型搞搞交易策略" class="headerlink" title="7.2 用线性模型搞搞交易策略"></a>7.2 用线性模型搞搞交易策略</h2><p>如何用线性模型来制定交易策略：</p>
<p>假如我们把炒股看作做生意，那么我要做的就是以<strong>较低的价格</strong>买入股票，等<strong>价格涨起来</strong>之后卖出股票。那么问题来了——我们怎么知道股票的价格是在较低的水平，还是在较高的水平</p>
<p>我们提出一个假设——市场是有效的，在某个时期内，企业的估值总是在一定的范围内上下波动（<strong>有时候被低估，有时候被高估</strong>），市场整体存在一个<strong>公允的估值方法</strong>，<strong>被低估的股票迟早会上涨，被高估的股票迟早会回调</strong>。借助线性模型的图可以说明这个假设</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(7).png" alt="下载 (7)"></p>
<p>这个假设有一定道理，我们可以把线性回归模型看作一个市场公允的估值（<strong>在这条线以下的股票是价值被低估的，在这条线以上的股票价值是被高估的</strong>），带着这种假设，来进行实验</p>
<h3 id="7-2-1-准备因子"><a href="#7-2-1-准备因子" class="headerlink" title="7.2.1 准备因子"></a>7.2.1 准备因子</h3><p>既然我们要判断某只股票的估值，我们要用到财务相关的因子：如净资产、资产负债率、净利润、利润的增长、以及在研发方面的投入等等。当然<strong>资产负债率越低，说明财务状况越好。</strong>为了使这个指标与估值呈现<strong>正相关</strong>的关系，我们来取它的倒数，下面我们就来获取这些因子的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入聚宽数据加载工具</span></span><br><span class="line"><span class="keyword">import</span> jqdata</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这回咱们就把上证50成分股作为股票池</span></span><br><span class="line">stocks = get_index_stocks(<span class="string">&#x27;000016.XSHG&#x27;</span>)</span><br><span class="line"><span class="comment">#用query函数获取股票的代码</span></span><br><span class="line">q = query(valuation.code,</span><br><span class="line">          <span class="comment">#还有市值</span></span><br><span class="line">          valuation.market_cap,</span><br><span class="line">          <span class="comment">#净资产，用总资产减去总负债</span></span><br><span class="line">         balance.total_assets - balance.total_liability,</span><br><span class="line">          <span class="comment">#再来一个资产负债率的倒数</span></span><br><span class="line">         balance.total_assets/balance.total_liability,</span><br><span class="line">          <span class="comment">#把净利润也考虑进来</span></span><br><span class="line">         income.net_profit,</span><br><span class="line">          <span class="comment">#还有年度收入增长</span></span><br><span class="line">         indicator.inc_revenue_year_on_year,</span><br><span class="line">          <span class="comment">#研发费用</span></span><br><span class="line">         balance.development_expenditure</span><br><span class="line">         ).<span class="built_in">filter</span>(valuation.code.in_(stocks))</span><br><span class="line"><span class="comment">#将这些数据存入一个数据表中</span></span><br><span class="line">df = get_fundamentals(q)</span><br><span class="line"><span class="comment">#给数据表指定每列的列名称</span></span><br><span class="line">df.columns = [<span class="string">&#x27;code&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;mcap&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;na&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;1/DA ratio&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;net income&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;growth&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;RD&#x27;</span>]</span><br><span class="line"><span class="comment">#检查一下是否成功</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>code</th>
      <th>mcap</th>
      <th>na</th>
      <th>1/DA ratio</th>
      <th>net income</th>
      <th>growth</th>
      <th>RD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>600010.XSHG</td>
      <td>879.7911</td>
      <td>6.198162e+10</td>
      <td>1.721479</td>
      <td>-1.407279e+09</td>
      <td>-30.21</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>600028.XSHG</td>
      <td>5222.6997</td>
      <td>9.255369e+11</td>
      <td>1.822713</td>
      <td>1.339400e+10</td>
      <td>13.41</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>600030.XSHG</td>
      <td>2931.5042</td>
      <td>2.538121e+11</td>
      <td>1.234698</td>
      <td>5.587781e+09</td>
      <td>-25.66</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>600031.XSHG</td>
      <td>1330.0486</td>
      <td>6.596622e+10</td>
      <td>1.746315</td>
      <td>9.901590e+08</td>
      <td>-8.27</td>
      <td>531280000.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>600036.XSHG</td>
      <td>9389.3486</td>
      <td>9.277664e+11</td>
      <td>1.105676</td>
      <td>3.797700e+10</td>
      <td>3.73</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="7-2-2-训练模型"><a href="#7-2-2-训练模型" class="headerlink" title="7.2.2 训练模型"></a>7.2.2 训练模型</h3><p>接下来对数据做预处理，首先，把股票代码作为数据表的index，让它们<strong>不参与模型的训练</strong>；其次，要把数据分成<strong>特征</strong>和<strong>目标</strong>——股票的<strong>市值</strong>作为数据集的<strong>目标值</strong>，<strong>其他财务因子</strong>作为<strong>特征值</strong>；最后，要用0来替换原始数据中的空值，防止在模型训练的过程中产生错误</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把股票代码做成数据表的index</span></span><br><span class="line">df.index = df[<span class="string">&#x27;code&#x27;</span>].values</span><br><span class="line"><span class="comment">#然后把原来代码这一列丢弃掉，防止它参与计算</span></span><br><span class="line">df = df.drop(<span class="string">&#x27;code&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line"><span class="comment">#把除去市值之外的数据作为特征，赋值给X</span></span><br><span class="line">X = df.drop(<span class="string">&#x27;mcap&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line"><span class="comment">#市值这一列作为目标值，赋值给y</span></span><br><span class="line">y = df[<span class="string">&#x27;mcap&#x27;</span>]</span><br><span class="line"><span class="comment">#用0来填补数据中的空值</span></span><br><span class="line">X = X.fillna(<span class="number">0</span>)</span><br><span class="line">y = y.fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用线性回归来拟合数据</span></span><br><span class="line">reg = LinearRegression().fit(X,y)</span><br><span class="line"><span class="comment">#将模型预测值存入数据表</span></span><br><span class="line">predict = pd.DataFrame(reg.predict(X), </span><br><span class="line">                       <span class="comment">#保持和y相同的index，也就是股票的代码</span></span><br><span class="line">                       index = y.index,</span><br><span class="line">                       <span class="comment">#设置一个列名，这个根据你个人爱好就好</span></span><br><span class="line">                       columns = [<span class="string">&#x27;predict_mcap&#x27;</span>])</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">predict.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>predict_mcap</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>600010.XSHG</th>
      <td>1578.503135</td>
    </tr>
    <tr>
      <th>600028.XSHG</th>
      <td>4741.222422</td>
    </tr>
    <tr>
      <th>600030.XSHG</th>
      <td>2414.459326</td>
    </tr>
    <tr>
      <th>600031.XSHG</th>
      <td>1860.004133</td>
    </tr>
    <tr>
      <th>600036.XSHG</th>
      <td>6568.577880</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：通过使用样本股票的特征数据进行训练之后，模型已经可以对股票的市值做出预测了。</p>
<p>以600010为例，可以看到这只股票的真实市值大约是879.79亿元，模型给出的预测市值大约是1578.5亿元，也就是说，模型给出的结论是：<strong>这只股票的价值被低估了</strong></p>
<h3 id="7-2-3-基于模型的预测进行选股"><a href="#7-2-3-基于模型的预测进行选股" class="headerlink" title="7.2.3 基于模型的预测进行选股"></a>7.2.3 基于模型的预测进行选股</h3><p>既然现在的模型已经可以对股票的市值做出预测了，我们就继续验证我们的假设：<strong>把真实的市值比模型预测值低得最多的股票找出来</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用真实的市值，减去模型预测的市值</span></span><br><span class="line">diff = df[<span class="string">&#x27;mcap&#x27;</span>] - predict[<span class="string">&#x27;predict_mcap&#x27;</span>]</span><br><span class="line"><span class="comment">#将两者的差存入一个数据表，index还是用股票的代码</span></span><br><span class="line">diff = pd.DataFrame(diff, index = y.index, columns = [<span class="string">&#x27;diff&#x27;</span>])</span><br><span class="line"><span class="comment">#将该数据表中的值，按生序进行排列</span></span><br><span class="line">diff = diff.sort_values(by = <span class="string">&#x27;diff&#x27;</span>, ascending = <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#找到市值被低估最多的10只股票</span></span><br><span class="line">diff.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>603986.XSHG</th>
      <td>-4087.218052</td>
    </tr>
    <tr>
      <th>601919.XSHG</th>
      <td>-4047.569143</td>
    </tr>
    <tr>
      <th>600276.XSHG</th>
      <td>-3087.546760</td>
    </tr>
    <tr>
      <th>601288.XSHG</th>
      <td>-2341.502871</td>
    </tr>
    <tr>
      <th>601668.XSHG</th>
      <td>-2131.547602</td>
    </tr>
    <tr>
      <th>600585.XSHG</th>
      <td>-1831.204375</td>
    </tr>
    <tr>
      <th>600438.XSHG</th>
      <td>-1677.323115</td>
    </tr>
    <tr>
      <th>601166.XSHG</th>
      <td>-1619.978951</td>
    </tr>
    <tr>
      <th>600436.XSHG</th>
      <td>-1473.564018</td>
    </tr>
    <tr>
      <th>603799.XSHG</th>
      <td>-1435.884564</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：程序计算出实际市值比模型预测市值低的最多的10只股票进行了返回，后面我们将对这个列表中的股票<strong>进行买入并持有</strong>。一旦某只股票的市值上升后，与模型预测的<strong>市值差距将缩小</strong>，这时该股票可能不会再出现在这个列表中，此时就考虑将该股票卖出。</p>
<h2 id="7-3-能不能赚到钱"><a href="#7-3-能不能赚到钱" class="headerlink" title="7.3 能不能赚到钱"></a>7.3 能不能赚到钱</h2><p>根据我们的设想，使用财务因子和线性模型，列出了一个包含若干只股票的表——表中的股票都是市值被<strong>低估</strong>的，交易思路是，当某只股票出现在这个表中，就<strong>买入并持仓</strong>，当原本在列表中的股票从列表中消失时（也急就是市值上升），就将其卖出。</p>
<p>至于这个策略是否可行，我们来回测以下</p>
<p>以下内容在聚宽的策略列表中实现</p>
<p>代码在聚宽——线性回归策略中</p>
<p>结果：<br><img src="%E4%B8%8B%E8%BD%BD%20(8).png" alt="下载 (8)"></p>
<p>结果分析：这个策略确实给我们带来了正向收益，而且收益在绝大多数情况下都跑赢了大盘，再具体指标：三年来，策略的累计收益率为16.1%，年华收益率为5.55%，超额收益率为22.79%</p>
<p>1.<strong>阿尔法</strong>：也就是Alpha，指的是我们通过投资，获得的<strong>与市场波动无关的回报</strong>，简单来说，也就是策略收益比<strong>基准收益</strong>多（或者少）的部分</p>
<p>Alpha&#x3D;$R_p-(R_f+β_P (R_m-R_f ))$</p>
<p>式中，$R_p$是策略的年化收益率，$R_f$是无风险利润（默认0.04），$R_m$是基准收益率，$β_p$是策略的贝塔值。阿尔法值<strong>越大</strong>，说明策略的收益<strong>越高</strong>。如果有个策略的阿尔法值小于0，那说明使用这个策略进行交易，<strong>还不如直接买指数基金赚的多</strong></p>
<p>2.<strong>贝塔</strong>：也是Beta，指的是策略对与<strong>大盘变化</strong>的敏感性。例如，假如大盘上涨了1%，而策略的收益上涨了2%，说明贝塔值在2左右。当然这是粗略的说法，详细的公式是：</p>
<p>Beta&#x3D;$Cov（D_p,D_m）&#x2F;Var(D_m)$</p>
<p>式中，$D_p$指的是每日策略的收益，$D_m$指的是每日的基准收益。Cov指的是协方差，Var指的是方差。</p>
<p>如果β&lt;0，说明策略收益与大盘的走势<strong>相反</strong></p>
<p>如果β&#x3D;0，说明策略收益与大盘走势<strong>没有关系</strong></p>
<p>如果0&lt;β&lt;1，说明策略收益与大盘走势<strong>相同</strong>，但是波动幅度比大盘的波动幅度<strong>小</strong></p>
<p>如果β&gt;1，说明策略收益与大盘走势<strong>相同</strong>，而且波动幅度比大盘的波动幅度<strong>大</strong></p>
<p>3.<strong>夏普比率</strong>：Sharpe Ratio,值的是策略每承受<strong>一单位的风险</strong>，能够产生多少<strong>超额回报</strong>，计算公式为：</p>
<p>Sharpe Ratio&#x3D;$(R_p-R_f)&#x2F;σ_p$</p>
<p>式中，$R_p$是策略的年化收益率，$R_f$是基准收益，$σ_p$是策略收益的标准差，也就是策略收益的波动率。对于收益来说，夏普率的值<strong>越高越好</strong></p>
<p>4.<strong>最大回撤</strong>：也就是Max DrawDown，指的是在一定时间范围内，总资产的<strong>最大值与最小值的差与最大值的比率</strong>。这个指标衡量的是策略可能<strong>带来的亏损</strong>，其计算公式为：</p>
<p>$Max Drawdown &#x3D; Max(P_x-P_y)&#x2F;P_x$</p>
<p>通俗地说，假设某日我们的总资产$P_x$是1万元，而过了若干天，总资产$P_y$缩水倒了8000元，则最大回撤率为（10000-8000）&#x2F;10000x100%&#x3D;20%。即该策略的最大回撤率为20%</p>
<h1 id="第八章-因子遇到决策树与随机森林"><a href="#第八章-因子遇到决策树与随机森林" class="headerlink" title="第八章 因子遇到决策树与随机森林"></a>第八章 因子遇到决策树与随机森林</h1><h2 id="8-1-什么是决策树和随机森林"><a href="#8-1-什么是决策树和随机森林" class="headerlink" title="8.1 什么是决策树和随机森林"></a>8.1 什么是决策树和随机森林</h2><p>当样本的特征与目标没有明显的线性关系时，就要考虑使用<strong>非线性模型</strong></p>
<h3 id="8-1-1-线性模型不适用的数据样本"><a href="#8-1-1-线性模型不适用的数据样本" class="headerlink" title="8.1.1 线性模型不适用的数据样本"></a>8.1.1 线性模型不适用的数据样本</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># SimHei表示简体黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span>  <span class="comment"># 为了正确显示负号</span></span><br><span class="line"><span class="comment">#导入决策树回归器和其它必要的库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>

<p>我们来生成一个数据集，并且这个数据集不适用线性模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#生成一个回归任务数据集，样本数量100</span></span><br><span class="line">X, y  = make_regression(n_samples = <span class="number">100</span>,</span><br><span class="line">                        <span class="comment">#只有一个特征</span></span><br><span class="line">                       n_features = <span class="number">1</span>,</span><br><span class="line">                        <span class="comment">#为了使线性模型不适用</span></span><br><span class="line">                        <span class="comment">#增加噪音值为60</span></span><br><span class="line">                       noise = <span class="number">60</span>,</span><br><span class="line">                        <span class="comment">#设定随机状态，便于复现</span></span><br><span class="line">                       random_state = <span class="number">18</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用散点图将样本进行可视化</span></span><br><span class="line">plt.scatter(X, y, s=<span class="number">80</span>,</span><br><span class="line">            <span class="comment">#下面几个参数都是为了美观</span></span><br><span class="line">           c = y, edgecolor = <span class="string">&#x27;grey&#x27;</span>,</span><br><span class="line">           alpha = <span class="number">0.6</span>)</span><br><span class="line"><span class="comment">#添加网格并展示图像</span></span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_237_0.png" alt="output_237_0"></p>
<p>结果分析：当我们把样本的噪声参数增加到60时，样本不再呈现一条线的分布状况，而是更加“零散”地散布在二维空间中，在这种情况下，使用线性模型进行拟合显然有些不合理</p>
<h3 id="8-1-2-决策树的用法和原理"><a href="#8-1-2-决策树的用法和原理" class="headerlink" title="8.1.2 决策树的用法和原理"></a>8.1.2 决策树的用法和原理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个决策树示例，可以通过调节max_depth参数来防止模型过拟合</span></span><br><span class="line"><span class="comment">#这里我们不限制决策树的max_depth</span></span><br><span class="line">reg = DecisionTreeRegressor(max_depth = <span class="literal">None</span>)</span><br><span class="line"><span class="comment">#使用模型拟合样本数据</span></span><br><span class="line">reg.fit(X,y)</span><br><span class="line"><span class="comment">#为了将模型进行可视化，同样生成一个沿横轴分布的数列</span></span><br><span class="line">X_new = np.linspace(-<span class="number">2.5</span>, <span class="number">3.5</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment">#调用模型对生成数列的目标值作出预测</span></span><br><span class="line">y_new = reg.predict(X_new.reshape(-<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#以下是绘图的部分</span></span><br><span class="line">plt.scatter(X, y, s=<span class="number">80</span>,</span><br><span class="line">           c = y, edgecolor = <span class="string">&#x27;grey&#x27;</span>,</span><br><span class="line">           alpha = <span class="number">0.4</span>)</span><br><span class="line">plt.plot(X_new, y_new, lw = <span class="number">2</span>, </span><br><span class="line">         ls = <span class="string">&#x27;-&#x27;</span>, c=<span class="string">&#x27;grey&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_240_0.png" alt="output_240_0"></p>
<p>结果分析：决策树模型是一条曲线，这条曲线在<strong>尽力地覆盖</strong>所有的样本，以此来提高模型的准确率，也可以说，决策树模型的复杂度比线性模型高了不少</p>
<h3 id="8-1-3-随机森林的用法和原理"><a href="#8-1-3-随机森林的用法和原理" class="headerlink" title="8.1.3 随机森林的用法和原理"></a>8.1.3 随机森林的用法和原理</h3><p>通过观察可以发现，决策树会努力地覆盖样本中的每个点。这种机制可以让模型准确率更高。但是如果样本中有<strong>过多噪声</strong>，模型就难免出现<strong>过拟合</strong>的现象，为了解决这个问题，我们引入一种集成方法——<strong>随机森林</strong></p>
<p>随机森林的原理用一句话概括：<strong>将多棵决策树打包在一起，并且将多棵决策树的预测结果的平均值作为随机森林的预测结果</strong>。这样就可以在一定程度上避免过拟合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入随机森林回归器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="comment">#创建一个随机森林实例，指定森林中有100棵决策树</span></span><br><span class="line">reg2 = RandomForestRegressor(n_estimators=<span class="number">100</span>)</span><br><span class="line"><span class="comment">#使用随机森林拟合数据</span></span><br><span class="line">reg2.fit(X,y)</span><br><span class="line"><span class="comment">#同样对生成对数列进行预测</span></span><br><span class="line">y_new_2 = reg2.predict(X_new.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment">#下面是绘图部分</span></span><br><span class="line">plt.scatter(X, y, s=<span class="number">80</span>,</span><br><span class="line">           c = y, edgecolor = <span class="string">&#x27;grey&#x27;</span>,</span><br><span class="line">           alpha = <span class="number">0.4</span>)</span><br><span class="line"><span class="comment">#将决策树和随机森林的模型进行可视化</span></span><br><span class="line">plt.plot(X_new, y_new, lw = <span class="number">1.5</span>, </span><br><span class="line">         ls = <span class="string">&#x27;-&#x27;</span>, c=<span class="string">&#x27;grey&#x27;</span>,</span><br><span class="line">        label = <span class="string">&#x27;Tree&#x27;</span>)</span><br><span class="line">plt.plot(X_new, y_new_2, lw = <span class="number">1.5</span>, </span><br><span class="line">         ls = <span class="string">&#x27;--&#x27;</span>, c=<span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">        label = <span class="string">&#x27;Forest&#x27;</span>)</span><br><span class="line"><span class="comment">#添加图注、网格并展示</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_244_0.png" alt="output_244_0"></p>
<p>结果分析：实线部分是<strong>决策树模型</strong>，虚线部分是<strong>随机森林模型</strong>，我们可以发现，随机森林模型“波动”的幅度没有决策树模型大。这说明，随机森林模型要比决策树模型<strong>更简单</strong>，相对<strong>不容易受到噪声的干扰</strong>，也就更不容易出现过拟合的现象。</p>
<p>使用下面的代码，可以看见随机森林在的每一棵树</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看随机森林中前两棵决策树</span></span><br><span class="line">reg2.estimators_[:<span class="number">2</span>]</span><br></pre></td></tr></table></figure>




<pre><code>[DecisionTreeRegressor(criterion=&#39;mse&#39;, max_depth=None, max_features=&#39;auto&#39;,
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=68927329, splitter=&#39;best&#39;),
 DecisionTreeRegressor(criterion=&#39;mse&#39;, max_depth=None, max_features=&#39;auto&#39;,
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            presort=False, random_state=936016940, splitter=&#39;best&#39;)]
</code></pre>
<p>结果分析：系统返回了随机森林中前两棵决策树的模型。可以看到，这两棵决策树模型大部分参数是相同的，只有rando_state参数不同。当然仅仅是这个参数的差别也能让两棵决策树的预测结果有一定的差异。在我们的随机森林中，有100棵不同的决策树，这就使得随机森林的预测结果更倾向于<strong>中立</strong>，从而降低过拟合的风险。</p>
<h2 id="8-2-哪些因子重要，决策树能告诉你"><a href="#8-2-哪些因子重要，决策树能告诉你" class="headerlink" title="8.2 哪些因子重要，决策树能告诉你"></a>8.2 哪些因子重要，决策树能告诉你</h2><p>有没有一种可能，我们选的因子对于股价的变动压根儿不重要呢？我们可以借助决策树的“隐藏功能”——<strong>判断特征重要性</strong></p>
<h3 id="8-2-1-多来点因子"><a href="#8-2-1-多来点因子" class="headerlink" title="8.2.1 多来点因子"></a>8.2.1 多来点因子</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#还是先导入jqdata和技术分析工具</span></span><br><span class="line"><span class="keyword">import</span> jqdata</span><br><span class="line"><span class="keyword">from</span> jqlib.technical_analysis <span class="keyword">import</span> *</span><br><span class="line"><span class="comment">#同样选择沪深300成分股做股票池</span></span><br><span class="line">stocks = get_index_stocks(<span class="string">&#x27;000300.XSHG&#x27;</span>)</span><br><span class="line"><span class="comment">#创建query对象，指定获取股票的代码、市值、净运营资本</span></span><br><span class="line"><span class="comment">#净债务、产权比率、股东权益比率、营收增长率、换手率、</span></span><br><span class="line"><span class="comment">#市盈率（PE）、市净率（PB）、市销率（PS）、总资产收益率因子</span></span><br><span class="line">q = query(valuation.code, valuation.market_cap,</span><br><span class="line">           balance.total_current_assets- balance.total_current_liability,</span><br><span class="line">        balance.total_liability- balance.total_assets,</span><br><span class="line">           balance.total_liability/balance.equities_parent_company_owners,</span><br><span class="line">        (balance.total_assets-balance.total_current_assets)/balance.total_assets,</span><br><span class="line">        balance.equities_parent_company_owners/balance.total_assets,</span><br><span class="line">        indicator.inc_total_revenue_year_on_year,</span><br><span class="line">           valuation.turnover_ratio,</span><br><span class="line">        valuation.pe_ratio,</span><br><span class="line">           valuation.pb_ratio,</span><br><span class="line">           valuation.ps_ratio,indicator.roa).<span class="built_in">filter</span>(</span><br><span class="line">     valuation.code.in_(stocks))</span><br><span class="line"><span class="comment">#将获得的因子值存入一个数据表</span></span><br><span class="line">df = get_fundamentals(q, date = <span class="literal">None</span>)</span><br><span class="line"><span class="comment">#把数据表的字段名指定为对应的因子名</span></span><br><span class="line">df.columns = [<span class="string">&#x27;code&#x27;</span>, <span class="string">&#x27;市值&#x27;</span>, <span class="string">&#x27;净营运资本&#x27;</span>, </span><br><span class="line">              <span class="string">&#x27;净债务&#x27;</span>, <span class="string">&#x27;产权比率&#x27;</span>,<span class="string">&#x27;非流动资产比率&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;股东权益比率&#x27;</span>, <span class="string">&#x27;营收增长率&#x27;</span></span><br><span class="line">          ,<span class="string">&#x27;换手率&#x27;</span>,<span class="string">&#x27;PE&#x27;</span>,<span class="string">&#x27;PB&#x27;</span>,<span class="string">&#x27;PS&#x27;</span>,<span class="string">&#x27;总资产收益率&#x27;</span>]</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>code</th>
      <th>市值</th>
      <th>净营运资本</th>
      <th>净债务</th>
      <th>产权比率</th>
      <th>非流动资产比率</th>
      <th>股东权益比率</th>
      <th>营收增长率</th>
      <th>换手率</th>
      <th>PE</th>
      <th>PB</th>
      <th>PS</th>
      <th>总资产收益率</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000001.XSHE</td>
      <td>2528.5911</td>
      <td>NaN</td>
      <td>-4.253842e+11</td>
      <td>11.212808</td>
      <td>NaN</td>
      <td>0.081881</td>
      <td>8.78</td>
      <td>0.3437</td>
      <td>5.7651</td>
      <td>0.7114</td>
      <td>1.4012</td>
      <td>0.28</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000002.XSHE</td>
      <td>2112.1367</td>
      <td>3.139084e+11</td>
      <td>-4.059684e+11</td>
      <td>5.917107</td>
      <td>0.191196</td>
      <td>0.131564</td>
      <td>25.28</td>
      <td>0.6245</td>
      <td>9.2291</td>
      <td>0.8760</td>
      <td>0.4070</td>
      <td>0.49</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000063.XSHE</td>
      <td>1210.0767</td>
      <td>5.596039e+10</td>
      <td>-5.846901e+10</td>
      <td>2.140853</td>
      <td>0.231090</td>
      <td>0.316350</td>
      <td>6.46</td>
      <td>0.5275</td>
      <td>15.5536</td>
      <td>2.1114</td>
      <td>0.9818</td>
      <td>1.19</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000069.XSHE</td>
      <td>433.0547</td>
      <td>1.242620e+11</td>
      <td>-1.190248e+11</td>
      <td>4.336695</td>
      <td>0.235088</td>
      <td>0.171682</td>
      <td>-51.25</td>
      <td>1.0476</td>
      <td>85.6062</td>
      <td>0.5632</td>
      <td>0.5254</td>
      <td>0.03</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000100.XSHE</td>
      <td>631.6600</td>
      <td>4.021854e+09</td>
      <td>-1.217908e+11</td>
      <td>5.793576</td>
      <td>0.730321</td>
      <td>0.112026</td>
      <td>-9.97</td>
      <td>0.6150</td>
      <td>51.4595</td>
      <td>1.3117</td>
      <td>0.3735</td>
      <td>0.01</td>
    </tr>
  </tbody>
</table>
</div>



<p>下面继续获取技术因子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将股票代码作为数据表的index</span></span><br><span class="line">df.index = df.code.values</span><br><span class="line"><span class="comment">#使用del也可以删除列</span></span><br><span class="line"><span class="keyword">del</span> df[<span class="string">&#x27;code&#x27;</span>]</span><br><span class="line"><span class="comment">#下面来把时间变量都定义好</span></span><br><span class="line">today = datetime.datetime.today()</span><br><span class="line"><span class="comment">#设定3个时间差，分别是50天，1天和2天</span></span><br><span class="line">delta50 = datetime.timedelta(days=<span class="number">50</span>)</span><br><span class="line">delta1 = datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line">delta2 = datetime.timedelta(days=<span class="number">2</span>)</span><br><span class="line"><span class="comment">#50日前作为一个历史节点</span></span><br><span class="line">history = today - delta50</span><br><span class="line"><span class="comment">#再计算昨天和2天前的日期</span></span><br><span class="line">yesterday = today - delta1</span><br><span class="line">two_days_ago = today - delta2</span><br><span class="line"><span class="comment">#下面就获取股票的动量线、成交量、累计能量线、平均差、</span></span><br><span class="line"><span class="comment">#指数移动平均、移动平均、乖离率等因子</span></span><br><span class="line"><span class="comment">#时间范围都设为10天</span></span><br><span class="line">df[<span class="string">&#x27;动量线&#x27;</span>]=<span class="built_in">list</span>(MTM(df.index, two_days_ago, </span><br><span class="line">                   timeperiod=<span class="number">10</span>, unit = <span class="string">&#x27;1d&#x27;</span>, </span><br><span class="line">                   include_now = <span class="literal">True</span>, </span><br><span class="line">                   fq_ref_date = <span class="literal">None</span>).values())</span><br><span class="line">df[<span class="string">&#x27;成交量&#x27;</span>]=<span class="built_in">list</span>(VOL(df.index, two_days_ago, M1=<span class="number">10</span> ,</span><br><span class="line">                   unit = <span class="string">&#x27;1d&#x27;</span>, include_now = <span class="literal">True</span>, </span><br><span class="line">                   fq_ref_date = <span class="literal">None</span>)[<span class="number">0</span>].values())</span><br><span class="line">df[<span class="string">&#x27;累计能量线&#x27;</span>]=<span class="built_in">list</span>(OBV(df.index,check_date=two_days_ago, </span><br><span class="line">                     timeperiod=<span class="number">10</span>).values())</span><br><span class="line">df[<span class="string">&#x27;平均差&#x27;</span>]=<span class="built_in">list</span>(DMA(df.index, two_days_ago, N1 = <span class="number">10</span>, </span><br><span class="line">                   unit = <span class="string">&#x27;1d&#x27;</span>, include_now = <span class="literal">True</span>, </span><br><span class="line">                   fq_ref_date = <span class="literal">None</span>)[<span class="number">0</span>].values())</span><br><span class="line">df[<span class="string">&#x27;指数移动平均&#x27;</span>]=<span class="built_in">list</span>(EMA(df.index, two_days_ago, timeperiod=<span class="number">10</span>, </span><br><span class="line">                      unit = <span class="string">&#x27;1d&#x27;</span>, include_now = <span class="literal">True</span>, </span><br><span class="line">                      fq_ref_date = <span class="literal">None</span>).values())</span><br><span class="line">df[<span class="string">&#x27;移动平均&#x27;</span>]=<span class="built_in">list</span>(MA(df.index, two_days_ago, timeperiod=<span class="number">10</span>, </span><br><span class="line">                   unit = <span class="string">&#x27;1d&#x27;</span>, include_now = <span class="literal">True</span>, </span><br><span class="line">                   fq_ref_date = <span class="literal">None</span>).values())</span><br><span class="line">df[<span class="string">&#x27;乖离率&#x27;</span>]=<span class="built_in">list</span>(BIAS(df.index,two_days_ago, N1=<span class="number">10</span>, </span><br><span class="line">                    unit = <span class="string">&#x27;1d&#x27;</span>, include_now = <span class="literal">True</span>, </span><br><span class="line">                    fq_ref_date = <span class="literal">None</span>)[<span class="number">0</span>].values())</span><br><span class="line"><span class="comment">#把数据表中的空值用0来代替</span></span><br><span class="line">df.fillna(<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>市值</th>
      <th>净营运资本</th>
      <th>净债务</th>
      <th>产权比率</th>
      <th>非流动资产比率</th>
      <th>股东权益比率</th>
      <th>营收增长率</th>
      <th>换手率</th>
      <th>PE</th>
      <th>PB</th>
      <th>PS</th>
      <th>总资产收益率</th>
      <th>动量线</th>
      <th>成交量</th>
      <th>累计能量线</th>
      <th>平均差</th>
      <th>指数移动平均</th>
      <th>移动平均</th>
      <th>乖离率</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>000001.XSHE</th>
      <td>2528.5911</td>
      <td>0.000000e+00</td>
      <td>-4.253842e+11</td>
      <td>11.212808</td>
      <td>0.000000</td>
      <td>0.081881</td>
      <td>8.78</td>
      <td>0.3437</td>
      <td>5.7651</td>
      <td>0.7114</td>
      <td>1.4012</td>
      <td>0.28</td>
      <td>-0.09</td>
      <td>791191.98</td>
      <td>256400922.0</td>
      <td>0.9700</td>
      <td>13.022366</td>
      <td>13.008</td>
      <td>1.014760</td>
    </tr>
    <tr>
      <th>000002.XSHE</th>
      <td>2112.1367</td>
      <td>3.139084e+11</td>
      <td>-4.059684e+11</td>
      <td>5.917107</td>
      <td>0.191196</td>
      <td>0.131564</td>
      <td>25.28</td>
      <td>0.6245</td>
      <td>9.2291</td>
      <td>0.8760</td>
      <td>0.4070</td>
      <td>0.49</td>
      <td>-0.67</td>
      <td>397502.52</td>
      <td>98804905.0</td>
      <td>1.9286</td>
      <td>18.731235</td>
      <td>18.823</td>
      <td>-1.290974</td>
    </tr>
    <tr>
      <th>000063.XSHE</th>
      <td>1210.0767</td>
      <td>5.596039e+10</td>
      <td>-5.846901e+10</td>
      <td>2.140853</td>
      <td>0.231090</td>
      <td>0.316350</td>
      <td>6.46</td>
      <td>0.5275</td>
      <td>15.5536</td>
      <td>2.1114</td>
      <td>0.9818</td>
      <td>1.19</td>
      <td>-1.44</td>
      <td>200173.15</td>
      <td>-75924871.0</td>
      <td>1.1390</td>
      <td>25.484054</td>
      <td>25.535</td>
      <td>-1.390249</td>
    </tr>
    <tr>
      <th>000069.XSHE</th>
      <td>433.0547</td>
      <td>1.242620e+11</td>
      <td>-1.190248e+11</td>
      <td>4.336695</td>
      <td>0.235088</td>
      <td>0.171682</td>
      <td>-51.25</td>
      <td>1.0476</td>
      <td>85.6062</td>
      <td>0.5632</td>
      <td>0.5254</td>
      <td>0.03</td>
      <td>-0.27</td>
      <td>473075.15</td>
      <td>121838216.0</td>
      <td>0.4384</td>
      <td>5.519886</td>
      <td>5.521</td>
      <td>-0.742619</td>
    </tr>
    <tr>
      <th>000100.XSHE</th>
      <td>631.6600</td>
      <td>4.021854e+09</td>
      <td>-1.217908e+11</td>
      <td>5.793576</td>
      <td>0.730321</td>
      <td>0.112026</td>
      <td>-9.97</td>
      <td>0.6150</td>
      <td>51.4595</td>
      <td>1.3117</td>
      <td>0.3735</td>
      <td>0.01</td>
      <td>-0.17</td>
      <td>690095.26</td>
      <td>-72103607.0</td>
      <td>-0.2730</td>
      <td>3.790962</td>
      <td>3.792</td>
      <td>-1.635021</td>
    </tr>
  </tbody>
</table>
</div>



<p>以上表格包括了财务因子和技术因子。关于技术因子，<strong>我们选择的是两天前的数据，用它们来预测一天前股票价格变动带来的收益，并找到相对更重要的因子</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Index: 300 entries, 000001.XSHE to 688981.XSHG
Data columns (total 19 columns):
市值         300 non-null float64
净营运资本      300 non-null float64
净债务        300 non-null float64
产权比率       300 non-null float64
非流动资产比率    300 non-null float64
股东权益比率     300 non-null float64
营收增长率      300 non-null float64
换手率        300 non-null float64
PE         300 non-null float64
PB         300 non-null float64
PS         300 non-null float64
总资产收益率     300 non-null float64
动量线        300 non-null float64
成交量        300 non-null float64
累计能量线      300 non-null float64
平均差        300 non-null float64
指数移动平均     300 non-null float64
移动平均       300 non-null float64
乖离率        300 non-null float64
dtypes: float64(19)
memory usage: 46.9+ KB
</code></pre>
<h3 id="8-2-2-设定目标并训练模型"><a href="#8-2-2-设定目标并训练模型" class="headerlink" title="8.2.2 设定目标并训练模型"></a>8.2.2 设定目标并训练模型</h3><p>设定目标：我们的思路是，<strong>先找到股票的历史收盘价（如前50天），再用前一天的收盘价除以50天前的收盘价并减1，计算出这50天来股票的收益</strong>；然后我们找到那些收益水平大于平均水平的股票，标记为1，其余标记为0，作为模型的分类标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取股票前一日的收盘价</span></span><br><span class="line">df[<span class="string">&#x27;close1&#x27;</span>]=<span class="built_in">list</span>(get_price(stocks, </span><br><span class="line">                       end_date=yesterday, </span><br><span class="line">                       count = <span class="number">1</span>,</span><br><span class="line">                       fq=<span class="string">&#x27;pre&#x27;</span>,panel=<span class="literal">False</span>)[<span class="string">&#x27;close&#x27;</span>])</span><br><span class="line"><span class="comment">#获取股票50日前的收盘价</span></span><br><span class="line">df[<span class="string">&#x27;close2&#x27;</span>]=<span class="built_in">list</span>(get_price(stocks,  </span><br><span class="line">                       end_date=history, </span><br><span class="line">                       count = <span class="number">1</span>,</span><br><span class="line">                       fq =<span class="string">&#x27;pre&#x27;</span>,panel=<span class="literal">False</span>)[<span class="string">&#x27;close&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算出收益</span></span><br><span class="line">df[<span class="string">&#x27;return&#x27;</span>]=df[<span class="string">&#x27;close1&#x27;</span>]/df[<span class="string">&#x27;close2&#x27;</span>]-<span class="number">1</span></span><br><span class="line"><span class="comment">#如果收益大于平均水平，则标记为1</span></span><br><span class="line"><span class="comment">#否则标记为0</span></span><br><span class="line">df[<span class="string">&#x27;signal&#x27;</span>]=np.where(df[<span class="string">&#x27;return&#x27;</span>]&lt;df[<span class="string">&#x27;return&#x27;</span>].mean(),<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>市值</th>
      <th>净营运资本</th>
      <th>净债务</th>
      <th>产权比率</th>
      <th>非流动资产比率</th>
      <th>股东权益比率</th>
      <th>营收增长率</th>
      <th>换手率</th>
      <th>PE</th>
      <th>PB</th>
      <th>PS</th>
      <th>总资产收益率</th>
      <th>动量线</th>
      <th>成交量</th>
      <th>累计能量线</th>
      <th>平均差</th>
      <th>指数移动平均</th>
      <th>移动平均</th>
      <th>乖离率</th>
      <th>close1</th>
      <th>close2</th>
      <th>return</th>
      <th>signal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>000001.XSHE</th>
      <td>2528.5911</td>
      <td>0.000000e+00</td>
      <td>-4.253842e+11</td>
      <td>11.212808</td>
      <td>0.000000</td>
      <td>0.081881</td>
      <td>8.78</td>
      <td>0.3437</td>
      <td>5.7651</td>
      <td>0.7114</td>
      <td>1.4012</td>
      <td>0.28</td>
      <td>-0.09</td>
      <td>791191.98</td>
      <td>256400922.0</td>
      <td>0.9700</td>
      <td>13.022366</td>
      <td>13.008</td>
      <td>1.014760</td>
      <td>13.03</td>
      <td>10.87</td>
      <td>0.198712</td>
      <td>1</td>
    </tr>
    <tr>
      <th>000002.XSHE</th>
      <td>2112.1367</td>
      <td>3.139084e+11</td>
      <td>-4.059684e+11</td>
      <td>5.917107</td>
      <td>0.191196</td>
      <td>0.131564</td>
      <td>25.28</td>
      <td>0.6245</td>
      <td>9.2291</td>
      <td>0.8760</td>
      <td>0.4070</td>
      <td>0.49</td>
      <td>-0.67</td>
      <td>397502.52</td>
      <td>98804905.0</td>
      <td>1.9286</td>
      <td>18.731235</td>
      <td>18.823</td>
      <td>-1.290974</td>
      <td>18.16</td>
      <td>14.33</td>
      <td>0.267271</td>
      <td>1</td>
    </tr>
    <tr>
      <th>000063.XSHE</th>
      <td>1210.0767</td>
      <td>5.596039e+10</td>
      <td>-5.846901e+10</td>
      <td>2.140853</td>
      <td>0.231090</td>
      <td>0.316350</td>
      <td>6.46</td>
      <td>0.5275</td>
      <td>15.5536</td>
      <td>2.1114</td>
      <td>0.9818</td>
      <td>1.19</td>
      <td>-1.44</td>
      <td>200173.15</td>
      <td>-75924871.0</td>
      <td>1.1390</td>
      <td>25.484054</td>
      <td>25.535</td>
      <td>-1.390249</td>
      <td>25.55</td>
      <td>22.89</td>
      <td>0.116208</td>
      <td>1</td>
    </tr>
    <tr>
      <th>000069.XSHE</th>
      <td>433.0547</td>
      <td>1.242620e+11</td>
      <td>-1.190248e+11</td>
      <td>4.336695</td>
      <td>0.235088</td>
      <td>0.171682</td>
      <td>-51.25</td>
      <td>1.0476</td>
      <td>85.6062</td>
      <td>0.5632</td>
      <td>0.5254</td>
      <td>0.03</td>
      <td>-0.27</td>
      <td>473075.15</td>
      <td>121838216.0</td>
      <td>0.4384</td>
      <td>5.519886</td>
      <td>5.521</td>
      <td>-0.742619</td>
      <td>5.28</td>
      <td>4.60</td>
      <td>0.147826</td>
      <td>1</td>
    </tr>
    <tr>
      <th>000100.XSHE</th>
      <td>631.6600</td>
      <td>4.021854e+09</td>
      <td>-1.217908e+11</td>
      <td>5.793576</td>
      <td>0.730321</td>
      <td>0.112026</td>
      <td>-9.97</td>
      <td>0.6150</td>
      <td>51.4595</td>
      <td>1.3117</td>
      <td>0.3735</td>
      <td>0.01</td>
      <td>-0.17</td>
      <td>690095.26</td>
      <td>-72103607.0</td>
      <td>-0.2730</td>
      <td>3.790962</td>
      <td>3.792</td>
      <td>-1.635021</td>
      <td>3.70</td>
      <td>4.08</td>
      <td>-0.093137</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：closa1,close2,return和signal，它们分别对应的是1天前的收盘价、50天前的收盘价、该时间段内的收益，以及收益是否大于平均值。signal这一列是训练模型用的分类标签。</p>
<p>现在数据集已经准备就绪，我们可以开始训练模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入数据集拆分工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment">#导入决策树分类器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="comment">#把因子值作为样本的特征，所以要去掉刚刚添加的几个字段</span></span><br><span class="line">X = df.drop([<span class="string">&#x27;close1&#x27;</span>, <span class="string">&#x27;close2&#x27;</span>, <span class="string">&#x27;return&#x27;</span>, <span class="string">&#x27;signal&#x27;</span>], axis = <span class="number">1</span>)</span><br><span class="line"><span class="comment">#把signal作为分类标签</span></span><br><span class="line">y = df[<span class="string">&#x27;signal&#x27;</span>]</span><br><span class="line"><span class="comment">#将数据拆分为训练集和验证集</span></span><br><span class="line">X_train,X_test,y_train,y_test=\</span><br><span class="line">train_test_split(X,y,test_size = <span class="number">0.2</span>)</span><br><span class="line"><span class="comment">#创建决策树分类器实例，指定random_state便于复现</span></span><br><span class="line">clf = DecisionTreeClassifier(random_state=<span class="number">1000</span>)</span><br><span class="line"><span class="comment">#拟合训练集数据</span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#查看分类器在训练集和验证集中的准确率</span></span><br><span class="line"><span class="built_in">print</span>(clf.score(X_train, y_train),</span><br><span class="line">      clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure>

<pre><code>1.0 0.7333333333333333
</code></pre>
<p>结果分析：从代码运行结果来看，决策树模型的表现比较不错——训练集的准确率达到了100%，在验证集中的准确率达到了73.3%，这样的情况下，我们相信模型给出的<strong>特征重要性</strong>还是有一定参考价值的</p>
<h3 id="8-2-3-哪些因子重要"><a href="#8-2-3-哪些因子重要" class="headerlink" title="8.2.3 哪些因子重要"></a>8.2.3 哪些因子重要</h3><p>决策树的属性——feature_importances_存储的是模型判断的样本特征的<strong>重要程度</strong>，为了便于查看，我们把这个属性存储到一个列表中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了便于观察，我们创建一个数据表</span></span><br><span class="line"><span class="comment">#数据表有两个字段，分别是特征名和重要性</span></span><br><span class="line"><span class="comment">#特征名就是因子的名称</span></span><br><span class="line"><span class="comment">#重要性就是决策树给出的feature_importances_</span></span><br><span class="line">factor_weight = pd.DataFrame(&#123;<span class="string">&#x27;features&#x27;</span>:<span class="built_in">list</span>(X.columns),</span><br><span class="line">                             <span class="string">&#x27;importance&#x27;</span>:clf.feature_importances_&#125;).sort_values(</span><br><span class="line">    <span class="comment">#这里根据重要程度降序排列，一遍遍找到重要性最高的特征</span></span><br><span class="line">    by=<span class="string">&#x27;importance&#x27;</span>, ascending = <span class="literal">False</span>)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">factor_weight</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>features</th>
      <th>importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15</th>
      <td>平均差</td>
      <td>0.647979</td>
    </tr>
    <tr>
      <th>18</th>
      <td>乖离率</td>
      <td>0.092945</td>
    </tr>
    <tr>
      <th>6</th>
      <td>营收增长率</td>
      <td>0.067748</td>
    </tr>
    <tr>
      <th>14</th>
      <td>累计能量线</td>
      <td>0.035882</td>
    </tr>
    <tr>
      <th>1</th>
      <td>净营运资本</td>
      <td>0.024896</td>
    </tr>
    <tr>
      <th>16</th>
      <td>指数移动平均</td>
      <td>0.023317</td>
    </tr>
    <tr>
      <th>11</th>
      <td>总资产收益率</td>
      <td>0.022228</td>
    </tr>
    <tr>
      <th>5</th>
      <td>股东权益比率</td>
      <td>0.021581</td>
    </tr>
    <tr>
      <th>10</th>
      <td>PS</td>
      <td>0.016496</td>
    </tr>
    <tr>
      <th>3</th>
      <td>产权比率</td>
      <td>0.015836</td>
    </tr>
    <tr>
      <th>12</th>
      <td>动量线</td>
      <td>0.015574</td>
    </tr>
    <tr>
      <th>8</th>
      <td>PE</td>
      <td>0.015519</td>
    </tr>
    <tr>
      <th>17</th>
      <td>移动平均</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>0</th>
      <td>市值</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>13</th>
      <td>成交量</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>7</th>
      <td>换手率</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>非流动资产比率</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>净债务</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>9</th>
      <td>PB</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：在所有因子中，平均差（DMA）这个因子的重要性竟然是最高的，达到了0.647，远远超过其他因子</p>
<p>平均差因子的含义是：<strong>短期均线的数值减去长期均线的数值</strong>，这里的DMA是默认的参数，也就是10天均线减去50天均线</p>
<h2 id="8-3-用重要因子和随机森林来制订策略"><a href="#8-3-用重要因子和随机森林来制订策略" class="headerlink" title="8.3 用重要因子和随机森林来制订策略"></a>8.3 用重要因子和随机森林来制订策略</h2><p>既然我们找到了一些对收益影响最多的因子，那就来用这些因子训练模型制定交易策略。使用模型进行回归分析，找到价值低估的股票，并编写策略进行回测</p>
<p>注意：接下来的代码无用，转而去看聚宽上的——随机森林策略</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">stocks = get_index_stocks(<span class="string">&#x27;000300.XSHG&#x27;</span>)</span><br><span class="line">q = query(valuation.code,valuation.market_cap).<span class="built_in">filter</span>(</span><br><span class="line">     valuation.code.in_(stocks))</span><br><span class="line">dataset = get_fundamentals(q)</span><br><span class="line">dataset[<span class="string">&#x27;平均差&#x27;</span>] = <span class="built_in">list</span>(DMA(dataset.code, yesterday)[<span class="number">0</span>].values())</span><br><span class="line">dataset[<span class="string">&#x27;换手率&#x27;</span>] = <span class="built_in">list</span>(HSL(dataset.code, yesterday)[<span class="number">0</span>].values())</span><br><span class="line">dataset[<span class="string">&#x27;移动平均&#x27;</span>] = <span class="built_in">list</span>(MA(dataset.code, yesterday).values())</span><br><span class="line">dataset[<span class="string">&#x27;乖离率&#x27;</span>] = <span class="built_in">list</span>(BIAS(dataset.code, yesterday)[<span class="number">0</span>].values())</span><br><span class="line">dataset[<span class="string">&#x27;动量线&#x27;</span>] = <span class="built_in">list</span>(MTM(dataset.code,yesterday).values())</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>code</th>
      <th>market_cap</th>
      <th>平均差</th>
      <th>换手率</th>
      <th>移动平均</th>
      <th>乖离率</th>
      <th>动量线</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000001.XSHE</td>
      <td>2528.5911</td>
      <td>0.9264</td>
      <td>0.343660</td>
      <td>13.006</td>
      <td>0.256476</td>
      <td>-0.21</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000002.XSHE</td>
      <td>2112.1367</td>
      <td>1.7918</td>
      <td>0.624520</td>
      <td>18.480</td>
      <td>-1.952668</td>
      <td>-1.32</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000063.XSHE</td>
      <td>1210.0767</td>
      <td>0.9688</td>
      <td>0.527461</td>
      <td>25.334</td>
      <td>1.088032</td>
      <td>-0.80</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000069.XSHE</td>
      <td>433.0547</td>
      <td>0.4030</td>
      <td>1.047584</td>
      <td>5.420</td>
      <td>-2.822086</td>
      <td>-0.46</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000100.XSHE</td>
      <td>631.6600</td>
      <td>-0.2826</td>
      <td>0.615023</td>
      <td>3.732</td>
      <td>-0.715564</td>
      <td>-0.21</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset.index = dataset.code</span><br><span class="line">dataset.drop(<span class="string">&#x27;code&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>market_cap</th>
      <th>平均差</th>
      <th>换手率</th>
      <th>移动平均</th>
      <th>乖离率</th>
      <th>动量线</th>
    </tr>
    <tr>
      <th>code</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>000001.XSHE</th>
      <td>2528.5911</td>
      <td>0.9264</td>
      <td>0.343660</td>
      <td>13.006</td>
      <td>0.256476</td>
      <td>-0.21</td>
    </tr>
    <tr>
      <th>000002.XSHE</th>
      <td>2112.1367</td>
      <td>1.7918</td>
      <td>0.624520</td>
      <td>18.480</td>
      <td>-1.952668</td>
      <td>-1.32</td>
    </tr>
    <tr>
      <th>000063.XSHE</th>
      <td>1210.0767</td>
      <td>0.9688</td>
      <td>0.527461</td>
      <td>25.334</td>
      <td>1.088032</td>
      <td>-0.80</td>
    </tr>
    <tr>
      <th>000069.XSHE</th>
      <td>433.0547</td>
      <td>0.4030</td>
      <td>1.047584</td>
      <td>5.420</td>
      <td>-2.822086</td>
      <td>-0.46</td>
    </tr>
    <tr>
      <th>000100.XSHE</th>
      <td>631.6600</td>
      <td>-0.2826</td>
      <td>0.615023</td>
      <td>3.732</td>
      <td>-0.715564</td>
      <td>-0.21</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">reg = RandomForestRegressor(random_state=<span class="number">20</span>)</span><br><span class="line">X = dataset.drop(<span class="string">&#x27;market_cap&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line">y = dataset[<span class="string">&#x27;market_cap&#x27;</span>]</span><br><span class="line">reg.fit(X,y)</span><br><span class="line"></span><br><span class="line">predict = pd.DataFrame(reg.predict(X), </span><br><span class="line">                       <span class="comment">#保持和y相同的index，也就是股票的代码</span></span><br><span class="line">                       index = y.index,</span><br><span class="line">                       <span class="comment">#设置一个列名，这个根据你个人爱好就好</span></span><br><span class="line">                       columns = [<span class="string">&#x27;predict_mcap&#x27;</span>])</span><br><span class="line"><span class="comment">#使用真实的市值，减去模型预测的市值</span></span><br><span class="line">diff = dataset[<span class="string">&#x27;market_cap&#x27;</span>] - predict[<span class="string">&#x27;predict_mcap&#x27;</span>]</span><br><span class="line"><span class="comment">#将两者的差存入一个数据表，index还是用股票的代码</span></span><br><span class="line">diff = pd.DataFrame(diff, index = y.index, columns = [<span class="string">&#x27;diff&#x27;</span>])</span><br><span class="line"><span class="comment">#将该数据表中的值，按生序进行排列</span></span><br><span class="line">diff = diff.sort_values(by = <span class="string">&#x27;diff&#x27;</span>, ascending = <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#找到市值被低估最多的10只股票</span></span><br><span class="line">diff.diff</span><br></pre></td></tr></table></figure>




<pre><code>&lt;bound method DataFrame.diff of                    diff
code                   
002032.XSHE -3457.69843
600606.XSHG -3032.12636
601390.XSHG -2687.79675
601668.XSHG -2225.65243
300595.XSHE -1802.05338
300751.XSHE -1722.25609
688363.XSHG -1661.99326
603833.XSHG -1574.83712
600332.XSHG -1555.53435
002252.XSHE -1518.26201
300769.XSHE -1506.47182
600115.XSHG -1502.14917
002555.XSHE -1495.35866
601009.XSHG -1478.46858
300896.XSHE -1470.28062
603486.XSHG -1439.11373
300413.XSHE -1413.75560
603986.XSHG -1386.54560
600745.XSHG -1371.08463
000625.XSHE -1266.33087
600362.XSHG -1237.12706
601336.XSHG -1237.06657
600025.XSHG -1146.93954
002601.XSHE -1128.63898
000596.XSHE -1096.22128
600426.XSHG -1086.99393
003816.XSHE -1083.00372
002311.XSHE -1051.53796
601728.XSHG  -962.16691
000786.XSHE  -951.41011
...                 ...
600030.XSHG   512.18582
601166.XSHG   537.39571
000651.XSHE   542.37472
601319.XSHG   740.86340
002475.XSHE   762.42913
601899.XSHG   771.83105
300059.XSHE   778.49319
600276.XSHG   850.14143
002714.XSHE   880.74165
000333.XSHE   897.84908
603288.XSHG   911.60087
688981.XSHG   912.38874
300015.XSHE   932.99456
601012.XSHG   975.18165
601633.XSHG  1118.51824
601658.XSHG  1413.96586
600036.XSHG  1495.56422
600900.XSHG  1614.14414
600028.XSHG  1642.24899
000858.XSHE  2046.33541
601088.XSHG  2418.78792
601857.XSHG  2481.43953
601288.XSHG  2636.47093
002594.XSHE  2727.37020
300750.XSHE  2917.27644
601318.XSHG  3575.00548
600941.XSHG  4186.84610
601398.XSHG  4270.32446
600519.XSHG  4409.03137
601939.XSHG  5232.13002

[300 rows x 1 columns]&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reg.score(X,y)</span><br></pre></td></tr></table></figure>




<pre><code>0.8498808937397061
</code></pre>
<h3 id="8-3-6-对策略进行回测"><a href="#8-3-6-对策略进行回测" class="headerlink" title="8.3.6 对策略进行回测"></a>8.3.6 对策略进行回测</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(9).png" alt="下载 (9)"></p>
<p>结果分析：经过决策树遴选出的因子，再加上随机森林模型的选股，我们的策略收益与第七章中使用线性模型的策略相比，略微提高了一些——累计收益率达到了18.44%，年化收益率达到了5.98%,不过需要注意的是，这个策略的最大回撤率高一些，超过了30%，这比第七章还略高</p>
<p>思考：因子的重要程度会不会在不同的时期发生变化呢？换句话说，有些因子是否会在某个时间<strong>失效</strong>呢？看第九章</p>
<h1 id="第九章-因子遇到支持向量机"><a href="#第九章-因子遇到支持向量机" class="headerlink" title="第九章 因子遇到支持向量机"></a>第九章 因子遇到支持向量机</h1><h2 id="9-1-什么是支持向量机"><a href="#9-1-什么是支持向量机" class="headerlink" title="9.1 什么是支持向量机"></a>9.1 什么是支持向量机</h2><h3 id="9-1-1-支持向量机的基本原理"><a href="#9-1-1-支持向量机的基本原理" class="headerlink" title="9.1.1 支持向量机的基本原理"></a>9.1.1 支持向量机的基本原理</h3><p>“支持” “向量”</p>
<p>拿分类任务来举例子：模型要能够将样本<strong>根据特征</strong>归纳至<strong>不同的类别</strong>，就会有一个区分的“边界”。而支持模型找到这个“边界”的向量就是支持向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先导入要用的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#导入支持向量机分类模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="comment">#这里我们用scikit-learn自带的样本生成工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="comment">#生成50个样本，分成2个类</span></span><br><span class="line"><span class="comment">#注意cluster_std设为1，使两类样本比较容易区分</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">50</span>, centers=<span class="number">2</span>, random_state=<span class="number">6</span>,cluster_std=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#创建svc实例，选择线性内核</span></span><br><span class="line"><span class="comment">#正则化参数我们设大一点，为1000</span></span><br><span class="line">clf = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, C=<span class="number">1000</span>)</span><br><span class="line"><span class="comment">#拟合样本数据</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"><span class="comment">#下面来画图，首先是用散点图来绘制样本</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, s=<span class="number">30</span>, cmap=plt.cm.Paired)</span><br><span class="line"><span class="comment">#然后找到样本的上下限</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">xlim = ax.get_xlim()</span><br><span class="line">ylim = ax.get_ylim()</span><br><span class="line"><span class="comment">#在画布中创建网格，以便绘制决策边界</span></span><br><span class="line">xx = np.linspace(xlim[<span class="number">0</span>], xlim[<span class="number">1</span>], <span class="number">30</span>)</span><br><span class="line">yy = np.linspace(ylim[<span class="number">0</span>], ylim[<span class="number">1</span>], <span class="number">30</span>)</span><br><span class="line">YY, XX = np.meshgrid(yy, xx)</span><br><span class="line">xy = np.vstack([XX.ravel(), YY.ravel()]).T</span><br><span class="line">Z = clf.decision_function(xy).reshape(XX.shape)</span><br><span class="line"><span class="comment">#绘制决策边界</span></span><br><span class="line">ax.contour(XX, YY, Z, colors=<span class="string">&#x27;k&#x27;</span>, levels=[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>], alpha=<span class="number">0.5</span>,</span><br><span class="line">           linestyles=[<span class="string">&#x27;--&#x27;</span>, <span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;--&#x27;</span>])</span><br><span class="line"><span class="comment">#找出支持向量</span></span><br><span class="line">ax.scatter(clf.support_vectors_[:, <span class="number">0</span>], clf.support_vectors_[:, <span class="number">1</span>], s=<span class="number">100</span>,</span><br><span class="line">           linewidth=<span class="number">1</span>, facecolors=<span class="string">&#x27;none&#x27;</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_281_0.png" alt="output_281_0"></p>
<p>结果分析：在50个样本中，有3个样本被选了出来（图中黑色圆圈中的点）。这三个样本，作为支持模型进行分类的向量，帮助模型找到了决策边界（图中的黑色实线）。这就是“支持向量机”名称的由来</p>
<h3 id="9-1-2-线性内核有时“很着急”"><a href="#9-1-2-线性内核有时“很着急”" class="headerlink" title="9.1.2 线性内核有时“很着急”"></a>9.1.2 线性内核有时“很着急”</h3><p>从上图来看，支持向量机和线性模型的样子很像，那二者有什么区别呢？</p>
<p>确实，因为我们这里设置了支持向量机的内核为线性（linear），所以模型表现出来的样子就与线性模型非常接近了。不过，假设分布不像上图那样可以用一条直线来分割的话，恐怕线性内核的支持向量机就会表现得差一点</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#重新生成数据，这次把cluster_std增加到3</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">50</span>, centers=<span class="number">2</span>, random_state=<span class="number">6</span>,cluster_std=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#下面的代码不变</span></span><br><span class="line">clf = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, C=<span class="number">1000</span>)</span><br><span class="line"><span class="comment">#拟合样本数据</span></span><br><span class="line">clf.fit(X, y)</span><br><span class="line"><span class="comment">#下面来画图，首先是用散点图来绘制样本</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, s=<span class="number">30</span>, cmap=plt.cm.Paired)</span><br><span class="line"><span class="comment">#然后找到样本的上下限</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">xlim = ax.get_xlim()</span><br><span class="line">ylim = ax.get_ylim()</span><br><span class="line"><span class="comment">#在画布中创建网格，以便绘制决策边界</span></span><br><span class="line">xx = np.linspace(xlim[<span class="number">0</span>], xlim[<span class="number">1</span>], <span class="number">30</span>)</span><br><span class="line">yy = np.linspace(ylim[<span class="number">0</span>], ylim[<span class="number">1</span>], <span class="number">30</span>)</span><br><span class="line">YY, XX = np.meshgrid(yy, xx)</span><br><span class="line">xy = np.vstack([XX.ravel(), YY.ravel()]).T</span><br><span class="line">Z = clf.decision_function(xy).reshape(XX.shape)</span><br><span class="line"><span class="comment">#绘制决策边界</span></span><br><span class="line">ax.contour(XX, YY, Z, colors=<span class="string">&#x27;k&#x27;</span>, levels=[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>], alpha=<span class="number">0.5</span>,</span><br><span class="line">           linestyles=[<span class="string">&#x27;--&#x27;</span>, <span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;--&#x27;</span>])</span><br><span class="line"><span class="comment">#找出支持向量</span></span><br><span class="line">ax.scatter(clf.support_vectors_[:, <span class="number">0</span>], clf.support_vectors_[:, <span class="number">1</span>], s=<span class="number">100</span>,</span><br><span class="line">           linewidth=<span class="number">1</span>, facecolors=<span class="string">&#x27;none&#x27;</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_285_0.png" alt="output_285_0"></p>
<p>当我们把cluster_std的值增加到5的时候，虽然线性内核的支持向量机能够做出分类预测，但是正确率下降了很多——很多样本的分类都是错误的。这也是线性内核的局限性所在</p>
<h3 id="9-1-3-RBF内核“闪亮登场”"><a href="#9-1-3-RBF内核“闪亮登场”" class="headerlink" title="9.1.3 RBF内核“闪亮登场”"></a>9.1.3 RBF内核“闪亮登场”</h3><p>RBF内核全称是径向基内核，它是利用样本在空间中的<strong>欧式距离</strong>来判断样本是否处于同一个分类当中。因此，我们只要控制径向基内核的<strong>距离参数</strong>，就能够调节模型的<strong>拟合度</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在创建一个支持向量机实例</span></span><br><span class="line"><span class="comment">#这次把kernel设置为rbf</span></span><br><span class="line">clf2 = svm.SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>, C=<span class="number">1000</span>)</span><br><span class="line"><span class="comment">#拟合数据</span></span><br><span class="line">clf2.fit(X, y)</span><br><span class="line"><span class="comment">#下面画图的部分同上</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, s=<span class="number">30</span>, cmap=plt.cm.Paired)</span><br><span class="line">ax = plt.gca()</span><br><span class="line">xlim = ax.get_xlim()</span><br><span class="line">ylim = ax.get_ylim()</span><br><span class="line">Z2 = clf2.decision_function(xy).reshape(XX.shape)</span><br><span class="line">ax.contour(XX, YY, Z2, colors=<span class="string">&#x27;k&#x27;</span>, levels=[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>], alpha=<span class="number">0.5</span>,</span><br><span class="line">           linestyles=[<span class="string">&#x27;--&#x27;</span>, <span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;--&#x27;</span>])</span><br><span class="line">ax.scatter(clf2.support_vectors_[:, <span class="number">0</span>], clf2.support_vectors_[:, <span class="number">1</span>], s=<span class="number">100</span>,</span><br><span class="line">           linewidth=<span class="number">1</span>, facecolors=<span class="string">&#x27;none&#x27;</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_289_0.png" alt="output_289_0"></p>
<p>结果分析：RBF内核的支持向量机它不再是用一条直线去尝试将样本进行分类，而是根据不同类别样本的距离，在空间中划分出若干个“区域”，然后把处于不同区域的样本放入对应的类别中</p>
<h2 id="9-2-动态因子选择策略"><a href="#9-2-动态因子选择策略" class="headerlink" title="9.2 动态因子选择策略"></a>9.2 动态因子选择策略</h2><p>在第7章和第8章中，我们使用机器学习算法和多因子做的策略虽然说年化率都不高，我们会发现拖累整体收益的，大致是在2018年1月到10月这段时间，也正好是最大回撤的时间范围。这说明在这段时间当中，我们选择的因子可能是失效了。基于这种情况，在我们的策略中，有没有可能设计一种机制，<strong>即能够在每次运行时，自动判断因子的重要性，再选出重要的因子来训练模型</strong>，换句话说，就是不要人为地选定因子，而是让机器动态地选择因子</p>
<h3 id="9-2-1-设置回测环境"><a href="#9-2-1-设置回测环境" class="headerlink" title="9.2.1 设置回测环境"></a>9.2.1 设置回测环境</h3><p>以下部分在聚宽策略中实现</p>
<h2 id="9-3-策略的回测详情"><a href="#9-3-策略的回测详情" class="headerlink" title="9.3 策略的回测详情"></a>9.3 策略的回测详情</h2><h3 id="9-3-1-策略收益概述"><a href="#9-3-1-策略收益概述" class="headerlink" title="9.3.1 策略收益概述"></a>9.3.1 策略收益概述</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(10).png" alt="下载 (10)"></p>
<p>结果分析：总体上不算优秀，只能算一般</p>
<h3 id="9-3-2-策略交易详情"><a href="#9-3-2-策略交易详情" class="headerlink" title="9.3.2 策略交易详情"></a>9.3.2 策略交易详情</h3><p>交易详情<br><img src="%E4%B8%8B%E8%BD%BD%20(11).png" alt="下载 (11)"><br>我们可以看到策略买了哪些股票，以及买卖的数量、日期、成交量等信息</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(12).png" alt="下载 (12)"><br>我们可以看到，2019年3月6号这一天，基于策略买了5只股票，买入平安银行数量1500股，每股13.06元买入近2万元。因为这一天是建仓，所以没有平仓盈亏。这一笔交易的手续费是58.77元。</p>
<h3 id="9-3-3-持仓和收益情况"><a href="#9-3-3-持仓和收益情况" class="headerlink" title="9.3.3 持仓和收益情况"></a>9.3.3 持仓和收益情况</h3><p>每日持仓&amp;收益</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(13).png" alt="下载 (13)"><br>我们编写的策略在3月6日持仓5只股票（也就是当日建仓的5只)。在这一天中，我们持有中国平安股票1500股，当天收盘价是13.8元，持有这只股票的市值在当日一共是19620元，给我们带来的浮盈是30元。对于中兴通讯这只股票，我们持有600股，该股当日的收盘价是31.3元，当日的总市值是18780元，但持有这只股票让我们的浮亏达到678元</p>
<p>从2019年3月6日来看，我们持有的股票有盈有亏，总体是浮亏的状态，总的亏损金额达到980元，那么策略会如何调仓呢？继续往下看</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(14).png" alt="下载 (14)"><br>在2019年4月9号这一天，策略的持仓发生了变化，中兴通讯这只“赔钱货”已经不在持仓列表中。当日持仓的股票只有4只，且每一只都是浮盈的状态。尤其是华侨城A股票带来了4671元的盈利，整体盈利也到达了8068元</p>
<p>注意：页面只提供显示1000条持仓和收益的记录，如果要查看全部记录，可以把页面拉到最低端，将记录导出后查看</p>
<h2 id="9-4-使用策略进行模拟交易"><a href="#9-4-使用策略进行模拟交易" class="headerlink" title="9.4 使用策略进行模拟交易"></a>9.4 使用策略进行模拟交易</h2><p>先使用模拟交易，看看交易的表现如何。如果策略表现不错，可以进行“跟单”，也就是把模拟买入并持仓的股票使用自己的实盘账户买入；如果模拟把某只股票清仓，则我们也可以在自己的实盘账户将股票卖出</p>
<h3 id="9-4-3-模拟交易的持仓与下单"><a href="#9-4-3-模拟交易的持仓与下单" class="headerlink" title="9.4.3 模拟交易的持仓与下单"></a>9.4.3 模拟交易的持仓与下单</h3><p>以下内容看聚宽自行学习</p>
<h1 id="第十章-初始自然语言处理"><a href="#第十章-初始自然语言处理" class="headerlink" title="第十章 初始自然语言处理"></a>第十章 初始自然语言处理</h1><h2 id="10-1-我们的想法是否靠谱"><a href="#10-1-我们的想法是否靠谱" class="headerlink" title="10.1 我们的想法是否靠谱"></a>10.1 我们的想法是否靠谱</h2><h3 id="思考几个问题"><a href="#思考几个问题" class="headerlink" title="思考几个问题"></a>思考几个问题</h3><p>有的时候，无论使用什么因子和算法，都会在2018年1月至10月这段时间，遇到最大回撤。在这段时间，中国股市由于受到某些国际因素的影响而略显“萎靡不振”，这也使得绝大多数因子处于失效的状态</p>
<p><strong>我们能不能让机器在危机爆发的初期就感知到“大事不妙”，及时抛出全部股票，从而躲过后面的大跌</strong></p>
<p><strong>我们能不能让机器从各类新闻与媒体报道中，找到对应某个行业或概念的重大利好，并迅速建仓，吃一波热点的红利</strong></p>
<p><strong>假如机器可以捕捉到“韭菜”们积极主动“送人头”的疯狂情绪，并预判到“镰刀”即将落下，不就可以帮我们及时止盈平仓了吗？</strong></p>
<h3 id="10-1-2-参考一下“大佬”们的做法"><a href="#10-1-2-参考一下“大佬”们的做法" class="headerlink" title="10.1.2 参考一下“大佬”们的做法"></a>10.1.2 参考一下“大佬”们的做法</h3><p>对冲基金Two Sigma就使用了NLP技术中的LDA话题模型，分析美国联邦公开市场委员会（FOMC）历年会议记录的主题，根据不同主题比例的变化趋势来分析FOMC在不同时期对于美国经济及金融状况的主要观点和立场。</p>
<p>贝莱德集团与加利福尼亚大学伯克利分校共同开展了一项研究。该研究的主要工作是通过从新闻标题中聚类出典型事件来分析各类事件对标准普尔500指数公司股价的正负影响及影响周期：在此基础上，运用组合投资的方法来获取超额收益。研究人员选取了新闻标题而非新闻正文作为原始文本。主要原因在于，他们认为新闻正文包含了太多的噪声信息，尤其当新闻中引用过去的其他事件时，这会对提取结果造成很大的误差，而新闻标题只会聚焦于文本的主题，相当于事前加了一层噪声过滤。</p>
<p>此外，在波兰克拉科夫举行的2019年秋季研讨会上，约100名投资专业人士和学者讨论了“利用机器学习和新技术进行投资”的问题。他们研究了NLP技术如何通过将语言转换为数据来帮助投资者简单有效地消化大量文本。例如，洛佩兹拉里的论文《重要的风险因素：收益回报的横截面的文本分析》研究了风险因素是否能够比现有模型更好地解释公司的收益。她利用美国上市公司在2005年至2018年间提交的10-K年度报告中声明的风险，通过lemmatization技术简化了文本。然后，他构造了一个文档术语矩阵，并使用了LDA模型来生成25个主题。对于整个样本，保留了2006年报告的四个风险较高的主题，以避免数据挖掘中的“前瞻性偏差”。</p>
<h3 id="10-1-3-什么是NLP"><a href="#10-1-3-什么是NLP" class="headerlink" title="10.1.3 什么是NLP"></a>10.1.3 什么是NLP</h3><p>NLP：自然语言处理，自然语言认知和理解是让计算机把输入的语言变成有意思的符号和关系，然后根据目的再处理。通俗地说，自然语言处理就是让计算机能够懂得我们人类的语言，并且能够帮助我们干活</p>
<h2 id="10-2-获取文本数据并简单清洗"><a href="#10-2-获取文本数据并简单清洗" class="headerlink" title="10.2 获取文本数据并简单清洗"></a>10.2 获取文本数据并简单清洗</h2><h3 id="10-2-1-获取新闻联播文本数据"><a href="#10-2-1-获取新闻联播文本数据" class="headerlink" title="10.2.1 获取新闻联播文本数据"></a>10.2.1 获取新闻联播文本数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入jqdata和datetime</span></span><br><span class="line"><span class="keyword">from</span> jqdata <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> datetime</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用timedelta计算出前一日的日期</span></span><br><span class="line">yesterday = datetime.date.today() - datetime.timedelta(days=<span class="number">2</span>)</span><br><span class="line"><span class="comment">#创建query，获取前一日的数据</span></span><br><span class="line">q = query(finance.CCTV_NEWS).<span class="built_in">filter</span>(finance.CCTV_NEWS.day==yesterday)</span><br><span class="line"><span class="comment">#执行query</span></span><br><span class="line">news = finance.run_query(q)</span><br><span class="line"><span class="comment">#检查数据的前5行</span></span><br><span class="line">news.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>day</th>
      <th>title</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>103822</td>
      <td>2022-12-30</td>
      <td>【央视快评】以奋进拼搏开辟未来</td>
      <td>央视网消息\n（新闻联播）：本台播发央视快评《以奋进拼搏开辟未来》。</td>
    </tr>
    <tr>
      <th>1</th>
      <td>103833</td>
      <td>2022-12-30</td>
      <td>中央广播电视总台元旦假期节目精彩纷呈</td>
      <td>央视网消息\n（新闻联播）：元旦假期期间，中央广播电视总台将推出一系列精彩节目，陪伴您迎接新...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>103830</td>
      <td>2022-12-30</td>
      <td>中央广播电视总台发布2022国内十大新闻 国际十大新闻</td>
      <td>央视网消息\n（新闻联播）：中央广播电视总台今天（12月30日）发布2022国内十大新闻、国...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>103823</td>
      <td>2022-12-30</td>
      <td>习近平同俄罗斯总统举行视频会晤</td>
      <td>央视网消息\n（新闻联播）：12月30日下午，国家主席习近平在北京同俄罗斯总统普京举行视频会...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>103824</td>
      <td>2022-12-30</td>
      <td>习近平签署国家主席令</td>
      <td>央视网消息\n（新闻联播）：国家主席习近平12月30日签署第一二六号、一二七号、一二八号、一...</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">news.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>day</th>
      <th>title</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>103822</td>
      <td>2022-12-30</td>
      <td>【央视快评】以奋进拼搏开辟未来</td>
      <td>央视网消息\n（新闻联播）：本台播发央视快评《以奋进拼搏开辟未来》。</td>
    </tr>
    <tr>
      <th>1</th>
      <td>103833</td>
      <td>2022-12-30</td>
      <td>中央广播电视总台元旦假期节目精彩纷呈</td>
      <td>央视网消息\n（新闻联播）：元旦假期期间，中央广播电视总台将推出一系列精彩节目，陪伴您迎接新...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>103830</td>
      <td>2022-12-30</td>
      <td>中央广播电视总台发布2022国内十大新闻 国际十大新闻</td>
      <td>央视网消息\n（新闻联播）：中央广播电视总台今天（12月30日）发布2022国内十大新闻、国...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>103823</td>
      <td>2022-12-30</td>
      <td>习近平同俄罗斯总统举行视频会晤</td>
      <td>央视网消息\n（新闻联播）：12月30日下午，国家主席习近平在北京同俄罗斯总统普京举行视频会...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>103824</td>
      <td>2022-12-30</td>
      <td>习近平签署国家主席令</td>
      <td>央视网消息\n（新闻联播）：国家主席习近平12月30日签署第一二六号、一二七号、一二八号、一...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>103836</td>
      <td>2022-12-30</td>
      <td>俄称摧毁乌方美制装备 乌称拦截俄方导弹</td>
      <td>央视网消息\n（新闻联播）：俄罗斯国防部29日称，俄军在扎波罗热等地打击乌军人员，并在顿涅茨...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>103829</td>
      <td>2022-12-30</td>
      <td>全国政协主席会议建议明年3月4日召开全国政协十四届一次会议</td>
      <td>央视网消息\n（新闻联播）：政协第十三届全国委员会日前召开主席会议，建议全国政协十四届一次会...</td>
    </tr>
    <tr>
      <th>7</th>
      <td>103821</td>
      <td>2022-12-30</td>
      <td>全国政协举行新年茶话会 习近平发表重要讲话</td>
      <td>央视网消息\n（新闻联播）：中国人民政治协商会议全国委员会12月30日上午在全国政协礼堂举行...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>103828</td>
      <td>2022-12-30</td>
      <td>十三届全国人大常委会第三十八次会议在京闭幕 栗战书强调 紧紧围绕党和国家工作大局依法履职担当...</td>
      <td>央视网消息\n（新闻联播）：十三届全国人大常委会第三十八次会议30日下午在北京人民大会堂闭幕...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>103831</td>
      <td>2022-12-30</td>
      <td>各地新年氛围渐浓 假日市场供应丰富</td>
      <td>央视网消息\n（新闻联播）：亮起彩灯，备足年货。各地新年氛围渐浓，假日市场供应丰富。\n\n...</td>
    </tr>
    <tr>
      <th>10</th>
      <td>103832</td>
      <td>2022-12-30</td>
      <td>各地采取措施提升基层医疗救治能力</td>
      <td>央视网消息\n（新闻联播）：为了应对新冠病毒感染，各地普遍采取医疗专家下沉、加强农村药品配备...</td>
    </tr>
    <tr>
      <th>11</th>
      <td>103834</td>
      <td>2022-12-30</td>
      <td>国内联播快讯</td>
      <td>央视网消息\n（新闻联播）：\n\n\n\n铁路元旦小长假运输今天启动\n\n\n\n为期四...</td>
    </tr>
    <tr>
      <th>12</th>
      <td>103825</td>
      <td>2022-12-30</td>
      <td>国家主席习近平将发表二〇二三年新年贺词</td>
      <td>央视网消息\n（新闻联播）：国家主席习近平将于31日晚7时通过中央广播电视总台和互联网，发表...</td>
    </tr>
    <tr>
      <th>13</th>
      <td>103837</td>
      <td>2022-12-30</td>
      <td>国际联播快讯</td>
      <td>央视网消息\n（新闻联播）：\n\n\n\n塞尔维亚总统下令解除最高战备状态\n\n\n\n...</td>
    </tr>
    <tr>
      <th>14</th>
      <td>103835</td>
      <td>2022-12-30</td>
      <td>多国人士：中国为各国共同发展提供强劲引擎</td>
      <td>央视网消息\n（新闻联播）：国际人士表示，2022年中国为充满不确定性的世界注入稳定性和正能...</td>
    </tr>
    <tr>
      <th>15</th>
      <td>103826</td>
      <td>2022-12-30</td>
      <td>应习近平邀请 菲律宾总统将访华</td>
      <td>央视网消息\n（新闻联播）：应国家主席习近平邀请，菲律宾共和国总统费迪南德·罗慕尔德兹·马科...</td>
    </tr>
    <tr>
      <th>16</th>
      <td>103827</td>
      <td>2022-12-30</td>
      <td>李克强向尼泊尔新任总理致贺电</td>
      <td>央视网消息\n（新闻联播）：国务院总理李克强12月29日致电普拉昌达，祝贺他就任尼泊尔总理。...</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="10-2-2-对文本数据进行简单清洗"><a href="#10-2-2-对文本数据进行简单清洗" class="headerlink" title="10.2.2 对文本数据进行简单清洗"></a>10.2.2 对文本数据进行简单清洗</h3><p>既然现在已经可以很便利地获得新闻联播的文本数据，下面我们就找一条关心的文本来看看完整的正文是什么样的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过指定行与列序号，</span></span><br><span class="line"><span class="comment">#可以查看某一条新闻的完整正文</span></span><br><span class="line">text= news.iloc[<span class="number">13</span>,<span class="number">3</span>]</span><br><span class="line"><span class="comment">#显示文本</span></span><br><span class="line">text</span><br></pre></td></tr></table></figure>




<pre><code>&#39;央视网消息\n（新闻联播）：\n\n\n\n塞尔维亚总统下令解除最高战备状态\n\n\n\n据塞尔维亚媒体报道，塞尔维亚总统武契奇29日下令解除最高战备状态。科索沃塞族民众当天开始拆除北部要道上的路障，部分路段已恢复交通。\n\n\n2008年2月科索沃单方面宣布独立，塞尔维亚始终坚持对科索沃的主权。近来，一名科索沃塞族前警察被科索沃当局逮捕引发抗议，科索沃北部紧张局势升级。\n\n\n\n内塔尼亚胡宣誓就任以色列总理\n\n\n\n以色列新一届政府29日宣誓就职，利库德集团领导人内塔尼亚胡出任总理。内塔尼亚胡当天表示，新政府将致力于重构以色列安全、解决生活成本高和住房问题等。 \n\n\n\n\n\n美媒：纽约流浪者收容所暴力事件频发\n\n\n\n美国《纽约邮报》日前报道称，内部报告显示美国最大城市纽约市的无家可归者收容机构充斥着殴打、虐待、无端攻击等各类暴力事件，仅今年9月的一个星期，就记录了约273起“严重事件”。另有美国媒体报道称，2019到2021年间纽约市收容机构收容人员死亡人数上升了58%。&#39;
</code></pre>
<p>结果分析：平台返回了行序号13、列序号3（也就是DataFrame中的content列）。我们注意到，文本中参杂了一些空格，还有回车换行符（\r\n,r代表return， n代表newline），为避免这些无用字符影响结果分析结果，我们需要把它们去掉</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#去掉正文中的空格</span></span><br><span class="line">text = text.replace(<span class="string">&#x27; &#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="comment">#去掉回撤与换行\r\n</span></span><br><span class="line">text = text.replace(<span class="string">&#x27;\n&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">text</span><br></pre></td></tr></table></figure>




<pre><code>&#39;央视网消息（新闻联播）：塞尔维亚总统下令解除最高战备状态据塞尔维亚媒体报道，塞尔维亚总统武契奇29日下令解除最高战备状态。科索沃塞族民众当天开始拆除北部要道上的路障，部分路段已恢复交通。2008年2月科索沃单方面宣布独立，塞尔维亚始终坚持对科索沃的主权。近来，一名科索沃塞族前警察被科索沃当局逮捕引发抗议，科索沃北部紧张局势升级。内塔尼亚胡宣誓就任以色列总理以色列新一届政府29日宣誓就职，利库德集团领导人内塔尼亚胡出任总理。内塔尼亚胡当天表示，新政府将致力于重构以色列安全、解决生活成本高和住房问题等。美媒：纽约流浪者收容所暴力事件频发美国《纽约邮报》日前报道称，内部报告显示美国最大城市纽约市的无家可归者收容机构充斥着殴打、虐待、无端攻击等各类暴力事件，仅今年9月的一个星期，就记录了约273起“严重事件”。另有美国媒体报道称，2019到2021年间纽约市收容机构收容人员死亡人数上升了58%。&#39;
</code></pre>
<h2 id="10-3-中文分词，“结巴”来帮忙"><a href="#10-3-中文分词，“结巴”来帮忙" class="headerlink" title="10.3 中文分词，“结巴”来帮忙"></a>10.3 中文分词，“结巴”来帮忙</h2><h3 id="10-3-1-使用结巴进行分词"><a href="#10-3-1-使用结巴进行分词" class="headerlink" title="10.3.1 使用结巴进行分词"></a>10.3.1 使用结巴进行分词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入结巴分词</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="comment">#使用cut方法即可完成分词</span></span><br><span class="line">words = jieba.cut(text)</span><br><span class="line"><span class="comment">#在词之间插入空格</span></span><br><span class="line">words = <span class="string">&#x27; &#x27;</span>.join(words)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">words</span><br></pre></td></tr></table></figure>

<pre><code>Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 1.168 seconds.
Prefix dict has been built succesfully.





&#39;央视网 消息 （ 新闻联播 ） ： 塞尔维亚 总统 下令 解除 最高 战备 状态 据 塞尔维亚 媒体报道 ， 塞尔维亚 总统 武契奇 29 日 下令 解除 最高 战备 状态 。 科索沃 塞族 民众 当天 开始 拆除 北部 要 道 上 的 路障 ， 部分 路段 已 恢复 交通 。 2008 年 2 月 科索沃 单方面 宣布独立 ， 塞尔维亚 始终 坚持 对 科索沃 的 主权 。 近来 ， 一名 科索沃 塞族 前 警察 被 科索沃 当局 逮捕 引发 抗议 ， 科索沃 北部 紧张局势 升级 。 内塔尼亚胡 宣誓 就任 以色列 总理 以色列 新一届 政府 29 日 宣誓就职 ， 利库德集团 领导人 内塔尼亚胡 出任 总理 。 内塔尼亚胡 当天 表示 ， 新政府 将 致力于 重构 以色列 安全 、 解决 生活 成本 高 和 住房问题 等 。 美媒 ： 纽约 流浪者 收容所 暴力事件 频发 美国 《 纽约 邮报 》 日前 报道 称 ， 内部 报告 显示 美国 最大 城市 纽约市 的 无家可归者 收容 机构 充斥 着 殴打 、 虐待 、 无端 攻击 等 各类 暴力事件 ， 仅 今年 9 月 的 一个 星期 ， 就 记录 了 约 273 起 “ 严重 事件 ” 。 另有 美国 媒体报道 称 ， 2019 到 2021 年间 纽约市 收容 机构 收容 人员 死亡 人数 上升 了 58% 。&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">type</span>(words)</span><br></pre></td></tr></table></figure>




<pre><code>str
</code></pre>
<h3 id="10-3-2-使用“结巴”进行列表分词"><a href="#10-3-2-使用“结巴”进行列表分词" class="headerlink" title="10.3.2 使用“结巴”进行列表分词"></a>10.3.2 使用“结巴”进行列表分词</h3><p>我们希望返回的结果是一个列表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用lcut将文本分词并存为列表</span></span><br><span class="line">word_list = jieba.lcut(text)</span><br><span class="line"><span class="comment">#检查列表中前30个元素</span></span><br><span class="line">word_list[:<span class="number">30</span>]</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;央视网&#39;,
 &#39;消息&#39;,
 &#39;（&#39;,
 &#39;新闻联播&#39;,
 &#39;）&#39;,
 &#39;：&#39;,
 &#39;塞尔维亚&#39;,
 &#39;总统&#39;,
 &#39;下令&#39;,
 &#39;解除&#39;,
 &#39;最高&#39;,
 &#39;战备&#39;,
 &#39;状态&#39;,
 &#39;据&#39;,
 &#39;塞尔维亚&#39;,
 &#39;媒体报道&#39;,
 &#39;，&#39;,
 &#39;塞尔维亚&#39;,
 &#39;总统&#39;,
 &#39;武契奇&#39;,
 &#39;29&#39;,
 &#39;日&#39;,
 &#39;下令&#39;,
 &#39;解除&#39;,
 &#39;最高&#39;,
 &#39;战备&#39;,
 &#39;状态&#39;,
 &#39;。&#39;,
 &#39;科索沃&#39;,
 &#39;塞族&#39;]
</code></pre>
<p>结果可以看出，使用lcut可以对同一条文本数据进行分词，并将分词结果保存为一个列表，但是有一个问题——例表中有大量的标点符号，以及一些诸如“和”“并”等没有什么实际意义的词。我们需要把这些词和标点符号去掉</p>
<h3 id="10-3-3-建立停用词表"><a href="#10-3-3-建立停用词表" class="headerlink" title="10.3.3 建立停用词表"></a>10.3.3 建立停用词表</h3><p>无论是中文还是英文，都存在一些诸如语气助词、介词、连词等词。在处理文本的时候，这些停用词可以被看作噪声数据，需要被去除</p>
<p>首先建立一个停用词表，我们有一个1893个停用词的版本</p>
<h3 id="10-3-4-去掉文本中的停用词"><a href="#10-3-4-去掉文本中的停用词" class="headerlink" title="10.3.4 去掉文本中的停用词"></a>10.3.4 去掉文本中的停用词</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先创建一个空字符串</span></span><br><span class="line">word = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#逐行读取停用词表，并按行分隔后，存入列表中</span></span><br><span class="line">stopwords = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;stopwords.txt&#x27;</span>,encoding=<span class="string">&#x27;UTF-8&#x27;</span>).readlines()]</span><br><span class="line"><span class="comment">#对于原文本中的元素</span></span><br><span class="line"><span class="keyword">for</span> element <span class="keyword">in</span> words:</span><br><span class="line">    <span class="comment">#如果不在停用词表中</span></span><br><span class="line">    <span class="keyword">if</span> element <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">        <span class="comment">#就添加到我们创建的空字符串中</span></span><br><span class="line">        word += element</span><br><span class="line"><span class="comment">#检查一下结果</span></span><br><span class="line">word</span><br></pre></td></tr></table></figure>




<pre><code>&#39;央视网 消息  新闻联播   塞维亚 总统 令 解 高 战备 状态  塞维亚 媒体报道  塞维亚 总统 武契  日 令 解 高 战备 状态  科索沃 塞族 民众 天 开始 拆 北部  道   路障  部分 路段  恢复 交通   年  月 科索沃 面 宣布  塞维亚 始终 坚持  科索沃  主权    名 科索沃 塞族 前 警察  科索沃 局 逮捕 引发 抗议  科索沃 北部 紧张局势 升级  塔尼亚胡 宣誓  色列 总理 色列 新届 政府  日 宣誓职  利库德集团 领导 塔尼亚胡  总理  塔尼亚胡 天 表示  新政府  力 重构 色列 安全  解决 生 成 高  住房问题   美媒  纽约 流浪 收容 暴力事件 频发 美国  纽约 邮报  日前 报道 称  部 报告 显示 美国  城市 纽约市  家 收容 机构 充斥  殴  虐  端 攻击  类 暴力事件   年  月   星期   记录  约    严重 事件    美国 媒体报道 称     年间 纽约市 收容 机构 收容 员 死亡 数 升   &#39;
</code></pre>
<h3 id="10-3-5-使用“结巴”提取关键词"><a href="#10-3-5-使用“结巴”提取关键词" class="headerlink" title="10.3.5 使用“结巴”提取关键词"></a>10.3.5 使用“结巴”提取关键词</h3><p>在一段文本中，往往较为关键的几个词就可以让我们理解80%或者更多的含义。</p>
<p>“结巴”分词工具具有提取关键词的功能</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入结巴分词中的analyse</span></span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"><span class="comment">#继续使用停用词表</span></span><br><span class="line">jieba.analyse.set_stop_words(<span class="string">&quot;stopwords.txt&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#抽取关键词</span></span><br><span class="line"><span class="comment">#withWeight参数控制的是，返回的结果是否包含关键词的权重</span></span><br><span class="line">tags = jieba.analyse.extract_tags(text,withWeight=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">tags</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;科索沃&#39;,
 &#39;塞尔维亚&#39;,
 &#39;内塔尼亚胡&#39;,
 &#39;收容&#39;,
 &#39;塞族&#39;,
 &#39;29&#39;,
 &#39;以色列&#39;,
 &#39;暴力事件&#39;,
 &#39;纽约市&#39;,
 &#39;战备&#39;,
 &#39;媒体报道&#39;,
 &#39;解除&#39;,
 &#39;下令&#39;,
 &#39;纽约&#39;,
 &#39;总理&#39;,
 &#39;当天&#39;,
 &#39;美国&#39;,
 &#39;总统&#39;,
 &#39;无家可归者&#39;,
 &#39;收容所&#39;]
</code></pre>
<p>结果分析：使用“结巴”的analyse.extract_tags.可以将原始文本的关键词提取出来。其原理是基于某个词在文本中出现的频率，计算出它的权重，并返回权重最大的词。在缺省参数的情况下，“结巴”返回的是权重较高的前20个词</p>
<p>当然，我们还可以通过调整参数来控制“结巴”返回的关键词的个数，以及是否包含权重等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调节extract_tags的参数</span></span><br><span class="line"><span class="comment">#设置topK，也就是关键词数量为10</span></span><br><span class="line"><span class="comment">#withWeight为True，让结果带上权重数值</span></span><br><span class="line">tags = jieba.analyse.extract_tags(text,</span><br><span class="line">                                  topK = <span class="number">10</span>,</span><br><span class="line">                                  withWeight=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">tags</span><br></pre></td></tr></table></figure>




<pre><code>[(&#39;科索沃&#39;, 0.5428077607149999),
 (&#39;塞尔维亚&#39;, 0.3057763277753333),
 (&#39;内塔尼亚胡&#39;, 0.289952313975),
 (&#39;收容&#39;, 0.240600288324),
 (&#39;塞族&#39;, 0.213367756055),
 (&#39;29&#39;, 0.19924612504833333),
 (&#39;以色列&#39;, 0.1901352912635),
 (&#39;暴力事件&#39;, 0.18546814882833335),
 (&#39;纽约市&#39;, 0.16289238778216666),
 (&#39;战备&#39;, 0.14931725382283334)]
</code></pre>
<h1 id="第11章-新闻文本向量化和话题建模"><a href="#第11章-新闻文本向量化和话题建模" class="headerlink" title="第11章 新闻文本向量化和话题建模"></a>第11章 新闻文本向量化和话题建模</h1><h2 id="11-1-让机器“读懂”新闻"><a href="#11-1-让机器“读懂”新闻" class="headerlink" title="11.1 让机器“读懂”新闻"></a>11.1 让机器“读懂”新闻</h2><h3 id="11-1-1-准备文本数据"><a href="#11-1-1-准备文本数据" class="headerlink" title="11.1.1 准备文本数据"></a>11.1.1 准备文本数据</h3><p>给机器输入一段文字，机器会根据某个词出现的次数或者频率，给这个词分配<strong>一个向量</strong>，那么这一整段文字会变成一个由多个向量组成的矩阵。这样就可以让机器“了解”这段话所表达的意思了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入需要的库</span></span><br><span class="line"><span class="keyword">from</span> jqdata <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设置日期</span></span><br><span class="line">yesterday = datetime.date.today()-datetime.timedelta(days=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#创建query，查询昨天的新闻联播数据</span></span><br><span class="line">q = query(finance.CCTV_NEWS).<span class="built_in">filter</span>(finance.CCTV_NEWS.day==yesterday)</span><br><span class="line"><span class="comment">#执行query</span></span><br><span class="line">news = finance.run_query(q)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">news.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>day</th>
      <th>title</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>103844</td>
      <td>2022-12-31</td>
      <td>“奋进新时代”主题成就展闭幕</td>
      <td>央视网消息\n（新闻联播）：由中央宣传部、国家发展改革委、中央军委政治工作部、北京市联合主办...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>103839</td>
      <td>2022-12-31</td>
      <td>【央视快评】让明天的中国更美好</td>
      <td>央视网消息\n（新闻联播）：本台播发央视快评《让明天的中国更美好》。</td>
    </tr>
    <tr>
      <th>2</th>
      <td>103840</td>
      <td>2022-12-31</td>
      <td>中俄两国元首互致新年贺电 中俄两国总理互致新年贺电</td>
      <td>央视网消息\n（新闻联播）：2022年12月31日，国家主席习近平和俄罗斯总统普京互致新年贺...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>103845</td>
      <td>2022-12-31</td>
      <td>中央文明办部署开展元旦春节文明实践志愿服务活动</td>
      <td>央视网消息\n（新闻联播）：中央文明办日前印发通知，要求元旦春节期间在全国城乡广泛开展文明实...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>103841</td>
      <td>2022-12-31</td>
      <td>习近平向拉马福萨当选连任南非非洲人国民大会主席致贺电</td>
      <td>央视网消息\n（新闻联播）：12月31日，中共中央总书记习近平致电祝贺拉马福萨当选连任南非非...</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">news.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>day</th>
      <th>title</th>
      <th>content</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>103844</td>
      <td>2022-12-31</td>
      <td>“奋进新时代”主题成就展闭幕</td>
      <td>央视网消息\n（新闻联播）：由中央宣传部、国家发展改革委、中央军委政治工作部、北京市联合主办...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>103839</td>
      <td>2022-12-31</td>
      <td>【央视快评】让明天的中国更美好</td>
      <td>央视网消息\n（新闻联播）：本台播发央视快评《让明天的中国更美好》。</td>
    </tr>
    <tr>
      <th>2</th>
      <td>103840</td>
      <td>2022-12-31</td>
      <td>中俄两国元首互致新年贺电 中俄两国总理互致新年贺电</td>
      <td>央视网消息\n（新闻联播）：2022年12月31日，国家主席习近平和俄罗斯总统普京互致新年贺...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>103845</td>
      <td>2022-12-31</td>
      <td>中央文明办部署开展元旦春节文明实践志愿服务活动</td>
      <td>央视网消息\n（新闻联播）：中央文明办日前印发通知，要求元旦春节期间在全国城乡广泛开展文明实...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>103841</td>
      <td>2022-12-31</td>
      <td>习近平向拉马福萨当选连任南非非洲人国民大会主席致贺电</td>
      <td>央视网消息\n（新闻联播）：12月31日，中共中央总书记习近平致电祝贺拉马福萨当选连任南非非...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>103842</td>
      <td>2022-12-31</td>
      <td>人民日报社论：锚定奋斗目标 创造新的伟业——元旦献词</td>
      <td>央视网消息\n（新闻联播）：明天（2023年1月1日）出版的《人民日报》将发表社论，题目是《...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>103848</td>
      <td>2022-12-31</td>
      <td>各地医疗机构全力以赴保障患者医疗救治</td>
      <td>央视网消息\n（新闻联播）：连日来，各地各级医疗机构全力以赴，着力做好诊疗关口前移和患者救治...</td>
    </tr>
    <tr>
      <th>7</th>
      <td>103838</td>
      <td>2022-12-31</td>
      <td>国家主席习近平发表二〇二三年新年贺词</td>
      <td>央视网消息\n（新闻联播）：新年前夕，国家主席习近平通过中央广播电视总台和互联网，发表了二〇...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>103850</td>
      <td>2022-12-31</td>
      <td>大美中国</td>
      <td>央视网消息\n（新闻联播）：新年将至，神州大地银装素裹，流光溢彩。节目的最后，让我们一起领略...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>103847</td>
      <td>2022-12-31</td>
      <td>李家超欢迎全国人大常委会就香港国安法有关条款作出解释 驻港国家安全公署发言人就全国人大常委会...</td>
      <td>央视网消息\n（新闻联播）：12月30日下午，十三届全国人大常委会第三十八次会议表决通过了《...</td>
    </tr>
    <tr>
      <th>10</th>
      <td>103843</td>
      <td>2022-12-31</td>
      <td>欢乐祥和迎新年 神州大地气象新</td>
      <td>央视网消息\n（新闻联播）：今天（2022年12月31日）是元旦假期第一天，人们在丰富多彩的...</td>
    </tr>
    <tr>
      <th>11</th>
      <td>103846</td>
      <td>2022-12-31</td>
      <td>民政部部署各地保障元旦春节期间困难群众基本生活</td>
      <td>央视网消息\n（新闻联播）：民政部日前印发通知，要求各地及时将符合条件的困难群众纳入救助范围...</td>
    </tr>
    <tr>
      <th>12</th>
      <td>103849</td>
      <td>2022-12-31</td>
      <td>联播快讯</td>
      <td>央视网消息\n（新闻联播）：\n\n\n今天全国铁路预计发送旅客550万人次\n\n\n元旦...</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">news.iloc[<span class="number">7</span>][<span class="number">3</span>]</span><br></pre></td></tr></table></figure>




<pre><code>&#39;央视网消息\n（新闻联播）：新年前夕，国家主席习近平通过中央广播电视总台和互联网，发表了二〇二三年新年贺词。全文如下：\n\n大家好！2023年即将到来，我在北京向大家致以美好的新年祝福！\n\n2022年，我们胜利召开党的二十大，擘画了全面建设社会主义现代化国家、以中国式现代化全面推进中华民族伟大复兴的宏伟蓝图，吹响了奋进新征程的时代号角。\n\n我国继续保持世界第二大经济体的地位，经济稳健发展，全年国内生产总值预计超过120万亿元。面对全球粮食危机，我国粮食生产实现“十九连丰”，中国人的饭碗端得更牢了。我们巩固脱贫攻坚成果，全面推进乡村振兴，采取减税降费等系列措施为企业纾难解困，着力解决人民群众急难愁盼问题。\n\n疫情发生以来，我们始终坚持人民至上、生命至上，坚持科学精准防控，因时因势优化调整防控措施，最大限度保护了人民生命安全和身体健康。广大干部群众特别是医务人员、基层工作者不畏艰辛、勇毅坚守。经过艰苦卓绝的努力，我们战胜了前所未有的困难和挑战，每个人都不容易。目前，疫情防控进入新阶段，仍是吃劲的时候，大家都在坚忍不拔努力，曙光就在前头。大家再加把劲，坚持就是胜利，团结就是胜利。\n\n2022年，江泽民同志离开了我们。我们深切缅怀他的丰功伟绩和崇高风范，珍惜他留下的宝贵精神财富。我们要继承他的遗志，把新时代中国特色社会主义事业不断推向前进。\n\n历史长河波澜壮阔，一代又一代人接续奋斗创造了今天的中国。\n\n今天的中国，是梦想接连实现的中国。北京冬奥会、冬残奥会成功举办，冰雪健儿驰骋赛场，取得了骄人成绩。神舟十三号、十四号、十五号接力腾飞，中国空间站全面建成，我们的“太空之家”遨游苍穹。人民军队迎来95岁生日，广大官兵在强军伟业征程上昂扬奋进。第三艘航母“福建号”下水，首架C919大飞机正式交付，白鹤滩水电站全面投产……这一切，凝结着无数人的辛勤付出和汗水。点点星火，汇聚成炬，这就是中国力量！\n\n今天的中国，是充满生机活力的中国。各自由贸易试验区、海南自由贸易港蓬勃兴起，沿海地区踊跃创新，中西部地区加快发展，东北振兴蓄势待发，边疆地区兴边富民。中国经济韧性强、潜力大、活力足，长期向好的基本面依然不变。只要笃定信心、稳中求进，就一定能实现我们的既定目标。今年我去了香港，看到香港将由治及兴十分欣慰。坚定不移落实好“一国两制”，香港、澳门必将长期繁荣稳定。\n\n今天的中国，是赓续民族精神的中国。这一年发生的地震、洪水、干旱、山火等自然灾害和一些安全事故，让人揪心，令人难过，但一幕幕舍生取义、守望相助的场景感人至深，英雄的事迹永远铭记在我们心中。每当辞旧迎新，总会念及中华民族千年传承的浩然之气，倍增前行信心。\n\n今天的中国，是紧密联系世界的中国。这一年，我在北京迎接了不少新老朋友，也走出国门讲述中国主张。百年变局加速演进，世界并不太平。我们始终如一珍视和平和发展，始终如一珍惜朋友和伙伴，坚定站在历史正确的一边、站在人类文明进步的一边，努力为人类和平与发展事业贡献中国智慧、中国方案。\n\n党的二十大后我和同事们一起去了延安，重温党中央在延安时期战胜世所罕见困难的光辉岁月，感悟老一辈共产党人的精神力量。我常说，艰难困苦，玉汝于成。中国共产党百年栉风沐雨、披荆斩棘，历程何其艰辛又何其伟大。我们要一往无前、顽强拼搏，让明天的中国更美好。\n\n明天的中国，奋斗创造奇迹。苏轼有句话：“犯其至难而图其至远”，意思是说“向最难之处攻坚，追求最远大的目标”。路虽远，行则将至；事虽难，做则必成。只要有愚公移山的志气、滴水穿石的毅力，脚踏实地，埋头苦干，积跬步以至千里，就一定能够把宏伟目标变为美好现实。\n\n明天的中国，力量源于团结。中国这么大，不同人会有不同诉求，对同一件事也会有不同看法，这很正常，要通过沟通协商凝聚共识。14亿多中国人心往一处想、劲往一处使，同舟共济、众志成城，就没有干不成的事、迈不过的坎。海峡两岸一家亲。衷心希望两岸同胞相向而行、携手并进，共创中华民族绵长福祉。\n\n明天的中国，希望寄予青年。青年兴则国家兴，中国发展要靠广大青年挺膺担当。年轻充满朝气，青春孕育希望。广大青年要厚植家国情怀、涵养进取品格，以奋斗姿态激扬青春，不负时代，不负华年。\n\n此时此刻，许多人还在辛苦忙碌，大家辛苦了！新年的钟声即将敲响，让我们怀着对未来的美好向往，共同迎接2023年的第一缕阳光。\n\n祝愿祖国繁荣昌盛、国泰民安！祝愿世界和平美好、幸福安宁！祝愿大家新年快乐、皆得所愿！\n\n谢谢！&#39;
</code></pre>
<p>接下来，我们选择一条文本数据，对其进行分词处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#选择行序号为7的新闻正文文本</span></span><br><span class="line">message = news.iloc[<span class="number">7</span>][<span class="number">3</span>]</span><br><span class="line"><span class="comment">#这里教大家一个去掉无用字符的新方法</span></span><br><span class="line"><span class="comment">#使用split()即可</span></span><br><span class="line">message = <span class="string">&#x27;&#x27;</span>.join(message.split())</span><br><span class="line"><span class="comment">#下面是我们在第10章中学习过的</span></span><br><span class="line"><span class="comment">#分词并去除停用词的过程</span></span><br><span class="line">words = <span class="string">&#x27;&#x27;</span></span><br><span class="line">stopwords = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;stopwords.txt&#x27;</span>,encoding=<span class="string">&#x27;UTF-8&#x27;</span>).readlines()]</span><br><span class="line">word = <span class="string">&#x27; &#x27;</span>.join(jieba.cut(message))</span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> word:</span><br><span class="line">    <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">        words += w</span><br><span class="line">words</span><br></pre></td></tr></table></figure>




<pre><code>&#39;央视网 消息  新闻联播   新年 前夕  国家 主席 习平 通 中央 广播电视 总台  联网  发表   〇 年 新年贺词  全文  家    年      北京  家  美  新年 祝福   年   胜利 召开 党  十  擘画  全面 建设 社主义 现代化 国家   中国式 现代化 全面 推进 中华民族 伟 复兴  宏伟蓝图  吹响  奋进 新 征程  时代 号角  国 继续 保持 世界   济体  位  济 稳健 发展  全年 国 生产总值 预计 超  万亿元  面 全球 粮食 危机  国 粮食 生产 实现  十 丰   中国   饭碗 端  牢    巩 脱贫 攻坚 成果  全面 推进 乡村 振兴  采取 减税 降费  系列 措施  企业 纾 难 解困  力 解决 民 群众 急难 愁 盼 问题  疫情 发生    始终 坚持 民   生命   坚持 科学 精准 防控  时 势 优化 调整 防控 措施   限度 保护  民 生命安全  身体健康  广干部 群众 特  医务员  基层 工作 畏 艰辛  勇毅 坚守   艰苦卓  努力   战胜  前未  困难  挑战      容易  目前  疫情 防控 进入 新 阶段    吃劲  时候  家   坚忍拔 努力  曙   前头  家  加劲  坚持  胜利  团结  胜利   年  江泽民 志 开     深 缅怀   丰功伟绩  崇高 风范  珍惜  留  宝贵 精神财富    继承   遗志   新 时代 中国 特色 社主义 事业 断 推 前进  史长河 波澜壮阔  代  代 接续 奋斗 创造  天  中国  天  中国   梦想 接 实现  中国  北京 冬奥  冬 残奥 成功 举办  冰雪 健 驰骋 赛场  取  骄成绩  神舟 十号  十号  十号 接力 飞  中国 空间站 全面 建成     太空  家  遨游 苍穹  民军队 迎  岁 生日  广 官兵  强军 伟业 征程  昂扬 奋进  艘 航母  福建 号  水  首架 C  飞机 正式 交付  鹤 滩 水电站 全面 投产      凝结  数   辛勤 付  汗水  点点 星火  汇聚 成炬    中国 力量  天  中国   充生机 力  中国   贸易 试验区  海南 贸易 港 蓬勃 兴  海区 踊跃 创新  中西部 区 加 发展  东北 振兴 蓄势发  疆区 兴 富民  中国 济 韧性 强  潜力   力 足  长期    基面  变   笃 信心  稳中求进     实现   目标  年    香港   香港  治 兴 十分 欣慰  坚移 落实   国两制   香港  澳门  长期 繁荣 稳  天  中国  赓续 民族 精神  中国   年 发生  震  洪水  干旱  山火  灾害   安全事    揪心  令 难   幕幕 舍生取义  守相助  场景 感深  英雄  事迹 永远 铭记   心中   辞旧迎新  总 念 中华民族 年 承  浩气  倍增 前行 信心  天  中国   紧密联系 世界  中国   年    北京 迎接  少 新朋友   走 国门 讲述 中国 主张  百年 变局 加速 演进  世界   太平   始终 珍视 平  发展  始终 珍惜 朋友  伙伴  坚 站  史 正确    站  类文明 进步    努力  类 平  发展 事业 贡献 中国 智慧  中国 案  党  十    事     延安  重温 党中央  延安 时期 战胜 世 罕 困难  辉 岁月  感悟 辈 产党  精神力量   说  艰难困苦  玉成  中国产党 百年 栉风沐雨  披荆斩棘  程  艰辛   伟    前  顽强拼搏   明天  中国  美  明天  中国  奋斗 创造 迹  苏轼 句 话   犯  难  图   远   意思  说   难 处 攻坚  追求 远   目标   路 远  行    事 难  做  成    愚公移山  志气  滴水穿石  毅力  脚踏实  埋头苦干  积 跬步  里    够  宏伟目标 变 美 现实  明天  中国  力量 源 团结  中国        诉求   件 事     法    正   通 沟通 协商 凝聚 识   亿 中国 心  处 想  劲 处   舟济  众志成城    干 成  事  迈   坎  海峡两岸 家亲  衷心希 两岸 胞 相 行  携手 进  创 中华民族 绵长 福祉  明天  中国  希 寄予 青年  青年 兴 国家 兴  中国 发展   广青年 挺膺 担  年轻 充 气  青春 孕育 希  广青年 厚 植家国 情怀  涵养 进取 品格   奋斗 姿态 激扬 青春  负 时代  负 华年  时刻  许    辛苦 忙碌  家 辛苦   新年  钟声  敲响    怀  未  美    迎接  年  缕 阳  祝愿 祖国 繁荣昌盛  国泰民安  祝愿 世界 平 美  幸福 安  祝愿 家 新年乐  皆  愿  谢谢 &#39;
</code></pre>
<h3 id="11-1-2-使用CountVectorizer将文本转化为向量"><a href="#11-1-2-使用CountVectorizer将文本转化为向量" class="headerlink" title="11.1.2 使用CountVectorizer将文本转化为向量"></a>11.1.2 使用CountVectorizer将文本转化为向量</h3><p>scikit_learn中主要有两种用于文本向量化的方法：一种是基于<strong>单个词</strong>在整段文本中出现的<strong>次数</strong>来进行向量化的方法，另一种是基于<strong>词频——逆文本频率（TF-IDF）</strong>方法来进行量化的方法</p>
<p>首先我们来练习比较容易理解的方法，也就是基于单个词在整段文本中出现的<strong>次数</strong>来进行向量化的方法——CountVectorizer</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先我们来使用</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把上一步分好词的文本保存为一个txt文档</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;message.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(words)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个CountVectoerizer实例</span></span><br><span class="line">vect = CountVectorizer()</span><br><span class="line"><span class="comment">#打开刚刚保存的txt文档</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;message.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"><span class="comment">#使用CountVectorizer拟合数据</span></span><br><span class="line">vect.fit(f)</span><br></pre></td></tr></table></figure>




<pre><code>CountVectorizer(analyzer=&#39;word&#39;, binary=False, decode_error=&#39;strict&#39;,
        dtype=&lt;class &#39;numpy.int64&#39;&gt;, encoding=&#39;utf-8&#39;, input=&#39;content&#39;,
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern=&#39;(?u)\\b\\w\\w+\\b&#39;,
        tokenizer=None, vocabulary=None)
</code></pre>
<p>CountVectorizer完成对文本数据的拟合。我们可以用它进行向量化操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#接下来就可以将该文本数据转化为向量了</span></span><br><span class="line"><span class="comment">#还是打开这个文件</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;message.txt&#x27;</span>)</span><br><span class="line"><span class="comment">#使用训练好的CountVectorizer转化文本</span></span><br><span class="line">vectors = vect.transform(f)</span><br><span class="line"><span class="comment">#查看转化后的向量</span></span><br><span class="line"><span class="built_in">print</span>(vectors.toarray())</span><br></pre></td></tr></table></figure>

<pre><code>[[1 4 1 1 3 24 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 5
  1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 3 1 3 1 1 3 1 1 1 5 2 1 1 1 1 1 1 1 1 2 2
  1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 1 3 2 3 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1
  1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1
  1 1 2 1 3 1 1 1 1 3 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 1 2 2 1 3 1 1 1
  1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 3 1 1 1 1 1 1 2 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 2 1 3 1 1 1 2
  2 1 1 1 1 1 1 1 3 1 1]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vect.vocabulary_</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;央视网&#39;: 86,
 &#39;消息&#39;: 184,
 &#39;新闻联播&#39;: 151,
 &#39;新年&#39;: 147,
 &#39;前夕&#39;: 42,
 &#39;国家&#39;: 72,
 &#39;主席&#39;: 11,
 &#39;习平&#39;: 14,
 &#39;中央&#39;: 8,
 &#39;广播电视&#39;: 112,
 &#39;总台&#39;: 123,
 &#39;联网&#39;: 235,
 &#39;发表&#39;: 61,
 &#39;新年贺词&#39;: 149,
 &#39;全文&#39;: 32,
 &#39;北京&#39;: 52,
 &#39;祝福&#39;: 212,
 &#39;胜利&#39;: 236,
 &#39;召开&#39;: 63,
 &#39;擘画&#39;: 144,
 &#39;全面&#39;: 34,
 &#39;建设&#39;: 116,
 &#39;社主义&#39;: 209,
 &#39;现代化&#39;: 195,
 &#39;中国式&#39;: 7,
 &#39;推进&#39;: 140,
 &#39;中华民族&#39;: 4,
 &#39;复兴&#39;: 83,
 &#39;宏伟蓝图&#39;: 95,
 &#39;吹响&#39;: 67,
 &#39;奋进&#39;: 88,
 &#39;征程&#39;: 118,
 &#39;时代&#39;: 152,
 &#39;号角&#39;: 65,
 &#39;继续&#39;: 231,
 &#39;保持&#39;: 26,
 &#39;世界&#39;: 1,
 &#39;济体&#39;: 179,
 &#39;稳健&#39;: 218,
 &#39;发展&#39;: 59,
 &#39;全年&#39;: 31,
 &#39;生产总值&#39;: 200,
 &#39;预计&#39;: 290,
 &#39;万亿元&#39;: 0,
 &#39;全球&#39;: 33,
 &#39;粮食&#39;: 221,
 &#39;危机&#39;: 58,
 &#39;生产&#39;: 199,
 &#39;实现&#39;: 98,
 &#39;中国&#39;: 5,
 &#39;饭碗&#39;: 293,
 &#39;脱贫&#39;: 238,
 &#39;攻坚&#39;: 145,
 &#39;成果&#39;: 130,
 &#39;乡村&#39;: 15,
 &#39;振兴&#39;: 136,
 &#39;采取&#39;: 276,
 &#39;减税&#39;: 37,
 &#39;降费&#39;: 284,
 &#39;系列&#39;: 226,
 &#39;措施&#39;: 141,
 &#39;企业&#39;: 20,
 &#39;解困&#39;: 253,
 &#39;解决&#39;: 252,
 &#39;群众&#39;: 234,
 &#39;急难&#39;: 122,
 &#39;问题&#39;: 281,
 &#39;疫情&#39;: 205,
 &#39;发生&#39;: 60,
 &#39;始终&#39;: 89,
 &#39;坚持&#39;: 78,
 &#39;生命&#39;: 201,
 &#39;科学&#39;: 216,
 &#39;精准&#39;: 222,
 &#39;防控&#39;: 282,
 &#39;优化&#39;: 22,
 &#39;调整&#39;: 257,
 &#39;限度&#39;: 285,
 &#39;保护&#39;: 25,
 &#39;生命安全&#39;: 202,
 &#39;身体健康&#39;: 265,
 &#39;广干部&#39;: 111,
 &#39;医务员&#39;: 53,
 &#39;基层&#39;: 81,
 &#39;工作&#39;: 106,
 &#39;艰辛&#39;: 243,
 &#39;勇毅&#39;: 51,
 &#39;坚守&#39;: 76,
 &#39;艰苦卓&#39;: 242,
 &#39;努力&#39;: 50,
 &#39;战胜&#39;: 132,
 &#39;前未&#39;: 44,
 &#39;困难&#39;: 70,
 &#39;挑战&#39;: 135,
 &#39;容易&#39;: 100,
 &#39;目前&#39;: 207,
 &#39;进入&#39;: 270,
 &#39;阶段&#39;: 283,
 &#39;吃劲&#39;: 66,
 &#39;时候&#39;: 153,
 &#39;坚忍拔&#39;: 77,
 &#39;前头&#39;: 43,
 &#39;加劲&#39;: 48,
 &#39;团结&#39;: 69,
 &#39;江泽民&#39;: 175,
 &#39;缅怀&#39;: 233,
 &#39;丰功伟绩&#39;: 10,
 &#39;崇高&#39;: 105,
 &#39;风范&#39;: 291,
 &#39;珍惜&#39;: 197,
 &#39;宝贵&#39;: 97,
 &#39;精神财富&#39;: 225,
 &#39;继承&#39;: 230,
 &#39;遗志&#39;: 274,
 &#39;特色&#39;: 193,
 &#39;事业&#39;: 16,
 &#39;前进&#39;: 46,
 &#39;史长河&#39;: 64,
 &#39;波澜壮阔&#39;: 177,
 &#39;接续&#39;: 139,
 &#39;奋斗&#39;: 87,
 &#39;创造&#39;: 41,
 &#39;梦想&#39;: 162,
 &#39;冬奥&#39;: 35,
 &#39;残奥&#39;: 167,
 &#39;成功&#39;: 129,
 &#39;举办&#39;: 13,
 &#39;冰雪&#39;: 36,
 &#39;驰骋&#39;: 296,
 &#39;赛场&#39;: 262,
 &#39;骄成绩&#39;: 297,
 &#39;神舟&#39;: 213,
 &#39;十号&#39;: 55,
 &#39;接力&#39;: 138,
 &#39;空间站&#39;: 219,
 &#39;建成&#39;: 115,
 &#39;太空&#39;: 85,
 &#39;遨游&#39;: 275,
 &#39;苍穹&#39;: 245,
 &#39;民军队&#39;: 169,
 &#39;生日&#39;: 203,
 &#39;官兵&#39;: 96,
 &#39;强军&#39;: 117,
 &#39;伟业&#39;: 24,
 &#39;昂扬&#39;: 156,
 &#39;航母&#39;: 241,
 &#39;福建&#39;: 214,
 &#39;首架&#39;: 294,
 &#39;飞机&#39;: 292,
 &#39;正式&#39;: 165,
 &#39;交付&#39;: 18,
 &#39;水电站&#39;: 171,
 &#39;投产&#39;: 133,
 &#39;凝结&#39;: 38,
 &#39;辛勤&#39;: 266,
 &#39;汗水&#39;: 174,
 &#39;点点&#39;: 192,
 &#39;星火&#39;: 158,
 &#39;汇聚&#39;: 173,
 &#39;成炬&#39;: 131,
 &#39;力量&#39;: 47,
 &#39;充生机&#39;: 29,
 &#39;贸易&#39;: 260,
 &#39;试验区&#39;: 256,
 &#39;海南&#39;: 182,
 &#39;蓬勃&#39;: 250,
 &#39;海区&#39;: 181,
 &#39;踊跃&#39;: 264,
 &#39;创新&#39;: 40,
 &#39;中西部&#39;: 9,
 &#39;东北&#39;: 2,
 &#39;蓄势发&#39;: 249,
 &#39;疆区&#39;: 204,
 &#39;富民&#39;: 102,
 &#39;韧性&#39;: 288,
 &#39;潜力&#39;: 188,
 &#39;长期&#39;: 280,
 &#39;基面&#39;: 82,
 &#39;信心&#39;: 27,
 &#39;稳中求进&#39;: 217,
 &#39;目标&#39;: 208,
 &#39;香港&#39;: 295,
 &#39;十分&#39;: 54,
 &#39;欣慰&#39;: 164,
 &#39;坚移&#39;: 79,
 &#39;落实&#39;: 248,
 &#39;国两制&#39;: 71,
 &#39;澳门&#39;: 189,
 &#39;繁荣&#39;: 228,
 &#39;赓续&#39;: 261,
 &#39;民族&#39;: 170,
 &#39;精神&#39;: 223,
 &#39;洪水&#39;: 178,
 &#39;干旱&#39;: 108,
 &#39;山火&#39;: 103,
 &#39;灾害&#39;: 191,
 &#39;安全事&#39;: 93,
 &#39;揪心&#39;: 142,
 &#39;幕幕&#39;: 107,
 &#39;舍生取义&#39;: 239,
 &#39;守相助&#39;: 92,
 &#39;场景&#39;: 75,
 &#39;感深&#39;: 128,
 &#39;英雄&#39;: 247,
 &#39;事迹&#39;: 17,
 &#39;永远&#39;: 172,
 &#39;铭记&#39;: 279,
 &#39;心中&#39;: 119,
 &#39;辞旧迎新&#39;: 268,
 &#39;浩气&#39;: 180,
 &#39;倍增&#39;: 28,
 &#39;前行&#39;: 45,
 &#39;紧密联系&#39;: 227,
 &#39;迎接&#39;: 269,
 &#39;新朋友&#39;: 150,
 &#39;国门&#39;: 74,
 &#39;讲述&#39;: 254,
 &#39;主张&#39;: 12,
 &#39;百年&#39;: 206,
 &#39;变局&#39;: 62,
 &#39;加速&#39;: 49,
 &#39;演进&#39;: 187,
 &#39;太平&#39;: 84,
 &#39;珍视&#39;: 198,
 &#39;朋友&#39;: 160,
 &#39;伙伴&#39;: 23,
 &#39;正确&#39;: 166,
 &#39;类文明&#39;: 220,
 &#39;进步&#39;: 272,
 &#39;贡献&#39;: 259,
 &#39;智慧&#39;: 159,
 &#39;延安&#39;: 114,
 &#39;重温&#39;: 277,
 &#39;党中央&#39;: 30,
 &#39;时期&#39;: 155,
 &#39;岁月&#39;: 104,
 &#39;感悟&#39;: 127,
 &#39;产党&#39;: 19,
 &#39;精神力量&#39;: 224,
 &#39;艰难困苦&#39;: 244,
 &#39;玉成&#39;: 194,
 &#39;中国产党&#39;: 6,
 &#39;栉风沐雨&#39;: 161,
 &#39;披荆斩棘&#39;: 134,
 &#39;顽强拼搏&#39;: 289,
 &#39;明天&#39;: 157,
 &#39;苏轼&#39;: 246,
 &#39;意思&#39;: 125,
 &#39;追求&#39;: 273,
 &#39;愚公移山&#39;: 126,
 &#39;志气&#39;: 120,
 &#39;滴水穿石&#39;: 186,
 &#39;毅力&#39;: 168,
 &#39;脚踏实&#39;: 237,
 &#39;埋头苦干&#39;: 80,
 &#39;跬步&#39;: 263,
 &#39;宏伟目标&#39;: 94,
 &#39;现实&#39;: 196,
 &#39;诉求&#39;: 255,
 &#39;沟通&#39;: 176,
 &#39;协商&#39;: 57,
 &#39;凝聚&#39;: 39,
 &#39;舟济&#39;: 240,
 &#39;众志成城&#39;: 21,
 &#39;海峡两岸&#39;: 183,
 &#39;家亲&#39;: 99,
 &#39;衷心希&#39;: 251,
 &#39;两岸&#39;: 3,
 &#39;携手&#39;: 143,
 &#39;绵长&#39;: 232,
 &#39;福祉&#39;: 215,
 &#39;寄予&#39;: 101,
 &#39;青年&#39;: 286,
 &#39;广青年&#39;: 113,
 &#39;挺膺&#39;: 137,
 &#39;年轻&#39;: 109,
 &#39;青春&#39;: 287,
 &#39;孕育&#39;: 91,
 &#39;植家国&#39;: 163,
 &#39;情怀&#39;: 124,
 &#39;涵养&#39;: 185,
 &#39;进取&#39;: 271,
 &#39;品格&#39;: 68,
 &#39;姿态&#39;: 90,
 &#39;激扬&#39;: 190,
 &#39;华年&#39;: 56,
 &#39;时刻&#39;: 154,
 &#39;辛苦&#39;: 267,
 &#39;忙碌&#39;: 121,
 &#39;钟声&#39;: 278,
 &#39;敲响&#39;: 146,
 &#39;祝愿&#39;: 211,
 &#39;祖国&#39;: 210,
 &#39;繁荣昌盛&#39;: 229,
 &#39;国泰民安&#39;: 73,
 &#39;幸福&#39;: 110,
 &#39;新年乐&#39;: 148,
 &#39;谢谢&#39;: 258&#125;
</code></pre>
<p>我们可以看到原始文本数据现在现在已经变成由整数组成的数组。无论后面的话题提取，还是文本分类等，都以此为基础来进行</p>
<h3 id="11-1-3-使用TfidVectorizer将文本转换为向量"><a href="#11-1-3-使用TfidVectorizer将文本转换为向量" class="headerlink" title="11.1.3 使用TfidVectorizer将文本转换为向量"></a>11.1.3 使用TfidVectorizer将文本转换为向量</h3><p>此方法是基于词频——逆文本频率方法来进行向量化，也就是TfidVectorizor,它不是基于文档中每个词出现的次数来进行向量转化的，而是根据<strong>单个词在文档中出现的概率（TF），再乘以逆向文档频率（IDF）来计算的</strong></p>
<p>具体公式如下：</p>
<p><img src="Snipaste_2023-02-03_21-26-37.png" alt="Snipaste_2023-02-03_21-26-37"></p>
<p>其中，tf(t,d)表示某个词（term）在文档（document）中出现的频率；idf(t)表示逆向文档频率；n表示一个文档集合中所有文档的个数；df(t)表示一个文档集合中包含某个词的文档的个数</p>
<p>这种计算方法的思想是：假如某个词在某一个文档中出现的频率很高，但在其他文档中出现的概率较低，则说明这个词可以很好地将不同的文档区分开，算法就会给其分配更高的权重；假如某个词在所有文档中出现的概率都很高，则说明这个词区分文档的作用不大，这样算法就会给其分配一个较低的权重。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入Tfidf向量化工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="comment">#创建一个实例</span></span><br><span class="line">tfidf = TfidfVectorizer()</span><br><span class="line"><span class="comment">#打开我们之前保存的文本文件</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;message.txt&#x27;</span>)</span><br><span class="line"><span class="comment">#使用fit_transform方法可以直接对文本进行转换</span></span><br><span class="line">vect_tf = tfidf.fit_transform(f)</span><br><span class="line"><span class="comment">#打印部分结果查看一下</span></span><br><span class="line"><span class="built_in">print</span>(vect_tf.toarray()[<span class="number">0</span>][:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0.02931051908802746 0.11724207635210984 0.02931051908802746
 0.02931051908802746 0.08793155726408239 0.7034524581126591
 0.02931051908802746 0.02931051908802746 0.02931051908802746
 0.02931051908802746]
</code></pre>
<p>结果分析：所返回向量的结果不是整数类型而是浮点类型。在文档个数不太多的情况下，使用CountVecyorizer与TfidfVetorizer进行向量转化，效果并没有太大区别。当文档个数比较多时，推荐使用后者来进行操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tfidf.vocabulary_</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;央视网&#39;: 86,
 &#39;消息&#39;: 184,
 &#39;新闻联播&#39;: 151,
 &#39;新年&#39;: 147,
 &#39;前夕&#39;: 42,
 &#39;国家&#39;: 72,
 &#39;主席&#39;: 11,
 &#39;习平&#39;: 14,
 &#39;中央&#39;: 8,
 &#39;广播电视&#39;: 112,
 &#39;总台&#39;: 123,
 &#39;联网&#39;: 235,
 &#39;发表&#39;: 61,
 &#39;新年贺词&#39;: 149,
 &#39;全文&#39;: 32,
 &#39;北京&#39;: 52,
 &#39;祝福&#39;: 212,
 &#39;胜利&#39;: 236,
 &#39;召开&#39;: 63,
 &#39;擘画&#39;: 144,
 &#39;全面&#39;: 34,
 &#39;建设&#39;: 116,
 &#39;社主义&#39;: 209,
 &#39;现代化&#39;: 195,
 &#39;中国式&#39;: 7,
 &#39;推进&#39;: 140,
 &#39;中华民族&#39;: 4,
 &#39;复兴&#39;: 83,
 &#39;宏伟蓝图&#39;: 95,
 &#39;吹响&#39;: 67,
 &#39;奋进&#39;: 88,
 &#39;征程&#39;: 118,
 &#39;时代&#39;: 152,
 &#39;号角&#39;: 65,
 &#39;继续&#39;: 231,
 &#39;保持&#39;: 26,
 &#39;世界&#39;: 1,
 &#39;济体&#39;: 179,
 &#39;稳健&#39;: 218,
 &#39;发展&#39;: 59,
 &#39;全年&#39;: 31,
 &#39;生产总值&#39;: 200,
 &#39;预计&#39;: 290,
 &#39;万亿元&#39;: 0,
 &#39;全球&#39;: 33,
 &#39;粮食&#39;: 221,
 &#39;危机&#39;: 58,
 &#39;生产&#39;: 199,
 &#39;实现&#39;: 98,
 &#39;中国&#39;: 5,
 &#39;饭碗&#39;: 293,
 &#39;脱贫&#39;: 238,
 &#39;攻坚&#39;: 145,
 &#39;成果&#39;: 130,
 &#39;乡村&#39;: 15,
 &#39;振兴&#39;: 136,
 &#39;采取&#39;: 276,
 &#39;减税&#39;: 37,
 &#39;降费&#39;: 284,
 &#39;系列&#39;: 226,
 &#39;措施&#39;: 141,
 &#39;企业&#39;: 20,
 &#39;解困&#39;: 253,
 &#39;解决&#39;: 252,
 &#39;群众&#39;: 234,
 &#39;急难&#39;: 122,
 &#39;问题&#39;: 281,
 &#39;疫情&#39;: 205,
 &#39;发生&#39;: 60,
 &#39;始终&#39;: 89,
 &#39;坚持&#39;: 78,
 &#39;生命&#39;: 201,
 &#39;科学&#39;: 216,
 &#39;精准&#39;: 222,
 &#39;防控&#39;: 282,
 &#39;优化&#39;: 22,
 &#39;调整&#39;: 257,
 &#39;限度&#39;: 285,
 &#39;保护&#39;: 25,
 &#39;生命安全&#39;: 202,
 &#39;身体健康&#39;: 265,
 &#39;广干部&#39;: 111,
 &#39;医务员&#39;: 53,
 &#39;基层&#39;: 81,
 &#39;工作&#39;: 106,
 &#39;艰辛&#39;: 243,
 &#39;勇毅&#39;: 51,
 &#39;坚守&#39;: 76,
 &#39;艰苦卓&#39;: 242,
 &#39;努力&#39;: 50,
 &#39;战胜&#39;: 132,
 &#39;前未&#39;: 44,
 &#39;困难&#39;: 70,
 &#39;挑战&#39;: 135,
 &#39;容易&#39;: 100,
 &#39;目前&#39;: 207,
 &#39;进入&#39;: 270,
 &#39;阶段&#39;: 283,
 &#39;吃劲&#39;: 66,
 &#39;时候&#39;: 153,
 &#39;坚忍拔&#39;: 77,
 &#39;前头&#39;: 43,
 &#39;加劲&#39;: 48,
 &#39;团结&#39;: 69,
 &#39;江泽民&#39;: 175,
 &#39;缅怀&#39;: 233,
 &#39;丰功伟绩&#39;: 10,
 &#39;崇高&#39;: 105,
 &#39;风范&#39;: 291,
 &#39;珍惜&#39;: 197,
 &#39;宝贵&#39;: 97,
 &#39;精神财富&#39;: 225,
 &#39;继承&#39;: 230,
 &#39;遗志&#39;: 274,
 &#39;特色&#39;: 193,
 &#39;事业&#39;: 16,
 &#39;前进&#39;: 46,
 &#39;史长河&#39;: 64,
 &#39;波澜壮阔&#39;: 177,
 &#39;接续&#39;: 139,
 &#39;奋斗&#39;: 87,
 &#39;创造&#39;: 41,
 &#39;梦想&#39;: 162,
 &#39;冬奥&#39;: 35,
 &#39;残奥&#39;: 167,
 &#39;成功&#39;: 129,
 &#39;举办&#39;: 13,
 &#39;冰雪&#39;: 36,
 &#39;驰骋&#39;: 296,
 &#39;赛场&#39;: 262,
 &#39;骄成绩&#39;: 297,
 &#39;神舟&#39;: 213,
 &#39;十号&#39;: 55,
 &#39;接力&#39;: 138,
 &#39;空间站&#39;: 219,
 &#39;建成&#39;: 115,
 &#39;太空&#39;: 85,
 &#39;遨游&#39;: 275,
 &#39;苍穹&#39;: 245,
 &#39;民军队&#39;: 169,
 &#39;生日&#39;: 203,
 &#39;官兵&#39;: 96,
 &#39;强军&#39;: 117,
 &#39;伟业&#39;: 24,
 &#39;昂扬&#39;: 156,
 &#39;航母&#39;: 241,
 &#39;福建&#39;: 214,
 &#39;首架&#39;: 294,
 &#39;飞机&#39;: 292,
 &#39;正式&#39;: 165,
 &#39;交付&#39;: 18,
 &#39;水电站&#39;: 171,
 &#39;投产&#39;: 133,
 &#39;凝结&#39;: 38,
 &#39;辛勤&#39;: 266,
 &#39;汗水&#39;: 174,
 &#39;点点&#39;: 192,
 &#39;星火&#39;: 158,
 &#39;汇聚&#39;: 173,
 &#39;成炬&#39;: 131,
 &#39;力量&#39;: 47,
 &#39;充生机&#39;: 29,
 &#39;贸易&#39;: 260,
 &#39;试验区&#39;: 256,
 &#39;海南&#39;: 182,
 &#39;蓬勃&#39;: 250,
 &#39;海区&#39;: 181,
 &#39;踊跃&#39;: 264,
 &#39;创新&#39;: 40,
 &#39;中西部&#39;: 9,
 &#39;东北&#39;: 2,
 &#39;蓄势发&#39;: 249,
 &#39;疆区&#39;: 204,
 &#39;富民&#39;: 102,
 &#39;韧性&#39;: 288,
 &#39;潜力&#39;: 188,
 &#39;长期&#39;: 280,
 &#39;基面&#39;: 82,
 &#39;信心&#39;: 27,
 &#39;稳中求进&#39;: 217,
 &#39;目标&#39;: 208,
 &#39;香港&#39;: 295,
 &#39;十分&#39;: 54,
 &#39;欣慰&#39;: 164,
 &#39;坚移&#39;: 79,
 &#39;落实&#39;: 248,
 &#39;国两制&#39;: 71,
 &#39;澳门&#39;: 189,
 &#39;繁荣&#39;: 228,
 &#39;赓续&#39;: 261,
 &#39;民族&#39;: 170,
 &#39;精神&#39;: 223,
 &#39;洪水&#39;: 178,
 &#39;干旱&#39;: 108,
 &#39;山火&#39;: 103,
 &#39;灾害&#39;: 191,
 &#39;安全事&#39;: 93,
 &#39;揪心&#39;: 142,
 &#39;幕幕&#39;: 107,
 &#39;舍生取义&#39;: 239,
 &#39;守相助&#39;: 92,
 &#39;场景&#39;: 75,
 &#39;感深&#39;: 128,
 &#39;英雄&#39;: 247,
 &#39;事迹&#39;: 17,
 &#39;永远&#39;: 172,
 &#39;铭记&#39;: 279,
 &#39;心中&#39;: 119,
 &#39;辞旧迎新&#39;: 268,
 &#39;浩气&#39;: 180,
 &#39;倍增&#39;: 28,
 &#39;前行&#39;: 45,
 &#39;紧密联系&#39;: 227,
 &#39;迎接&#39;: 269,
 &#39;新朋友&#39;: 150,
 &#39;国门&#39;: 74,
 &#39;讲述&#39;: 254,
 &#39;主张&#39;: 12,
 &#39;百年&#39;: 206,
 &#39;变局&#39;: 62,
 &#39;加速&#39;: 49,
 &#39;演进&#39;: 187,
 &#39;太平&#39;: 84,
 &#39;珍视&#39;: 198,
 &#39;朋友&#39;: 160,
 &#39;伙伴&#39;: 23,
 &#39;正确&#39;: 166,
 &#39;类文明&#39;: 220,
 &#39;进步&#39;: 272,
 &#39;贡献&#39;: 259,
 &#39;智慧&#39;: 159,
 &#39;延安&#39;: 114,
 &#39;重温&#39;: 277,
 &#39;党中央&#39;: 30,
 &#39;时期&#39;: 155,
 &#39;岁月&#39;: 104,
 &#39;感悟&#39;: 127,
 &#39;产党&#39;: 19,
 &#39;精神力量&#39;: 224,
 &#39;艰难困苦&#39;: 244,
 &#39;玉成&#39;: 194,
 &#39;中国产党&#39;: 6,
 &#39;栉风沐雨&#39;: 161,
 &#39;披荆斩棘&#39;: 134,
 &#39;顽强拼搏&#39;: 289,
 &#39;明天&#39;: 157,
 &#39;苏轼&#39;: 246,
 &#39;意思&#39;: 125,
 &#39;追求&#39;: 273,
 &#39;愚公移山&#39;: 126,
 &#39;志气&#39;: 120,
 &#39;滴水穿石&#39;: 186,
 &#39;毅力&#39;: 168,
 &#39;脚踏实&#39;: 237,
 &#39;埋头苦干&#39;: 80,
 &#39;跬步&#39;: 263,
 &#39;宏伟目标&#39;: 94,
 &#39;现实&#39;: 196,
 &#39;诉求&#39;: 255,
 &#39;沟通&#39;: 176,
 &#39;协商&#39;: 57,
 &#39;凝聚&#39;: 39,
 &#39;舟济&#39;: 240,
 &#39;众志成城&#39;: 21,
 &#39;海峡两岸&#39;: 183,
 &#39;家亲&#39;: 99,
 &#39;衷心希&#39;: 251,
 &#39;两岸&#39;: 3,
 &#39;携手&#39;: 143,
 &#39;绵长&#39;: 232,
 &#39;福祉&#39;: 215,
 &#39;寄予&#39;: 101,
 &#39;青年&#39;: 286,
 &#39;广青年&#39;: 113,
 &#39;挺膺&#39;: 137,
 &#39;年轻&#39;: 109,
 &#39;青春&#39;: 287,
 &#39;孕育&#39;: 91,
 &#39;植家国&#39;: 163,
 &#39;情怀&#39;: 124,
 &#39;涵养&#39;: 185,
 &#39;进取&#39;: 271,
 &#39;品格&#39;: 68,
 &#39;姿态&#39;: 90,
 &#39;激扬&#39;: 190,
 &#39;华年&#39;: 56,
 &#39;时刻&#39;: 154,
 &#39;辛苦&#39;: 267,
 &#39;忙碌&#39;: 121,
 &#39;钟声&#39;: 278,
 &#39;敲响&#39;: 146,
 &#39;祝愿&#39;: 211,
 &#39;祖国&#39;: 210,
 &#39;繁荣昌盛&#39;: 229,
 &#39;国泰民安&#39;: 73,
 &#39;幸福&#39;: 110,
 &#39;新年乐&#39;: 148,
 &#39;谢谢&#39;: 258&#125;
</code></pre>
<h2 id="11-2-让机器告诉我们新闻说了啥"><a href="#11-2-让机器告诉我们新闻说了啥" class="headerlink" title="11.2 让机器告诉我们新闻说了啥"></a>11.2 让机器告诉我们新闻说了啥</h2><p>我们已经使用scikit-learn内置工具来将文本转化为向量了，接下来我们用经过预处理的数据来开展下一步的工作</p>
<h3 id="11-2-1-什么是话题建模"><a href="#11-2-1-什么是话题建模" class="headerlink" title="11.2.1 什么是话题建模"></a>11.2.1 什么是话题建模</h3><p>让机器帮助我们在海量的文本中快速地找到关键信息，这种技术就被称为话题建模。</p>
<p>目前话题建模的方法很多，入潜在语义索引LSI或LSA，概率潜在语义分析pLSA，潜狄狄利克雷分布LDA。其中LSI是一种基于线性代数的方法。它通过分解文档词条矩阵（DTM）来找到给定数量的潜在主题K。这里我们简单讲一下它的原理：LSI是一种无监督算法，它根据给定的K个奇异值和向量去寻找彼此相似度最高的文档。LSI的优点很多，包括能够消除噪声和降低数据的维度，同时捕获一些语义并对文本进行聚类。然而，LSI的结果很难解释，因为LSI的主题是同时具有正项和负项的词向量。在选择维度或主题的数量时，也没有任何基础模型允许对拟合进行评估并用来改进。</p>
<p>pLSA则从统计学的角度对潜在语义进行分析，并建立了一个生成模型来解决LSI缺乏理论基础的问题。pLSA将文档矩阵中的文档和单词每次同时出现的概率显式建模为代表某个主题的若干个词语的组合。</p>
<h3 id="11-2-2-什么是LDA模型"><a href="#11-2-2-什么是LDA模型" class="headerlink" title="11.2.2 什么是LDA模型"></a>11.2.2 什么是LDA模型</h3><p> LDA 就是在 pLSA 的基础上加层贝叶斯框架,即 LDA 就是 pLSA 的贝叶斯版本</p>
<p> LDA模型更倾向于生成人类看得懂的主题，还可以将主题分配给新文档，并且LDA模型还具备可扩展性，它的变体可以包括文本的元数据，如文章的作者或图像数据等．与pLSA所不同的是,LDA模型在pLSA模型基础上添加了<strong>主题生成的过程</strong></p>
<p>LDA模型是一个<strong>分层贝叶斯模型</strong>，它假设主题是单词的概率分布，而文档是主题的分布．更具体来说，该模型假设文本的主题都符合稀疏的狄利克雷分布．这意味着我们<strong>只需阅读文档的一小部分内容就可以概括出主题，而主题往往是由一小部分单词组成的</strong>．</p>
<p>在LDA主题模型中，狄利克雷分布非常重要．当我们向文档集中添加一篇文章时，LDA主题模型假定文章的内容取决于每个主题的权重和构成每个主题的词语．迪利克雷分布控制文档主题和主题词的选择，并基于<strong>文档仅包含少数主题，而每个主题仅频繁使用少量单词</strong>的思想来进行建模</p>
<p>LDA算法对文本的生成过程进行逆向操作,得到文档主题词关系的摘要.该摘要简明地描述了每个主题对文档的贡献率,以及每个单词与主题的概率关联.在LDA中,这种通过对<strong>假设的内容</strong>生成过程进行逆向操作的方法,解决了从文档体及其包含的单词中恢复分布的贝叶斯推理问题.</p>
<p>LDA模型是一种无监督学习的方法,而这种无监督的主题模型往往很难保证结果是有意义的或可解释的,也没有客观的标准来评估结果.当然,人工对聚类出的话题做出的评价,可以看作黄金标准,但数据规模一旦达到一定量级,这种做法就会带来高昂的成本</p>
<p>这里我们提供两种可以更客观地评估结果的方法:一种是用新的文档用模型来进行话题建模,看模型能否正确地找出文本中的话题;另一种就是使用主题一致性度量,评估模型识别出来的话题质量</p>
<h2 id="11-3-话题建模实战"><a href="#11-3-话题建模实战" class="headerlink" title="11.3 话题建模实战"></a>11.3 话题建模实战</h2><h3 id="11-3-1-加载数据并进行分词"><a href="#11-3-1-加载数据并进行分词" class="headerlink" title="11.3.1 加载数据并进行分词"></a>11.3.1 加载数据并进行分词</h3><p>为了使数据更为丰富一些,这次我们不使用单条新闻正文文本,而将所有的新闻正文文本都拿过来进行操作,首先做的还是对文本进行分词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入scikit-learn中的潜狄利克雷分布</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> LatentDirichletAllocation</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这次我们用当天的全部新闻正文来实验</span></span><br><span class="line"><span class="comment">#创建空列表</span></span><br><span class="line">tokens = []</span><br><span class="line"><span class="comment">#设置好停用词表</span></span><br><span class="line">stopwords = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;stopwords.txt&#x27;</span>,encoding=<span class="string">&#x27;UTF-8&#x27;</span>).readlines()]</span><br><span class="line"><span class="comment">#将正文进行分词，并去掉停用词</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(news)):</span><br><span class="line">    words = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    word = <span class="string">&#x27; &#x27;</span>.join(jieba.cut(news.iloc[i][<span class="number">3</span>])).replace(<span class="string">&#x27;\r\n&#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> word:</span><br><span class="line">        <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">            words += w</span><br><span class="line">    <span class="comment">#把分出来的词添加到空列表中</span></span><br><span class="line">    tokens.append(words)</span><br><span class="line"><span class="comment">#把结果作为新的一列，添加到DataFrame中</span></span><br><span class="line">news[<span class="string">&#x27;tokens&#x27;</span>] = pd.Series(tokens)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">news.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>day</th>
      <th>title</th>
      <th>content</th>
      <th>tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>103844</td>
      <td>2022-12-31</td>
      <td>“奋进新时代”主题成就展闭幕</td>
      <td>央视网消息\n（新闻联播）：由中央宣传部、国家发展改革委、中央军委政治工作部、北京市联合主办...</td>
      <td>央视网 消息 \n  新闻联播    中央宣部  国家 发展 改革 委  中央军委 政治 工...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>103839</td>
      <td>2022-12-31</td>
      <td>【央视快评】让明天的中国更美好</td>
      <td>央视网消息\n（新闻联播）：本台播发央视快评《让明天的中国更美好》。</td>
      <td>央视网 消息 \n  新闻联播   台 播发 央视 评   明天  中国  美</td>
    </tr>
    <tr>
      <th>2</th>
      <td>103840</td>
      <td>2022-12-31</td>
      <td>中俄两国元首互致新年贺电 中俄两国总理互致新年贺电</td>
      <td>央视网消息\n（新闻联播）：2022年12月31日，国家主席习近平和俄罗斯总统普京互致新年贺...</td>
      <td>央视网 消息 \n  新闻联播    年  月  日  国家 主席 习平  俄罗斯 总统 普...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>103845</td>
      <td>2022-12-31</td>
      <td>中央文明办部署开展元旦春节文明实践志愿服务活动</td>
      <td>央视网消息\n（新闻联播）：中央文明办日前印发通知，要求元旦春节期间在全国城乡广泛开展文明实...</td>
      <td>央视网 消息 \n  新闻联播   中央文明办 日前 印发 通知  求 元旦 春节 期间  ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>103841</td>
      <td>2022-12-31</td>
      <td>习近平向拉马福萨当选连任南非非洲人国民大会主席致贺电</td>
      <td>央视网消息\n（新闻联播）：12月31日，中共中央总书记习近平致电祝贺拉马福萨当选连任南非非...</td>
      <td>央视网 消息 \n  新闻联播    月  日  中中央 总书记 习平 电 祝贺 拉马 福萨...</td>
    </tr>
  </tbody>
</table>
</div>



<p>我们可以看到,这次我们把当天的新闻联播中的全部正文文本数据都进行了分词处理,并保存到了DataFrame当中</p>
<h3 id="11-3-2-将分词结果合并保存"><a href="#11-3-2-将分词结果合并保存" class="headerlink" title="11.3.2 将分词结果合并保存"></a>11.3.2 将分词结果合并保存</h3><p>下面将全部的新闻正文文本数据的分词结果合并成一个长字符串,即我们要把所有的新闻正文合并在一个文档中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面我们把所有的分词结果合并成一个长字符串</span></span><br><span class="line">text = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#并且用回车来分割不同的内容</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(news)):</span><br><span class="line">    text += news.iloc[i][<span class="number">4</span>]+<span class="string">&#x27;\n&#x27;</span></span><br><span class="line"><span class="comment">#检查一下结果</span></span><br><span class="line">text</span><br></pre></td></tr></table></figure>




<pre><code>&#39;央视网 消息 \n  新闻联播    中央宣部  国家 发展 改革 委  中央军委 政治 工作部  北京市 联合 主办   奋进 新 时代  主题 成展 天   年  月  日   京 圆 闭幕  展览  月  日 开幕   广干部 群众 踊跃 参观  新闻媒体 集中 报道  社界 高度评价   迎接 宣 贯彻 党  十 营造  良  社 氛围  \n \n 展览 紧扣  奋进 新 时代  主题   设置  展区  总面积  平米  展 图片  视频  实物  模型  展览 素  项  全位  全景式 展现  新 时代 十年 党国家 事业 取  史性 成  发生  史性 变革  悉   奋进 新 时代  主题 成展 网 展馆  继续 运行 \n央视网 消息 \n  新闻联播   台 播发 央视 评   明天  中国  美  \n央视网 消息 \n  新闻联播    年  月  日  国家 主席 习平  俄罗斯 总统 普京  新年 贺电  \n \n 习平 代表 中国政府  中国 民  普京 总统  俄罗斯 民  诚挚  祝贺  美  祝愿  习平 指   年    平  年  面 加速 演变  国际形势  持续 蔓延  全球 疫情  中俄关系 始终保持 健康 发展势头   年  中 俄 贸合作 稳步 推进  源  投资  联通  领域 合作 取 新 成果   两国  发展 提供  助力  双 正式 启动 中 俄 体育 交流 年  两 国 民众  相解  统友谊 进步 加深  \n \n 习平 指      年  中国 全面落实 中 十 精神  开局  年  中俄关系   迎 新  发展 机遇  愿 普京 总统 保持 密 交  引领 双 深化 全面 战 协作   领域 务实 合作  造福 两国  两国民  \n \n 普京 总统  习平 主席  衷心  节日 祝贺  祝愿 友  中国 民 幸福 安康  普京 表示      年 里  俄中 全面 战 协作 伙伴关系 持续 加强  展现 强劲 发展势头  受 住 外部 挑战 考验  两 国 政治 话 容 丰富  双 贸易额 创 史 新高  重 跨境 交通 基础设施 项目 建设 完工  俄中 体育 交流 年 利 举办   推动 双 文 合作 作 重 贡献  相信 通 努力  双 够  两国 合作 提升  新   高水平  造福 俄中 两国民  \n \n 日  国务院 总理 李克强  俄罗斯 总理 米 舒斯京  新年 贺电  李克强 表示    年  中 俄 全位 务实 合作 持续 深化  文 交流 日益 密  两 国 友  社 民意基础 愈加 稳  双 成功 举行  中 俄 总理 十次 期 晤  达成 重 识  愿 米 舒斯京 总理 加强 沟通交流  推动 两国  领域 务实 合作 取   实实  成果  米 舒斯京 表示  俄中 全面 战 协作 伙伴关系 断 前 发展  相信 两 国 总理 期 晤 框架  达成  项 识  助 增进 两 国 战 协作  提升 两国民 福祉 \n央视网 消息 \n  新闻联播   中央文明办 日前 印发 通知  求 元旦 春节 期间  全国 城乡 广泛开展 文明 实践 志愿 服务  \n \n  通知  强调   组织 开展  党  声音 进万家  主题 动  推动 党  十 精神 深入心  落生根   优化 疫情 防控 志愿 服务 举措  开展 丰富彩  节庆 文化 动  统 民俗  年俗 动  组织 志愿 参 平安 谐社 建设   城乡居民  成 文明 实践  参  受益 \n央视网 消息 \n  新闻联播    月  日  中中央 总书记 习平 电 祝贺 拉马 福萨 选  南非非洲国民 主席  \n \n 习平  贺电 中说  欣悉  选  南非非洲国民 主席     诚挚  祝贺  祝     崇高 岗位  取 新    成  \n \n 习平 指  中国产党  南非非洲国民 统友谊 深厚  交流 合作 成果 丰硕   推动 两 国 全面 战伙伴 关系 深入 发展 发挥  重 作  愿 主席 先生 道   引领 中南 两党 两国关系 迈  高水平  携手 构建 新 时代 中非 命运 体  类 命运 体    \n\n央视网 消息 \n  新闻联播   明天   年  月  日  版   民日报   发表 社  题目   锚 奋斗目标   创造 新  伟业   元旦 献词  \n央视网 消息 \n  新闻联播   日   级 医疗机构 全力赴  力 做 诊疗 关口 前移  患 救治 工作  \n \n 目前  北京 疫情 总体 趋缓   缓解  级 医院  救治 压力  北京市  社区卫生 服务中心 百计 提升 服务 力     需求  居民 提供 氧气 灌装 服务  丰台区 辖  家 社区卫生 中心  增设  张 住院 床位   居民  提供 住院 诊疗  服务  \n \n 海市 统筹 医疗 资源  实施 分类 分级 诊疗  全市  家 社区卫生 服务中心   家 区级 医院   家 市级 综合 医院 形成 应  合作 关系  \n \n 川 实行 分片包干 责制  建 级 重症 救治 体系  覆盖 全省  市  州   家 级 医院   家区 县级 医院  目前  级  医疗机构 总 床位  重症 床位 率 分     \n央视网 消息 \n  新闻联播   新年 前夕  国家 主席 习平 通 中央 广播电视 总台  联网  发表   〇 年 新年贺词  全文  \n \n 家    年      北京  家  美  新年 祝福  \n \n  年   胜利 召开 党  十  擘画  全面 建设 社主义 现代化 国家   中国式 现代化 全面 推进 中华民族 伟 复兴  宏伟蓝图  吹响  奋进 新 征程  时代 号角  \n \n 国 继续 保持 世界   济体  位  济 稳健 发展  全年 国 生产总值 预计 超  万亿元  面 全球 粮食 危机  国 粮食 生产 实现  十 丰   中国   饭碗 端  牢    巩 脱贫 攻坚 成果  全面 推进 乡村 振兴  采取 减税 降费  系列 措施  企业 纾 难 解困  力 解决 民 群众 急难 愁 盼 问题  \n \n 疫情 发生    始终 坚持 民   生命   坚持 科学 精准 防控  时 势 优化 调整 防控 措施   限度 保护  民 生命安全  身体健康  广干部 群众 特  医务员  基层 工作 畏 艰辛  勇毅 坚守   艰苦卓  努力   战胜  前未  困难  挑战      容易  目前  疫情 防控 进入 新 阶段    吃劲  时候  家   坚忍拔 努力  曙   前头  家  加劲  坚持  胜利  团结  胜利  \n \n  年  江泽民 志 开     深 缅怀   丰功伟绩  崇高 风范  珍惜  留  宝贵 精神财富    继承   遗志   新 时代 中国 特色 社主义 事业 断 推 前进  \n \n 史长河 波澜壮阔  代  代 接续 奋斗 创造  天  中国  \n \n 天  中国   梦想 接 实现  中国  北京 冬奥  冬 残奥 成功 举办  冰雪 健 驰骋 赛场  取  骄成绩  神舟 十号  十号  十号 接力 飞  中国 空间站 全面 建成     太空  家  遨游 苍穹  民军队 迎  岁 生日  广 官兵  强军 伟业 征程  昂扬 奋进  艘 航母  福建 号  水  首架 C  飞机 正式 交付  鹤 滩 水电站 全面 投产      凝结  数   辛勤 付  汗水  点点 星火  汇聚 成炬    中国 力量  \n \n 天  中国   充生机 力  中国   贸易 试验区  海南 贸易 港 蓬勃 兴  海区 踊跃 创新  中西部 区 加 发展  东北 振兴 蓄势发  疆区 兴 富民  中国 济 韧性 强  潜力   力 足  长期    基面  变   笃 信心  稳中求进     实现   目标  年    香港   香港  治 兴 十分 欣慰  坚移 落实   国两制   香港  澳门  长期 繁荣 稳  \n \n 天  中国  赓续 民族 精神  中国   年 发生  震  洪水  干旱  山火  灾害   安全事    揪心  令 难   幕幕 舍生取义  守相助  场景 感深  英雄  事迹 永远 铭记   心中   辞旧迎新  总 念 中华民族 年 承  浩气  倍增 前行 信心  \n \n 天  中国   紧密联系 世界  中国   年    北京 迎接  少 新朋友   走 国门 讲述 中国 主张  百年 变局 加速 演进  世界   太平   始终 珍视 平  发展  始终 珍惜 朋友  伙伴  坚 站  史 正确    站  类文明 进步    努力  类 平  发展 事业 贡献 中国 智慧  中国 案  \n \n 党  十    事     延安  重温 党中央  延安 时期 战胜 世 罕 困难  辉 岁月  感悟 辈 产党  精神力量   说  艰难困苦  玉成  中国产党 百年 栉风沐雨  披荆斩棘  程  艰辛   伟    前  顽强拼搏   明天  中国  美  \n \n 明天  中国  奋斗 创造 迹  苏轼 句 话   犯  难  图   远   意思  说   难 处 攻坚  追求 远   目标   路 远  行    事 难  做  成    愚公移山  志气  滴水穿石  毅力  脚踏实  埋头苦干  积 跬步  里    够  宏伟目标 变 美 现实  \n \n 明天  中国  力量 源 团结  中国        诉求   件 事     法    正   通 沟通 协商 凝聚 识   亿 中国 心  处 想  劲 处   舟济  众志成城    干 成  事  迈   坎  海峡两岸 家亲  衷心希 两岸 胞 相 行  携手 进  创 中华民族 绵长 福祉  \n \n 明天  中国  希 寄予 青年  青年 兴 国家 兴  中国 发展   广青年 挺膺 担  年轻 充 气  青春 孕育 希  广青年 厚 植家国 情怀  涵养 进取 品格   奋斗 姿态 激扬 青春  负 时代  负 华年  \n \n 时刻  许    辛苦 忙碌  家 辛苦   新年  钟声  敲响    怀  未  美    迎接  年  缕 阳  \n \n 祝愿 祖国 繁荣昌盛  国泰民安  祝愿 世界 平 美  幸福 安  祝愿 家 新年乐  皆  愿  \n \n 谢谢 \n央视网 消息 \n  新闻联播   新年    神州 银装素裹  流溢彩  节目       领 美 中国 \n央视网 消息 \n  新闻联播    月  日 午  十届 全国委 十 次 议 表决 通   全国民代表务委员 关  中华民国香港特行政区 维护 国家 安全法  十条  十条  解释   香港特区 行政长官 李家 超 晚 发表声明  表示 欢迎  感谢  李家 超 表示  香港特行政区 维护 国家 安全 委员  特区政府  全力 落实 次 释法 容 中  说明  责  全国委 根 宪法  香港 国安法 赋予  权力 解释 香港 国安法 条文   进步 完善 特区 维护 国家 安全  法律 制度  执行 机制  效 维护 国家 安全  重意义  特区政府 坚决 维护 国家主权  安全  发展 利益  维护 香港 国安法  权威  法 履行 维护 国家 安全  职责  义务  确保  国两制  实践 行稳 远  \n \n 中央民政府 驻 香港特行政区 维护 国家 安全 公署 发言 发表谈话 表示  全国委  法律 解释  香港 国安法 具  效力  香港特区 行政  法  司法机关 须 遵  执行  驻港 国家 安全 公署 法 监督  指导  协调  支持 香港特行政区 履行 维护 国家 安全 职责  支持 特区 国安 委 落实 委 释法  精神  求  实 执行 香港 国安法   释法  确保 国家 安全  效 维护    \n \n \n 香港特区 法  司法 机构 表示  欢迎  尊重 全国委  香港 国安法  条文 作 解释 \n央视网 消息 \n  新闻联播   天   年  月  日   元旦假期 天    丰富彩  假日 生 中  享 祖国 发展 成果  喜迎 新年   \n \n 年  接 田  羌    铁路 正式 开通 运营   环抱  塔克拉玛干沙漠  世界 首 沙漠 铁路 环线 全线贯通  旅游 探亲 成 少 家庭  假日 选择  \n \n  年    辛勤耕耘 换  果实累累   安徽 颍   冬捕 现场  黑龙江 逊克县  田间 头  江南北   庆 丰收  迎新年  \n \n  假期  运动 节 气 旺   福建 鼓山   年 古道 登高远  览 秀美 风   海南 亚 蜈支洲岛  风破浪  体验 浪 潜水   云南 怒江  皮划艇 竞技 赛 激烈 展开  百名 选手 奋楫 争先   拼搏 中 怀信心  未  \n \n  辽沈阳 冰雪 嘉年华 玩冰乐雪   吉林 梅河口  雪道  疾驰    北京 冬奥   首 雪季     精彩纷呈  冰雪 动 中  迎接 新年   \n \n  假期  文化 节 选择   世界 文化遗产 重庆 足 石刻 造 深度 体验 游  帮助 游客  领 年 石窟 石刻 造 艺术  特 魅力  广州 永庆 坊  粤剧 表演  河南 开封  民俗 展示  蒙古 拉善右旗  达慕      欢度 假日  时  感知 统 文化  天津 推  航天 科技成果 主题 展   吸引 广 青少年 前 观展 \n央视网 消息 \n  新闻联播   民政部 日前 印发 通知  求  时  符合条件  困难群众 纳入 救助 范围  时 足额 发放 类 救助金  密 关注  综合 研判 节日期间 物价 波动 情况  规 时 启动 困难群众 价格 补贴 联动机制  确保 困难群众 基 生  受 物价涨 影响  加强  分散 供养 特困 员  困难群众  走访 探视    疫情  导 基 生 现 暂时性 困难  群众 时 予 时 救助  实 保障 元旦 春节 期间 困难群众 基 生 \n央视网 消息 \n  新闻联播   \n \n \n 天 全国 铁路 预计 发送 旅客  万次 \n \n \n 元旦  长假 首日  全国 铁路 预计 发送 旅客  万次  长角  成渝    行  热门 区域  铁路 部门 采取 灵 增加 运力 投放  加密 重点部位 消毒 频次  优化 客流 组织  式  保障 旅客 假日 平安 序 行  \n \n \n 两项 民币 汇率 指数  货币 篮子 权重 明年  调整 \n \n \n  进步 增强 民币 汇率 指数 货币 篮子 代表性  中国外汇交易中心 调整 CFETS 民币 汇率 指数  SDR 货币 篮子 民币 汇率 指数  货币 篮子 权重  新版 指数   年  月  日 生效  \n \n \n  启航   中央 广播电视 总台 跨年 晚  晚 播 \n \n \n  启航   中央 广播电视 总台 跨年 晚    晚   年  月  日   总台 央视 综合 频道  综艺 频道  音乐频道  央 视频  央视网  音乐 声  文艺 声  平台 推  载  未  美 愿景  营造 暖心  舒心  信心  跨年 氛围  \n \n \n 俄称 击 乌 源 系统   乌称 击 俄 弹药库 \n \n \n 俄罗斯国防部  日称  俄军  日  乌克兰 军 源 系统  进行  规模 击  乌 军事装备 生产  维修 中断  西 武器 运输 受阻  乌 称  乌军  俄军 弹药库  雷达站 发动 击   击落 架 俄军 机 \n&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这个代码也是学过的</span></span><br><span class="line"><span class="comment">#把上面的长字符串写入到名叫text.txt的文本文件中</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span> (<span class="string">&#x27;text.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(text)</span><br></pre></td></tr></table></figure>

<h3 id="11-3-3-使用LDA进行话题建模"><a href="#11-3-3-使用LDA进行话题建模" class="headerlink" title="11.3.3 使用LDA进行话题建模"></a>11.3.3 使用LDA进行话题建模</h3><p><strong>重点来了</strong>,接下来,我们让机器根据我们的要求,从文档中提取出指定数量的<strong>话题</strong>,并且告诉我们每个话题包含的<strong>高频词</strong>有哪些</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了一会儿方便我们打印话题建模的结果</span></span><br><span class="line"><span class="comment">#这里我们定义一个函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_topics</span>(<span class="params">model, feature_names, n_top_words</span>):</span><br><span class="line">    <span class="comment">#首先是遍历模型中存储的话题序号和话题内容</span></span><br><span class="line">    <span class="keyword">for</span> topic_idx, topic <span class="keyword">in</span> <span class="built_in">enumerate</span>(model.components_):</span><br><span class="line">        <span class="comment">#然后打印话题的序号以及指定数量的最高频的关键词</span></span><br><span class="line">        message = <span class="string">&#x27;topic #%d:&#x27;</span> % topic_idx</span><br><span class="line">        message += <span class="string">&#x27; &#x27;</span>.join([feature_names[i]</span><br><span class="line">                           <span class="keyword">for</span> i <span class="keyword">in</span> topic.argsort()[:-n_top_words - <span class="number">1</span>:-<span class="number">1</span>]])</span><br><span class="line">        <span class="built_in">print</span> (message)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure>

<p>运行上面的代码后,我们就有了一个可以很方便输出模型结果的函数了,接下来我们使用LDA模型来进行话题建模</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#打开刚刚保存的文本文档，指定打开方式为r</span></span><br><span class="line"><span class="comment">#也就是读取</span></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;text.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"><span class="comment">#指定一个模型输出的话题中，显示5个最高频的关键词</span></span><br><span class="line">n_top_words = <span class="number">5</span></span><br><span class="line"><span class="comment">#创建一个TfidfVectorizer实例</span></span><br><span class="line"><span class="comment">#这里把ngram_range参数改为（2，2）</span></span><br><span class="line">tf = TfidfVectorizer(ngram_range=(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"><span class="comment">#用TfidfVectorizer将文本数据转化为向量</span></span><br><span class="line">x_train = tf.fit_transform(f)</span><br><span class="line"><span class="comment">#创建一个LDA实例，指定模型从文本中提取10个话题</span></span><br><span class="line">lda = LatentDirichletAllocation(n_components=<span class="number">10</span>)</span><br><span class="line"><span class="comment">#用LDA模型拟合数据</span></span><br><span class="line">lda.fit(x_train)</span><br><span class="line"><span class="comment">#将结果进行打印</span></span><br><span class="line">print_topics(lda, tf.get_feature_names(), n_top_words)</span><br></pre></td></tr></table></figure>

<pre><code>/opt/conda/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for &#39;learning_method&#39; will be changed from &#39;online&#39; to &#39;batch&#39; in the release 0.20. This warning was introduced in 0.18.
  DeprecationWarning)


topic #0:系统 乌称 俄称 系统 乌称 弹药库 题目 奋斗目标 元旦 献词
topic #1:新年 祝福 北京 新年 引领 中南 十号 十号 发展 发挥
topic #2:祝贺 拉马 新闻联播 中中央 拉马 福萨 习平 祝贺 中中央 总书记
topic #3:旅客 万次 铁路 预计 全国 铁路 预计 发送 发送 旅客
topic #4:银装素裹 流溢彩 节目 中国 神州 银装素裹 新年 神州 世界 幸福
topic #5:央视网 消息 国家 安全 维护 国家 香港 国安法 发展 成果
topic #6:汇率 指数 民币 汇率 货币 篮子 指数 货币 篮子 权重
topic #7:明天 中国 播发 央视 新闻联播 播发 央视 明天 普京 新年
topic #8:史长河 波澜壮阔 接续 奋斗 波澜壮阔 接续 奋斗 创造 全面 协作
topic #9:总台 跨年 启航 中央 中央 广播电视 广播电视 总台 冰雪 迎接
</code></pre>
<p>其中我们可以调整ngram_range参数,ngram_range(a,b)意思是模型”装进口袋”的词最少是a个,最多是b个</p>
<h1 id="第12章-股评数据情感分析"><a href="#第12章-股评数据情感分析" class="headerlink" title="第12章 股评数据情感分析"></a>第12章 股评数据情感分析</h1><h2 id="12-1-机器懂我们的情感吗"><a href="#12-1-机器懂我们的情感吗" class="headerlink" title="12.1 机器懂我们的情感吗"></a>12.1 机器懂我们的情感吗</h2><p>情感分析(情绪分析),这项技术的主要目的是识别和提取文本数据中的<strong>主观信息</strong>,以便我们对文本所表达的情绪做出判断</p>
<p>归根结底,情感分析还是属于机器学习中分类任务的范畴,同样地,我们可以把这个方法用于判断由市场投资者的情绪反映出的股市的状态,并借此来对交易进行择时</p>
<h3 id="12-1-1-了解好分类的语料"><a href="#12-1-1-了解好分类的语料" class="headerlink" title="12.1.1 了解好分类的语料"></a>12.1.1 了解好分类的语料</h3><p>预先下载已经根据市场投资者的情绪分类好的文本数据</p>
<p>positive.txt  </p>
<p>negtive.txt</p>
<h3 id="12-1-2-将文件上传到量化交易平台"><a href="#12-1-2-将文件上传到量化交易平台" class="headerlink" title="12.1.2 将文件上传到量化交易平台"></a>12.1.2 将文件上传到量化交易平台</h3><h2 id="12-2-用语料制作数据集"><a href="#12-2-用语料制作数据集" class="headerlink" title="12.2 用语料制作数据集"></a>12.2 用语料制作数据集</h2><p>下一步我们要把这些语料数据加工成可以训练模型的数据集.由于原始的语料数据是以TXT文件的形式存储的,我们要对文件做一点处理,将TXT文件中的数据转化成一个<strong>包含正负极性</strong>且<strong>两个分类中的样本数量基本均衡</strong>的数据集</p>
<h3 id="12-2-1-将正面情绪语料存储为列表"><a href="#12-2-1-将正面情绪语料存储为列表" class="headerlink" title="12.2.1 将正面情绪语料存储为列表"></a>12.2.1 将正面情绪语料存储为列表</h3><p>将txt文件中的语料数据按照逐行的方式存储到列表中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先把一些会用到的库进行导入</span></span><br><span class="line"><span class="comment">#这些库大家都比较熟悉了</span></span><br><span class="line"><span class="comment">#就不一一介绍了</span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>

<p>把positive.txt中的内容读取出来,并将其保存到一个列表中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个空列表，用来存储正面情绪的语料</span></span><br><span class="line">pos_corpus = []</span><br><span class="line"><span class="comment">#打开positive.txt文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;positive.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="comment">#设置一个for循环</span></span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> f:</span><br><span class="line">        <span class="comment">#将文件中的文本每行为一个元素，添加到刚创建的空列表中</span></span><br><span class="line">        pos_corpus.append(sent.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>))</span><br><span class="line"><span class="comment">#检查列表中的元素数量</span></span><br><span class="line"><span class="built_in">len</span>(pos_corpus)</span><br></pre></td></tr></table></figure>




<pre><code>4607
</code></pre>
<p>这样操作的原因是,我们不可能把positive.txt和negtive.txt两个文件作为训练数据直接扔给模型.在原始的语料数据中,每一行应该就是一条股评文本.这样的话,思路就是应该是把<strong>每条股评</strong>作为单独的一条数据来看待.从代码运行结果可以看到代表正面情绪的股评就有4607条,数量还是较多的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#可以用下面的方法检查一下列表的前5条</span></span><br><span class="line">pos_corpus[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;买入 长期 持有 沃森 生物 19条 简短 想法&#39;,
 &#39;利好 出 还 涨&#39;,
 &#39;线 战士 持 全安 牌 伟哥 火爆 进货 深交所 9月 17日 暂停 etf 融资 买入 etf 融资 余额 已 达到 证券 上市 流通 市值 每个 男人 都 一颗 王全安 心 王 后 深 男哥 私募 火爆 大战 伟哥 股 王全安 时代 召唤&#39;,
 &#39;浙江 冬日 彻底 破位&#39;,
 &#39;达安 基因 该涨&#39;]
</code></pre>
<h3 id="12-2-2-将负面情绪语料存储为列表"><a href="#12-2-2-将负面情绪语料存储为列表" class="headerlink" title="12.2.2 将负面情绪语料存储为列表"></a>12.2.2 将负面情绪语料存储为列表</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个空列表，用来存储负面情绪的语料</span></span><br><span class="line">neg_corpus = []</span><br><span class="line"><span class="comment">#打开negtive.txt文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;negtive.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="comment">#设置一个for循环</span></span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> f:</span><br><span class="line">        <span class="comment">#将文件中的文本每行为一个元素，添加到刚创建的空列表中</span></span><br><span class="line">        neg_corpus.append(sent.replace(<span class="string">&#x27;\n&#x27;</span>,<span class="string">&#x27;&#x27;</span>))</span><br><span class="line"><span class="comment">#检查列表中的元素数量</span></span><br><span class="line"><span class="built_in">len</span>(neg_corpus)</span><br></pre></td></tr></table></figure>




<pre><code>4607
</code></pre>
<p>正负面情绪语料数量相同,说明这两种语料的数量还是比较均衡的,省去了我们要手动均衡正负面情绪语料的工作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#检查一下列表的前5条</span></span><br><span class="line">neg_corpus[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;此股 垃圾 买 上套 nndnull 整个 上午 大 单 都 抛 基本上 跑 跑掉 下午 猛冲&#39;,
 &#39;变绿&#39;,
 &#39;明天 开盘 清仓 卖光 一文不值 弄 虚 造假 实际 巨亏 国农 最 明智 最 理智 决定&#39;,
 &#39;资金 已经 出逃 融券 大胆 做空 跳水 走为上着 已 清仓 希望 18块 接回 今天 全部 卖 出 清仓 完 明天 大跌 清仓 坐等 3个 跌停 后 进货&#39;,
 &#39;鬼 弄 金融 SB 顶 老贴 不累&#39;]
</code></pre>
<h3 id="12-2-3-给数据”打上标签”"><a href="#12-2-3-给数据”打上标签”" class="headerlink" title="12.2.3 给数据”打上标签”"></a>12.2.3 给数据”打上标签”</h3><p>在监督学习方法中,数据是带有分类标签的,所以接下来,我们要用标签来区分语料代表的情绪,或者说极性</p>
<p>下面我们用1来代表正面情绪,用0来代表负面情绪,对数据进行标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将正面情绪列表转化为DataFrame</span></span><br><span class="line"><span class="comment">#列命名为text</span></span><br><span class="line">pos_df = pd.DataFrame(pos_corpus, columns = [<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line"><span class="comment">#创建一个新的字段，命名为polarity，正面情绪语料全部标“1”</span></span><br><span class="line">pos_df[<span class="string">&#x27;polarity&#x27;</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">pos_df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>polarity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>买入 长期 持有 沃森 生物 19条 简短 想法</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>利好 出 还 涨</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>线 战士 持 全安 牌 伟哥 火爆 进货 深交所 9月 17日 暂停 etf 融资 买入 e...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>浙江 冬日 彻底 破位</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>达安 基因 该涨</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将正面情绪列表转化为DataFrame</span></span><br><span class="line"><span class="comment">#列命名为text</span></span><br><span class="line">neg_df = pd.DataFrame(neg_corpus, columns = [<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line"><span class="comment">#创建一个新的字段，命名为polarity，正面情绪语料全部标“0”</span></span><br><span class="line">neg_df[<span class="string">&#x27;polarity&#x27;</span>] = <span class="number">0</span></span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">neg_df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>polarity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>此股 垃圾 买 上套 nndnull 整个 上午 大 单 都 抛 基本上 跑 跑掉 下午 猛冲</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>变绿</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>明天 开盘 清仓 卖光 一文不值 弄 虚 造假 实际 巨亏 国农 最 明智 最 理智 决定</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>资金 已经 出逃 融券 大胆 做空 跳水 走为上着 已 清仓 希望 18块 接回 今天 全部...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>鬼 弄 金融 SB 顶 老贴 不累</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="12-2-4-合并正负面情绪语料"><a href="#12-2-4-合并正负面情绪语料" class="headerlink" title="12.2.4 合并正负面情绪语料"></a>12.2.4 合并正负面情绪语料</h3><p>现在我们已经分别给代表正负面情绪语料打上了标签,并且将其保存在DataFrame中</p>
<p>接下来要做的事情是把正负面情绪语料合并到一个数据集中,以便于模型的训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用pandas的concat方法就可以合并两个DataFrame</span></span><br><span class="line"><span class="comment">#这里还要把原来的index去掉，并重设一个新的index</span></span><br><span class="line">df = pd.concat([pos_df, neg_df]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#为了查看是否合并成功，我们可以用seaborn的计数图来看下</span></span><br><span class="line"><span class="comment">#标签0和标签1的数量</span></span><br><span class="line">sns.countplot(df[<span class="string">&#x27;polarity&#x27;</span>])</span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_425_0.png" alt="output_425_0"></p>
<p>在使用concat方法将两个DataFrame合并后,我们使用了seaborn中的countplot来绘制新数据集中不同极性标签的数量分布情况.</p>
<p>从图中可以看到,合并完成之后,在新的数据集中,极性标注为0的数据和极性标注为1的数据的数量是相同的.这说明数据的合并已经成功</p>
<h2 id="12-3-隆重推出”朴素贝叶斯”"><a href="#12-3-隆重推出”朴素贝叶斯”" class="headerlink" title="12.3 隆重推出”朴素贝叶斯”"></a>12.3 隆重推出”朴素贝叶斯”</h2><h3 id="12-3-1-“朴素贝叶斯”又是什么"><a href="#12-3-1-“朴素贝叶斯”又是什么" class="headerlink" title="12.3.1 “朴素贝叶斯”又是什么"></a>12.3.1 “朴素贝叶斯”又是什么</h3><p>假如我们计划买一只股票,肯定希望买入之后它就会涨停(俗话叫抓涨停板),但做到这一点非常困难</p>
<p>首先我们针对某只股票的历史数据,统计出它涨停的概率;然后分析一下它在涨停前成交量的变化,计算出”如果该股票涨停,则前一日成交量显著增加”的概率</p>
<p>如果股票涨停的前一日成交量显著增加的概率非常高,那我们每天下单买前一日成交量显著增加的股票,就更容易抓到”涨停板”了,用贝叶斯定理描述就是:</p>
<p>(1)某只股票涨停的概率,记为P(涨停),等于5%</p>
<p>(2)该股票每次涨停前一日,成交量显著增加的概率,记为P(成交量增加|涨停), 等于60%</p>
<p>(3)该股票在过去的时间中,成交量显著增加的概率,记为P(成交量增加), 假设为4%</p>
<p>(4)该股票成交量显著增加, 次日涨停的概率, 记为P(涨停|成交量增加)</p>
<p>根据贝叶斯定理,想知道成交量显著增加的股票在次日涨停的概率,计算方法为</p>
<p>P(涨停|成交量增加)&#x3D;p(成交量增加|涨停)·p(涨停)&#x2F;p(成交量增加)&#x3D;0.6X0.05&#x2F;0.04X100%&#x3D;75%</p>
<p>要是上面的假设全部成立,那么根据贝叶斯公式,只要我们每次都买入前一日成交量显著增加的股票,就会有75%的概率抓到”涨停板”</p>
<h3 id="12-3-2-为贝叶斯模型准备数据"><a href="#12-3-2-为贝叶斯模型准备数据" class="headerlink" title="12.3.2 为贝叶斯模型准备数据"></a>12.3.2 为贝叶斯模型准备数据</h3><p>要判断一条新文本包含的是正面情绪还是负面情绪,则模型需要先在已经增加了极性标签的数据中去分别学习包含正面情绪的文本中的各个词汇出现的概率及包含负面情绪的文本的各个词汇出现的概率,然后根据这条文本包含的词汇来预测该文本包含某种情绪的概率.</p>
<p>在文本分析领域,朴素贝叶斯算法是最常见的算法之一了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用数据集中的text作为特征</span></span><br><span class="line">X = df[<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line"><span class="comment">#polarity作为标签</span></span><br><span class="line">y = df[<span class="string">&#x27;polarity&#x27;</span>]</span><br><span class="line"><span class="comment">#创建一个TfidfVectorizer的实例</span></span><br><span class="line">vectorizer = TfidfVectorizer()</span><br><span class="line"><span class="comment">#使用Tfidf将文本转化为向量</span></span><br><span class="line">X = vectorizer.fit_transform(X)</span><br><span class="line"><span class="comment">#看看特征长什么样子</span></span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>&lt;9214x14503 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
    with 56565 stored elements in Compressed Sparse Row format&gt;
</code></pre>
<p>结果分析:在使用Tfidf将文本转化为向量之后,数据集的特征成为一个9214行14503列的稀疏矩阵</p>
<h3 id="12-3-3-开始训练贝叶斯模型并评估其性能"><a href="#12-3-3-开始训练贝叶斯模型并评估其性能" class="headerlink" title="12.3.3 开始训练贝叶斯模型并评估其性能"></a>12.3.3 开始训练贝叶斯模型并评估其性能</h3><p>现在我们已经把原始的文本数据集转化成可以用来训练模型的稀疏矩阵了,接下来开始进行模型的训练工作.</p>
<p>按照惯例, 我们先把数据集拆分为训练集和验证集,以便于对模型的性能进行评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将数据集拆分为训练集和验证集</span></span><br><span class="line"><span class="comment">#这里固定一下random_state为30</span></span><br><span class="line"><span class="comment">#便于复现</span></span><br><span class="line">X_train, X_test, y_train, y_test =\</span><br><span class="line">train_test_split(X,y,random_state = <span class="number">30</span>)</span><br><span class="line"><span class="comment">#可以检查一下拆分</span></span><br><span class="line">X_train.shape</span><br></pre></td></tr></table></figure>




<pre><code>(6910, 14503)
</code></pre>
<p>在缺省的情况下,train_test_split默认的拆分是将数据集中75%的样本作为训练集,将其余25%的样本作为验证集.经过拆分之后,在全部9214条数据中,训练集中的样本数量为6910. 当然, 特征数量不变,仍然是14503</p>
<p>下面可以开始训练一个朴素贝叶斯模型, 这里要说明, 朴素贝叶斯包含了一系列算法—伯努利朴素贝叶斯, 多项式朴素贝叶斯, 高斯朴素贝叶斯</p>
<p>其中,伯努利朴素贝叶斯适用于样本特征符合伯努利分布(或者说二值分布)的情况;高斯朴素贝叶斯适用于非稀疏矩阵. 在这种情况下,多项式朴素贝叶斯更加适用. 于是我们就选择多项式朴素贝叶斯来进行模型的训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入scikit-learn中的朴素贝叶斯</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> naive_bayes</span><br><span class="line"><span class="comment">#创建一个多项式朴素贝叶斯分类器</span></span><br><span class="line">clf = naive_bayes.MultinomialNB()</span><br><span class="line"><span class="comment">#使用训练集训练模型</span></span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#检查一下模型在验证集中的准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;模型在验证集中的准确率为：%.2f&#x27;</span>%(clf.score(X_test, y_test)))</span><br></pre></td></tr></table></figure>

<pre><code>模型在验证集中的准确率为：0.86
</code></pre>
<p>结果分析:可以看到多项式朴素贝叶斯模型在验证集中的得分达到了86%</p>
<p>具体来说,对于一条新的股评数据,我们就可以使用这个训练好的模型来进行预测,并给出交易信号.</p>
<p>下面我们随机抽取一条股评数据来进行实验</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#我们抽取数据集中序号为5127的数据来看一下</span></span><br><span class="line">df.iloc[<span class="number">5127</span>]</span><br></pre></td></tr></table></figure>




<pre><code>text        周二 跌停
polarity        0
Name: 5127, dtype: object
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用模型对矩阵中序号为5127的数据作出预测</span></span><br><span class="line">predict = clf.predict(X[<span class="number">5127</span>])[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#如果预测值为1</span></span><br><span class="line"><span class="keyword">if</span> predict == <span class="number">1</span>:</span><br><span class="line">    <span class="comment">#给出买入建议</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;快点买入&#x27;</span>)</span><br><span class="line"><span class="comment">#否则给出卖出建议</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;赶快清仓&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>赶快清仓
</code></pre>
<h1 id="第13章-深度学习来了"><a href="#第13章-深度学习来了" class="headerlink" title="第13章 深度学习来了"></a>第13章 深度学习来了</h1><h2 id="13-1-开始研究前的准备"><a href="#13-1-开始研究前的准备" class="headerlink" title="13.1 开始研究前的准备"></a>13.1 开始研究前的准备</h2><h3 id="13-1-1-翻翻工具箱-看看有什么"><a href="#13-1-1-翻翻工具箱-看看有什么" class="headerlink" title="13.1.1 翻翻工具箱,看看有什么"></a>13.1.1 翻翻工具箱,看看有什么</h3><p>TensorFlow是一个开源软件库,可以用于各种感知和语言理解任务的机器学习(做文本分类也不在话下)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先来看看平台是否提供了tensorflw</span></span><br><span class="line">!pip show tensorflow</span><br></pre></td></tr></table></figure>

<pre><code>Name: tensorflow
Version: 1.12.2
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /opt/conda/lib/python3.6/site-packages
Requires: protobuf, absl-py, gast, grpcio, keras-preprocessing, astor, keras-applications, termcolor, wheel, numpy, six, tensorboard
Required-by: 
</code></pre>
<p>Keras是一个用python编写的开源神经网络库</p>
<p>基于Tensor Flow等深度学习框架,Keras才可以用来构建神经网络. Keras是一个接口,而非独立的机器学习框架, 可以提供更高级别,更直观的抽象集. 无论使用何种计算后端, 用户都可以通过Keras轻松地开发深度学习模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果有keras就更好了</span></span><br><span class="line">!pip show keras</span><br></pre></td></tr></table></figure>

<pre><code>Name: Keras
Version: 2.2.4
Summary: Deep Learning for humans
Home-page: https://github.com/keras-team/keras
Author: Francois Chollet
Author-email: francois.chollet@gmail.com
License: MIT
Location: /opt/conda/lib/python3.6/site-packages
Requires: keras-applications, six, pyyaml, keras-preprocessing, h5py, numpy, scipy
Required-by: 
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入keras，看看在用什么做后端</span></span><br><span class="line"><span class="keyword">import</span> keras</span><br></pre></td></tr></table></figure>

<pre><code>Using TensorFlow backend.
</code></pre>
<h3 id="13-1-2-为神经网络准备数据"><a href="#13-1-2-为神经网络准备数据" class="headerlink" title="13.1.2 为神经网络准备数据"></a>13.1.2 为神经网络准备数据</h3><p>不管什么样的算法, 我们用算法来完成的任务不外乎分类,回归等.  神经网络也不例外(GAN对抗神经网络另当别论), 也可以用来分类和回归. 对感知类任务,神经网络的优势是非常明显的</p>
<p>在第12章中,我们所做的股评文本情感分析任务也属于一种感知类任务. 既然这样,我们就复用第12章中的数据,用神经网络来进行情感分类,看看效果如何</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入要用到的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment">#这次我们使用keras内置的tokenizer来处理文本数据</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="comment">#导入一个用来填充序列的工具</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="comment">#导入全连接层和Dropout层</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"><span class="comment">#导入model类中的Sequential</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这个单元格中的内容就是在第12章中用过的</span></span><br><span class="line"><span class="comment">#载入数据并添加极性标签</span></span><br><span class="line"><span class="comment">#并合成一个DataFrame的代码</span></span><br><span class="line"><span class="comment">#本章中就不逐行注释了</span></span><br><span class="line">pos_corpus = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;positive.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> f:</span><br><span class="line">        pos_corpus.append(sent.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>))</span><br><span class="line">neg_corpus = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;negtive.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> f:</span><br><span class="line">        neg_corpus.append(sent.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>))</span><br><span class="line">pos_df = pd.DataFrame(pos_corpus, columns=[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">pos_df[<span class="string">&#x27;polarity&#x27;</span>] = <span class="number">1</span></span><br><span class="line">neg_df = pd.DataFrame(neg_corpus, columns=[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">neg_df[<span class="string">&#x27;polarity&#x27;</span>] = <span class="number">0</span></span><br><span class="line">df = pd.concat([pos_df, neg_df]).reset_index(drop = <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#检查一下DataFrame的信息</span></span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 9214 entries, 0 to 9213
Data columns (total 2 columns):
text        9214 non-null object
polarity    9214 non-null int64
dtypes: int64(1), object(1)
memory usage: 144.0+ KB
</code></pre>
<p>可以看到,现在的数据集中有9214条记录,且有两列,这说明我们完成了数据的载入,打标及合并的工作</p>
<h2 id="13-2-使用Keras对文本进行预处理"><a href="#13-2-使用Keras对文本进行预处理" class="headerlink" title="13.2 使用Keras对文本进行预处理"></a>13.2 使用Keras对文本进行预处理</h2><p>在第12章中,要想用文本数据来训练模型,要先对文本数据进行处理,将它们转化为向量.当时我们使用的工具是scikit-learn中的CountVectorizer和TfidVectorizer</p>
<p>这两个工具是比较好用的,在本章中,我们还要学习一个新的工具_Keras内置的文本预处理工具</p>
<h3 id="13-2-1-使用Tokenizer提取特征"><a href="#13-2-1-使用Tokenizer提取特征" class="headerlink" title="13.2.1 使用Tokenizer提取特征"></a>13.2.1 使用Tokenizer提取特征</h3><p>在Keras中,文本预处理模块processing.text中的Tokenizer类能够做的事情和CountVetorizer是基本相同的–把文本转化为向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先还是将文本作为样本特征</span></span><br><span class="line">X = df[<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line"><span class="comment">#极性标签作为目标</span></span><br><span class="line">y = df[<span class="string">&#x27;polarity&#x27;</span>].astype(<span class="string">&#x27;int&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>&#39;买入 长期 持有 沃森 生物 19条 简短 想法&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里使用keras中的tokenizer来进行向量的转化</span></span><br><span class="line"><span class="comment">#filter参数可以就使用下面这行代码中的</span></span><br><span class="line"><span class="comment">#这样一般的标点符号和特殊字符就会被过滤出去</span></span><br><span class="line">tokenizer = Tokenizer(filters = <span class="string">&#x27;!&quot;#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`&#123;|&#125;~\t\n&#x27;</span>,</span><br><span class="line">                     lower = <span class="literal">True</span>, split=<span class="string">&quot; &quot;</span>)</span><br><span class="line"><span class="comment">#用tokenizer拟合文本数据</span></span><br><span class="line">tokenizer.fit_on_texts(X)</span><br><span class="line"><span class="comment">#文本特征存储在word_index中</span></span><br><span class="line">vocab = tokenizer.word_index</span><br><span class="line"><span class="comment">#可以检查一下特征的数量</span></span><br><span class="line"><span class="built_in">len</span>(vocab)</span><br></pre></td></tr></table></figure>




<pre><code>15644
</code></pre>
<p>Tokenizer是Keras内置的文本数据预处理工具,它的作用也是将文本转化为向量. 其原理其实和scikit-learn中的CountVectorizer的原理非常接近, 即通过每个词在文档中出现的次数来生成一个特征字典, 再根据特征字典将每条文本中出现的词转化为数字. Tokenizer生成的特征字典就存储在word_index中.我们可以看到,该字典中存储了15644个特征</p>
<p>如果想查看word_index中存储的字典是什么样子的,可以使用下面的代码来查看</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果大家好奇的话，可以查看一下前几个特征</span></span><br><span class="line">slice_dict = &#123;k: vocab[k] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">list</span>(vocab.keys())[<span class="number">0</span>:<span class="number">10</span>]&#125;</span><br><span class="line">slice_dict</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;不&#39;: 1,
 &#39;今天&#39;: 2,
 &#39;大&#39;: 3,
 &#39;涨停&#39;: 4,
 &#39;明天&#39;: 5,
 &#39;跌&#39;: 6,
 &#39;大盘&#39;: 7,
 &#39;都&#39;: 8,
 &#39;涨&#39;: 9,
 &#39;股&#39;: 10&#125;
</code></pre>
<p>这里我们从word_index中取出来前10个键, 可以看到, 第一个特征是”不”, 对应的是1….</p>
<p>这个字典将会被用来将文本转化为向量</p>
<h3 id="13-2-2-将文本转化为序列"><a href="#13-2-2-将文本转化为序列" class="headerlink" title="13.2.2 将文本转化为序列"></a>13.2.2 将文本转化为序列</h3><p>在13.2.1节中,我们使用Tokenizer中fit_on_texts方法提取出了文本数据中的特征.</p>
<p>fit_on_texts方法的作用和scikit-learn中CountVectorizer的fit方法的作用是相同的. 与CountVectorizer的transform方法对应的是texts_to_sequences方法.</p>
<p>texts_to_sequences方法的作用是把原始的文本转为序列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里导入scikit-learn的数据集拆分工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment">#将数据集拆分为训练集和验证集</span></span><br><span class="line">X_train, X_test, y_train, y_test =\</span><br><span class="line">train_test_split(X, y, random_state = <span class="number">30</span>)</span><br><span class="line"><span class="comment">#使用texts_to_sequences就可以把文本转化为序列</span></span><br><span class="line"><span class="comment">#这个序列可以看成是数组</span></span><br><span class="line">X_train_ids = tokenizer.texts_to_sequences(X_train)</span><br></pre></td></tr></table></figure>

<p>在运行这个代码后,我们就完成了将训练集中的文本转化为序列的工作了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#和原始的训练集对比一下</span></span><br><span class="line"><span class="comment">#大家就明白texts_to_sequances的作用</span></span><br><span class="line">X_train[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>3467    目前 走势 良好 继续 持股 观望
8296       伊利 行情 会 不会 一日游
6357        现在 价位 盈利 真 不信
3729    不要 后知后觉 尾盘 大涨 酷 酷
9196    收市 前仓底 应该 呵呵 继续 跌
Name: text, dtype: object
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#检查转化后的训练集</span></span><br><span class="line">X_train_ids[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>[[110, 70, 1066, 18, 102, 403],
 [1812, 48, 16, 300, 14683],
 [59, 753, 409, 106, 2925],
 [86, 9892, 51, 165, 857, 857],
 [2461, 15632, 99, 314, 18, 6]]
</code></pre>
<p>结果分析:text_to_sequences方法是根据word_index中存储的特征字典, 将每条数据中的文本转化成了对应的数字.</p>
<p>例如,第一条中的”目前”转化为110, “走势”转化成70, “良好”转化成1066等. 这样我们就对原始的数据完成了从文本到序列的转化</p>
<h3 id="13-2-3-填充序列与转化矩阵"><a href="#13-2-3-填充序列与转化矩阵" class="headerlink" title="13.2.3 填充序列与转化矩阵"></a>13.2.3 填充序列与转化矩阵</h3><p>我们发现一个现象,在所给的5个样本中, 有的样本有6个特征值,如第一个样本; 而有的样本有5个特征值,如第二个样本.</p>
<p>也就是说,数据集的样本存在特征数量不一致的问题.这样的样本无法用于训练模型. 因此我们还需要把样本的数量统一才行. 下面我们介绍第一种方法—<strong>填充序列</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果要让所有样本向量化后的特征数量一致</span></span><br><span class="line"><span class="comment">#就要用到填充序列的方法，pad_sequences</span></span><br><span class="line"><span class="comment">#例如我们指定maxlen为64，也就是会让keras保留出现次数最多的64个词</span></span><br><span class="line"><span class="comment">#作为特征</span></span><br><span class="line">X_train_padded = pad_sequences(X_train_ids,maxlen = <span class="number">64</span>)</span><br><span class="line"><span class="comment">#检查一下填充后的序列</span></span><br><span class="line">X_train_padded[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 110, 70, 1066, 18, 102,
        403],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1812, 48, 16, 300,
        14683],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 753, 409, 106,
        2925],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 86, 9892, 51, 165, 857,
        857],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2461, 15632, 99, 314,
        18, 6]], dtype=int32)
</code></pre>
<p>结果分析:原本特征数量不同的样本,在使用pad_sequences方法进行填充后,特征数量变得统一了—-特征数量都是64个</p>
<p>转化成了张量,能够用来进行模拟的训练</p>
<p>除了使用pad_sequences实现这样的效果外,我们还可以用tokenizer中的sequences_to_matrix将数据转化成矩阵matrix</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#当然，我们还可以使用sequences_to_matrix来保留全部的特征</span></span><br><span class="line">X_train_matrix = tokenizer.sequences_to_matrix(X_train_ids, mode=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line"><span class="comment">#可以检查一下转化为matrix的结果</span></span><br><span class="line">X_train_matrix[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#转化成matrix后的特征数量</span></span><br><span class="line"><span class="built_in">len</span>(X_train_matrix[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>




<pre><code>15645
</code></pre>
<p>结果分析:在使用sequences_to_matrix方法之后,样本的特征数量变成了15645个,而且特征是以one-hot二进制形式表现的.<br>例如,某个文本中有”不”这个词,则”不”对应的特征值为1,否则为0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把验证集转化为序列</span></span><br><span class="line">X_test_ids = tokenizer.texts_to_sequences(X_test)</span><br><span class="line"><span class="comment">#并且进行填充</span></span><br><span class="line">X_test_padded = pad_sequences(X_test_ids, maxlen = <span class="number">64</span>)</span><br><span class="line"><span class="comment">#检查结果</span></span><br><span class="line">X_test_padded[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 276, 60, 229, 2951, 38, 1,
        786, 478],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 86, 3347, 959, 5,
        462],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 110, 10369, 670,
        10370, 10371, 45],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 265, 121, 1176,
        3619, 9],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 229, 357, 92, 6, 470, 294, 215,
        1917, 80, 944]], dtype=int32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把验证集转化为矩阵</span></span><br><span class="line">X_test_matrix = tokenizer.sequences_to_matrix(X_test_ids, mode=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">X_test_matrix[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([0.0, 1.0, 0.0, ..., 0.0, 0.0, 0.0])
</code></pre>
<h2 id="13-3-使用Keras构建简单神经网络"><a href="#13-3-使用Keras构建简单神经网络" class="headerlink" title="13.3 使用Keras构建简单神经网络"></a>13.3 使用Keras构建简单神经网络</h2><p>实际上,神经网络并不是特指某一种算法,而是一类算法的统称, 包括卷积神经网络,循环神经网络,对抗神经网络等. </p>
<p>这里我们就从最简单的多层感知机(MLP)开始介绍神经网络的使用方法</p>
<h3 id="13-3-1-先动手”撸”一个多层感知机"><a href="#13-3-1-先动手”撸”一个多层感知机" class="headerlink" title="13.3.1 先动手”撸”一个多层感知机"></a>13.3.1 先动手”撸”一个多层感知机</h3><p>在Keras中,实现神经网络最简单的方法是,使用Sequential模块来搭建模型,这种方法就像”搭积木一样”,把各个层堆叠在一起,简单直观</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面就可以开始模型的搭建了</span></span><br><span class="line"><span class="comment">#这里我们使用Sequential模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment">#首先向模型添加一个全连接层</span></span><br><span class="line"><span class="comment">#包含16个隐藏单元，激活函数选择relu</span></span><br><span class="line"><span class="comment">#input_shape选择样本特征的数量</span></span><br><span class="line">model.add(Dense(<span class="number">16</span>, input_shape = (<span class="built_in">len</span>(vocab)+<span class="number">1</span>,), activation = <span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment">#再添加一个dropout层，来降低过拟合的风险</span></span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"><span class="comment">#最后一个全连接层，激活函数为sigmoid</span></span><br><span class="line"><span class="comment">#输出的结果是样本属于标签“1”的可能性</span></span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"><span class="comment">#几个隐藏层堆叠好，就可以对模型进行编译</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">             optimizer = <span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">             metrics = [<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment">#查看模型的概况</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 16)                250336    
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 17        
=================================================================
Total params: 250,353
Trainable params: 250,353
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>结果分析:我们使用Keras搭建了一个非常简单的模型.使用Sequential搭建模型的好处是,我们要用到的各个隐藏层被堆叠到了一起</p>
<p>例如,第一层是一个全连接层(Dense),它的节点设置为16,所以输出的数据形态也是16</p>
<p>第二层是一个Dropout层,它输出的数据形态也是16</p>
<p>第三层是用于输出分类结果的,它输出的数据形态是1,也就是某个样本属于分类1的概率</p>
<h3 id="13-3-2-念叨一下多层感知机的原理"><a href="#13-3-2-念叨一下多层感知机的原理" class="headerlink" title="13.3.2 念叨一下多层感知机的原理"></a>13.3.2 念叨一下多层感知机的原理</h3><p>要理解多层感知机(全连接层神经网络), 我们可以先回忆一下曾经学过的线性模型</p>
<p>一般公式是:</p>
<p>y^&#x3D;w[0]·x[0]+w[1]·x[1]+….+w[p]·x[p]+b</p>
<p>用图形表示线性模型如图<br><img src="%E4%B8%8B%E8%BD%BD%20(15).png" alt="下载 (15)"></p>
<p>在上图中,x[0]~x[3]表示样本的特征. 每一个特征都有一个对应的权重. 通过所给公式,我们可以计算出一个输出的估计值y^(表示目标的估计值), 而模型要做的工作, 就是让这个估值和真实值的差尽可能小</p>
<p>在多层感知机中,模型会变成如图13.11所示的样子<br><img src="%E4%B8%8B%E8%BD%BD%20(16).png" alt="下载 (16)"></p>
<p>可以看到,与图13.10不同的是,多层感知机多了一个隐藏层,而在这个隐藏层包含3个节点.每个节点都会对特征进行一次线性模型的计算.模型最后会对各个节点的计算结果进行计算,以便得到最终的结果</p>
<h3 id="13-3-3-再来说说激活函数"><a href="#13-3-3-再来说说激活函数" class="headerlink" title="13.3.3 再来说说激活函数"></a>13.3.3 再来说说激活函数</h3><p>到这里,大家可能会问,既然在多层感知机的隐藏层中,每个节点都会进行一次线性模型的计算,那么最后得到的结果与单纯使用线性模型又有什么区别呢? 为了解决这个问题, 我们还需要引入激活函数</p>
<p>例如,在13.3.1节中,我们构建的模型在第一个隐藏层里用到的激活函数是relu(线性整流函数),它的作用是把隐藏节点计算的结果变成如图13.12所示的样子</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(17).png" alt="下载 (17)"></p>
<p>从上图可以看出,relu函数其实就是把所有的负值都归零了,如果想要用公式来表达的话,可写成</p>
<p>f(x)&#x3D;max(0,x)</p>
<p>如果计算结果大于0,则这个结果保持不变;如果计算结果小于0,则结果取0. 这样一来,每个隐藏节点的计算结果就与原始线性模型计算的结果不一样了. 用术语来说就是,模型增加了非线性</p>
<p>模型在最后一个隐藏层中使用了激活函数sigmoid,这又为何? 这是因为,通过模型计算出来的数值的范围可能是-100<del>+100(也可能是-1000</del>+1000),但我们想要模型告诉我们这个样本究竟是属于分类0(也就是负面情绪)还是分类1(正面情绪),所以模型应该给我们返回一个0~1之间的数—–这个数字越大,样本就越可能属于分类1;反之,样本越可能属于分类0</p>
<p>正好sigmoid函数提供了这样的功能,它会把计算结果变成如图13.13所示的样子</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(18).png" alt="下载 (18)"></p>
<p>从13.13中可以看到,sigmoid函数会将模型计算的结果”压缩”到0~1.如果使用公式来表达的话,则公式为</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(19).png" alt="下载 (19)"></p>
<p>这就是我们在最后一个隐藏层中使用sigmoid函数的原因</p>
<p><strong>注意:实际上,激活函数除了relu和sigmoid外,还有tanh,这里我们暂不介绍</strong></p>
<h3 id="13-3-4-Dropout层又是干嘛的"><a href="#13-3-4-Dropout层又是干嘛的" class="headerlink" title="13.3.4 Dropout层又是干嘛的"></a>13.3.4 Dropout层又是干嘛的</h3><p>我们在两个全连接层中还插入了一个Dropout层</p>
<p>在机器学习领域中,<strong>过拟合</strong>是一种需要格外注意的问题,也就是说,模型在<strong>训练集</strong>中获得了<strong>比较高</strong>的预测性能,但是在<strong>验证集或者测试集</strong>中的表现却比较<strong>差</strong>,解决模型过拟合问题的方法有很多,<strong>添加Dropout层</strong>就是常用的方法之一</p>
<p>Dropout其实是一种<strong>正则化</strong>的方法. 它的工作原理其实很好理解,就是把<strong>前一个隐藏层</strong>计算出的结果**”扔掉”<strong>一部分(<strong>把它们变成0</strong>). 例如,我们在模型中添加的Dropout层参数为0.5,也就是说它会将前一层的计算结果</strong>“扔掉”50%<strong>, 这个方法听起来有点诡异,不过它的本质是向某一层的计算结果中添加</strong>噪声数据**,以便于打破数据中隐藏的一些偶然模式, 并且降低过拟合的风险</p>
<p>当然, 除了Dropout正则化之外,也可以像岭回归或套索回归那样, 使用L1正则化或L2正则化—-通过<strong>直接调整特征前面的权重</strong>来降低过拟合.我们还可以通过<strong>减小神经网络的规模</strong>来避免过拟合.例如,第一个隐藏层包含了16个隐藏单元,如果隐藏单元减少到8个,则过拟合的风险就会降低了(当然可能会增加欠拟合的风险).因此,使用这种方法,我们就需要慢慢调节神经网路的结构,以便得到最佳的效果</p>
<h3 id="13-3-5-训练一下-看看效果如何"><a href="#13-3-5-训练一下-看看效果如何" class="headerlink" title="13.3.5 训练一下,看看效果如何"></a>13.3.5 训练一下,看看效果如何</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面就可以开始训练模型</span></span><br><span class="line"><span class="comment">#使用128个样本组成的小批量</span></span><br><span class="line"><span class="comment">#进行10个轮次的训练</span></span><br><span class="line"><span class="comment">#指定转化为矩阵的验证集作为验证数据</span></span><br><span class="line">hist = model.fit(X_train_matrix, y_train,</span><br><span class="line">              batch_size=<span class="number">128</span>,</span><br><span class="line">              epochs=<span class="number">10</span>,</span><br><span class="line">              validation_data=(X_test_matrix, y_test))</span><br><span class="line"><span class="comment">#找到模型训练过程中最高的准确率</span></span><br><span class="line">best_acc = <span class="built_in">max</span>(hist.history[<span class="string">&#x27;val_acc&#x27;</span>])</span><br><span class="line"><span class="comment">#检查一下最高准确率是多少</span></span><br><span class="line">best_acc</span><br></pre></td></tr></table></figure>

<pre><code>Train on 6910 samples, validate on 2304 samples
Epoch 1/10
6910/6910 [==============================] - 3s 482us/step - loss: 0.6662 - acc: 0.6922 - val_loss: 0.6213 - val_acc: 0.8394
Epoch 2/10
6910/6910 [==============================] - 3s 390us/step - loss: 0.5620 - acc: 0.8418 - val_loss: 0.5255 - val_acc: 0.8681
Epoch 3/10
6910/6910 [==============================] - 3s 383us/step - loss: 0.4606 - acc: 0.8829 - val_loss: 0.4510 - val_acc: 0.8776
Epoch 4/10
6910/6910 [==============================] - 3s 383us/step - loss: 0.3807 - acc: 0.9027 - val_loss: 0.3997 - val_acc: 0.8828
Epoch 5/10
6910/6910 [==============================] - 3s 375us/step - loss: 0.3248 - acc: 0.9174 - val_loss: 0.3631 - val_acc: 0.8885
Epoch 6/10
6910/6910 [==============================] - 3s 370us/step - loss: 0.2820 - acc: 0.9320 - val_loss: 0.3383 - val_acc: 0.8906
Epoch 7/10
6910/6910 [==============================] - 3s 404us/step - loss: 0.2449 - acc: 0.9407 - val_loss: 0.3195 - val_acc: 0.8915
Epoch 8/10
6910/6910 [==============================] - 3s 383us/step - loss: 0.2206 - acc: 0.9440 - val_loss: 0.3064 - val_acc: 0.8924
Epoch 9/10
6910/6910 [==============================] - 3s 400us/step - loss: 0.1952 - acc: 0.9518 - val_loss: 0.2969 - val_acc: 0.8919
Epoch 10/10
6910/6910 [==============================] - 3s 377us/step - loss: 0.1764 - acc: 0.9606 - val_loss: 0.2896 - val_acc: 0.8932





0.8932291666666666
</code></pre>
<p>结果分析:在上面的代码中,我们指定模型一共训练10个轮次,模型包含了10次训练结果,模型在验证集中的准确率保存在val_acc中,第一轮次训练结束后,模型的准确率只有83.94%,随后一路上升,在整个训练过程中,最高的准确率为89.32%,也就是模型经过十个轮次训练后的准确值.</p>
<p>这个准确率超过了第12章中朴素贝叶斯模型的准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#当然，也可以使用evaluate方法对模型评估</span></span><br><span class="line">model.evaluate(X_test_matrix, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>2304/2304 [==============================] - 0s 174us/step





[0.2896178737282753, 0.8932291666666666]
</code></pre>
<p>当然,我们也可以使用模型尝试对某一样本进行<strong>预测</strong>,看看是否准确</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用模型进行预测的方法和scikit-learn也比较接近</span></span><br><span class="line"><span class="comment">#我们可以随意挑一个来试试</span></span><br><span class="line">model.predict([X_test_matrix[:<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>




<pre><code>array([[0.6906114]], dtype=float32)
</code></pre>
<p>结果分析:经过sigmoid函数的处理,模型对验证集中第一个样本的预测结果大约是0.6906,也就是说,这个样本有69.06%的概率属于分类1(正面情绪)</p>
<p>为了验证模型的预测准确结果是否正确,我们来检查一下这个样本的极性标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#和真值做个对比，看看模型预测是否正确</span></span><br><span class="line">y_test[:<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>3596    1
Name: polarity, dtype: int64
</code></pre>
<p>结果分析:这条样本在原数据集中的序号是3596,它的极性标签是1,与模型的预测结果是一致的,因此,针对这个样本,模型的预测结果是正确的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入几个可以让模型性能达到最优时停止训练的工具</span></span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> Callback, EarlyStopping, ModelCheckpoint</span><br></pre></td></tr></table></figure>

<h1 id="第14章-再进一步-CNN和LSTM"><a href="#第14章-再进一步-CNN和LSTM" class="headerlink" title="第14章 再进一步-CNN和LSTM"></a>第14章 再进一步-CNN和LSTM</h1><h2 id="14-1-动手先”撸”一个卷积神经网络"><a href="#14-1-动手先”撸”一个卷积神经网络" class="headerlink" title="14.1 动手先”撸”一个卷积神经网络"></a>14.1 动手先”撸”一个卷积神经网络</h2><h3 id="14-1-1-准备好库和数据集"><a href="#14-1-1-准备好库和数据集" class="headerlink" title="14.1.1 准备好库和数据集"></a>14.1.1 准备好库和数据集</h3><p>在本章中,我们还是使用Keras来搭建卷积神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先导入必要的库</span></span><br><span class="line"><span class="comment">#有些库读者朋友可能不知道是做什么的</span></span><br><span class="line"><span class="comment">#没有关系，后面我们在用到的时候，会进行讲解</span></span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding, Dense, Activation, Input</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Convolution1D, Flatten, Dropout, MaxPool1D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> concatenate</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, Sequential</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> Callback, EarlyStopping, ModelCheckpoint</span><br></pre></td></tr></table></figure>

<pre><code>Using TensorFlow backend.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这个单元格中的内容就是在第12、13章中用过的</span></span><br><span class="line"><span class="comment">#载入数据并添加极性标签</span></span><br><span class="line"><span class="comment">#并合成一个DataFrame的代码</span></span><br><span class="line"><span class="comment">#本章中就不逐行注释了</span></span><br><span class="line">pos_corpus = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;positive.txt&#x27;</span>,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> f:</span><br><span class="line">        pos_corpus.append(sent.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>))</span><br><span class="line">neg_corpus = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;negtive.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> f:</span><br><span class="line">        neg_corpus.append(sent.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>))</span><br><span class="line">pos_df = pd.DataFrame(pos_corpus, columns=[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">pos_df[<span class="string">&#x27;polarity&#x27;</span>] = <span class="number">1</span></span><br><span class="line">neg_df = pd.DataFrame(neg_corpus, columns=[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">neg_df[<span class="string">&#x27;polarity&#x27;</span>] = <span class="number">0</span></span><br><span class="line">df = pd.concat([pos_df, neg_df]).reset_index(drop = <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#检查一下DataFrame的信息</span></span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 9214 entries, 0 to 9213
Data columns (total 2 columns):
text        9214 non-null object
polarity    9214 non-null int64
dtypes: int64(1), object(1)
memory usage: 144.0+ KB
</code></pre>
<h3 id="14-1-2-处理数据与搭建模型"><a href="#14-1-2-处理数据与搭建模型" class="headerlink" title="14.1.2 处理数据与搭建模型"></a>14.1.2 处理数据与搭建模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#分配好数据集的特征和目标</span></span><br><span class="line">X = df[<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line">y = df[<span class="string">&#x27;polarity&#x27;</span>].astype(<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line"><span class="comment">#使用tokenizer对数据进行处理</span></span><br><span class="line"><span class="comment">#这个在第13章中，也是使用过的了</span></span><br><span class="line">tokenizer = Tokenizer(filters = <span class="string">&#x27;!&quot;#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`&#123;|&#125;~\t\n&#x27;</span>,</span><br><span class="line">                     lower = <span class="literal">True</span>, split=<span class="string">&quot; &quot;</span>)</span><br><span class="line"><span class="comment">#用tokenizer拟合文本数据</span></span><br><span class="line">tokenizer.fit_on_texts(X)</span><br><span class="line"><span class="comment">#文本特征存储在word_index中</span></span><br><span class="line">vocab = tokenizer.word_index</span><br><span class="line"><span class="comment">#拆分数据</span></span><br><span class="line">X_train, X_test, y_train, y_test =\</span><br><span class="line">train_test_split(X, y, random_state = <span class="number">30</span>)</span><br><span class="line"><span class="comment">#这次我们使用填充序列来训练模型</span></span><br><span class="line"><span class="comment">#也就是用pad_sequences来进行处理</span></span><br><span class="line">X_train_word_ids = tokenizer.texts_to_sequences(X_train)</span><br><span class="line">X_test_word_ids = tokenizer.texts_to_sequences(X_test)</span><br><span class="line"><span class="comment">#将训练集和验证集都转化为填充序列</span></span><br><span class="line"><span class="comment">#为了节省时间，我们设置序列的最大长度为16</span></span><br><span class="line">X_train_padded_seqs = pad_sequences(X_train_word_ids, maxlen=<span class="number">16</span>)</span><br><span class="line">X_test_padded_seqs = pad_sequences(X_test_word_ids, maxlen=<span class="number">16</span>)</span><br></pre></td></tr></table></figure>

<p>运行代码后,训练集和验证集就转化成了已经填充好的序列.这里我们设置序列的最大长度为16,这样做的目的主要是节省计算资源,让模型的训练时间更短</p>
<p>接下来就是搭建神经网络的部分了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面我们就开始搭建卷积神经网络</span></span><br><span class="line"><span class="comment">#首先是建立一个输入，因为填充序列的长度是16</span></span><br><span class="line"><span class="comment">#所以Input的形态也要指定为16，数据类型为64位浮点数</span></span><br><span class="line">main_input = Input(shape = (<span class="number">16</span>,),dtype = <span class="string">&#x27;float64&#x27;</span>)</span><br><span class="line"><span class="comment">#这里我们引入一个嵌入层，对输入的序列进行处理</span></span><br><span class="line"><span class="comment"># 我们设置了三个参数，分别是input_dim, output_dim, input_length</span></span><br><span class="line"><span class="comment"># input_dim：输入的词汇表的大小，也就是我们使用Tokenizer拟合文本数据后生成的词汇表的长度+1，</span></span><br><span class="line"><span class="comment">#所以是len(vocab)+1</span></span><br><span class="line"><span class="comment"># output_dim：嵌入层输出的词向量的维度。这里为了进行演示，我们把output_dim设置得比较小，即8</span></span><br><span class="line"><span class="comment"># input_length：输入的序列长度。因为我们再使用pad_sequences这一步指定了填充序列的长度是16，</span></span><br><span class="line"><span class="comment"># embedding层的input_length也要保持一致，因此这里也要设置为16</span></span><br><span class="line">embedder = Embedding(<span class="built_in">len</span>(vocab)+<span class="number">1</span>, <span class="number">8</span>, input_length = <span class="number">16</span>)</span><br><span class="line">embed = embedder(main_input)</span><br><span class="line"><span class="comment">#先创建一个1维卷积神经层</span></span><br><span class="line"><span class="comment"># 参数说明：</span></span><br><span class="line"><span class="comment"># filter参数：卷积核的数量，对应的是输出的维度。这里我们将其设置为16</span></span><br><span class="line"><span class="comment"># kernel_size参数：卷积核的空域或时域窗的长度。在第1个卷积层中，我们将其设置为3</span></span><br><span class="line"><span class="comment"># padding参数：补0策略。这里我们将其设置为same，表示保留边界处的卷积结果，这样做可以保证输入和输出的</span></span><br><span class="line"><span class="comment"># 维度是一致的（如果将其设置为valid,则表示只进行有效的卷积，对边界处的卷积结果不进行处理）</span></span><br><span class="line"><span class="comment"># strides参数：卷积的步长，通俗地讲，就是每“卷”一下的长度是多少。这里我们讲其设置为1</span></span><br><span class="line"><span class="comment"># activation参数：激活函数，这里设置为relu</span></span><br><span class="line">cnn1 = Convolution1D(<span class="number">16</span>, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>, strides=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(embed)</span><br><span class="line"><span class="comment">#用一个池化层与cnn1堆叠</span></span><br><span class="line"><span class="comment"># 参数说明：</span></span><br><span class="line"><span class="comment"># 这里面，我们设置pool_size参数为8，也就是池化窗口的大小，通俗地讲，在卷积层输出的序列中，最大</span></span><br><span class="line"><span class="comment"># 池化层会在每8个元素中寻找最大值</span></span><br><span class="line">cnn1 = MaxPool1D(pool_size=<span class="number">8</span>)(cnn1)</span><br><span class="line"><span class="comment">#创建第二个1维卷积层</span></span><br><span class="line">cnn2 = Convolution1D(<span class="number">16</span>, <span class="number">4</span>, padding=<span class="string">&#x27;same&#x27;</span>, strides=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(embed)</span><br><span class="line"><span class="comment">#同样与池化层堆叠</span></span><br><span class="line">cnn2 = MaxPool1D(pool_size=<span class="number">8</span>)(cnn2)</span><br><span class="line"><span class="comment">#第3个1维卷积层</span></span><br><span class="line">cnn3 = Convolution1D(<span class="number">16</span>, <span class="number">5</span>, padding=<span class="string">&#x27;same&#x27;</span>, strides=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(embed)</span><br><span class="line"><span class="comment">#与池化层堆叠</span></span><br><span class="line">cnn3 = MaxPool1D(pool_size=<span class="number">8</span>)(cnn3)</span><br><span class="line"><span class="comment">#将3个卷积层进行连接，concatenate层的作用是把3个卷积层进行拼接</span></span><br><span class="line">cnn = concatenate([cnn1, cnn2, cnn3], axis=-<span class="number">1</span>)</span><br><span class="line"><span class="comment">#使用一个Flatten层，把输入从高维压缩到1维，用于从卷积层到全连接层的过渡</span></span><br><span class="line">flat = Flatten()(cnn)</span><br><span class="line"><span class="comment">#添加一个dropout层来进行正则化</span></span><br><span class="line">drop = Dropout(<span class="number">0.2</span>)(flat)</span><br><span class="line"><span class="comment">#最后是一个全连接层，用来输出模型结果</span></span><br><span class="line">main_output = Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)(drop)</span><br><span class="line"><span class="comment">#这次使用Model来搭建模型，输入和输出分别是最初的输入和全连接层给出的输出</span></span><br><span class="line">model = Model(inputs=main_input, outputs=main_output)</span><br><span class="line"><span class="comment">#最后对模型进行编译</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,optimizer=<span class="string">&#x27;adam&#x27;</span>,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment">#查看模型的概述</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 16)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 16, 8)        125160      input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 16, 16)       400         embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 16, 16)       528         embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 16, 16)       656         embedding_1[0][0]                
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 2, 16)        0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 2, 16)        0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 2, 16)        0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 2, 48)        0           max_pooling1d_1[0][0]            
                                                                 max_pooling1d_2[0][0]            
                                                                 max_pooling1d_3[0][0]            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 96)           0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 96)           0           flatten_1[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            97          dropout_1[0][0]                  
==================================================================================================
Total params: 126,841
Trainable params: 126,841
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre>
<p>结果分析：从结果可以看出，模型第一层是一个输入层（输入的数据是16列的填充序列），后面紧跟着一个嵌入层（Embedding），然后分别是3个1维卷积层和3个最大池化层，接着是Flatten层、Dropout层和用来输出结果的全连接层</p>
<h2 id="14-2-卷积神经网络模型详解"><a href="#14-2-卷积神经网络模型详解" class="headerlink" title="14.2 卷积神经网络模型详解"></a>14.2 卷积神经网络模型详解</h2><h3 id="14-2-1-嵌入层是干啥用的"><a href="#14-2-1-嵌入层是干啥用的" class="headerlink" title="14.2.1 嵌入层是干啥用的"></a>14.2.1 嵌入层是干啥用的</h3><p>说到模型中的<strong>嵌入层</strong>，就要说一下在自然语言处理领域的词嵌入（word embedding）的概念</p>
<p>我们已经知道，如果要使用<strong>文本数据</strong>来训练模型，就要先把文本转换为<strong>向量</strong>，在scikit-learn中，这项工作可以通过CountVectorzier和TfidfVectorizer来完成；在Keras中，这项工作可以通过Tokenizer来完成。这些方法可以在<strong>高维</strong>的词空间中表示文档。</p>
<p>我们可以让机器来评估<strong>文档的相似性</strong>，并创建特征来训练机器学习算法，对文档<strong>话题进行提取</strong>或对其中表达的<strong>情感进行分类</strong>。然而，这些向量忽略了<strong>某个单词的上下文</strong>，所以虽然包含相同单词的不同句子将由同一向量编码，但机器无法判断这些句子是否表达了同一个意思。</p>
<p>因此，这里我们需要一种新的方法——使用算法来学习<strong>单个语义单位（如单词或段落）</strong>的向量表示。这些向量是<strong>密集</strong>的而不是稀疏的，并且维度比使用前面两种方法得到的向量的维度<strong>要低很多</strong>。这种方法是在连续向量空间中为<strong>每个语义单元指定一个位置</strong>，因此该方法被成为<strong>词嵌入</strong>。词嵌入的结果是训练一个模型将<strong>某个单词与其上下文关联起来</strong>，这样做的好处是，如果某个词在两段不同文本中的用法不同，则其转化后的向量也不一样。</p>
<p>完成词嵌入的过程，有两种常用的方法：</p>
<p>（1）把<strong>嵌入层直接集成在模型中</strong>，也就是说，在完成分类模型训练的过程中，我们利用现有的数据集就完成了词嵌入的学习</p>
<p>（2）需要使用<strong>预训练词嵌入模型</strong>（Pre-trained word embedding）计算好词向量，再将其加载到神经网络中</p>
<p>那么到实践中，一般来讲，如果数据集中的<strong>样本不够多</strong>的话，那我们很难从已有数据集中获得效果良好的词嵌入，这样一来就要考虑使用预训练的词嵌入空间，并把向量加载到模型当中。<strong>需要注意的是，目前世界上并没有一个完美的预训练词嵌入模型能够解决所有的问题。要解决一些特定场景的问题，而非通用的问题的时候，每次单独进行词嵌入学习的效果会更好一些</strong></p>
<p>Keras中的嵌入层代码：</p>
<p>embedder &#x3D; Embedding(len(vocab)+1, 8, input_length &#x3D; 16)</p>
<p>注释已经在代码中体现</p>
<h3 id="14-2-2-卷积层是干啥用的"><a href="#14-2-2-卷积层是干啥用的" class="headerlink" title="14.2.2 卷积层是干啥用的"></a>14.2.2 卷积层是干啥用的</h3><p>在嵌入层之后，我们还创建了1维卷积层（Convolution1D）和最大池化层（MaxPool1D）</p>
<p>卷积二字代表的数学中的卷积运算，卷积就是通过函数$f$和函数$g$生成第三个函数的数学算子，表征函数$f$与$g$经过<strong>翻转和平移的重叠部分函数值乘积对重叠长度的积分</strong></p>
<p>离散形式：<br><img src="%E4%B8%8B%E8%BD%BD%20(20).png" alt="下载 (20)"></p>
<p>连续形式：<br><img src="%E4%B8%8B%E8%BD%BD%20(21).png" alt="下载 (21)"></p>
<p>在第13章，多层感知机神经网络模型主要使用的是全连接层。全连接层与卷积层的不同之处在于：全连接层学到的是<strong>全局模式</strong>，而卷积层学习到的是<strong>局部模式</strong>，拿图像识别中猫狗识别任务来举例子，全连接层看到的是一整只猫，但卷积层看到的是猫的耳朵、鼻子、眼睛等。也就是说，如果图片中的猫<strong>换了一个位置</strong>，那么全连接层就要<strong>重新学习</strong>，但卷积层仍然可以借助局部模式来判断图片中的动物是一只猫。</p>
<p>1维卷积层用于识别<strong>一个序列中的局部模式</strong>（也就是说，会在原序列中提取子序列，并学习其中的模式）<br><img src="%E4%B8%8B%E8%BD%BD%20(22).png" alt="下载 (22)"><br>1维卷积层从原始输入的特征（在本章中就是填充过的序列)中提取出序列段，然后将其与权重做点积，得到新的特征，并进行输出</p>
<p>Keras中创建卷积层的代码为：</p>
<p>cnn1 &#x3D; Convolution1D(16, 3, padding&#x3D;’same’, strides&#x3D;1, activation&#x3D;’relu’)(embed)</p>
<h3 id="14-2-3-最大池化层是干啥用的"><a href="#14-2-3-最大池化层是干啥用的" class="headerlink" title="14.2.3 最大池化层是干啥用的"></a>14.2.3 最大池化层是干啥用的</h3><p>在我们创建1维卷积层后，紧接着就会堆叠一个最大池化层（MaxPool1D）</p>
<p>我们先介绍最大池化运算——它是取<strong>局部接收域中值最大的点</strong>。下面用图像表示<br><img src="%E4%B8%8B%E8%BD%BD%20(23).png" alt="下载 (23)"><br>在左上角的四个格子中取最大值放入右边的格子，以此类推，重复这样的操作，我们只保留4x4矩阵中每个子区域的最大值，并输出一个2x2矩阵</p>
<p>上图展示的是一个2维最大池化层的工作原理，而1维最大池化层的工作原理与其近似，本质上也是对输入的1维数据进行<strong>下采样</strong>（subsample）,以便于降低1维输入的长度</p>
<p>在卷积神经网络中使用最大池化层的原因是：为了缩减模型的大小、节省计算资源的同时，<strong>降低过拟合的风险</strong>，同时，在卷积层中堆叠最大池化层，可以让卷积层观察的窗口更大，并引入空间过滤器的层级结构</p>
<p>MaxPool1D的用法</p>
<p>cnn1 &#x3D; MaxPool1D(pool_size&#x3D;8)(cnn1)</p>
<h3 id="14-2-4-训练模型看看效果"><a href="#14-2-4-训练模型看看效果" class="headerlink" title="14.2.4 训练模型看看效果"></a>14.2.4 训练模型看看效果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先设置early_stopping，</span></span><br><span class="line"><span class="comment">#这次选择监控的指标是验证集的准确率，</span></span><br><span class="line"><span class="comment">#在准确率连续下降5次后停止训练</span></span><br><span class="line">early_stopping = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, patience=<span class="number">5</span>)</span><br><span class="line"><span class="comment">#设置模型的检查点，用来保存最佳的模型参数</span></span><br><span class="line">model_checkpoint = ModelCheckpoint(<span class="string">&#x27;model-TextCNN.h5&#x27;</span>, save_best_only=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#下面就开模型的训练</span></span><br><span class="line"><span class="comment">#为了节约时间，还是将轮次设定为10</span></span><br><span class="line">hist = model.fit(X_train_padded_seqs, y_train, batch_size=<span class="number">128</span>, epochs=<span class="number">10</span>,</span><br><span class="line">                 validation_data=(X_test_padded_seqs, y_test),</span><br><span class="line">                 callbacks=[early_stopping, model_checkpoint])</span><br></pre></td></tr></table></figure>

<pre><code>Train on 6910 samples, validate on 2304 samples
Epoch 1/10
6910/6910 [==============================] - 2s 279us/step - loss: 0.6905 - acc: 0.5573 - val_loss: 0.6833 - val_acc: 0.6780
Epoch 2/10
6910/6910 [==============================] - 1s 159us/step - loss: 0.6520 - acc: 0.7965 - val_loss: 0.6079 - val_acc: 0.8333
Epoch 3/10
6910/6910 [==============================] - 1s 172us/step - loss: 0.4900 - acc: 0.9000 - val_loss: 0.4157 - val_acc: 0.8759
Epoch 4/10
6910/6910 [==============================] - 1s 151us/step - loss: 0.2862 - acc: 0.9339 - val_loss: 0.3117 - val_acc: 0.8880
Epoch 5/10
6910/6910 [==============================] - 1s 159us/step - loss: 0.1790 - acc: 0.9559 - val_loss: 0.2831 - val_acc: 0.8893
Epoch 6/10
6910/6910 [==============================] - 1s 181us/step - loss: 0.1221 - acc: 0.9693 - val_loss: 0.2789 - val_acc: 0.8859
Epoch 7/10
6910/6910 [==============================] - 1s 191us/step - loss: 0.0873 - acc: 0.9787 - val_loss: 0.2819 - val_acc: 0.8850
Epoch 8/10
6910/6910 [==============================] - 1s 204us/step - loss: 0.0627 - acc: 0.9864 - val_loss: 0.2922 - val_acc: 0.8815
Epoch 9/10
6910/6910 [==============================] - 1s 174us/step - loss: 0.0488 - acc: 0.9896 - val_loss: 0.3036 - val_acc: 0.8815
Epoch 10/10
6910/6910 [==============================] - 1s 185us/step - loss: 0.0382 - acc: 0.9925 - val_loss: 0.3144 - val_acc: 0.8785
</code></pre>
<p>结果分析：在本章中，我们降低了文本转化填充序列的长度（只有16），这样也可以提高模型的训练速度。</p>
<p>然而，与第13章中多层感知机的验证集准确率相比，卷积神经网络的准确率稍有下降，这时非常正常的，毕竟我们人为降低了训练集所包含的信息。如果想要对比两种神经网络的表现，把填充序列的maxlen设置为相同的数字，再进行实验即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(X_test_padded_seqs, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>2304/2304 [==============================] - 0s 71us/step





[0.31437859166827464, 0.8784722222222222]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用卷积神经网络模型对样本作出预测</span></span><br><span class="line">model.predict(X_test_padded_seqs[:<span class="number">1</span>])</span><br></pre></td></tr></table></figure>




<pre><code>array([[0.92676705]], dtype=float32)
</code></pre>
<p>结果分析：模型对样本做出的预测值是0.9916，也就是说，该样本数据极有可能属于分类1，即包含正面情绪的文本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_test[:<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>3596    1
Name: polarity, dtype: int64
</code></pre>
<p>预测正确</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#清除一下垃圾</span></span><br><span class="line">gc.collect()</span><br></pre></td></tr></table></figure>




<pre><code>70
</code></pre>
<h2 id="14-3-长短期记忆网络"><a href="#14-3-长短期记忆网络" class="headerlink" title="14.3 长短期记忆网络"></a>14.3 长短期记忆网络</h2><p>卷积神经网络和全连接神经网络都有一个共性——“无记忆性”，这两种神经网络模型不会考虑每个<strong>输入之间的关系</strong>，而循环神经网络就不同了，它会遍历输入的各个元素，并且保持它们之间的状态关系。长短期记忆网络（LSTM）就是循环神经网络的一种</p>
<h3 id="14-3-1-搭建一个简单的长短期记忆神经网络"><a href="#14-3-1-搭建一个简单的长短期记忆神经网络" class="headerlink" title="14.3.1 搭建一个简单的长短期记忆神经网络"></a>14.3.1 搭建一个简单的长短期记忆神经网络</h3><p>用Keras搭建一个简单的长短期记忆网络模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面来搭建长短期记忆网络</span></span><br><span class="line">lstm = Sequential()</span><br><span class="line"><span class="comment">#在网络中先添加一个Embedding层</span></span><br><span class="line">lstm.add(Embedding(<span class="built_in">len</span>(vocab)+<span class="number">1</span>, <span class="number">8</span>, weights=[np.zeros((<span class="built_in">len</span>(vocab) + <span class="number">1</span>, <span class="number">8</span>))], </span><br><span class="line">                   input_length=<span class="number">16</span>, trainable=<span class="literal">True</span>))</span><br><span class="line"><span class="comment">#添加长短期记忆网络</span></span><br><span class="line">lstm.add(LSTM(<span class="number">8</span>, dropout=<span class="number">0.5</span>, recurrent_dropout=<span class="number">0.2</span>))</span><br><span class="line"><span class="comment">#添加全连接层</span></span><br><span class="line">lstm.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"><span class="comment">#编译模型</span></span><br><span class="line">lstm.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment">#看产模型的概况</span></span><br><span class="line">lstm.summary()</span><br></pre></td></tr></table></figure>

<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_3 (Embedding)      (None, 16, 8)             125160    
_________________________________________________________________
lstm_1 (LSTM)                (None, 8)                 544       
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 9         
=================================================================
Total params: 125,713
Trainable params: 125,713
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>结果分析：我们再次使用Sequential方法搭建模型，只要使用.add就可以把需要的隐藏层添加到模型中。在这个长短期记忆网络中，我们添加了嵌入层，其作用和卷积神经网络中一样，也是为了对填充序列进行处理。嵌入层之后就是长短期记忆层LSTM，最后是全连接层，也是为了输出结果</p>
<h3 id="14-3-2-关于长短期记忆网络"><a href="#14-3-2-关于长短期记忆网络" class="headerlink" title="14.3.2 关于长短期记忆网络"></a>14.3.2 关于长短期记忆网络</h3><p>简单来说，长短期记忆网络是一种<strong>增加了携带信息跨越多个时间步</strong>的方法</p>
<p>实际上，长短期记忆网络是为了解决传统循环神经网络的缺点。传统循环神经网络可以在短时间内存储先前的输出，并且来处理当前的输入。这种特性使传统循环神经网络在语音处理和音乐创作领域颇受欢迎。然而，传统循环神经网络<strong>不能长时间存储信息</strong>（由于梯度消失的问题）。这样一来，在处理那些<strong>需要参考很久以前</strong>存储的某些信息来<strong>预测当前</strong>输出的任务的时候，传统循环神经网络就有些“捉襟见肘”了；此外，传统循环神经网络无法更好地控制上下文的<strong>哪些部分需要继承</strong>，以及过去的多少需要遗忘。正是因为如此，长短期记忆网络便应运而生。</p>
<p>与传统循环神经网络最根本的区别是，长短期记忆神经网络的<strong>隐藏层</strong>是一个门控单元。它由4个层组成，各层之间互相作用，并生成每个单元（细胞）的输出。以及此刻单元（细胞）的状态。然后，这个单元（细胞）的输出和状态会被传递到下一个隐藏层。与传统循环神经网络只有1个tanh层不同的是，长短期记忆网络具有3个sigmoid“门”和一个tanh层。这3个sigmoid“门”的作用就是限制某些信息被传递到下一个单元（细胞）。大家已经知道，sigmoid函数的作用就是把模型计算的结果“压缩”到0~1.在长短期记忆网络中，通过sigmoid函数计算后，结果为0的输出就会被“挡在门外”，而结果为1的输出会被“全部放行”。</p>
<h3 id="14-3-3-训练模型及评估"><a href="#14-3-3-训练模型及评估" class="headerlink" title="14.3.3 训练模型及评估"></a>14.3.3 训练模型及评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里是设置模型停止和保存检查点的代码</span></span><br><span class="line">early_stopping = EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, patience=<span class="number">5</span>)</span><br><span class="line">model_checkpoint = ModelCheckpoint(<span class="string">&#x27;model-LSTM.h5&#x27;</span>, save_best_only=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#开始训练LSTM网络</span></span><br><span class="line">hist = lstm.fit(X_train_padded_seqs, y_train,</span><br><span class="line">                batch_size=<span class="number">128</span>,</span><br><span class="line">                epochs=<span class="number">10</span>,</span><br><span class="line">                validation_data=(X_test_padded_seqs, y_test),</span><br><span class="line">                callbacks=[early_stopping, model_checkpoint])</span><br></pre></td></tr></table></figure>

<pre><code>Train on 6910 samples, validate on 2304 samples
Epoch 1/10
6910/6910 [==============================] - 12s 2ms/step - loss: 0.6881 - acc: 0.6693 - val_loss: 0.6780 - val_acc: 0.7990
Epoch 2/10
6910/6910 [==============================] - 10s 1ms/step - loss: 0.6419 - acc: 0.7864 - val_loss: 0.5929 - val_acc: 0.8047
Epoch 3/10
6910/6910 [==============================] - 10s 1ms/step - loss: 0.5111 - acc: 0.8262 - val_loss: 0.4713 - val_acc: 0.8299
Epoch 4/10
6910/6910 [==============================] - 10s 1ms/step - loss: 0.3943 - acc: 0.8831 - val_loss: 0.4089 - val_acc: 0.8424
Epoch 5/10
6910/6910 [==============================] - 9s 1ms/step - loss: 0.3140 - acc: 0.9146 - val_loss: 0.3642 - val_acc: 0.8615
Epoch 6/10
6910/6910 [==============================] - 10s 1ms/step - loss: 0.2525 - acc: 0.9336 - val_loss: 0.3388 - val_acc: 0.8689
Epoch 7/10
6910/6910 [==============================] - 10s 1ms/step - loss: 0.2058 - acc: 0.9498 - val_loss: 0.3306 - val_acc: 0.8668
Epoch 8/10
6910/6910 [==============================] - 10s 1ms/step - loss: 0.1702 - acc: 0.9580 - val_loss: 0.3289 - val_acc: 0.8754
Epoch 9/10
6910/6910 [==============================] - 10s 1ms/step - loss: 0.1465 - acc: 0.9630 - val_loss: 0.3278 - val_acc: 0.8785
Epoch 10/10
6910/6910 [==============================] - 10s 1ms/step - loss: 0.1252 - acc: 0.9713 - val_loss: 0.3276 - val_acc: 0.8750
</code></pre>
<p>结果分析：长短期记忆网络完成了10个轮次的训练，并且在第9轮达到了最高的验证集准确率——87.85%，在同样的数据处理的情况下。与卷积神经网络相比，验证集准确率稍微提高了一点。然而，需要注意的是长短期记忆网络消耗的时间比卷积神经网络长了不少</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lstm.evaluate(X_test_padded_seqs, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>2304/2304 [==============================] - 2s 715us/step





[0.3275794620729155, 0.875]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lstm.predict(X_test_padded_seqs[<span class="number">0</span>].reshape(<span class="number">1</span>,-<span class="number">1</span>))</span><br></pre></td></tr></table></figure>




<pre><code>array([[0.7954852]], dtype=float32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_test_padded_seqs[<span class="number">0</span>].reshape(<span class="number">1</span>,-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([[0, 0, 0, 0, 0, 0, 0, 0, 276, 60, 229, 2951, 38, 1, 786, 478]],
      dtype=int32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_test_padded_seqs[:<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([[0, 0, 0, 0, 0, 0, 0, 0, 276, 60, 229, 2951, 38, 1, 786, 478]],
      dtype=int32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gc.collect()</span><br></pre></td></tr></table></figure>




<pre><code>0
</code></pre>
<h3 id="14-3-4-保存模型并在回测中调用"><a href="#14-3-4-保存模型并在回测中调用" class="headerlink" title="14.3.4 保存模型并在回测中调用"></a>14.3.4 保存模型并在回测中调用</h3><p>我们要先对训练好的模型进行保存</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#keras的模型保存是比较简单的</span></span><br><span class="line"><span class="comment">#使用save方法就可以了</span></span><br><span class="line">lstm.save(<span class="string">&#x27;lstm.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="第15章-未来的征程"><a href="#第15章-未来的征程" class="headerlink" title="第15章 未来的征程"></a>第15章 未来的征程</h1><h3 id="15-1-1-使用第三方量化平台是个好主意吗"><a href="#15-1-1-使用第三方量化平台是个好主意吗" class="headerlink" title="15.1.1 使用第三方量化平台是个好主意吗"></a>15.1.1 使用第三方量化平台是个好主意吗</h3><p>使用第三方平台免去了自己收集数据、计算因子和配置模块的工作，但是这个方法并不能保证平台数据的质量，以及数据的多样性</p>
<h3 id="15-1-2-机器学习到底有没有用"><a href="#15-1-2-机器学习到底有没有用" class="headerlink" title="15.1.2 机器学习到底有没有用"></a>15.1.2 机器学习到底有没有用</h3><p>当下的量化交易圈子中，机器学习的作用仍然存在很多不确定性，数据的信噪比太低，以至于无法让机器学习模型“学到”有用的模式</p>
<p>在本书的前半部分，我们大量使用多因子加机器学习算法来编写策略。然而，不论我们如何选择因子，都要面临一个问题——<strong>因子是有可能失效的</strong>。在某一个时间范围内，某些因子确实可以帮助我们预测出不同股票的价值；但在其他时间内，这些因子可能就会<strong>失效</strong>，而在过一段时间，这些因子没准儿变得<strong>有效</strong>了。这种变化不定的现象也给机器学习带来了困难</p>
<h3 id="15-1-3-A股市场的特点"><a href="#15-1-3-A股市场的特点" class="headerlink" title="15.1.3 A股市场的特点"></a>15.1.3 A股市场的特点</h3><p>（1）散户多，散户投资的方法基本是“追涨杀跌”（说好听点叫趋势投资），在这种市场氛围下，如果单纯考虑价值因子，我们的收益就不一定能最大化</p>
<p>（2）A股市场是“政策市”，监管层的意图和动作会给A股市场带来比较显著的影响。因此照抄国外的方法，用社交媒体数据来训练模型，并试图预测股价趋势的方法就不一定是最好的方法，可以采用政策性文件（证监会）数据来试试</p>
<h2 id="15-2-未来要做什么"><a href="#15-2-未来要做什么" class="headerlink" title="15.2 未来要做什么"></a>15.2 未来要做什么</h2><p>平台提供的数据毕竟有限，如果我们希望实现更好的效果（如自己搭建一个知识图谱进行选股），那我们就要进一步扩宽数据的来源</p>
<p>如果我们打算使用NLP技术分析某个政策文件利好哪一个行业，那图数据库似乎是一共不错的选择</p>
<h3 id="15-2-2-其他不同行业"><a href="#15-2-2-其他不同行业" class="headerlink" title="15.2.2 其他不同行业"></a>15.2.2 其他不同行业</h3><p>基金：主要说一下场内交易基金——因为我们使用在证券公司开立的账户就可以进行场内交易基金的买卖操作，比较方便。</p>
<p>常见的场内交易基金包括交易型开放式指数基金（ETF）和上市开放式基金（LOF）。以ETF为例，目前市场上有很多行业ETF。<strong>我们可以使用NLP技术，分析出时下的国内外形势，并利用知识图谱关联出利好的行业，然后买入对应的行业ETF</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">聚宽</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/量化交易//" class="article-tag-list-link color5">量化交易</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/03/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApython%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E5%AE%9E%E6%88%98-part2/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-python大数据分析与机器学习商业案例实战-part5" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part5/">Python大数据分析与机器学习商业案例实战-part5</a>
    </h1>
  

        
        <a href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part5/" class="archive-article-date">
  	<time datetime="2023-02-03T12:13:14.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-03</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="15-关联分析：Apriori算法"><a href="#15-关联分析：Apriori算法" class="headerlink" title="15 关联分析：Apriori算法"></a>15 关联分析：Apriori算法</h1><h2 id="15-1-关联分析的基础概念和Apriori算法"><a href="#15-1-关联分析的基础概念和Apriori算法" class="headerlink" title="15.1 关联分析的基础概念和Apriori算法"></a>15.1 关联分析的基础概念和Apriori算法</h2><p>关联分析是数据挖掘中一种简单而实用的技术，它通过深入分析数据集，寻找事物间的关联性，挖掘频繁出现的组合，并描述组合内对象同时出现的模式和规律，例如，对超时购物的数据进行关联分析，通过发现顾客所购买的不同商品之间的关系，分析顾客的购买习惯，设计商品的组合摆放位置，指定相应的营销策略，从而制造需求，提高销售量，创造额外收入。关联分析技术也可以应用于智能推荐系统，当我们挖掘出频繁出现的组合和强关联规则之后，就可以通过强关联规则为顾客推荐商品。该技术不仅在商品推荐领域应用广泛，在医疗、保险、电信和证券领域也同样大有可为。</p>
<h3 id="15-1-1-关联分析的基本概念"><a href="#15-1-1-关联分析的基本概念" class="headerlink" title="15.1.1 关联分析的基本概念"></a>15.1.1 关联分析的基本概念</h3><p><img src="%E4%B8%8B%E8%BD%BD.png" alt="下载"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(1).png" alt="下载 (1)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(2).png" alt="下载 (2)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(3).png" alt="下载 (3)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(4).png" alt="下载 (4)"></p>
<p>这个结果说明了购买商品A和商品B的人中有67%的人也购买了商品C，该概率还是很高的，因此，商场可以向购买了商品A和商品B的人推荐商品C，如可以将这3种商品放得较近</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(5).png" alt="下载 (5)"></p>
<h3 id="15-1-2-Apriori算法的数学演示"><a href="#15-1-2-Apriori算法的数学演示" class="headerlink" title="15.1.2 Apriori算法的数学演示"></a>15.1.2 Apriori算法的数学演示</h3><p>1.基本思路</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(6).png" alt="下载 (6)"></p>
<p>2.案例演示</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(7).png" alt="下载 (7)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(8).png" alt="下载 (8)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(9).png" alt="下载 (9)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(10).png" alt="下载 (10)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(11).png" alt="下载 (11)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(12).png" alt="下载 (12)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(13).png" alt="下载 (13)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(14).png" alt="下载 (14)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(15).png" alt="下载 (15)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(16).png" alt="下载 (16)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(17).png" alt="下载 (17)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(18).png" alt="下载 (18)"></p>
<h3 id="15-1-3-Apriori算法的代码实现"><a href="#15-1-3-Apriori算法的代码实现" class="headerlink" title="15.1.3 Apriori算法的代码实现"></a>15.1.3 Apriori算法的代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">transactions = [[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>], [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>], [<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>], [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>], [<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>]]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> apyori <span class="keyword">import</span> apriori</span><br><span class="line">rules = apriori(transactions, min_support=<span class="number">0.4</span>, min_confidence=<span class="number">0.8</span>)</span><br><span class="line">results = <span class="built_in">list</span>(rules)</span><br></pre></td></tr></table></figure>

<p>第二行代码：min_support参数为最小支持度，这里设置为0.4，min_confidence参数为最小置信度，这里设置为0.8，将获取到的关联规则赋给变量rules，第三行代码用list()函数将获得的关联规则转换为列表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">results</span><br></pre></td></tr></table></figure>




<pre><code>[RelationRecord(items=frozenset(&#123;&#39;B&#39;&#125;), support=1.0, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset(&#123;&#39;B&#39;&#125;), confidence=1.0, lift=1.0)]),
 RelationRecord(items=frozenset(&#123;&#39;C&#39;&#125;), support=0.8, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset(&#123;&#39;C&#39;&#125;), confidence=0.8, lift=1.0)]),
 RelationRecord(items=frozenset(&#123;&#39;A&#39;, &#39;B&#39;&#125;), support=0.6, ordered_statistics=[OrderedStatistic(items_base=frozenset(&#123;&#39;A&#39;&#125;), items_add=frozenset(&#123;&#39;B&#39;&#125;), confidence=1.0, lift=1.0)]),
 RelationRecord(items=frozenset(&#123;&#39;B&#39;, &#39;C&#39;&#125;), support=0.8, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset(&#123;&#39;B&#39;, &#39;C&#39;&#125;), confidence=0.8, lift=1.0), OrderedStatistic(items_base=frozenset(&#123;&#39;B&#39;&#125;), items_add=frozenset(&#123;&#39;C&#39;&#125;), confidence=0.8, lift=1.0), OrderedStatistic(items_base=frozenset(&#123;&#39;C&#39;&#125;), items_add=frozenset(&#123;&#39;B&#39;&#125;), confidence=1.0, lift=1.0)]),
 RelationRecord(items=frozenset(&#123;&#39;D&#39;, &#39;B&#39;&#125;), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(&#123;&#39;D&#39;&#125;), items_add=frozenset(&#123;&#39;B&#39;&#125;), confidence=1.0, lift=1.0)]),
 RelationRecord(items=frozenset(&#123;&#39;D&#39;, &#39;C&#39;&#125;), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(&#123;&#39;D&#39;&#125;), items_add=frozenset(&#123;&#39;C&#39;&#125;), confidence=1.0, lift=1.25)]),
 RelationRecord(items=frozenset(&#123;&#39;A&#39;, &#39;B&#39;, &#39;C&#39;&#125;), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(&#123;&#39;A&#39;, &#39;C&#39;&#125;), items_add=frozenset(&#123;&#39;B&#39;&#125;), confidence=1.0, lift=1.0)]),
 RelationRecord(items=frozenset(&#123;&#39;D&#39;, &#39;B&#39;, &#39;C&#39;&#125;), support=0.4, ordered_statistics=[OrderedStatistic(items_base=frozenset(&#123;&#39;D&#39;&#125;), items_add=frozenset(&#123;&#39;B&#39;, &#39;C&#39;&#125;), confidence=1.0, lift=1.25), OrderedStatistic(items_base=frozenset(&#123;&#39;D&#39;, &#39;B&#39;&#125;), items_add=frozenset(&#123;&#39;C&#39;&#125;), confidence=1.0, lift=1.25), OrderedStatistic(items_base=frozenset(&#123;&#39;D&#39;, &#39;C&#39;&#125;), items_add=frozenset(&#123;&#39;B&#39;&#125;), confidence=1.0, lift=1.0)])]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">type</span>(results[<span class="number">0</span>].ordered_statistics)</span><br></pre></td></tr></table></figure>




<pre><code>list
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> results:  <span class="comment"># 遍历results中的每一个频繁项集</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> i.ordered_statistics:  <span class="comment"># 获取频繁项集中的关联规则</span></span><br><span class="line">        X = j.items_base  <span class="comment"># 关联规则的前件</span></span><br><span class="line">        Y = j.items_add  <span class="comment"># 关联规则的后件</span></span><br><span class="line">        x = <span class="string">&#x27;, &#x27;</span>.join([item <span class="keyword">for</span> item <span class="keyword">in</span> X])  <span class="comment"># 连接前件中的元素</span></span><br><span class="line">        y = <span class="string">&#x27;, &#x27;</span>.join([item <span class="keyword">for</span> item <span class="keyword">in</span> Y])  <span class="comment"># 连接后件中的元素</span></span><br><span class="line">        <span class="keyword">if</span> x != <span class="string">&#x27;&#x27;</span>:  <span class="comment"># 防止出现关联规则前件为空的情况</span></span><br><span class="line">            <span class="built_in">print</span>(x + <span class="string">&#x27; → &#x27;</span> + y)  <span class="comment"># 通过字符串拼接的方式更好呈现结果</span></span><br></pre></td></tr></table></figure>

<pre><code>A → B
B → C
C → B
D → B
D → C
A, C → B
D → B, C
D, B → C
D, C → B
</code></pre>
<p>可以看到apyori库获取了所有强关联规则</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过在内容后面加?可以查看官方介绍</span></span><br><span class="line"><span class="comment"># apriori?</span></span><br></pre></td></tr></table></figure>

<h2 id="15-2-案例实战：病症关联分析"><a href="#15-2-案例实战：病症关联分析" class="headerlink" title="15.2 案例实战：病症关联分析"></a>15.2 案例实战：病症关联分析</h2><h3 id="案例背景"><a href="#案例背景" class="headerlink" title="案例背景"></a>案例背景</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(19).png" alt="下载 (19)"></p>
<h3 id="15-2-2-数据读取与处理"><a href="#15-2-2-数据读取与处理" class="headerlink" title="15.2.2 数据读取与处理"></a>15.2.2 数据读取与处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;中医辨证.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>病人编号</th>
      <th>病人症状</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>消化不良,便秘</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>心悸,失眠</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>腰疼,脱发,眼干</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>腹胀,便秘,哮喘,胸闷气短,消化不良</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>神经衰弱,失眠,月经不调</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简单演示下tolist()函数</span></span><br><span class="line">df[<span class="string">&#x27;病人症状&#x27;</span>].tolist()</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;消化不良,便秘&#39;,
 &#39;心悸,失眠&#39;,
 &#39;腰疼,脱发,眼干&#39;,
 &#39;腹胀,便秘,哮喘,胸闷气短,消化不良&#39;,
 &#39;神经衰弱,失眠,月经不调&#39;,
 &#39;神经衰弱,消化不良,月经不调&#39;,
 &#39;失眠,眼干,月经不调&#39;,
 &#39;腹胀,便秘,哮喘,胸闷气短,消化不良&#39;,
 &#39;腰疼,脱发,眼干,心悸&#39;,
 &#39;神经衰弱,消化不良,月经不调&#39;,
 &#39;腰疼,眼干,月经不调&#39;,
 &#39;心悸,腹胀,便秘,消化不良&#39;,
 &#39;心悸,月经不调,消化不良&#39;,
 &#39;心悸,失眠,月经不调&#39;,
 &#39;心悸,神经衰弱,消化不良,便秘&#39;,
 &#39;失眠,月经不调,胸闷气短&#39;,
 &#39;心悸,失眠,脱发,眼干,月经不调&#39;,
 &#39;哮喘,胸闷气短&#39;,
 &#39;心悸,月经不调,消化不良&#39;,
 &#39;消化不良,月经不调&#39;,
 &#39;腹胀,便秘,消化不良&#39;,
 &#39;失眠,月经不调&#39;,
 &#39;腰疼,脱发,眼干,易怒&#39;,
 &#39;失眠,月经不调&#39;,
 &#39;哮喘,腰疼&#39;,
 &#39;心悸,腹胀&#39;,
 &#39;失眠,眼干,月经不调&#39;,
 &#39;失眠,眼干,月经不调&#39;,
 &#39;消化不良,便秘&#39;,
 &#39;失眠,月经不调&#39;,
 &#39;消化不良,便秘&#39;,
 &#39;心悸,神经衰弱,消化不良,便秘&#39;,
 &#39;哮喘,鼻炎,脱发&#39;,
 &#39;心悸,腹胀&#39;,
 &#39;心悸,失眠,月经不调&#39;,
 &#39;腰疼,眼干,便秘&#39;,
 &#39;心悸,失眠&#39;,
 &#39;心悸,神经衰弱,易怒,消化不良&#39;,
 &#39;神经衰弱,消化不良&#39;,
 &#39;心悸,失眠,月经不调&#39;,
 &#39;哮喘,胸闷气短&#39;,
 &#39;心悸,失眠,眼干,月经不调,消化不良&#39;,
 ……………………………………
 ……………………………………]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转换为双重列表结构</span></span><br><span class="line">symptoms = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df[<span class="string">&#x27;病人症状&#x27;</span>].tolist():</span><br><span class="line">    symptoms.append(i.split(<span class="string">&#x27;,&#x27;</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(symptoms)</span><br></pre></td></tr></table></figure>

<pre><code>[[&#39;消化不良&#39;, &#39;便秘&#39;], [&#39;心悸&#39;, &#39;失眠&#39;], [&#39;腰疼&#39;, &#39;脱发&#39;, &#39;眼干&#39;], [&#39;腹胀&#39;, &#39;便秘&#39;, &#39;哮喘&#39;, &#39;胸闷气短&#39;, &#39;消化不良&#39;], [&#39;神经衰弱&#39;, &#39;失眠&#39;, &#39;月经不调&#39;], [&#39;神经衰弱&#39;, &#39;消化不良&#39;, &#39;月经不调&#39;], [&#39;失眠&#39;, &#39;眼干&#39;, &#39;月经不调&#39;], [&#39;腹胀&#39;, &#39;便秘&#39;, &#39;哮喘&#39;, &#39;胸闷气短&#39;, &#39;消化不良&#39;], [&#39;腰疼&#39;, &#39;脱发&#39;, &#39;眼干&#39;, &#39;心悸&#39;], [&#39;神经衰弱&#39;, &#39;消化不良&#39;, &#39;月经不调&#39;], [&#39;腰疼&#39;, &#39;眼干&#39;, &#39;月经不调&#39;], [&#39;心悸&#39;, &#39;腹胀&#39;, &#39;便秘&#39;, &#39;消化不良&#39;], [&#39;心悸&#39;, &#39;月经不调&#39;, &#39;消化不良&#39;], [&#39;心悸&#39;, &#39;失眠&#39;, &#39;月经不调&#39;], [&#39;心悸&#39;, &#39;神经衰弱&#39;, &#39;消化不良&#39;, &#39;便秘&#39;], [&#39;失眠&#39;, &#39;月经不调&#39;, &#39;胸闷气短&#39;], [&#39;心悸&#39;, &#39;失眠&#39;, &#39;脱发&#39;, &#39;眼干&#39;, &#39;月经不调&#39;], [&#39;哮喘&#39;, &#39;胸闷气短&#39;], [&#39;心悸&#39;, &#39;月经不调&#39;, &#39;消化不良&#39;], [&#39;消化不良&#39;, &#39;月经不调&#39;], [&#39;腹胀&#39;, &#39;便秘&#39;, &#39;消化不良&#39;], [&#39;失眠&#39;, &#39;月经不调&#39;], [&#39;腰疼&#39;, &#39;脱发&#39;, &#39;眼干&#39;, &#39;易怒&#39;], [&#39;失眠&#39;, &#39;月经不调&#39;], [&#39;哮喘&#39;, &#39;腰疼&#39;], [&#39;心悸&#39;, &#39;腹胀&#39;], [&#39;失眠&#39;, &#39;眼干&#39;, &#39;月经不调&#39;], [&#39;失眠&#39;, &#39;眼干&#39;, &#39;月经不调&#39;], [&#39;消化不良&#39;, &#39;便秘&#39;], [&#39;失眠&#39;, &#39;月经不调&#39;], [&#39;消化不良&#39;, &#39;便秘&#39;], [&#39;心悸&#39;, &#39;神经衰弱&#39;, &#39;消化不良&#39;, &#39;便秘&#39;], [&#39;哮喘&#39;, &#39;鼻炎&#39;, &#39;脱发&#39;], [&#39;心悸&#39;, &#39;腹胀&#39;], [&#39;心悸&#39;, &#39;失眠&#39;, &#39;月经不调&#39;], [&#39;腰疼&#39;, &#39;眼干&#39;, &#39;便秘&#39;], [&#39;心悸&#39;, &#39;失眠&#39;], [&#39;心悸&#39;, &#39;神经衰弱&#39;, &#39;易怒&#39;, &#39;消化不良&#39;], [&#39;神经衰弱&#39;, &#39;消化不良&#39;], [&#39;心悸&#39;, &#39;失眠&#39;, &#39;月经不调&#39;],………………………………]]
</code></pre>
<p>第一行代码创建一个空列表symptoms（病症），用来存储之后提取的每一个患者的病症数据；第二行代码遍历每个患者的“患者病症”列，并用tolist()函数将该列的内容转换为一个列表，列表中的每个元素就是每个患者的所有病症，如第一个元素为“消化不良，便秘”，两个病症通过逗号连接；第三行代码先用split()函数按逗号对列表元素进行分割，将患者的一个个病症分割开来，并存储在一个个子列表中，再用append()函数将所有患者的病症子列表汇总到symptoms列表中</p>
<h3 id="15-2-3-关联规则分析"><a href="#15-2-3-关联规则分析" class="headerlink" title="15.2.3 关联规则分析"></a>15.2.3 关联规则分析</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> apyori <span class="keyword">import</span> apriori</span><br><span class="line">rules = apriori(symptoms, min_support=<span class="number">0.1</span>, min_confidence=<span class="number">0.7</span>)</span><br><span class="line">results = <span class="built_in">list</span>(rules)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> results:  <span class="comment"># 遍历results中的每一个频繁项集</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> i.ordered_statistics:  <span class="comment"># 获取频繁项集中的关联规则</span></span><br><span class="line">        X = j.items_base  <span class="comment"># 关联规则的前件</span></span><br><span class="line">        Y = j.items_add  <span class="comment"># 关联规则的后件</span></span><br><span class="line">        x = <span class="string">&#x27;, &#x27;</span>.join([item <span class="keyword">for</span> item <span class="keyword">in</span> X])  <span class="comment"># 连接前件中的元素</span></span><br><span class="line">        y = <span class="string">&#x27;, &#x27;</span>.join([item <span class="keyword">for</span> item <span class="keyword">in</span> Y])  <span class="comment"># 连接后件中的元素</span></span><br><span class="line">        <span class="keyword">if</span> x != <span class="string">&#x27;&#x27;</span>:  <span class="comment"># 防止出现关联规则前件为空的情况</span></span><br><span class="line">            <span class="built_in">print</span>(x + <span class="string">&#x27; → &#x27;</span> + y)  <span class="comment"># 通过字符串拼接的方式更好呈现结果</span></span><br></pre></td></tr></table></figure>

<pre><code>便秘 → 消化不良
失眠 → 月经不调
神经衰弱 → 消化不良
脱发 → 眼干
腰疼 → 眼干
心悸, 失眠 → 月经不调
心悸, 神经衰弱 → 消化不良
</code></pre>
<p>可以看到，在获得的关联规则中，的确有之前提到的同一脏器导致的病症关联规则，如便秘和消化不良（脾的关联病症）的关联规则，并且还有不同脏器之间相互影响导致的病症关联规则，如脱发（肾的关联病症）和眼干（肝的关联病症）的关联规则，其余的关联规则也说明了不同病症之间存在一些关联性</p>
<hr>
<p><strong>金融产品交叉销售案例</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;金融产品购买数据.xlsx&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>用户编号</th>
      <th>购买产品</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>华小智2号产品,华小智4号产品,华小智5号产品,华小智6号产品</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>华大智1号产品,华大智2号产品,华大智5号产品,华大智6号产品</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>华小智9号产品,华小智10号产品,华小智12号产品</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>华大智1号产品,华大智5号产品</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>华大智5号产品,华大智6号产品</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简单演示下tolist()函数</span></span><br><span class="line">df[<span class="string">&#x27;购买产品&#x27;</span>].tolist()</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;华小智2号产品,华小智4号产品,华小智5号产品,华小智6号产品&#39;,
 &#39;华大智1号产品,华大智2号产品,华大智5号产品,华大智6号产品&#39;,
 &#39;华小智9号产品,华小智10号产品,华小智12号产品&#39;,
 &#39;华大智1号产品,华大智5号产品&#39;,
 &#39;华大智5号产品,华大智6号产品&#39;,
 &#39;华中智2号产品&#39;,
 &#39;华大智2号产品,华大智3号产品,华大智6号产品&#39;,
 &#39;华小智7号产品,华小智8号产品,华小智11号产品&#39;,
 &#39;华大智1号产品,华大智3号产品,华大智4号产品,华大智5号产品&#39;,
 &#39;华中智2号产品,华中智5号产品&#39;,
 &#39;华大智3号产品,华大智4号产品,华大智5号产品,华大智6号产品&#39;,
 …………………………
 …………………………]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转换为双重列表结构</span></span><br><span class="line">products = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df[<span class="string">&#x27;购买产品&#x27;</span>].tolist():</span><br><span class="line">    products.append(i.split(<span class="string">&#x27;,&#x27;</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(products)</span><br></pre></td></tr></table></figure>

<pre><code>[[&#39;华小智2号产品&#39;, &#39;华小智4号产品&#39;, &#39;华小智5号产品&#39;, &#39;华小智6号产品&#39;], [&#39;华大智1号产品&#39;, &#39;华大智2号产品&#39;, &#39;华大智5号产品&#39;, &#39;华大智6号产品&#39;], [&#39;华小智9号产品&#39;, &#39;华小智10号产品&#39;, &#39;华小智12号产品&#39;], [&#39;华大智1号产品&#39;, &#39;华大智5号产品&#39;], [&#39;华大智5号产品&#39;, &#39;华大智6号产品&#39;], [&#39;华中智2号产品&#39;], [&#39;华大智2号产品&#39;, &#39;华大智3号产品&#39;, &#39;华大智6号产品&#39;], [&#39;华小智7号产品&#39;, &#39;华小智8号产品&#39;, &#39;华小智11号产品&#39;], [&#39;华大智1号产品&#39;, &#39;华大智3号产品&#39;, &#39;华大智4号产品&#39;, &#39;华大智5号产品&#39;], [&#39;华中智2号产品&#39;, &#39;华中智5号产品&#39;], [&#39;华大智3号产品&#39;, &#39;华大智4号产品&#39;, &#39;华大智5号产品&#39;, &#39;华大智6号产品&#39;], [&#39;华小智13号产品&#39;, &#39;华小智17号产品&#39;], [&#39;华中智3号产品&#39;, &#39;华中智4号产品&#39;, &#39;华中智5号产品&#39;], [&#39;华大智2号产品&#39;, &#39;华大智4号产品&#39;, &#39;华大智5号产品&#39;], [&#39;华小智2号产品&#39;, &#39;华小智3号产品&#39;, &#39;华小智6号产品&#39;], [&#39;华小智1号产品&#39;, &#39;华小智3号产品&#39;,……………………………………]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> apyori <span class="keyword">import</span> apriori</span><br><span class="line">rules = apriori(products, min_support=<span class="number">0.01</span>, min_confidence=<span class="number">0.5</span>)</span><br><span class="line">results = <span class="built_in">list</span>(rules)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> results:  <span class="comment"># 遍历results中的每一个频繁项集</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> i.ordered_statistics:  <span class="comment"># 获取频繁项集中的关联规则</span></span><br><span class="line">        X = j.items_base  <span class="comment"># 关联规则的前件</span></span><br><span class="line">        Y = j.items_add  <span class="comment"># 关联规则的后件</span></span><br><span class="line">        x = <span class="string">&#x27;, &#x27;</span>.join([item <span class="keyword">for</span> item <span class="keyword">in</span> X])  <span class="comment"># 连接前件中的元素</span></span><br><span class="line">        y = <span class="string">&#x27;, &#x27;</span>.join([item <span class="keyword">for</span> item <span class="keyword">in</span> Y])  <span class="comment"># 连接后件中的元素</span></span><br><span class="line">        <span class="keyword">if</span> x != <span class="string">&#x27;&#x27;</span>:  <span class="comment"># 防止出现关联规则前件为空的情况</span></span><br><span class="line">            <span class="built_in">print</span>(x + <span class="string">&#x27; → &#x27;</span> + y)  <span class="comment"># 通过字符串拼接的方式更好呈现结果</span></span><br></pre></td></tr></table></figure>

<pre><code>华中智2号产品 → 华中智1号产品
华中智1号产品 → 华中智3号产品
华中智3号产品 → 华中智1号产品
华中智4号产品 → 华中智1号产品
华中智1号产品 → 华中智6号产品
华中智6号产品 → 华中智1号产品
华中智2号产品 → 华中智3号产品
华中智2号产品 → 华中智6号产品
华中智4号产品 → 华中智3号产品
华中智5号产品 → 华中智3号产品
华中智3号产品 → 华中智6号产品
华中智6号产品 → 华中智3号产品
华中智4号产品 → 华中智5号产品
华中智4号产品 → 华中智6号产品
华大智1号产品 → 华大智2号产品
华大智1号产品 → 华大智3号产品
华大智1号产品 → 华大智4号产品
华大智4号产品 → 华大智1号产品
华大智5号产品 → 华大智1号产品
华大智1号产品 → 华大智6号产品
华大智6号产品 → 华大智1号产品
华大智4号产品 → 华大智2号产品
华大智2号产品 → 华大智6号产品
华大智4号产品 → 华大智3号产品
华大智5号产品 → 华大智3号产品
华大智3号产品 → 华大智6号产品
华大智6号产品 → 华大智3号产品
华大智4号产品 → 华大智5号产品
华大智5号产品 → 华大智4号产品
华大智4号产品 → 华大智6号产品
华大智5号产品 → 华大智6号产品
华小智10号产品 → 华小智11号产品
………………………………
………………………………
</code></pre>
<h1 id="16-深度学习之神经网络模型"><a href="#16-深度学习之神经网络模型" class="headerlink" title="16 深度学习之神经网络模型"></a>16 深度学习之神经网络模型</h1><h2 id="16-1-深度学习基础：神经网络模型"><a href="#16-1-深度学习基础：神经网络模型" class="headerlink" title="16.1 深度学习基础：神经网络模型"></a>16.1 深度学习基础：神经网络模型</h2><h3 id="16-1-1-神经网络模型的基本原理"><a href="#16-1-1-神经网络模型的基本原理" class="headerlink" title="16.1.1 神经网络模型的基本原理"></a>16.1.1 神经网络模型的基本原理</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(20).png" alt="下载 (20)"></p>
<p>1.单层神经网路模型</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(21).png" alt="下载 (21)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(22).png" alt="下载 (22)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(23).png" alt="下载 (23)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(24).png" alt="下载 (24)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(25).png" alt="下载 (25)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(26).png" alt="下载 (26)"></p>
<p>2.多层神经网络模型</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(27).png" alt="下载 (27)"></p>
<h3 id="16-1-2-神经网络模型的简单代码实现"><a href="#16-1-2-神经网络模型的简单代码实现" class="headerlink" title="16.1.2 神经网络模型的简单代码实现"></a>16.1.2 神经网络模型的简单代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = [[<span class="number">1</span>, <span class="number">0</span>], [<span class="number">5</span>, <span class="number">1</span>], [<span class="number">6</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">2</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier  <span class="comment"># 引入MLP多层神经网络模型</span></span><br><span class="line">mlp =MLPClassifier()</span><br><span class="line">mlp.fit(X, y)</span><br></pre></td></tr></table></figure>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred = mlp.predict(X)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y)</span><br><span class="line">a</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>补充知识点 - 神经网络回归模型：MLPRegressor</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPRegressor</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">model = MLPRegressor(random_state=<span class="number">123</span>)  <span class="comment"># 设置random_state随机状态参数，使得每次训练的模型都是一样的</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[2.85598566]
</code></pre>
<h2 id="16-2-案例实战：用户评论情感分析模型"><a href="#16-2-案例实战：用户评论情感分析模型" class="headerlink" title="16.2 案例实战：用户评论情感分析模型"></a>16.2 案例实战：用户评论情感分析模型</h2><h3 id="16-2-1-案例背景"><a href="#16-2-1-案例背景" class="headerlink" title="16.2.1 案例背景"></a>16.2.1 案例背景</h3><h3 id="16-2-2-数据读取、中文分词、文本向量化"><a href="#16-2-2-数据读取、中文分词、文本向量化" class="headerlink" title="16.2.2 数据读取、中文分词、文本向量化"></a>16.2.2 数据读取、中文分词、文本向量化</h3><p>1.读取数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;产品评价.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>客户编号</th>
      <th>评论</th>
      <th>评价</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>是iPhone8 XR正品，按键屏幕反应蛮快的很灵活，屏幕6.0的不算很大，刚刚好，这款面容...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>外形外观：外光非常漂亮，黑色的非常大气。适合男士拥有。屏幕音效：刚开机就下载了一个QQ音乐试...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>从苹果4s，到6s，再到xr，就是喜欢苹果的手感和风格，视频流畅，图片清晰，纠结了好久买哪个...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>主要是手感，太沉了，比苹果6，沉一倍，厚太多了，看中双卡双待机，刚买回来用，待机时间还不错，...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>外形外观：红色超级好看，送妈妈的。屏幕音效：音效还可以，也什么特别的，屏幕看着也挺舒服。拍照...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>2.中文分词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过第2章讲的iloc获取数据表DataFrame第一行信息，0表示第一行</span></span><br><span class="line">df.iloc[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>客户编号                                                    1
评论      是iPhone8 XR正品，按键屏幕反应蛮快的很灵活，屏幕6.0的不算很大，刚刚好，这款面容...
评价                                                      1
Name: 0, dtype: object
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了循序渐进，这里先演示第一条评论的分词效果</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">word = jieba.cut(df.iloc[<span class="number">0</span>][<span class="string">&#x27;评论&#x27;</span>]) <span class="comment"># 读取第一条评论</span></span><br><span class="line">result = <span class="string">&#x27; &#x27;</span>.join(word)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<pre><code>Building prefix dict from the default dictionary ...
Loading model from cache C:\Users\王宇涵\AppData\Local\Temp\jieba.cache
Loading model cost 0.445 seconds.
Prefix dict has been built successfully.


是 iPhone8   XR 正品 ， 按键 屏幕 反应 蛮快 的 很 灵活 ， 屏幕 6.0 的 不算 很大 ， 刚刚 好 ， 这 款 面容 识别 开锁 比 指纹 方便 多 了 ， 内外 的 整体 看起来 很 美观 ， 整机 子 不算 是 很厚感 ， 像素 高 比较 清晰 ， 双卡 双待 ， 续航 强 ， 跟 8plus 差价 300 元 ， 还是 选 XR 款好 ， 性能 不错 ， 处理器 、 芯片 也 是 最新 一代
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 遍历整张表格，对所有评论进行分词</span></span><br><span class="line">words = []</span><br><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows(): <span class="comment"># df.iterrows()是pandas库遍历表格每一行的方法，i是每一行的行号，row是每一行的内容</span></span><br><span class="line">    word = jieba.cut(row[<span class="string">&#x27;评论&#x27;</span>]) <span class="comment"># cut()分词函数，row代表每一行的数据，row[&#x27;评论&#x27;]就代表该行中“评论”列的内容</span></span><br><span class="line">    result = <span class="string">&#x27; &#x27;</span>.join(word) </span><br><span class="line">    words.append(result) <span class="comment"># 将每一条评论的分词结果添加到words列表中</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words[<span class="number">0</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;是 iPhone8   XR 正品 ， 按键 屏幕 反应 蛮快 的 很 灵活 ， 屏幕 6.0 的 不算 很大 ， 刚刚 好 ， 这 款 面容 识别 开锁 比 指纹 方便 多 了 ， 内外 的 整体 看起来 很 美观 ， 整机 子 不算 是 很厚感 ， 像素 高 比较 清晰 ， 双卡 双待 ， 续航 强 ， 跟 8plus 差价 300 元 ， 还是 选 XR 款好 ， 性能 不错 ， 处理器 、 芯片 也 是 最新 一代&#39;,
 &#39;外形 外观 ： 外光 非常 漂亮 ， 黑色 的 非常 大气 。 适合 男士 拥有 。 屏幕 音效 ： 刚 开机 就 下载 了 一个 QQ 音乐 试 了 一下 。   音效 还是 非常 不错 的 。 拍照 效果 ： 拍照 很 清晰 ， 照亮 你 脸上 的 痘痘 。 运行 速度 ： 运行 速度 就 不用说 了 。   一个 字快 。 待机时间 ： 待机 很 不错 。 用 一段时间 再 来 评价 。 其他 特色 ： 个人感觉 比 Ｘ 好 。   可能 是因为 上手 的 手感 比较 好 吧 ， 总之 还是 值得 入手 的&#39;,
 &#39;从 苹果 4s ， 到 6s ， 再 到 xr ， 就是 喜欢 苹果 的 手感 和 风格 ， 视频 流畅 ， 图片 清晰 ， 纠结 了 好久 买 哪个 颜色 ， 白色 干净 ， 同事 买 的 黄色 ， 感觉 也 很 好看 ， 蓝色 ， 珊瑚 我 也 喜欢 ， 最终 还是 选择 比较 适合 女生 的 珊瑚 色 ， 实物 比 图片 更 漂亮 ， 超级 喜欢 ， 运行 速度 快 ， 全屏 显示 ， 体积小 了 ， 可 显示 区域 变得 了 ， 很棒 。&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果对上面过程如果熟悉后，也可以直接写成如下的合并代码形式</span></span><br><span class="line">words = []</span><br><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    words.append(<span class="string">&#x27; &#x27;</span>.join(jieba.cut(row[<span class="string">&#x27;评论&#x27;</span>])))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # iterrows()函数相关知识点，不熟悉DataFrame数据表遍历的话，可以把下面的注释取消了，看看效果</span></span><br><span class="line"><span class="comment"># for i, row in df.iterrows():</span></span><br><span class="line"><span class="comment">#     print(i)</span></span><br><span class="line"><span class="comment">#     print(row)</span></span><br></pre></td></tr></table></figure>

<p>3.构造特征变量和目标变量</p>
<p>（1）特征变量提取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 文本向量化CountVectorizer()函数的使用技巧：使用示例</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">test = [<span class="string">&#x27;手机 外观 漂亮&#x27;</span>, <span class="string">&#x27;手机 图片 清晰&#x27;</span>]</span><br><span class="line">vect = CountVectorizer()</span><br><span class="line">X = vect.fit_transform(test)</span><br><span class="line">X = X.toarray()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">words_bag = vect.vocabulary_</span><br><span class="line"><span class="built_in">print</span>(words_bag)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;手机&#39;: 2, &#39;外观&#39;: 1, &#39;漂亮&#39;: 4, &#39;图片&#39;: 0, &#39;清晰&#39;: 3&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实际应用</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">vect = CountVectorizer()</span><br><span class="line">X = vect.fit_transform(words)</span><br><span class="line">X = X.toarray()</span><br><span class="line"><span class="built_in">print</span>(X)</span><br></pre></td></tr></table></figure>

<pre><code>[[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">words_bag = vect.vocabulary_</span><br><span class="line"><span class="built_in">print</span>(words_bag)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;iphone8&#39;: 194, &#39;xr&#39;: 264, &#39;正品&#39;: 2660, &#39;按键&#39;: 2221, &#39;屏幕&#39;: 1798, &#39;反应&#39;: 1210, &#39;蛮快&#39;: 3492, &#39;灵活&#39;: 2843, &#39;不算&#39;: 517, &#39;很大&#39;: 1967, &#39;刚刚&#39;: 1031, &#39;面容&#39;: 3979, &#39;识别&#39;: 3570, &#39;开锁&#39;: 1915, &#39;指纹&#39;: 2218, &#39;方便&#39;: 2362, &#39;内外&#39;: 941, &#39;整体&#39;: 2341, &#39;看起来&#39;: 3101, &#39;美观&#39;: 3345, &#39;整机&#39;: 2344, &#39;很厚感&#39;: 1959, &#39;像素&#39;: 862, &#39;比较&#39;: 2704, &#39;清晰&#39;: 2808, &#39;双卡&#39;: 1201, &#39;双待&#39;: 1203, &#39;续航&#39;: 3301, &#39;8plus&#39;: 143, &#39;差价&#39;: 1823, &#39;300&#39;: 50, &#39;还是&#39;: 3758, &#39;款好&#39;: 2655, &#39;性能&#39;: 2040, &#39;不错&#39;: 538, &#39;处理器&#39;: 1460, &#39;芯片&#39;: 3455, &#39;最新&#39;: 2506, &#39;一代&#39;: 290, &#39;外形&#39;: 1471, &#39;外观&#39;: 1473, &#39;外光&#39;: 1468, &#39;非常&#39;: 3972, &#39;漂亮&#39;: 2832, &#39;黑色&#39;: 4068, &#39;大气&#39;: 1521, &#39;适合&#39;: 3827, &#39;男士&#39;: 2997, &#39;拥有&#39;: 2207, &#39;音效&#39;: 3985, &#39;开机&#39;: 1910, &#39;下载&#39;: 445, &#39;一个&#39;: 280, &#39;qq&#39;: 234, &#39;音乐&#39;: 3983, &#39;一下&#39;: 276, &#39;拍照&#39;: 2203, &#39;效果&#39;: 2330, &#39;照亮&#39;: 2863, &#39;脸上&#39;: 3409, &#39;痘痘&#39;: 3019, &#39;运行&#39;: 3744, &#39;速度&#39;: 3854, &#39;不用说&#39;: 514, &#39;字快&#39;: 1666, &#39;待机时间&#39;: 1951, &#39;待机&#39;: 1950, &#39;一段时间&#39;: 354, &#39;评价&#39;: 3566, &#39;其他&#39;: 928, &#39;特色&#39;: 2908, &#39;个人感觉&#39;: 583, &#39;可能&#39;: 1271, &#39;是因为&#39;: 2449, &#39;上手&#39;: 420,…………………………&#125;
</code></pre>
<p>可以看到，所得到的词袋就是一个字典，其内容是对评论的分词结果进行去重，再对不同的词进行编号</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(words_bag) <span class="comment"># 查看词袋中一共有多少个词，产生了多少特征变量</span></span><br></pre></td></tr></table></figure>




<pre><code>4075
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)  <span class="comment"># 添加这行代码可以显示所有列，如果讲None改成500，则表示可最多显示500列</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_rows&#x27;</span>, <span class="literal">None</span>)  <span class="comment"># 添加这行代码可以显示所有行，如果讲None改成500，则表示可最多显示500行</span></span><br><span class="line">pd.DataFrame(X).head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>19</th>
      <th>20</th>
      <th>21</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
      <th>26</th>
      <th>27</th>
      <th>28</th>
      <th>29</th>
      <th>30</th>
      <th>31</th>
      <th>32</th>
      <th>33</th>
      <th>34</th>
      <th>35</th>
      <th>36</th>
      <th>37</th>
      <th>38</th>
      <th>39</th>
      <th>40</th>
      <th>41</th>
      <th>42</th>
      <th>43</th>
      <th>44</th>
      <th>45</th>
      <th>46</th>
      <th>47</th>
      <th>48</th>
      <th>49</th>
      <th>50</th>
      <th>51</th>
      <th>52</th>
      <th>53</th>
      <th>54</th>
      <th>55</th>
      <th>56</th>
      <th>57</th>
      <th>58</th>
      <th>59</th>
      <th>60</th>
      <th>61</th>
      <th>62</th>
      <th>63</th>
      <th>64</th>
      <th>65</th>
      <th>66</th>
      <th>67</th>
      <th>68</th>
      <th>69</th>
      <th>70</th>
      <th>71</th>
      <th>72</th>
      <th>73</th>
      <th>74</th>
      <th>75</th>
      <th>76</th>
      <th>77</th>
      <th>78</th>
      <th>79</th>
      <th>80</th>
      <th>81</th>
      <th>82</th>
      <th>83</th>
      <th>84</th>
      <th>85</th>
      <th>86</th>
      <th>87</th>
      <th>88</th>
      <th>89</th>
      <th>90</th>
      <th>91</th>
      <th>92</th>
      <th>93</th>
      <th>94</th>
      <th>95</th>
      <th>96</th>
      <th>97</th>
      <th>98</th>
      <th>99</th>
      <th>100</th>
      <th>101</th>
      <th>102</th>
      <th>103</th>
      <th>104</th>
      <th>105</th>
      <th>106</th>
      <th>107</th>
      <th>108</th>
      <th>109</th>
      <th>110</th>
      <th>111</th>
      <th>112</th>
      <th>113</th>
      <th>114</th>
      <th>115</th>
      <th>116</th>
      <th>117</th>
      <th>118</th>
      <th>119</th>
      <th>120</th>
      <th>121</th>
      <th>122</th>
      <th>123</th>
      <th>124</th>
      <th>125</th>
      <th>126</th>
      <th>127</th>
      <th>128</th>
      <th>129</th>
      <th>130</th>
      <th>131</th>
      <th>132</th>
      <th>133</th>
      <th>134</th>
      <th>135</th>
      <th>136</th>
      <th>137</th>
      <th>138</th>
      <th>139</th>
      <th>140</th>
      <th>141</th>
      <th>142</th>
      <th>143</th>
      <th>144</th>
      <th>145</th>
      <th>146</th>
      <th>147</th>
      <th>148</th>
      <th>149</th>
      <th>150</th>
      <th>151</th>
      <th>152</th>
      <th>153</th>
      <th>154</th>
      <th>155</th>
      <th>156</th>
      <th>157</th>
      <th>158</th>
      <th>159</th>
      <th>160</th>
      <th>161</th>
      <th>162</th>
      <th>163</th>
      <th>164</th>
      <th>165</th>
      <th>166</th>
      <th>167</th>
      <th>168</th>
      <th>169</th>
      <th>170</th>
      <th>171</th>
      <th>172</th>
      <th>173</th>
      <th>174</th>
      <th>175</th>
      <th>176</th>
      <th>177</th>
      <th>178</th>
      <th>179</th>
      <th>180</th>
      <th>181</th>
      <th>182</th>
      <th>183</th>
      <th>184</th>
      <th>185</th>
      <th>186</th>
      <th>187</th>
      <th>188</th>
      <th>189</th>
      <th>190</th>
      <th>191</th>
      <th>192</th>
      <th>193</th>
      <th>194</th>
      <th>195</th>
      <th>196</th>
      <th>197</th>
      <th>198</th>
      <th>199</th>
      <th>200</th>
      <th>201</th>
      <th>202</th>
      <th>203</th>
      <th>204</th>
      <th>205</th>
      <th>206</th>
      <th>207</th>
      <th>208</th>
      <th>209</th>
      <th>210</th>
      <th>211</th>
      <th>212</th>
      <th>213</th>
      <th>214</th>
      <th>215</th>
      <th>216</th>
      <th>217</th>
      <th>218</th>
      <th>219</th>
      <th>220</th>
      <th>221</th>
      <th>222</th>
      <th>223</th>
      <th>224</th>
      <th>225</th>
      <th>226</th>
      <th>227</th>
      <th>228</th>
      <th>229</th>
      <th>230</th>
      <th>231</th>
      <th>232</th>
      <th>233</th>
      <th>234</th>
      <th>235</th>
      <th>236</th>
      <th>237</th>
      <th>238</th>
      <th>239</th>
      <th>240</th>
      <th>241</th>
      <th>242</th>
      <th>243</th>
      <th>244</th>
      <th>245</th>
      <th>246</th>
      <th>247</th>
      <th>248</th>
      <th>249</th>
      <th>250</th>
      <th>251</th>
      <th>252</th>
      <th>253</th>
      <th>254</th>
      <th>255</th>
      <th>256</th>
      <th>257</th>
      <th>258</th>
      <th>259</th>
      <th>260</th>
      <th>261</th>
      <th>262</th>
      <th>263</th>
      <th>264</th>
      <th>265</th>
      <th>266</th>
      <th>267</th>
      <th>268</th>
      <th>269</th>
      <th>270</th>
      <th>271</th>
      <th>272</th>
      <th>273</th>
      <th>274</th>
      <th>275</th>
      <th>276</th>
      <th>277</th>
      <th>278</th>
      <th>279</th>
      <th>280</th>
      <th>281</th>
      <th>282</th>
      <th>283</th>
      <th>284</th>
      <th>285</th>
      <th>286</th>
      <th>287</th>
      <th>288</th>
      <th>289</th>
      <th>290</th>
      <th>291</th>
      <th>292</th>
      <th>293</th>
      <th>294</th>
      <th>295</th>
      <th>296</th>
      <th>297</th>
      <th>298</th>
      <th>299</th>
      <th>300</th>
      <th>301</th>
      <th>302</th>
      <th>303</th>
      <th>304</th>
      <th>305</th>
      <th>306</th>
      <th>307</th>
      <th>308</th>
      <th>309</th>
      <th>310</th>
      <th>311</th>
      <th>312</th>
      <th>313</th>
      <th>314</th>
      <th>315</th>
      <th>316</th>
      <th>317</th>
      <th>318</th>
      <th>319</th>
      <th>320</th>
      <th>321</th>
      <th>322</th>
      <th>323</th>
      <th>324</th>
      <th>325</th>
      <th>326</th>
      <th>327</th>
      <th>328</th>
      <th>329</th>
      <th>330</th>
      <th>331</th>
      <th>332</th>
      <th>333</th>
      <th>334</th>
      <th>335</th>
      <th>336</th>
      <th>337</th>
      <th>338</th>
      <th>339</th>
      <th>340</th>
      <th>341</th>
      <th>342</th>
      <th>343</th>
      <th>344</th>
      <th>345</th>
      <th>346</th>
      <th>347</th>
      <th>348</th>
      <th>349</th>
      <th>350</th>
      <th>351</th>
      <th>352</th>
      <th>353</th>
      <th>354</th>
      <th>355</th>
      <th>356</th>
      <th>357</th>
      <th>358</th>
      <th>359</th>
      <th>360</th>
      <th>361</th>
      <th>362</th>
      <th>363</th>
      <th>364</th>
      <th>365</th>
      <th>366</th>
      <th>367</th>
      <th>368</th>
      <th>369</th>
      <th>370</th>
      <th>371</th>
      <th>372</th>
      <th>373</th>
      <th>374</th>
      <th>375</th>
      <th>376</th>
      <th>377</th>
      <th>378</th>
      <th>379</th>
      <th>380</th>
      <th>381</th>
      <th>382</th>
      <th>383</th>
      <th>384</th>
      <th>385</th>
      <th>386</th>
      <th>387</th>
      <th>388</th>
      <th>389</th>
      <th>390</th>
      <th>391</th>
      <th>392</th>
      <th>393</th>
      <th>394</th>
      <th>395</th>
      <th>396</th>
      <th>397</th>
      <th>398</th>
      <th>399</th>
      <th>400</th>
      <th>401</th>
      <th>402</th>
      <th>403</th>
      <th>404</th>
      <th>405</th>
      <th>406</th>
      <th>407</th>
      <th>408</th>
      <th>409</th>
      <th>410</th>
      <th>411</th>
      <th>412</th>
      <th>413</th>
      <th>414</th>
      <th>415</th>
      <th>416</th>
      <th>417</th>
      <th>418</th>
      <th>419</th>
      <th>420</th>
      <th>421</th>
      <th>422</th>
      <th>423</th>
      <th>424</th>
      <th>425</th>
      <th>426</th>
      <th>427</th>
      <th>428</th>
      <th>429</th>
      <th>430</th>
      <th>431</th>
      <th>432</th>
      <th>433</th>
      <th>434</th>
      <th>435</th>
      <th>436</th>
      <th>437</th>
      <th>438</th>
      <th>439</th>
      <th>440</th>
      <th>441</th>
      <th>442</th>
      <th>443</th>
      <th>444</th>
      <th>445</th>
      <th>446</th>
      <th>447</th>
      <th>448</th>
      <th>449</th>
      <th>450</th>
      <th>451</th>
      <th>452</th>
      <th>453</th>
      <th>454</th>
      <th>455</th>
      <th>456</th>
      <th>457</th>
      <th>458</th>
      <th>459</th>
      <th>460</th>
      <th>461</th>
      <th>462</th>
      <th>463</th>
      <th>464</th>
      <th>465</th>
      <th>466</th>
      <th>467</th>
      <th>468</th>
      <th>469</th>
      <th>470</th>
      <th>471</th>
      <th>472</th>
      <th>473</th>
      <th>474</th>
      <th>475</th>
      <th>476</th>
      <th>477</th>
      <th>478</th>
      <th>479</th>
      <th>480</th>
      <th>481</th>
      <th>482</th>
      <th>483</th>
      <th>484</th>
      <th>485</th>
      <th>486</th>
      <th>487</th>
      <th>488</th>
      <th>489</th>
      <th>490</th>
      <th>491</th>
      <th>492</th>
      <th>493</th>
      <th>494</th>
      <th>495</th>
      <th>496</th>
      <th>497</th>
      <th>498</th>
      <th>499</th>
      <th>500</th>
      <th>501</th>
      <th>502</th>
      <th>503</th>
      <th>504</th>
      <th>505</th>
      <th>506</th>
      <th>507</th>
      <th>508</th>
      <th>509</th>
      <th>510</th>
      <th>511</th>
      <th>512</th>
      <th>513</th>
      <th>514</th>
      <th>515</th>
      <th>516</th>
      <th>517</th>
      <th>518</th>
      <th>519</th>
      <th>520</th>
      <th>521</th>
      <th>522</th>
      <th>523</th>
      <th>524</th>
      <th>525</th>
      <th>526</th>
      <th>527</th>
      <th>528</th>
      <th>529</th>
      <th>530</th>
      <th>531</th>
      <th>532</th>
      <th>533</th>
      <th>534</th>
      <th>535</th>
      <th>536</th>
      <th>537</th>
      <th>538</th>
      <th>539</th>
      <th>540</th>
      <th>541</th>
      <th>542</th>
      <th>543</th>
      <th>544</th>
      <th>545</th>
      <th>546</th>
      <th>547</th>
      <th>548</th>
      <th>549</th>
      <th>550</th>
      <th>551</th>
      <th>552</th>
      <th>553</th>
      <th>554</th>
      <th>555</th>
      <th>556</th>
      <th>557</th>
      <th>558</th>
      <th>559</th>
      <th>560</th>
      <th>561</th>
      <th>562</th>
      <th>563</th>
      <th>564</th>
      <th>565</th>
      <th>566</th>
      <th>567</th>
      <th>568</th>
      <th>569</th>
      <th>570</th>
      <th>571</th>
      <th>572</th>
      <th>573</th>
      <th>574</th>
      <th>575</th>
      <th>576</th>
      <th>577</th>
      <th>578</th>
      <th>579</th>
      <th>580</th>
      <th>581</th>
      <th>582</th>
      <th>583</th>
      <th>584</th>
      <th>585</th>
      <th>586</th>
      <th>587</th>
      <th>588</th>
      <th>589</th>
      <th>590</th>
      <th>591</th>
      <th>592</th>
      <th>593</th>
      <th>594</th>
      <th>595</th>
      <th>596</th>
      <th>597</th>
      <th>598</th>
      <th>599</th>
      <th>600</th>
      <th>601</th>
      <th>602</th>
      <th>603</th>
      <th>604</th>
      <th>605</th>
      <th>606</th>
      <th>607</th>
      <th>608</th>
      <th>609</th>
      <th>610</th>
      <th>611</th>
      <th>612</th>
      <th>613</th>
      <th>614</th>
      <th>615</th>
      <th>616</th>
      <th>617</th>
      <th>618</th>
      <th>619</th>
      <th>620</th>
      <th>621</th>
      <th>622</th>
      <th>623</th>
      <th>624</th>
      <th>625</th>
      <th>626</th>
      <th>627</th>
      <th>628</th>
      <th>629</th>
      <th>630</th>
      <th>631</th>
      <th>632</th>
      <th>633</th>
      <th>634</th>
      <th>635</th>
      <th>636</th>
      <th>637</th>
      <th>638</th>
      <th>639</th>
      <th>640</th>
      <th>641</th>
      <th>642</th>
      <th>643</th>
      <th>644</th>
      <th>645</th>
      <th>646</th>
      <th>647</th>
      <th>648</th>
      <th>649</th>
      <th>650</th>
      <th>651</th>
      <th>652</th>
      <th>653</th>
      <th>654</th>
      <th>655</th>
      <th>656</th>
      <th>657</th>
      <th>658</th>
      <th>659</th>
      <th>660</th>
      <th>661</th>
      <th>662</th>
      <th>663</th>
      <th>664</th>
      <th>665</th>
      <th>666</th>
      <th>667</th>
      <th>668</th>
      <th>669</th>
      <th>670</th>
      <th>671</th>
      <th>672</th>
      <th>673</th>
      <th>674</th>
      <th>675</th>
      <th>676</th>
      <th>677</th>
      <th>678</th>
      <th>679</th>
      <th>680</th>
      <th>681</th>
      <th>682</th>
      <th>683</th>
      <th>684</th>
      <th>685</th>
      <th>686</th>
      <th>687</th>
      <th>688</th>
      <th>689</th>
      <th>690</th>
      <th>691</th>
      <th>692</th>
      <th>693</th>
      <th>694</th>
      <th>695</th>
      <th>696</th>
      <th>697</th>
      <th>698</th>
      <th>699</th>
      <th>700</th>
      <th>701</th>
      <th>702</th>
      <th>703</th>
      <th>704</th>
      <th>705</th>
      <th>706</th>
      <th>707</th>
      <th>708</th>
      <th>709</th>
      <th>710</th>
      <th>711</th>
      <th>712</th>
      <th>713</th>
      <th>714</th>
      <th>715</th>
      <th>716</th>
      <th>717</th>
      <th>718</th>
      <th>719</th>
      <th>720</th>
      <th>721</th>
      <th>722</th>
      <th>723</th>
      <th>724</th>
      <th>725</th>
      <th>726</th>
      <th>727</th>
      <th>728</th>
      <th>729</th>
      <th>730</th>
      <th>731</th>
      <th>732</th>
      <th>733</th>
      <th>734</th>
      <th>735</th>
      <th>736</th>
      <th>737</th>
      <th>738</th>
      <th>739</th>
      <th>740</th>
      <th>741</th>
      <th>742</th>
      <th>743</th>
      <th>744</th>
      <th>745</th>
      <th>746</th>
      <th>747</th>
      <th>748</th>
      <th>749</th>
      <th>750</th>
      <th>751</th>
      <th>752</th>
      <th>753</th>
      <th>754</th>
      <th>755</th>
      <th>756</th>
      <th>757</th>
      <th>758</th>
      <th>759</th>
      <th>760</th>
      <th>761</th>
      <th>762</th>
      <th>763</th>
      <th>764</th>
      <th>765</th>
      <th>766</th>
      <th>767</th>
      <th>768</th>
      <th>769</th>
      <th>770</th>
      <th>771</th>
      <th>772</th>
      <th>773</th>
      <th>774</th>
      <th>775</th>
      <th>776</th>
      <th>777</th>
      <th>778</th>
      <th>779</th>
      <th>780</th>
      <th>781</th>
      <th>782</th>
      <th>783</th>
      <th>784</th>
      <th>785</th>
      <th>786</th>
      <th>787</th>
      <th>788</th>
      <th>789</th>
      <th>790</th>
      <th>791</th>
      <th>792</th>
      <th>793</th>
      <th>794</th>
      <th>795</th>
      <th>796</th>
      <th>797</th>
      <th>798</th>
      <th>799</th>
      <th>800</th>
      <th>801</th>
      <th>802</th>
      <th>803</th>
      <th>804</th>
      <th>805</th>
      <th>806</th>
      <th>807</th>
      <th>808</th>
      <th>809</th>
      <th>810</th>
      <th>811</th>
      <th>812</th>
      <th>813</th>
      <th>814</th>
      <th>815</th>
      <th>816</th>
      <th>817</th>
      <th>818</th>
      <th>819</th>
      <th>820</th>
      <th>821</th>
      <th>822</th>
      <th>823</th>
      <th>824</th>
      <th>825</th>
      <th>826</th>
      <th>827</th>
      <th>828</th>
      <th>829</th>
      <th>830</th>
      <th>831</th>
      <th>832</th>
      <th>833</th>
      <th>834</th>
      <th>835</th>
      <th>836</th>
      <th>837</th>
      <th>838</th>
      <th>839</th>
      <th>840</th>
      <th>841</th>
      <th>842</th>
      <th>843</th>
      <th>844</th>
      <th>845</th>
      <th>846</th>
      <th>847</th>
      <th>848</th>
      <th>849</th>
      <th>850</th>
      <th>851</th>
      <th>852</th>
      <th>853</th>
      <th>854</th>
      <th>855</th>
      <th>856</th>
      <th>857</th>
      <th>858</th>
      <th>859</th>
      <th>860</th>
      <th>861</th>
      <th>862</th>
      <th>863</th>
      <th>864</th>
      <th>865</th>
      <th>866</th>
      <th>867</th>
      <th>868</th>
      <th>869</th>
      <th>870</th>
      <th>871</th>
      <th>872</th>
      <th>873</th>
      <th>874</th>
      <th>875</th>
      <th>876</th>
      <th>877</th>
      <th>878</th>
      <th>879</th>
      <th>880</th>
      <th>881</th>
      <th>882</th>
      <th>883</th>
      <th>884</th>
      <th>885</th>
      <th>886</th>
      <th>887</th>
      <th>888</th>
      <th>889</th>
      <th>890</th>
      <th>891</th>
      <th>892</th>
      <th>893</th>
      <th>894</th>
      <th>895</th>
      <th>896</th>
      <th>897</th>
      <th>898</th>
      <th>899</th>
      <th>900</th>
      <th>901</th>
      <th>902</th>
      <th>903</th>
      <th>904</th>
      <th>905</th>
      <th>906</th>
      <th>907</th>
      <th>908</th>
      <th>909</th>
      <th>910</th>
      <th>911</th>
      <th>912</th>
      <th>913</th>
      <th>914</th>
      <th>915</th>
      <th>916</th>
      <th>917</th>
      <th>918</th>
      <th>919</th>
      <th>920</th>
      <th>921</th>
      <th>922</th>
      <th>923</th>
      <th>924</th>
      <th>925</th>
      <th>926</th>
      <th>927</th>
      <th>928</th>
      <th>929</th>
      <th>930</th>
      <th>931</th>
      <th>932</th>
      <th>933</th>
      <th>934</th>
      <th>935</th>
      <th>936</th>
      <th>937</th>
      <th>938</th>
      <th>939</th>
      <th>940</th>
      <th>941</th>
      <th>942</th>
      <th>943</th>
      <th>944</th>
      <th>945</th>
      <th>946</th>
      <th>947</th>
      <th>948</th>
      <th>949</th>
      <th>950</th>
      <th>951</th>
      <th>952</th>
      <th>953</th>
      <th>954</th>
      <th>955</th>
      <th>956</th>
      <th>957</th>
      <th>958</th>
      <th>959</th>
      <th>960</th>
      <th>961</th>
      <th>962</th>
      <th>963</th>
      <th>964</th>
      <th>965</th>
      <th>966</th>
      <th>967</th>
      <th>968</th>
      <th>969</th>
      <th>970</th>
      <th>971</th>
      <th>972</th>
      <th>973</th>
      <th>974</th>
      <th>975</th>
      <th>976</th>
      <th>977</th>
      <th>978</th>
      <th>979</th>
      <th>980</th>
      <th>981</th>
      <th>982</th>
      <th>983</th>
      <th>984</th>
      <th>985</th>
      <th>986</th>
      <th>987</th>
      <th>988</th>
      <th>989</th>
      <th>990</th>
      <th>991</th>
      <th>992</th>
      <th>993</th>
      <th>994</th>
      <th>995</th>
      <th>996</th>
      <th>997</th>
      <th>998</th>
      <th>999</th>
      <th>1000</th>
      <th>1001</th>
      <th>1002</th>
      <th>1003</th>
      <th>1004</th>
      <th>1005</th>
      <th>1006</th>
      <th>1007</th>
      <th>1008</th>
      <th>1009</th>
      <th>1010</th>
      <th>1011</th>
      <th>1012</th>
      <th>1013</th>
      <th>1014</th>
      <th>1015</th>
      <th>1016</th>
      <th>1017</th>
      <th>1018</th>
      <th>1019</th>
      <th>1020</th>
      <th>1021</th>
      <th>1022</th>
      <th>1023</th>
      <th>1024</th>
      <th>1025</th>
      <th>1026</th>
      <th>1027</th>
      <th>1028</th>
      <th>1029</th>
      <th>1030</th>
      <th>1031</th>
      <th>1032</th>
      <th>1033</th>
      <th>1034</th>
      <th>1035</th>
      <th>1036</th>
      <th>1037</th>
      <th>1038</th>
      <th>1039</th>
      <th>1040</th>
      <th>1041</th>
      <th>1042</th>
      <th>1043</th>
      <th>1044</th>
      <th>1045</th>
      <th>1046</th>
      <th>1047</th>
      <th>1048</th>
      <th>1049</th>
      <th>1050</th>
      <th>1051</th>
      <th>1052</th>
      <th>1053</th>
      <th>1054</th>
      <th>1055</th>
      <th>1056</th>
      <th>1057</th>
      <th>1058</th>
      <th>1059</th>
      <th>1060</th>
      <th>1061</th>
      <th>1062</th>
      <th>1063</th>
      <th>1064</th>
      <th>1065</th>
      <th>1066</th>
      <th>1067</th>
      <th>1068</th>
      <th>1069</th>
      <th>1070</th>
      <th>1071</th>
      <th>1072</th>
      <th>1073</th>
      <th>1074</th>
      <th>1075</th>
      <th>1076</th>
      <th>1077</th>
      <th>1078</th>
      <th>1079</th>
      <th>1080</th>
      <th>1081</th>
      <th>1082</th>
      <th>1083</th>
      <th>1084</th>
      <th>1085</th>
      <th>1086</th>
      <th>1087</th>
      <th>1088</th>
      <th>1089</th>
      <th>1090</th>
      <th>1091</th>
      <th>1092</th>
      <th>1093</th>
      <th>1094</th>
      <th>1095</th>
      <th>1096</th>
      <th>1097</th>
      <th>1098</th>
      <th>1099</th>
      <th>1100</th>
      <th>1101</th>
      <th>1102</th>
      <th>1103</th>
      <th>1104</th>
      <th>1105</th>
      <th>1106</th>
      <th>1107</th>
      <th>1108</th>
      <th>1109</th>
      <th>1110</th>
      <th>1111</th>
      <th>1112</th>
      <th>1113</th>
      <th>1114</th>
      <th>1115</th>
      <th>1116</th>
      <th>1117</th>
      <th>1118</th>
      <th>1119</th>
      <th>1120</th>
      <th>1121</th>
      <th>1122</th>
      <th>1123</th>
      <th>1124</th>
      <th>1125</th>
      <th>1126</th>
      <th>1127</th>
      <th>1128</th>
      <th>1129</th>
      <th>1130</th>
      <th>1131</th>
      <th>1132</th>
      <th>1133</th>
      <th>1134</th>
      <th>1135</th>
      <th>1136</th>
      <th>1137</th>
      <th>1138</th>
      <th>1139</th>
      <th>1140</th>
      <th>1141</th>
      <th>1142</th>
      <th>1143</th>
      <th>1144</th>
      <th>1145</th>
      <th>1146</th>
      <th>1147</th>
      <th>1148</th>
      <th>1149</th>
      <th>1150</th>
      <th>1151</th>
      <th>1152</th>
      <th>1153</th>
      <th>1154</th>
      <th>1155</th>
      <th>1156</th>
      <th>1157</th>
      <th>1158</th>
      <th>1159</th>
      <th>1160</th>
      <th>1161</th>
      <th>1162</th>
      <th>1163</th>
      <th>1164</th>
      <th>1165</th>
      <th>1166</th>
      <th>1167</th>
      <th>1168</th>
      <th>1169</th>
      <th>1170</th>
      <th>1171</th>
      <th>1172</th>
      <th>1173</th>
      <th>1174</th>
      <th>1175</th>
      <th>1176</th>
      <th>1177</th>
      <th>1178</th>
      <th>1179</th>
      <th>1180</th>
      <th>1181</th>
      <th>1182</th>
      <th>1183</th>
      <th>1184</th>
      <th>1185</th>
      <th>1186</th>
      <th>1187</th>
      <th>1188</th>
      <th>1189</th>
      <th>1190</th>
      <th>1191</th>
      <th>1192</th>
      <th>1193</th>
      <th>1194</th>
      <th>1195</th>
      <th>1196</th>
      <th>1197</th>
      <th>1198</th>
      <th>1199</th>
      <th>1200</th>
      <th>1201</th>
      <th>1202</th>
      <th>1203</th>
      <th>1204</th>
      <th>1205</th>
      <th>1206</th>
      <th>1207</th>
      <th>1208</th>
      <th>1209</th>
      <th>1210</th>
      <th>1211</th>
      <th>1212</th>
      <th>1213</th>
      <th>1214</th>
      <th>1215</th>
      <th>1216</th>
      <th>1217</th>
      <th>1218</th>
      <th>1219</th>
      <th>1220</th>
      <th>1221</th>
      <th>1222</th>
      <th>1223</th>
      <th>1224</th>
      <th>1225</th>
      <th>1226</th>
      <th>1227</th>
      <th>1228</th>
      <th>1229</th>
      <th>1230</th>
      <th>1231</th>
      <th>1232</th>
      <th>1233</th>
      <th>1234</th>
      <th>1235</th>
      <th>1236</th>
      <th>1237</th>
      <th>1238</th>
      <th>1239</th>
      <th>1240</th>
      <th>1241</th>
      <th>1242</th>
      <th>1243</th>
      <th>1244</th>
      <th>1245</th>
      <th>1246</th>
      <th>1247</th>
      <th>1248</th>
      <th>1249</th>
      <th>1250</th>
      <th>1251</th>
      <th>1252</th>
      <th>1253</th>
      <th>1254</th>
      <th>1255</th>
      <th>1256</th>
      <th>1257</th>
      <th>1258</th>
      <th>1259</th>
      <th>1260</th>
      <th>1261</th>
      <th>1262</th>
      <th>1263</th>
      <th>1264</th>
      <th>1265</th>
      <th>1266</th>
      <th>1267</th>
      <th>1268</th>
      <th>1269</th>
      <th>1270</th>
      <th>1271</th>
      <th>1272</th>
      <th>1273</th>
      <th>1274</th>
      <th>1275</th>
      <th>1276</th>
      <th>1277</th>
      <th>1278</th>
      <th>1279</th>
      <th>1280</th>
      <th>1281</th>
      <th>1282</th>
      <th>1283</th>
      <th>1284</th>
      <th>1285</th>
      <th>1286</th>
      <th>1287</th>
      <th>1288</th>
      <th>1289</th>
      <th>1290</th>
      <th>1291</th>
      <th>1292</th>
      <th>1293</th>
      <th>1294</th>
      <th>1295</th>
      <th>1296</th>
      <th>1297</th>
      <th>1298</th>
      <th>1299</th>
      <th>1300</th>
      <th>1301</th>
      <th>1302</th>
      <th>1303</th>
      <th>1304</th>
      <th>1305</th>
      <th>1306</th>
      <th>1307</th>
      <th>1308</th>
      <th>1309</th>
      <th>1310</th>
      <th>1311</th>
      <th>1312</th>
      <th>1313</th>
      <th>1314</th>
      <th>1315</th>
      <th>1316</th>
      <th>1317</th>
      <th>1318</th>
      <th>1319</th>
      <th>1320</th>
      <th>1321</th>
      <th>1322</th>
      <th>1323</th>
      <th>1324</th>
      <th>1325</th>
      <th>1326</th>
      <th>1327</th>
      <th>1328</th>
      <th>1329</th>
      <th>1330</th>
      <th>1331</th>
      <th>1332</th>
      <th>1333</th>
      <th>1334</th>
      <th>1335</th>
      <th>1336</th>
      <th>1337</th>
      <th>1338</th>
      <th>1339</th>
      <th>1340</th>
      <th>1341</th>
      <th>1342</th>
      <th>1343</th>
      <th>1344</th>
      <th>1345</th>
      <th>1346</th>
      <th>1347</th>
      <th>1348</th>
      <th>1349</th>
      <th>1350</th>
      <th>1351</th>
      <th>1352</th>
      <th>1353</th>
      <th>1354</th>
      <th>1355</th>
      <th>1356</th>
      <th>1357</th>
      <th>1358</th>
      <th>1359</th>
      <th>1360</th>
      <th>1361</th>
      <th>1362</th>
      <th>1363</th>
      <th>1364</th>
      <th>1365</th>
      <th>1366</th>
      <th>1367</th>
      <th>1368</th>
      <th>1369</th>
      <th>1370</th>
      <th>1371</th>
      <th>1372</th>
      <th>1373</th>
      <th>1374</th>
      <th>1375</th>
      <th>1376</th>
      <th>1377</th>
      <th>1378</th>
      <th>1379</th>
      <th>1380</th>
      <th>1381</th>
      <th>1382</th>
      <th>1383</th>
      <th>1384</th>
      <th>1385</th>
      <th>1386</th>
      <th>1387</th>
      <th>1388</th>
      <th>1389</th>
      <th>1390</th>
      <th>1391</th>
      <th>1392</th>
      <th>1393</th>
      <th>1394</th>
      <th>1395</th>
      <th>1396</th>
      <th>1397</th>
      <th>1398</th>
      <th>1399</th>
      <th>1400</th>
      <th>1401</th>
      <th>1402</th>
      <th>1403</th>
      <th>1404</th>
      <th>1405</th>
      <th>1406</th>
      <th>1407</th>
      <th>1408</th>
      <th>1409</th>
      <th>1410</th>
      <th>1411</th>
      <th>1412</th>
      <th>1413</th>
      <th>1414</th>
      <th>1415</th>
      <th>1416</th>
      <th>1417</th>
      <th>1418</th>
      <th>1419</th>
      <th>1420</th>
      <th>1421</th>
      <th>1422</th>
      <th>1423</th>
      <th>1424</th>
      <th>1425</th>
      <th>1426</th>
      <th>1427</th>
      <th>1428</th>
      <th>1429</th>
      <th>1430</th>
      <th>1431</th>
      <th>1432</th>
      <th>1433</th>
      <th>1434</th>
      <th>1435</th>
      <th>1436</th>
      <th>1437</th>
      <th>1438</th>
      <th>1439</th>
      <th>1440</th>
      <th>1441</th>
      <th>1442</th>
      <th>1443</th>
      <th>1444</th>
      <th>1445</th>
      <th>1446</th>
      <th>1447</th>
      <th>1448</th>
      <th>1449</th>
      <th>1450</th>
      <th>1451</th>
      <th>1452</th>
      <th>1453</th>
      <th>1454</th>
      <th>1455</th>
      <th>1456</th>
      <th>1457</th>
      <th>1458</th>
      <th>1459</th>
      <th>1460</th>
      <th>1461</th>
      <th>1462</th>
      <th>1463</th>
      <th>1464</th>
      <th>1465</th>
      <th>1466</th>
      <th>1467</th>
      <th>1468</th>
      <th>1469</th>
      <th>1470</th>
      <th>1471</th>
      <th>1472</th>
      <th>1473</th>
      <th>1474</th>
      <th>1475</th>
      <th>1476</th>
      <th>1477</th>
      <th>1478</th>
      <th>1479</th>
      <th>1480</th>
      <th>1481</th>
      <th>1482</th>
      <th>1483</th>
      <th>1484</th>
      <th>1485</th>
      <th>1486</th>
      <th>1487</th>
      <th>1488</th>
      <th>1489</th>
      <th>1490</th>
      <th>1491</th>
      <th>1492</th>
      <th>1493</th>
      <th>1494</th>
      <th>1495</th>
      <th>1496</th>
      <th>1497</th>
      <th>1498</th>
      <th>1499</th>
      <th>1500</th>
      <th>1501</th>
      <th>1502</th>
      <th>1503</th>
      <th>1504</th>
      <th>1505</th>
      <th>1506</th>
      <th>1507</th>
      <th>1508</th>
      <th>1509</th>
      <th>1510</th>
      <th>1511</th>
      <th>1512</th>
      <th>1513</th>
      <th>1514</th>
      <th>1515</th>
      <th>1516</th>
      <th>1517</th>
      <th>1518</th>
      <th>1519</th>
      <th>1520</th>
      <th>1521</th>
      <th>1522</th>
      <th>1523</th>
      <th>1524</th>
      <th>1525</th>
      <th>1526</th>
      <th>1527</th>
      <th>1528</th>
      <th>1529</th>
      <th>1530</th>
      <th>1531</th>
      <th>1532</th>
      <th>1533</th>
      <th>1534</th>
      <th>1535</th>
      <th>1536</th>
      <th>1537</th>
      <th>1538</th>
      <th>1539</th>
      <th>1540</th>
      <th>1541</th>
      <th>1542</th>
      <th>1543</th>
      <th>1544</th>
      <th>1545</th>
      <th>1546</th>
      <th>1547</th>
      <th>1548</th>
      <th>1549</th>
      <th>1550</th>
      <th>1551</th>
      <th>1552</th>
      <th>1553</th>
      <th>1554</th>
      <th>1555</th>
      <th>1556</th>
      <th>1557</th>
      <th>1558</th>
      <th>1559</th>
      <th>1560</th>
      <th>1561</th>
      <th>1562</th>
      <th>1563</th>
      <th>1564</th>
      <th>1565</th>
      <th>1566</th>
      <th>1567</th>
      <th>1568</th>
      <th>1569</th>
      <th>1570</th>
      <th>1571</th>
      <th>1572</th>
      <th>1573</th>
      <th>1574</th>
      <th>1575</th>
      <th>1576</th>
      <th>1577</th>
      <th>1578</th>
      <th>1579</th>
      <th>1580</th>
      <th>1581</th>
      <th>1582</th>
      <th>1583</th>
      <th>1584</th>
      <th>1585</th>
      <th>1586</th>
      <th>1587</th>
      <th>1588</th>
      <th>1589</th>
      <th>1590</th>
      <th>1591</th>
      <th>1592</th>
      <th>1593</th>
      <th>1594</th>
      <th>1595</th>
      <th>1596</th>
      <th>1597</th>
      <th>1598</th>
      <th>1599</th>
      <th>1600</th>
      <th>1601</th>
      <th>1602</th>
      <th>1603</th>
      <th>1604</th>
      <th>1605</th>
      <th>1606</th>
      <th>1607</th>
      <th>1608</th>
      <th>1609</th>
      <th>1610</th>
      <th>1611</th>
      <th>1612</th>
      <th>1613</th>
      <th>1614</th>
      <th>1615</th>
      <th>1616</th>
      <th>1617</th>
      <th>1618</th>
      <th>1619</th>
      <th>1620</th>
      <th>1621</th>
      <th>1622</th>
      <th>1623</th>
      <th>1624</th>
      <th>1625</th>
      <th>1626</th>
      <th>1627</th>
      <th>1628</th>
      <th>1629</th>
      <th>1630</th>
      <th>1631</th>
      <th>1632</th>
      <th>1633</th>
      <th>1634</th>
      <th>1635</th>
      <th>1636</th>
      <th>1637</th>
      <th>1638</th>
      <th>1639</th>
      <th>1640</th>
      <th>1641</th>
      <th>1642</th>
      <th>1643</th>
      <th>1644</th>
      <th>1645</th>
      <th>1646</th>
      <th>1647</th>
      <th>1648</th>
      <th>1649</th>
      <th>1650</th>
      <th>1651</th>
      <th>1652</th>
      <th>1653</th>
      <th>1654</th>
      <th>1655</th>
      <th>1656</th>
      <th>1657</th>
      <th>1658</th>
      <th>1659</th>
      <th>1660</th>
      <th>1661</th>
      <th>1662</th>
      <th>1663</th>
      <th>1664</th>
      <th>1665</th>
      <th>1666</th>
      <th>1667</th>
      <th>1668</th>
      <th>1669</th>
      <th>1670</th>
      <th>1671</th>
      <th>1672</th>
      <th>1673</th>
      <th>1674</th>
      <th>1675</th>
      <th>1676</th>
      <th>1677</th>
      <th>1678</th>
      <th>1679</th>
      <th>1680</th>
      <th>1681</th>
      <th>1682</th>
      <th>1683</th>
      <th>1684</th>
      <th>1685</th>
      <th>1686</th>
      <th>1687</th>
      <th>1688</th>
      <th>1689</th>
      <th>1690</th>
      <th>1691</th>
      <th>1692</th>
      <th>1693</th>
      <th>1694</th>
      <th>1695</th>
      <th>1696</th>
      <th>1697</th>
      <th>1698</th>
      <th>1699</th>
      <th>1700</th>
      <th>1701</th>
      <th>1702</th>
      <th>1703</th>
      <th>1704</th>
      <th>1705</th>
      <th>1706</th>
      <th>1707</th>
      <th>1708</th>
      <th>1709</th>
      <th>1710</th>
      <th>1711</th>
      <th>1712</th>
      <th>1713</th>
      <th>1714</th>
      <th>1715</th>
      <th>1716</th>
      <th>1717</th>
      <th>1718</th>
      <th>1719</th>
      <th>1720</th>
      <th>1721</th>
      <th>1722</th>
      <th>1723</th>
      <th>1724</th>
      <th>1725</th>
      <th>1726</th>
      <th>1727</th>
      <th>1728</th>
      <th>1729</th>
      <th>1730</th>
      <th>1731</th>
      <th>1732</th>
      <th>1733</th>
      <th>1734</th>
      <th>1735</th>
      <th>1736</th>
      <th>1737</th>
      <th>1738</th>
      <th>1739</th>
      <th>1740</th>
      <th>1741</th>
      <th>1742</th>
      <th>1743</th>
      <th>1744</th>
      <th>1745</th>
      <th>1746</th>
      <th>1747</th>
      <th>1748</th>
      <th>1749</th>
      <th>1750</th>
      <th>1751</th>
      <th>1752</th>
      <th>1753</th>
      <th>1754</th>
      <th>1755</th>
      <th>1756</th>
      <th>1757</th>
      <th>1758</th>
      <th>1759</th>
      <th>1760</th>
      <th>1761</th>
      <th>1762</th>
      <th>1763</th>
      <th>1764</th>
      <th>1765</th>
      <th>1766</th>
      <th>1767</th>
      <th>1768</th>
      <th>1769</th>
      <th>1770</th>
      <th>1771</th>
      <th>1772</th>
      <th>1773</th>
      <th>1774</th>
      <th>1775</th>
      <th>1776</th>
      <th>1777</th>
      <th>1778</th>
      <th>1779</th>
      <th>1780</th>
      <th>1781</th>
      <th>1782</th>
      <th>1783</th>
      <th>1784</th>
      <th>1785</th>
      <th>1786</th>
      <th>1787</th>
      <th>1788</th>
      <th>1789</th>
      <th>1790</th>
      <th>1791</th>
      <th>1792</th>
      <th>1793</th>
      <th>1794</th>
      <th>1795</th>
      <th>1796</th>
      <th>1797</th>
      <th>1798</th>
      <th>1799</th>
      <th>1800</th>
      <th>1801</th>
      <th>1802</th>
      <th>1803</th>
      <th>1804</th>
      <th>1805</th>
      <th>1806</th>
      <th>1807</th>
      <th>1808</th>
      <th>1809</th>
      <th>1810</th>
      <th>1811</th>
      <th>1812</th>
      <th>1813</th>
      <th>1814</th>
      <th>1815</th>
      <th>1816</th>
      <th>1817</th>
      <th>1818</th>
      <th>1819</th>
      <th>1820</th>
      <th>1821</th>
      <th>1822</th>
      <th>1823</th>
      <th>1824</th>
      <th>1825</th>
      <th>1826</th>
      <th>1827</th>
      <th>1828</th>
      <th>1829</th>
      <th>1830</th>
      <th>1831</th>
      <th>1832</th>
      <th>1833</th>
      <th>1834</th>
      <th>1835</th>
      <th>1836</th>
      <th>1837</th>
      <th>1838</th>
      <th>1839</th>
      <th>1840</th>
      <th>1841</th>
      <th>1842</th>
      <th>1843</th>
      <th>1844</th>
      <th>1845</th>
      <th>1846</th>
      <th>1847</th>
      <th>1848</th>
      <th>1849</th>
      <th>1850</th>
      <th>1851</th>
      <th>1852</th>
      <th>1853</th>
      <th>1854</th>
      <th>1855</th>
      <th>1856</th>
      <th>1857</th>
      <th>1858</th>
      <th>1859</th>
      <th>1860</th>
      <th>1861</th>
      <th>1862</th>
      <th>1863</th>
      <th>1864</th>
      <th>1865</th>
      <th>1866</th>
      <th>1867</th>
      <th>1868</th>
      <th>1869</th>
      <th>1870</th>
      <th>1871</th>
      <th>1872</th>
      <th>1873</th>
      <th>1874</th>
      <th>1875</th>
      <th>1876</th>
      <th>1877</th>
      <th>1878</th>
      <th>1879</th>
      <th>1880</th>
      <th>1881</th>
      <th>1882</th>
      <th>1883</th>
      <th>1884</th>
      <th>1885</th>
      <th>1886</th>
      <th>1887</th>
      <th>1888</th>
      <th>1889</th>
      <th>1890</th>
      <th>1891</th>
      <th>1892</th>
      <th>1893</th>
      <th>1894</th>
      <th>1895</th>
      <th>1896</th>
      <th>1897</th>
      <th>1898</th>
      <th>1899</th>
      <th>1900</th>
      <th>1901</th>
      <th>1902</th>
      <th>1903</th>
      <th>1904</th>
      <th>1905</th>
      <th>1906</th>
      <th>1907</th>
      <th>1908</th>
      <th>1909</th>
      <th>1910</th>
      <th>1911</th>
      <th>1912</th>
      <th>1913</th>
      <th>1914</th>
      <th>1915</th>
      <th>1916</th>
      <th>1917</th>
      <th>1918</th>
      <th>1919</th>
      <th>1920</th>
      <th>1921</th>
      <th>1922</th>
      <th>1923</th>
      <th>1924</th>
      <th>1925</th>
      <th>1926</th>
      <th>1927</th>
      <th>1928</th>
      <th>1929</th>
      <th>1930</th>
      <th>1931</th>
      <th>1932</th>
      <th>1933</th>
      <th>1934</th>
      <th>1935</th>
      <th>1936</th>
      <th>1937</th>
      <th>1938</th>
      <th>1939</th>
      <th>1940</th>
      <th>1941</th>
      <th>1942</th>
      <th>1943</th>
      <th>1944</th>
      <th>1945</th>
      <th>1946</th>
      <th>1947</th>
      <th>1948</th>
      <th>1949</th>
      <th>1950</th>
      <th>1951</th>
      <th>1952</th>
      <th>1953</th>
      <th>1954</th>
      <th>1955</th>
      <th>1956</th>
      <th>1957</th>
      <th>1958</th>
      <th>1959</th>
      <th>1960</th>
      <th>1961</th>
      <th>1962</th>
      <th>1963</th>
      <th>1964</th>
      <th>1965</th>
      <th>1966</th>
      <th>1967</th>
      <th>1968</th>
      <th>1969</th>
      <th>1970</th>
      <th>1971</th>
      <th>1972</th>
      <th>1973</th>
      <th>1974</th>
      <th>1975</th>
      <th>1976</th>
      <th>1977</th>
      <th>1978</th>
      <th>1979</th>
      <th>1980</th>
      <th>1981</th>
      <th>1982</th>
      <th>1983</th>
      <th>1984</th>
      <th>1985</th>
      <th>1986</th>
      <th>1987</th>
      <th>1988</th>
      <th>1989</th>
      <th>1990</th>
      <th>1991</th>
      <th>1992</th>
      <th>1993</th>
      <th>1994</th>
      <th>1995</th>
      <th>1996</th>
      <th>1997</th>
      <th>1998</th>
      <th>1999</th>
      <th>2000</th>
      <th>2001</th>
      <th>2002</th>
      <th>2003</th>
      <th>2004</th>
      <th>2005</th>
      <th>2006</th>
      <th>2007</th>
      <th>2008</th>
      <th>2009</th>
      <th>2010</th>
      <th>2011</th>
      <th>2012</th>
      <th>2013</th>
      <th>2014</th>
      <th>2015</th>
      <th>2016</th>
      <th>2017</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
      <th>2022</th>
      <th>2023</th>
      <th>2024</th>
      <th>2025</th>
      <th>2026</th>
      <th>2027</th>
      <th>2028</th>
      <th>2029</th>
      <th>2030</th>
      <th>2031</th>
      <th>2032</th>
      <th>2033</th>
      <th>2034</th>
      <th>2035</th>
      <th>2036</th>
      <th>2037</th>
      <th>2038</th>
      <th>2039</th>
      <th>2040</th>
      <th>2041</th>
      <th>2042</th>
      <th>2043</th>
      <th>2044</th>
      <th>2045</th>
      <th>2046</th>
      <th>2047</th>
      <th>2048</th>
      <th>2049</th>
      <th>2050</th>
      <th>2051</th>
      <th>2052</th>
      <th>2053</th>
      <th>2054</th>
      <th>2055</th>
      <th>2056</th>
      <th>2057</th>
      <th>2058</th>
      <th>2059</th>
      <th>2060</th>
      <th>2061</th>
      <th>2062</th>
      <th>2063</th>
      <th>2064</th>
      <th>2065</th>
      <th>2066</th>
      <th>2067</th>
      <th>2068</th>
      <th>2069</th>
      <th>2070</th>
      <th>2071</th>
      <th>2072</th>
      <th>2073</th>
      <th>2074</th>
      <th>2075</th>
      <th>2076</th>
      <th>2077</th>
      <th>2078</th>
      <th>2079</th>
      <th>2080</th>
      <th>2081</th>
      <th>2082</th>
      <th>2083</th>
      <th>2084</th>
      <th>2085</th>
      <th>2086</th>
      <th>2087</th>
      <th>2088</th>
      <th>2089</th>
      <th>2090</th>
      <th>2091</th>
      <th>2092</th>
      <th>2093</th>
      <th>2094</th>
      <th>2095</th>
      <th>2096</th>
      <th>2097</th>
      <th>2098</th>
      <th>2099</th>
      <th>2100</th>
      <th>2101</th>
      <th>2102</th>
      <th>2103</th>
      <th>2104</th>
      <th>2105</th>
      <th>2106</th>
      <th>2107</th>
      <th>2108</th>
      <th>2109</th>
      <th>2110</th>
      <th>2111</th>
      <th>2112</th>
      <th>2113</th>
      <th>2114</th>
      <th>2115</th>
      <th>2116</th>
      <th>2117</th>
      <th>2118</th>
      <th>2119</th>
      <th>2120</th>
      <th>2121</th>
      <th>2122</th>
      <th>2123</th>
      <th>2124</th>
      <th>2125</th>
      <th>2126</th>
      <th>2127</th>
      <th>2128</th>
      <th>2129</th>
      <th>2130</th>
      <th>2131</th>
      <th>2132</th>
      <th>2133</th>
      <th>2134</th>
      <th>2135</th>
      <th>2136</th>
      <th>2137</th>
      <th>2138</th>
      <th>2139</th>
      <th>2140</th>
      <th>2141</th>
      <th>2142</th>
      <th>2143</th>
      <th>2144</th>
      <th>2145</th>
      <th>2146</th>
      <th>2147</th>
      <th>2148</th>
      <th>2149</th>
      <th>2150</th>
      <th>2151</th>
      <th>2152</th>
      <th>2153</th>
      <th>2154</th>
      <th>2155</th>
      <th>2156</th>
      <th>2157</th>
      <th>2158</th>
      <th>2159</th>
      <th>2160</th>
      <th>2161</th>
      <th>2162</th>
      <th>2163</th>
      <th>2164</th>
      <th>2165</th>
      <th>2166</th>
      <th>2167</th>
      <th>2168</th>
      <th>2169</th>
      <th>2170</th>
      <th>2171</th>
      <th>2172</th>
      <th>2173</th>
      <th>2174</th>
      <th>2175</th>
      <th>2176</th>
      <th>2177</th>
      <th>2178</th>
      <th>2179</th>
      <th>2180</th>
      <th>2181</th>
      <th>2182</th>
      <th>2183</th>
      <th>2184</th>
      <th>2185</th>
      <th>2186</th>
      <th>2187</th>
      <th>2188</th>
      <th>2189</th>
      <th>2190</th>
      <th>2191</th>
      <th>2192</th>
      <th>2193</th>
      <th>2194</th>
      <th>2195</th>
      <th>2196</th>
      <th>2197</th>
      <th>2198</th>
      <th>2199</th>
      <th>2200</th>
      <th>2201</th>
      <th>2202</th>
      <th>2203</th>
      <th>2204</th>
      <th>2205</th>
      <th>2206</th>
      <th>2207</th>
      <th>2208</th>
      <th>2209</th>
      <th>2210</th>
      <th>2211</th>
      <th>2212</th>
      <th>2213</th>
      <th>2214</th>
      <th>2215</th>
      <th>2216</th>
      <th>2217</th>
      <th>2218</th>
      <th>2219</th>
      <th>2220</th>
      <th>2221</th>
      <th>2222</th>
      <th>2223</th>
      <th>2224</th>
      <th>2225</th>
      <th>2226</th>
      <th>2227</th>
      <th>2228</th>
      <th>2229</th>
      <th>2230</th>
      <th>2231</th>
      <th>2232</th>
      <th>2233</th>
      <th>2234</th>
      <th>2235</th>
      <th>2236</th>
      <th>2237</th>
      <th>2238</th>
      <th>2239</th>
      <th>2240</th>
      <th>2241</th>
      <th>2242</th>
      <th>2243</th>
      <th>2244</th>
      <th>2245</th>
      <th>2246</th>
      <th>2247</th>
      <th>2248</th>
      <th>2249</th>
      <th>2250</th>
      <th>2251</th>
      <th>2252</th>
      <th>2253</th>
      <th>2254</th>
      <th>2255</th>
      <th>2256</th>
      <th>2257</th>
      <th>2258</th>
      <th>2259</th>
      <th>2260</th>
      <th>2261</th>
      <th>2262</th>
      <th>2263</th>
      <th>2264</th>
      <th>2265</th>
      <th>2266</th>
      <th>2267</th>
      <th>2268</th>
      <th>2269</th>
      <th>2270</th>
      <th>2271</th>
      <th>2272</th>
      <th>2273</th>
      <th>2274</th>
      <th>2275</th>
      <th>2276</th>
      <th>2277</th>
      <th>2278</th>
      <th>2279</th>
      <th>2280</th>
      <th>2281</th>
      <th>2282</th>
      <th>2283</th>
      <th>2284</th>
      <th>2285</th>
      <th>2286</th>
      <th>2287</th>
      <th>2288</th>
      <th>2289</th>
      <th>2290</th>
      <th>2291</th>
      <th>2292</th>
      <th>2293</th>
      <th>2294</th>
      <th>2295</th>
      <th>2296</th>
      <th>2297</th>
      <th>2298</th>
      <th>2299</th>
      <th>2300</th>
      <th>2301</th>
      <th>2302</th>
      <th>2303</th>
      <th>2304</th>
      <th>2305</th>
      <th>2306</th>
      <th>2307</th>
      <th>2308</th>
      <th>2309</th>
      <th>2310</th>
      <th>2311</th>
      <th>2312</th>
      <th>2313</th>
      <th>2314</th>
      <th>2315</th>
      <th>2316</th>
      <th>2317</th>
      <th>2318</th>
      <th>2319</th>
      <th>2320</th>
      <th>2321</th>
      <th>2322</th>
      <th>2323</th>
      <th>2324</th>
      <th>2325</th>
      <th>2326</th>
      <th>2327</th>
      <th>2328</th>
      <th>2329</th>
      <th>2330</th>
      <th>2331</th>
      <th>2332</th>
      <th>2333</th>
      <th>2334</th>
      <th>2335</th>
      <th>2336</th>
      <th>2337</th>
      <th>2338</th>
      <th>2339</th>
      <th>2340</th>
      <th>2341</th>
      <th>2342</th>
      <th>2343</th>
      <th>2344</th>
      <th>2345</th>
      <th>2346</th>
      <th>2347</th>
      <th>2348</th>
      <th>2349</th>
      <th>2350</th>
      <th>2351</th>
      <th>2352</th>
      <th>2353</th>
      <th>2354</th>
      <th>2355</th>
      <th>2356</th>
      <th>2357</th>
      <th>2358</th>
      <th>2359</th>
      <th>2360</th>
      <th>2361</th>
      <th>2362</th>
      <th>2363</th>
      <th>2364</th>
      <th>2365</th>
      <th>2366</th>
      <th>2367</th>
      <th>2368</th>
      <th>2369</th>
      <th>2370</th>
      <th>2371</th>
      <th>2372</th>
      <th>2373</th>
      <th>2374</th>
      <th>2375</th>
      <th>2376</th>
      <th>2377</th>
      <th>2378</th>
      <th>2379</th>
      <th>2380</th>
      <th>2381</th>
      <th>2382</th>
      <th>2383</th>
      <th>2384</th>
      <th>2385</th>
      <th>2386</th>
      <th>2387</th>
      <th>2388</th>
      <th>2389</th>
      <th>2390</th>
      <th>2391</th>
      <th>2392</th>
      <th>2393</th>
      <th>2394</th>
      <th>2395</th>
      <th>2396</th>
      <th>2397</th>
      <th>2398</th>
      <th>2399</th>
      <th>2400</th>
      <th>2401</th>
      <th>2402</th>
      <th>2403</th>
      <th>2404</th>
      <th>2405</th>
      <th>2406</th>
      <th>2407</th>
      <th>2408</th>
      <th>2409</th>
      <th>2410</th>
      <th>2411</th>
      <th>2412</th>
      <th>2413</th>
      <th>2414</th>
      <th>2415</th>
      <th>2416</th>
      <th>2417</th>
      <th>2418</th>
      <th>2419</th>
      <th>2420</th>
      <th>2421</th>
      <th>2422</th>
      <th>2423</th>
      <th>2424</th>
      <th>2425</th>
      <th>2426</th>
      <th>2427</th>
      <th>2428</th>
      <th>2429</th>
      <th>2430</th>
      <th>2431</th>
      <th>2432</th>
      <th>2433</th>
      <th>2434</th>
      <th>2435</th>
      <th>2436</th>
      <th>2437</th>
      <th>2438</th>
      <th>2439</th>
      <th>2440</th>
      <th>2441</th>
      <th>2442</th>
      <th>2443</th>
      <th>2444</th>
      <th>2445</th>
      <th>2446</th>
      <th>2447</th>
      <th>2448</th>
      <th>2449</th>
      <th>2450</th>
      <th>2451</th>
      <th>2452</th>
      <th>2453</th>
      <th>2454</th>
      <th>2455</th>
      <th>2456</th>
      <th>2457</th>
      <th>2458</th>
      <th>2459</th>
      <th>2460</th>
      <th>2461</th>
      <th>2462</th>
      <th>2463</th>
      <th>2464</th>
      <th>2465</th>
      <th>2466</th>
      <th>2467</th>
      <th>2468</th>
      <th>2469</th>
      <th>2470</th>
      <th>2471</th>
      <th>2472</th>
      <th>2473</th>
      <th>2474</th>
      <th>2475</th>
      <th>2476</th>
      <th>2477</th>
      <th>2478</th>
      <th>2479</th>
      <th>2480</th>
      <th>2481</th>
      <th>2482</th>
      <th>2483</th>
      <th>2484</th>
      <th>2485</th>
      <th>2486</th>
      <th>2487</th>
      <th>2488</th>
      <th>2489</th>
      <th>2490</th>
      <th>2491</th>
      <th>2492</th>
      <th>2493</th>
      <th>2494</th>
      <th>2495</th>
      <th>2496</th>
      <th>2497</th>
      <th>2498</th>
      <th>2499</th>
      <th>2500</th>
      <th>2501</th>
      <th>2502</th>
      <th>2503</th>
      <th>2504</th>
      <th>2505</th>
      <th>2506</th>
      <th>2507</th>
      <th>2508</th>
      <th>2509</th>
      <th>2510</th>
      <th>2511</th>
      <th>2512</th>
      <th>2513</th>
      <th>2514</th>
      <th>2515</th>
      <th>2516</th>
      <th>2517</th>
      <th>2518</th>
      <th>2519</th>
      <th>2520</th>
      <th>2521</th>
      <th>2522</th>
      <th>2523</th>
      <th>2524</th>
      <th>2525</th>
      <th>2526</th>
      <th>2527</th>
      <th>2528</th>
      <th>2529</th>
      <th>2530</th>
      <th>2531</th>
      <th>2532</th>
      <th>2533</th>
      <th>2534</th>
      <th>2535</th>
      <th>2536</th>
      <th>2537</th>
      <th>2538</th>
      <th>2539</th>
      <th>2540</th>
      <th>2541</th>
      <th>2542</th>
      <th>2543</th>
      <th>2544</th>
      <th>2545</th>
      <th>2546</th>
      <th>2547</th>
      <th>2548</th>
      <th>2549</th>
      <th>2550</th>
      <th>2551</th>
      <th>2552</th>
      <th>2553</th>
      <th>2554</th>
      <th>2555</th>
      <th>2556</th>
      <th>2557</th>
      <th>2558</th>
      <th>2559</th>
      <th>2560</th>
      <th>2561</th>
      <th>2562</th>
      <th>2563</th>
      <th>2564</th>
      <th>2565</th>
      <th>2566</th>
      <th>2567</th>
      <th>2568</th>
      <th>2569</th>
      <th>2570</th>
      <th>2571</th>
      <th>2572</th>
      <th>2573</th>
      <th>2574</th>
      <th>2575</th>
      <th>2576</th>
      <th>2577</th>
      <th>2578</th>
      <th>2579</th>
      <th>2580</th>
      <th>2581</th>
      <th>2582</th>
      <th>2583</th>
      <th>2584</th>
      <th>2585</th>
      <th>2586</th>
      <th>2587</th>
      <th>2588</th>
      <th>2589</th>
      <th>2590</th>
      <th>2591</th>
      <th>2592</th>
      <th>2593</th>
      <th>2594</th>
      <th>2595</th>
      <th>2596</th>
      <th>2597</th>
      <th>2598</th>
      <th>2599</th>
      <th>2600</th>
      <th>2601</th>
      <th>2602</th>
      <th>2603</th>
      <th>2604</th>
      <th>2605</th>
      <th>2606</th>
      <th>2607</th>
      <th>2608</th>
      <th>2609</th>
      <th>2610</th>
      <th>2611</th>
      <th>2612</th>
      <th>2613</th>
      <th>2614</th>
      <th>2615</th>
      <th>2616</th>
      <th>2617</th>
      <th>2618</th>
      <th>2619</th>
      <th>2620</th>
      <th>2621</th>
      <th>2622</th>
      <th>2623</th>
      <th>2624</th>
      <th>2625</th>
      <th>2626</th>
      <th>2627</th>
      <th>2628</th>
      <th>2629</th>
      <th>2630</th>
      <th>2631</th>
      <th>2632</th>
      <th>2633</th>
      <th>2634</th>
      <th>2635</th>
      <th>2636</th>
      <th>2637</th>
      <th>2638</th>
      <th>2639</th>
      <th>2640</th>
      <th>2641</th>
      <th>2642</th>
      <th>2643</th>
      <th>2644</th>
      <th>2645</th>
      <th>2646</th>
      <th>2647</th>
      <th>2648</th>
      <th>2649</th>
      <th>2650</th>
      <th>2651</th>
      <th>2652</th>
      <th>2653</th>
      <th>2654</th>
      <th>2655</th>
      <th>2656</th>
      <th>2657</th>
      <th>2658</th>
      <th>2659</th>
      <th>2660</th>
      <th>2661</th>
      <th>2662</th>
      <th>2663</th>
      <th>2664</th>
      <th>2665</th>
      <th>2666</th>
      <th>2667</th>
      <th>2668</th>
      <th>2669</th>
      <th>2670</th>
      <th>2671</th>
      <th>2672</th>
      <th>2673</th>
      <th>2674</th>
      <th>2675</th>
      <th>2676</th>
      <th>2677</th>
      <th>2678</th>
      <th>2679</th>
      <th>2680</th>
      <th>2681</th>
      <th>2682</th>
      <th>2683</th>
      <th>2684</th>
      <th>2685</th>
      <th>2686</th>
      <th>2687</th>
      <th>2688</th>
      <th>2689</th>
      <th>2690</th>
      <th>2691</th>
      <th>2692</th>
      <th>2693</th>
      <th>2694</th>
      <th>2695</th>
      <th>2696</th>
      <th>2697</th>
      <th>2698</th>
      <th>2699</th>
      <th>2700</th>
      <th>2701</th>
      <th>2702</th>
      <th>2703</th>
      <th>2704</th>
      <th>2705</th>
      <th>2706</th>
      <th>2707</th>
      <th>2708</th>
      <th>2709</th>
      <th>2710</th>
      <th>2711</th>
      <th>2712</th>
      <th>2713</th>
      <th>2714</th>
      <th>2715</th>
      <th>2716</th>
      <th>2717</th>
      <th>2718</th>
      <th>2719</th>
      <th>2720</th>
      <th>2721</th>
      <th>2722</th>
      <th>2723</th>
      <th>2724</th>
      <th>2725</th>
      <th>2726</th>
      <th>2727</th>
      <th>2728</th>
      <th>2729</th>
      <th>2730</th>
      <th>2731</th>
      <th>2732</th>
      <th>2733</th>
      <th>2734</th>
      <th>2735</th>
      <th>2736</th>
      <th>2737</th>
      <th>2738</th>
      <th>2739</th>
      <th>2740</th>
      <th>2741</th>
      <th>2742</th>
      <th>2743</th>
      <th>2744</th>
      <th>2745</th>
      <th>2746</th>
      <th>2747</th>
      <th>2748</th>
      <th>2749</th>
      <th>2750</th>
      <th>2751</th>
      <th>2752</th>
      <th>2753</th>
      <th>2754</th>
      <th>2755</th>
      <th>2756</th>
      <th>2757</th>
      <th>2758</th>
      <th>2759</th>
      <th>2760</th>
      <th>2761</th>
      <th>2762</th>
      <th>2763</th>
      <th>2764</th>
      <th>2765</th>
      <th>2766</th>
      <th>2767</th>
      <th>2768</th>
      <th>2769</th>
      <th>2770</th>
      <th>2771</th>
      <th>2772</th>
      <th>2773</th>
      <th>2774</th>
      <th>2775</th>
      <th>2776</th>
      <th>2777</th>
      <th>2778</th>
      <th>2779</th>
      <th>2780</th>
      <th>2781</th>
      <th>2782</th>
      <th>2783</th>
      <th>2784</th>
      <th>2785</th>
      <th>2786</th>
      <th>2787</th>
      <th>2788</th>
      <th>2789</th>
      <th>2790</th>
      <th>2791</th>
      <th>2792</th>
      <th>2793</th>
      <th>2794</th>
      <th>2795</th>
      <th>2796</th>
      <th>2797</th>
      <th>2798</th>
      <th>2799</th>
      <th>2800</th>
      <th>2801</th>
      <th>2802</th>
      <th>2803</th>
      <th>2804</th>
      <th>2805</th>
      <th>2806</th>
      <th>2807</th>
      <th>2808</th>
      <th>2809</th>
      <th>2810</th>
      <th>2811</th>
      <th>2812</th>
      <th>2813</th>
      <th>2814</th>
      <th>2815</th>
      <th>2816</th>
      <th>2817</th>
      <th>2818</th>
      <th>2819</th>
      <th>2820</th>
      <th>2821</th>
      <th>2822</th>
      <th>2823</th>
      <th>2824</th>
      <th>2825</th>
      <th>2826</th>
      <th>2827</th>
      <th>2828</th>
      <th>2829</th>
      <th>2830</th>
      <th>2831</th>
      <th>2832</th>
      <th>2833</th>
      <th>2834</th>
      <th>2835</th>
      <th>2836</th>
      <th>2837</th>
      <th>2838</th>
      <th>2839</th>
      <th>2840</th>
      <th>2841</th>
      <th>2842</th>
      <th>2843</th>
      <th>2844</th>
      <th>2845</th>
      <th>2846</th>
      <th>2847</th>
      <th>2848</th>
      <th>2849</th>
      <th>2850</th>
      <th>2851</th>
      <th>2852</th>
      <th>2853</th>
      <th>2854</th>
      <th>2855</th>
      <th>2856</th>
      <th>2857</th>
      <th>2858</th>
      <th>2859</th>
      <th>2860</th>
      <th>2861</th>
      <th>2862</th>
      <th>2863</th>
      <th>2864</th>
      <th>2865</th>
      <th>2866</th>
      <th>2867</th>
      <th>2868</th>
      <th>2869</th>
      <th>2870</th>
      <th>2871</th>
      <th>2872</th>
      <th>2873</th>
      <th>2874</th>
      <th>2875</th>
      <th>2876</th>
      <th>2877</th>
      <th>2878</th>
      <th>2879</th>
      <th>2880</th>
      <th>2881</th>
      <th>2882</th>
      <th>2883</th>
      <th>2884</th>
      <th>2885</th>
      <th>2886</th>
      <th>2887</th>
      <th>2888</th>
      <th>2889</th>
      <th>2890</th>
      <th>2891</th>
      <th>2892</th>
      <th>2893</th>
      <th>2894</th>
      <th>2895</th>
      <th>2896</th>
      <th>2897</th>
      <th>2898</th>
      <th>2899</th>
      <th>2900</th>
      <th>2901</th>
      <th>2902</th>
      <th>2903</th>
      <th>2904</th>
      <th>2905</th>
      <th>2906</th>
      <th>2907</th>
      <th>2908</th>
      <th>2909</th>
      <th>2910</th>
      <th>2911</th>
      <th>2912</th>
      <th>2913</th>
      <th>2914</th>
      <th>2915</th>
      <th>2916</th>
      <th>2917</th>
      <th>2918</th>
      <th>2919</th>
      <th>2920</th>
      <th>2921</th>
      <th>2922</th>
      <th>2923</th>
      <th>2924</th>
      <th>2925</th>
      <th>2926</th>
      <th>2927</th>
      <th>2928</th>
      <th>2929</th>
      <th>2930</th>
      <th>2931</th>
      <th>2932</th>
      <th>2933</th>
      <th>2934</th>
      <th>2935</th>
      <th>2936</th>
      <th>2937</th>
      <th>2938</th>
      <th>2939</th>
      <th>2940</th>
      <th>2941</th>
      <th>2942</th>
      <th>2943</th>
      <th>2944</th>
      <th>2945</th>
      <th>2946</th>
      <th>2947</th>
      <th>2948</th>
      <th>2949</th>
      <th>2950</th>
      <th>2951</th>
      <th>2952</th>
      <th>2953</th>
      <th>2954</th>
      <th>2955</th>
      <th>2956</th>
      <th>2957</th>
      <th>2958</th>
      <th>2959</th>
      <th>2960</th>
      <th>2961</th>
      <th>2962</th>
      <th>2963</th>
      <th>2964</th>
      <th>2965</th>
      <th>2966</th>
      <th>2967</th>
      <th>2968</th>
      <th>2969</th>
      <th>2970</th>
      <th>2971</th>
      <th>2972</th>
      <th>2973</th>
      <th>2974</th>
      <th>2975</th>
      <th>2976</th>
      <th>2977</th>
      <th>2978</th>
      <th>2979</th>
      <th>2980</th>
      <th>2981</th>
      <th>2982</th>
      <th>2983</th>
      <th>2984</th>
      <th>2985</th>
      <th>2986</th>
      <th>2987</th>
      <th>2988</th>
      <th>2989</th>
      <th>2990</th>
      <th>2991</th>
      <th>2992</th>
      <th>2993</th>
      <th>2994</th>
      <th>2995</th>
      <th>2996</th>
      <th>2997</th>
      <th>2998</th>
      <th>2999</th>
      <th>3000</th>
      <th>3001</th>
      <th>3002</th>
      <th>3003</th>
      <th>3004</th>
      <th>3005</th>
      <th>3006</th>
      <th>3007</th>
      <th>3008</th>
      <th>3009</th>
      <th>3010</th>
      <th>3011</th>
      <th>3012</th>
      <th>3013</th>
      <th>3014</th>
      <th>3015</th>
      <th>3016</th>
      <th>3017</th>
      <th>3018</th>
      <th>3019</th>
      <th>3020</th>
      <th>3021</th>
      <th>3022</th>
      <th>3023</th>
      <th>3024</th>
      <th>3025</th>
      <th>3026</th>
      <th>3027</th>
      <th>3028</th>
      <th>3029</th>
      <th>3030</th>
      <th>3031</th>
      <th>3032</th>
      <th>3033</th>
      <th>3034</th>
      <th>3035</th>
      <th>3036</th>
      <th>3037</th>
      <th>3038</th>
      <th>3039</th>
      <th>3040</th>
      <th>3041</th>
      <th>3042</th>
      <th>3043</th>
      <th>3044</th>
      <th>3045</th>
      <th>3046</th>
      <th>3047</th>
      <th>3048</th>
      <th>3049</th>
      <th>3050</th>
      <th>3051</th>
      <th>3052</th>
      <th>3053</th>
      <th>3054</th>
      <th>3055</th>
      <th>3056</th>
      <th>3057</th>
      <th>3058</th>
      <th>3059</th>
      <th>3060</th>
      <th>3061</th>
      <th>3062</th>
      <th>3063</th>
      <th>3064</th>
      <th>3065</th>
      <th>3066</th>
      <th>3067</th>
      <th>3068</th>
      <th>3069</th>
      <th>3070</th>
      <th>3071</th>
      <th>3072</th>
      <th>3073</th>
      <th>3074</th>
      <th>3075</th>
      <th>3076</th>
      <th>3077</th>
      <th>3078</th>
      <th>3079</th>
      <th>3080</th>
      <th>3081</th>
      <th>3082</th>
      <th>3083</th>
      <th>3084</th>
      <th>3085</th>
      <th>3086</th>
      <th>3087</th>
      <th>3088</th>
      <th>3089</th>
      <th>3090</th>
      <th>3091</th>
      <th>3092</th>
      <th>3093</th>
      <th>3094</th>
      <th>3095</th>
      <th>3096</th>
      <th>3097</th>
      <th>3098</th>
      <th>3099</th>
      <th>3100</th>
      <th>3101</th>
      <th>3102</th>
      <th>3103</th>
      <th>3104</th>
      <th>3105</th>
      <th>3106</th>
      <th>3107</th>
      <th>3108</th>
      <th>3109</th>
      <th>3110</th>
      <th>3111</th>
      <th>3112</th>
      <th>3113</th>
      <th>3114</th>
      <th>3115</th>
      <th>3116</th>
      <th>3117</th>
      <th>3118</th>
      <th>3119</th>
      <th>3120</th>
      <th>3121</th>
      <th>3122</th>
      <th>3123</th>
      <th>3124</th>
      <th>3125</th>
      <th>3126</th>
      <th>3127</th>
      <th>3128</th>
      <th>3129</th>
      <th>3130</th>
      <th>3131</th>
      <th>3132</th>
      <th>3133</th>
      <th>3134</th>
      <th>3135</th>
      <th>3136</th>
      <th>3137</th>
      <th>3138</th>
      <th>3139</th>
      <th>3140</th>
      <th>3141</th>
      <th>3142</th>
      <th>3143</th>
      <th>3144</th>
      <th>3145</th>
      <th>3146</th>
      <th>3147</th>
      <th>3148</th>
      <th>3149</th>
      <th>3150</th>
      <th>3151</th>
      <th>3152</th>
      <th>3153</th>
      <th>3154</th>
      <th>3155</th>
      <th>3156</th>
      <th>3157</th>
      <th>3158</th>
      <th>3159</th>
      <th>3160</th>
      <th>3161</th>
      <th>3162</th>
      <th>3163</th>
      <th>3164</th>
      <th>3165</th>
      <th>3166</th>
      <th>3167</th>
      <th>3168</th>
      <th>3169</th>
      <th>3170</th>
      <th>3171</th>
      <th>3172</th>
      <th>3173</th>
      <th>3174</th>
      <th>3175</th>
      <th>3176</th>
      <th>3177</th>
      <th>3178</th>
      <th>3179</th>
      <th>3180</th>
      <th>3181</th>
      <th>3182</th>
      <th>3183</th>
      <th>3184</th>
      <th>3185</th>
      <th>3186</th>
      <th>3187</th>
      <th>3188</th>
      <th>3189</th>
      <th>3190</th>
      <th>3191</th>
      <th>3192</th>
      <th>3193</th>
      <th>3194</th>
      <th>3195</th>
      <th>3196</th>
      <th>3197</th>
      <th>3198</th>
      <th>3199</th>
      <th>3200</th>
      <th>3201</th>
      <th>3202</th>
      <th>3203</th>
      <th>3204</th>
      <th>3205</th>
      <th>3206</th>
      <th>3207</th>
      <th>3208</th>
      <th>3209</th>
      <th>3210</th>
      <th>3211</th>
      <th>3212</th>
      <th>3213</th>
      <th>3214</th>
      <th>3215</th>
      <th>3216</th>
      <th>3217</th>
      <th>3218</th>
      <th>3219</th>
      <th>3220</th>
      <th>3221</th>
      <th>3222</th>
      <th>3223</th>
      <th>3224</th>
      <th>3225</th>
      <th>3226</th>
      <th>3227</th>
      <th>3228</th>
      <th>3229</th>
      <th>3230</th>
      <th>3231</th>
      <th>3232</th>
      <th>3233</th>
      <th>3234</th>
      <th>3235</th>
      <th>3236</th>
      <th>3237</th>
      <th>3238</th>
      <th>3239</th>
      <th>3240</th>
      <th>3241</th>
      <th>3242</th>
      <th>3243</th>
      <th>3244</th>
      <th>3245</th>
      <th>3246</th>
      <th>3247</th>
      <th>3248</th>
      <th>3249</th>
      <th>3250</th>
      <th>3251</th>
      <th>3252</th>
      <th>3253</th>
      <th>3254</th>
      <th>3255</th>
      <th>3256</th>
      <th>3257</th>
      <th>3258</th>
      <th>3259</th>
      <th>3260</th>
      <th>3261</th>
      <th>3262</th>
      <th>3263</th>
      <th>3264</th>
      <th>3265</th>
      <th>3266</th>
      <th>3267</th>
      <th>3268</th>
      <th>3269</th>
      <th>3270</th>
      <th>3271</th>
      <th>3272</th>
      <th>3273</th>
      <th>3274</th>
      <th>3275</th>
      <th>3276</th>
      <th>3277</th>
      <th>3278</th>
      <th>3279</th>
      <th>3280</th>
      <th>3281</th>
      <th>3282</th>
      <th>3283</th>
      <th>3284</th>
      <th>3285</th>
      <th>3286</th>
      <th>3287</th>
      <th>3288</th>
      <th>3289</th>
      <th>3290</th>
      <th>3291</th>
      <th>3292</th>
      <th>3293</th>
      <th>3294</th>
      <th>3295</th>
      <th>3296</th>
      <th>3297</th>
      <th>3298</th>
      <th>3299</th>
      <th>3300</th>
      <th>3301</th>
      <th>3302</th>
      <th>3303</th>
      <th>3304</th>
      <th>3305</th>
      <th>3306</th>
      <th>3307</th>
      <th>3308</th>
      <th>3309</th>
      <th>3310</th>
      <th>3311</th>
      <th>3312</th>
      <th>3313</th>
      <th>3314</th>
      <th>3315</th>
      <th>3316</th>
      <th>3317</th>
      <th>3318</th>
      <th>3319</th>
      <th>3320</th>
      <th>3321</th>
      <th>3322</th>
      <th>3323</th>
      <th>3324</th>
      <th>3325</th>
      <th>3326</th>
      <th>3327</th>
      <th>3328</th>
      <th>3329</th>
      <th>3330</th>
      <th>3331</th>
      <th>3332</th>
      <th>3333</th>
      <th>3334</th>
      <th>3335</th>
      <th>3336</th>
      <th>3337</th>
      <th>3338</th>
      <th>3339</th>
      <th>3340</th>
      <th>3341</th>
      <th>3342</th>
      <th>3343</th>
      <th>3344</th>
      <th>3345</th>
      <th>3346</th>
      <th>3347</th>
      <th>3348</th>
      <th>3349</th>
      <th>3350</th>
      <th>3351</th>
      <th>3352</th>
      <th>3353</th>
      <th>3354</th>
      <th>3355</th>
      <th>3356</th>
      <th>3357</th>
      <th>3358</th>
      <th>3359</th>
      <th>3360</th>
      <th>3361</th>
      <th>3362</th>
      <th>3363</th>
      <th>3364</th>
      <th>3365</th>
      <th>3366</th>
      <th>3367</th>
      <th>3368</th>
      <th>3369</th>
      <th>3370</th>
      <th>3371</th>
      <th>3372</th>
      <th>3373</th>
      <th>3374</th>
      <th>3375</th>
      <th>3376</th>
      <th>3377</th>
      <th>3378</th>
      <th>3379</th>
      <th>3380</th>
      <th>3381</th>
      <th>3382</th>
      <th>3383</th>
      <th>3384</th>
      <th>3385</th>
      <th>3386</th>
      <th>3387</th>
      <th>3388</th>
      <th>3389</th>
      <th>3390</th>
      <th>3391</th>
      <th>3392</th>
      <th>3393</th>
      <th>3394</th>
      <th>3395</th>
      <th>3396</th>
      <th>3397</th>
      <th>3398</th>
      <th>3399</th>
      <th>3400</th>
      <th>3401</th>
      <th>3402</th>
      <th>3403</th>
      <th>3404</th>
      <th>3405</th>
      <th>3406</th>
      <th>3407</th>
      <th>3408</th>
      <th>3409</th>
      <th>3410</th>
      <th>3411</th>
      <th>3412</th>
      <th>3413</th>
      <th>3414</th>
      <th>3415</th>
      <th>3416</th>
      <th>3417</th>
      <th>3418</th>
      <th>3419</th>
      <th>3420</th>
      <th>3421</th>
      <th>3422</th>
      <th>3423</th>
      <th>3424</th>
      <th>3425</th>
      <th>3426</th>
      <th>3427</th>
      <th>3428</th>
      <th>3429</th>
      <th>3430</th>
      <th>3431</th>
      <th>3432</th>
      <th>3433</th>
      <th>3434</th>
      <th>3435</th>
      <th>3436</th>
      <th>3437</th>
      <th>3438</th>
      <th>3439</th>
      <th>3440</th>
      <th>3441</th>
      <th>3442</th>
      <th>3443</th>
      <th>3444</th>
      <th>3445</th>
      <th>3446</th>
      <th>3447</th>
      <th>3448</th>
      <th>3449</th>
      <th>3450</th>
      <th>3451</th>
      <th>3452</th>
      <th>3453</th>
      <th>3454</th>
      <th>3455</th>
      <th>3456</th>
      <th>3457</th>
      <th>3458</th>
      <th>3459</th>
      <th>3460</th>
      <th>3461</th>
      <th>3462</th>
      <th>3463</th>
      <th>3464</th>
      <th>3465</th>
      <th>3466</th>
      <th>3467</th>
      <th>3468</th>
      <th>3469</th>
      <th>3470</th>
      <th>3471</th>
      <th>3472</th>
      <th>3473</th>
      <th>3474</th>
      <th>3475</th>
      <th>3476</th>
      <th>3477</th>
      <th>3478</th>
      <th>3479</th>
      <th>3480</th>
      <th>3481</th>
      <th>3482</th>
      <th>3483</th>
      <th>3484</th>
      <th>3485</th>
      <th>3486</th>
      <th>3487</th>
      <th>3488</th>
      <th>3489</th>
      <th>3490</th>
      <th>3491</th>
      <th>3492</th>
      <th>3493</th>
      <th>3494</th>
      <th>3495</th>
      <th>3496</th>
      <th>3497</th>
      <th>3498</th>
      <th>3499</th>
      <th>3500</th>
      <th>3501</th>
      <th>3502</th>
      <th>3503</th>
      <th>3504</th>
      <th>3505</th>
      <th>3506</th>
      <th>3507</th>
      <th>3508</th>
      <th>3509</th>
      <th>3510</th>
      <th>3511</th>
      <th>3512</th>
      <th>3513</th>
      <th>3514</th>
      <th>3515</th>
      <th>3516</th>
      <th>3517</th>
      <th>3518</th>
      <th>3519</th>
      <th>3520</th>
      <th>3521</th>
      <th>3522</th>
      <th>3523</th>
      <th>3524</th>
      <th>3525</th>
      <th>3526</th>
      <th>3527</th>
      <th>3528</th>
      <th>3529</th>
      <th>3530</th>
      <th>3531</th>
      <th>3532</th>
      <th>3533</th>
      <th>3534</th>
      <th>3535</th>
      <th>3536</th>
      <th>3537</th>
      <th>3538</th>
      <th>3539</th>
      <th>3540</th>
      <th>3541</th>
      <th>3542</th>
      <th>3543</th>
      <th>3544</th>
      <th>3545</th>
      <th>3546</th>
      <th>3547</th>
      <th>3548</th>
      <th>3549</th>
      <th>3550</th>
      <th>3551</th>
      <th>3552</th>
      <th>3553</th>
      <th>3554</th>
      <th>3555</th>
      <th>3556</th>
      <th>3557</th>
      <th>3558</th>
      <th>3559</th>
      <th>3560</th>
      <th>3561</th>
      <th>3562</th>
      <th>3563</th>
      <th>3564</th>
      <th>3565</th>
      <th>3566</th>
      <th>3567</th>
      <th>3568</th>
      <th>3569</th>
      <th>3570</th>
      <th>3571</th>
      <th>3572</th>
      <th>3573</th>
      <th>3574</th>
      <th>3575</th>
      <th>3576</th>
      <th>3577</th>
      <th>3578</th>
      <th>3579</th>
      <th>3580</th>
      <th>3581</th>
      <th>3582</th>
      <th>3583</th>
      <th>3584</th>
      <th>3585</th>
      <th>3586</th>
      <th>3587</th>
      <th>3588</th>
      <th>3589</th>
      <th>3590</th>
      <th>3591</th>
      <th>3592</th>
      <th>3593</th>
      <th>3594</th>
      <th>3595</th>
      <th>3596</th>
      <th>3597</th>
      <th>3598</th>
      <th>3599</th>
      <th>3600</th>
      <th>3601</th>
      <th>3602</th>
      <th>3603</th>
      <th>3604</th>
      <th>3605</th>
      <th>3606</th>
      <th>3607</th>
      <th>3608</th>
      <th>3609</th>
      <th>3610</th>
      <th>3611</th>
      <th>3612</th>
      <th>3613</th>
      <th>3614</th>
      <th>3615</th>
      <th>3616</th>
      <th>3617</th>
      <th>3618</th>
      <th>3619</th>
      <th>3620</th>
      <th>3621</th>
      <th>3622</th>
      <th>3623</th>
      <th>3624</th>
      <th>3625</th>
      <th>3626</th>
      <th>3627</th>
      <th>3628</th>
      <th>3629</th>
      <th>3630</th>
      <th>3631</th>
      <th>3632</th>
      <th>3633</th>
      <th>3634</th>
      <th>3635</th>
      <th>3636</th>
      <th>3637</th>
      <th>3638</th>
      <th>3639</th>
      <th>3640</th>
      <th>3641</th>
      <th>3642</th>
      <th>3643</th>
      <th>3644</th>
      <th>3645</th>
      <th>3646</th>
      <th>3647</th>
      <th>3648</th>
      <th>3649</th>
      <th>3650</th>
      <th>3651</th>
      <th>3652</th>
      <th>3653</th>
      <th>3654</th>
      <th>3655</th>
      <th>3656</th>
      <th>3657</th>
      <th>3658</th>
      <th>3659</th>
      <th>3660</th>
      <th>3661</th>
      <th>3662</th>
      <th>3663</th>
      <th>3664</th>
      <th>3665</th>
      <th>3666</th>
      <th>3667</th>
      <th>3668</th>
      <th>3669</th>
      <th>3670</th>
      <th>3671</th>
      <th>3672</th>
      <th>3673</th>
      <th>3674</th>
      <th>3675</th>
      <th>3676</th>
      <th>3677</th>
      <th>3678</th>
      <th>3679</th>
      <th>3680</th>
      <th>3681</th>
      <th>3682</th>
      <th>3683</th>
      <th>3684</th>
      <th>3685</th>
      <th>3686</th>
      <th>3687</th>
      <th>3688</th>
      <th>3689</th>
      <th>3690</th>
      <th>3691</th>
      <th>3692</th>
      <th>3693</th>
      <th>3694</th>
      <th>3695</th>
      <th>3696</th>
      <th>3697</th>
      <th>3698</th>
      <th>3699</th>
      <th>3700</th>
      <th>3701</th>
      <th>3702</th>
      <th>3703</th>
      <th>3704</th>
      <th>3705</th>
      <th>3706</th>
      <th>3707</th>
      <th>3708</th>
      <th>3709</th>
      <th>3710</th>
      <th>3711</th>
      <th>3712</th>
      <th>3713</th>
      <th>3714</th>
      <th>3715</th>
      <th>3716</th>
      <th>3717</th>
      <th>3718</th>
      <th>3719</th>
      <th>3720</th>
      <th>3721</th>
      <th>3722</th>
      <th>3723</th>
      <th>3724</th>
      <th>3725</th>
      <th>3726</th>
      <th>3727</th>
      <th>3728</th>
      <th>3729</th>
      <th>3730</th>
      <th>3731</th>
      <th>3732</th>
      <th>3733</th>
      <th>3734</th>
      <th>3735</th>
      <th>3736</th>
      <th>3737</th>
      <th>3738</th>
      <th>3739</th>
      <th>3740</th>
      <th>3741</th>
      <th>3742</th>
      <th>3743</th>
      <th>3744</th>
      <th>3745</th>
      <th>3746</th>
      <th>3747</th>
      <th>3748</th>
      <th>3749</th>
      <th>3750</th>
      <th>3751</th>
      <th>3752</th>
      <th>3753</th>
      <th>3754</th>
      <th>3755</th>
      <th>3756</th>
      <th>3757</th>
      <th>3758</th>
      <th>3759</th>
      <th>3760</th>
      <th>3761</th>
      <th>3762</th>
      <th>3763</th>
      <th>3764</th>
      <th>3765</th>
      <th>3766</th>
      <th>3767</th>
      <th>3768</th>
      <th>3769</th>
      <th>3770</th>
      <th>3771</th>
      <th>3772</th>
      <th>3773</th>
      <th>3774</th>
      <th>3775</th>
      <th>3776</th>
      <th>3777</th>
      <th>3778</th>
      <th>3779</th>
      <th>3780</th>
      <th>3781</th>
      <th>3782</th>
      <th>3783</th>
      <th>3784</th>
      <th>3785</th>
      <th>3786</th>
      <th>3787</th>
      <th>3788</th>
      <th>3789</th>
      <th>3790</th>
      <th>3791</th>
      <th>3792</th>
      <th>3793</th>
      <th>3794</th>
      <th>3795</th>
      <th>3796</th>
      <th>3797</th>
      <th>3798</th>
      <th>3799</th>
      <th>3800</th>
      <th>3801</th>
      <th>3802</th>
      <th>3803</th>
      <th>3804</th>
      <th>3805</th>
      <th>3806</th>
      <th>3807</th>
      <th>3808</th>
      <th>3809</th>
      <th>3810</th>
      <th>3811</th>
      <th>3812</th>
      <th>3813</th>
      <th>3814</th>
      <th>3815</th>
      <th>3816</th>
      <th>3817</th>
      <th>3818</th>
      <th>3819</th>
      <th>3820</th>
      <th>3821</th>
      <th>3822</th>
      <th>3823</th>
      <th>3824</th>
      <th>3825</th>
      <th>3826</th>
      <th>3827</th>
      <th>3828</th>
      <th>3829</th>
      <th>3830</th>
      <th>3831</th>
      <th>3832</th>
      <th>3833</th>
      <th>3834</th>
      <th>3835</th>
      <th>3836</th>
      <th>3837</th>
      <th>3838</th>
      <th>3839</th>
      <th>3840</th>
      <th>3841</th>
      <th>3842</th>
      <th>3843</th>
      <th>3844</th>
      <th>3845</th>
      <th>3846</th>
      <th>3847</th>
      <th>3848</th>
      <th>3849</th>
      <th>3850</th>
      <th>3851</th>
      <th>3852</th>
      <th>3853</th>
      <th>3854</th>
      <th>3855</th>
      <th>3856</th>
      <th>3857</th>
      <th>3858</th>
      <th>3859</th>
      <th>3860</th>
      <th>3861</th>
      <th>3862</th>
      <th>3863</th>
      <th>3864</th>
      <th>3865</th>
      <th>3866</th>
      <th>3867</th>
      <th>3868</th>
      <th>3869</th>
      <th>3870</th>
      <th>3871</th>
      <th>3872</th>
      <th>3873</th>
      <th>3874</th>
      <th>3875</th>
      <th>3876</th>
      <th>3877</th>
      <th>3878</th>
      <th>3879</th>
      <th>3880</th>
      <th>3881</th>
      <th>3882</th>
      <th>3883</th>
      <th>3884</th>
      <th>3885</th>
      <th>3886</th>
      <th>3887</th>
      <th>3888</th>
      <th>3889</th>
      <th>3890</th>
      <th>3891</th>
      <th>3892</th>
      <th>3893</th>
      <th>3894</th>
      <th>3895</th>
      <th>3896</th>
      <th>3897</th>
      <th>3898</th>
      <th>3899</th>
      <th>3900</th>
      <th>3901</th>
      <th>3902</th>
      <th>3903</th>
      <th>3904</th>
      <th>3905</th>
      <th>3906</th>
      <th>3907</th>
      <th>3908</th>
      <th>3909</th>
      <th>3910</th>
      <th>3911</th>
      <th>3912</th>
      <th>3913</th>
      <th>3914</th>
      <th>3915</th>
      <th>3916</th>
      <th>3917</th>
      <th>3918</th>
      <th>3919</th>
      <th>3920</th>
      <th>3921</th>
      <th>3922</th>
      <th>3923</th>
      <th>3924</th>
      <th>3925</th>
      <th>3926</th>
      <th>3927</th>
      <th>3928</th>
      <th>3929</th>
      <th>3930</th>
      <th>3931</th>
      <th>3932</th>
      <th>3933</th>
      <th>3934</th>
      <th>3935</th>
      <th>3936</th>
      <th>3937</th>
      <th>3938</th>
      <th>3939</th>
      <th>3940</th>
      <th>3941</th>
      <th>3942</th>
      <th>3943</th>
      <th>3944</th>
      <th>3945</th>
      <th>3946</th>
      <th>3947</th>
      <th>3948</th>
      <th>3949</th>
      <th>3950</th>
      <th>3951</th>
      <th>3952</th>
      <th>3953</th>
      <th>3954</th>
      <th>3955</th>
      <th>3956</th>
      <th>3957</th>
      <th>3958</th>
      <th>3959</th>
      <th>3960</th>
      <th>3961</th>
      <th>3962</th>
      <th>3963</th>
      <th>3964</th>
      <th>3965</th>
      <th>3966</th>
      <th>3967</th>
      <th>3968</th>
      <th>3969</th>
      <th>3970</th>
      <th>3971</th>
      <th>3972</th>
      <th>3973</th>
      <th>3974</th>
      <th>3975</th>
      <th>3976</th>
      <th>3977</th>
      <th>3978</th>
      <th>3979</th>
      <th>3980</th>
      <th>3981</th>
      <th>3982</th>
      <th>3983</th>
      <th>3984</th>
      <th>3985</th>
      <th>3986</th>
      <th>3987</th>
      <th>3988</th>
      <th>3989</th>
      <th>3990</th>
      <th>3991</th>
      <th>3992</th>
      <th>3993</th>
      <th>3994</th>
      <th>3995</th>
      <th>3996</th>
      <th>3997</th>
      <th>3998</th>
      <th>3999</th>
      <th>4000</th>
      <th>4001</th>
      <th>4002</th>
      <th>4003</th>
      <th>4004</th>
      <th>4005</th>
      <th>4006</th>
      <th>4007</th>
      <th>4008</th>
      <th>4009</th>
      <th>4010</th>
      <th>4011</th>
      <th>4012</th>
      <th>4013</th>
      <th>4014</th>
      <th>4015</th>
      <th>4016</th>
      <th>4017</th>
      <th>4018</th>
      <th>4019</th>
      <th>4020</th>
      <th>4021</th>
      <th>4022</th>
      <th>4023</th>
      <th>4024</th>
      <th>4025</th>
      <th>4026</th>
      <th>4027</th>
      <th>4028</th>
      <th>4029</th>
      <th>4030</th>
      <th>4031</th>
      <th>4032</th>
      <th>4033</th>
      <th>4034</th>
      <th>4035</th>
      <th>4036</th>
      <th>4037</th>
      <th>4038</th>
      <th>4039</th>
      <th>4040</th>
      <th>4041</th>
      <th>4042</th>
      <th>4043</th>
      <th>4044</th>
      <th>4045</th>
      <th>4046</th>
      <th>4047</th>
      <th>4048</th>
      <th>4049</th>
      <th>4050</th>
      <th>4051</th>
      <th>4052</th>
      <th>4053</th>
      <th>4054</th>
      <th>4055</th>
      <th>4056</th>
      <th>4057</th>
      <th>4058</th>
      <th>4059</th>
      <th>4060</th>
      <th>4061</th>
      <th>4062</th>
      <th>4063</th>
      <th>4064</th>
      <th>4065</th>
      <th>4066</th>
      <th>4067</th>
      <th>4068</th>
      <th>4069</th>
      <th>4070</th>
      <th>4071</th>
      <th>4072</th>
      <th>4073</th>
      <th>4074</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>（2）目标变量提取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = df[<span class="string">&#x27;评价&#x27;</span>]</span><br><span class="line">y.head()</span><br></pre></td></tr></table></figure>




<pre><code>0    1
1    1
2    1
3    1
4    1
Name: 评价, dtype: int64
</code></pre>
<h3 id="16-2-3-神经网络模型的搭建与使用"><a href="#16-2-3-神经网络模型的搭建与使用" class="headerlink" title="16.2.3 神经网络模型的搭建与使用"></a>16.2.3 神经网络模型的搭建与使用</h3><p>1.划分训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.1</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>2.搭建神经网络模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line">mlp =MLPClassifier()  <span class="comment"># 因为模型运行具有随机性，如果想让每次运行结果一致，可以设置random_state随机参数为任一数字，如MLPClassifier(random_state=123)</span></span><br><span class="line">mlp.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>



<p><img src="%E4%B8%8B%E8%BD%BD%20(28).png" alt="下载 (28)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(29).png" alt="下载 (29)"></p>
<p>3.模型使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = mlp.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred)  <span class="comment"># 因为模型运行具有随机性，所以这里得到的结果可能和书上的略有不同，如果想让每次运行结果一致，可以设置random_state随机参数为任一数字，如MLPClassifier(random_state=123)</span></span><br></pre></td></tr></table></figure>

<pre><code>[1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0
 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1
 1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取预测准确度</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.9814814814814815
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过模型自带的score()函数也可以获取预测准确度</span></span><br><span class="line">mlp.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.9814814814814815
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自我体验</span></span><br><span class="line">comment = <span class="built_in">input</span>(<span class="string">&#x27;请输入您对本商品的评价：&#x27;</span>)</span><br><span class="line">comment = [<span class="string">&#x27; &#x27;</span>.join(jieba.cut(comment))]</span><br><span class="line"><span class="built_in">print</span>(comment)</span><br><span class="line">X_try = vect.transform(comment)</span><br><span class="line">y_pred = mlp.predict(X_try.toarray())</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>请输入您对本商品的评价：物流为什么这么慢，到手里都已经一周了。五星给手机，一星给物流。
[&#39;物流 为什么 这么 慢 ， 到 手里 都 已经 一周 了 。 五星 给 手机 ， 一星 给 物流 。&#39;]
[0]
</code></pre>
<p>预测结果为0，代表差评</p>
<p>4.模型对比</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 朴素贝叶斯模型对比</span></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line">nb_clf = GaussianNB()</span><br><span class="line">nb_clf.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line">y_pred = nb_clf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>[1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1
 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1
 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1]
0.8703703703703703
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">数据科学</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习与深度学习//" class="article-tag-list-link color5">机器学习与深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part5/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-深入浅出python量化交易实战-part1" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/03/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApython%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E5%AE%9E%E6%88%98-part1/">深入浅出python量化交易实战-part1</a>
    </h1>
  

        
        <a href="/2023/02/03/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApython%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E5%AE%9E%E6%88%98-part1/" class="archive-article-date">
  	<time datetime="2023-02-03T11:56:03.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-03</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-从零开始"><a href="#1-从零开始" class="headerlink" title="1 从零开始"></a>1 从零开始</h1><h2 id="1-1-高频交易"><a href="#1-1-高频交易" class="headerlink" title="1.1 高频交易"></a>1.1 高频交易</h2><p>高频交易（HFT）是指在微秒范围内以极低延迟执行的金融工具的自动交易，美国，欧洲超过一半的股市交易采用高频交易</p>
<h2 id="1-2-因子投资"><a href="#1-2-因子投资" class="headerlink" title="1.2 因子投资"></a>1.2 因子投资</h2><p>1.资本资产定价模型（CAPM），其中最重要的组成部分是β系数，它用于表示某项资产的<strong>系统性风险</strong>，这种风险并非孤立却决于该资产，而是该资产相对于其他资产及整个市场的走向。但是只使用β这一个因子对资产回报率的预测并不准确，需要额外的风险因子。————因子投资</p>
<p>2.因子投资（多因子模型）中，因子定义为**<span class="burk">可以量化的信号、特征或其他变量</span><strong>，这些因子与资产回报率呈现明显的</strong>相关性**，并且在未来还要保持这种相关性。</p>
<p>3.多因子模型介绍：</p>
<p><strong>套利定价理论</strong>（APT）：认为证券的回报率与一组因子线性相关</p>
<p><strong>Fama-French三因子模型</strong>：指出证券回报率可以用市场资产组合、市值及账面市值比这三个因子来解释。</p>
<p><strong>Carhart四因子模型</strong>：在三因子模型的基础上，添加了动量因子</p>
<h2 id="1-3-数据"><a href="#1-3-数据" class="headerlink" title="1.3 数据"></a>1.3 数据</h2><p>1.这里的数据是包括任何可以使用机器学习提取交易信号的信息，即<strong>经济统计数据</strong>，<strong>市场交易数据</strong>，<strong>上市公司财报</strong>，<strong>信用卡销售数据</strong>，<strong>股民情绪分析</strong>，<strong>手机地理位置定位</strong>，<strong>爬虫抓取</strong>等等</p>
<p>2.例子：如果在某家上市公司公布财报数据之前，我们可以获取该公司在招聘网站上发布的<strong>招聘岗位数量</strong>，就可以先于财报数据发布了解到该公司的<strong>运营状况</strong>。假如该公司的招聘人数在上升，则可能说明该公司业绩良好，自然股票的价格也可能上涨；反之，加入该公司的招聘人数锐减，则说明该公司的经营状况可能有困难，则可能会导致该公司股价下跌。当然最直接有效的数据还是哪些能够直接体现<strong>用户消费</strong>的数据，如<strong>支付数据</strong>。</p>
<h2 id="1-4-交易策略和α因子"><a href="#1-4-交易策略和α因子" class="headerlink" title="1.4 交易策略和α因子"></a>1.4 交易策略和α因子</h2><p>通过各种数据源提取出<strong>有效信息</strong>，并且通过<strong>特征工程</strong>将数据转换成为<strong>阿尔法因子</strong>，再将这些因子拿来训练模型，使<strong>模型</strong>可以对交易品未来的趋势或价格变动做出<strong>预测</strong>，并触发买单或者卖单。例如，模型预测次日股价大涨，则下单买入，反之则卖出。</p>
<h2 id="1-5-用真实股票数据练手"><a href="#1-5-用真实股票数据练手" class="headerlink" title="1.5 用真实股票数据练手"></a>1.5 用真实股票数据练手</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! pip install tushare <span class="comment"># 安装tushare库</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入tushare并重命名为ts</span></span><br><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts</span><br><span class="line"><span class="comment">#查看tushare的版本信息</span></span><br><span class="line">ts.__version__</span><br></pre></td></tr></table></figure>




<pre><code>&#39;1.2.89&#39;
</code></pre>
<p>1.下载股票数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定一下获取股票数据的起始日期和截止日期</span></span><br><span class="line"><span class="comment">#这里就用2020年1月1日至3月18日的数据</span></span><br><span class="line">start_date = <span class="string">&#x27;2020-01-01&#x27;</span></span><br><span class="line">end_date = <span class="string">&#x27;2020-03-18&#x27;</span></span><br><span class="line"><span class="comment">#创建数据表，这里选择下载的股票代码为601318</span></span><br><span class="line"><span class="comment">#并把我们把设定的开始日期和截止日期作为参数传入</span></span><br><span class="line">data = ts.get_k_data(<span class="string">&#x27;601318&#x27;</span>,</span><br><span class="line">                          start = start_date,</span><br><span class="line">                          end = end_date)</span><br><span class="line">data = data.set_index(<span class="string">&#x27;date&#x27;</span>)</span><br><span class="line"><span class="comment">#下面来检查一下数据表的前5行</span></span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># date日期，open开盘价，close收盘价，high最高价，low最低价，volume成交量，code股票代码</span></span><br></pre></td></tr></table></figure>

<pre><code>本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>code</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-01-02</th>
      <td>79.149</td>
      <td>79.369</td>
      <td>80.039</td>
      <td>79.129</td>
      <td>778252.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2020-01-03</th>
      <td>80.059</td>
      <td>79.449</td>
      <td>80.129</td>
      <td>79.149</td>
      <td>594980.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2020-01-06</th>
      <td>79.169</td>
      <td>78.849</td>
      <td>80.119</td>
      <td>78.749</td>
      <td>636448.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2020-01-07</th>
      <td>79.259</td>
      <td>79.399</td>
      <td>79.709</td>
      <td>78.919</td>
      <td>452188.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2020-01-08</th>
      <td>79.229</td>
      <td>78.249</td>
      <td>79.229</td>
      <td>77.749</td>
      <td>628053.0</td>
      <td>601318</td>
    </tr>
  </tbody>
</table>
</div>



<p>2.最简单的数据处理</p>
<p>股票每日的涨跌是用当日的收盘价减去前一个交易日的收盘价来计算的，可以在数据表中添加一个字段，用来表示当日股价较前一日的变化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#给新的字段命名为diff，代表difference</span></span><br><span class="line"><span class="comment">#用.diff()方法来计算每日股价变化情况</span></span><br><span class="line">data[<span class="string">&#x27;diff&#x27;</span>] = data[<span class="string">&#x27;close&#x27;</span>].diff()</span><br><span class="line"><span class="comment">#检查一下前5行</span></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>code</th>
      <th>diff</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-01-02</th>
      <td>79.149</td>
      <td>79.369</td>
      <td>80.039</td>
      <td>79.129</td>
      <td>778252.0</td>
      <td>601318</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2020-01-03</th>
      <td>80.059</td>
      <td>79.449</td>
      <td>80.129</td>
      <td>79.149</td>
      <td>594980.0</td>
      <td>601318</td>
      <td>0.08</td>
    </tr>
    <tr>
      <th>2020-01-06</th>
      <td>79.169</td>
      <td>78.849</td>
      <td>80.119</td>
      <td>78.749</td>
      <td>636448.0</td>
      <td>601318</td>
      <td>-0.60</td>
    </tr>
    <tr>
      <th>2020-01-07</th>
      <td>79.259</td>
      <td>79.399</td>
      <td>79.709</td>
      <td>78.919</td>
      <td>452188.0</td>
      <td>601318</td>
      <td>0.55</td>
    </tr>
    <tr>
      <th>2020-01-08</th>
      <td>79.229</td>
      <td>78.249</td>
      <td>79.229</td>
      <td>77.749</td>
      <td>628053.0</td>
      <td>601318</td>
      <td>-1.15</td>
    </tr>
  </tbody>
</table>
</div>



<p>3.设计最简单的交易策略</p>
<p>最简单的交易策略：如果当日股价<strong>下跌</strong>，我们就在下一个交易日开盘前挂单<strong>买入</strong>；反之，如果当日股价<strong>上涨</strong>，我们就在下一个交易日开盘前挂单<strong>卖出</strong>，循环这个步骤</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#此处会用到numpy，故导入</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#创建交易信号字段，命名为Signal</span></span><br><span class="line"><span class="comment">#如果diff值大于0，则Signal为1，否则为0</span></span><br><span class="line">data[<span class="string">&#x27;Signal&#x27;</span>] = np.where(data[<span class="string">&#x27;diff&#x27;</span>] &gt; <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>code</th>
      <th>diff</th>
      <th>Signal</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-01-02</th>
      <td>79.149</td>
      <td>79.369</td>
      <td>80.039</td>
      <td>79.129</td>
      <td>778252.0</td>
      <td>601318</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-01-03</th>
      <td>80.059</td>
      <td>79.449</td>
      <td>80.129</td>
      <td>79.149</td>
      <td>594980.0</td>
      <td>601318</td>
      <td>0.08</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2020-01-06</th>
      <td>79.169</td>
      <td>78.849</td>
      <td>80.119</td>
      <td>78.749</td>
      <td>636448.0</td>
      <td>601318</td>
      <td>-0.60</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-01-07</th>
      <td>79.259</td>
      <td>79.399</td>
      <td>79.709</td>
      <td>78.919</td>
      <td>452188.0</td>
      <td>601318</td>
      <td>0.55</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2020-01-08</th>
      <td>79.229</td>
      <td>78.249</td>
      <td>79.229</td>
      <td>77.749</td>
      <td>628053.0</td>
      <td>601318</td>
      <td>-1.15</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>使用np.where()可以让程序判断每日股价是上涨还是下跌；如果<strong>上涨</strong>，交易信号为为<strong>1</strong>，代表<strong>卖出</strong>；否则交易信号为<strong>0</strong>，代表<strong>买入</strong></p>
<p>4.交易信号可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入画图工具matplotlib</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#设置画布的尺寸为10*5</span></span><br><span class="line">plt.figure(figsize = (<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#使用折线图绘制出每天的收盘价</span></span><br><span class="line">plt.plot(data[<span class="string">&#x27;close&#x27;</span>],linewidth=<span class="number">2</span>, color=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"><span class="comment">#如果当天股价上涨，标出卖出信号，用倒三角表示</span></span><br><span class="line">plt.scatter(data[<span class="string">&#x27;close&#x27;</span>].loc[data.Signal==<span class="number">1</span>].index,</span><br><span class="line">        data[<span class="string">&#x27;close&#x27;</span>][data.Signal==<span class="number">1</span>],</span><br><span class="line">        marker = <span class="string">&#x27;v&#x27;</span>, s=<span class="number">80</span>, c=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line"><span class="comment">#如果当天股价下跌给出买入信号，用正三角表示</span></span><br><span class="line">plt.scatter(data[<span class="string">&#x27;close&#x27;</span>].loc[data.Signal==<span class="number">0</span>].index,</span><br><span class="line">        data[<span class="string">&#x27;close&#x27;</span>][data.Signal==<span class="number">0</span>],</span><br><span class="line">        marker = <span class="string">&#x27;^&#x27;</span>, s=<span class="number">80</span>, c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.xticks([<span class="number">0</span>,<span class="number">12</span>,<span class="number">24</span>,<span class="number">36</span>,<span class="number">48</span>])</span><br><span class="line">plt.grid()</span><br><span class="line"><span class="comment">#将图像进行展示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_22_0.png" alt="output_22_0"></p>
<p>【结果分析】<strong>倒三角</strong>所处的位置是股票收盘价较上一个交易日<strong>上涨</strong>的时刻，代表<strong>卖出</strong>；<strong>正三角</strong>所处的位置是股票收盘价较上一个交易日<strong>下跌</strong>的时刻，代表<strong>买入</strong>。直观来看，在这个时间范围内，股价整体呈现出<strong>下跌</strong>的天数大于<strong>上涨</strong>天数的情况。使用这个交易策略，且每次买入和卖出的股票数量相同的话，那么持有这只股票的仓位会越来越<strong>高</strong>（越买越多）</p>
<h1 id="2-回测与经典策略"><a href="#2-回测与经典策略" class="headerlink" title="2 回测与经典策略"></a>2 回测与经典策略</h1><h2 id="2-1-对“低买高卖”策略进行简单回测"><a href="#2-1-对“低买高卖”策略进行简单回测" class="headerlink" title="2.1 对“低买高卖”策略进行简单回测"></a>2.1 对“低买高卖”策略进行简单回测</h2><h3 id="2-1-1-下载数据并创建交易信号"><a href="#2-1-1-下载数据并创建交易信号" class="headerlink" title="2.1.1 下载数据并创建交易信号"></a>2.1.1 下载数据并创建交易信号</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入必要的库</span></span><br><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#指定下载股票的日期范围</span></span><br><span class="line">start_date = <span class="string">&#x27;2020-01-01&#x27;</span></span><br><span class="line">end_date = <span class="string">&#x27;2020-03-20&#x27;</span></span><br><span class="line"><span class="comment">#使用ts获取数据</span></span><br><span class="line"><span class="comment">#将时间范围作为参数传入</span></span><br><span class="line">zgpa = ts.get_k_data(<span class="string">&#x27;601318&#x27;</span>,</span><br><span class="line">                    start_date, end_date)</span><br><span class="line">zgpa = zgpa.set_index(<span class="string">&#x27;date&#x27;</span>)</span><br><span class="line"><span class="comment">#检查是否下载成功</span></span><br><span class="line">zgpa.head()</span><br></pre></td></tr></table></figure>

<pre><code>本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>code</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-01-02</th>
      <td>79.149</td>
      <td>79.369</td>
      <td>80.039</td>
      <td>79.129</td>
      <td>778252.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2020-01-03</th>
      <td>80.059</td>
      <td>79.449</td>
      <td>80.129</td>
      <td>79.149</td>
      <td>594980.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2020-01-06</th>
      <td>79.169</td>
      <td>78.849</td>
      <td>80.119</td>
      <td>78.749</td>
      <td>636448.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2020-01-07</th>
      <td>79.259</td>
      <td>79.399</td>
      <td>79.709</td>
      <td>78.919</td>
      <td>452188.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2020-01-08</th>
      <td>79.229</td>
      <td>78.249</td>
      <td>79.229</td>
      <td>77.749</td>
      <td>628053.0</td>
      <td>601318</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面我们来创建交易信号</span></span><br><span class="line"><span class="comment">#为了不影响原始数据，这里创建一个新的数据表</span></span><br><span class="line"><span class="comment">#只保留原始数据中的日期index</span></span><br><span class="line">zgpa_signal = pd.DataFrame(index = zgpa.index)</span><br><span class="line"><span class="comment">#为了更能体现股票的真实价值</span></span><br><span class="line"><span class="comment">#使用Adj Close调整价格作为股票价格</span></span><br><span class="line">zgpa_signal[<span class="string">&#x27;price&#x27;</span>] = zgpa[<span class="string">&#x27;close&#x27;</span>]</span><br><span class="line"><span class="comment">#增加一个字段，来存储股价的变化</span></span><br><span class="line">zgpa_signal[<span class="string">&#x27;diff&#x27;</span>] = zgpa_signal[<span class="string">&#x27;price&#x27;</span>].diff()</span><br><span class="line"><span class="comment">#增加diff字段后，第一行会出现空值，我们使用0来进行填补</span></span><br><span class="line">zgpa_signal = zgpa_signal.fillna(<span class="number">0.0</span>)</span><br><span class="line"><span class="comment">#如果股价上涨或不变，则标记为0</span></span><br><span class="line"><span class="comment">#如果股价下跌，则标记为1</span></span><br><span class="line">zgpa_signal[<span class="string">&#x27;signal&#x27;</span>] = np.where(zgpa_signal[<span class="string">&#x27;diff&#x27;</span>] &gt;= <span class="number">0</span>, <span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line"><span class="comment">#接下来，根据交易信号的变化进行下单</span></span><br><span class="line"><span class="comment">#一般情况下，在A股市场，买入或卖出至少为100股，即1手</span></span><br><span class="line">zgpa_signal[<span class="string">&#x27;order&#x27;</span>] = zgpa_signal[<span class="string">&#x27;signal&#x27;</span>].diff()*<span class="number">100</span></span><br><span class="line"><span class="comment">#检查一下下单的情况</span></span><br><span class="line">zgpa_signal.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
      <th>diff</th>
      <th>signal</th>
      <th>order</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-01-02</th>
      <td>79.369</td>
      <td>0.00</td>
      <td>0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2020-01-03</th>
      <td>79.449</td>
      <td>0.08</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-01-06</th>
      <td>78.849</td>
      <td>-0.60</td>
      <td>1</td>
      <td>100.0</td>
    </tr>
    <tr>
      <th>2020-01-07</th>
      <td>79.399</td>
      <td>0.55</td>
      <td>0</td>
      <td>-100.0</td>
    </tr>
    <tr>
      <th>2020-01-08</th>
      <td>78.249</td>
      <td>-1.15</td>
      <td>1</td>
      <td>100.0</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：在2020年1月6日这一天，股价下跌了大约6角，程序给出交易信号“1”，这时下单买入100股；而到了1月7日，股价上涨了0.55元，程序给出交易信号“0”，此时交易信号的变化为0-1&#x3D;-1，因此下单卖出100股。经过这一买一卖的交易，可赚到大约55元，看起来不错</p>
<h3 id="2-1-2-对交易策略进行简单回测"><a href="#2-1-2-对交易策略进行简单回测" class="headerlink" title="2.1.2 对交易策略进行简单回测"></a>2.1.2 对交易策略进行简单回测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#考虑到股价较高，我们初始给小瓦2万块钱让她去交易</span></span><br><span class="line">initial_cash = <span class="number">20000.00</span></span><br><span class="line"><span class="comment">#增加一个字段，代表小瓦交易的股票的市值</span></span><br><span class="line">zgpa_signal[<span class="string">&#x27;stock&#x27;</span>] = zgpa_signal[<span class="string">&#x27;order&#x27;</span>]*zgpa_signal[<span class="string">&#x27;price&#x27;</span>]</span><br><span class="line"><span class="comment">#两次买卖的订单变化之差就是某一时刻小瓦仓位的变化情况</span></span><br><span class="line"><span class="comment">#持仓股票的数量变化乘以现价，就是代表小瓦交易产生的现金流</span></span><br><span class="line"><span class="comment">#用初始资金减去现金流变化的累加，就是小瓦剩余的现金</span></span><br><span class="line">zgpa_signal[<span class="string">&#x27;cash&#x27;</span>] = initial_cash -\</span><br><span class="line">(zgpa_signal[<span class="string">&#x27;order&#x27;</span>].diff()*zgpa_signal[<span class="string">&#x27;price&#x27;</span>]).cumsum()</span><br><span class="line"><span class="comment">#而最股票的市值加上剩余的现金，就是小瓦的总资产</span></span><br><span class="line">zgpa_signal[<span class="string">&#x27;total&#x27;</span>] = zgpa_signal[<span class="string">&#x27;stock&#x27;</span>] + zgpa_signal[<span class="string">&#x27;cash&#x27;</span>]</span><br><span class="line"><span class="comment">#为了让小瓦直观看到自己的总资产变化</span></span><br><span class="line"><span class="comment">#我们用图形来进行展示</span></span><br><span class="line"><span class="comment">#设置图形的尺寸是10*6</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"><span class="comment">#分别绘制总资产和持仓股票市值的变化</span></span><br><span class="line">plt.plot(zgpa_signal[<span class="string">&#x27;total&#x27;</span>])</span><br><span class="line">plt.plot(zgpa_signal[<span class="string">&#x27;order&#x27;</span>].cumsum()*zgpa_signal[<span class="string">&#x27;price&#x27;</span>],<span class="string">&#x27;--&#x27;</span>,</span><br><span class="line">        label=<span class="string">&#x27;stock value&#x27;</span>)</span><br><span class="line"><span class="comment">#增加网格，调整一下图注的位置，就可以显示图像了</span></span><br><span class="line">plt.xticks([<span class="number">0</span>,<span class="number">12</span>,<span class="number">24</span>,<span class="number">36</span>,<span class="number">48</span>])</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;center right&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_32_0.png" alt="output_32_0"></p>
<p>何为回测？使用这个策略模拟交易一段时间后总资产的变化情况</p>
<p>分析：从一月初到3.20，使用该低买高卖策略进行交易，总资产最后略微减少了。虽然从1月中旬到2月中旬，总资产也曾经有一定的增长，但涨幅也并不明显。当然，考虑在此期间，股市整体表现都不好，在这样的背景下，其策略没有让总资产大幅缩水，对一个新手来说，很不错</p>
<h3 id="2-1-3-关于回测更多"><a href="#2-1-3-关于回测更多" class="headerlink" title="2.1.3 关于回测更多"></a>2.1.3 关于回测更多</h3><p>回测：通过模拟算法进行交易的过程，用一些指标对交易策略进行评估。在我们所做的回测中，所测量的指标就是<strong>利润和损失</strong>（PnL）。不过在刚才的回测中，我们并没有考虑交易手续费和税费等成本，如果将这些附加成本也添加到模型中参与计算，算出来的就是<strong>净利润和损失</strong>（net PnL）。常用的指标还有年化收益、交易手数、风险敞口以及夏普指数等。</p>
<p><strong>风险敞口</strong>：指的是<strong>未加保护</strong>的风险，在股市中，就是指投资股票的资金。比如我有一万元，其中5000买了股票，另外5000买了保本的理财产品，那么买股票的5000元钱面临着股价下跌的风险，即风险敞口为5000元</p>
<p><strong>夏普指数</strong>（夏普比率）：将一组<strong>投资组合的回报率</strong>与<strong>无风险投资的回报率</strong>（如银行存款或国债）进行对比，看投资组合的回报会<strong>超过</strong>无风险投资回报率多少。夏普指数越高，说明投资组合的回报率越高；相反，如果投资组合的回报率不及无风险投资的回报，就说明这项投资是不应该进行的。</p>
<h2 id="2-2-经典策略之移动平均策略-趋势跟随策略之一"><a href="#2-2-经典策略之移动平均策略-趋势跟随策略之一" class="headerlink" title="2.2 经典策略之移动平均策略(趋势跟随策略之一)"></a>2.2 经典策略之移动平均策略(趋势跟随策略之一)</h2><h3 id="2-2-1-单一移动平均指标"><a href="#2-2-1-单一移动平均指标" class="headerlink" title="2.2.1 单一移动平均指标"></a>2.2.1 单一移动平均指标</h3><p><strong>移动平均策略</strong>：当股价上升且<strong>向上穿过</strong>N日的均线时，说明股价在向上突破，此时<strong>下单买入</strong>；当股价下降且<strong>向下穿过</strong>N日均线时，说明股价整体出现下跌的趋势，此时下单卖出。或者当M日均线上升穿过N日均线（M&lt;N）时，说明股票处于上升的趋势，应该下单买入；反之应下单卖出。</p>
<p>本节需要用到指标为均线，使用2.1节中的股票数据，选取10个交易日的股票均价作为均线</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里使用10日均线</span></span><br><span class="line">period = <span class="number">10</span></span><br><span class="line"><span class="comment">#设置一个空列表，用来存储每10天的价格</span></span><br><span class="line">avg_10 = []</span><br><span class="line"><span class="comment">#再设置一个空列表，用来存储每10天价格的均值</span></span><br><span class="line">avg_value = []</span><br><span class="line"><span class="comment">#设置一个循环</span></span><br><span class="line"><span class="keyword">for</span> price <span class="keyword">in</span> zgpa[<span class="string">&#x27;close&#x27;</span>]:</span><br><span class="line">    <span class="comment">#把每天的价格传入到avg_10列表</span></span><br><span class="line">    avg_10.append(price)</span><br><span class="line">    <span class="comment">#当列表中存储的数值多于10个时</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(avg_10) &gt; period:</span><br><span class="line">        <span class="comment">#就把前面传入的价格数据删掉，确保列表中只有10天的数据</span></span><br><span class="line">        <span class="keyword">del</span> avg_10[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#将10天数据的均值传入到avg_value列表中</span></span><br><span class="line">    avg_value.append(np.mean(avg_10))</span><br><span class="line"><span class="comment">#把计算好的10日均价写到股票价格数据表中</span></span><br><span class="line">zgpa = zgpa.assign(avg_10 = pd.Series(avg_value, index = zgpa.index))</span><br><span class="line"><span class="comment">#检查一下是否添加成功</span></span><br><span class="line">zgpa.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>code</th>
      <th>avg_10</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-01-02</th>
      <td>79.149</td>
      <td>79.369</td>
      <td>80.039</td>
      <td>79.129</td>
      <td>778252.0</td>
      <td>601318</td>
      <td>79.369000</td>
    </tr>
    <tr>
      <th>2020-01-03</th>
      <td>80.059</td>
      <td>79.449</td>
      <td>80.129</td>
      <td>79.149</td>
      <td>594980.0</td>
      <td>601318</td>
      <td>79.409000</td>
    </tr>
    <tr>
      <th>2020-01-06</th>
      <td>79.169</td>
      <td>78.849</td>
      <td>80.119</td>
      <td>78.749</td>
      <td>636448.0</td>
      <td>601318</td>
      <td>79.222333</td>
    </tr>
    <tr>
      <th>2020-01-07</th>
      <td>79.259</td>
      <td>79.399</td>
      <td>79.709</td>
      <td>78.919</td>
      <td>452188.0</td>
      <td>601318</td>
      <td>79.266500</td>
    </tr>
    <tr>
      <th>2020-01-08</th>
      <td>79.229</td>
      <td>78.249</td>
      <td>79.229</td>
      <td>77.749</td>
      <td>628053.0</td>
      <td>601318</td>
      <td>79.063000</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以看到，数据表中多出一个字段avg_10。该字段存储的是10日内股票的均价。而在前9天中，由于数据不足10天，均价计算的是自有数据以来，截至到当前的股票均价</p>
<p>为了直观地展示股价与均价的关系，可以进行数据可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># SimHei表示简体黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span>  <span class="comment"># 为了正确显示负号</span></span><br><span class="line"><span class="comment">#设置图像尺寸为10*6</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"><span class="comment">#绘制股价的变化</span></span><br><span class="line">plt.plot(zgpa[<span class="string">&#x27;close&#x27;</span>],lw=<span class="number">2</span>, c=<span class="string">&#x27;k&#x27;</span>,label=<span class="string">&#x27;股价&#x27;</span>)</span><br><span class="line"><span class="comment">#绘制10日均线</span></span><br><span class="line">plt.plot(zgpa[<span class="string">&#x27;avg_10&#x27;</span>], <span class="string">&#x27;--&#x27;</span>,lw=<span class="number">2</span>, c=<span class="string">&#x27;b&#x27;</span>,label=<span class="string">&#x27;10日均价&#x27;</span>)</span><br><span class="line"><span class="comment">#添加图注和网格</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.xticks([<span class="number">0</span>,<span class="number">12</span>,<span class="number">24</span>,<span class="number">36</span>,<span class="number">48</span>])</span><br><span class="line"><span class="comment">#将图像进行显示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_46_0.png" alt="output_46_0"></p>
<p>整体来看，在此期间，该股的整体趋势处于下行，不过不要紧，我们就基于这种“逆境”来尝试创建交易策略</p>
<h3 id="2-2-2-双移动平均策略的实现"><a href="#2-2-2-双移动平均策略的实现" class="headerlink" title="2.2.2 双移动平均策略的实现"></a>2.2.2 双移动平均策略的实现</h3><p>双移动平均策略就是使用<strong>两条均线</strong>来判断股价未来的走势。两条均线中，一条是<strong>长期均线</strong>（如10日均线），另一条是<strong>短期均线</strong>（如5日均线）。</p>
<p>这种策略基于这样一种假设：股票价格的动量会朝着<strong>短期均线</strong>的方向移动。当<strong>短期均线穿过长期均线</strong>，超过长期均线时，动量将向上，此时股价可能会<strong>上涨</strong>。然而，如果短期均线的移动方向相反，则股价可能<strong>下跌</strong>。</p>
<p>根据此理论，创建一个双移动平均交易策略</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#新建一个数据表，命名为strategy（策略）</span></span><br><span class="line"><span class="comment">#序号保持和原始数据一致</span></span><br><span class="line">strategy = pd.DataFrame(index = zgpa.index)</span><br><span class="line"><span class="comment">#添加一个signal字段，用来存储交易信号</span></span><br><span class="line">strategy[<span class="string">&#x27;signal&#x27;</span>] = <span class="number">0</span></span><br><span class="line"><span class="comment">#将5日均价保存到avg_5这个字段</span></span><br><span class="line">strategy[<span class="string">&#x27;avg_5&#x27;</span>] = zgpa[<span class="string">&#x27;close&#x27;</span>].rolling(<span class="number">5</span>).mean()</span><br><span class="line"><span class="comment">#同样，将10日均价保存到avg_10</span></span><br><span class="line">strategy[<span class="string">&#x27;avg_10&#x27;</span>] = zgpa[<span class="string">&#x27;close&#x27;</span>].rolling(<span class="number">10</span>).mean()</span><br><span class="line"><span class="comment">#当5日均价大于10日均价时，标记为1</span></span><br><span class="line"><span class="comment">#反之标记为0</span></span><br><span class="line">strategy[<span class="string">&#x27;signal&#x27;</span>] = np.where(strategy[<span class="string">&#x27;avg_5&#x27;</span>]&gt;strategy[<span class="string">&#x27;avg_10&#x27;</span>], <span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment">#根据交易信号的变化下单，当交易信号从0变成1时买入</span></span><br><span class="line"><span class="comment">#交易信号从1变成0时卖出</span></span><br><span class="line"><span class="comment">#交易信号不变时不下单</span></span><br><span class="line">strategy[<span class="string">&#x27;order&#x27;</span>] = strategy[<span class="string">&#x27;signal&#x27;</span>].diff()</span><br><span class="line"><span class="comment">#查看数据表后10行</span></span><br><span class="line">strategy.tail(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>signal</th>
      <th>avg_5</th>
      <th>avg_10</th>
      <th>order</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-03-09</th>
      <td>1</td>
      <td>73.563</td>
      <td>73.117</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-03-10</th>
      <td>1</td>
      <td>73.501</td>
      <td>73.016</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-03-11</th>
      <td>1</td>
      <td>73.015</td>
      <td>72.848</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-03-12</th>
      <td>0</td>
      <td>71.855</td>
      <td>72.534</td>
      <td>-1.0</td>
    </tr>
    <tr>
      <th>2020-03-13</th>
      <td>0</td>
      <td>70.615</td>
      <td>72.233</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-03-16</th>
      <td>0</td>
      <td>69.387</td>
      <td>71.475</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-03-17</th>
      <td>0</td>
      <td>67.979</td>
      <td>70.740</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-03-18</th>
      <td>0</td>
      <td>66.323</td>
      <td>69.669</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-03-19</th>
      <td>0</td>
      <td>64.555</td>
      <td>68.205</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2020-03-20</th>
      <td>0</td>
      <td>63.413</td>
      <td>67.014</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>



<p>3.9这一天，5日均线大于10日均线，故程序给出的交易信号是1；在3.10这一天，5日均线依然大于10日均线，交易信号不变，仍然是1，所以这一天不进行任何交易；但到了3.12，5日均线小于10日均线，交易信号变为0，与前一天相比，交易信号的变化为-1，所以下单卖出一手股票。</p>
<p>可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建尺寸为10*5的画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#使用实线绘制股价</span></span><br><span class="line">plt.plot(zgpa[<span class="string">&#x27;close&#x27;</span>],lw=<span class="number">2</span>,label=<span class="string">&#x27;price&#x27;</span>)</span><br><span class="line"><span class="comment">#使用虚线绘制5日均线</span></span><br><span class="line">plt.plot(strategy[<span class="string">&#x27;avg_5&#x27;</span>],lw=<span class="number">2</span>,ls=<span class="string">&#x27;--&#x27;</span>,label=<span class="string">&#x27;avg5&#x27;</span>)</span><br><span class="line"><span class="comment">#使用-.风格绘制10日均线</span></span><br><span class="line">plt.plot(strategy[<span class="string">&#x27;avg_10&#x27;</span>],lw=<span class="number">2</span>,ls=<span class="string">&#x27;-.&#x27;</span>,label=<span class="string">&#x27;avg10&#x27;</span>)</span><br><span class="line"><span class="comment">#将买入信号用正三角进行标示</span></span><br><span class="line">plt.scatter(strategy.loc[strategy.order==<span class="number">1</span>].index,</span><br><span class="line">           zgpa[<span class="string">&#x27;close&#x27;</span>][strategy.order==<span class="number">1</span>],</span><br><span class="line">           marker = <span class="string">&#x27;^&#x27;</span>, s=<span class="number">80</span>,color=<span class="string">&#x27;r&#x27;</span>,label=<span class="string">&#x27;Buy&#x27;</span>)</span><br><span class="line"><span class="comment">#将卖出信号用倒三角进行标示</span></span><br><span class="line">plt.scatter(strategy.loc[strategy.order==-<span class="number">1</span>].index,</span><br><span class="line">           zgpa[<span class="string">&#x27;close&#x27;</span>][strategy.order==-<span class="number">1</span>],</span><br><span class="line">           marker = <span class="string">&#x27;v&#x27;</span>, s=<span class="number">80</span>,color=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&#x27;Sell&#x27;</span>)</span><br><span class="line"><span class="comment">#添加图注</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.xticks([<span class="number">0</span>,<span class="number">12</span>,<span class="number">24</span>,<span class="number">36</span>,<span class="number">48</span>])</span><br><span class="line"><span class="comment">#添加网格以便于观察</span></span><br><span class="line">plt.grid()</span><br><span class="line"><span class="comment">#显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_54_0.png" alt="output_54_0"></p>
<p>结果分析：使用移动平均策略，在选取的时间范围内一共进行了<strong>6笔交易，其中3笔买入，3笔卖出</strong>。由于在该时间范围内，该股的价格一直处于下跌的趋势，通过肉眼也可以看出，每次卖出的价格都要低于买入的价格，总体应该是亏损的状态。</p>
<h3 id="2-2-3-对双移动平均策略进行回测"><a href="#2-2-3-对双移动平均策略进行回测" class="headerlink" title="2.2.3 对双移动平均策略进行回测"></a>2.2.3 对双移动平均策略进行回测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这次我们还是给小瓦2万块钱的启动资金</span></span><br><span class="line">initial_cash = <span class="number">20000</span></span><br><span class="line"><span class="comment">#新建一个数据表positions，序号保持和strategy数据表一致</span></span><br><span class="line"><span class="comment">#用0将空值进行替换</span></span><br><span class="line">positions = pd.DataFrame(index = strategy.index).fillna(<span class="number">0</span>)</span><br><span class="line"><span class="comment">#因为A股买卖都是最低100股</span></span><br><span class="line"><span class="comment">#因此设置stock字段为交易信号的100倍</span></span><br><span class="line">positions[<span class="string">&#x27;stock&#x27;</span>] = strategy[<span class="string">&#x27;signal&#x27;</span>] * <span class="number">100</span></span><br><span class="line"><span class="comment">#创建投资组合数据表，用持仓的股票数量乘股价得出持仓的股票市值</span></span><br><span class="line">portfolio = pd.DataFrame(index = strategy.index)</span><br><span class="line">portfolio[<span class="string">&#x27;stock value&#x27;</span>] = positions.multiply(zgpa[<span class="string">&#x27;close&#x27;</span>], axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#同样仓位的变化就是下单的数量</span></span><br><span class="line">order = positions.diff()</span><br><span class="line"><span class="comment">#用初始资金减去下单金额的总和就是剩余的资金</span></span><br><span class="line">portfolio[<span class="string">&#x27;cash&#x27;</span>] = initial_cash - order.multiply(zgpa[<span class="string">&#x27;close&#x27;</span>],</span><br><span class="line">                                                 axis=<span class="number">0</span>).cumsum()</span><br><span class="line"><span class="comment">#剩余的资金+持仓股票市值即为总资产</span></span><br><span class="line">portfolio[<span class="string">&#x27;total&#x27;</span>] = portfolio[<span class="string">&#x27;cash&#x27;</span>] + portfolio[<span class="string">&#x27;stock value&#x27;</span>]</span><br><span class="line"><span class="comment">#检查一下后10行</span></span><br><span class="line">portfolio.tail(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stock value</th>
      <th>cash</th>
      <th>total</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-03-09</th>
      <td>7138.9</td>
      <td>12316.1</td>
      <td>19455.0</td>
    </tr>
    <tr>
      <th>2020-03-10</th>
      <td>7242.9</td>
      <td>12316.1</td>
      <td>19559.0</td>
    </tr>
    <tr>
      <th>2020-03-11</th>
      <td>7139.9</td>
      <td>12316.1</td>
      <td>19456.0</td>
    </tr>
    <tr>
      <th>2020-03-12</th>
      <td>0.0</td>
      <td>19306.0</td>
      <td>19306.0</td>
    </tr>
    <tr>
      <th>2020-03-13</th>
      <td>0.0</td>
      <td>19306.0</td>
      <td>19306.0</td>
    </tr>
    <tr>
      <th>2020-03-16</th>
      <td>0.0</td>
      <td>19306.0</td>
      <td>19306.0</td>
    </tr>
    <tr>
      <th>2020-03-17</th>
      <td>0.0</td>
      <td>19306.0</td>
      <td>19306.0</td>
    </tr>
    <tr>
      <th>2020-03-18</th>
      <td>0.0</td>
      <td>19306.0</td>
      <td>19306.0</td>
    </tr>
    <tr>
      <th>2020-03-19</th>
      <td>0.0</td>
      <td>19306.0</td>
      <td>19306.0</td>
    </tr>
    <tr>
      <th>2020-03-20</th>
      <td>0.0</td>
      <td>19306.0</td>
      <td>19306.0</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：截至2020年3月20日，持仓仓位为0，此时的总资产只剩19306元，相比于初始的20000元，总资产缩水了694元。虽然没有赚到钱，但也没有亏损太多</p>
<p>可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建10*5的画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#绘制总资产曲线</span></span><br><span class="line">plt.plot(portfolio[<span class="string">&#x27;total&#x27;</span>], lw=<span class="number">2</span>, label=<span class="string">&#x27;total&#x27;</span>)</span><br><span class="line"><span class="comment">#绘制持仓股票市值曲线</span></span><br><span class="line">plt.plot(portfolio[<span class="string">&#x27;stock value&#x27;</span>],lw=<span class="number">2</span>,ls=<span class="string">&#x27;--&#x27;</span>, label=<span class="string">&#x27;stock value&#x27;</span>)</span><br><span class="line"><span class="comment">#添加图注</span></span><br><span class="line">plt.legend()</span><br><span class="line"><span class="comment">#添加网格</span></span><br><span class="line">plt.grid()</span><br><span class="line">plt.xticks([<span class="number">0</span>,<span class="number">12</span>,<span class="number">24</span>,<span class="number">36</span>,<span class="number">48</span>])</span><br><span class="line"><span class="comment">#展示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_60_0.png" alt="output_60_0"></p>
<p>结果分析：使用双移动平均策略进行交易，在选定的时间范围内，总资产也轻微减少了。其表现也没有“低买高卖”策略更加出色。仔细分析该策略会发现，我们<strong>持仓的时间</strong>要比使用“低买高卖”策略短很多；而在3.12以后，一直保持着<strong>空仓</strong>的状态，避免了股价大幅下跌带来的损失。</p>
<p>经过测试，双移动平均策略作为经典策略之一，有一定的可取之处，但是在股价下行的趋势中，也没有实现“逆势赚钱”</p>
<h2 id="2-3-经典策略之海龟策略"><a href="#2-3-经典策略之海龟策略" class="headerlink" title="2.3 经典策略之海龟策略"></a>2.3 经典策略之海龟策略</h2><p>核心要点：在股价<strong>超过过去N个交易日</strong>的<strong>股价最高点</strong>时买入，在股价<strong>低于过去N个交易日</strong>的<strong>股价最低点</strong>时卖出。上述的若干个最高点和最低点会组成一个通道，称为<strong>唐奇安通道</strong></p>
<h3 id="2-3-1-使用海龟策略生成交易信号"><a href="#2-3-1-使用海龟策略生成交易信号" class="headerlink" title="2.3.1 使用海龟策略生成交易信号"></a>2.3.1 使用海龟策略生成交易信号</h3><p>使用过去N天的股价最高点和过去N天的股价最低点生成唐奇安通道。一般来说，N会设置为20.不过因为我们下载的股票数据时间范围跨度比较小，所以选择了使用过去5日的股价最高点和最低点来进行演示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个名为turtle的数据表，使用原始数据表的日期序号</span></span><br><span class="line">turtle = pd.DataFrame(index = zgpa.index)</span><br><span class="line"><span class="comment">#设置唐奇安通道的上沿为前5天股价的最高点</span></span><br><span class="line">turtle[<span class="string">&#x27;high&#x27;</span>] = zgpa[<span class="string">&#x27;close&#x27;</span>].shift(<span class="number">1</span>).rolling(<span class="number">5</span>).<span class="built_in">max</span>()</span><br><span class="line"><span class="comment">#设置唐奇安通道的下沿为过去5天的最低点</span></span><br><span class="line">turtle[<span class="string">&#x27;low&#x27;</span>] = zgpa[<span class="string">&#x27;close&#x27;</span>].shift(<span class="number">1</span>).rolling(<span class="number">5</span>).<span class="built_in">min</span>()</span><br><span class="line"><span class="comment">#当股价突破上沿时，发出买入信号</span></span><br><span class="line">turtle[<span class="string">&#x27;buy&#x27;</span>] = zgpa[<span class="string">&#x27;close&#x27;</span>] &gt; turtle[<span class="string">&#x27;high&#x27;</span>]</span><br><span class="line"><span class="comment">#当股价突破下沿时，发出卖出信号</span></span><br><span class="line">turtle[<span class="string">&#x27;sell&#x27;</span>] = zgpa[<span class="string">&#x27;close&#x27;</span>] &lt; turtle[<span class="string">&#x27;low&#x27;</span>]</span><br><span class="line"><span class="comment">#检查信号创建情况</span></span><br><span class="line">turtle.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>high</th>
      <th>low</th>
      <th>buy</th>
      <th>sell</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-03-16</th>
      <td>72.429</td>
      <td>67.959</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2020-03-17</th>
      <td>72.429</td>
      <td>65.249</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2020-03-18</th>
      <td>71.399</td>
      <td>65.249</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2020-03-19</th>
      <td>69.899</td>
      <td>63.119</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2020-03-20</th>
      <td>67.959</td>
      <td>61.059</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：high存储的是唐奇安通道的上沿数据，low中存储的是唐奇安通道的下沿；buy如果为True，则为买入信号；sell如果为True，则为卖出信号；而当buy和sell都是False时，则不进行下单。</p>
<p>实际上，在唐奇安通道中，还有一条中线，中线的值是上沿和下沿的均值，本例进行了简化处理</p>
<h3 id="2-3-2-根据交易信号和仓位进行下单"><a href="#2-3-2-根据交易信号和仓位进行下单" class="headerlink" title="2.3.2 根据交易信号和仓位进行下单"></a>2.3.2 根据交易信号和仓位进行下单</h3><p>我们根据生成的交易信号来下单。注意：当程序给出交易信号时，还要结合仓位来判断：</p>
<p>当交易信号为<strong>买入</strong>且<strong>空仓</strong>时，我们才会下<strong>买入</strong>订单；</p>
<p>而交易信号为<strong>卖出</strong>且有<strong>持仓股票</strong>时，我们才会下<strong>卖出</strong>订单。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#初始的订单状态为0</span></span><br><span class="line">turtle[<span class="string">&#x27;orders&#x27;</span>]=<span class="number">0</span></span><br><span class="line"><span class="comment">#初始的仓位为0</span></span><br><span class="line">position = <span class="number">0</span></span><br><span class="line"><span class="comment">#设置循环，遍历turtle数据表</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(turtle)):</span><br><span class="line">    <span class="comment">#当买入信号为True且仓位为0时下单买入1手</span></span><br><span class="line">    <span class="keyword">if</span> turtle.buy[k] <span class="keyword">and</span> position ==<span class="number">0</span>:</span><br><span class="line">        <span class="comment">#修改对应的orders值为1</span></span><br><span class="line">        turtle.orders.values[k] = <span class="number">1</span></span><br><span class="line">        <span class="comment">#仓位也增加1手</span></span><br><span class="line">        position = <span class="number">1</span></span><br><span class="line">    <span class="comment">#而当卖出信号为True且有持仓时买出1手</span></span><br><span class="line">    <span class="keyword">elif</span> turtle.sell[k] <span class="keyword">and</span> position &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment">#orders的值修改为-1</span></span><br><span class="line">        turtle.orders.values[k] = -<span class="number">1</span></span><br><span class="line">        <span class="comment">#仓位相应清零</span></span><br><span class="line">        position = <span class="number">0</span>   </span><br><span class="line"><span class="comment">#检查是否成功</span></span><br><span class="line">turtle.tail(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>high</th>
      <th>low</th>
      <th>buy</th>
      <th>sell</th>
      <th>orders</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-03-02</th>
      <td>73.969</td>
      <td>70.969</td>
      <td>False</td>
      <td>False</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-03</th>
      <td>73.439</td>
      <td>70.969</td>
      <td>False</td>
      <td>False</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-04</th>
      <td>73.079</td>
      <td>70.969</td>
      <td>True</td>
      <td>False</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2020-03-05</th>
      <td>73.829</td>
      <td>70.969</td>
      <td>True</td>
      <td>False</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-06</th>
      <td>75.699</td>
      <td>70.969</td>
      <td>False</td>
      <td>False</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-09</th>
      <td>75.699</td>
      <td>72.739</td>
      <td>False</td>
      <td>True</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>2020-03-10</th>
      <td>75.699</td>
      <td>71.389</td>
      <td>False</td>
      <td>False</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-11</th>
      <td>75.699</td>
      <td>71.389</td>
      <td>False</td>
      <td>False</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-12</th>
      <td>75.699</td>
      <td>71.389</td>
      <td>False</td>
      <td>True</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-13</th>
      <td>74.159</td>
      <td>69.899</td>
      <td>False</td>
      <td>True</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-16</th>
      <td>72.429</td>
      <td>67.959</td>
      <td>False</td>
      <td>True</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-17</th>
      <td>72.429</td>
      <td>65.249</td>
      <td>False</td>
      <td>False</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-18</th>
      <td>71.399</td>
      <td>65.249</td>
      <td>False</td>
      <td>True</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-19</th>
      <td>69.899</td>
      <td>63.119</td>
      <td>False</td>
      <td>True</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2020-03-20</th>
      <td>67.959</td>
      <td>61.059</td>
      <td>False</td>
      <td>False</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：在3.4日，程序下了买入单，在3.9日，程序下了卖出单</p>
<p>可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># SimHei表示简体黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span>  <span class="comment"># 为了正确显示负号</span></span><br><span class="line"><span class="comment">#创建10*5的画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#绘制股价的折线图</span></span><br><span class="line">plt.plot(zgpa[<span class="string">&#x27;close&#x27;</span>],lw=<span class="number">2</span>,label=<span class="string">&#x27;股价&#x27;</span>)</span><br><span class="line"><span class="comment">#绘制唐奇安通道上沿</span></span><br><span class="line">plt.plot(turtle[<span class="string">&#x27;high&#x27;</span>],lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>,c=<span class="string">&#x27;r&#x27;</span>,label=<span class="string">&#x27;上沿&#x27;</span>)</span><br><span class="line"><span class="comment">#绘制唐奇安通道下沿</span></span><br><span class="line">plt.plot(turtle[<span class="string">&#x27;low&#x27;</span>],lw=<span class="number">2</span>,ls=<span class="string">&#x27;--&#x27;</span>,c=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&#x27;下沿&#x27;</span>)</span><br><span class="line"><span class="comment">#标出买入订单，用正三角标记</span></span><br><span class="line">plt.scatter(turtle.loc[turtle.orders==<span class="number">1</span>].index,</span><br><span class="line">           zgpa[<span class="string">&#x27;close&#x27;</span>][turtle.orders==<span class="number">1</span>],</span><br><span class="line">           marker=<span class="string">&#x27;^&#x27;</span>,s=<span class="number">80</span>,color=<span class="string">&#x27;r&#x27;</span>,label=<span class="string">&#x27;Buy&#x27;</span>)</span><br><span class="line"><span class="comment">#标出卖出订单，用倒三角标记</span></span><br><span class="line">plt.scatter(turtle.loc[turtle.orders==-<span class="number">1</span>].index,</span><br><span class="line">           zgpa[<span class="string">&#x27;close&#x27;</span>][turtle.orders==-<span class="number">1</span>],</span><br><span class="line">           marker=<span class="string">&#x27;v&#x27;</span>,s=<span class="number">80</span>,color=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&#x27;Sell&#x27;</span>)</span><br><span class="line"><span class="comment">#添加网格、图注并显示</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.xticks([<span class="number">0</span>,<span class="number">12</span>,<span class="number">24</span>,<span class="number">36</span>,<span class="number">48</span>])</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_74_0.png" alt="output_74_0"></p>
<p>结果分析：当股价第一次突破唐奇安通道<strong>上沿</strong>时，程序进性了<strong>买入</strong>，但随后的几天中，股价再次突破了上沿，但由于此时已经有1手持仓，故没有再次买入。之后股价<strong>急转直下</strong>，突破了通道<strong>下沿</strong>，程序下单<strong>卖出</strong>。以此类推，在选定的时间范围内，程序进行了6笔交易。</p>
<h3 id="2-3-3-对海龟交易进行回测"><a href="#2-3-3-对海龟交易进行回测" class="headerlink" title="2.3.3 对海龟交易进行回测"></a>2.3.3 对海龟交易进行回测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># SimHei表示简体黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span>  <span class="comment"># 为了正确显示负号</span></span><br><span class="line"><span class="comment">#再次给小瓦2万块初始资金</span></span><br><span class="line">initial_cash = <span class="number">20000</span></span><br><span class="line"><span class="comment">#创建新的数据表，序号和turtle数据表一致</span></span><br><span class="line">positions = pd.DataFrame(index=turtle.index).fillna(<span class="number">0.0</span>)</span><br><span class="line"><span class="comment">#每次交易为1手，即100股，仓位即买单和卖单的累积加和</span></span><br><span class="line">positions[<span class="string">&#x27;stock&#x27;</span>] = <span class="number">100</span> * turtle[<span class="string">&#x27;orders&#x27;</span>].cumsum()</span><br><span class="line"><span class="comment">#创建投资组合数据表</span></span><br><span class="line">portfolio = positions.multiply(zgpa[<span class="string">&#x27;close&#x27;</span>], axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#持仓市值为持仓股票数乘以股价</span></span><br><span class="line">portfolio[<span class="string">&#x27;holding_values&#x27;</span>] = (positions.multiply(zgpa[<span class="string">&#x27;close&#x27;</span>], axis=<span class="number">0</span>))</span><br><span class="line"><span class="comment">#计算出仓位的变化</span></span><br><span class="line">pos_diff = positions.diff()</span><br><span class="line"><span class="comment">#剩余的现金是初始资金减去仓位变化产生的现金流累计加和</span></span><br><span class="line">portfolio[<span class="string">&#x27;cash&#x27;</span>] = initial_cash - (pos_diff.multiply(zgpa[<span class="string">&#x27;close&#x27;</span>], axis=<span class="number">0</span>)).cumsum()</span><br><span class="line"><span class="comment">#总资产即为持仓股票市值加剩余现金</span></span><br><span class="line">portfolio[<span class="string">&#x27;total&#x27;</span>] = portfolio[<span class="string">&#x27;cash&#x27;</span>] + portfolio[<span class="string">&#x27;holding_values&#x27;</span>]</span><br><span class="line"><span class="comment">#使用可视化的方式展示</span></span><br><span class="line"><span class="comment">#下面的代码都很熟悉了，就不逐行注释了</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(portfolio[<span class="string">&#x27;total&#x27;</span>],label=<span class="string">&#x27;总资产&#x27;</span>)</span><br><span class="line">plt.plot(portfolio[<span class="string">&#x27;holding_values&#x27;</span>],<span class="string">&#x27;--&#x27;</span>,label=<span class="string">&#x27;持仓价值&#x27;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xticks([<span class="number">0</span>,<span class="number">12</span>,<span class="number">24</span>,<span class="number">36</span>,<span class="number">48</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_77_0.png" alt="output_77_0"></p>
<p>结果分析：与使用双移动均线相似，在整个股价变动明显的情况下，总资产略有减少</p>
<p>为了对比海龟策略和双移动平均策略的业绩表现，我们可以可靠使用海龟策略后，我们的总资产究竟少了多少</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#检查最后若干天小瓦的资产情况</span></span><br><span class="line">portfolio.tail(<span class="number">13</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stock</th>
      <th>holding_values</th>
      <th>cash</th>
      <th>total</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2020-03-04</th>
      <td>7382.9</td>
      <td>7382.9</td>
      <td>12327.1</td>
      <td>19710.0</td>
    </tr>
    <tr>
      <th>2020-03-05</th>
      <td>7569.9</td>
      <td>7569.9</td>
      <td>12327.1</td>
      <td>19897.0</td>
    </tr>
    <tr>
      <th>2020-03-06</th>
      <td>7415.9</td>
      <td>7415.9</td>
      <td>12327.1</td>
      <td>19743.0</td>
    </tr>
    <tr>
      <th>2020-03-09</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-10</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-11</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-12</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-13</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-16</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-17</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-18</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-19</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
    <tr>
      <th>2020-03-20</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>19466.0</td>
      <td>19466.0</td>
    </tr>
  </tbody>
</table>
</div>



<p>结果分析：最后总资产为19466元，相比于初始资金20000元，减少了544元；而使用双移动平均策略进行交易，我们的总资产缩水694元。可见，本例中，海龟策略略胜一筹。</p>
<p>其中，双移动平均策略和海龟策略，都是基于市场<strong>动量的变化</strong>而设计的，核心思想如下：如果股价上涨并超过某个点位，说明其<strong>上升</strong>的动量变强，这时应该<strong>买入</strong>；反之，则<strong>下行</strong>的动量增强，此时应该卖出。</p>
<h1 id="3-机器学习在交易中的简单应用"><a href="#3-机器学习在交易中的简单应用" class="headerlink" title="3 机器学习在交易中的简单应用"></a>3 机器学习在交易中的简单应用</h1><h2 id="3-1-机器学习的基本概念"><a href="#3-1-机器学习的基本概念" class="headerlink" title="3.1 机器学习的基本概念"></a>3.1 机器学习的基本概念</h2><h3 id="3-1-1-有监督学习和无监督学习"><a href="#3-1-1-有监督学习和无监督学习" class="headerlink" title="3.1.1 有监督学习和无监督学习"></a>3.1.1 有监督学习和无监督学习</h3><p>有监督学习：已知标签的任务</p>
<p>无监督学习：没有已知标签，但是让模型通过观察特征将它们放入不同类别的过程，就是无监督学习的一种</p>
<h3 id="3-1-2-分类和回归"><a href="#3-1-2-分类和回归" class="headerlink" title="3.1.2 分类和回归"></a>3.1.2 分类和回归</h3><p>分类的任务：给定样本的分类标签，训练模型使其可以将新的样本归入正确的分类中——这时模型的目标是离散的</p>
<p>回归的任务：给定样本的目标值，训练模型使其可以预测出新样本对应的数值——这时模型的目标是连续的</p>
<p>在股票领域，假如预测某只股票在未来会“涨”还是会“跌”，这时模型所做的就是分类的工作，但假如要预测某只股票未来会涨1元，还是8角8分，这时模型所做的就是回归的工作</p>
<h3 id="3-1-3-模型性能的评估"><a href="#3-1-3-模型性能的评估" class="headerlink" title="3.1.3 模型性能的评估"></a>3.1.3 模型性能的评估</h3><p>将掌握的<strong>数据集</strong>拆分为<strong>训练集</strong>和<strong>验证集</strong>，使用训练集训练模型，并使用验证集来评估模型是否可用</p>
<p>例如，某只股票有100天的价格数据，就可以将前80天的数据作为训练集，将后20天的数据作为验证集，同时评估模型分别在<strong>训练集</strong>与<strong>验证集</strong>中的准确率。</p>
<p>如果模型在训练集中的得分很高，而在验证集中的得分很低，说明模型出现了<strong>过拟合</strong>的问题；而如果模型在训练集和验证集中的得分都很低，说明模型出现了<strong>欠拟合</strong>的问题。</p>
<p><strong>要想深入解决这些问题，就需要调整模型的参数、补充数据，或者进行更细致的特征工程</strong>。</p>
<h2 id="3-2-机器学习工具的基本使用方法"><a href="#3-2-机器学习工具的基本使用方法" class="headerlink" title="3.2 机器学习工具的基本使用方法"></a>3.2 机器学习工具的基本使用方法</h2><h3 id="3-2-1-KNN算法的基本原理"><a href="#3-2-1-KNN算法的基本原理" class="headerlink" title="3.2.1 KNN算法的基本原理"></a>3.2.1 KNN算法的基本原理</h3><p>K最近邻，既可以用于分类也可以用于回归<br>它识别<strong>k个最近</strong>的数据点（基于欧几里得距离）来进行预测，它分别预测邻域中<strong>最频繁</strong>的分类或是回归情况下的平均结果。</p>
<h3 id="3-2-2-KNN算法用于分类"><a href="#3-2-2-KNN算法用于分类" class="headerlink" title="3.2.2 KNN算法用于分类"></a>3.2.2 KNN算法用于分类</h3><p>1.载入数据集并查看</p>
<p>scikit-learn内置了一些供大家学习的玩具数据集，有些是分类任务的数据，有些是回归任务的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先导入鸢尾花数据载入工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="comment">#导入KNN分类模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="comment">#为了方便可视化，我们再导入matplotlib和seaborn</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加载鸢尾花数据集，赋值给iris变量</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"><span class="comment">#查看数据集的键名</span></span><br><span class="line">iris.keys()</span><br></pre></td></tr></table></figure>




<pre><code>dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;frame&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;, &#39;filename&#39;])
</code></pre>
<p>该数据集存储了若干个健，我们重点关注一下其中的target和feature_names，因为这两个健对应的分别是样本的<strong>分类标签</strong>和<strong>特征名称</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看数据集的特征名称</span></span><br><span class="line">iris.feature_names</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;sepal length (cm)&#39;,
 &#39;sepal width (cm)&#39;,
 &#39;petal length (cm)&#39;,
 &#39;petal width (cm)&#39;]
</code></pre>
<p>数据集样本有四个特征：sepal length（萼片长度）、sepal width（萼片宽度）、petal lenght（花瓣长度）和petal width（花瓣宽度）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看数据集中的样本分类</span></span><br><span class="line">iris.target</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
</code></pre>
<p>说明数据集中的样本分为3类，分别用0、1、2这三个数字来表示。</p>
<p>这个数据集的目的是：根据样本鸢尾花萼片和花瓣的长度及宽度，结合分类标签来训练模型，以便让模型可以预测出某一种鸢尾花属于哪个分类</p>
<p>2.拆分数据集</p>
<p>下面我们把数据集拆分为训练集和验证集，以便验证模型的准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将样本的特征和标签分别赋值给X和y</span></span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"><span class="comment">#查看是否成功</span></span><br><span class="line">X.shape</span><br></pre></td></tr></table></figure>




<pre><code>(150, 4)
</code></pre>
<p>可知，样本数量共有150个，每个样本有4个特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入数据集拆分工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment">#将X和y拆分为训练集与验证集</span></span><br><span class="line">X_train, X_test, y_train, y_test =\</span><br><span class="line">train_test_split(X, y)</span><br><span class="line"><span class="comment">#查看拆分情况</span></span><br><span class="line">X_train.shape</span><br></pre></td></tr></table></figure>




<pre><code>(112, 4)
</code></pre>
<p>通过拆分，训练集中的样本数量为112个，其余的38个样本则进入了验证集</p>
<p>3.训练模型并评估准确率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建knn分类器,参数保持默认</span></span><br><span class="line">knn_clf = KNeighborsClassifier()</span><br><span class="line"><span class="comment">#使用训练集拟合模型</span></span><br><span class="line">knn_clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#查看模型在训练集和验证集中的准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练集准确率：%.2f&#x27;</span>%knn_clf.score(X_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;验证集准确率：%.2f&#x27;</span>%knn_clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure>

<pre><code>训练集准确率：0.96
验证集准确率：0.97
</code></pre>
<p>从上面的代码可以看出，使用KNN算法训练的分类模型，在训练集中的准确率达到了96%，在验证集中的准确率达到了97%。非常不错</p>
<p>在scikit-learn中，KNN可以通过调节n_neighbors参数来改进模型的性能。在不手动指定的情况下，KNN默认的近邻参数n_neighbors为5。我们可以使用网格搜索法来寻找到模型的最优参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn_clf</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsClassifier()
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入网格搜索</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="comment">#定义一个从1到10的n_neighbors</span></span><br><span class="line">n_neighbors = <span class="built_in">tuple</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#创建网格搜索实例，estimator用KNN分类器</span></span><br><span class="line"><span class="comment">#把刚刚定义的n_neighbors传入给param_grid参数</span></span><br><span class="line"><span class="comment">#cv参数指交叉验证次数为5</span></span><br><span class="line">cv = GridSearchCV(estimator=KNeighborsClassifier(),</span><br><span class="line">                 param_grid = &#123;<span class="string">&#x27;n_neighbors&#x27;</span>:n_neighbors&#125;,</span><br><span class="line">                 cv = <span class="number">5</span>)</span><br><span class="line"><span class="comment">#使用网格搜索拟合数据集</span></span><br><span class="line">cv.fit(X,y)</span><br><span class="line"><span class="comment">#查看最优参数</span></span><br><span class="line">cv.best_params_</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;n_neighbors&#39;: 6&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n_neighbors</span><br></pre></td></tr></table></figure>




<pre><code>(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
</code></pre>
<p>当n_neighbors参数为6时，模型的准确率是最高的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建knn分类器,n_neighbors设置为6</span></span><br><span class="line">knn_clf = KNeighborsClassifier(n_neighbors=<span class="number">6</span>)</span><br><span class="line"><span class="comment">#使用模型拟合训练集数据</span></span><br><span class="line">knn_clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#查看模型在训练集和验证集中的准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练集准确率：%.2f&#x27;</span>%knn_clf.score(X_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;验证集准确率：%.2f&#x27;</span>%knn_clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure>

<pre><code>训练集准确率：0.96
验证集准确率：0.97
</code></pre>
<h3 id="3-2-3-KNN算法用于回归"><a href="#3-2-3-KNN算法用于回归" class="headerlink" title="3.2.3 KNN算法用于回归"></a>3.2.3 KNN算法用于回归</h3><p>1.载入数据集并查看</p>
<p>波士顿房价数据集，该数据集中有506个样本，每个样本有13个特征，以及对应的价格（target）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#载入波士顿房价数据集导入工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="comment">#将数据导入</span></span><br><span class="line">boston = load_boston()</span><br><span class="line"><span class="comment">#查看数据集的键名</span></span><br><span class="line">boston.keys()</span><br></pre></td></tr></table></figure>




<pre><code>dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;feature_names&#39;, &#39;DESCR&#39;, &#39;filename&#39;])
</code></pre>
<p>数据集中存储了5个健，我们重点关注target（房屋的售价）及feature_names（房屋的特征），也就是说，我们需要训练模型，让它学习房屋特征和售价的关系，并且可以自动预测出新房屋的售价</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看样本的特征名称</span></span><br><span class="line">boston.feature_names</span><br></pre></td></tr></table></figure>




<pre><code>array([&#39;CRIM&#39;, &#39;ZN&#39;, &#39;INDUS&#39;, &#39;CHAS&#39;, &#39;NOX&#39;, &#39;RM&#39;, &#39;AGE&#39;, &#39;DIS&#39;, &#39;RAD&#39;,
       &#39;TAX&#39;, &#39;PTRATIO&#39;, &#39;B&#39;, &#39;LSTAT&#39;], dtype=&#39;&lt;U7&#39;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#选取前十套房屋，查看售价</span></span><br><span class="line">boston.target[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9])
</code></pre>
<p>2.拆分数据集并训练模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将样本特征和售价赋值给X，y</span></span><br><span class="line">X, y = boston.data, boston.target</span><br><span class="line"><span class="comment">#使用train_test_split拆分为训练集和验证集</span></span><br><span class="line">X_train, X_test, y_train, y_test =\</span><br><span class="line">train_test_split(X, y)</span><br><span class="line"><span class="comment">#查看拆分的结果</span></span><br><span class="line">X_train.shape</span><br></pre></td></tr></table></figure>




<pre><code>(379, 13)
</code></pre>
<p>训练集中有379个样本，其余127个样本进入了验证集</p>
<p>下面开始模型的训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入KNN回归算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"><span class="comment">#创建一个实例，参数保持默认</span></span><br><span class="line">knn_reg = KNeighborsRegressor()</span><br><span class="line"><span class="comment">#拟合训练集数据</span></span><br><span class="line">knn_reg.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#查看模型在训练集和验证集的性能表现</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练集准确率：%.2f&#x27;</span>%knn_reg.score(X_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;验证集准确率：%.2f&#x27;</span>%knn_reg.score(X_test, y_test))</span><br></pre></td></tr></table></figure>

<pre><code>训练集准确率：0.68
验证集准确率：0.55
</code></pre>
<p>结果分析：缺省参数的KNN回归模型在该数据集中的性能表现差强人意，在训练集中的准确率只有68%，而在验证集中只有55%，这说明模型出现了欠拟合的问题，我们需要对数据集进行处理，或者对模型进行调优</p>
<p>3.模型评估的不同方法和改进</p>
<p>不论是在分类模型中还是回归模型中，我们都使用了**.score()方法**，来评估模型的性能。然和，在两种模型中，.score()方法所进行的计算是不一样的。分类模型中，.score()返回的是模型预测的准确率，其计算公式为:</p>
<p><strong>acc&#x3D;(TP+TN)&#x2F;(TP+FP+TN+FN)</strong></p>
<p>在上面公式中，TP(True Positive)表示模型预测正确的正样本数量；TN(True Negative)表示模型预测正确的负样本数量；FP(False Positive)表示原本是负样本，却被模型预测为正样本的数量。也就是我们平时说的“假阳性”；FN(False Negative)表示原本是正样本，却被模型预测为负样本的数量，也就是“假阴性”。TP、FP、TN、FN的和就是所有样本的样本数量。也就是说，<strong>分类模型的准确率是模型预测正确的样本数量，除以全部参与预测的样本数量</strong>。当然除了准确率外，我们还可以用Precision、Recall、F1score等方法来对模型进行性能评估。</p>
<p>在回归模型中，.score()方法返回的是模型的R^2，它是描述模型预测数值与真实值差距的指标，计算公式为：</p>
<p><img src="%E4%B8%8B%E8%BD%BD.png" alt="下载"></p>
<p>其中，y^代表模型对样本的估计值，y-可代表的是样本真实值的均值。也就是说，R^2是样本真实值减模型估计值，再进行平方并求和，除以样本真实值减样本平均值的平方和，最后用1减去这个结果。因此R^2取值为0-1，并且越接近1，说明模型的性能越好。</p>
<p>除了R^2外，回归模型还可以用均方误差MSE、绝对中位差MAE等指标来进行评估</p>
<p>前面说了，缺省参数的KNN模型再波士顿房价预测这个任务中表现并不理想。下面尝试对KNN回归的参数进行调整，看是否可以改进模型的性能。与分类模型一样，我们先使用网格搜索来寻找模型的最优参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这次让n_neighbors参数从1到20遍历</span></span><br><span class="line">n_neighbors = <span class="built_in">tuple</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">21</span>,<span class="number">1</span>))</span><br><span class="line"><span class="comment">#创建KNN回归的网格搜索实例</span></span><br><span class="line">cv_reg = GridSearchCV(estimator = KNeighborsRegressor(),</span><br><span class="line">                     param_grid = &#123;<span class="string">&#x27;n_neighbors&#x27;</span>:n_neighbors&#125;,</span><br><span class="line">                     cv = <span class="number">5</span>)</span><br><span class="line"><span class="comment">#用网格搜索拟合数据集</span></span><br><span class="line">cv_reg.fit(X, y)</span><br><span class="line"><span class="comment">#返回最佳参数</span></span><br><span class="line">cv_reg.best_params_</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;n_neighbors&#39;: 10&#125;
</code></pre>
<p>可以看出，KNN回归模型的最佳n_neighbors参数是10，也就是说，当n_neighbors取10时，模型的R^2最高</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看最佳参数对应的最佳模型R平方分数</span></span><br><span class="line">cv.best_score_</span><br></pre></td></tr></table></figure>




<pre><code>0.9800000000000001
</code></pre>
<p>R^2提高到了98%，说明在性能方面有了显著提升</p>
<h2 id="3-3-基于机器学习的简单交易策略"><a href="#3-3-基于机器学习的简单交易策略" class="headerlink" title="3.3 基于机器学习的简单交易策略"></a>3.3 基于机器学习的简单交易策略</h2><h3 id="3-3-1-获取股票数据"><a href="#3-3-1-获取股票数据" class="headerlink" title="3.3.1 获取股票数据"></a>3.3.1 获取股票数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入Pandas</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment">#导入金融数据获取模块datareader</span></span><br><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts</span><br><span class="line"><span class="comment">#导入numpy，一会儿会用到</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先我们来定义一个函数，用来获取数据</span></span><br><span class="line"><span class="comment">#传入的三个参数分别是开始日期，结束日期和输出的文件名</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_stock</span>(<span class="params">start_date, end_date, output_file</span>):</span><br><span class="line">    <span class="comment">#首先让程序尝试读取已下载并保存的文件</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        df = pd.read_pickle(output_file)</span><br><span class="line">        <span class="comment">#如果文件已存在，则打印载入股票数据文件完毕</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;载入股票数据文件完毕&#x27;</span>)</span><br><span class="line">    <span class="comment">#如果没有找到文件，则重新进行下载</span></span><br><span class="line">    <span class="keyword">except</span> FileNotFoundError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;文件未找到，重新下载中&#x27;</span>)</span><br><span class="line">        <span class="comment">#这里制定下载中国平安（601318）的交易数据</span></span><br><span class="line">        <span class="comment">#下载源为yahoo</span></span><br><span class="line">        df = ts.get_k_data(<span class="string">&#x27;601318&#x27;</span>, start_date, end_date)</span><br><span class="line">        df = df.set_index(<span class="string">&#x27;date&#x27;</span>)</span><br><span class="line">        <span class="comment">#下载成功后保存为pickle文件</span></span><br><span class="line">        df.to_pickle(output_file)</span><br><span class="line">        <span class="comment">#并通知我们下载完成</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;下载完成&#x27;</span>)</span><br><span class="line">    <span class="comment">#最后将下载的数据表进行返回</span></span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面使用我们定义好的函数来获取中国平安的交易数据</span></span><br><span class="line"><span class="comment">#获取三年的数据，从2017年3月9日至2020年的3月5日</span></span><br><span class="line"><span class="comment">#保存为名为601318的pickle文件</span></span><br><span class="line">zgpa = load_stock(start_date = <span class="string">&#x27;2017-03-09&#x27;</span>, </span><br><span class="line">                  end_date = <span class="string">&#x27;2020-03-05&#x27;</span>,</span><br><span class="line">                 output_file = <span class="string">&#x27;601318.pkl&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>文件未找到，重新下载中
本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2
下载完成
</code></pre>
<p>因为这里是第一次使用load_stock函数来获取数据，所以程序会提示没有找到文件，并重新开始下载文件。稍等片刻后，我们可以看到程序告知数据下载完成</p>
<p>如果想要查看自己已经下载好的数据，可以：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看一下数据的前五行</span></span><br><span class="line">zgpa.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>code</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-03-09</th>
      <td>24.301</td>
      <td>24.311</td>
      <td>24.331</td>
      <td>24.031</td>
      <td>377966.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2017-03-10</th>
      <td>24.241</td>
      <td>24.131</td>
      <td>24.301</td>
      <td>24.111</td>
      <td>207446.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2017-03-13</th>
      <td>24.131</td>
      <td>24.501</td>
      <td>24.571</td>
      <td>24.091</td>
      <td>359990.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2017-03-14</th>
      <td>24.521</td>
      <td>24.471</td>
      <td>24.661</td>
      <td>24.341</td>
      <td>276964.0</td>
      <td>601318</td>
    </tr>
    <tr>
      <th>2017-03-15</th>
      <td>24.411</td>
      <td>24.491</td>
      <td>24.531</td>
      <td>24.291</td>
      <td>268720.0</td>
      <td>601318</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="3-3-2-创建交易条件"><a href="#3-3-2-创建交易条件" class="headerlink" title="3.3.2 创建交易条件"></a>3.3.2 创建交易条件</h3><p>我们做一点简单的特征工程，以便后续工作。</p>
<p>这里用每日开盘价减去收盘价，并保存为一个新的特征。</p>
<p>用最高价减去最低价，保存为另一个特征。</p>
<p>如果股票次日收盘价高于当日收盘价，则标记为1，代表次日股票价格上涨，反之，如果次日收盘价低于当日收盘价，则标记为-1，代表股票次日价格下跌或者不变。这个过程可以称为创建股票的交易条件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面我们来定义一个用于分类的函数，给数据表增加三个字段</span></span><br><span class="line"><span class="comment">#首先是开盘价减收盘价，命名为‘Open-Close’</span></span><br><span class="line"><span class="comment">#其次是最高价减最低价，命名为‘High-Low’</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classification_tc</span>(<span class="params">df</span>):</span><br><span class="line">    df[<span class="string">&#x27;Open-Close&#x27;</span>] = df[<span class="string">&#x27;open&#x27;</span>] - df[<span class="string">&#x27;close&#x27;</span>]</span><br><span class="line">    df[<span class="string">&#x27;High-Low&#x27;</span>] = df[<span class="string">&#x27;high&#x27;</span>] - df[<span class="string">&#x27;low&#x27;</span>]</span><br><span class="line">    <span class="comment">#在添加一个target字段，如果次日收盘价高于当日收盘价，则标记为1，反之为-1</span></span><br><span class="line">    df[<span class="string">&#x27;target&#x27;</span>] = np.where(df[<span class="string">&#x27;close&#x27;</span>].shift(-<span class="number">1</span>)&gt;df[<span class="string">&#x27;close&#x27;</span>], <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#去掉有空值的行</span></span><br><span class="line">    df = df.dropna()</span><br><span class="line">    <span class="comment">#将‘Open-Close’和‘High-Low’作为数据集的特征</span></span><br><span class="line">    X = df[[<span class="string">&#x27;Open-Close&#x27;</span>, <span class="string">&#x27;High-Low&#x27;</span>]]</span><br><span class="line">    <span class="comment">#将target赋值给y</span></span><br><span class="line">    y = df[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">    <span class="comment">#将处理好的数据表以及X与y进行返回</span></span><br><span class="line">    <span class="keyword">return</span>(df,X,y)</span><br></pre></td></tr></table></figure>

<p>这个交易条件可以用来训练分类模型。让模型预测某只股票在下一个交易日价格上涨与否</p>
<p>现创造一个用于回归模型的交易条件。将次日收盘价减去当日收盘价的差价作为预测的目标。这样就可以训练回归模型，使其预测次日股价上涨（或下跌）的幅度，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面定义一个用于回归的函数</span></span><br><span class="line"><span class="comment">#特征的添加和分类函数类似</span></span><br><span class="line"><span class="comment">#只不过target字段改为次日收盘价减去当日收盘价</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regression_tc</span>(<span class="params">df</span>):</span><br><span class="line">    df[<span class="string">&#x27;Open-Close&#x27;</span>] = df[<span class="string">&#x27;open&#x27;</span>] - df[<span class="string">&#x27;close&#x27;</span>]</span><br><span class="line">    df[<span class="string">&#x27;High-Low&#x27;</span>] = df[<span class="string">&#x27;high&#x27;</span>] - df[<span class="string">&#x27;low&#x27;</span>]</span><br><span class="line">    df[<span class="string">&#x27;target&#x27;</span>] = df[<span class="string">&#x27;close&#x27;</span>].shift(-<span class="number">1</span>) - df[<span class="string">&#x27;close&#x27;</span>]</span><br><span class="line">    df = df.dropna()</span><br><span class="line">    X = df[[<span class="string">&#x27;Open-Close&#x27;</span>, <span class="string">&#x27;High-Low&#x27;</span>]]</span><br><span class="line">    y = df[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">    <span class="comment">#将处理好的数据表以及X与y进行返回</span></span><br><span class="line">    <span class="keyword">return</span>(df,X,y)</span><br></pre></td></tr></table></figure>

<p>与分类交易条件一样，我们同样是把股票当日的开盘价和收盘价的差，与最高价和最低价的差作为样本的特征。不同的是，预测目标变成了次日收盘价与当日收盘价的差。</p>
<h3 id="3-3-3-使用分类算法制定交易策略"><a href="#3-3-3-使用分类算法制定交易策略" class="headerlink" title="3.3.3 使用分类算法制定交易策略"></a>3.3.3 使用分类算法制定交易策略</h3><p>我们使用上一节中定义的函数来处理下载好的股票数据，生成训练集与验证集，并训练一个简单的模型，以执行我们的交易策略</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用classification_tc函数生成数据集的特征与目标</span></span><br><span class="line">df, X, y = classification_tc(zgpa)</span><br><span class="line"><span class="comment">#将数据集拆分为训练集与验证集</span></span><br><span class="line">X_train, X_test, y_train, y_test =\</span><br><span class="line">train_test_split(X, y, shuffle=<span class="literal">False</span>,train_size=<span class="number">0.8</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>code</th>
      <th>Open-Close</th>
      <th>High-Low</th>
      <th>target</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-03-09</th>
      <td>24.301</td>
      <td>24.311</td>
      <td>24.331</td>
      <td>24.031</td>
      <td>377966.0</td>
      <td>601318</td>
      <td>-0.01</td>
      <td>0.30</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>2017-03-10</th>
      <td>24.241</td>
      <td>24.131</td>
      <td>24.301</td>
      <td>24.111</td>
      <td>207446.0</td>
      <td>601318</td>
      <td>0.11</td>
      <td>0.19</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2017-03-13</th>
      <td>24.131</td>
      <td>24.501</td>
      <td>24.571</td>
      <td>24.091</td>
      <td>359990.0</td>
      <td>601318</td>
      <td>-0.37</td>
      <td>0.48</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>2017-03-14</th>
      <td>24.521</td>
      <td>24.471</td>
      <td>24.661</td>
      <td>24.341</td>
      <td>276964.0</td>
      <td>601318</td>
      <td>0.05</td>
      <td>0.32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2017-03-15</th>
      <td>24.411</td>
      <td>24.491</td>
      <td>24.531</td>
      <td>24.291</td>
      <td>268720.0</td>
      <td>601318</td>
      <td>-0.08</td>
      <td>0.24</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建一个knn实例，n_neighbors取95</span></span><br><span class="line">knn_clf = KNeighborsClassifier(n_neighbors=<span class="number">95</span>)</span><br><span class="line"><span class="comment">#使用knn拟合训练集</span></span><br><span class="line">knn_clf.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#打印模型在训练集中的准确率</span></span><br><span class="line"><span class="built_in">print</span>(knn_clf.score(X_train, y_train))</span><br><span class="line"><span class="comment">#打印模型在验证集中的准确率</span></span><br><span class="line"><span class="built_in">print</span>(knn_clf.score(X_test, y_test))</span><br></pre></td></tr></table></figure>

<pre><code>0.5643224699828473
0.4863013698630137
</code></pre>
<p>结果分析：使用经过处理的数据集训练的KNN模型，在训练集中的准确率和验证集中的准确率仍然不高。原因是我们训练模型的样本特征确实<strong>太少</strong>了，无法支撑模型做出正确的判断。</p>
<p>既然模型已经可以做出预测（不论准确率如何），接下来我们就可以来验证一下，使用模型预测作为<strong>交易信号</strong>来进行交易，并且与<strong>基准收益</strong>进行对比。首先我们要计算出<strong>基准收益</strong>和<strong>基于模型预测的策略所带来的收益</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用KNN模型预测每日股票的涨跌，保存为‘Predict_Signal’</span></span><br><span class="line">df[<span class="string">&#x27;Predict_Signal&#x27;</span>] = knn_clf.predict(X)</span><br><span class="line"><span class="comment">#在数据集中添加一个字段，用当日收盘价除以前一日收盘价，并取其自然对数</span></span><br><span class="line">df[<span class="string">&#x27;Return&#x27;</span>] = np.log(df[<span class="string">&#x27;close&#x27;</span>]/df[<span class="string">&#x27;close&#x27;</span>].shift(<span class="number">1</span>))</span><br><span class="line"><span class="comment">#查看一下</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>volume</th>
      <th>code</th>
      <th>Open-Close</th>
      <th>High-Low</th>
      <th>target</th>
      <th>Predict_Signal</th>
      <th>Return</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-03-09</th>
      <td>24.301</td>
      <td>24.311</td>
      <td>24.331</td>
      <td>24.031</td>
      <td>377966.0</td>
      <td>601318</td>
      <td>-0.01</td>
      <td>0.30</td>
      <td>-1</td>
      <td>1</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2017-03-10</th>
      <td>24.241</td>
      <td>24.131</td>
      <td>24.301</td>
      <td>24.111</td>
      <td>207446.0</td>
      <td>601318</td>
      <td>0.11</td>
      <td>0.19</td>
      <td>1</td>
      <td>1</td>
      <td>-0.007432</td>
    </tr>
    <tr>
      <th>2017-03-13</th>
      <td>24.131</td>
      <td>24.501</td>
      <td>24.571</td>
      <td>24.091</td>
      <td>359990.0</td>
      <td>601318</td>
      <td>-0.37</td>
      <td>0.48</td>
      <td>-1</td>
      <td>1</td>
      <td>0.015217</td>
    </tr>
    <tr>
      <th>2017-03-14</th>
      <td>24.521</td>
      <td>24.471</td>
      <td>24.661</td>
      <td>24.341</td>
      <td>276964.0</td>
      <td>601318</td>
      <td>0.05</td>
      <td>0.32</td>
      <td>1</td>
      <td>1</td>
      <td>-0.001225</td>
    </tr>
    <tr>
      <th>2017-03-15</th>
      <td>24.411</td>
      <td>24.491</td>
      <td>24.531</td>
      <td>24.291</td>
      <td>268720.0</td>
      <td>601318</td>
      <td>-0.08</td>
      <td>0.24</td>
      <td>1</td>
      <td>1</td>
      <td>0.000817</td>
    </tr>
  </tbody>
</table>
</div>



<p>从表中我们可以看出，数据表中的Predict_Signal存储的是KNN模型对股票涨跌的预测，而Return是指当日股票价格变动所带来的收益。</p>
<p>下面我们定义一个函数，计算一下累计的<strong>基准收益</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义一个计算累计回报的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cum_return</span>(<span class="params">df, split_value</span>):</span><br><span class="line">    <span class="comment">#该股票基准收益为‘Return’的总和*100</span></span><br><span class="line">    cum_return = df[split_value:][<span class="string">&#x27;Return&#x27;</span>].cumsum()*<span class="number">100</span></span><br><span class="line">    <span class="comment">#将计算结果进行返回</span></span><br><span class="line">    <span class="keyword">return</span> cum_return</span><br></pre></td></tr></table></figure>

<p>再定义一个函数，计算基于<strong>KNN模型预测</strong>的交易信号所进行的策略交易带来的收益：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#再定义一个计算使用策略交易的收益</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">strategy_return</span>(<span class="params">df, split_value</span>):</span><br><span class="line">    <span class="comment">#使用策略交易的收益为模型‘zgpa_Return’乘以模型预测的涨跌幅</span></span><br><span class="line">    df[<span class="string">&#x27;Strategy_Return&#x27;</span>] = df[<span class="string">&#x27;Return&#x27;</span>]*df[<span class="string">&#x27;Predict_Signal&#x27;</span>].shift(<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#将每日策略交易的收益加和并乘以100</span></span><br><span class="line">    cum_strategy_return = df[split_value:][<span class="string">&#x27;Strategy_Return&#x27;</span>].cumsum()*<span class="number">100</span></span><br><span class="line">    <span class="comment">#将计算结果进行返回</span></span><br><span class="line">    <span class="keyword">return</span> cum_strategy_return</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义一个绘图函数，用来对比基准收益和算法交易的收益</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_chart</span>(<span class="params">cum_return, cum_strategy_return, symbol</span>):</span><br><span class="line">    <span class="comment">#首先是定义画布的尺寸</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">9</span>,<span class="number">6</span>))</span><br><span class="line">    <span class="comment">#使用折线图绘制基准收益</span></span><br><span class="line">    plt.plot(cum_return, <span class="string">&#x27;--&#x27;</span>,label=<span class="string">&#x27;%s Returns&#x27;</span>%symbol)</span><br><span class="line">    <span class="comment">#使用折线图绘制算法交易收益</span></span><br><span class="line">    plt.plot(cum_strategy_return, label = <span class="string">&#x27;Strategy Returns&#x27;</span>)</span><br><span class="line">    <span class="comment">#添加图注</span></span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.xticks([<span class="number">0</span>,<span class="number">36</span>,<span class="number">72</span>,<span class="number">108</span>,<span class="number">145</span>])</span><br><span class="line">    <span class="comment">#显示图像</span></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先来计算基准收益（预测集）</span></span><br><span class="line">cum_return = cum_return(df, split_value=<span class="built_in">len</span>(X_train))</span><br><span class="line"><span class="comment">#然后是计算使用算法交易带来的收益（同样只计算预测集）</span></span><br><span class="line">cum_strategy_return = strategy_return(df, </span><br><span class="line">                                      split_value=<span class="built_in">len</span>(X_train))</span><br><span class="line"><span class="comment">#用图像来进行对比</span></span><br><span class="line">plot_chart(cum_return, cum_strategy_return, <span class="string">&#x27;zgpa&#x27;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="output_158_0.png" alt="output_158_0"></p>
<p>结果分析：虚线部分是该股票的累积基准收益，实线部分是使用算法进行交易的累计收益。虽然这里使用KNN分类模型的准确率并不高，但使用该模型预测涨跌后，进行交易的收益还是高于该股票的基准收益的。如果我们通过补充因子（或者说数据集的特征）的方法来进一步提高模型的准确率的话，则算法交易带来的收益还会显著提高。</p>
<p><strong>注意</strong>：与第二章所使用的回测方式不同，这里我们通过对<strong>算法交易收益</strong>与<strong>基准收益</strong>的对比来评估策略的业绩，而这种方法在实际中更为普遍。</p>
<h1 id="4-多来点数据——借助量化交易平台"><a href="#4-多来点数据——借助量化交易平台" class="headerlink" title="4 多来点数据——借助量化交易平台"></a>4 多来点数据——借助量化交易平台</h1><h2 id="4-1-数据不够，平台来凑"><a href="#4-1-数据不够，平台来凑" class="headerlink" title="4.1 数据不够，平台来凑"></a>4.1 数据不够，平台来凑</h2><h3 id="4-1-1-选择量化交易平台——聚宽"><a href="#4-1-1-选择量化交易平台——聚宽" class="headerlink" title="4.1.1 选择量化交易平台——聚宽"></a>4.1.1 选择量化交易平台——聚宽</h3><h3 id="4-1-2-量化交易平台的研究环境"><a href="#4-1-2-量化交易平台的研究环境" class="headerlink" title="4.1.2 量化交易平台的研究环境"></a>4.1.2 量化交易平台的研究环境</h3><p>后续代码在聚宽上实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">聚宽</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/量化交易//" class="article-tag-list-link color5">量化交易</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/03/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BApython%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93%E5%AE%9E%E6%88%98-part1/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-python大数据分析与机器学习商业案例实战-part4" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part4/">Python大数据分析与机器学习商业案例实战-part4</a>
    </h1>
  

        
        <a href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part4/" class="archive-article-date">
  	<time datetime="2023-02-03T10:13:14.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-03</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="13-数据聚类与分群分析"><a href="#13-数据聚类与分群分析" class="headerlink" title="13 数据聚类与分群分析"></a>13 数据聚类与分群分析</h1><p>机器学习可以分为监督学习和无监督学习两大类，其中非监督学习的数据集只有特征变量，而没有目标变量，我们需要对已有的数据进行建模，根据性质及进行分组。其典型案例是聚类分析问题，例如根据信用卡申请人进行分类（客户分群），根据新闻标题和内容对新闻进行分类等。</p>
<h2 id="13-1-KMeans算法"><a href="#13-1-KMeans算法" class="headerlink" title="13.1 KMeans算法"></a>13.1 KMeans算法</h2><h3 id="13-1-1-KMeans算法的基本原理"><a href="#13-1-1-KMeans算法的基本原理" class="headerlink" title="13.1.1 KMeans算法的基本原理"></a>13.1.1 KMeans算法的基本原理</h3><p>KMeans算法名称中的K代表类别数量，Means代表每个类别内样本的均值，所以又称为K-均值算法。KMeans算法以距离作为样本间相似度的度量标准，将距离相近的样本分配至同一个类别。样本间距离的计算方式可以是欧式距离、曼哈顿距离、余弦相似度等，KMeans算法通常采用欧式距离来度量各样本间的距离</p>
<p>KMeans算法的核心思想是对每个样本点计算到各个中心点的距离，并将该样本点分配给距离最近的中心点代表的类别，一次迭代完成后，根据聚类结果更新每个类别的中心点，然后重复之前操作再次迭代，直到前后两次分类结果没有差别。（下图目的是将8各样本点聚成3各类别K&#x3D;3）<br><img src="%E4%B8%8B%E8%BD%BD%20.png" alt="下载 "></p>
<h3 id="13-1-2-KMeans算法的代码实现"><a href="#13-1-2-KMeans算法的代码实现" class="headerlink" title="13.1.2 KMeans算法的代码实现"></a>13.1.2 KMeans算法的代码实现</h3><p>1.构造数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.array([[<span class="number">3</span>, <span class="number">2</span>], [<span class="number">4</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">6</span>], [<span class="number">4</span>, <span class="number">7</span>], [<span class="number">3</span>, <span class="number">9</span>], [<span class="number">6</span>, <span class="number">8</span>], [<span class="number">6</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">7</span>]])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure>




<pre><code>array([[3, 2],
       [4, 1],
       [3, 6],
       [4, 7],
       [3, 9],
       [6, 8],
       [6, 6],
       [7, 7]])
</code></pre>
<p>2.可视化展示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.scatter(data[:, <span class="number">0</span>], data[:, <span class="number">1</span>], c=<span class="string">&quot;red&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;samples&#x27;</span>)  <span class="comment"># 以红色圆圈样式绘制散点图并加上标签</span></span><br><span class="line">plt.legend()  <span class="comment"># 设置图例，图例内容为上面设置的label参数</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_10_0.png" alt="output_10_0"></p>
<p>第二行代码：data是用numpy库构造的，所以data[:,0]表示两列数的第一列数（第一个元素表示行，冒号表示所有行；第二个元素表示列，0表示第一列），即x坐标，同理，data[:,1]表示y坐标</p>
<p>3.KMeans聚类（聚类成2类）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">kms = KMeans(n_clusters=<span class="number">2</span>) <span class="comment"># K值设置为2</span></span><br><span class="line">kms.fit(data)</span><br></pre></td></tr></table></figure>



<p>4.获取结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label = kms.labels_  <span class="comment"># 通过模型的labels_属性获取聚类结果</span></span><br><span class="line"><span class="built_in">print</span>(label)</span><br></pre></td></tr></table></figure>

<pre><code>[1 1 0 0 0 0 0 0]
</code></pre>
<p>结果表示原数据中前两个数据聚为一类，其他数据聚为另一类</p>
<p>5.结果可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(data[label == <span class="number">0</span>][:, <span class="number">0</span>], data[label == <span class="number">0</span>][:, <span class="number">1</span>], c=<span class="string">&quot;red&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;class0&#x27;</span>)  <span class="comment"># 以红色圆圈样式绘制散点图并加上标签</span></span><br><span class="line">plt.scatter(data[label == <span class="number">1</span>][:, <span class="number">0</span>], data[label == <span class="number">1</span>][:, <span class="number">1</span>], c=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&#x27;*&#x27;</span>, label=<span class="string">&#x27;class1&#x27;</span>)  <span class="comment"># 以绿色星星样式绘制散点图并加上标签</span></span><br><span class="line">plt.legend()  <span class="comment"># 设置图例</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.legend.Legend at 0x19db372cf10&gt;
</code></pre>
<p><img src="output_18_1.png" alt="output_18_1"></p>
<p>6.聚类成3类，并可视化呈现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kms_3 = KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line">kms_3.fit(data)</span><br><span class="line">label_3 = kms_3.labels_</span><br><span class="line"><span class="built_in">print</span>(label_3)</span><br></pre></td></tr></table></figure>


<pre><code>[1 1 2 2 2 0 0 0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(data[label_3 == <span class="number">0</span>][:, <span class="number">0</span>], data[label_3 == <span class="number">0</span>][:, <span class="number">1</span>], c=<span class="string">&quot;red&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;class0&#x27;</span>)  <span class="comment"># 以红色圆圈样式绘制散点图并加上标签</span></span><br><span class="line">plt.scatter(data[label_3 == <span class="number">1</span>][:, <span class="number">0</span>], data[label_3 == <span class="number">1</span>][:, <span class="number">1</span>], c=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&#x27;*&#x27;</span>, label=<span class="string">&#x27;class1&#x27;</span>)  <span class="comment"># 以绿色星星样式绘制散点图并加上标签</span></span><br><span class="line">plt.scatter(data[label_3 == <span class="number">2</span>][:, <span class="number">0</span>], data[label_3 == <span class="number">2</span>][:, <span class="number">1</span>], c=<span class="string">&quot;blue&quot;</span>, marker=<span class="string">&#x27;+&#x27;</span>, label=<span class="string">&#x27;class2&#x27;</span>)  <span class="comment"># 以蓝色加号样式绘制散点图并加上标签</span></span><br><span class="line">plt.legend()  <span class="comment"># 设置图例</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.legend.Legend at 0x19db39903a0&gt;
</code></pre>
<p><img src="output_21_1.png" alt="output_21_1"></p>
<p>说明：因为KMeans算法的初始中心点是随机选取的，所以如果样本数据量比较大，可能会导致每次运行代码得到的聚类结果略有不同，如果希望每次运行的代码得到的聚类结果相同，可以在模型中传入random_state参数，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kms = KMeans(n_clusters=3,random_state=123)</span></span><br></pre></td></tr></table></figure>

<h3 id="13-1-3-案例实战：银行客户分群模型"><a href="#13-1-3-案例实战：银行客户分群模型" class="headerlink" title="13.1.3 案例实战：银行客户分群模型"></a>13.1.3 案例实战：银行客户分群模型</h3><p>1.案例背景</p>
<p>银行拥有海量的客户，对于不同的客户，银行需要采取不同的营销工作策略。例如，对于收入高且风险承受能力强的客户，可以重点挖掘业务机会，如向其推销一些收益率高但周期相对较长的理财产品；对于收入低且风险承受能力较弱的客户，则需要采取其他策略，因此，银行通常需要将客户进行分群处理，以便有的放矢地开展营销工作</p>
<p>2.读取银行客户数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;客户信息.xlsx&#x27;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>年龄(岁)</th>
      <th>收入(万元)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>50</td>
      <td>66</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44</td>
      <td>51</td>
    </tr>
    <tr>
      <th>2</th>
      <td>30</td>
      <td>56</td>
    </tr>
    <tr>
      <th>3</th>
      <td>46</td>
      <td>50</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>50</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.scatter(data.iloc[:, <span class="number">0</span>], data.iloc[:, <span class="number">1</span>], c=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&#x27;*&#x27;</span>)  <span class="comment"># 以绿色星星样式绘制散点图</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;age&#x27;</span>)  <span class="comment"># 添加x轴名称</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;salary&#x27;</span>)  <span class="comment"># 添加y轴名称</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_29_0.png" alt="output_29_0"></p>
<p>可以看出，年龄越大的人收入相对越高，符合认知</p>
<p>3.模型搭建与使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">kms = KMeans(n_clusters=<span class="number">3</span>, random_state=<span class="number">123</span>)</span><br><span class="line">kms.fit(data)</span><br><span class="line">label = kms.labels_</span><br><span class="line">label = kms.fit_predict(data)</span><br><span class="line"><span class="built_in">print</span>(label)</span><br></pre></td></tr></table></figure>


<pre><code>[1 1 2 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 2 2 1 2 1 2 2 2 0 2
 1 2 0 1 1 2 1 2 1 2 1 1 2 2 0 1 2 1 1 1 1 2 1 2 2 2 2 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 1 1 1 2 1 2 0 0 0 0 0 0
 2]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(data[label == <span class="number">0</span>].iloc[:, <span class="number">0</span>], data[label == <span class="number">0</span>].iloc[:, <span class="number">1</span>], c=<span class="string">&quot;red&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;class0&#x27;</span>)  <span class="comment"># 以红色圆圈样式绘制散点图并加上标签  </span></span><br><span class="line">plt.scatter(data[label == <span class="number">1</span>].iloc[:, <span class="number">0</span>], data[label == <span class="number">1</span>].iloc[:, <span class="number">1</span>], c=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&#x27;*&#x27;</span>, label=<span class="string">&#x27;class1&#x27;</span>)  <span class="comment"># 以绿色星星样式绘制散点图并加上标签 </span></span><br><span class="line">plt.scatter(data[label == <span class="number">2</span>].iloc[:, <span class="number">0</span>], data[label == <span class="number">2</span>].iloc[:, <span class="number">1</span>], c=<span class="string">&quot;blue&quot;</span>, marker=<span class="string">&#x27;+&#x27;</span>, label=<span class="string">&#x27;class2&#x27;</span>)  <span class="comment"># 以蓝色加号样式绘制散点图并加上标签</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;age&#x27;</span>)  <span class="comment"># 添加x轴名称</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;salary&#x27;</span>)  <span class="comment"># 添加y轴名称</span></span><br><span class="line">plt.legend()  <span class="comment"># 设置图例</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.legend.Legend at 0x19db375bf70&gt;
</code></pre>
<p><img src="output_33_1.png" alt="output_33_1"></p>
<p>在上图中，class1代表的这部分客户年龄为40-50岁，平均收入58万元，可以视为重点客户，是需要重点营销和推广的对象；class2代表的这部分客户年龄为25-42岁，平均收入46万元，可以视为优质客户，是需要精心维护和营销的对象；class0代表的这部分客户年龄为20-40岁，平均收入21万元，可以视为潜力客户，是需要耐心挖掘和等待都对象</p>
<p><strong>补充知识点，查看各标签人的收入均值</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(data[label == <span class="number">0</span>].iloc[:, <span class="number">1</span>].mean())  <span class="comment"># 看下分类为标签0的人的收入均值，iloc[:, 1]为data表格的第二列，也即“收入”列</span></span><br><span class="line"><span class="built_in">print</span>(data[label == <span class="number">1</span>].iloc[:, <span class="number">1</span>].mean())</span><br><span class="line"><span class="built_in">print</span>(data[label == <span class="number">2</span>].iloc[:, <span class="number">1</span>].mean())</span><br></pre></td></tr></table></figure>

<pre><code>21.125
57.55555555555556
46.285714285714285
</code></pre>
<h2 id="13-2-DBSCAN算法"><a href="#13-2-DBSCAN算法" class="headerlink" title="13.2 DBSCAN算法"></a>13.2 DBSCAN算法</h2><p>DBCAN（Density-Based Apatial Clustering of Applications with Noise）是一种以密度为基础的空间聚类算法，可以用密度的概念剔除不属于任一类别的噪声点。该算法将簇定义为密度相连的点的最大集合，将具有足够密度的区域划分为簇，并可以发现任意形状的簇</p>
<h3 id="13-2-1-DBSCAN算法的基本原理"><a href="#13-2-1-DBSCAN算法的基本原理" class="headerlink" title="13.2.1 DBSCAN算法的基本原理"></a>13.2.1 DBSCAN算法的基本原理</h3><p><img src="%E4%B8%8B%E8%BD%BD.png" alt="下载"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(1).png" alt="下载 (1)"></p>
<p>可视化网站：<a target="_blank" rel="noopener" href="https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/">https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/</a></p>
<h3 id="13-2-2-DBSCAN算法的代码实现"><a href="#13-2-2-DBSCAN算法的代码实现" class="headerlink" title="13.2.2 DBSCAN算法的代码实现"></a>13.2.2 DBSCAN算法的代码实现</h3><p>1.读取数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;演示数据.xlsx&#x27;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.44</td>
      <td>5.74</td>
    </tr>
    <tr>
      <th>1</th>
      <td>11.55</td>
      <td>6.16</td>
    </tr>
    <tr>
      <th>2</th>
      <td>11.36</td>
      <td>5.10</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10.62</td>
      <td>6.12</td>
    </tr>
    <tr>
      <th>4</th>
      <td>11.20</td>
      <td>5.39</td>
    </tr>
  </tbody>
</table>
</div>



<p>2.数据可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.scatter(data.iloc[:, <span class="number">0</span>], data.iloc[:, <span class="number">1</span>], c=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&#x27;*&#x27;</span>)  <span class="comment"># 以绿色星星样式绘制散点图</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)  <span class="comment"># 添加x轴名称</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)  <span class="comment"># 添加y轴名称</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_47_0.png" alt="output_47_0"></p>
<p>3.数据建模&#x2F;4.查看聚类结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line">dbs = DBSCAN()  <span class="comment"># 不设置参数，即所有参数都取默认值：画圆半径参数eps取默认值0.5，园内最小样本数参数min_samples取默认值5</span></span><br><span class="line">dbs.fit(data)</span><br><span class="line">label_dbs = dbs.labels_</span><br><span class="line"><span class="built_in">print</span>(label_dbs)</span><br></pre></td></tr></table></figure>

<pre><code>[0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0
 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1
 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DBSCAN?  # 如果想查看DBSCAN的官方说明，可以在其DBSCAN后面加上?进行查看</span></span><br></pre></td></tr></table></figure>

<p>5.用散点图展示DBSCAN算法的聚类结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(data[label_dbs == <span class="number">0</span>].iloc[:, <span class="number">0</span>], data[label_dbs == <span class="number">0</span>].iloc[:, <span class="number">1</span>], c=<span class="string">&quot;red&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;class0&#x27;</span>)  <span class="comment"># 以红色圆圈样式绘制散点图并加上标签  </span></span><br><span class="line">plt.scatter(data[label_dbs == <span class="number">1</span>].iloc[:, <span class="number">0</span>], data[label_dbs == <span class="number">1</span>].iloc[:, <span class="number">1</span>], c=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&#x27;*&#x27;</span>, label=<span class="string">&#x27;class1&#x27;</span>)  <span class="comment"># 以绿色星星样式绘制散点图并加上标签 </span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)  <span class="comment"># 添加x轴名称</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)  <span class="comment"># 添加y轴名称</span></span><br><span class="line">plt.legend()  <span class="comment"># 设置图例</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.legend.Legend at 0x19db4f3e1f0&gt;
</code></pre>
<p><img src="output_52_1.png" alt="output_52_1"></p>
<h3 id="13-2-3-KMeans算法与DBSCAN算法的对比"><a href="#13-2-3-KMeans算法与DBSCAN算法的对比" class="headerlink" title="13.2.3 KMeans算法与DBSCAN算法的对比"></a>13.2.3 KMeans算法与DBSCAN算法的对比</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">KMs = KMeans(n_clusters=<span class="number">2</span>)</span><br><span class="line">KMs.fit(data)</span><br><span class="line">label_kms = KMs.labels_</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># KMs # 这样可以查看模型参数，这里没有设置random_state参数，所以可能每次跑出来的结果略有不同（因为每次起始点选的地方不同）</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(label_kms)</span><br></pre></td></tr></table></figure>

<pre><code>[1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1
 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0
 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(data[label_kms == <span class="number">0</span>].iloc[:, <span class="number">0</span>], data[label_kms == <span class="number">0</span>].iloc[:, <span class="number">1</span>], c=<span class="string">&quot;red&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;class0&#x27;</span>)  <span class="comment"># 以红色圆圈样式绘制散点图并加上标签  </span></span><br><span class="line">plt.scatter(data[label_kms == <span class="number">1</span>].iloc[:, <span class="number">0</span>], data[label_kms == <span class="number">1</span>].iloc[:, <span class="number">1</span>], c=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&#x27;*&#x27;</span>, label=<span class="string">&#x27;class1&#x27;</span>)  <span class="comment"># 以绿色星星样式绘制散点图并加上标签 </span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)  <span class="comment"># 添加x轴名称</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)  <span class="comment"># 添加y轴名称</span></span><br><span class="line">plt.legend()  <span class="comment"># 设置图例</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.legend.Legend at 0x19db4d20df0&gt;
</code></pre>
<p><img src="output_57_1.png" alt="output_57_1"></p>
<p>可以看到，对于形状类似同心圆的数据，KMeans算法聚类效果较差，只能机械地将数据分为左右两部分，而无法以外圆内圆的方式进行区分。</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(2).png" alt="下载 (2)"></p>
<h2 id="13-3-案例实战：新闻聚类分群模型"><a href="#13-3-案例实战：新闻聚类分群模型" class="headerlink" title="13.3 案例实战：新闻聚类分群模型"></a>13.3 案例实战：新闻聚类分群模型</h2><h3 id="13-3-1-案例背景"><a href="#13-3-1-案例背景" class="headerlink" title="13.3.1 案例背景"></a>13.3.1 案例背景</h3><p>新闻种类复杂多样，财经、体育、科技、娱乐等等，在本案例中，笔者根据关键词从百度新闻爬取了962条新闻，且每个关键词对应的新闻条数接近，现在需要对每条新闻划分类别，匹配到正确的版面</p>
<h3 id="13-3-2-文本数据的读取与处理"><a href="#13-3-2-文本数据的读取与处理" class="headerlink" title="13.3.2 文本数据的读取与处理"></a>13.3.2 文本数据的读取与处理</h3><p><strong>1.读取数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;新闻.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>关键词</th>
      <th>标题</th>
      <th>网址</th>
      <th>来源</th>
      <th>时间</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>华能信托</td>
      <td>信托公司2019年上半年经营业绩概览</td>
      <td>http://www.financialnews.com.cn/jrsb_m/xt/zx/2...</td>
      <td>中国金融新闻网</td>
      <td>2019年07月23日 00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>华能信托</td>
      <td>首单信托型企业ABS获批</td>
      <td>http://www.jjckb.cn/2018-10/23/c_137552198.htm</td>
      <td>经济参考网</td>
      <td>2018年10月23日 12:21</td>
    </tr>
    <tr>
      <th>2</th>
      <td>华能信托</td>
      <td>华能贵诚信托孙磊:金融科技助力打造开放信托生态</td>
      <td>https://baijiahao.baidu.com/s?id=1639276579449...</td>
      <td>同花顺财经</td>
      <td>2019年07月17日 10:49</td>
    </tr>
    <tr>
      <th>3</th>
      <td>华能信托</td>
      <td>华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施</td>
      <td>https://finance.qq.com/a/20190716/007898.htm</td>
      <td>腾讯财经</td>
      <td>2019年07月16日 18:53</td>
    </tr>
    <tr>
      <th>4</th>
      <td>华能信托</td>
      <td>格力电器股权转让意向方闭门开会 华能信托赫然在列</td>
      <td>https://finance.sina.com.cn/trust/roll/2019-05...</td>
      <td>新浪</td>
      <td>2019年05月22日 22:53</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.shape</span><br></pre></td></tr></table></figure>




<pre><code>(962, 5)
</code></pre>
<p><strong>2.中文分词</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中文分词演示</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">word = jieba.cut(<span class="string">&#x27;我爱北京天安门&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> word:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>


<pre><code>我
爱
北京
天安门
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一条新闻标题</span></span><br><span class="line">df.iloc[<span class="number">0</span>][<span class="string">&#x27;标题&#x27;</span>]</span><br></pre></td></tr></table></figure>




<pre><code>&#39;信托公司2019年上半年经营业绩概览&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一条新闻标题中文分词</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">word = jieba.cut(df.iloc[<span class="number">0</span>][<span class="string">&#x27;标题&#x27;</span>])</span><br><span class="line">result = <span class="string">&#x27; &#x27;</span>.join(word) <span class="comment"># jion函数将变量word中的各个分词以空格（‘’）为连接符连接在一起</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<pre><code>信托公司 2019 年 上半年 经营 业绩 概览
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过for循环遍历来进行所有标题的分词</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">words = []</span><br><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    word = jieba.cut(row[<span class="string">&#x27;标题&#x27;</span>])</span><br><span class="line">    result = <span class="string">&#x27; &#x27;</span>.join(word) </span><br><span class="line">    words.append(result)</span><br></pre></td></tr></table></figure>

<p>第三行代码创建一个空列表words来存储每一条新闻标题的分词结果。第四行代码通过for循环遍历整张表格，其中iterrows()是pandas库遍历表格每一行的方法，i对应每一行的行号，row对应每一行的内容。5，6行代码对每一条新闻标题进行分词，并将各个分词用空格连接在一起，roe[‘标题’]表示这一行的“标题”列的内容。第七行代码用append()函数将每一条新闻标题的分词结果添加到works列表中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words[<span class="number">0</span>:<span class="number">3</span>]  <span class="comment"># 展示前三条新闻的分词结果</span></span><br></pre></td></tr></table></figure>




<pre><code>[&#39;信托公司 2019 年 上半年 经营 业绩 概览&#39;,
 &#39;首单 信托 型 企业 ABS 获批&#39;,
 &#39;华能 贵 诚信 托孙磊 : 金融 科技 助力 打造 开放 信托 生态&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 熟悉了上面的过程后，可以把代码合并写成如下形式</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">words = []</span><br><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    words.append(<span class="string">&#x27; &#x27;</span>.join(jieba.cut(row[<span class="string">&#x27;标题&#x27;</span>])))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words[<span class="number">0</span>:<span class="number">3</span>]  <span class="comment"># 同样展示前三条新闻的分词结果</span></span><br></pre></td></tr></table></figure>




<pre><code>[&#39;信托公司 2019 年 上半年 经营 业绩 概览&#39;,
 &#39;首单 信托 型 企业 ABS 获批&#39;,
 &#39;华能 贵 诚信 托孙磊 : 金融 科技 助力 打造 开放 信托 生态&#39;]
</code></pre>
<p><strong>补充知识点：遍历DataFrame表格的函数 - iterrows()函数</strong></p>
<p>pandas库中的iterrows()函数用于遍历DataFrame的每一行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line">    <span class="built_in">print</span>(row)</span><br></pre></td></tr></table></figure>

<pre><code>0
关键词                                                 华能信托
标题                                    信托公司2019年上半年经营业绩概览
网址     http://www.financialnews.com.cn/jrsb_m/xt/zx/2...
来源                                               中国金融新闻网
时间                                     2019年07月23日 00:00
Name: 0, dtype: object
1
关键词                                              华能信托
标题                                       首单信托型企业ABS获批
网址     http://www.jjckb.cn/2018-10/23/c_137552198.htm
来源                                              经济参考网
时间                                  2018年10月23日 12:21
Name: 1, dtype: object
2
关键词                                                 华能信托
标题                               华能贵诚信托孙磊:金融科技助力打造开放信托生态
网址     https://baijiahao.baidu.com/s?id=1639276579449...
来源                                                 同花顺财经
时间                                     2019年07月17日 10:49
Name: 2, dtype: object
3
关键词                                            华能信托
标题                     华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施
网址     https://finance.qq.com/a/20190716/007898.htm
来源                                             腾讯财经
时间                                2019年07月16日 18:53
Name: 3, dtype: object
4
关键词                                                 华能信托
标题                              格力电器股权转让意向方闭门开会 华能信托赫然在列
网址     https://finance.sina.com.cn/trust/roll/2019-05...
来源                                                    新浪
时间                                     2019年05月22日 22:53
Name: 4, dtype: object
5
关键词                                      华能信托
标题         直击格力电器意向投资者见面会:参会者华能信托背后现国务院国资委...
网址     http://finance.ifeng.com/c/7mt651IB1rX
来源                                        凤凰网
时间                          2019年05月22日 18:24
Name: 5, dtype: object
6
关键词                                      华能信托
标题             格力电器股权转让意向投资者见面会召开 自称华能信托的人士到场
网址     http://finance.ifeng.com/c/7msujqm5Mcr
来源                                        凤凰网
时间                          2019年05月22日 15:42
Name: 6, dtype: object
7
关键词                                                 华能信托
标题                      2018年信托业人均创利304万元 华润、华能贵诚跌出万亿俱乐部
网址     http://finance.eastmoney.com/a/201905121120104...
来源                                                 东方财富网
时间                                     2019年05月12日 16:00
Name: 7, dtype: object
8
关键词                                                 华能信托
标题                          去年信托业人均创利304万元,华能贵诚信托跌出万亿俱乐部
网址     https://baijiahao.baidu.com/s?id=1633311466139...
来源                                                 财经新鲜事
时间                                     2019年05月12日 15:47
Name: 8, dtype: object
9
关键词                                                华能信托
标题              ...或200亿收购中江信托 50亿爆雷“烫手山芋”如何处置?;华能信托...
网址     http://www.jnlc.com/article/20190417239422.shtml
来源                                                金牛基金网
时间                                    2019年04月17日 09:41
Name: 9, dtype: object
10
关键词                                                华能信托
标题                                 华能信托是外界传言泰禾引进战投的目标之一
网址     http://www.jnlc.com/article/20190417239409.shtml
来源                                                金牛基金网
时间                                    2019年04月17日 08:35
Name: 10, dtype: object
 …………………………………………
 …………………………………………
Name: 961,dtype: object
</code></pre>
<p>可以看到，这里的i就是每一行的行索引序号，row就是每一行的内容，该内容是一个一维的Series对象，它可以根据索引来提取内容，例如，通过roe[‘标题’]可以提取该条新闻的标题内容，通过row[‘网址’]可以提取该条新闻的网址内容</p>
<p><strong>3.文本向量化基础：建立词频矩阵</strong></p>
<p>此时已经把每一条新闻标题分词完毕并存储到words列表中，下面需要将这些文本类型的数据转换成数值类型的数据，以便构造特征变量及训练模型。文本向量化函数CountVectorizer()，通过它可以很方便地将文本转换成数值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CountVectorizer()函数简单演示</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">test = [<span class="string">&#x27;金融 科技 厉害&#x27;</span>, <span class="string">&#x27;华能 信托 厉害&#x27;</span>]</span><br><span class="line">vect = CountVectorizer()</span><br><span class="line">X = vect.fit_transform(test) <span class="comment"># 用fit_transform（）函数进行文本向量化转换</span></span><br><span class="line">X = X.toarray()</span><br><span class="line"><span class="built_in">print</span>(X)</span><br></pre></td></tr></table></figure>

<pre><code>[[0 0 1 1 1]
 [1 1 1 0 0]]
</code></pre>
<p>可以看到，此时2条新闻标题已经变成了由数字0和1组成的2个一维数组，每个数组中各有5个元素</p>
<p>CountVectorizer()函数会先根据空格来识别每一句话中的词语，“金融”，“科技”，“厉害”，“华能”，“信托”这5个不同的词，这5个词便构成了这2条新闻标题的词袋，该函数会自动对词袋中的词进行编号，通过vocabulary_属性便能获取词袋内容及响应编号</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看词袋和对应的顺序</span></span><br><span class="line">words_bag = vect.vocabulary_</span><br><span class="line"><span class="built_in">print</span>(words_bag)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;金融&#39;: 4, &#39;科技&#39;: 3, &#39;厉害&#39;: 2, &#39;华能&#39;: 1, &#39;信托&#39;: 0&#125;
</code></pre>
<p>可以看到，词袋是一个字典，每个词是字典的键，词对应的编号是字典的值。这些不同的词其实就代表着不同的特征，第几个编号就代表第几个特征</p>
<p>有了上面的词袋，就可以构建如下表所示的词频矩阵，表中的数值即为相关标题中对应特征词的出现频数</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(3).png" alt="下载 (3)"></p>
<p>所以标题1对应的数值数组就是[0 0 1 1 1]，此外，CountVectorizer()函数会自动过滤掉一个字的词，这样会过滤掉“的”“之”等没有重要意义的词，不过同时也会过滤掉“爱”“坑”等可能有重要意义的词，因此，这个特点既是一个优势，也是一个劣势</p>
<p><strong>4.文本向量化实战：构造特征变量</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将之前所有的新闻标题进行文本向量化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">vect = CountVectorizer()</span><br><span class="line">X = vect.fit_transform(words)</span><br><span class="line">X = X.toarray()  <span class="comment"># 用toarray()函数将X转换成为数组形式并重新赋给变量X</span></span><br><span class="line"><span class="built_in">print</span>(X)</span><br></pre></td></tr></table></figure>

<pre><code>[[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 ...
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为新闻标题的数据居多，分词后得到的不同的词语非常多，导致词频矩阵比较稀疏</span></span><br><span class="line"><span class="comment"># 特征向量X中很多地方都是0（即该词在新闻标题中出现的频次为0）</span></span><br><span class="line"><span class="comment"># 查看所有新闻标题的词袋</span></span><br><span class="line">words_bag = vect.vocabulary_</span><br><span class="line"><span class="built_in">print</span>(words_bag)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;信托公司&#39;: 630, &#39;2019&#39;: 21, &#39;上半年&#39;: 296, &#39;经营&#39;: 2659, &#39;业绩&#39;: 345, &#39;概览&#39;: 2130, &#39;首单&#39;: 3337, &#39;信托&#39;: 628, &#39;企业&#39;: 538, &#39;abs&#39;: 103, &#39;获批&#39;: 2827, &#39;华能&#39;: 896, &#39;诚信&#39;: 2947, &#39;托孙磊&#39;: 1721, &#39;金融&#39;: 3199, &#39;科技&#39;: 2541, &#39;助力&#39;: 854, &#39;打造&#39;: 1720, &#39;开放&#39;: 1553, &#39;生态&#39;: 2408, &#39;已经&#39;: 1467, &#39;成为&#39;: 1673, &#39;行业&#39;: 2860, &#39;重要&#39;: 3191, &#39;基础设施&#39;: 1135, &#39;格力电器&#39;: 2116, &#39;股权&#39;: 2754, &#39;转让&#39;: 3063, &#39;意向&#39;: 1664, &#39;闭门&#39;: 3229, &#39;开会&#39;: 1535, &#39;赫然&#39;: 3013, &#39;直击&#39;: 2465, &#39;投资者&#39;: 1744, &#39;见面会&#39;: 2886, &#39;参会者&#39;: 934, &#39;背后&#39;: 2758, &#39;国务院&#39;: 1091, &#39;国资委&#39;: 1098, &#39;召开&#39;: 972, &#39;自称&#39;: 2784, &#39;人士&#39;: 492, &#39;到场&#39;: 818, &#39;2018&#39;: 20, &#39;信托业&#39;: 629, &#39;人均&#39;: 491, &#39;创利&#39;: 798, &#39;304&#39;: 44, &#39;万元&#39;: 273, &#39;华润&#39;: 895, &#39;贵诚&#39;: 2992, &#39;跌出&#39;: 3039, &#39;万亿&#39;: 272, &#39;俱乐部&#39;: 633, &#39;去年&#39;: 932, &#39;托跌出&#39;: 1724, &#39;200&#39;: 17, &#39;收购&#39;: 1854, &#39;50&#39;: 60, &#39;亿爆雷&#39;: 508, &#39;烫手山芋&#39;: 2323, &#39;如何&#39;: 1269, &#39;处置&#39;: 1152, &#39;外界&#39;: 1159, &#39;传言&#39;: 564, &#39;泰禾&#39;: 2221, &#39;引进&#39;: 1566, &#39;战投&#39;: 1695, &#39;目标&#39;: 2464, &#39;之一&#39;: 407, &#39;行业动态&#39;: 2861, &#39;山东&#39;: 1438, &#39;年报&#39;: 1497, &#39;规模&#39;: 2890, &#39;缩水&#39;: 2686, &#39;曲线&#39;: 2021, &#39;上市&#39;: 297, &#39;浪潮&#39;: 2241, &#39;再度&#39;: 739, &#39;托换帅&#39;: 1722, &#39;孙磊&#39;: 1303, &#39;出任&#39;: 764, &#39;总经理&#39;: 1641, &#39;换帅&#39;: 1794, &#39;任职&#39;: 537, &#39;资格&#39;: 3002, &#39;到期&#39;: 821, &#39;债务&#39;: 638, &#39;590&#39;: 70, &#39;集团&#39;: 3263, &#39;救命&#39;: 1875, &#39;国际&#39;: 1101, &#39;资本&#39;: 3000, &#39;有限公司&#39;: 2059, &#39;股东&#39;: 2750, &#39;东莞&#39;: 351, &#39;昨日&#39;: 1996, &#39;双双&#39;: 940, &#39;增资&#39;: 1143, &#39;今年&#39;: 515, &#39;注册资本&#39;: 2216, &#39;增加&#39;: 1140, &#39;总额&#39;: 1643, &#39;注册&#39;: 2215, &#39;资本金&#39;: 3001, &#39;42&#39;: 55, &#39;亿元&#39;: 505, &#39;61&#39;: 75, &#39;94&#39;: 95, &#39;时隔&#39;: 1983, &#39;近两年&#39;: 3089, &#39;再次&#39;: 740, &#39;增至&#39;: 1142, &#39;95&#39;: 96, &#39;肖钢&#39;: 2749, &#39;密集&#39;: 1373, &#39;调研&#39;: 2965, &#39;资产&#39;: 2999, &#39;证券化&#39;: 2931, &#39;业务&#39;: 343, &#39;访华&#39;: 2929, &#39;中信&#39;: 363, &#39;62&#39;: 79, &#39;净利润&#39;: 756, &#39;排名&#39;: 1803, &#39;平安&#39;: 1491, &#39;位列&#39;: 572, &#39;速睹&#39;: 3148, &#39;金志&#39;: 3196, &#39;五大&#39;: 460, &#39;秘诀&#39;: 2551, &#39;塑造&#39;: 1139, &#39;核心&#39;: 2112, &#39;竞争力&#39;: 2574, &#39;单家&#39;: 902, &#39;公司股票&#39;: 701, &#39;产品&#39;: 477, &#39;净值&#39;: 754, &#39;20&#39;: 16, &#39;持有&#39;: 1778, &#39;股票&#39;: 2756, &#39;超过&#39;: 3030, &#39;参与&#39;: 933, &#39;消费&#39;: 2252, &#39;机会&#39;: 2076, &#39;模式分析&#39;: 2138, &#39;新任&#39;: 1921, &#39;到位&#39;: 817, &#39;五矿&#39;: 464, &#39;突围&#39;: 2566, &#39;首任&#39;: 3335, &#39;辞职&#39;: 3070, &#39;接任&#39;: 1812, &#39;王卓&#39;: 2372, &#39;华夏&#39;: 892, &#39;幸福&#39;: 1505, &#39;关于&#39;: 719, &#39;签署&#39;: 2608, &#39;协议&#39;: 900, &#39;公告&#39;: 702, &#39;普邦&#39;: 2006, &#39;股份&#39;: 2752, &#39;集合&#39;: 3262, &#39;资金&#39;: 3005, &#39;计划&#39;: 2910, &#39;合同&#39;: 988, &#39;试水&#39;: 2944, &#39;不良资产&#39;: 327, &#39;收益权&#39;: 1853, &#39;已有&#39;: 1466, &#39;46&#39;: 58, &#39;银登&#39;: 3209, &#39;中心&#39;: 376, &#39;北京&#39;: 862, &#39;银行&#39;: 3210, &#39;携手&#39;: 1838, &#39;中航&#39;: 385, &#39;创新&#39;: 802, &#39;慈善&#39;: 1670, &#39;模式&#39;: 2137, &#39;acca&#39;: 104, &#39;财经&#39;: 2977, &#39;领袖&#39;: 3312, &#39;培养&#39;: 1129, &#39;第一期&#39;: 2585, &#39;学员&#39;: 1311, &#39;选拔&#39;: 3135, &#39;结果&#39;: 2666, &#39;公布&#39;: 704, &#39;国金&#39;: 1100, &#39;早报&#39;: 1977, &#39;招行&#39;: 1771, &#39;合作&#39;: 986, &#39;发行&#39;: 957, &#39;99&#39;: 99, &#39;用益&#39;: 2419, &#39;日报&#39;: 1971, &#39;江苏&#39;: 2194, &#39;前四&#39;: 828, &#39;58&#39;: 68, &#39;净利&#39;: 755, &#39;排位&#39;: 1802, &#39;杨广伟&#39;: 2093, &#39;未来&#39;: 2071, &#39;10&#39;: 5, &#39;人工智能&#39;: 495, &#39;一定&#39;: 232, &#39;改变&#39;: 1858, &#39;房地产&#39;: 1702, &#39;文献&#39;: 1912, &#39;述评&#39;: 3120, &#39;精神科&#39;: 2623, &#39;应用&#39;: 1517, &#39;严重&#39;: 359, &#39;提醒&#39;: 1830, &#39;骗子&#39;: 3365, &#39;ai&#39;: 105, &#39;技术&#39;: 1737, &#39;知道&#39;: 2490, &#39;时代&#39;: 1979, &#39;征程&#39;: 1595, &#39;机遇&#39;: 2080, &#39;机器&#39;: 2077, &#39;视觉&#39;: 2893, &#39;高峰论坛&#39;: 3367, &#39;如期而至&#39;: 1271, &#39;华为&#39;: 889, &#39;atlas&#39;: 108, &#39;遥感&#39;: 3160, &#39;碧空&#39;: 2511, &#39;慧眼&#39;: 1671, &#39;读心术&#39;: 2958, &#39;新高&#39;: 1946, &#39;基于&#39;: 1131, &#39;血谱&#39;: 2859, &#39;光学&#39;: 658, &#39;成像&#39;: 1674, &#39;情感&#39;: 1653, &#39;伙伴&#39;: 552, &#39;招募&#39;: 1768, &#39;京东&#39;: 479, &#39;炼金&#39;: 2322, &#39;开启&#39;: 1538, &#39;共生&#39;: 715, &#39;融合&#39;: 2857, &#39;商业化&#39;: 1058, &#39;场景&#39;: 1117, &#39;发展&#39;: 951, &#39;实践&#39;: 1357, &#39;落地&#39;: 2834, &#39;注重&#39;: 2218, &#39;三大&#39;: 285, &#39;渗透&#39;: 2283, &#39;年内&#39;: 1494, &#39;占领&#39;: 917, &#39;市场&#39;: 1470, &#39;言通&#39;: 2904, &#39;专注&#39;: 339, &#39;领域&#39;: 3309, &#39;语音&#39;: 2953, &#39;识别&#39;: 2941, &#39;服务&#39;: 2061, &#39;多维度&#39;: 1174, &#39;赋能&#39;: 3007, &#39;智能&#39;: 2012, &#39;营销&#39;: 2833, &#39;阿尔法&#39;: 3238, &#39;现身&#39;: 2392, &#39;教育&#39;: 1879, &#39;数据&#39;: 1885, &#39;峰会&#39;: 1443, &#39;获点&#39;: 2828, &#39;世界&#39;: 341, &#39;大会&#39;: 1181, &#39;看点&#39;: 2474, &#39;聚焦&#39;: 2746, &#39;全球&#39;: 684, &#39;健康&#39;: 646, &#39;智汇&#39;: 2010, &#39;预见&#39;: 3306, &#39;亚马逊&#39;: 469, &#39;stylesnap&#39;: 194, &#39;一款&#39;: 244, &#39;工具&#39;: 1452, &#39;倒计时&#39;: 635, &#39;22&#39;: 29, &#39;众多&#39;: 543, &#39;民生&#39;: 2175, &#39;展商&#39;: 1427, &#39;亮相&#39;: 485, &#39;联想&#39;: 2740, &#39;宣布&#39;: 1363, &#39;开展&#39;: 1544, &#39;为期&#39;: 393, &#39;多年&#39;: 1168, &#39;提升&#39;: 1827, &#39;高性能&#39;: 3370, &#39;计算&#39;: 2911, &#39;百度&#39;: 2449, &#39;副总裁&#39;: 835, &#39;张旭&#39;: 1573, &#39;学好&#39;: 1312, &#39;少儿&#39;: 1413, &#39;编程&#39;: 2683, &#39;轻松&#39;: 3065, &#39;掌控&#39;: 1799, &#39;跨境&#39;: 3041, &#39;电商&#39;: 2423, &#39;交通运输&#39;: 473, &#39;西媒&#39;: 2878, &#39;盘点&#39;: 2456, &#39;2016&#39;: 19, &#39;中国&#39;: 368, &#39;打响&#39;: 1715, &#39;发令枪&#39;: 948, &#39;足迹&#39;: 3037, &#39;惊人&#39;: 1655, &#39;研究&#39;: 2498, &#39;人员&#39;: 490, &#39;呼吁&#39;: 1037, &#39;提高&#39;: 1832, &#39;效率&#39;: 1874, &#39;乐队&#39;: 427, &#39;鼓手&#39;: 3398, &#39;失业&#39;: 1231, &#39;索尼&#39;: 2628, &#39;自动&#39;: 2775, &#39;音乐&#39;: 3294, &#39;节拍&#39;: 2798, &#39;各国&#39;: 983, &#39;战略&#39;: 1697, &#39;构筑&#39;: 2100, &#39;我国&#39;: 1686, &#39;优势&#39;: 546, &#39;赛事&#39;: 3010, &#39;对标&#39;: 1383, &#39;高手&#39;: 3371, &#39;齐聚&#39;: 3400, &#39;鹭岛&#39;: 3386, &#39;竞技&#39;: 2576, &#39;国家&#39;: 1093, &#39;新一代&#39;: 1920, &#39;平台&#39;: 1489, &#39;将近&#39;: 1397, &#39;280&#39;: 36, &#39;高效&#39;: 3373, &#39;还要&#39;: 3094, &#39;符合&#39;: 2581, &#39;伦理&#39;: 567, &#39;怎么&#39;: 1621, &#39;ibm&#39;: 145, &#39;即将&#39;: 921, &#39;站上&#39;: 2571, &#39;长春&#39;: 3223, &#39;旗山&#39;: 1959, &#39;论谈&#39;: 2923, &#39;专场&#39;: 337, &#39;论坛&#39;: 2922, &#39;举办&#39;: 405, &#39;一项&#39;: 263, &#39;确认&#39;: 2510, &#39;避开&#39;: 3163, &#39;行人&#39;: 2862, &#39;开车&#39;: 1557, &#39;睡觉&#39;: 2483, &#39;现实&#39;: 2390, &#39;性感&#39;: 1633, &#39;在线&#39;: 1111, &#39;程序&#39;: 2558, &#39;猴子&#39;: 2365, &#39;网友&#39;: 2688, &#39;小米&#39;: 1408, &#39;关系&#39;: 723, &#39;arm&#39;: 107, &#39;布局&#39;: 1473, &#39;生态圈&#39;: 2409, &#39;瞄准&#39;: 2484, &#39;联网&#39;: 2744, &#39;设备&#39;: 2925, &#39;来看&#39;: 2091, &#39;是否&#39;: 1999, &#39;需要&#39;: 3273, &#39;拥有&#39;: 1774, &#39;智慧&#39;: 2008, &#39;明白&#39;: 1990, &#39;2019china&#39;: 23, &#39;控制&#39;: 1815, &#39;展示会&#39;: 1432, &#39;官网&#39;: 1335, &#39;上海&#39;: 299, &#39;成立&#39;: 1680, &#39;联盟&#39;: 2742, &#39;集成电路&#39;: 3265, &#39;涂国身&#39;: 2251, &#39;关键&#39;: 724, &#39;用例&#39;: 2417, &#39;一天&#39;: 231, &#39;可能&#39;: 978, &#39;使用&#39;: 610, &#39;创造&#39;: 805, &#39;就业机会&#39;: 1419, &#39;破坏&#39;: 2502, &#39;希鸥&#39;: 1475, &#39;专访&#39;: 340, &#39;拓世&#39;: 1766, &#39;创始人&#39;: 800, &#39;火亮&#39;: 2309, &#39;通用&#39;: 3145, &#39;对战&#39;: 1380, &#39;王者&#39;: 2381, &#39;荣耀&#39;: 2820, &#39;职业&#39;: 2733, &#39;战队&#39;: 1698, &#39;表现&#39;: 2868, &#39;出色&#39;: 773, &#39;落实&#39;: 2835, &#39;风潮&#39;: 3326, &#39;科技领域&#39;: 2546, &#39;带来&#39;: 1477, &#39;变革&#39;: 966, &#39;更为&#39;: 2022, &#39;用户&#39;: 2418, &#39;生活&#39;: 2413, &#39;惊喜&#39;: 1656, &#39;所说&#39;: 1705, &#39;不是&#39;: 322, &#39;口中&#39;: 967, &#39;科学&#39;: 2539, &#39;一起&#39;: 259, &#39;看看&#39;: 2475, &#39;艺术&#39;: 2794, &#39;奇特&#39;: 1241, &#39;美妙&#39;: 2706, &#39;媒介&#39;: 1293, &#39;超越&#39;: 3029, &#39;美国&#39;: 2703, &#39;欧洲联盟&#39;: 2142, &#39;生态系统&#39;: 2410, &#39;调查&#39;: 2963, &#39;寻求&#39;: 1388, &#39;硅谷&#39;: 2504, &#39;夺取&#39;: 1238, &#39;宝座&#39;: 1345, &#39;23&#39;: 30, &#39;概念股&#39;: 2129, &#39;湖南卫视&#39;: 2292, &#39;十年&#39;: 873, &#39;匠心&#39;: 865, &#39;几年&#39;: 763, &#39;专业&#39;: 334, &#39;大获全胜&#39;: 1208, &#39;这个&#39;: 3095, &#39;新起&#39;: 1943, &#39;之秀&#39;: 415, &#39;抗衡&#39;: 1746, &#39;究竟&#39;: 2563, &#39;地方&#39;: 1113, &#39;政府&#39;: 1866, &#39;新宠&#39;: 1930, &#39;先进&#39;: 657, &#39;汽车&#39;: 2199, &#39;目前&#39;: 2463, &#39;谷歌&#39;: 2970, &#39;正在&#39;: 2146, &#39;预测&#39;: 3304, &#39;风电场&#39;: 3327, &#39;输出功率&#39;: 3068, &#39;it&#39;: 150, &#39;领导者&#39;: 3310, &#39;希望&#39;: 1474, &#39;更加&#39;: 2023, &#39;关注&#39;: 721, &#39;道德&#39;: 3157, &#39;一直&#39;: 248, &#39;年前&#39;: 1495, &#39;老本&#39;: 2724, &#39;少年&#39;: 1415, &#39;有个&#39;: 2051, &#39;梦想&#39;: 2124, &#39;一种&#39;: 249, &#39;受欢迎&#39;: 960, &#39;推动力&#39;: 1821, &#39;可以&#39;: 975, &#39;gdp&#39;: 135, &#39;数百万美元&#39;: 1888, &#39;法律&#39;: 2213, &#39;十大&#39;: 872, &#39;前沿&#39;: 831, &#39;问题&#39;: 3231, &#39;威盛&#39;: 1281, &#39;展览会&#39;: 1434, &#39;文艺创作&#39;: 1916, &#39;适恰性&#39;: 3133, &#39;之识&#39;: 418, &#39;无界&#39;: 1967, &#39;探索&#39;: 1810, &#39;边界&#39;: 3071, &#39;当大&#39;: 1583, &#39;结合&#39;: 2662, &#39;哪些&#39;: 1048, &#39;gartner&#39;: 133, &#39;增强&#39;: 1141, &#39;最有&#39;: 2041, &#39;价值&#39;: 532, &#39;应用程序&#39;: 1518, &#39;广元&#39;: 1507, &#39;示范&#39;: 2512, &#39;全国&#39;: 676, &#39;首个&#39;: 3334, &#39;职称&#39;: 2734, &#39;评审会&#39;: 2937, &#39;掀起&#39;: 1797, &#39;革命&#39;: 3291, &#39;医学影像&#39;: 868, &#39;交大&#39;: 470, &#39;同济&#39;: 1001, &#39;复旦&#39;: 1155, &#39;大将&#39;: 1195, &#39;加入&#39;: 841, &#39;遍地开花&#39;: 3156, &#39;霍金&#39;: 3275, &#39;生前&#39;: 2406, &#39;告诫&#39;: 1029, &#39;人类&#39;: 502, &#39;小心&#39;: 1406, &#39;他们&#39;: 522, &#39;真的&#39;: 2482, &#39;能够&#39;: 2765, &#39;威胁&#39;: 1282, &#39;引育&#39;: 1564, &#39;人才&#39;: 497, &#39;天津&#39;: 1220, &#39;持续&#39;: 1779, &#39;引领&#39;: 1567, &#39;牢记&#39;: 2346, &#39;嘱托&#39;: 1069, &#39;天津市&#39;: 1222, &#39;能否&#39;: 2764, &#39;获得&#39;: 2826, &#39;永生&#39;: 2184, &#39;或许&#39;: 1693, &#39;告诉&#39;: 1028, &#39;我们&#39;: 1685, &#39;答案&#39;: 2604, &#39;刘庆峰&#39;: 792, &#39;每个&#39;: 2160, &#39;孩子&#39;: 1317, &#39;肩膀&#39;: 2757, &#39;适应&#39;: 3132, &#39;解读&#39;: 2901, &#39;医疗&#39;: 869, &#39;无限&#39;: 1970, &#39;读研&#39;: 2959, &#39;选择&#39;: 3136, &#39;方向&#39;: 1947, &#39;沐盟&#39;: 2202, ………………………………&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看词袋中词的数目</span></span><br><span class="line"><span class="built_in">len</span>(words_bag)</span><br></pre></td></tr></table></figure>




<pre><code>3402
</code></pre>
<p>从上面的输出结果可以看出，词袋的词汇量很大，然而具体到某一条新闻标题，其中只会出现词袋中的少数几个词，其他大部分的词都不会出现，这就是词频矩阵中有很多0的原因</p>
<p><strong>选取前2条新闻标题做一个简单的演示</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看前两条分词完的新闻</span></span><br><span class="line"><span class="built_in">print</span>(words[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(words[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<pre><code>信托公司 2019 年 上半年 经营 业绩 概览
首单 信托 型 企业 ABS 获批
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 文本向量化</span></span><br><span class="line">vect = CountVectorizer()  <span class="comment"># 引入CountVectorizer()函数</span></span><br><span class="line">X_test = vect.fit_transform(words[<span class="number">0</span>:<span class="number">2</span>])  <span class="comment"># 将前两条新闻文本向量化</span></span><br><span class="line">X_test = X_test.toarray()  <span class="comment"># 将X_test转为数组</span></span><br><span class="line"><span class="built_in">print</span>(X_test)  <span class="comment"># 查看生成的二维数组</span></span><br></pre></td></tr></table></figure>

<pre><code>[[1 0 1 1 0 0 1 1 1 0 0]
 [0 1 0 0 1 1 0 0 0 1 1]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看词袋的第一种方式</span></span><br><span class="line">words_bag = vect.vocabulary_  <span class="comment"># 第一种查看词袋的方式</span></span><br><span class="line"><span class="built_in">print</span>(words_bag)  <span class="comment"># 查看词袋</span></span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;信托公司&#39;: 6, &#39;2019&#39;: 0, &#39;上半年&#39;: 2, &#39;经营&#39;: 8, &#39;业绩&#39;: 3, &#39;概览&#39;: 7, &#39;首单&#39;: 10, &#39;信托&#39;: 5, &#39;企业&#39;: 4, &#39;abs&#39;: 1, &#39;获批&#39;: 9&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看词袋的第二种方式</span></span><br><span class="line">words_bag2 = vect.get_feature_names_out()  <span class="comment"># 第二种查看词袋的方法</span></span><br><span class="line"><span class="built_in">print</span>(words_bag2)  <span class="comment"># 第二种查看词袋的方式</span></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;2019&#39; &#39;abs&#39; &#39;上半年&#39; &#39;业绩&#39; &#39;企业&#39; &#39;信托&#39; &#39;信托公司&#39; &#39;概览&#39; &#39;经营&#39; &#39;获批&#39; &#39;首单&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame(X_test, columns=words_bag2)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2019</th>
      <th>abs</th>
      <th>上半年</th>
      <th>业绩</th>
      <th>企业</th>
      <th>信托</th>
      <th>信托公司</th>
      <th>概览</th>
      <th>经营</th>
      <th>获批</th>
      <th>首单</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将之前所有的新闻标题进行文本向量化并通过pandas展示</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本向量化</span></span><br><span class="line">vect = CountVectorizer()</span><br><span class="line">X = vect.fit_transform(words)  <span class="comment"># 将分词后的内容文本向量化</span></span><br><span class="line">X = X.toarray()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看文本向量化的结果</span></span><br><span class="line">words_bag2 = vect.get_feature_names_out()  <span class="comment"># 第二种查看词袋的方法</span></span><br><span class="line">df = pd.DataFrame(X, columns=words_bag2)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>00700</th>
      <th>03</th>
      <th>04</th>
      <th>08s</th>
      <th>09</th>
      <th>10</th>
      <th>100</th>
      <th>11</th>
      <th>12</th>
      <th>150</th>
      <th>...</th>
      <th>黄萍</th>
      <th>黄金</th>
      <th>黑客</th>
      <th>黑灰产</th>
      <th>黑金</th>
      <th>黑马</th>
      <th>鼓手</th>
      <th>鼻祖</th>
      <th>齐聚</th>
      <th>龙风</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 3402 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # 如果想显示pandas中DataFrmae所有行，或者所有列，可以采用下面的代码</span></span><br><span class="line"><span class="comment"># import pandas as pd</span></span><br><span class="line"><span class="comment"># pd.set_option(&#x27;display.max_columns&#x27;, None)  # 显示所有列，如果把None改成100则显示100列</span></span><br><span class="line"><span class="comment"># pd.set_option(&#x27;display.max_rows&#x27;, None)  # 显示所有行，如果把None改成100则显示100行</span></span><br><span class="line"><span class="comment"># df = pd.DataFrame(X, columns=words_bag2)</span></span><br><span class="line"><span class="comment"># df.head()</span></span><br></pre></td></tr></table></figure>

<p><strong>总结</strong>：当有n条新闻标题时，先用jieba库对它们进行分词，然后用CountVectorizer()函数提取所有分词中k个不同的词，用这些词构成一个词袋，每个词对应一个编号，即相应的特征，根据原标题中相关词出现的次数来赋值相关特征为i（即相关词出现的次数），这样就完成了文本数值化的工作，接下来进行模型的搭建与使用</p>
<h3 id="13-3-3-模型的搭建与使用"><a href="#13-3-3-模型的搭建与使用" class="headerlink" title="13.3.3 模型的搭建与使用"></a>13.3.3 模型的搭建与使用</h3><p><strong>1.通过KMeans算法进行聚类分群</strong></p>
<p>本案例的原始数据是根据10个关键词爬取的新闻，下面利用KMeans算法搭建模型进行聚类分群，看看它能否将来自10个不同题材的新闻准确地分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">kms = KMeans(n_clusters=<span class="number">10</span>, random_state=<span class="number">123</span>) <span class="comment"># 将样本聚成10类</span></span><br><span class="line">k_data = kms.fit_predict(df) <span class="comment"># 用fit_predict()函数将模型拟合训练和聚类结果传递合二为一</span></span><br><span class="line"><span class="built_in">print</span>(k_data)</span><br></pre></td></tr></table></figure>


<pre><code>[0 0 3 3 0 0 0 0 0 8 0 8 8 0 0 0 0 8 0 0 8 0 7 0 0 0 0 0 0 0 8 0 8 0 8 0 0
 0 7 8 0 8 0 8 0 0 0 7 8 0 8 0 8 0 0 0 7 8 0 8 0 8 0 0 0 7 8 0 8 0 8 0 0 0
 7 8 0 8 0 8 0 0 0 7 8 0 8 0 8 0 0 0 7 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 9
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 3 3 3 0 3 3 3 0 3 3 9 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 2 0 0
 2 2 0 2 2 2 0 0 0 2 0 2 2 2 0 2 5 5 2 0 2 2 2 5 5 0 2 0 2 0 0 2 0 0 2 5 2
 2 5 5 2 0 0 0 0 2 2 2 2 0 5 2 2 0 2 2 2 2 5 2 5 2 2 2 5 2 2 0 2 2 2 2 0 0
 5 2 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0
 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 5 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1
 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1
 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 6 1 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 3 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 4
 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 0 0 0 0 0 4 0 0 0 0 0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">words_ary = np.array(words)</span><br><span class="line"><span class="built_in">print</span>(words_ary[k_data == <span class="number">2</span>])  <span class="comment"># 可以把数字1改成其他数字看看效果</span></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;数字 媒体 的 体育 版权 经营 逻辑&#39; &#39;关心 下一代 华夏 国际 体育 训练营 丨 美国 体育 训练营&#39;
 &#39;左手 优酷 体育 右手 苏宁 体育   阿里 体育 组队 围攻 腾讯 体育&#39;
 &#39;新 赛季 “ 抢人 ” 大战 正酣   优酷 体育 会员 悄然 下架&#39; &#39;学校 体育 资源 开放 , 步子 再 快 一点&#39;
 &#39;PP 体育 独家 呈现 英超 精彩   会员 专享 50 帧 直播 技术&#39; &#39;广州 : 中考 体育 跳绳 满分 标准 逐步提高&#39;
 &#39;2019 重庆 青少年 体育 夏令营 关心 关爱 留守 儿童&#39; &#39;第三届 “ 全国 小学 体育 活力 校园 创新奖 ” 揭晓&#39;
 &#39;二青会 湖北 体育 代表团 誓师大会 胜利 召开&#39; &#39;官宣 了 ! 洲明 体育 正式 成为 国际 篮联 全球 供应商&#39;
 &#39;体育彩票 公益金 支持 湖南 体育 舞蹈 锦标赛&#39; &#39;中国 传媒大学 推出 体育 传播 MBA , 培养 全球 体育产业 人才&#39;
 &#39;记得 《 大 李小李 和 老李 》 吗   演绎 体育 经典电影 底色&#39; &#39;体育 与 健康 _ 20190807&#39;
 &#39;惠州 将 举行 系列 体育 活动 迎接 全民 健身 日 的 到来&#39; &#39;惠州 将 举行 系列 体育 活动 迎接 全民 健身 日 的 到来&#39;
 &#39;新政 | 让 学生 学会 两项 体育 技能 一项 艺术 爱好 , 上海 “ 一条龙 ” 布局 ...&#39;
 &#39;响应 国家 全民 健身 , 超级 猩猩 为 互联网 + 体育 助力 发展&#39; &#39;体育 惠民 , 让 全城 “ 动 起来 ”&#39;
 &#39;新 中国 成立 70 周年 中国 体育 巨变 纵览 之三 : 专业 体育 和 全民 健身&#39; &#39;太原 : 一个 城市 的 体育 成长&#39;
 &#39;婺源 百姓 吃 上 “ 体育 饭 ”&#39; &#39;重庆 两个 社区 体育 文化公园 建成 迎客&#39; &#39;社区 体育 文化公园   漂亮 实用 更 人性化&#39;
 &#39;海看 体育 新 服务 发布&#39; &#39;女排 首夺 大满贯 , 国足 04 亚洲杯 折戟 工体 , 中国 体育 历史 上 的 8 月 7 日&#39;
 &#39;体育 + 旅游 的 有效 尝试   阿坝 分赛区 完美 呈现 !&#39;
 &#39;上海 建工 建设者 连续 奋战   市民 体育 公园 ( 一期 ) 下 月 基本 建成&#39;
 &#39;英超 开赛 在 即   苏宁 体育 王冬 : 苏宁 布局 体育 的 逻辑&#39;
 &#39;跳绳 、 中长跑 更难 拿 满分 ! 广州 中考 体育 改革 2021 年 起 实施&#39;
 &#39;跳绳 、 中长跑 更难 拿 满分 ! 广州 中考 体育 改革 2021 年 起 实施&#39;
 &#39;体育 大 V 和 MCN 如何 在 微博玩 出新 套路 ? 邓亚萍 及 皇马 、 拜仁 如是说&#39;
 &#39;2000 多名 体育 爱好者 共享 “ 全民 健身 日 ”&#39;
 &#39;看见 | 第二批 社区 体育 文化公园 今日 开园   这次 有 很多 便民 的 人性化 设计&#39;
 &#39;重磅 ! PP 体育 全场 次 独家 视频 直播 英超 + 超级 福利&#39;
 &#39;重庆 今年 将 建成 20 个 社区 体育 文化公园   本月 起 陆续 开放&#39;
 &#39;苏州 体育 惠民 消费 行动 火热 进行 中   办卡 可享 诸多 优惠 补贴&#39; &#39;我省 制定 计划 促进 体育 消费&#39;
 &#39;启蒙 《 体育 三字经 》 亚博 体育 俱乐部 公益 开放日&#39; &#39;平湖 老人 诠释 体育 人生 之美 】&#39;
 &#39;王国生 : 守初 心担 使命 强 责任 抓 落实   高质量 办好 民族 体育 盛会&#39;
 &#39;“ 智慧 + 体育 ” 全国 首批 智慧 社区 健身 中心 在 雨花台区 启用&#39;
 &#39;莱昂纳多 转型 记 : 从 球员 到 体育 总监 , 广泛 的 足球圈 人脉助 一臂之力&#39;
 &#39;“ 足球 + 时尚 ” 跨界 升级 球迷 体验   天猫 引领 体育 消费 蓝海&#39;
 &#39;首座 体育场馆 落成 , 阿里 体育 继续 拼 体育 服务&#39; &#39;海看 体育 新 服务 发布会 举行   为 体育产业 发展 提供 新 动能&#39;
 &#39;动因 体育 篮球 技术 总监 麦迪要 来 了 !&#39; &#39;新利 18app 体育&#39; &#39;婺源 : “ 体育 风 ” 吹热 乡村 振兴&#39;
 &#39;中考 体育 培训 大热 , 学业 压力 为何 难成 行业 动力 ?&#39; &#39;山西 代县 的 体育 脉动&#39; &#39;体育 六艺   孔子 故里 发 新芽&#39;
 &#39;体育 还 得 从 娃娃 抓起&#39; &#39;梅列 阳光 体育   让 生命 更 阳光&#39;
 &#39;《 体育 鹅 》 —   体育 鹅 - 体育迷 及 体育 游戏 爱好者 的 娱乐 营地&#39;
 &#39;职业 体育 有 多 残酷 ? 足球 先生 、 NBA 得分王 亦 难 体面 告别&#39;
 &#39;江苏 : 2022 年 体育 消费 总 规模 达 2800 亿元&#39; &#39;以 体育 人   为 爱而赛&#39;
 &#39;姚明 多次 谈 体育 教育 到底 谈 了 什么 ?&#39;
 &#39;体育 、 艺术 科考 将 影响 高考 ! 广东 2018 或 2019 年 入学 新生 开始 试点 !&#39;]
</code></pre>
<p>可以看到，分类为2的新闻标题大多是和体育相关的</p>
<p><strong>2.通过DBSCAN算法进行聚类分群</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line">dbs = DBSCAN(eps=<span class="number">1</span>, min_samples=<span class="number">3</span>)</span><br><span class="line">d_data = dbs.fit_predict(df)</span><br><span class="line"><span class="built_in">print</span>(d_data)</span><br></pre></td></tr></table></figure>

<pre><code>[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1  0  1  2  3  4  5  6  7  8  0  1  2  3  4  5  6  7  8
  0  1  2  3  4  5  6  7  8  0  1  2  3  4  5  6  7  8  0  1  2  3  4  5
  6  7  8  0  1  2  3  4  5  6  7  8  0  1  2  3  4  5  6  7  8 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1  9 10 11  9 10 11  9 10 11  9 10 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 12 13 14 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 12 13 14 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 12 13 14 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1]
</code></pre>
<p>可以看到DBSCAN算法对新闻标题的聚类效果较差，其中有大量的离群点（-1），即不知道这些新闻标题属于什么分类，因为进行文本向量化后，每个新闻标题都有3402个特征，过多的特征容易导致样本点间距离较远，从而产生离群点，因此对于新闻文本而言，KMeans算法的聚类效果很好，DBSCAN算法的聚类效果则不尽如人意，这也说明了对于特征变量较多的数据，KMeans算法的聚类效果要优于DBSCAN算法的聚类效果</p>
<h3 id="13-3-4-模型优化（利用余弦相似度进行优化）"><a href="#13-3-4-模型优化（利用余弦相似度进行优化）" class="headerlink" title="13.3.4 模型优化（利用余弦相似度进行优化）"></a>13.3.4 模型优化（利用余弦相似度进行优化）</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(4).png" alt="下载 (4)"></p>
<p><strong>1.模型误差产生的原因</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(5).png" alt="下载 (5)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(6).png" alt="下载 (6)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">words_test = [<span class="string">&#x27;想去 华能 信托&#x27;</span>, <span class="string">&#x27;华能 信托 很好 想去&#x27;</span>, <span class="string">&#x27;华能 信托 很好 想去 华能 信托 很好 想去&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本向量化</span></span><br><span class="line">vect = CountVectorizer()</span><br><span class="line">X_test = vect.fit_transform(words_test)  <span class="comment"># 将分词后的内容文本向量化</span></span><br><span class="line">X_test = X_test.toarray()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看文本向量化的结果</span></span><br><span class="line">words_bag2 = vect.get_feature_names_out()  <span class="comment"># 第二种查看词袋的方法</span></span><br><span class="line">df_test = pd.DataFrame(X_test, columns=words_bag2)</span><br><span class="line">df_test.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>信托</th>
      <th>华能</th>
      <th>很好</th>
      <th>想去</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



<p><img src="%E4%B8%8B%E8%BD%BD%20(7).png" alt="下载 (7)"></p>
<p>这种因为文本长短造成的预测不准确可以通过余弦相似度来解决。余弦相似度是根据向量的夹角而非距离来判断相似度的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 补充知识点：通过numpy库计算欧式距离</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">dist = np.linalg.norm(df_test.iloc[<span class="number">0</span>] - df_test.iloc[<span class="number">1</span>])</span><br><span class="line">dist</span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<p><strong>2.余弦相似度的数学原理</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(8).png" alt="下载 (8)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(9).png" alt="下载 (9)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(10).png" alt="下载 (10)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(11).png" alt="下载 (11)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(12).png" alt="下载 (12)"></p>
<p><strong>3.余弦相似度的python代码实现</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(13).png" alt="下载 (13)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算余弦相似度</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line">cosine_similarities  = cosine_similarity(df_test)</span><br><span class="line">cosine_similarities</span><br></pre></td></tr></table></figure>




<pre><code>array([[1.       , 0.8660254, 0.8660254],
       [0.8660254, 1.       , 1.       ],
       [0.8660254, 1.       , 1.       ]])
</code></pre>
<p>上述结果为3行3列的二维数组，第i行第j列的数字表示第i个数据和第j个数据的余弦相似度，如第二行第三列的数字1是第二条新闻标题和第三条新闻标题的余弦相似度</p>
<p><strong>4.余弦相似度实战 - 模型优化</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line">cosine_similarities  = cosine_similarity(df)</span><br><span class="line"><span class="built_in">print</span>(cosine_similarities)</span><br></pre></td></tr></table></figure>

<pre><code>[[1.         0.         0.         ... 0.         0.         0.        ]
 [0.         1.         0.14142136 ... 0.         0.         0.        ]
 [0.         0.14142136 1.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 1.         0.18490007 0.10050378]
 [0.         0.         0.         ... 0.18490007 1.         0.0836242 ]
 [0.         0.         0.         ... 0.10050378 0.0836242  1.        ]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">kms = KMeans(n_clusters=<span class="number">10</span>, random_state=<span class="number">123</span>)</span><br><span class="line">k_data = kms.fit_predict(cosine_similarities)</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(k_data)</span><br></pre></td></tr></table></figure>

<pre><code>[1 3 3 3 3 3 3 1 1 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 1 1 3 1 3 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 1 1 8 8 8 8 1 8 8 8 8 8 8 8 8 8 8 8 8 8 1 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 1 8 8 1 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 1 8 8 8 1 8 8 8 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 8 8 8 1 8 8 8 8 7 1 1
 7 7 1 7 7 7 1 1 1 7 1 7 7 7 1 7 7 7 7 1 7 7 7 7 7 1 7 1 7 1 1 7 1 1 7 7 7
 7 7 1 7 1 1 1 1 7 7 7 7 1 7 7 7 1 7 7 7 7 7 7 7 7 7 7 7 7 7 1 7 7 7 7 1 1
 7 7 1 7 7 7 7 7 7 7 7 7 1 7 7 7 7 7 7 7 7 1 7 4 4 4 4 4 4 4 1 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 8 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 1 2 2
 2 2 2 1 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 1 1 2 1 1 2 8 2 2 2 1 2 2 2 2 2
 5 2 2 1 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2 6 2 6
 6 6 6 6 6 6 0 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 5 8 6 6 6 5 6 6 6 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 0 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 5 5 5 5 5 5 5 2 5 5 5 5 2 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
 5 5 5 5 5 5 5 0 5 5 5 9 9 9 9 9 9 9 9 9 9 1 9 9 9 0 9 1 9 9 9 9 9 9 9 9 9
 9 9 9 9 9 9 9 9 9 9 9 1 9 9 9 9 9 9 9 1 9 9 9 9 1 9 9 9 9 9 9 9 9 9 9 9 9
 9 9 1 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 1 9 9 9 9 9 9]
</code></pre>
<p>可以看到，利用余弦相似度优化后的KMeans模型能够较好地将新闻分成10类，并且每类新闻的数量都比较接近，与原始数据的实际情况比较一致</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看分类结果</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">words_ary = np.array(words)</span><br><span class="line"><span class="built_in">print</span>(words_ary[k_data == <span class="number">3</span>])  <span class="comment"># 可以把数字3改成其他数字看看效果</span></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;首单 信托 型 企业 ABS 获批&#39; &#39;华能 贵 诚信 托孙磊 : 金融 科技 助力 打造 开放 信托 生态&#39;
 &#39;华能 贵 诚信 托孙磊 : 金融 科技 已经 成为 信托 行业 重要 的 基础设施&#39;
 &#39;格力电器 股权 转让 意向 方 闭门 开会   华能 信托 赫然 在 列&#39;
 &#39;直击 格力电器 意向 投资者 见面会 : 参会者 华能 信托 背后 现 国务院 国资委 ...&#39;
 &#39;格力电器 股权 转让 意向 投资者 见面会 召开   自称 华能 信托 的 人士 到场&#39;
 &#39;... 或 200 亿 收购 中 江 信托   50 亿爆雷 “ 烫手山芋 ” 如何 处置 ? ; 华能 信托 ...&#39;
 &#39;华能 信托 是 外界 传言 泰禾 引进 战投 的 目标 之一&#39;
 &#39;... 或 200 亿 收购 中 江 信托   50 亿爆雷 “ 烫手山芋 ” 如何 处置 ? ; 华能 信托 ...&#39;
 &#39;【 行业动态 】 山东 信托 2018 年报   规模 缩水 ; 信托 曲线 上市 浪潮 再度 涌 ...&#39;
 &#39;华能 贵 诚信 托换帅 , 孙磊 出任 总经理&#39; &#39;华能 信托 换帅 总经理 孙磊 任职 资格 获批&#39;
 &#39;2019 年 到期 债务 达 590 亿 ! 泰禾 集团 找 华能 信托 来 救命&#39;
 &#39;华能 国际 : 华能 资本 是 华能 贵 诚信 托 有限公司 大 股东&#39;
 &#39;华能 信托 、 东莞 信托 昨日 双双 增资   今年 信托公司 注册资本 增加 总额 逾 ...&#39;
 &#39;华能 信托 注册 资本金 由 42 亿元 增资 至 61.94 亿&#39;
 &#39;时隔 近两年 再次 增资   华能 信托 注册资本 增至 61.95 亿元&#39;
 &#39;肖钢 密集 调研 资产 证券化 业务   走 访华 能 信托 和 中信 信托&#39;
 &#39;速睹 62 家 信托 上半年 业绩 ! 平安 中信 华能 位列 前 三&#39; &#39;华能 信托 总经理 金志 培 : 五大 秘诀 塑造 核心 竞争力&#39;
 &#39;华能 信托 : 信托公司 参与 消费 金融 的 新 机会 与 模式分析&#39; &#39;华能 信托&#39; &#39;新任 总经理 到位   五矿 信托 谋 突围&#39;
 &#39;五矿 信托 首任 总经理 辞职   接任 者 或 为 华能 信托 王卓&#39;
 &#39;华夏 幸福 关于 拟 与 华能 信托 签署 《 增资 协议 》 的 公告&#39;
 &#39;普邦 股份 : 华能 信托 . 普邦 1 号 集合 资金 信托 计划 信托 合同&#39;
 &#39;华能 信托 试水 首单 不良资产 收益权 转让 已有 46 家 信托公司 与 银登 中心 ...&#39;
 &#39;北京 银行 携手 华能 、 中航 信托 创新 慈善 信托 模式&#39;
 &#39;ACCA - 华能 信托 “ 财经 领袖 培养 计划 ” 第一期 学员 选拔 结果 公布&#39; &#39;华能 贵 诚信 托 有限公司&#39;
 &#39;国金 ABS 云   ·   早报 丨 招行 与 华能 信托 将 合作 发行 99 亿元 ABS&#39;
 &#39;用益 - 信托 日报 : 平安 江苏 中信 华能 位列 前四 ! 58 家 信托 上半年 净利 排位 !&#39;
 &#39;五矿 信托 首任 总经理 辞职   接任 者 或 为 华能 信托 王卓&#39;
 &#39;华夏 幸福 关于 拟 与 华能 信托 签署 《 增资 协议 》 的 公告&#39;
 &#39;普邦 股份 : 华能 信托 . 普邦 1 号 集合 资金 信托 计划 信托 合同&#39;
 &#39;华能 信托 试水 首单 不良资产 收益权 转让 已有 46 家 信托公司 与 银登 中心 ...&#39;
 &#39;北京 银行 携手 华能 、 中航 信托 创新 慈善 信托 模式&#39;
 &#39;ACCA - 华能 信托 “ 财经 领袖 培养 计划 ” 第一期 学员 选拔 结果 公布&#39; &#39;华能 贵 诚信 托 有限公司&#39;
 &#39;国金 ABS 云   ·   早报 丨 招行 与 华能 信托 将 合作 发行 99 亿元 ABS&#39;
 &#39;用益 - 信托 日报 : 平安 江苏 中信 华能 位列 前四 ! 58 家 信托 上半年 净利 排位 !&#39;
 &#39;五矿 信托 首任 总经理 辞职   接任 者 或 为 华能 信托 王卓&#39;
 &#39;华夏 幸福 关于 拟 与 华能 信托 签署 《 增资 协议 》 的 公告&#39;
 &#39;普邦 股份 : 华能 信托 . 普邦 1 号 集合 资金 信托 计划 信托 合同&#39;
 &#39;华能 信托 试水 首单 不良资产 收益权 转让 已有 46 家 信托公司 与 银登 中心 ...&#39;
 &#39;北京 银行 携手 华能 、 中航 信托 创新 慈善 信托 模式&#39;
 &#39;ACCA - 华能 信托 “ 财经 领袖 培养 计划 ” 第一期 学员 选拔 结果 公布&#39; &#39;华能 贵 诚信 托 有限公司&#39;
 &#39;国金 ABS 云   ·   早报 丨 招行 与 华能 信托 将 合作 发行 99 亿元 ABS&#39;
 &#39;用益 - 信托 日报 : 平安 江苏 中信 华能 位列 前四 ! 58 家 信托 上半年 净利 排位 !&#39;
 &#39;五矿 信托 首任 总经理 辞职   接任 者 或 为 华能 信托 王卓&#39;
 &#39;华夏 幸福 关于 拟 与 华能 信托 签署 《 增资 协议 》 的 公告&#39;
 &#39;普邦 股份 : 华能 信托 . 普邦 1 号 集合 资金 信托 计划 信托 合同&#39;
 &#39;华能 信托 试水 首单 不良资产 收益权 转让 已有 46 家 信托公司 与 银登 中心 ...&#39;
 &#39;北京 银行 携手 华能 、 中航 信托 创新 慈善 信托 模式&#39;
 &#39;ACCA - 华能 信托 “ 财经 领袖 培养 计划 ” 第一期 学员 选拔 结果 公布&#39; &#39;华能 贵 诚信 托 有限公司&#39;
 &#39;国金 ABS 云   ·   早报 丨 招行 与 华能 信托 将 合作 发行 99 亿元 ABS&#39;
 &#39;用益 - 信托 日报 : 平安 江苏 中信 华能 位列 前四 ! 58 家 信托 上半年 净利 排位 !&#39;
 &#39;五矿 信托 首任 总经理 辞职   接任 者 或 为 华能 信托 王卓&#39;
 &#39;华夏 幸福 关于 拟 与 华能 信托 签署 《 增资 协议 》 的 公告&#39;
 &#39;普邦 股份 : 华能 信托 . 普邦 1 号 集合 资金 信托 计划 信托 合同&#39;
 &#39;华能 信托 试水 首单 不良资产 收益权 转让 已有 46 家 信托公司 与 银登 中心 ...&#39;
 &#39;北京 银行 携手 华能 、 中航 信托 创新 慈善 信托 模式&#39;
 &#39;ACCA - 华能 信托 “ 财经 领袖 培养 计划 ” 第一期 学员 选拔 结果 公布&#39; &#39;华能 贵 诚信 托 有限公司&#39;
 &#39;国金 ABS 云   ·   早报 丨 招行 与 华能 信托 将 合作 发行 99 亿元 ABS&#39;
 &#39;用益 - 信托 日报 : 平安 江苏 中信 华能 位列 前四 ! 58 家 信托 上半年 净利 排位 !&#39;
 &#39;五矿 信托 首任 总经理 辞职   接任 者 或 为 华能 信托 王卓&#39;
 &#39;华夏 幸福 关于 拟 与 华能 信托 签署 《 增资 协议 》 的 公告&#39;
 &#39;普邦 股份 : 华能 信托 . 普邦 1 号 集合 资金 信托 计划 信托 合同&#39;
 &#39;华能 信托 试水 首单 不良资产 收益权 转让 已有 46 家 信托公司 与 银登 中心 ...&#39;
 &#39;北京 银行 携手 华能 、 中航 信托 创新 慈善 信托 模式&#39;
 &#39;ACCA - 华能 信托 “ 财经 领袖 培养 计划 ” 第一期 学员 选拔 结果 公布&#39; &#39;华能 贵 诚信 托 有限公司&#39;
 &#39;国金 ABS 云   ·   早报 丨 招行 与 华能 信托 将 合作 发行 99 亿元 ABS&#39;
 &#39;用益 - 信托 日报 : 平安 江苏 中信 华能 位列 前四 ! 58 家 信托 上半年 净利 排位 !&#39;
 &#39;五矿 信托 首任 总经理 辞职   接任 者 或 为 华能 信托 王卓&#39;
 &#39;华夏 幸福 关于 拟 与 华能 信托 签署 《 增资 协议 》 的 公告&#39;
 &#39;普邦 股份 : 华能 信托 . 普邦 1 号 集合 资金 信托 计划 信托 合同&#39;
 &#39;华能 信托 试水 首单 不良资产 收益权 转让 已有 46 家 信托公司 与 银登 中心 ...&#39;
 &#39;北京 银行 携手 华能 、 中航 信托 创新 慈善 信托 模式&#39;
 &#39;ACCA - 华能 信托 “ 财经 领袖 培养 计划 ” 第一期 学员 选拔 结果 公布&#39; &#39;华能 贵 诚信 托 有限公司&#39;
 &#39;国金 ABS 云   ·   早报 丨 招行 与 华能 信托 将 合作 发行 99 亿元 ABS&#39;
 &#39;用益 - 信托 日报 : 平安 江苏 中信 华能 位列 前四 ! 58 家 信托 上半年 净利 排位 !&#39;]
</code></pre>
<p>可以看到是有关财经类的新闻</p>
<hr>
<p><strong>补充：大数据分词：jieba库的使用</strong></p>
<p>1.jieba库的安装与简单演示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">word = jieba.cut(<span class="string">&#x27;我爱北京天安门&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> word:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>

<pre><code>我
爱
北京
天安门
</code></pre>
<p>注意，用cut()函数分词得到的word不是一个列表，而是一个迭代器，所谓迭代器其实和列表很相似，可以把它理解成一个“隐身的列表”，但是迭代器里的元素要通过for循环来访问，所以第3-4行代码不能改写成print(word)</p>
<p>2.读取文本内容并进行分词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">report = <span class="built_in">open</span>(<span class="string">&#x27;信托行业年度报告.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>).read()</span><br><span class="line">words = jieba.cut(report)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    <span class="built_in">print</span>(word)</span><br></pre></td></tr></table></figure>

<pre><code>2017
年
信托业
面临
着
较为
复杂
的
外部环境
。
一方面
，
全球
经济
逐步
复苏
，
中国
经济
持续
向
好
，
实体
经济
结构调整
，
新兴产业
发展
迅猛
，
居民
财富
不断
增长
，
这些
均
为
信托业
的
发展
带来
新
的
业务
机会
；
另一方面
，
社会
资金
供给
整体
偏紧
，
传统
业务
领域
不可
持续
，
风险
暴露
逐渐
增加
，
金融监管
持续
收紧
，
进入
“
统筹
协调
监管
”
的
新
阶段
，
信托业
的
转型
发展
压力
依然
较大
。
在
此
背景
下
，
信托公司
纷纷
将
战略
制定
和
战略
管理工作
提高
到
更加
重要
的
层面
，
包含
战略
制定
、
战略
分解
、
战略
监督
、
战略
评估
等
在内
的
战略
管理体系
逐步
建成
，
聚焦
公司
核心
竞争力
，
为
企业
的
长远
发展
作出
整体性
、
长期性
、
连续性
、
全局性
的
规划
方案
。
………………………………    
</code></pre>
<p>3.提取分词后的4字词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">words = jieba.cut(report)  <span class="comment"># 这里得重新jieba.cut()一下，因为之前的words用过一次就被清空了</span></span><br><span class="line">report_words = []</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:  <span class="comment"># 将大于4个字的词语放入列表</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(word) &gt;= <span class="number">4</span>:</span><br><span class="line">        report_words.append(word)</span><br><span class="line"><span class="built_in">print</span>(report_words)</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;2017&#39;, &#39;外部环境&#39;, &#39;结构调整&#39;, &#39;新兴产业&#39;, &#39;另一方面&#39;, &#39;金融监管&#39;, &#39;信托公司&#39;, &#39;管理工作&#39;, &#39;管理体系&#39;, &#39;2017&#39;, &#39;全面落实&#39;, &#39;结构调整&#39;, &#39;初见成效&#39;, &#39;金融监管&#39;, &#39;小康社会&#39;, &#39;深远影响&#39;, &#39;2017&#39;, &#39;多管齐下&#39;, &#39;长效机制&#39;, &#39;长效机制&#39;, &#39;建立健全&#39;, &#39;变化趋势&#39;, &#39;合作伙伴&#39;, &#39;积极探索&#39;, &#39;另一方面&#39;, &#39;积极探索&#39;, &#39;更新改造&#39;, &#39;REITs&#39;, &#39;市场前景&#39;, &#39;REITs&#39;, &#39;信托公司&#39;, &#39;充分发挥&#39;, &#39;REITs&#39;, &#39;REITs&#39;, &#39;REITs&#39;, &#39;2017&#39;, &#39;信托公司&#39;, &#39;信托公司&#39;, &#39;科技园区&#39;, &#39;CMBS&#39;, &#39;住宅建设&#39;, &#39;REITs&#39;, &#39;投资信托&#39;, &#39;基础设施&#39;, &#39;新形势下&#39;, &#39;基础产业&#39;, &#39;基础产业&#39;, &#39;交易方式&#39;, &#39;2017&#39;, &#39;信托公司&#39;, &#39;基础设施&#39;, &#39;基础产业&#39;, &#39;配套工程&#39;, &#39;有限公司&#39;, &#39;国际展览中心&#39;, &#39;管理机构&#39;, &#39;市场需求&#39;, &#39;金融机构&#39;, &#39;快速增长&#39;, &#39;2016&#39;, &#39;金融机构&#39;, &#39;金融机构&#39;, &#39;金融机构&#39;, &#39;信托公司&#39;, &#39;与此同时&#39;, &#39;信托公司&#39;, &#39;保险市场&#39;, &#39;金融工具&#39;, &#39;信托公司&#39;, &#39;传统模式&#39;, &#39;信托公司&#39;, &#39;事务管理&#39;, &#39;主导作用&#39;, &#39;信托公司&#39;, &#39;2017&#39;, &#39;常务会议&#39;, &#39;2025&#39;, &#39;2025&#39;, &#39;与此同时&#39;, &#39;高度重视&#39;, &#39;金融服务&#39;, &#39;明确指出&#39;, &#39;金融体制&#39;, &#39;金融服务&#39;, &#39;贯彻落实&#39;, &#39;2017&#39;, &#39;大力开展&#39;, &#39;新兴产业&#39;, &#39;信托公司&#39;, &#39;航空航天&#39;, &#39;新兴产业&#39;, &#39;贡献力量&#39;, &#39;生物医药&#39;, &#39;基础设施&#39;, &#39;现代农业&#39;, &#39;国家统计局&#39;, &#39;2017&#39;, &#39;58.8%&#39;, &#39;信托公司&#39;, &#39;积极开展&#39;, &#39;2014&#39;, &#39;金融业务&#39;, &#39;管理制度&#39;, &#39;管理系统&#39;, &#39;金融公司&#39;, &#39;金融公司&#39;, &#39;抢占市场&#39;, &#39;纷繁复杂&#39;, &#39;2017&#39;, &#39;金融业务&#39;, &#39;信托公司&#39;, &#39;信托公司&#39;, &#39;高附加值&#39;, &#39;事务管理&#39;, &#39;组成部分&#39;, &#39;2017&#39;, &#39;信托公司&#39;, &#39;友邦保险&#39;, &#39;人寿保险&#39;, &#39;金融机构&#39;, &#39;信托公司&#39;, &#39;保险公司&#39;, &#39;信托公司&#39;, &#39;信托公司&#39;, &#39;信托公司&#39;, &#39;信托公司&#39;, &#39;除此之外&#39;, &#39;2017&#39;, &#39;信托公司&#39;, &#39;美好生活&#39;, &#39;管理体系&#39;, &#39;管理决策&#39;, &#39;绩效考核&#39;, &#39;信息系统&#39;，………………]
</code></pre>
<p>4.统计高频词汇的词频</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">result = Counter(report_words) </span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<pre><code>Counter(&#123;&#39;信托公司&#39;: 1391, &#39;2017&#39;: 577, &#39;2016&#39;: 184, &#39;金融机构&#39;: 148, &#39;投资信托&#39;: 108, &#39;基础产业&#39;: 91, &#39;2018&#39;: 87, &#39;风险管理&#39;: 82, &#39;工商企业&#39;: 77, &#39;QDII&#39;: 70, &#39;金融服务&#39;: 69, &#39;信息系统&#39;: 63, &#39;2015&#39;: 59, &#39;基础设施&#39;: 56, &#39;金融公司&#39;: 47, &#39;另一方面&#39;: 45, &#39;信托投资公司&#39;: 45, &#39;中国人民银行&#39;: 44, &#39;REITs&#39;: 39, &#39;金融业务&#39;: 38, &#39;监管部门&#39;: 35, &#39;客户服务&#39;: 33, &#39;2013&#39;: 32, &#39;新兴产业&#39;: 31, &#39;资金来源&#39;: 31, &#39;商业银行&#39;: 30, &#39;信息技术&#39;: 29, &#39;金融市场&#39;: 29, &#39;2014&#39;: 28, &#39;有限公司&#39;: 24, &#39;债券市场&#39;: 24, &#39;管理体系&#39;: 23, &#39;发展趋势&#39;: 22, &#39;法律法规&#39;: 22, &#39;金融监管&#39;: 21, &#39;宏观经济&#39;: 20, &#39;产品设计&#39;: 19, &#39;对外开放&#39;: 19, &#39;管理系统&#39;: 18, &#39;人工智能&#39;: 18, &#39;事务管理&#39;: 17, &#39;金融风险&#39;: 17, &#39;上市公司&#39;: 16, &#39;积极探索&#39;: 15, &#39;充分发挥&#39;: 15, &#39;与此同时&#39;: 15, &#39;战略规划&#39;: 15, &#39;从业人员&#39;: 15, &#39;消费信贷&#39;: 15, &#39;组成部分&#39;: 14, ………………………………&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = Counter(report_words).most_common(<span class="number">50</span>)  <span class="comment"># 取最多的50组</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<pre><code>[(&#39;信托公司&#39;, 1391), (&#39;2017&#39;, 577), (&#39;2016&#39;, 184), (&#39;金融机构&#39;, 148), (&#39;投资信托&#39;, 108), (&#39;基础产业&#39;, 91), (&#39;2018&#39;, 87), (&#39;风险管理&#39;, 82), (&#39;工商企业&#39;, 77), (&#39;QDII&#39;, 70), (&#39;金融服务&#39;, 69), (&#39;信息系统&#39;, 63), (&#39;2015&#39;, 59), (&#39;基础设施&#39;, 56), (&#39;金融公司&#39;, 47), (&#39;另一方面&#39;, 45), (&#39;信托投资公司&#39;, 45), (&#39;中国人民银行&#39;, 44), (&#39;REITs&#39;, 39), (&#39;金融业务&#39;, 38), (&#39;监管部门&#39;, 35), (&#39;客户服务&#39;, 33), (&#39;2013&#39;, 32), (&#39;新兴产业&#39;, 31), (&#39;资金来源&#39;, 31), (&#39;商业银行&#39;, 30), (&#39;信息技术&#39;, 29), (&#39;金融市场&#39;, 29), (&#39;2014&#39;, 28), (&#39;有限公司&#39;, 24), (&#39;债券市场&#39;, 24), (&#39;管理体系&#39;, 23), (&#39;发展趋势&#39;, 22), (&#39;法律法规&#39;, 22), (&#39;金融监管&#39;, 21), (&#39;宏观经济&#39;, 20), (&#39;产品设计&#39;, 19), (&#39;对外开放&#39;, 19), (&#39;管理系统&#39;, 18), (&#39;人工智能&#39;, 18), (&#39;事务管理&#39;, 17), (&#39;金融风险&#39;, 17), (&#39;上市公司&#39;, 16), (&#39;积极探索&#39;, 15), (&#39;充分发挥&#39;, 15), (&#39;与此同时&#39;, 15), (&#39;战略规划&#39;, 15), (&#39;从业人员&#39;, 15), (&#39;消费信贷&#39;, 15), (&#39;组成部分&#39;, 14)]
</code></pre>
<p>完整代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.读取文本内容，并利用jieba.cut功能俩进行自动分词</span></span><br><span class="line">report = <span class="built_in">open</span>(<span class="string">&#x27;信托行业年度报告.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>).read()</span><br><span class="line">words = jieba.cut(report) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.通过for循环来提取words列表中大于4个字的词语</span></span><br><span class="line">report_words = []</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:  <span class="comment"># 将大于4个字的词语放入列表</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(word) &gt;= <span class="number">4</span>:</span><br><span class="line">        report_words.append(word)</span><br><span class="line"><span class="built_in">print</span>(report_words)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.获得打印输出高频词的出现次数</span></span><br><span class="line">result = Counter(report_words).most_common(<span class="number">50</span>)  <span class="comment"># 取词频最高的50组词</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<pre><code>Counter(&#123;&#39;信托公司&#39;: 1391, &#39;2017&#39;: 577, &#39;2016&#39;: 184, &#39;金融机构&#39;: 148, &#39;投资信托&#39;: 108, &#39;基础产业&#39;: 91, &#39;2018&#39;: 87, &#39;风险管理&#39;: 82, &#39;工商企业&#39;: 77, &#39;QDII&#39;: 70, &#39;金融服务&#39;: 69, &#39;信息系统&#39;: 63, &#39;2015&#39;: 59, &#39;基础设施&#39;: 56, &#39;金融公司&#39;: 47, &#39;另一方面&#39;: 45, &#39;信托投资公司&#39;: 45, &#39;中国人民银行&#39;: 44, &#39;REITs&#39;: 39, &#39;金融业务&#39;: 38, &#39;监管部门&#39;: 35, &#39;客户服务&#39;: 33, &#39;2013&#39;: 32, &#39;新兴产业&#39;: 31, &#39;资金来源&#39;: 31, &#39;商业银行&#39;: 30, &#39;信息技术&#39;: 29, &#39;金融市场&#39;: 29, &#39;2014&#39;: 28, &#39;有限公司&#39;: 24, &#39;债券市场&#39;: 24, &#39;管理体系&#39;: 23, &#39;发展趋势&#39;: 22, &#39;法律法规&#39;: 22, &#39;金融监管&#39;: 21, &#39;宏观经济&#39;: 20, &#39;产品设计&#39;: 19, &#39;对外开放&#39;: 19, &#39;管理系统&#39;: 18, &#39;人工智能&#39;: 18, &#39;事务管理&#39;: 17, &#39;金融风险&#39;: 17, &#39;上市公司&#39;: 16, &#39;积极探索&#39;: 15, &#39;充分发挥&#39;: 15, &#39;与此同时&#39;: 15, &#39;战略规划&#39;: 15, &#39;从业人员&#39;: 15, &#39;消费信贷&#39;: 15, &#39;组成部分&#39;: 14, ………………………………&#125;)
</code></pre>
<h1 id="14-智能推荐系统"><a href="#14-智能推荐系统" class="headerlink" title="14 智能推荐系统"></a>14 智能推荐系统</h1><h2 id="14-1-智能推荐系统的基本原理"><a href="#14-1-智能推荐系统的基本原理" class="headerlink" title="14.1 智能推荐系统的基本原理"></a>14.1 智能推荐系统的基本原理</h2><h3 id="14-1-1-智能推荐系统的应用场景"><a href="#14-1-1-智能推荐系统的应用场景" class="headerlink" title="14.1.1 智能推荐系统的应用场景"></a>14.1.1 智能推荐系统的应用场景</h3><h3 id="14-1-2-智能推荐系统的基础：协同过滤算法"><a href="#14-1-2-智能推荐系统的基础：协同过滤算法" class="headerlink" title="14.1.2 智能推荐系统的基础：协同过滤算法"></a>14.1.2 智能推荐系统的基础：协同过滤算法</h3><p>协同过滤算法的原理是根据用户群体的产品的偏好数据，发现用户或物品之间的相关性，并基于这些相关性为用户进行推荐。根据原理的不同，协同过滤算法分为两类——基于用户的协同过滤算法和基于物品的协同过滤算法</p>
<p><strong>1.基于用户的协同过滤算法</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(14).png" alt="下载 (14)"></p>
<p><strong>2.基于物品的协同过滤算法</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(15).png" alt="下载 (15)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(16).png" alt="下载 (16)"></p>
<h2 id="14-2-计算相似度的常用方法"><a href="#14-2-计算相似度的常用方法" class="headerlink" title="14.2 计算相似度的常用方法"></a>14.2 计算相似度的常用方法</h2><p>无论是基于用户还是基于产品的协同过滤算法，其本质都是寻找数据之间的相似度，计算相似度的三种方法——欧式距离、余弦值和皮尔逊相关系数<br><img src="%E4%B8%8B%E8%BD%BD%20(17).png" alt="下载 (17)"></p>
<h3 id="14-2-1-欧氏距离"><a href="#14-2-1-欧氏距离" class="headerlink" title="14.2.1 欧氏距离"></a>14.2.1 欧氏距离</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(18).png" alt="下载 (18)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(19).png" alt="下载 (19)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(20).png" alt="下载 (20)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(21).png" alt="下载 (21)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(22).png" alt="下载 (22)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame([[<span class="number">5</span>, <span class="number">1</span>, <span class="number">5</span>], [<span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>]], columns=[<span class="string">&#x27;用户1&#x27;</span>, <span class="string">&#x27;用户2&#x27;</span>, <span class="string">&#x27;用户3&#x27;</span>], index=[<span class="string">&#x27;物品A&#x27;</span>, <span class="string">&#x27;物品B&#x27;</span>, <span class="string">&#x27;物品C&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>用户1</th>
      <th>用户2</th>
      <th>用户3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>物品A</th>
      <td>5</td>
      <td>1</td>
      <td>5</td>
    </tr>
    <tr>
      <th>物品B</th>
      <td>4</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>物品C</th>
      <td>4</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">dist = np.linalg.norm(df.iloc[<span class="number">0</span>] - df.iloc[<span class="number">1</span>])</span><br><span class="line">dist</span><br></pre></td></tr></table></figure>




<pre><code>3.3166247903554
</code></pre>
<p><img src="%E4%B8%8B%E8%BD%BD%20(23).png" alt="下载 (23)"></p>
<h3 id="14-2-2-余弦相似度"><a href="#14-2-2-余弦相似度" class="headerlink" title="14.2.2 余弦相似度"></a>14.2.2 余弦相似度</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(24).png" alt="下载 (24)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame([[<span class="number">5</span>, <span class="number">1</span>, <span class="number">5</span>], [<span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>]], columns=[<span class="string">&#x27;用户1&#x27;</span>, <span class="string">&#x27;用户2&#x27;</span>, <span class="string">&#x27;用户3&#x27;</span>], index=[<span class="string">&#x27;物品A&#x27;</span>, <span class="string">&#x27;物品B&#x27;</span>, <span class="string">&#x27;物品C&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>用户1</th>
      <th>用户2</th>
      <th>用户3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>物品A</th>
      <td>5</td>
      <td>1</td>
      <td>5</td>
    </tr>
    <tr>
      <th>物品B</th>
      <td>4</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>物品C</th>
      <td>4</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line">user_similarity = cosine_similarity(df)</span><br><span class="line">pd.DataFrame(user_similarity, columns=[<span class="string">&#x27;物品A&#x27;</span>, <span class="string">&#x27;物品B&#x27;</span>, <span class="string">&#x27;物品C&#x27;</span>], index=[<span class="string">&#x27;物品A&#x27;</span>, <span class="string">&#x27;物品B&#x27;</span>, <span class="string">&#x27;物品C&#x27;</span>])</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>物品A</th>
      <th>物品B</th>
      <th>物品C</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>物品A</th>
      <td>1.000000</td>
      <td>0.914659</td>
      <td>0.825029</td>
    </tr>
    <tr>
      <th>物品B</th>
      <td>0.914659</td>
      <td>1.000000</td>
      <td>0.979958</td>
    </tr>
    <tr>
      <th>物品C</th>
      <td>0.825029</td>
      <td>0.979958</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以看到，物品B和物品C的余弦相似度最大，约为0.98，因此可以认为表中的所有物品中它们最相似</p>
<h3 id="14-2-3-皮尔逊相关系数"><a href="#14-2-3-皮尔逊相关系数" class="headerlink" title="14.2.3 皮尔逊相关系数"></a>14.2.3 皮尔逊相关系数</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(25).png" alt="下载 (25)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">X = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>]</span><br><span class="line">Y = [<span class="number">9</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>]</span><br><span class="line">corr = pearsonr(X, Y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;相关系数r值为&#x27;</span> + <span class="built_in">str</span>(corr[<span class="number">0</span>]) + <span class="string">&#x27;，显著性水平P值为&#x27;</span> + <span class="built_in">str</span>(corr[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>相关系数r值为-0.993883734673619，显著性水平P值为0.0005736731093321903
</code></pre>
<p><img src="%E4%B8%8B%E8%BD%BD%20(26).png" alt="下载 (26)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame([[<span class="number">5</span>, <span class="number">4</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>]], columns=[<span class="string">&#x27;物品A&#x27;</span>, <span class="string">&#x27;物品B&#x27;</span>, <span class="string">&#x27;物品C&#x27;</span>], index=[<span class="string">&#x27;用户1&#x27;</span>, <span class="string">&#x27;用户2&#x27;</span>, <span class="string">&#x27;用户3&#x27;</span>])  </span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>物品A</th>
      <th>物品B</th>
      <th>物品C</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>用户1</th>
      <td>5</td>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>用户2</th>
      <td>1</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>用户3</th>
      <td>5</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>corrwith()函数可以计算单个物品与其他物品的皮尔逊相关系数，corr()函数可以计算整张表的皮尔逊相关系数，因为这两个函数默认计算的是DataFrame的列与列之间的相关系数，所以需要将之前的表格转置一下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 物品A与其他物品的皮尔逊相关系数</span></span><br><span class="line">A = df[<span class="string">&#x27;物品A&#x27;</span>]</span><br><span class="line">corr_A = df.corrwith(A)</span><br><span class="line">corr_A</span><br></pre></td></tr></table></figure>




<pre><code>物品A    1.000000
物品B    0.500000
物品C    0.188982
dtype: float64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 皮尔逊系数表，获取各物品相关性</span></span><br><span class="line">df.corr()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>物品A</th>
      <th>物品B</th>
      <th>物品C</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>物品A</th>
      <td>1.000000</td>
      <td>0.500000</td>
      <td>0.188982</td>
    </tr>
    <tr>
      <th>物品B</th>
      <td>0.500000</td>
      <td>1.000000</td>
      <td>0.944911</td>
    </tr>
    <tr>
      <th>物品C</th>
      <td>0.188982</td>
      <td>0.944911</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



<p>B和C的r值的绝对值最大，约为0.9449，因此可以认为表中的所有物品中它们最相似，这与使用欧式距离和余弦相似度度量物品间相似度所得到的结论一致</p>
<h2 id="14-3-案例实战：电影智能推荐系统"><a href="#14-3-案例实战：电影智能推荐系统" class="headerlink" title="14.3 案例实战：电影智能推荐系统"></a>14.3 案例实战：电影智能推荐系统</h2><h3 id="14-3-1-案例背景"><a href="#14-3-1-案例背景" class="headerlink" title="14.3.1 案例背景"></a>14.3.1 案例背景</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(27).png" alt="下载 (27)"></p>
<h3 id="14-3-2-数据读取与处理"><a href="#14-3-2-数据读取与处理" class="headerlink" title="14.3.2 数据读取与处理"></a>14.3.2 数据读取与处理</h3><p><strong>1.读取数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">movies = pd.read_excel(<span class="string">&#x27;电影.xlsx&#x27;</span>)</span><br><span class="line">movies.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>电影编号</th>
      <th>名称</th>
      <th>类别</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>玩具总动员（1995）</td>
      <td>冒险|动画|儿童|喜剧|幻想</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>勇敢者的游戏（1995）</td>
      <td>冒险|儿童|幻想</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>斗气老顽童2（1995）</td>
      <td>喜剧|爱情</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>待到梦醒时分（1995）</td>
      <td>喜剧|剧情|爱情</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>新娘之父2（1995）</td>
      <td>喜剧</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = pd.read_excel(<span class="string">&#x27;评分.xlsx&#x27;</span>)</span><br><span class="line">score.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>用户编号</th>
      <th>电影编号</th>
      <th>评分</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>3</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>6</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>47</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>50</td>
      <td>5.0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.merge(movies, score, on=<span class="string">&#x27;电影编号&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>电影编号</th>
      <th>名称</th>
      <th>类别</th>
      <th>用户编号</th>
      <th>评分</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>玩具总动员（1995）</td>
      <td>冒险|动画|儿童|喜剧|幻想</td>
      <td>1</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>玩具总动员（1995）</td>
      <td>冒险|动画|儿童|喜剧|幻想</td>
      <td>5</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>玩具总动员（1995）</td>
      <td>冒险|动画|儿童|喜剧|幻想</td>
      <td>7</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>玩具总动员（1995）</td>
      <td>冒险|动画|儿童|喜剧|幻想</td>
      <td>15</td>
      <td>2.5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>玩具总动员（1995）</td>
      <td>冒险|动画|儿童|喜剧|幻想</td>
      <td>17</td>
      <td>4.5</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;评分&#x27;</span>].value_counts()  <span class="comment"># 查看各个评分的出现的次数</span></span><br></pre></td></tr></table></figure>




<pre><code>4.0    26794
3.0    20017
5.0    13180
3.5    13129
4.5     8544
2.0     7545
2.5     5544
1.0     2808
1.5     1791
0.5     1369
Name: 评分, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">df[<span class="string">&#x27;评分&#x27;</span>].hist(bins=<span class="number">20</span>)  <span class="comment"># hist()函数绘制直方图，竖轴为各评分出现的次数</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x15b3239c610&gt;
</code></pre>
<p><img src="output_195_1.png" alt="output_195_1"></p>
<p><strong>2.数据分析</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ratings = pd.DataFrame(df.groupby(<span class="string">&#x27;名称&#x27;</span>)[<span class="string">&#x27;评分&#x27;</span>].mean()) <span class="comment"># 对合并原始数据得到的DataFrame按“名称”归类，再用mean()函数计算每部电影的评分均值</span></span><br><span class="line">ratings.sort_values(<span class="string">&#x27;评分&#x27;</span>, ascending=<span class="literal">False</span>).head() <span class="comment"># 用sort_values()函数将评分均值从高到低排序</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>评分</th>
    </tr>
    <tr>
      <th>名称</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>假小子（1997）</th>
      <td>5.0</td>
    </tr>
    <tr>
      <th>福尔摩斯和华生医生历险记：讹诈之王（1980）</th>
      <td>5.0</td>
    </tr>
    <tr>
      <th>机器人（2016）</th>
      <td>5.0</td>
    </tr>
    <tr>
      <th>奥斯卡（1967）</th>
      <td>5.0</td>
    </tr>
    <tr>
      <th>人类状况III（1961）</th>
      <td>5.0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ratings[<span class="string">&#x27;评分次数&#x27;</span>] = df.groupby(<span class="string">&#x27;名称&#x27;</span>)[<span class="string">&#x27;评分&#x27;</span>].count() <span class="comment"># 统计每部电影的评分次数，然后为每部电影新增一列“评分次数”</span></span><br><span class="line">ratings.sort_values(<span class="string">&#x27;评分次数&#x27;</span>, ascending=<span class="literal">False</span>).head() <span class="comment"># 将评分次数从高到低排序</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>评分</th>
      <th>评分次数</th>
    </tr>
    <tr>
      <th>名称</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>阿甘正传（1994）</th>
      <td>4.164134</td>
      <td>329</td>
    </tr>
    <tr>
      <th>肖申克的救赎（1994）</th>
      <td>4.429022</td>
      <td>317</td>
    </tr>
    <tr>
      <th>低俗小说（1994）</th>
      <td>4.197068</td>
      <td>307</td>
    </tr>
    <tr>
      <th>沉默的羔羊（1991）</th>
      <td>4.161290</td>
      <td>279</td>
    </tr>
    <tr>
      <th>黑客帝国（1999）</th>
      <td>4.192446</td>
      <td>278</td>
    </tr>
  </tbody>
</table>
</div>



<p>从表中可以看出，排除极少数电影评分次数极低的情况，通常某部电影的评分次数越多，该电影的评分也会越高，假设某个用户给《阿甘正传》打了高分，我们需要寻找与《阿甘正传》相似度高的电影推荐给该用户</p>
<p><strong>3.数据处理</strong></p>
<p>先通过如下代码将原始数据转换为数据透视表。数据透视表是一种交互式表格，我们可以动态调整表格的版面布局，以便通过不同的方式分析数据，如求和、计数等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">user_movie = df.pivot_table(index=<span class="string">&#x27;用户编号&#x27;</span>, columns=<span class="string">&#x27;名称&#x27;</span>, values=<span class="string">&#x27;评分&#x27;</span>)</span><br><span class="line">user_movie.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>名称</th>
      <th>007之黄金眼（1995）</th>
      <th>100个女孩（2000）</th>
      <th>100条街道（2016）</th>
      <th>101忠狗续集:伦敦大冒险（2003）</th>
      <th>101忠狗（1961）</th>
      <th>101雷克雅未克（2000）</th>
      <th>102只斑点狗（2000）</th>
      <th>10件或更少（2006）</th>
      <th>10（1979）</th>
      <th>11:14（2003）</th>
      <th>...</th>
      <th>龙珠：神秘冒险（1988）</th>
      <th>龙珠：血红宝石的诅咒（1986）</th>
      <th>龙珠：魔鬼城堡中的睡公主（1987）</th>
      <th>龙种子（1944）</th>
      <th>龙纹身的女孩（2011）</th>
      <th>龙舌兰日出（1988）</th>
      <th>龙虾（2015）</th>
      <th>龙：夜之怒的礼物（2011）</th>
      <th>龙：李小龙的故事（1993）</th>
      <th>龟日记（1985）</th>
    </tr>
    <tr>
      <th>用户编号</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>606</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>607</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>608</th>
      <td>4.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>609</th>
      <td>4.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>610</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>4.5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 9687 columns</p>
</div>



<p>pivot_table()函数基于变量df创建数据透视表，并赋给变量user_movie。其中设置函数的index参数为“用户编号”，即以用户编号作为数据透视表的索引；设置columns参数为“名称”，即以电影名称作为数据透视表的列；设置values参数作为“评分”，即以电影评分作为数据透视表中显示的数据</p>
<p>其中行代表不同的用户，列代表不同的电影，第i行第j列单元格中的值代表第i个用户对第j部电影的评分，可以看到，绝大部分评分是NAN，数据透视表显得非常稀松，这是因为电影数量过于庞大，每个用户打分的电影数量却很有限</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user_movie.describe()  <span class="comment"># 因为数据量较大，这个耗时可能会有1分钟左右</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>名称</th>
      <th>007之黄金眼（1995）</th>
      <th>100个女孩（2000）</th>
      <th>100条街道（2016）</th>
      <th>101忠狗续集:伦敦大冒险（2003）</th>
      <th>101忠狗（1961）</th>
      <th>101雷克雅未克（2000）</th>
      <th>102只斑点狗（2000）</th>
      <th>10件或更少（2006）</th>
      <th>10（1979）</th>
      <th>11:14（2003）</th>
      <th>...</th>
      <th>龙珠：神秘冒险（1988）</th>
      <th>龙珠：血红宝石的诅咒（1986）</th>
      <th>龙珠：魔鬼城堡中的睡公主（1987）</th>
      <th>龙种子（1944）</th>
      <th>龙纹身的女孩（2011）</th>
      <th>龙舌兰日出（1988）</th>
      <th>龙虾（2015）</th>
      <th>龙：夜之怒的礼物（2011）</th>
      <th>龙：李小龙的故事（1993）</th>
      <th>龟日记（1985）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>132.000000</td>
      <td>4.00</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>44.000000</td>
      <td>1.0</td>
      <td>9.000000</td>
      <td>3.000000</td>
      <td>4.000000</td>
      <td>4.00</td>
      <td>...</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.000000</td>
      <td>1.0</td>
      <td>42.000000</td>
      <td>13.000000</td>
      <td>7.000000</td>
      <td>1.0</td>
      <td>8.00000</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.496212</td>
      <td>3.25</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>3.431818</td>
      <td>3.5</td>
      <td>2.777778</td>
      <td>2.666667</td>
      <td>3.375000</td>
      <td>3.75</td>
      <td>...</td>
      <td>3.5</td>
      <td>3.5</td>
      <td>3.250000</td>
      <td>3.5</td>
      <td>3.488095</td>
      <td>3.038462</td>
      <td>4.000000</td>
      <td>5.0</td>
      <td>2.81250</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.859381</td>
      <td>0.50</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.751672</td>
      <td>NaN</td>
      <td>0.833333</td>
      <td>1.040833</td>
      <td>1.030776</td>
      <td>0.50</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.353553</td>
      <td>NaN</td>
      <td>1.327422</td>
      <td>0.431158</td>
      <td>0.707107</td>
      <td>NaN</td>
      <td>1.03294</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.500000</td>
      <td>2.50</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>1.500000</td>
      <td>3.5</td>
      <td>2.000000</td>
      <td>1.500000</td>
      <td>2.000000</td>
      <td>3.00</td>
      <td>...</td>
      <td>3.5</td>
      <td>3.5</td>
      <td>3.000000</td>
      <td>3.5</td>
      <td>0.500000</td>
      <td>2.000000</td>
      <td>3.000000</td>
      <td>5.0</td>
      <td>0.50000</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>3.000000</td>
      <td>3.25</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>3.000000</td>
      <td>3.5</td>
      <td>2.000000</td>
      <td>2.250000</td>
      <td>3.125000</td>
      <td>3.75</td>
      <td>...</td>
      <td>3.5</td>
      <td>3.5</td>
      <td>3.125000</td>
      <td>3.5</td>
      <td>2.625000</td>
      <td>3.000000</td>
      <td>3.500000</td>
      <td>5.0</td>
      <td>2.87500</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.500000</td>
      <td>3.50</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>3.500000</td>
      <td>3.5</td>
      <td>2.500000</td>
      <td>3.000000</td>
      <td>3.500000</td>
      <td>4.00</td>
      <td>...</td>
      <td>3.5</td>
      <td>3.5</td>
      <td>3.250000</td>
      <td>3.5</td>
      <td>4.000000</td>
      <td>3.000000</td>
      <td>4.000000</td>
      <td>5.0</td>
      <td>3.00000</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>3.50</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>4.000000</td>
      <td>3.5</td>
      <td>3.000000</td>
      <td>3.250000</td>
      <td>3.750000</td>
      <td>4.00</td>
      <td>...</td>
      <td>3.5</td>
      <td>3.5</td>
      <td>3.375000</td>
      <td>3.5</td>
      <td>4.000000</td>
      <td>3.000000</td>
      <td>4.500000</td>
      <td>5.0</td>
      <td>3.12500</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>max</th>
      <td>5.000000</td>
      <td>3.50</td>
      <td>2.5</td>
      <td>2.5</td>
      <td>5.000000</td>
      <td>3.5</td>
      <td>4.500000</td>
      <td>3.500000</td>
      <td>4.500000</td>
      <td>4.00</td>
      <td>...</td>
      <td>3.5</td>
      <td>3.5</td>
      <td>3.500000</td>
      <td>3.5</td>
      <td>5.000000</td>
      <td>4.000000</td>
      <td>5.000000</td>
      <td>5.0</td>
      <td>4.00000</td>
      <td>4.0</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 9687 columns</p>
</div>



<p>上表中的count是该电影被评分的次数，mean是评分的均值，std是评分的标准差，min是最低评分，25%，50%，75%是相应的分位数，max是最高评分</p>
<h3 id="14-3-3-系统搭建"><a href="#14-3-3-系统搭建" class="headerlink" title="14.3.3 系统搭建"></a>14.3.3 系统搭建</h3><p>本小节利用之前处理好的数据进行相关性分析，以《阿甘正传》为例，分析应该向观看了《阿甘正传》的用户推荐什么样的电影</p>
<p>首先从数据透视表中提取各用户对《阿甘正传》的评分，使用head()函数显示前5行，代码如下，其中FG是《阿甘正传》的英文名首字母缩写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FG = user_movie[<span class="string">&#x27;阿甘正传（1994）&#x27;</span>]  <span class="comment"># FG是Forrest Gump（），阿甘英文名称的缩写</span></span><br><span class="line">pd.DataFrame(FG).head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>阿甘正传（1994）</th>
    </tr>
    <tr>
      <th>用户编号</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># axis默认为0，计算user_movie各列与FG的相关系数</span></span><br><span class="line">corr_FG = user_movie.corrwith(FG)</span><br><span class="line">similarity = pd.DataFrame(corr_FG, columns=[<span class="string">&#x27;相关系数&#x27;</span>])</span><br><span class="line">similarity.head()</span><br></pre></td></tr></table></figure>





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>相关系数</th>
    </tr>
    <tr>
      <th>名称</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>007之黄金眼（1995）</th>
      <td>0.217441</td>
    </tr>
    <tr>
      <th>100个女孩（2000）</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>100条街道（2016）</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>101忠狗续集:伦敦大冒险（2003）</th>
      <td>NaN</td>
    </tr>
    <tr>
      <th>101忠狗（1961）</th>
      <td>0.141023</td>
    </tr>
  </tbody>
</table>
</div>



<p>表中有些相关系数是空值，这是因为计算变量user_movie的列向量和变量FG的皮尔逊相关系数时，其实是在计算某部电影的所有评分和《阿甘正传》的所有评分的皮尔逊相关系数。如果某列的空值过多，与《阿甘正传》的所有用户的评分一个交叉项也没有，即没有一个用户同时对这两部电影进行打分，那么就无法计算皮尔逊相关系数中的协方差，导致表中出现了很多空值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">similarity.dropna(inplace=<span class="literal">True</span>)  <span class="comment"># 或写成similarity=similarity.dropna()</span></span><br><span class="line">similarity.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>相关系数</th>
    </tr>
    <tr>
      <th>名称</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>007之黄金眼（1995）</th>
      <td>0.217441</td>
    </tr>
    <tr>
      <th>101忠狗（1961）</th>
      <td>0.141023</td>
    </tr>
    <tr>
      <th>102只斑点狗（2000）</th>
      <td>-0.857589</td>
    </tr>
    <tr>
      <th>10件或更少（2006）</th>
      <td>-1.000000</td>
    </tr>
    <tr>
      <th>11:14（2003）</th>
      <td>0.500000</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">similarity_new = pd.merge(similarity, ratings[<span class="string">&#x27;评分次数&#x27;</span>], left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line">similarity_new.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>相关系数</th>
      <th>评分次数</th>
    </tr>
    <tr>
      <th>名称</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>007之黄金眼（1995）</th>
      <td>0.217441</td>
      <td>132</td>
    </tr>
    <tr>
      <th>101忠狗（1961）</th>
      <td>0.141023</td>
      <td>44</td>
    </tr>
    <tr>
      <th>102只斑点狗（2000）</th>
      <td>-0.857589</td>
      <td>9</td>
    </tr>
    <tr>
      <th>10件或更少（2006）</th>
      <td>-1.000000</td>
      <td>3</td>
    </tr>
    <tr>
      <th>11:14（2003）</th>
      <td>0.500000</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第二种合并方式</span></span><br><span class="line">similarity_new = similarity.join(ratings[<span class="string">&#x27;评分次数&#x27;</span>])</span><br><span class="line">similarity_new.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>相关系数</th>
      <th>评分次数</th>
    </tr>
    <tr>
      <th>名称</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>007之黄金眼（1995）</th>
      <td>0.217441</td>
      <td>132</td>
    </tr>
    <tr>
      <th>101忠狗（1961）</th>
      <td>0.141023</td>
      <td>44</td>
    </tr>
    <tr>
      <th>102只斑点狗（2000）</th>
      <td>-0.857589</td>
      <td>9</td>
    </tr>
    <tr>
      <th>10件或更少（2006）</th>
      <td>-1.000000</td>
      <td>3</td>
    </tr>
    <tr>
      <th>11:14（2003）</th>
      <td>0.500000</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>



<p>因为电影数量庞大，每个用户评过分的电影数量却是有限的，导致许多电影的评分次数很少，所以可能有偶然的因素导致部分电影的评分偏高或偏低，无法反映真实水平，此时需要设置阈值，只有当评分次数大于该阈值时才认为该电影的总体评分有效，这里简单设置阈值为20</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">similarity_new[similarity_new[<span class="string">&#x27;评分次数&#x27;</span>] &gt; <span class="number">20</span>].sort_values(by=<span class="string">&#x27;相关系数&#x27;</span>, ascending=<span class="literal">False</span>).head()  <span class="comment"># 选取阈值</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>相关系数</th>
      <th>评分次数</th>
    </tr>
    <tr>
      <th>名称</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>阿甘正传（1994）</th>
      <td>1.000000</td>
      <td>329</td>
    </tr>
    <tr>
      <th>抓狂双宝（1996）</th>
      <td>0.723238</td>
      <td>31</td>
    </tr>
    <tr>
      <th>雷神：黑暗世界（2013）</th>
      <td>0.715809</td>
      <td>21</td>
    </tr>
    <tr>
      <th>致命吸引力（1987）</th>
      <td>0.701856</td>
      <td>36</td>
    </tr>
    <tr>
      <th>X战警：未来的日子（2014）</th>
      <td>0.682284</td>
      <td>30</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>补充知识点：groupby()函数的使用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.DataFrame([[<span class="string">&#x27;战狼2&#x27;</span>, <span class="string">&#x27;丁一&#x27;</span>, <span class="number">6</span>, <span class="number">8</span>], [<span class="string">&#x27;攀登者&#x27;</span>, <span class="string">&#x27;王二&#x27;</span>, <span class="number">8</span>, <span class="number">6</span>], [<span class="string">&#x27;攀登者&#x27;</span>, <span class="string">&#x27;张三&#x27;</span>, <span class="number">10</span>, <span class="number">8</span>], [<span class="string">&#x27;卧虎藏龙&#x27;</span>, <span class="string">&#x27;李四&#x27;</span>, <span class="number">8</span>, <span class="number">8</span>], [<span class="string">&#x27;卧虎藏龙&#x27;</span>, <span class="string">&#x27;赵五&#x27;</span>, <span class="number">8</span>, <span class="number">10</span>]], columns=[<span class="string">&#x27;电影名称&#x27;</span>, <span class="string">&#x27;影评师&#x27;</span>, <span class="string">&#x27;观前评分&#x27;</span>, <span class="string">&#x27;观后评分&#x27;</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>电影名称</th>
      <th>影评师</th>
      <th>观前评分</th>
      <th>观后评分</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>战狼2</td>
      <td>丁一</td>
      <td>6</td>
      <td>8</td>
    </tr>
    <tr>
      <th>1</th>
      <td>攀登者</td>
      <td>王二</td>
      <td>8</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>攀登者</td>
      <td>张三</td>
      <td>10</td>
      <td>8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>卧虎藏龙</td>
      <td>李四</td>
      <td>8</td>
      <td>8</td>
    </tr>
    <tr>
      <th>4</th>
      <td>卧虎藏龙</td>
      <td>赵五</td>
      <td>8</td>
      <td>10</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">means = data.groupby(<span class="string">&#x27;电影名称&#x27;</span>)[[<span class="string">&#x27;观后评分&#x27;</span>]].mean()</span><br><span class="line">means</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>观后评分</th>
    </tr>
    <tr>
      <th>电影名称</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>卧虎藏龙</th>
      <td>9</td>
    </tr>
    <tr>
      <th>战狼2</th>
      <td>8</td>
    </tr>
    <tr>
      <th>攀登者</th>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div>



<p>这行代码的含义是为现根据电影名称进行分组，然后选取分组后的观影评分，并用mean()函数计算每个组的观后评分的平均值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">means = data.groupby(<span class="string">&#x27;电影名称&#x27;</span>)[[<span class="string">&#x27;观前评分&#x27;</span>, <span class="string">&#x27;观后评分&#x27;</span>]].mean()</span><br><span class="line">means</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>观前评分</th>
      <th>观后评分</th>
    </tr>
    <tr>
      <th>电影名称</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>卧虎藏龙</th>
      <td>8</td>
      <td>9</td>
    </tr>
    <tr>
      <th>战狼2</th>
      <td>6</td>
      <td>8</td>
    </tr>
    <tr>
      <th>攀登者</th>
      <td>9</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">means = data.groupby([<span class="string">&#x27;电影名称&#x27;</span>, <span class="string">&#x27;影评师&#x27;</span>])[[<span class="string">&#x27;观后评分&#x27;</span>]].mean()</span><br><span class="line">means</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>观后评分</th>
    </tr>
    <tr>
      <th>电影名称</th>
      <th>影评师</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">卧虎藏龙</th>
      <th>李四</th>
      <td>8</td>
    </tr>
    <tr>
      <th>赵五</th>
      <td>10</td>
    </tr>
    <tr>
      <th>战狼2</th>
      <th>丁一</th>
      <td>8</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">攀登者</th>
      <th>张三</th>
      <td>8</td>
    </tr>
    <tr>
      <th>王二</th>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>



<p>这里设置了多重索引，其中第一重索引为电影名称，第二重索引为影评师</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">count = data.groupby(<span class="string">&#x27;电影名称&#x27;</span>)[[<span class="string">&#x27;观后评分&#x27;</span>]].count()</span><br><span class="line">count</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>观后评分</th>
    </tr>
    <tr>
      <th>电影名称</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>卧虎藏龙</th>
      <td>2</td>
    </tr>
    <tr>
      <th>战狼2</th>
      <td>1</td>
    </tr>
    <tr>
      <th>攀登者</th>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">count = count.rename(columns=&#123;<span class="string">&#x27;观后评分&#x27;</span>:<span class="string">&#x27;评分次数&#x27;</span>&#125;)</span><br><span class="line">count</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>评分次数</th>
    </tr>
    <tr>
      <th>电影名称</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>卧虎藏龙</th>
      <td>2</td>
    </tr>
    <tr>
      <th>战狼2</th>
      <td>1</td>
    </tr>
    <tr>
      <th>攀登者</th>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>


      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">数据科学</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习与深度学习//" class="article-tag-list-link color5">机器学习与深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part4/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-python大数据分析与机器学习商业案例实战-part3" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part3/">Python大数据分析与机器学习商业案例实战-part3</a>
    </h1>
  

        
        <a href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part3/" class="archive-article-date">
  	<time datetime="2023-02-03T09:13:14.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-03</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="11-特征工程之数据预处理"><a href="#11-特征工程之数据预处理" class="headerlink" title="11 特征工程之数据预处理"></a>11 特征工程之数据预处理</h1><p>在实际工作中获取到的数据往往不那么理想，可能会存在非数值类型的文本数据、重复值、缺失值、异常值及数据分布不均衡等问题，因此，在进行数学建模前还需要对这些问题进行处理，这项工作称为特征工程。特征工程通常分为特征使用方案、特征获取方案、特征处理、特征监控几大部分，其中特征处理是特征工程的核心内容，有时称为数据预处理。</p>
<p>本章可以当成工具手册进行查阅</p>
<h2 id="11-1-非数值类型数据处理"><a href="#11-1-非数值类型数据处理" class="headerlink" title="11.1 非数值类型数据处理"></a>11.1 非数值类型数据处理</h2><p>有时会包含一些非数值数据，其中最常见的为文本数据，例如性别中的男女，处理时可替换为1和0</p>
<p>下面介绍python中两种常用的数值类型数据处理方法——Get_dummies哑变量处理和Label Encoding编号处理</p>
<h3 id="11-1-1-Get-dummies哑变量处理"><a href="#11-1-1-Get-dummies哑变量处理" class="headerlink" title="11.1.1 Get_dummies哑变量处理"></a>11.1.1 Get_dummies哑变量处理</h3><p>哑变量也叫虚拟变量，通常取值为0或1，python中用get_dummies()函数进行哑变量处理，不仅可以处理只有两个分类的简单问题，还可以处理含多个分类的问题</p>
<p>1.简单示例：“男”和“女”的数值转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;客户编号&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;性别&#x27;</span>: [<span class="string">&#x27;男&#x27;</span>, <span class="string">&#x27;女&#x27;</span>, <span class="string">&#x27;男&#x27;</span>]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>客户编号</th>
      <th>性别</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>男</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>女</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>男</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.get_dummies(df, columns=[<span class="string">&#x27;性别&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>客户编号</th>
      <th>性别_女</th>
      <th>性别_男</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以看到，原来的性别列变为“性别_女”和“性别_男”两列，这两列中的数字1表示符合列名，数字0表示不符合列名</p>
<p>虽然现在已经将文本类型的数据转换成了数字，但是“性别_女”和“性别_男”这两列存在多重共线性，即知道其中一列的内容，就能知道另一列的内容，用公式表达就是：性别_男&#x3D;1-性别_女</p>
<p>多重共线性会带来一些问题，因此需要用drop()函数删去其中一列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = df.drop(columns=<span class="string">&#x27;性别_女&#x27;</span>) </span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>客户编号</th>
      <th>性别_男</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>用rename()函数更改列名</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = df.rename(columns=&#123;<span class="string">&#x27;性别_男&#x27;</span>:<span class="string">&#x27;性别&#x27;</span>&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>客户编号</th>
      <th>性别</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>2.稍复杂点的案例：房屋朝向的数值转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;房屋编号&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="string">&#x27;朝向&#x27;</span>: [<span class="string">&#x27;东&#x27;</span>, <span class="string">&#x27;南&#x27;</span>, <span class="string">&#x27;西&#x27;</span>, <span class="string">&#x27;北&#x27;</span>, <span class="string">&#x27;南&#x27;</span>]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>房屋编号</th>
      <th>朝向</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>东</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>南</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>西</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>北</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>南</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.get_dummies(df, columns=[<span class="string">&#x27;朝向&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>房屋编号</th>
      <th>朝向_东</th>
      <th>朝向_北</th>
      <th>朝向_南</th>
      <th>朝向_西</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>上表还是同样存在多重共线性（即根据3个朝向的数字就能判断第4个朝向的数字是0还是1），因此需要从新构造出来的4个哑变量中删去一个</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = df.drop(columns=<span class="string">&#x27;朝向_西&#x27;</span>) </span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>房屋编号</th>
      <th>朝向_东</th>
      <th>朝向_北</th>
      <th>朝向_南</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>注意</strong>：构造哑变量容易产生高维数据，因此，哑变量常常和PCA主成分分析一起使用</p>
<h3 id="11-1-2-Label-Encoding编号处理"><a href="#11-1-2-Label-Encoding编号处理" class="headerlink" title="11.1.2 Label Encoding编号处理"></a>11.1.2 Label Encoding编号处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;编号&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="string">&#x27;城市&#x27;</span>: [<span class="string">&#x27;北京&#x27;</span>, <span class="string">&#x27;上海&#x27;</span>, <span class="string">&#x27;广州&#x27;</span>, <span class="string">&#x27;深圳&#x27;</span>, <span class="string">&#x27;北京&#x27;</span>]&#125;)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>编号</th>
      <th>城市</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>北京</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>上海</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>广州</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>深圳</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>北京</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">label = le.fit_transform(df[<span class="string">&#x27;城市&#x27;</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(label)</span><br></pre></td></tr></table></figure>

<pre><code>[1 0 2 3 1]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;城市&#x27;</span>] = label</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>编号</th>
      <th>城市</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>注意</strong>：可以看到上海和广州的平均值是北京，这个现象其实是没有现实意义的，这也是Label Encoding的一个缺点——可能会产生一些没有意义的关系。不过树模型（如决策树、随机森林及XGBoost等集成算法）能很好地处理这种转化，因此对于树模型来说，这种奇怪的现象是不会影响结果的。</p>
<p><strong>补充知识点</strong>：pandas库中的replace()函数</p>
<p>上述Label Encoding函数生成的数字是随机的，如果想按特定的内容进行替换，可以使用replace()函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;编号&#x27;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="string">&#x27;城市&#x27;</span>: [<span class="string">&#x27;北京&#x27;</span>, <span class="string">&#x27;上海&#x27;</span>, <span class="string">&#x27;广州&#x27;</span>, <span class="string">&#x27;深圳&#x27;</span>, <span class="string">&#x27;北京&#x27;</span>]&#125;)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;城市&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>北京    2
深圳    1
广州    1
上海    1
Name: 城市, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;城市&#x27;</span>] = df[<span class="string">&#x27;城市&#x27;</span>].replace(&#123;<span class="string">&#x27;北京&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;上海&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;广州&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;深圳&#x27;</span>:<span class="number">3</span>&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>编号</th>
      <th>城市</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>总结来说，Get_dummies的优点就是它的值只有0和1，缺点是当类别的数量很多时，特征维度会很高，我们可以配合使用下一章即将讲到的PCA主成分分析来减少维度。所以如果Get_dummies类别数目不多时可以优先考虑，其次考虑Label Encoding或replace()函数，但如果是基于树模型的机器学习模型，则是用Label Encoding编号处理则没有太大关系。</p>
<h2 id="11-2-重复值、缺失值及异常值处理"><a href="#11-2-重复值、缺失值及异常值处理" class="headerlink" title="11.2 重复值、缺失值及异常值处理"></a>11.2 重复值、缺失值及异常值处理</h2><h3 id="11-2-1-重复值处理"><a href="#11-2-1-重复值处理" class="headerlink" title="11.2.1 重复值处理"></a>11.2.1 重复值处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里首先创建一个含有重复值的DataFrame，代码如下：</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.DataFrame([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], columns=[<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时的data二维列表如下所示，可以看到第一行和第二行是重复的。</span></span><br><span class="line">data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果数据量较大，我们可以通过duplicated()函数来查询重复的内容，代码如下：</span></span><br><span class="line">data[data.duplicated()]</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果想统计重复行的数量，可以通过sum()函数进行查看，代码如下，本案例结果为1。</span></span><br><span class="line">data.duplicated().<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>




<pre><code>1
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发现有重复行的时候，可以通过drop_duplicates()函数删除重复行，代码如下：</span></span><br><span class="line">data = data.drop_duplicates()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果想按列进行去重，比如说如果c1列出现相同的内容，就把那行代码删掉，可以采用如下代码。这样的筛选条件则不如之前要全部一样才删除严格。</span></span><br><span class="line">data = pd.DataFrame([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], columns=[<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>])</span><br><span class="line">data = data.drop_duplicates(<span class="string">&#x27;c1&#x27;</span>)</span><br><span class="line">data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="11-2-2-缺失值处理"><a href="#11-2-2-缺失值处理" class="headerlink" title="11.2.2 缺失值处理"></a>11.2.2 缺失值处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里先构造一个含有缺失值的DataFrame，代码如下：</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = pd.DataFrame([[<span class="number">1</span>, np.nan, <span class="number">3</span>], [np.nan, <span class="number">2</span>, np.nan], [<span class="number">1</span>, np.nan, <span class="number">0</span>]], columns=[<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>])</span><br><span class="line">data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以用isnull()函数或isna()函数（两者作用类似）来查看空值，代码如下：</span></span><br><span class="line">data.isnull()  <span class="comment"># 或者写data.isna()</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 也可以对单列查看缺失值情况，代码如下：</span></span><br><span class="line">data[<span class="string">&#x27;c1&#x27;</span>].isnull()</span><br></pre></td></tr></table></figure>




<pre><code>0    False
1     True
2    False
Name: c1, dtype: bool
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果数据量较大，可以通过如下代码筛选某列内容为空值的行，代码如下：</span></span><br><span class="line">data[data[<span class="string">&#x27;c1&#x27;</span>].isnull()]</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于空值有两种常见的处理方式：删除空值和填补空值。常用方法</span></span><br><span class="line"><span class="comment"># 通过dropna()函数可以删除空值，代码如下：</span></span><br><span class="line">a = data.dropna()</span><br><span class="line">a</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果觉得该删除方法过于激进，可以设置thresh参数，比如将其设置为n，那么其含义是如果该行的非空值少于n个则删除该行，演示代码如下：</span></span><br><span class="line">a = data.dropna(thresh=<span class="number">2</span>)</span><br><span class="line">a</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>



<p>第一行和第三行都有两个非空值，因此不会被删除该行，而第二行只有一个非空值，少于两个，因此会被删除</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过finllna()函数可以填补空值，这里采用的是均值填充法，通过每一列的均值对该列的空值进行填充，也可以把其中的data.mean()换成data.meian()则变为中位数填充。</span></span><br><span class="line">b = data.fillna(data.mean())</span><br><span class="line">b</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处method=&#x27;pad&#x27;代表用缺失值所在列的前一个值填充，如果前一个值不存在或也缺失，则结果不变。运行结果如下：</span></span><br><span class="line">c = data.fillna(method=<span class="string">&#x27;pad&#x27;</span>)</span><br><span class="line">c</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 还可以采用method=&#x27;backfill&#x27;或method=&#x27;bfill&#x27;用缺失值所在列的后一个值填充，如果后一个值不存在或也缺失，则结果不变。</span></span><br><span class="line">d = data.fillna(method=<span class="string">&#x27;backfill&#x27;</span>)</span><br><span class="line">e = data.fillna(method=<span class="string">&#x27;bfill&#x27;</span>)</span><br><span class="line">e</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="11-2-3-异常值处理"><a href="#11-2-3-异常值处理" class="headerlink" title="11.2.3 异常值处理"></a>11.2.3 异常值处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里先构造一个含有异常值的数据集：</span></span><br><span class="line">data = pd.DataFrame(&#123;<span class="string">&#x27;c1&#x27;</span>: [<span class="number">3</span>, <span class="number">10</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">69</span>], <span class="string">&#x27;c2&#x27;</span>: [<span class="number">15</span>, <span class="number">16</span>, <span class="number">14</span>, <span class="number">100</span>, <span class="number">19</span>, <span class="number">11</span>, <span class="number">8</span>], <span class="string">&#x27;c3&#x27;</span>: [<span class="number">20</span>, <span class="number">15</span>, <span class="number">18</span>, <span class="number">21</span>, <span class="number">120</span>, <span class="number">27</span>, <span class="number">29</span>]&#125;, columns=[<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>])</span><br><span class="line">data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>15</td>
      <td>20</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10</td>
      <td>16</td>
      <td>15</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>14</td>
      <td>18</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7</td>
      <td>100</td>
      <td>21</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>19</td>
      <td>120</td>
    </tr>
    <tr>
      <th>5</th>
      <td>9</td>
      <td>11</td>
      <td>27</td>
    </tr>
    <tr>
      <th>6</th>
      <td>69</td>
      <td>8</td>
      <td>29</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以看到第一列的数字69，第二列的数字100，第三列的数字120为比较明显的异常值，那么该如何利用Python来进行异常值的检测呢？下面我们主要通过两种方法来进行检测：利用箱体图观察和利用标准差检测。</p>
<p><strong>1.利用箱型图观察</strong></p>
<p>箱体图是一种用于显示一组数据分散情况资料的统计图，可以通过设定标准，将大于或小于箱体图上下界的数值识别为异常值</p>
<p>如下图所示，将数据的下四分位数记为Q1，即样本中仅有25%的数据小于Q1；将数据的上四分位数记为Q3，即样本中仅有25%的数据大于Q3；将上四分位数和下四分位数的差值记为IQR，记IQR&#x3D;Q3-Q1；令箱体图上界为Q3+1.5xIQR，下界为Q1-1.5xIQR<br><img src="%E4%B8%8B%E8%BD%BD.png" alt="下载"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.boxplot()  <span class="comment"># 画箱型图</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1f64cdd69a0&gt;
</code></pre>
<p><img src="output_57_1.png" alt="output_57_1"></p>
<p>可以明显看到每列数据各有一个异常值</p>
<p><strong>2.利用标准差检测</strong></p>
<p>当数据服从标准正态分布时，99%的数值与均值的距离应该在3个标准差之内，95%的数值与均值的距离应该在2个标准差之内，因为三个标准差过于严格，此处将阈值设定为2个标准差，即认为当数值与均值的距离超出2个标准差，则可以认为它是异常值</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(1).png" alt="下载 (1)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data.columns:  <span class="comment"># 用for循环以此对数据的每列进行操作</span></span><br><span class="line">    z = (data[i] - data[i].mean()) / data[i].std()  <span class="comment"># 用均值函数和标准差函数将每列数据进行Z-score标准化</span></span><br><span class="line">    a[i] = <span class="built_in">abs</span>(z) &gt; <span class="number">2</span>  <span class="comment"># 如果标准化后的数值大于标准正态分布的标准差1的2倍，那么数值为异常值，返回True，否则返回False</span></span><br></pre></td></tr></table></figure>

<p>Z-score标准化：<br><img src="%E4%B8%8B%E8%BD%BD%20(2).png" alt="下载 (2)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a  <span class="comment"># 打印来看，每一列都有一个异常值</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>c1</th>
      <th>c2</th>
      <th>c3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>5</th>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>6</th>
      <td>True</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>



<p><img src="%E4%B8%8B%E8%BD%BD%20(3).png" alt="下载 (3)"><br>检测到异常后，如果异常值较少或影响不大，也可以不处理。如果需要处理，可以采用如下几种常见的方式：</p>
<p>删除含有异常值的记录</p>
<p>将异常值视为缺失值，利用11.2.2小节介绍的方法进行处理</p>
<p>利用11.4节讲解的数据分箱的方法进行处理</p>
<h2 id="11-3-数据标准化"><a href="#11-3-数据标准化" class="headerlink" title="11.3 数据标准化"></a>11.3 数据标准化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">X = pd.DataFrame(&#123;<span class="string">&#x27;酒精含量(%)&#x27;</span>: [<span class="number">50</span>, <span class="number">60</span>, <span class="number">40</span>, <span class="number">80</span>, <span class="number">90</span>], <span class="string">&#x27;苹果酸含量(%)&#x27;</span>: [<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>]&#125;)</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">X  <span class="comment"># 查看X</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>酒精含量(%)</th>
      <th>苹果酸含量(%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>50</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>60</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>40</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>80</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>90</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="11-3-1-min-max标准化"><a href="#11-3-1-min-max标准化" class="headerlink" title="11.3.1 min-max标准化"></a>11.3.1 min-max标准化</h3><p>min-max标准化也称为离差标准化，它利用原始数据的最大值和最小值把原始数据转换到[0,1]区间内，转换公式如下：<br><img src="%E4%B8%8B%E8%BD%BD%20(4).png" alt="下载 (4)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">X_new = MinMaxScaler().fit_transform(X)  <span class="comment"># 用fit_transform()函数对原始数据进行min-max标准化</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X_new)  <span class="comment"># 查看X_new</span></span><br></pre></td></tr></table></figure>

<pre><code>[[0.2 0.5]
 [0.4 0. ]
 [0.  0. ]
 [0.8 1. ]
 [1.  0.5]]
</code></pre>
<p>第1列为“酒精含量”标准化后的值，第二列为“苹果酸含量”标准化后的值，可以看到它们都在[0,1]区间内。在实际应用中，通常将所有数据都归一化后，再进行训练集和测试集划分，演示代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<h3 id="11-3-2-Z-score标准化"><a href="#11-3-2-Z-score标准化" class="headerlink" title="11.3.2 Z-score标准化"></a>11.3.2 Z-score标准化</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(5).png" alt="下载 (5)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">X_new = StandardScaler().fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(X_new)  <span class="comment"># 查看X_new</span></span><br></pre></td></tr></table></figure>

<pre><code>[[-0.75482941  0.26726124]
 [-0.21566555 -1.06904497]
 [-1.29399328 -1.06904497]
 [ 0.86266219  1.60356745]
 [ 1.40182605  0.26726124]]
</code></pre>
<p><img src="%E4%B8%8B%E8%BD%BD%20(6).png" alt="下载 (6)"></p>
<h2 id="11-4-数据分箱"><a href="#11-4-数据分箱" class="headerlink" title="11.4 数据分箱"></a>11.4 数据分箱</h2><p>各种贷款业务机构普遍使用信用评分对客户进行评估，相应的模型称为信用评分卡模型。在构建信用评分卡模型的过程中，需要利用WOE值和IV值进行特征筛选，而计算这两个值的第一步就是要进行数据分箱，所以本节先来学习如何对连续型变量进行分箱处理</p>
<p>数据分箱就是将一个连续型变量离散化，可分为<strong>等宽分箱</strong>和<strong>等深分箱</strong>。<strong>等宽分箱是指每个分箱的差值相等</strong>。例如年龄这一个连续型变量，其取值范围为0~100的连续数值，可以将“年龄”分为0-20、20-40、40-60、60-80、80-100共五个分箱，这五个分箱就可以当成离散的分类样本，每个分箱的年龄差相等都相差20岁。<strong>等深分箱是指每个分箱中的样本数一致</strong>，同样按年龄这一个特征变量进行分箱，例如500个样本分成5箱，那么每个分箱中都是100人，此时对应的5个分箱可能就是0-20、20-25、25-30、30-50、50-100，确保每个分箱中的人数一致。</p>
<p>实战中用等宽分箱较多</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.DataFrame([[<span class="number">22</span>,<span class="number">1</span>],[<span class="number">25</span>,<span class="number">1</span>],[<span class="number">20</span>,<span class="number">0</span>],[<span class="number">35</span>,<span class="number">0</span>],[<span class="number">32</span>,<span class="number">1</span>],[<span class="number">38</span>,<span class="number">0</span>],[<span class="number">50</span>,<span class="number">0</span>],[<span class="number">46</span>,<span class="number">1</span>]], columns=[<span class="string">&#x27;年龄&#x27;</span>, <span class="string">&#x27;是否违约&#x27;</span>])</span><br><span class="line">data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>年龄</th>
      <th>是否违约</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>22</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>25</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>35</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>38</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>46</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码即可进行等宽数据分箱：</span></span><br><span class="line">data_cut = pd.cut(data[<span class="string">&#x27;年龄&#x27;</span>], <span class="number">3</span>) <span class="comment"># 第一个参数是待分箱的列，第二个参数是分箱个数</span></span><br><span class="line"><span class="built_in">print</span>(data_cut)</span><br></pre></td></tr></table></figure>

<pre><code>0    (19.97, 30.0]
1    (19.97, 30.0]
2    (19.97, 30.0]
3     (30.0, 40.0]
4     (30.0, 40.0]
5     (30.0, 40.0]
6     (40.0, 50.0]
7     (40.0, 50.0]
Name: 年龄, dtype: category
Categories (3, interval[float64]): [(19.97, 30.0] &lt; (30.0, 40.0] &lt; (40.0, 50.0]]
</code></pre>
<p>年龄列中数据范围是20-50岁，分为三组恰好为20-30岁，30-40岁，40-50岁，即等宽分箱</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过groupby()函数进行分组，count()函数（详见14.3节补充知识点）进行计数可以获取每个分箱中的样本数目，代码如下：</span></span><br><span class="line">data[<span class="string">&#x27;年龄&#x27;</span>].groupby(data_cut).count()</span><br></pre></td></tr></table></figure>




<pre><code>年龄
(19.97, 30.0]    3
(30.0, 40.0]     3
(40.0, 50.0]     2
Name: 年龄, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 补充知识点，分箱并进行编号</span></span><br><span class="line"><span class="built_in">print</span>(pd.cut(data[<span class="string">&#x27;年龄&#x27;</span>], <span class="number">3</span>, labels=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0    1
1    1
2    1
3    2
4    2
5    2
6    3
7    3
Name: 年龄, dtype: category
Categories (3, int64): [1 &lt; 2 &lt; 3]
</code></pre>
<h2 id="11-5-特征筛选：WOE值与IV值——根据该指标大小进行特征变量的筛选"><a href="#11-5-特征筛选：WOE值与IV值——根据该指标大小进行特征变量的筛选" class="headerlink" title="11.5 特征筛选：WOE值与IV值——根据该指标大小进行特征变量的筛选"></a>11.5 特征筛选：WOE值与IV值——根据该指标大小进行特征变量的筛选</h2><p>在使用逻辑回归、决策树等模型算法构建分类模型的时候，经常需要对<strong>特征变量</strong>进行筛选。因为有时可能会获得100多个候选特征变量，通常不会直接把这些特征变量放到模型中去进行拟合训练，而是从这些特征变量中<strong>挑选一些</strong>放进模型，构成<strong>入模变量列表</strong>。那么该如何挑选入模变量模型呢？</p>
<p>挑选入模变量模型需要考虑很多因素，如变量的预测能力、简单性（容易生成和使用）、可解释性等。其中最主要的衡量标准就是<strong>变量的预测能力</strong>，对分类模型来说，即希望变量具有较好的<strong>特征区分度</strong>，可以较准确地将样本进行分类</p>
<p><strong>WOE和IV值</strong>就是这样的指标，它们可以用来衡量特征变量的<strong>预测能力</strong>，或者说特征变量的特征区分度，类似的指标还有5.1.2小节中提到的基尼系数和信息增益。对于决策树等树模型来说，可以通过基尼系数或信息增益来衡量变量的特征区分度，而对逻辑回归等没有基尼系数等指标的模型而言，可以通过WOE值和IV值进行变量选择。IV值的计算是以WOE值为基础的，而要计算一个变量的WOE值，需要先用上一节所讲的知识对这个变量进行分箱处理。</p>
<h3 id="11-5-1-WOE值的定义与计算"><a href="#11-5-1-WOE值的定义与计算" class="headerlink" title="11.5.1 WOE值的定义与计算"></a>11.5.1 WOE值的定义与计算</h3><p><strong>1.WOE值的定义</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(7).png" alt="下载 (7)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(8).png" alt="下载 (8)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(9).png" alt="下载 (9)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(10).png" alt="下载 (10)"></p>
<p>实际应用中，因为数据量通常较大，所以不太可能出现WOE值为+∞或-∞的情况，如果出现了无穷大的WOE值，也是我们不希望看到的，这样会导致基于WOE值的IV值也变成无穷大，不利于进行特征筛选。此时的处理方法有两种：第一种方法是对数据重新进行更合理的分箱，使各个分箱的WOE值不再无穷大；第二种方法是忽略这些无穷大的值，直接让它变为0，这一思路比较简单且易于实现，在11.5.3节会有应用</p>
<p><strong>2.WOE值的计算过程演示</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(11).png" alt="下载 (11)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(12).png" alt="下载 (12)"></p>
<h3 id="11-5-2-IV值的定义与计算"><a href="#11-5-2-IV值的定义与计算" class="headerlink" title="11.5.2 IV值的定义与计算"></a>11.5.2 IV值的定义与计算</h3><p>在实战应用中，通过IV值可以评判特征变量的<strong>预测能力</strong>，从而进行特征筛选</p>
<p><strong>1.IV值的定义</strong></p>
<p>IV值是Information Value（信息量）的缩写。在进行特征筛选时，IV值能较好地反映特征变量的预测能力，特征变量对预测结果的贡献越大，其价值就越大，对应的IV值就越大，因此，我们可以根据IV值的大小筛选出需要的特征变量</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(13).png" alt="下载 (13)"></p>
<p><strong>2.IV值的计算过程演示</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(14).png" alt="下载 (14)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(15).png" alt="下载 (15)"></p>
<p>汇总所有数据，可以得到下表：<br><img src="%E4%B8%8B%E8%BD%BD%20(16).png"></p>
<p>通过这种方式对样本数据的每个特征变量进行IV值计算并排序后，就可以获得特征变量的决策树能力强弱信息</p>
<p>一个特征变量的<strong>IV值越高</strong>，说明该特征变量越具有<strong>区分度</strong>。不过IV值也不是越大越好，如果一个特征变量的IV值大于0.5，有时需要对这个特征变量持有疑问，因为它有点过好而显得不够真实。通常会选择IV值在0.1~0.5这个范围内的特征范围。不同应用场景的取值也会有所不同，例如，有些风控团队会将IV值大于0.5的特征变量也纳入考量，这个其实也需要根据实际的建模效果来做进一步判断</p>
<p><strong>补充：使用IV值而不直接使用WOE值的原因</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(17).png" alt="下载 (17)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(18).png" alt="下载 (18)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(19).png" alt="下载 (19)"></p>
<h3 id="11-5-3-WOE值与IV值的代码实现"><a href="#11-5-3-WOE值与IV值的代码实现" class="headerlink" title="11.5.3 WOE值与IV值的代码实现"></a>11.5.3 WOE值与IV值的代码实现</h3><p>1.数据分箱</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先通过如下代码构造数据：</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.DataFrame([[<span class="number">22</span>,<span class="number">1</span>],[<span class="number">25</span>,<span class="number">1</span>],[<span class="number">20</span>,<span class="number">0</span>],[<span class="number">35</span>,<span class="number">0</span>],[<span class="number">32</span>,<span class="number">1</span>],[<span class="number">38</span>,<span class="number">0</span>],[<span class="number">50</span>,<span class="number">0</span>],[<span class="number">46</span>,<span class="number">1</span>]], columns=[<span class="string">&#x27;年龄&#x27;</span>, <span class="string">&#x27;是否违约&#x27;</span>])</span><br><span class="line">data</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>年龄</th>
      <th>是否违约</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>22</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>25</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>35</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>38</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>46</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有了数据之后，根据“年龄”这一特征变量进行数据分箱，代码如下：</span></span><br><span class="line">data_cut = pd.cut(data[<span class="string">&#x27;年龄&#x27;</span>], <span class="number">3</span>)</span><br><span class="line">data_cut</span><br></pre></td></tr></table></figure>




<pre><code>0    (19.97, 30.0]
1    (19.97, 30.0]
2    (19.97, 30.0]
3     (30.0, 40.0]
4     (30.0, 40.0]
5     (30.0, 40.0]
6     (40.0, 50.0]
7     (40.0, 50.0]
Name: 年龄, dtype: category
Categories (3, interval[float64]): [(19.97, 30.0] &lt; (30.0, 40.0] &lt; (40.0, 50.0]]
</code></pre>
<p>2.统计各个分箱样本总数、坏样本数和好样本数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计总客户数</span></span><br><span class="line">cut_group_all = data[<span class="string">&#x27;是否违约&#x27;</span>].groupby(data_cut).count() <span class="comment"># 用groupby()函数根据分箱内容进行分类，用count()函数进行计数，可以获得各个分箱中的总客户数</span></span><br><span class="line"><span class="comment"># 统计违约客户</span></span><br><span class="line">cut_y = data[<span class="string">&#x27;是否违约&#x27;</span>].groupby(data_cut).<span class="built_in">sum</span>() <span class="comment"># 用groupby()函数根据分箱内容进行归类，用sum()函数进行求和，因为违约客户的数字是1，未违约客户数字标识为0，所以sum()函数求和结果为违约客户数</span></span><br><span class="line"><span class="comment"># 统计未违约客户</span></span><br><span class="line">cut_n = cut_group_all - cut_y <span class="comment"># 总客户数减去违约客户数得到未违约客户数</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里展示下cut_group_all的结果，如下所示：</span></span><br><span class="line">cut_group_all</span><br></pre></td></tr></table></figure>




<pre><code>年龄
(19.97, 30.0]    3
(30.0, 40.0]     3
(40.0, 50.0]     2
Name: 是否违约, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过2.2.1节相关知识点将cut_group_all、cut_y、cut_n进行汇总，代码如下，这里我们将违约客户命名为“坏样本”，非违约客户命名为“好样本”。</span></span><br><span class="line">df = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame用来汇总数据</span></span><br><span class="line">df[<span class="string">&#x27;总数&#x27;</span>] = cut_group_all</span><br><span class="line">df[<span class="string">&#x27;坏样本&#x27;</span>] = cut_y</span><br><span class="line">df[<span class="string">&#x27;好样本&#x27;</span>] = cut_n</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>总数</th>
      <th>坏样本</th>
      <th>好样本</th>
    </tr>
    <tr>
      <th>年龄</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(19.97, 30.0]</th>
      <td>3</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>(30.0, 40.0]</th>
      <td>3</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>(40.0, 50.0]</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>3.统计各分箱中坏样本比率和好样本比率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算坏样本%和好样本%</span></span><br><span class="line">df[<span class="string">&#x27;坏样本%&#x27;</span>] = df[<span class="string">&#x27;坏样本&#x27;</span>] / df[<span class="string">&#x27;坏样本&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">df[<span class="string">&#x27;好样本%&#x27;</span>] = df[<span class="string">&#x27;好样本&#x27;</span>] / df[<span class="string">&#x27;好样本&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>总数</th>
      <th>坏样本</th>
      <th>好样本</th>
      <th>坏样本%</th>
      <th>好样本%</th>
    </tr>
    <tr>
      <th>年龄</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(19.97, 30.0]</th>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>0.50</td>
      <td>0.25</td>
    </tr>
    <tr>
      <th>(30.0, 40.0]</th>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>0.25</td>
      <td>0.50</td>
    </tr>
    <tr>
      <th>(40.0, 50.0]</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0.25</td>
      <td>0.25</td>
    </tr>
  </tbody>
</table>
</div>



<p>4.计算WOE值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df[<span class="string">&#x27;WOE&#x27;</span>] = np.log(df[<span class="string">&#x27;坏样本%&#x27;</span>] / df[<span class="string">&#x27;好样本%&#x27;</span>])  <span class="comment"># 使用对数函数np.log()</span></span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>总数</th>
      <th>坏样本</th>
      <th>好样本</th>
      <th>坏样本%</th>
      <th>好样本%</th>
      <th>WOE</th>
    </tr>
    <tr>
      <th>年龄</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(19.97, 30.0]</th>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.693147</td>
    </tr>
    <tr>
      <th>(30.0, 40.0]</th>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>-0.693147</td>
    </tr>
    <tr>
      <th>(40.0, 50.0]</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>



<p>此外，我们在11.5.1节第一部分也讲过，在实际应用中，我们不希望WOE值出现无穷大（这样会导致之后计算的IV值也变为无穷大，丧失了IV值的意义），但是有的时候可能由于数据特殊性及分箱的原因，它还是出现了WOE值为无穷大的情况（某个分箱中只含有一种类别的数据），此时解决办法是当WOE值为无穷大时，将它替换为0，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.replace(&#123;<span class="string">&#x27;WOE&#x27;</span>: &#123;np.inf: <span class="number">0</span>, -np.inf: <span class="number">0</span>&#125;&#125;)</span><br></pre></td></tr></table></figure>

<p>这行代码用pandas库中replace()函数将无穷大替换为0，其中np.inf是利用Numpy库构造的正无穷，-np.inf则是负无穷</p>
<p>5.计算IV值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;IV&#x27;</span>] = df[<span class="string">&#x27;WOE&#x27;</span>] * (df[<span class="string">&#x27;坏样本%&#x27;</span>] - df[<span class="string">&#x27;好样本%&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>总数</th>
      <th>坏样本</th>
      <th>好样本</th>
      <th>坏样本%</th>
      <th>好样本%</th>
      <th>WOE</th>
      <th>IV</th>
    </tr>
    <tr>
      <th>年龄</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>(19.97, 30.0]</th>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>0.50</td>
      <td>0.25</td>
      <td>0.693147</td>
      <td>0.173287</td>
    </tr>
    <tr>
      <th>(30.0, 40.0]</th>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>0.25</td>
      <td>0.50</td>
      <td>-0.693147</td>
      <td>0.173287</td>
    </tr>
    <tr>
      <th>(40.0, 50.0]</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>0.25</td>
      <td>0.25</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iv = df[<span class="string">&#x27;IV&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(iv)</span><br></pre></td></tr></table></figure>

<pre><code>0.34657359027997264
</code></pre>
<p>整理上面计算WOE值和IV值的内容，完整代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.构造数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.DataFrame([[<span class="number">22</span>,<span class="number">1</span>],[<span class="number">25</span>,<span class="number">1</span>],[<span class="number">20</span>,<span class="number">0</span>],[<span class="number">35</span>,<span class="number">0</span>],[<span class="number">32</span>,<span class="number">1</span>],[<span class="number">38</span>,<span class="number">0</span>],[<span class="number">50</span>,<span class="number">0</span>],[<span class="number">46</span>,<span class="number">1</span>]], columns=[<span class="string">&#x27;年龄&#x27;</span>, <span class="string">&#x27;是否违约&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.数据分箱</span></span><br><span class="line">data_cut = pd.cut(data[<span class="string">&#x27;年龄&#x27;</span>], <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.统计各个分箱样本总数、坏样本数和好样本数并汇总数据</span></span><br><span class="line"><span class="comment"># 统计总客户数</span></span><br><span class="line">cut_group_all = data[<span class="string">&#x27;是否违约&#x27;</span>].groupby(data_cut).count()</span><br><span class="line"><span class="comment"># 统计违约客户</span></span><br><span class="line">cut_y = data[<span class="string">&#x27;是否违约&#x27;</span>].groupby(data_cut).<span class="built_in">sum</span>()</span><br><span class="line"><span class="comment"># 统计未违约客户</span></span><br><span class="line">cut_n = cut_group_all - cut_y</span><br><span class="line"><span class="comment"># 汇总基础数据</span></span><br><span class="line">df = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame用来汇总数据</span></span><br><span class="line">df[<span class="string">&#x27;总数&#x27;</span>] = cut_group_all</span><br><span class="line">df[<span class="string">&#x27;坏样本&#x27;</span>] = cut_y</span><br><span class="line">df[<span class="string">&#x27;好样本&#x27;</span>] = cut_n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.统计坏样本%和好样本%</span></span><br><span class="line">df[<span class="string">&#x27;坏样本%&#x27;</span>] = df[<span class="string">&#x27;坏样本&#x27;</span>] / df[<span class="string">&#x27;坏样本&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">df[<span class="string">&#x27;好样本%&#x27;</span>] = df[<span class="string">&#x27;好样本&#x27;</span>] / df[<span class="string">&#x27;好样本&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.计算WOE值</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df[<span class="string">&#x27;WOE&#x27;</span>] = np.log(df[<span class="string">&#x27;坏样本%&#x27;</span>] / df[<span class="string">&#x27;好样本%&#x27;</span>])</span><br><span class="line">df = df.replace(&#123;<span class="string">&#x27;WOE&#x27;</span>: &#123;np.inf: <span class="number">0</span>, -np.inf: <span class="number">0</span>&#125;&#125;)  <span class="comment"># 替换可能存在的无穷大</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.计算各个分箱的IV值</span></span><br><span class="line">df[<span class="string">&#x27;IV&#x27;</span>] = df[<span class="string">&#x27;WOE&#x27;</span>] * (df[<span class="string">&#x27;坏样本%&#x27;</span>] - df[<span class="string">&#x27;好样本%&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7.汇总各个分箱的IV值，获得特征变量的IV值</span></span><br><span class="line">iv = df[<span class="string">&#x27;IV&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(iv)</span><br></pre></td></tr></table></figure>

<pre><code>0.34657359027997264
</code></pre>
<p>在实际应用中，通过类似上面的代码计算出各个特征变量的IV值，然后根据IV值从高到低排序，即可筛选出需要的特征变量</p>
<h3 id="11-5-4-案例实战：客户流失预警模型的IV值计算"><a href="#11-5-4-案例实战：客户流失预警模型的IV值计算" class="headerlink" title="11.5.4 案例实战：客户流失预警模型的IV值计算"></a>11.5.4 案例实战：客户流失预警模型的IV值计算</h3><p>4.2节中讲解了一个客户流失预警模型，下面就以它作为案例来计算各个特征变量的IV值，并筛选出合适的特征变量</p>
<p>为了提高代码的通用性，这里将上一节的代码稍加修改，写成如下的自定义函数形式。该函数一共有4个参数：data(原始数据)、cut_num（数据分箱步骤中的分箱的个数）、feature（需要计算IV值的特征变量名称）、target（目标变量名称）。有了这个函数，就能方便地对任意一个数据集计算各个特征变量的IV值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将上面的内容首先定义为一个函数</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_iv</span>(<span class="params">data, cut_num, feature, target</span>):</span><br><span class="line">    <span class="comment"># 1.数据分箱</span></span><br><span class="line">    data_cut = pd.cut(data[feature], cut_num)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.统计各个分箱样本总数、坏样本数和好样本数</span></span><br><span class="line">    cut_group_all = data[target].groupby(data_cut).count()  <span class="comment"># 总客户数</span></span><br><span class="line">    cut_y = data[target].groupby(data_cut).<span class="built_in">sum</span>()  <span class="comment"># 坏样本数</span></span><br><span class="line">    cut_n = cut_group_all - cut_y  <span class="comment"># 好样本数</span></span><br><span class="line">    <span class="comment"># 汇总基础数据</span></span><br><span class="line">    df = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame用来汇总数据</span></span><br><span class="line">    df[<span class="string">&#x27;总数&#x27;</span>] = cut_group_all</span><br><span class="line">    df[<span class="string">&#x27;坏样本&#x27;</span>] = cut_y</span><br><span class="line">    df[<span class="string">&#x27;好样本&#x27;</span>] = cut_n</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.统计坏样本%和好样本%</span></span><br><span class="line">    df[<span class="string">&#x27;坏样本%&#x27;</span>] = df[<span class="string">&#x27;坏样本&#x27;</span>] / df[<span class="string">&#x27;坏样本&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">    df[<span class="string">&#x27;好样本%&#x27;</span>] = df[<span class="string">&#x27;好样本&#x27;</span>] / df[<span class="string">&#x27;好样本&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.计算WOE值</span></span><br><span class="line">    df[<span class="string">&#x27;WOE&#x27;</span>] = np.log(df[<span class="string">&#x27;坏样本%&#x27;</span>] / df[<span class="string">&#x27;好样本%&#x27;</span>])</span><br><span class="line">    df = df.replace(&#123;<span class="string">&#x27;WOE&#x27;</span>: &#123;np.inf: <span class="number">0</span>, -np.inf: <span class="number">0</span>&#125;&#125;) </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5.计算各个分箱的IV值</span></span><br><span class="line">    df[<span class="string">&#x27;IV&#x27;</span>] = df[<span class="string">&#x27;WOE&#x27;</span>] * (df[<span class="string">&#x27;坏样本%&#x27;</span>] - df[<span class="string">&#x27;好样本%&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6.汇总各个分箱的IV值，获得特征变量的IV值</span></span><br><span class="line">    iv = df[<span class="string">&#x27;IV&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(iv)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有了上面的自动计算IV值的函数后，通过如下代码来读取客户流失预警模型中的相关数据：</span></span><br><span class="line">data = pd.read_excel(<span class="string">&#x27;股票客户流失.xlsx&#x27;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>账户资金（元）</th>
      <th>最后一次交易距今时间（天）</th>
      <th>上月交易佣金（元）</th>
      <th>本券商使用时长（年）</th>
      <th>是否流失</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>22686.5</td>
      <td>297</td>
      <td>149.25</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>190055.0</td>
      <td>42</td>
      <td>284.75</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>29733.5</td>
      <td>233</td>
      <td>269.25</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>185667.5</td>
      <td>44</td>
      <td>211.50</td>
      <td>3</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>33648.5</td>
      <td>213</td>
      <td>353.50</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们利用刚刚编好的函数进行第一个特征变量“账户资金（元）”的IV值计算，代码如下：</span></span><br><span class="line">cal_iv(data, <span class="number">4</span>, <span class="string">&#x27;账户资金（元）&#x27;</span>, <span class="string">&#x27;是否流失&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>0.15205722409339645
</code></pre>
<p>其中，第一个参数data就是刚刚读取的股票客户流失数据；设置第二个参数cut_num为4，即将数据分为4个箱；设置第三个参数feature为’账户资金（元）’，即要计算IV值的特征变量；设置第四个参数target为‘是否流失’，即原始表格中的目标变量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> data.columns[:-<span class="number">1</span>]:</span><br><span class="line">    <span class="built_in">print</span>(i + <span class="string">&#x27;的IV值为：&#x27;</span>)</span><br><span class="line">    cal_iv(data, <span class="number">4</span>, i, <span class="string">&#x27;是否流失&#x27;</span>)  <span class="comment"># 调用函数</span></span><br></pre></td></tr></table></figure>

<pre><code>账户资金（元）的IV值为：
0.15205722409339645
最后一次交易距今时间（天）的IV值为：
0.2508468300174099
上月交易佣金（元）的IV值为：
0.30811632146662304
本券商使用时长（年）的IV值为：
0.6144219248359752
</code></pre>
<p>将上述IV值从高到低排序，结果为：本券商使用时长（年）&gt;上月交易佣金（元）&gt;最后一次交易距今时间（天）&gt;账户资金（元）。可以得出结论：“本券商使用时长（年）”的信息量最大，而“账户资金（元）”的信息量最小，预测能力最低。这其实也是搭建逻辑回归模型时判断特征重要性的一个方式</p>
<h2 id="11-6-多重共线性的分析与处理"><a href="#11-6-多重共线性的分析与处理" class="headerlink" title="11.6 多重共线性的分析与处理"></a>11.6 多重共线性的分析与处理</h2><h3 id="11-6-1-多重共线性的定义"><a href="#11-6-1-多重共线性的定义" class="headerlink" title="11.6.1 多重共线性的定义"></a>11.6.1 多重共线性的定义</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(20).png" alt="下载 (20)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(21).png" alt="下载 (21)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(22).png" alt="下载 (22)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(23).png" alt="下载 (23)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(24).png" alt="下载 (24)"></p>
<h3 id="11-6-2-多重共线性的分析与检验"><a href="#11-6-2-多重共线性的分析与检验" class="headerlink" title="11.6.2 多重共线性的分析与检验"></a>11.6.2 多重共线性的分析与检验</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用Pandas库读入一组存在多重共线性的数据，并对其回归作为示例：</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;数据.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8</td>
      <td>16</td>
      <td>-32</td>
      <td>77</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7</td>
      <td>14</td>
      <td>-31</td>
      <td>52</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>9</td>
      <td>-12</td>
      <td>42</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>2</td>
      <td>5</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2</td>
      <td>8</td>
      <td>19</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以发现X2列中绝大部分数据是X1列中数据的2倍</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对数据集划分特征变量和目标变量：</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">Y = df[<span class="string">&#x27;Y&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>下面我们需要做的就是分析与检验这三个特征变量是否存在多重共线性，这里主要讲解两种判别方法：相关系数判断以及方差膨胀因子法（VIF检验）来检验多重共线性。</p>
<p><strong>1.相关系数判断</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.corr()  <span class="comment"># corr()函数可以快速计算不同变量间的相关系数</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>X1</th>
      <td>1.000000</td>
      <td>0.992956</td>
      <td>-0.422788</td>
    </tr>
    <tr>
      <th>X2</th>
      <td>0.992956</td>
      <td>1.000000</td>
      <td>-0.410412</td>
    </tr>
    <tr>
      <th>X3</th>
      <td>-0.422788</td>
      <td>-0.410412</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



<p><img src="%E4%B8%8B%E8%BD%BD%20(25).png"></p>
<p>这里用到的相关系数其实是皮尔逊相关系数</p>
<p>相关系数的判断使用起来非常简单，结论也比较清洗，不过它有一个缺点：简单相关系数只是多重共线性的充分条件，不是必要条件。在有多个特征变量时，相关系数较小的特征变量间也可能存在较严重的多重共线性。为了更加严谨，实战中还经常用到方差膨胀系数（VIF检验）</p>
<p><strong>2.方差膨胀因子法（VIF检验）</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(26).png" alt="下载 (26)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(27).png" alt="下载 (27)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了检验上述回归中是否存在严重的多重共线性，我们使用Python的VIF检验模块来验证：</span></span><br><span class="line"><span class="keyword">from</span> statsmodels.stats.outliers_influence <span class="keyword">import</span> variance_inflation_factor</span><br><span class="line">vif = [variance_inflation_factor(X.values, X.columns.get_loc(i)) <span class="keyword">for</span> i <span class="keyword">in</span> X.columns]</span><br></pre></td></tr></table></figure>

<p>第一行代码从statsmodels模块引入variance_inflation_factor()函数；第二行代码通过for循环循环依次求得每个特征变量的方差膨胀系数并将结果放入列表中，该行可以看成求VIF值的固定写法，其中X.columns.get_loc(i)返回的是指定列的序号数字，如第一列返回的就是数字0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vif</span><br></pre></td></tr></table></figure>




<pre><code>[259.6430487184967, 257.6315718292196, 1.302330632715429]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果对上面的快捷写法不太理解，上面的代码也可以写成：</span></span><br><span class="line">vif = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> X.columns:  <span class="comment"># i对应的是每一列的列名</span></span><br><span class="line">    vif.append(variance_inflation_factor(X.values, X.columns.get_loc(i)))</span><br><span class="line">    </span><br><span class="line">vif</span><br></pre></td></tr></table></figure>




<pre><code>[259.6430487184967, 257.6315718292196, 1.302330632715429]
</code></pre>
<p>因为特征变量X2是X1的2倍,所以使用X1对X2和X3回归和使用X2对X1和X3回归时所得的方差膨胀系数会很大，从上述计算结果也可以看出，前2个VIF值均大于100，暗示多重共线性十分严重，应该删掉X1或X2</p>
<p>下面删掉X2再进行一次回归和VIF检验，看看结果变化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对数据集重新划分特征变量和目标变量：</span></span><br><span class="line">X = df[[<span class="string">&#x27;X1&#x27;</span>, <span class="string">&#x27;X3&#x27;</span>]]</span><br><span class="line">Y = df[<span class="string">&#x27;Y&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进行检验VIF检验：</span></span><br><span class="line"><span class="keyword">from</span> statsmodels.stats.outliers_influence <span class="keyword">import</span> variance_inflation_factor</span><br><span class="line">vif = [variance_inflation_factor(X.values, X.columns.get_loc(i)) <span class="keyword">for</span> i <span class="keyword">in</span> X.columns]</span><br><span class="line"></span><br><span class="line">vif</span><br></pre></td></tr></table></figure>




<pre><code>[1.289349054516766, 1.2893490545167656]
</code></pre>
<p>可以看到，此时两个特征变量的方差膨胀系数都小于10，说明它们之间不存在多重共线性</p>
<p><strong>总结来说，对于线性回归模型和逻辑回归模型等以线性方程表达式为基础的机器学习模型，需要注意多重共线性的影响。如果存在多重共线性，则需要进行响应处理，如删去某个引起多重共线性的特征变量</strong></p>
<h2 id="11-7-过采样和欠采样"><a href="#11-7-过采样和欠采样" class="headerlink" title="11.7 过采样和欠采样"></a>11.7 过采样和欠采样</h2><p>建立模型时，可能会遇到正负样本比例极度不均衡的情况。例如，建立信用违约模型时，违约样本的比例远小于不违约样本的比例，此时模型会花更多的精力去拟合不违约的样本，但实际上找出违约样本更为重要。这会导致模型可能在训练集上表现良好，但测试时表现不佳。为了改善样本比例不均衡的问题，可以使用过采样和欠采样的方法。假设建立信用违约模型时，样本数据中有1000个不违约样本和100个违约样本</p>
<h3 id="11-7-1-过采样"><a href="#11-7-1-过采样" class="headerlink" title="11.7.1 过采样"></a>11.7.1 过采样</h3><p><strong>1.过采样的原理</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(28).png" alt="下载 (28)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(29).png" alt="下载 (29)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(30).png" alt="下载 (30)"></p>
<p><strong>2.过采样的代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_excel(<span class="string">&quot;信用卡数据.xlsx&quot;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>编号</th>
      <th>年龄</th>
      <th>负债比率</th>
      <th>月收入</th>
      <th>贷款数量</th>
      <th>家属人数</th>
      <th>分类</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>29</td>
      <td>0.22</td>
      <td>7800</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>52</td>
      <td>0.46</td>
      <td>4650</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>28</td>
      <td>0.10</td>
      <td>3000</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>29</td>
      <td>0.20</td>
      <td>5916</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>27</td>
      <td>1.28</td>
      <td>1300</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>分类指的是是否违约，1代表违约，0代表不违约</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码提取特征变量并将其赋值给变量X，提取目标变量并将其赋值给变量y：。</span></span><br><span class="line">X = data.drop(columns=<span class="string">&#x27;分类&#x27;</span>)</span><br><span class="line">y = data[<span class="string">&#x27;分类&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 然后使用collections库中的Counter()方法，对目标变量进行计数：</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">Counter(y)</span><br></pre></td></tr></table></figure>




<pre><code>Counter(&#123;0: 1000, 1: 100&#125;)
</code></pre>
<p>不违约的样本数有1000个，远远大于违约的样本数100。为了防止建立信用违约模型时，模型着重拟合不违约的样本，而无法找出违约的样本，我们采用过采样的方法来改善样本比例不均衡的问题，这里我们将通过上面讲到的随机过采样和SMOTE法过采样来进行代码实现。</p>
<p>（1）随机过采样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> RandomOverSampler</span><br><span class="line">ros = RandomOverSampler(random_state=<span class="number">0</span>)</span><br><span class="line">X_oversampled, y_oversampled = ros.fit_resample(X, y)</span><br></pre></td></tr></table></figure>

<p>第一行代码从imblearn库中引入用来进行随机过采样的RandomOverSampler()函数，第二行代码设置函数参数random_state为0（此数字没有特殊含义，可以换成其他数字），使得每次代码运行的结果保持一致，第三行代码使用原始数据的特征变量和目标变量生成过采样数据集，并分别赋给变量X_oversampled和y_oversampled</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用Counter()方法检验一下SMOTE过采样的效果。</span></span><br><span class="line">Counter(y_oversampled)</span><br></pre></td></tr></table></figure>




<pre><code>Counter(&#123;0: 1000, 1: 1000&#125;)
</code></pre>
<p>违约的样本数从100上升至不违约的样本数1000，这证明我们的随机过采样有效。同时我们可以打印特征变量X_oversampled的shape来看看特征变量的变化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_oversampled.shape</span><br></pre></td></tr></table></figure>




<pre><code>(2000, 6)
</code></pre>
<p>这里的2000就是1000个违约样本和1000个不违约样本相加得到的，可以看到，随机过采样后特征变量的数据也随之增多。</p>
<p>（2）SMOTE过采样</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码即可进行SMOTE过采样：</span></span><br><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line">smote = SMOTE(random_state=<span class="number">0</span>)</span><br><span class="line">X_smotesampled, y_smotesampled = smote.fit_resample(X, y)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用Counter()方法检验一下SMOTE过采样的效果。</span></span><br><span class="line">Counter(y_smotesampled)</span><br></pre></td></tr></table></figure>




<pre><code>Counter(&#123;0: 1000, 1: 1000&#125;)
</code></pre>
<h3 id="11-7-2-欠采样"><a href="#11-7-2-欠采样" class="headerlink" title="11.7.2 欠采样"></a>11.7.2 欠采样</h3><p><strong>1.欠采样的原理</strong></p>
<p>欠采样是从1000个不违约样本中随机选取100个样本，和100个违约样本一起构成新的训练集。欠采样抛弃了大部分不违约样本，在搭建模型时有可能产生欠拟合。</p>
<p><strong>2.欠采样的代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 仍然采用上方的信用违约数据进行欠采样代码的展示：</span></span><br><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> RandomUnderSampler</span><br><span class="line">rus = RandomUnderSampler(random_state=<span class="number">0</span>)</span><br><span class="line">X_undersampled, y_undersampled = rus.fit_resample(X, y)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用Counter()方法检验一下随机欠采样的效果。</span></span><br><span class="line">Counter(y_undersampled)</span><br></pre></td></tr></table></figure>




<pre><code>Counter(&#123;0: 100, 1: 100&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不违约的样本数从1000下降至违约的样本数100，这证明我们的随机欠采样有效。同时我们可以打印特征变量X_undersampled的shape来看看特征变量的变化：</span></span><br><span class="line">X_undersampled.shape</span><br></pre></td></tr></table></figure>




<pre><code>(200, 6)
</code></pre>
<p>在实战中处理样本不均衡问题时，如果样本数据量不大，通常使用过采样，因为这样能够更好地利用数据，不会像欠采样那样狠多数据都没有使用到；如果数据量充足，则过采样和欠采样都可以考虑使用</p>
<h1 id="12-数据降维之PCA"><a href="#12-数据降维之PCA" class="headerlink" title="12 数据降维之PCA"></a>12 数据降维之PCA</h1><p>建立模型分析特征数据时，很可能会面临特征数据维度过大的问题。如收入、年龄、性别、婚姻状况、工作单位等数百个维度的特征。如果将所有特征数据都用来拟合模型，会提高模型的复杂度，造成过拟合风险显著增大，且不同的特征维数间可能存在共线性。此时就需要对数据进行降维，以浓缩特征向量。</p>
<h2 id="12-1-数据降维"><a href="#12-1-数据降维" class="headerlink" title="12.1 数据降维"></a>12.1 数据降维</h2><p>如果特征变量的数量非常多（如成百上千个特征变量），我们往往需要进行数据降维。</p>
<p>降维的方法主要有两种：<strong>选择特征</strong>和<strong>抽取特征</strong>两种：选择特征是从原有的特征中挑选出<strong>最佳的特征</strong>；抽取特征是将数据从高维向低维投影，进行坐标的线性转换。PCA（主成分分析）即典型的抽取特征的方法，它不仅是对高维数据进行降维，更重要的是经过降维<strong>去除噪声，发现数据中的模式</strong>。</p>
<h3 id="12-1-1-PCA的基本原理"><a href="#12-1-1-PCA的基本原理" class="headerlink" title="12.1.1 PCA的基本原理"></a>12.1.1 PCA的基本原理</h3><p>1.二维空间降维</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(31).png" alt="下载 (31)"></p>
<p>在实际进行数据降维前，需要先对特征数据做零均值化处理，即将每个特征维度的数据减去该特征的均值。例如，此处的二维数据（1，1）、（2，2）、（3，3），其特征X（1，2，3）和特征Y（1，2，3）的均值都是（1+2+3）&#x2F;3&#x3D;2，每个特征都减去均值后，数据被转化为（-1，-1）、（0，0）、（1，1）.再对零均值化后的数据进行线性组合，二维空间中的3个点就依次转化为数轴上的-根号2，0和根号2<br><img src="%E4%B8%8B%E8%BD%BD%20(32).png" alt="下载 (32)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(33).png" alt="下载 (33)"></p>
<p>2.n维空间降维</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(34).png" alt="下载 (34)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(35).png" alt="下载 (35)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(36).png" alt="下载 (36)"></p>
<h3 id="12-1-2-PCA的代码实现"><a href="#12-1-2-PCA的代码实现" class="headerlink" title="12.1.2 PCA的代码实现"></a>12.1.2 PCA的代码实现</h3><p><strong>1.二维空间降维的代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>]])</span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>array([[1, 1],
       [2, 2],
       [3, 3]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 也可以通过pandas库来构造数据，效果一样</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">X = pd.DataFrame([[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>]])</span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据降维，由二维降至一维</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">1</span>) <span class="comment"># 该参数为保留的成分个数，设置为1</span></span><br><span class="line">pca.fit(X)  <span class="comment"># 进行降维模型训练</span></span><br><span class="line">X_transformed = pca.transform(X)  <span class="comment"># 进行数据降维，并赋值给X_transformed</span></span><br><span class="line"></span><br><span class="line">X_transformed  <span class="comment"># 查看降维后的结果</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[-1.41421356],
       [ 0.        ],
       [ 1.41421356]])
</code></pre>
<p><strong>说明</strong>：n_components设置为1，也就是二维数据降为一维数据。该参数不仅可以设置成降维后成分的个数，还可以设置成降维后保留的信息的百分比，例如，将其设置成0.9就是在降维后保留原特征90%的信息。注意，如果将参数设置为降维后成分的个数，其值不能大于min(n_samples,n_features)，即样本数和特征变量数两者之中的最小值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看此时的维度</span></span><br><span class="line">X_transformed.shape</span><br></pre></td></tr></table></figure>




<pre><code>(3, 1)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看降维的系数</span></span><br><span class="line">pca.components_  </span><br></pre></td></tr></table></figure>




<pre><code>array([[0.70710678, 0.70710678]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看线性组合表达式</span></span><br><span class="line">a = pca.components_[<span class="number">0</span>][<span class="number">0</span>] </span><br><span class="line">b = pca.components_[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">str</span>(a) + <span class="string">&#x27; * X + &#x27;</span> +  <span class="built_in">str</span>(b) + <span class="string">&#x27; * Y&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>0.7071067811865476 * X + 0.7071067811865475 * Y
</code></pre>
<p><strong>1.三维空间降维的代码实现</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">X = pd.DataFrame([[<span class="number">45</span>, <span class="number">0.8</span>, <span class="number">9120</span>], [<span class="number">40</span>, <span class="number">0.12</span>, <span class="number">2600</span>], [<span class="number">38</span>, <span class="number">0.09</span>, <span class="number">3042</span>], [<span class="number">30</span>, <span class="number">0.04</span>, <span class="number">3300</span>], [<span class="number">39</span>, <span class="number">0.21</span>, <span class="number">3500</span>]], columns=[<span class="string">&#x27;年龄(岁)&#x27;</span>, <span class="string">&#x27;负债比率&#x27;</span>, <span class="string">&#x27;月收入(元)&#x27;</span>])</span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>年龄(岁)</th>
      <th>负债比率</th>
      <th>月收入(元)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>45</td>
      <td>0.80</td>
      <td>9120</td>
    </tr>
    <tr>
      <th>1</th>
      <td>40</td>
      <td>0.12</td>
      <td>2600</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>0.09</td>
      <td>3042</td>
    </tr>
    <tr>
      <th>3</th>
      <td>30</td>
      <td>0.04</td>
      <td>3300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>39</td>
      <td>0.21</td>
      <td>3500</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为三个指标数据的量级相差较大，所以可以先进行数据归一化处理</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">X_new = StandardScaler().fit_transform(X)</span><br><span class="line"></span><br><span class="line">X_new  <span class="comment"># 查看归一化后的数据</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[ 1.36321743,  1.96044639,  1.98450514],
       [ 0.33047695, -0.47222431, -0.70685302],
       [-0.08261924, -0.57954802, -0.52440206],
       [-1.73500401, -0.75842087, -0.41790353],
       [ 0.12392886, -0.15025319, -0.33534653]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)  <span class="comment"># 将三维数据降为二维数据</span></span><br><span class="line">pca.fit(X_new)  <span class="comment"># 进行降维模型训练</span></span><br><span class="line">X_transformed = pca.transform(X_new)  <span class="comment"># 进行数据降维，并赋值给X_transformed</span></span><br><span class="line"></span><br><span class="line">X_transformed  <span class="comment"># 查看降维后的结果</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[ 3.08724247,  0.32991205],
       [-0.52888635, -0.74272137],
       [-0.70651782, -0.33057258],
       [-1.62877292,  1.05218639],
       [-0.22306538, -0.30880449]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看降维的系数</span></span><br><span class="line">pca.components_  </span><br></pre></td></tr></table></figure>




<pre><code>array([[ 0.52952108,  0.61328179,  0.58608264],
       [-0.82760701,  0.22182579,  0.51561609]])
</code></pre>
<p><img src="%E4%B8%8B%E8%BD%BD%20(37).png" alt="下载 (37)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dim = [<span class="string">&#x27;年龄(岁)&#x27;</span>, <span class="string">&#x27;负债比率&#x27;</span>, <span class="string">&#x27;月收入(元)&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pca.components_:</span><br><span class="line">    formula = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(i)):</span><br><span class="line">        formula.append(<span class="built_in">str</span>(i[j]) + <span class="string">&#x27; * &#x27;</span> + dim[j])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; + &quot;</span>.join(formula))</span><br></pre></td></tr></table></figure>

<pre><code>0.529521083916554 * 年龄(岁) + 0.6132817922410683 * 负债比率 + 0.5860826434841946 * 月收入(元)
-0.8276070105929828 * 年龄(岁) + 0.2218257919336098 * 负债比率 + 0.5156160917294703 * 月收入(元)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果不想显示具体的特征名称，可以采用如下的写法</span></span><br><span class="line">dim = [<span class="string">&#x27;X&#x27;</span>, <span class="string">&#x27;Y&#x27;</span>, <span class="string">&#x27;Z&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pca.components_:</span><br><span class="line">    formula = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(i)):</span><br><span class="line">        formula.append(<span class="built_in">str</span>(i[j]) + <span class="string">&#x27; * &#x27;</span> + dim[j])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot; + &quot;</span>.join(formula))</span><br></pre></td></tr></table></figure>

<pre><code>0.529521083916554 * X + 0.6132817922410683 * Y + 0.5860826434841946 * Z
-0.8276070105929828 * X + 0.2218257919336098 * Y + 0.5156160917294703 * Z
</code></pre>
<h2 id="12-2-案例实战：人脸识别模型"><a href="#12-2-案例实战：人脸识别模型" class="headerlink" title="12.2 案例实战：人脸识别模型"></a>12.2 案例实战：人脸识别模型</h2><h3 id="12-2-1-案例背景"><a href="#12-2-1-案例背景" class="headerlink" title="12.2.1 案例背景"></a>12.2.1 案例背景</h3><p>人脸识别的本质是根据每张人脸图像中不同像素点的颜色进行数据建模与判断。人脸图像的每个像素点的颜色都有不同的值，这些值可以组成人脸的特征向量，不过因为人脸图片的像素点很多，所以特征变量也很多，需要利用PCA进行数据降维</p>
<h3 id="12-2-2-人脸数据读取、处理与变量提取"><a href="#12-2-2-人脸数据读取、处理与变量提取" class="headerlink" title="12.2.2 人脸数据读取、处理与变量提取"></a>12.2.2 人脸数据读取、处理与变量提取</h3><p>1.读取人脸照片数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">names = os.listdir(<span class="string">&#x27;olivettifaces&#x27;</span>)</span><br><span class="line"></span><br><span class="line">names[<span class="number">0</span>:<span class="number">5</span>]  <span class="comment"># 查看前5项读取的文件名</span></span><br></pre></td></tr></table></figure>




<pre><code>[&#39;10_0.jpg&#39;, &#39;10_1.jpg&#39;, &#39;10_2.jpg&#39;, &#39;10_3.jpg&#39;, &#39;10_4.jpg&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取到文件名称后，便可以通过如下代码在Python中查看这些图片</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">img0 = Image.<span class="built_in">open</span>(<span class="string">&#x27;olivettifaces\\&#x27;</span> + names[<span class="number">0</span>])</span><br><span class="line">img0.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img0  <span class="comment"># 在Jupyter Notebook中可以直接输入变量名查看图像</span></span><br></pre></td></tr></table></figure>




<p><img src="output_235_0.png" alt="output_235_0"></p>
<p><strong>2.人脸数据处理 - 特征变量提取</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图像灰度处理及数值化处理</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img0 = img0.convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">img0 = img0.resize((<span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">arr = np.array(img0)</span><br><span class="line"></span><br><span class="line">arr  <span class="comment"># 查看数值化后的结果</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[186,  76,  73, ..., 100, 103, 106],
       [196,  85,  68, ...,  85, 106, 103],
       [193,  69,  79, ...,  82,  99, 100],
       ...,
       [196,  87, 193, ..., 103,  66,  52],
       [219, 179, 202, ..., 150, 127, 109],
       [244, 228, 230, ..., 198, 202, 206]], dtype=uint8)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果觉得numpy格式的arr不好观察，则可以通过pandas库将其转为DataFrame格式进行观察</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.DataFrame(arr)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
      <th>26</th>
      <th>27</th>
      <th>28</th>
      <th>29</th>
      <th>30</th>
      <th>31</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>186</td>
      <td>76</td>
      <td>73</td>
      <td>87</td>
      <td>89</td>
      <td>88</td>
      <td>75</td>
      <td>81</td>
      <td>100</td>
      <td>102</td>
      <td>...</td>
      <td>71</td>
      <td>75</td>
      <td>75</td>
      <td>73</td>
      <td>76</td>
      <td>85</td>
      <td>95</td>
      <td>100</td>
      <td>103</td>
      <td>106</td>
    </tr>
    <tr>
      <th>1</th>
      <td>196</td>
      <td>85</td>
      <td>68</td>
      <td>78</td>
      <td>104</td>
      <td>97</td>
      <td>100</td>
      <td>94</td>
      <td>83</td>
      <td>87</td>
      <td>...</td>
      <td>52</td>
      <td>59</td>
      <td>70</td>
      <td>85</td>
      <td>62</td>
      <td>82</td>
      <td>89</td>
      <td>85</td>
      <td>106</td>
      <td>103</td>
    </tr>
    <tr>
      <th>2</th>
      <td>193</td>
      <td>69</td>
      <td>79</td>
      <td>92</td>
      <td>105</td>
      <td>102</td>
      <td>112</td>
      <td>117</td>
      <td>106</td>
      <td>94</td>
      <td>...</td>
      <td>41</td>
      <td>45</td>
      <td>50</td>
      <td>76</td>
      <td>59</td>
      <td>74</td>
      <td>83</td>
      <td>82</td>
      <td>99</td>
      <td>100</td>
    </tr>
    <tr>
      <th>3</th>
      <td>186</td>
      <td>67</td>
      <td>71</td>
      <td>75</td>
      <td>85</td>
      <td>99</td>
      <td>114</td>
      <td>115</td>
      <td>109</td>
      <td>109</td>
      <td>...</td>
      <td>42</td>
      <td>43</td>
      <td>40</td>
      <td>52</td>
      <td>41</td>
      <td>61</td>
      <td>69</td>
      <td>76</td>
      <td>76</td>
      <td>108</td>
    </tr>
    <tr>
      <th>4</th>
      <td>179</td>
      <td>46</td>
      <td>41</td>
      <td>50</td>
      <td>53</td>
      <td>69</td>
      <td>80</td>
      <td>91</td>
      <td>108</td>
      <td>104</td>
      <td>...</td>
      <td>43</td>
      <td>37</td>
      <td>30</td>
      <td>31</td>
      <td>35</td>
      <td>43</td>
      <td>59</td>
      <td>61</td>
      <td>56</td>
      <td>101</td>
    </tr>
    <tr>
      <th>5</th>
      <td>173</td>
      <td>33</td>
      <td>43</td>
      <td>49</td>
      <td>48</td>
      <td>53</td>
      <td>64</td>
      <td>69</td>
      <td>72</td>
      <td>75</td>
      <td>...</td>
      <td>38</td>
      <td>36</td>
      <td>33</td>
      <td>32</td>
      <td>39</td>
      <td>45</td>
      <td>68</td>
      <td>60</td>
      <td>45</td>
      <td>83</td>
    </tr>
    <tr>
      <th>6</th>
      <td>173</td>
      <td>30</td>
      <td>37</td>
      <td>41</td>
      <td>42</td>
      <td>57</td>
      <td>81</td>
      <td>88</td>
      <td>77</td>
      <td>64</td>
      <td>...</td>
      <td>31</td>
      <td>32</td>
      <td>35</td>
      <td>32</td>
      <td>35</td>
      <td>49</td>
      <td>65</td>
      <td>64</td>
      <td>53</td>
      <td>87</td>
    </tr>
    <tr>
      <th>7</th>
      <td>171</td>
      <td>24</td>
      <td>32</td>
      <td>36</td>
      <td>42</td>
      <td>55</td>
      <td>77</td>
      <td>101</td>
      <td>107</td>
      <td>102</td>
      <td>...</td>
      <td>54</td>
      <td>64</td>
      <td>63</td>
      <td>51</td>
      <td>53</td>
      <td>60</td>
      <td>56</td>
      <td>46</td>
      <td>49</td>
      <td>89</td>
    </tr>
    <tr>
      <th>8</th>
      <td>170</td>
      <td>21</td>
      <td>31</td>
      <td>29</td>
      <td>28</td>
      <td>35</td>
      <td>47</td>
      <td>62</td>
      <td>76</td>
      <td>83</td>
      <td>...</td>
      <td>105</td>
      <td>101</td>
      <td>89</td>
      <td>63</td>
      <td>45</td>
      <td>42</td>
      <td>41</td>
      <td>37</td>
      <td>61</td>
      <td>101</td>
    </tr>
    <tr>
      <th>9</th>
      <td>172</td>
      <td>21</td>
      <td>22</td>
      <td>27</td>
      <td>28</td>
      <td>30</td>
      <td>33</td>
      <td>43</td>
      <td>46</td>
      <td>44</td>
      <td>...</td>
      <td>129</td>
      <td>118</td>
      <td>103</td>
      <td>74</td>
      <td>39</td>
      <td>27</td>
      <td>36</td>
      <td>34</td>
      <td>68</td>
      <td>101</td>
    </tr>
    <tr>
      <th>10</th>
      <td>171</td>
      <td>23</td>
      <td>30</td>
      <td>21</td>
      <td>30</td>
      <td>36</td>
      <td>44</td>
      <td>51</td>
      <td>46</td>
      <td>41</td>
      <td>...</td>
      <td>136</td>
      <td>126</td>
      <td>120</td>
      <td>102</td>
      <td>70</td>
      <td>40</td>
      <td>30</td>
      <td>35</td>
      <td>78</td>
      <td>101</td>
    </tr>
    <tr>
      <th>11</th>
      <td>175</td>
      <td>21</td>
      <td>33</td>
      <td>31</td>
      <td>42</td>
      <td>54</td>
      <td>71</td>
      <td>73</td>
      <td>64</td>
      <td>59</td>
      <td>...</td>
      <td>142</td>
      <td>133</td>
      <td>122</td>
      <td>114</td>
      <td>111</td>
      <td>77</td>
      <td>31</td>
      <td>36</td>
      <td>95</td>
      <td>104</td>
    </tr>
    <tr>
      <th>12</th>
      <td>192</td>
      <td>42</td>
      <td>27</td>
      <td>37</td>
      <td>63</td>
      <td>87</td>
      <td>99</td>
      <td>111</td>
      <td>116</td>
      <td>116</td>
      <td>...</td>
      <td>105</td>
      <td>108</td>
      <td>108</td>
      <td>107</td>
      <td>109</td>
      <td>104</td>
      <td>58</td>
      <td>59</td>
      <td>100</td>
      <td>97</td>
    </tr>
    <tr>
      <th>13</th>
      <td>196</td>
      <td>82</td>
      <td>41</td>
      <td>58</td>
      <td>102</td>
      <td>112</td>
      <td>110</td>
      <td>110</td>
      <td>107</td>
      <td>108</td>
      <td>...</td>
      <td>70</td>
      <td>71</td>
      <td>86</td>
      <td>102</td>
      <td>107</td>
      <td>116</td>
      <td>84</td>
      <td>77</td>
      <td>95</td>
      <td>99</td>
    </tr>
    <tr>
      <th>14</th>
      <td>192</td>
      <td>88</td>
      <td>78</td>
      <td>95</td>
      <td>96</td>
      <td>87</td>
      <td>81</td>
      <td>72</td>
      <td>51</td>
      <td>40</td>
      <td>...</td>
      <td>62</td>
      <td>73</td>
      <td>73</td>
      <td>101</td>
      <td>116</td>
      <td>116</td>
      <td>99</td>
      <td>80</td>
      <td>88</td>
      <td>105</td>
    </tr>
    <tr>
      <th>15</th>
      <td>190</td>
      <td>88</td>
      <td>102</td>
      <td>114</td>
      <td>99</td>
      <td>76</td>
      <td>55</td>
      <td>55</td>
      <td>50</td>
      <td>37</td>
      <td>...</td>
      <td>100</td>
      <td>112</td>
      <td>120</td>
      <td>120</td>
      <td>125</td>
      <td>125</td>
      <td>105</td>
      <td>97</td>
      <td>101</td>
      <td>98</td>
    </tr>
    <tr>
      <th>16</th>
      <td>189</td>
      <td>106</td>
      <td>111</td>
      <td>113</td>
      <td>137</td>
      <td>124</td>
      <td>113</td>
      <td>109</td>
      <td>103</td>
      <td>96</td>
      <td>...</td>
      <td>134</td>
      <td>137</td>
      <td>142</td>
      <td>146</td>
      <td>134</td>
      <td>120</td>
      <td>96</td>
      <td>115</td>
      <td>122</td>
      <td>93</td>
    </tr>
    <tr>
      <th>17</th>
      <td>188</td>
      <td>106</td>
      <td>132</td>
      <td>119</td>
      <td>142</td>
      <td>160</td>
      <td>158</td>
      <td>153</td>
      <td>148</td>
      <td>145</td>
      <td>...</td>
      <td>163</td>
      <td>158</td>
      <td>156</td>
      <td>142</td>
      <td>124</td>
      <td>110</td>
      <td>100</td>
      <td>114</td>
      <td>108</td>
      <td>86</td>
    </tr>
    <tr>
      <th>18</th>
      <td>193</td>
      <td>83</td>
      <td>140</td>
      <td>130</td>
      <td>122</td>
      <td>141</td>
      <td>153</td>
      <td>160</td>
      <td>168</td>
      <td>177</td>
      <td>...</td>
      <td>163</td>
      <td>158</td>
      <td>148</td>
      <td>129</td>
      <td>112</td>
      <td>103</td>
      <td>99</td>
      <td>99</td>
      <td>78</td>
      <td>77</td>
    </tr>
    <tr>
      <th>19</th>
      <td>190</td>
      <td>81</td>
      <td>117</td>
      <td>127</td>
      <td>107</td>
      <td>120</td>
      <td>134</td>
      <td>146</td>
      <td>163</td>
      <td>166</td>
      <td>...</td>
      <td>157</td>
      <td>145</td>
      <td>132</td>
      <td>117</td>
      <td>105</td>
      <td>103</td>
      <td>90</td>
      <td>64</td>
      <td>67</td>
      <td>72</td>
    </tr>
    <tr>
      <th>20</th>
      <td>193</td>
      <td>83</td>
      <td>84</td>
      <td>106</td>
      <td>104</td>
      <td>113</td>
      <td>122</td>
      <td>134</td>
      <td>138</td>
      <td>143</td>
      <td>...</td>
      <td>142</td>
      <td>129</td>
      <td>116</td>
      <td>109</td>
      <td>105</td>
      <td>102</td>
      <td>86</td>
      <td>55</td>
      <td>60</td>
      <td>63</td>
    </tr>
    <tr>
      <th>21</th>
      <td>194</td>
      <td>78</td>
      <td>87</td>
      <td>91</td>
      <td>92</td>
      <td>108</td>
      <td>113</td>
      <td>122</td>
      <td>127</td>
      <td>140</td>
      <td>...</td>
      <td>140</td>
      <td>128</td>
      <td>118</td>
      <td>113</td>
      <td>109</td>
      <td>101</td>
      <td>68</td>
      <td>56</td>
      <td>56</td>
      <td>56</td>
    </tr>
    <tr>
      <th>22</th>
      <td>191</td>
      <td>80</td>
      <td>89</td>
      <td>88</td>
      <td>90</td>
      <td>104</td>
      <td>114</td>
      <td>120</td>
      <td>131</td>
      <td>141</td>
      <td>...</td>
      <td>130</td>
      <td>129</td>
      <td>119</td>
      <td>108</td>
      <td>103</td>
      <td>101</td>
      <td>50</td>
      <td>53</td>
      <td>55</td>
      <td>53</td>
    </tr>
    <tr>
      <th>23</th>
      <td>189</td>
      <td>77</td>
      <td>89</td>
      <td>91</td>
      <td>86</td>
      <td>93</td>
      <td>111</td>
      <td>122</td>
      <td>133</td>
      <td>129</td>
      <td>...</td>
      <td>102</td>
      <td>113</td>
      <td>111</td>
      <td>107</td>
      <td>101</td>
      <td>85</td>
      <td>53</td>
      <td>51</td>
      <td>54</td>
      <td>55</td>
    </tr>
    <tr>
      <th>24</th>
      <td>190</td>
      <td>86</td>
      <td>88</td>
      <td>87</td>
      <td>87</td>
      <td>87</td>
      <td>104</td>
      <td>115</td>
      <td>127</td>
      <td>115</td>
      <td>...</td>
      <td>105</td>
      <td>108</td>
      <td>104</td>
      <td>102</td>
      <td>97</td>
      <td>55</td>
      <td>53</td>
      <td>50</td>
      <td>53</td>
      <td>59</td>
    </tr>
    <tr>
      <th>25</th>
      <td>187</td>
      <td>74</td>
      <td>89</td>
      <td>81</td>
      <td>93</td>
      <td>130</td>
      <td>103</td>
      <td>96</td>
      <td>110</td>
      <td>108</td>
      <td>...</td>
      <td>111</td>
      <td>105</td>
      <td>103</td>
      <td>102</td>
      <td>83</td>
      <td>50</td>
      <td>49</td>
      <td>56</td>
      <td>51</td>
      <td>49</td>
    </tr>
    <tr>
      <th>26</th>
      <td>190</td>
      <td>79</td>
      <td>81</td>
      <td>107</td>
      <td>166</td>
      <td>206</td>
      <td>119</td>
      <td>88</td>
      <td>94</td>
      <td>105</td>
      <td>...</td>
      <td>102</td>
      <td>104</td>
      <td>99</td>
      <td>100</td>
      <td>111</td>
      <td>111</td>
      <td>57</td>
      <td>48</td>
      <td>52</td>
      <td>53</td>
    </tr>
    <tr>
      <th>27</th>
      <td>192</td>
      <td>78</td>
      <td>83</td>
      <td>173</td>
      <td>211</td>
      <td>158</td>
      <td>114</td>
      <td>100</td>
      <td>87</td>
      <td>94</td>
      <td>...</td>
      <td>101</td>
      <td>98</td>
      <td>98</td>
      <td>96</td>
      <td>116</td>
      <td>123</td>
      <td>119</td>
      <td>52</td>
      <td>49</td>
      <td>55</td>
    </tr>
    <tr>
      <th>28</th>
      <td>188</td>
      <td>70</td>
      <td>136</td>
      <td>177</td>
      <td>198</td>
      <td>108</td>
      <td>101</td>
      <td>119</td>
      <td>86</td>
      <td>81</td>
      <td>...</td>
      <td>98</td>
      <td>98</td>
      <td>93</td>
      <td>82</td>
      <td>80</td>
      <td>123</td>
      <td>145</td>
      <td>73</td>
      <td>43</td>
      <td>51</td>
    </tr>
    <tr>
      <th>29</th>
      <td>196</td>
      <td>87</td>
      <td>193</td>
      <td>187</td>
      <td>179</td>
      <td>113</td>
      <td>123</td>
      <td>123</td>
      <td>110</td>
      <td>81</td>
      <td>...</td>
      <td>95</td>
      <td>90</td>
      <td>96</td>
      <td>77</td>
      <td>53</td>
      <td>160</td>
      <td>124</td>
      <td>103</td>
      <td>66</td>
      <td>52</td>
    </tr>
    <tr>
      <th>30</th>
      <td>219</td>
      <td>179</td>
      <td>202</td>
      <td>196</td>
      <td>198</td>
      <td>146</td>
      <td>122</td>
      <td>118</td>
      <td>119</td>
      <td>94</td>
      <td>...</td>
      <td>92</td>
      <td>90</td>
      <td>87</td>
      <td>57</td>
      <td>89</td>
      <td>126</td>
      <td>140</td>
      <td>150</td>
      <td>127</td>
      <td>109</td>
    </tr>
    <tr>
      <th>31</th>
      <td>244</td>
      <td>228</td>
      <td>230</td>
      <td>231</td>
      <td>233</td>
      <td>213</td>
      <td>188</td>
      <td>195</td>
      <td>193</td>
      <td>189</td>
      <td>...</td>
      <td>179</td>
      <td>184</td>
      <td>177</td>
      <td>161</td>
      <td>202</td>
      <td>182</td>
      <td>207</td>
      <td>198</td>
      <td>202</td>
      <td>206</td>
    </tr>
  </tbody>
</table>
<p>32 rows × 32 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上面获得的32*32的二维数组，还不利于数据建模，所以我们还需要通过reshape(1, -1)方法将其转换成一行(若reshape(-1,1)则转为一列），也即1*1024格式</span></span><br><span class="line">arr = arr.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(arr)  <span class="comment"># 查看转换后的结果，这一行数就是代表那张人脸图片了，其共有32*32=1024列数</span></span><br></pre></td></tr></table></figure>

<pre><code>[[186  76  73 ... 198 202 206]]
</code></pre>
<p>因为总共有400张照片需要处理，若将400个二维数组堆叠起来会形成三维数组，因为我们需要使用flatten()函数将1*1024的二维数组降维成一维数组，并通过tolist()函数将其转为列表方便之后和其他图片的颜色数值信息一起处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(arr.flatten().tolist())  <span class="comment"># 下面这一行数就是那张人脸转换后的结果了</span></span><br></pre></td></tr></table></figure>

<pre><code>[186, 76, 73, 87, 89, 88, 75, 81, 100, 102, 105, 92, 74, 65, 65, 53, 43, 55, 53, 42, 58, 77, 71, 75, 75, 73, 76, 85, 95, 100, 103, 106, 196, 85, 68, 78, 104, 97, 100, 94, 83, 87, 88, 89, 86, 70, 65, 61, 55, 52, 38, 32, 52, 66, 52, 59, 70, 85, 62, 82, 89, 85, 106, 103, 193, 69, 79, 92, 105, 102, 112, 117, 106, 94, 91, 112, 101, 87, 75, 61, 58, 54, 49, 48, 44, 41, 41, 45, 50, 76, 59, 74, 83, 82, 99, 100, 186, 67, 71, 75, 85, 99, 114, 115, 109, 109, 98, 101, 86, 68, 74, 65, 58, 53, 51, 52, 42, 40, 42, 43, 40, 52, 41, 61, 69, 76, 76, 108, 179, 46, 41, 50, 53, 69, 80, 91, 108, 104, 98, 93, 91, 88, 73, 60, 56, 55, 51, 49, 53, 55, 43, 37, 30, 31, 35, 43, 59, 61, 56, 101, 173, 33, 43, 49, 48, 53, 64, 69, 72, 75, 82, 84, 84, 82, 72, 75, 69, 71, 67, 56, 58, 55, 38, 36, 33, 32, 39, 45, 68, 60, 45, 83, 173, 30, 37, 41, 42, 57, 81, 88, 77, 64, 63, 64, 65, 64, 48, 48, 68, 62, 47, 50, 45, 31, 31, 32, 35, 32, 35, 49, 65, 64, 53, 87, 171, 24, 32, 36, 42, 55, 77, 101, 107, 102, 98, 83, 71, 64, 44, 48, 54, 64, 76, 65, 49, 48, 54, 64, 63, 51, 53, 60, 56, 46, 49, 89, 170, 21, 31, 29, 28, 35, 47, 62, 76, 83, 87, 78, 53, 58, 65, 83, 90, 97, 108, 101, 97, 105, 105, 101, 89, 63, 45, 42, 41, 37, 61, 101, 172, 21, 22, 27, 28, 30, 33, 43, 46, 44, 43, 46, 50, 63, 76, 87, 95, 104, 114, 120, 122, 125, 129, 118, 103, 74, 39, 27, 36, 34, 68, 101, 171, 23, 30, 21, 30, 36, 44, 51, 46, 41, 45, 52, 61, 70, 84, 101, 112, 119, 126, 131, 134, 138, 136, 126, 120, 102, 70, 40, 30, 35, 78, 101, 175, 21, 33, 31, 42, 54, 71, 73, 64, 59, 65, 78, 95, 106, 110, 116, 122, 130, 140, 143, 141, 142, 142, 133, 122, 114, 111, 77, 31, 36, 95, 104, 192, 42, 27, 37, 63, 87, 99, 111, 116, 116, 117, 117, 121, 122, 120, 119, 120, 121, 120, 113, 107, 106, 105, 108, 108, 107, 109, 104, 58, 59, 100, 97, 196, 82, 41, 58, 102, 112, 110, 110, 107, 108, 107, 107, 115, 126, 126, 118, 98, 87, 69, 57, 55, 55, 70, 71, 86, 102, 107, 116, 84, 77, 95, 99, 192, 88, 78, 95, 96, 87, 81, 72, 51, 40, 52, 53, 68, 89, 116, 111, 83, 61, 44, 55, 61, 42, 62, 73, 73, 101, 116, 116, 99, 80, 88, 105, 190, 88, 102, 114, 99, 76, 55, 55, 50, 37, 60, 53, 49, 84, 161, 155, 109, 94, 83, 76, 84, 88, 100, 112, 120, 120, 125, 125, 105, 97, 101, 98, 189, 106, 111, 113, 137, 124, 113, 109, 103, 96, 84, 84, 99, 123, 172, 176, 139, 130, 127, 120, 116, 115, 134, 137, 142, 146, 134, 120, 96, 115, 122, 93, 188, 106, 132, 119, 142, 160, 158, 153, 148, 145, 156, 151, 139, 139, 160, 177, 151, 138, 141, 153, 162, 164, 163, 158, 156, 142, 124, 110, 100, 114, 108, 86, 193, 83, 140, 130, 122, 141, 153, 160, 168, 177, 171, 154, 135, 137, 161, 176, 158, 146, 143, 142, 159, 164, 163, 158, 148, 129, 112, 103, 99, 99, 78, 77, 190, 81, 117, 127, 107, 120, 134, 146, 163, 166, 155, 134, 138, 137, 153, 164, 141, 132, 132, 127, 148, 156, 157, 145, 132, 117, 105, 103, 90, 64, 67, 72, 193, 83, 84, 106, 104, 113, 122, 134, 138, 143, 141, 138, 93, 69, 84, 86, 71, 62, 75, 106, 142, 146, 142, 129, 116, 109, 105, 102, 86, 55, 60, 63, 194, 78, 87, 91, 92, 108, 113, 122, 127, 140, 148, 154, 121, 80, 72, 66, 80, 96, 106, 112, 137, 147, 140, 128, 118, 113, 109, 101, 68, 56, 56, 56, 191, 80, 89, 88, 90, 104, 114, 120, 131, 141, 145, 150, 153, 142, 144, 124, 105, 111, 119, 121, 128, 128, 130, 129, 119, 108, 103, 101, 50, 53, 55, 53, 189, 77, 89, 91, 86, 93, 111, 122, 133, 129, 125, 126, 118, 117, 115, 111, 100, 85, 87, 86, 76, 88, 102, 113, 111, 107, 101, 85, 53, 51, 54, 55, 190, 86, 88, 87, 87, 87, 104, 115, 127, 115, 101, 88, 83, 84, 91, 96, 108, 114, 101, 98, 106, 103, 105, 108, 104, 102, 97, 55, 53, 50, 53, 59, 187, 74, 89, 81, 93, 130, 103, 96, 110, 108, 108, 129, 126, 112, 119, 108, 96, 98, 105, 110, 117, 118, 111, 105, 103, 102, 83, 50, 49, 56, 51, 49, 190, 79, 81, 107, 166, 206, 119, 88, 94, 105, 112, 116, 113, 106, 96, 92, 95, 102, 103, 107, 113, 108, 102, 104, 99, 100, 111, 111, 57, 48, 52, 53, 192, 78, 83, 173, 211, 158, 114, 100, 87, 94, 108, 114, 115, 119, 129, 146, 151, 144, 140, 133, 121, 112, 101, 98, 98, 96, 116, 123, 119, 52, 49, 55, 188, 70, 136, 177, 198, 108, 101, 119, 86, 81, 94, 105, 115, 123, 127, 128, 126, 122, 119, 109, 97, 97, 98, 98, 93, 82, 80, 123, 145, 73, 43, 51, 196, 87, 193, 187, 179, 113, 123, 123, 110, 81, 73, 81, 88, 96, 97, 95, 91, 91, 89, 86, 91, 99, 95, 90, 96, 77, 53, 160, 124, 103, 66, 52, 219, 179, 202, 196, 198, 146, 122, 118, 119, 94, 76, 73, 72, 74, 77, 73, 74, 79, 77, 83, 92, 94, 92, 90, 87, 57, 89, 126, 140, 150, 127, 109, 244, 228, 230, 231, 233, 213, 188, 195, 193, 189, 181, 173, 171, 171, 171, 168, 168, 171, 173, 178, 182, 179, 179, 184, 177, 161, 202, 182, 207, 198, 202, 206]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造所有图片的特征变量</span></span><br><span class="line">X = []  <span class="comment"># 特征变量</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> names:</span><br><span class="line">    img = Image.<span class="built_in">open</span>(<span class="string">&#x27;olivettifaces\\&#x27;</span> + i)</span><br><span class="line">    img = img.convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">    img = img.resize((<span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">    arr = np.array(img)</span><br><span class="line">    X.append(arr.reshape(<span class="number">1</span>, -<span class="number">1</span>).flatten().tolist())</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">X = pd.DataFrame(X)</span><br><span class="line"></span><br><span class="line">X  <span class="comment"># 查看400张图片转换后的结果</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>1014</th>
      <th>1015</th>
      <th>1016</th>
      <th>1017</th>
      <th>1018</th>
      <th>1019</th>
      <th>1020</th>
      <th>1021</th>
      <th>1022</th>
      <th>1023</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>186</td>
      <td>76</td>
      <td>73</td>
      <td>87</td>
      <td>89</td>
      <td>88</td>
      <td>75</td>
      <td>81</td>
      <td>100</td>
      <td>102</td>
      <td>...</td>
      <td>179</td>
      <td>184</td>
      <td>177</td>
      <td>161</td>
      <td>202</td>
      <td>182</td>
      <td>207</td>
      <td>198</td>
      <td>202</td>
      <td>206</td>
    </tr>
    <tr>
      <th>1</th>
      <td>196</td>
      <td>90</td>
      <td>97</td>
      <td>98</td>
      <td>98</td>
      <td>87</td>
      <td>101</td>
      <td>89</td>
      <td>65</td>
      <td>73</td>
      <td>...</td>
      <td>181</td>
      <td>167</td>
      <td>190</td>
      <td>188</td>
      <td>203</td>
      <td>209</td>
      <td>205</td>
      <td>198</td>
      <td>190</td>
      <td>190</td>
    </tr>
    <tr>
      <th>2</th>
      <td>193</td>
      <td>89</td>
      <td>97</td>
      <td>99</td>
      <td>75</td>
      <td>74</td>
      <td>83</td>
      <td>64</td>
      <td>77</td>
      <td>86</td>
      <td>...</td>
      <td>178</td>
      <td>178</td>
      <td>156</td>
      <td>185</td>
      <td>195</td>
      <td>201</td>
      <td>206</td>
      <td>201</td>
      <td>189</td>
      <td>190</td>
    </tr>
    <tr>
      <th>3</th>
      <td>192</td>
      <td>84</td>
      <td>93</td>
      <td>89</td>
      <td>97</td>
      <td>89</td>
      <td>66</td>
      <td>60</td>
      <td>60</td>
      <td>57</td>
      <td>...</td>
      <td>173</td>
      <td>151</td>
      <td>199</td>
      <td>189</td>
      <td>203</td>
      <td>200</td>
      <td>196</td>
      <td>186</td>
      <td>182</td>
      <td>184</td>
    </tr>
    <tr>
      <th>4</th>
      <td>194</td>
      <td>72</td>
      <td>49</td>
      <td>45</td>
      <td>56</td>
      <td>37</td>
      <td>44</td>
      <td>62</td>
      <td>71</td>
      <td>71</td>
      <td>...</td>
      <td>192</td>
      <td>194</td>
      <td>192</td>
      <td>176</td>
      <td>174</td>
      <td>224</td>
      <td>200</td>
      <td>218</td>
      <td>176</td>
      <td>168</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>395</th>
      <td>114</td>
      <td>115</td>
      <td>115</td>
      <td>119</td>
      <td>115</td>
      <td>120</td>
      <td>117</td>
      <td>118</td>
      <td>113</td>
      <td>112</td>
      <td>...</td>
      <td>190</td>
      <td>193</td>
      <td>169</td>
      <td>141</td>
      <td>142</td>
      <td>144</td>
      <td>143</td>
      <td>141</td>
      <td>143</td>
      <td>215</td>
    </tr>
    <tr>
      <th>396</th>
      <td>115</td>
      <td>118</td>
      <td>117</td>
      <td>117</td>
      <td>116</td>
      <td>118</td>
      <td>117</td>
      <td>119</td>
      <td>117</td>
      <td>116</td>
      <td>...</td>
      <td>187</td>
      <td>189</td>
      <td>183</td>
      <td>216</td>
      <td>189</td>
      <td>193</td>
      <td>148</td>
      <td>144</td>
      <td>142</td>
      <td>212</td>
    </tr>
    <tr>
      <th>397</th>
      <td>113</td>
      <td>116</td>
      <td>113</td>
      <td>117</td>
      <td>114</td>
      <td>121</td>
      <td>121</td>
      <td>120</td>
      <td>121</td>
      <td>114</td>
      <td>...</td>
      <td>184</td>
      <td>188</td>
      <td>185</td>
      <td>221</td>
      <td>203</td>
      <td>192</td>
      <td>144</td>
      <td>143</td>
      <td>137</td>
      <td>212</td>
    </tr>
    <tr>
      <th>398</th>
      <td>110</td>
      <td>109</td>
      <td>109</td>
      <td>110</td>
      <td>110</td>
      <td>112</td>
      <td>112</td>
      <td>113</td>
      <td>113</td>
      <td>111</td>
      <td>...</td>
      <td>172</td>
      <td>171</td>
      <td>209</td>
      <td>212</td>
      <td>175</td>
      <td>136</td>
      <td>142</td>
      <td>141</td>
      <td>137</td>
      <td>213</td>
    </tr>
    <tr>
      <th>399</th>
      <td>105</td>
      <td>107</td>
      <td>111</td>
      <td>112</td>
      <td>113</td>
      <td>113</td>
      <td>113</td>
      <td>116</td>
      <td>116</td>
      <td>107</td>
      <td>...</td>
      <td>181</td>
      <td>184</td>
      <td>220</td>
      <td>188</td>
      <td>140</td>
      <td>139</td>
      <td>142</td>
      <td>141</td>
      <td>138</td>
      <td>213</td>
    </tr>
  </tbody>
</table>
<p>400 rows × 1024 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(X.shape)  <span class="comment"># 查看此时的表格结构</span></span><br></pre></td></tr></table></figure>

<pre><code>(400, 1024)
</code></pre>
<p><strong>3.人脸数据处理 - 目标变量提取</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取目标变量y：第一张图片演示</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">int</span>(names[<span class="number">0</span>].split(<span class="string">&#x27;_&#x27;</span>)[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>10
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 批量获取所有图片的目标变量y</span></span><br><span class="line">y = []  <span class="comment"># 目标变量</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> names:</span><br><span class="line">    img = Image.<span class="built_in">open</span>(<span class="string">&#x27;olivettifaces\\&#x27;</span> + i)</span><br><span class="line">    y.append(<span class="built_in">int</span>(i.split(<span class="string">&#x27;_&#x27;</span>)[<span class="number">0</span>]))</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(y)  <span class="comment"># 查看目标变量,也就是对应的人员编号</span></span><br></pre></td></tr></table></figure>

<pre><code>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]
</code></pre>
<h3 id="12-2-3-数据划分与降维"><a href="#12-2-3-数据划分与降维" class="headerlink" title="12.2.3 数据划分与降维"></a>12.2.3 数据划分与降维</h3><p>1.划分训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>2.PCA数据降维</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据降维模型训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">100</span>)</span><br><span class="line">pca.fit(X_train)</span><br></pre></td></tr></table></figure>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对训练集和测试集进行数据降维</span></span><br><span class="line">X_train_pca = pca.transform(X_train)</span><br><span class="line">X_test_pca = pca.transform(X_test)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们通过如下代码验证PCA是否降维：</span></span><br><span class="line"><span class="built_in">print</span>(X_train_pca.shape)</span><br><span class="line"><span class="built_in">print</span>(X_test_pca.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(320, 100)
(80, 100)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果想查看此时降维后的X_train_pca和X_test_pca，可以直接将它们打印出来查看，也可以将它们转为DataFrame格式进行查看，代码如下：</span></span><br><span class="line">pd.DataFrame(X_train_pca).head()</span><br><span class="line"><span class="comment"># pd.DataFrame(X_test_pca).head()</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>90</th>
      <th>91</th>
      <th>92</th>
      <th>93</th>
      <th>94</th>
      <th>95</th>
      <th>96</th>
      <th>97</th>
      <th>98</th>
      <th>99</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>843.848468</td>
      <td>-117.990083</td>
      <td>341.041562</td>
      <td>-45.240791</td>
      <td>-265.560411</td>
      <td>243.732770</td>
      <td>280.603780</td>
      <td>-259.737066</td>
      <td>216.102416</td>
      <td>192.380199</td>
      <td>...</td>
      <td>-17.946320</td>
      <td>31.326442</td>
      <td>34.625376</td>
      <td>-8.882940</td>
      <td>24.183872</td>
      <td>-40.728981</td>
      <td>8.891023</td>
      <td>-10.077005</td>
      <td>-41.382655</td>
      <td>-15.945479</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-495.124726</td>
      <td>-937.701751</td>
      <td>-305.851409</td>
      <td>4.351306</td>
      <td>-127.743015</td>
      <td>504.793986</td>
      <td>389.144515</td>
      <td>5.118525</td>
      <td>-32.353105</td>
      <td>103.516952</td>
      <td>...</td>
      <td>-56.858041</td>
      <td>-21.676102</td>
      <td>-37.577951</td>
      <td>8.156807</td>
      <td>11.915498</td>
      <td>-59.731644</td>
      <td>50.641757</td>
      <td>-49.858187</td>
      <td>-19.619541</td>
      <td>-19.917775</td>
    </tr>
    <tr>
      <th>2</th>
      <td>201.200905</td>
      <td>623.575255</td>
      <td>130.691212</td>
      <td>22.627082</td>
      <td>-427.373676</td>
      <td>-85.786784</td>
      <td>531.627875</td>
      <td>95.691712</td>
      <td>-176.386340</td>
      <td>-70.070452</td>
      <td>...</td>
      <td>-46.574460</td>
      <td>4.225610</td>
      <td>-1.518801</td>
      <td>-28.003457</td>
      <td>99.331340</td>
      <td>-33.898140</td>
      <td>-12.756052</td>
      <td>-53.757395</td>
      <td>46.329195</td>
      <td>-36.555657</td>
    </tr>
    <tr>
      <th>3</th>
      <td>603.867640</td>
      <td>-744.880158</td>
      <td>-626.408564</td>
      <td>-598.649870</td>
      <td>-400.044101</td>
      <td>7.220209</td>
      <td>-246.688151</td>
      <td>58.416884</td>
      <td>-417.199241</td>
      <td>-121.976573</td>
      <td>...</td>
      <td>42.639400</td>
      <td>8.357066</td>
      <td>28.521712</td>
      <td>28.323359</td>
      <td>39.183447</td>
      <td>-8.003523</td>
      <td>-85.881704</td>
      <td>30.512104</td>
      <td>-18.756975</td>
      <td>-24.699085</td>
    </tr>
    <tr>
      <th>4</th>
      <td>935.882937</td>
      <td>132.602933</td>
      <td>441.577563</td>
      <td>145.548390</td>
      <td>-260.280190</td>
      <td>248.876747</td>
      <td>235.116995</td>
      <td>-333.232316</td>
      <td>98.692073</td>
      <td>75.838782</td>
      <td>...</td>
      <td>-33.393869</td>
      <td>-36.531246</td>
      <td>43.010484</td>
      <td>-0.482193</td>
      <td>-33.761494</td>
      <td>2.675790</td>
      <td>-61.477543</td>
      <td>87.388430</td>
      <td>-20.888620</td>
      <td>-82.934200</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 100 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在PCA后面加个“？”运行可以可以看看官方的一些提示</span></span><br><span class="line"><span class="comment"># PCA?</span></span><br></pre></td></tr></table></figure>

<h3 id="12-2-4-模型的搭建与使用"><a href="#12-2-4-模型的搭建与使用" class="headerlink" title="12.2.4 模型的搭建与使用"></a>12.2.4 模型的搭建与使用</h3><p>1.模型搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier()  <span class="comment"># 建立KNN模型  </span></span><br><span class="line">knn.fit(X_train_pca, y_train)  <span class="comment"># 用降维后的训练集进行训练模型</span></span><br></pre></td></tr></table></figure>





<p>2.模型预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = knn.predict(X_test_pca)  <span class="comment"># 用降维后的测试集进行测试</span></span><br><span class="line"><span class="built_in">print</span>(y_pred)  <span class="comment"># 将对测试集的预测结果打印出来</span></span><br></pre></td></tr></table></figure>

<pre><code>[ 9 21  3 40 26  4 28 37 12 36 26  7 27 21  3 24  7  2 17 24 21 32  8  2
 11 19  6 29  6 29 18 10 25 35 10 18 15  5  9 22 34 29  2 16  8 18  8 38
 39 35 16 30 30 11 37 36 35 20 33  6  1 16 31 32  5 30  1 39 35 39  2 19
  5  8 11  4 14 27 22 24]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过和之前章节类似的代码，我们可以将预测值和实际值进行对比：</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line"></span><br><span class="line">a.head()  <span class="comment"># 查看表格前5行</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>21</td>
      <td>21</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>40</td>
      <td>40</td>
    </tr>
    <tr>
      <th>4</th>
      <td>26</td>
      <td>26</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看预测准确度 - 方法1</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9125
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看预测准确度 - 方法2</span></span><br><span class="line">score = knn.score(X_test_pca, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9125
</code></pre>
<p>3.模型对比（数据降维与不降维）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier()  <span class="comment"># 建立KNN模型  </span></span><br><span class="line">knn.fit(X_train, y_train)  <span class="comment"># 不使用数据降维，直接训练</span></span><br><span class="line">y_pred = knn.predict(X_test)  <span class="comment"># 不使用数据降维，直接测试</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9125
</code></pre>
<p>此时获得的准确度评分score为0.91，可以看到使用数据降维对提高模型预测效果还是有一些效果的，这里的数据量并不大，当数据量更大的时候，利用PCA主成分分析进行数据降维则会发挥更大的作用。</p>
<p>其实看出，在数据量不大的时候，PCA效果不明显</p>
<h2 id="12-3-人脸识别外部接口调用（学习了解）"><a href="#12-3-人脸识别外部接口调用（学习了解）" class="headerlink" title="12.3 人脸识别外部接口调用（学习了解）"></a>12.3 人脸识别外部接口调用（学习了解）</h2><h3 id="12-3-1-baidu-aip安装"><a href="#12-3-1-baidu-aip安装" class="headerlink" title="12.3.1 baidu-aip安装"></a>12.3.1 baidu-aip安装</h3><h3 id="12-3-2-调用接口进行人脸识别和打分"><a href="#12-3-2-调用接口进行人脸识别和打分" class="headerlink" title="12.3.2 调用接口进行人脸识别和打分"></a>12.3.2 调用接口进行人脸识别和打分</h3><p>进入网址<a target="_blank" rel="noopener" href="https://ai.baidu.com/tech/face">https://ai.baidu.com/tech/face</a> 点击立即使用，点击创建应用，选择响应的选项，点击立即创建，在应用列表中可以看到如下：<br><img src="%E4%B8%8B%E8%BD%BD%20(38).png" alt="下载 (38)"></p>
<p>这些数据在调用接口时会用到</p>
<p>AppID：29907061</p>
<p>API Key：0ascf98uSFUgGHBcbG1GEr79</p>
<p>Secret Key：C6S8SFnC6zsxwqOZsgd0gnx7ssWZ1xBz</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> aip <span class="keyword">import</span> AipFace</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面3行内容为自己的APP_ID,API_KEY,SECRET_KEY</span></span><br><span class="line">APP_ID = <span class="string">&#x27;29907061&#x27;</span></span><br><span class="line">API_KEY = <span class="string">&#x27;0ascf98uSFUgGHBcbG1GEr79&#x27;</span></span><br><span class="line">SECRET_KEY = <span class="string">&#x27;C6S8SFnC6zsxwqOZsgd0gnx7ssWZ1xBz&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把上面输入的账号信息传入接口</span></span><br><span class="line">aipFace = AipFace(APP_ID, API_KEY, SECRET_KEY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面一行内容为需要识别的人脸图片的地址，其他地方就不用改了</span></span><br><span class="line">filePath = <span class="string">r&#x27;王宇涵.jpg&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义打开文件的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_file_content</span>(<span class="params">filePath</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filePath, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        content = base64.b64encode(fp.read())</span><br><span class="line">        <span class="keyword">return</span> content.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">imageType = <span class="string">&quot;BASE64&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择最后要展示的内容，这里展示age（年龄）；gender（性别）；beauty（颜值）</span></span><br><span class="line">options = &#123;&#125;</span><br><span class="line">options[<span class="string">&quot;face_field&quot;</span>] = <span class="string">&quot;age,gender,beauty&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用接口aipFace的detect()函数进行人脸识别，打印结果</span></span><br><span class="line">result = aipFace.detect(get_file_content(filePath), imageType, options)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印具体信息，本质就是列表索引和字典的键值对应</span></span><br><span class="line">age = result[<span class="string">&#x27;result&#x27;</span>][<span class="string">&#x27;face_list&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;age&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;年龄预测为：&#x27;</span> + <span class="built_in">str</span>(age))</span><br><span class="line">gender = result[<span class="string">&#x27;result&#x27;</span>][<span class="string">&#x27;face_list&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;gender&#x27;</span>][<span class="string">&#x27;type&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;性别预测为：&#x27;</span> + gender)</span><br><span class="line">beauty = result[<span class="string">&#x27;result&#x27;</span>][<span class="string">&#x27;face_list&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;beauty&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;颜值评分为：&#x27;</span> + <span class="built_in">str</span>(beauty))</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;error_code&#39;: 0, &#39;error_msg&#39;: &#39;SUCCESS&#39;, &#39;log_id&#39;: 1258602420, &#39;timestamp&#39;: 1674483658, &#39;cached&#39;: 0, &#39;result&#39;: &#123;&#39;face_num&#39;: 1, &#39;face_list&#39;: [&#123;&#39;face_token&#39;: &#39;7c0ca661081a579b2eb47a372a4be16a&#39;, &#39;location&#39;: &#123;&#39;left&#39;: 338.66, &#39;top&#39;: 291.83, &#39;width&#39;: 612, &#39;height&#39;: 637, &#39;rotation&#39;: -1&#125;, &#39;face_probability&#39;: 1, &#39;angle&#39;: &#123;&#39;yaw&#39;: -5.65, &#39;pitch&#39;: 5.96, &#39;roll&#39;: -2.13&#125;, &#39;age&#39;: 22, &#39;gender&#39;: &#123;&#39;type&#39;: &#39;male&#39;, &#39;probability&#39;: 1&#125;, &#39;beauty&#39;: 66.19&#125;]&#125;&#125;
年龄预测为：22
性别预测为：male
颜值评分为：66.19
</code></pre>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">数据科学</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习与深度学习//" class="article-tag-list-link color5">机器学习与深度学习</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part3/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/3/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/5/">Next &amp;raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2024 John Doe
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">常用算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据科学</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">面试</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">聚宽</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">随笔</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">项目</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">推荐系统</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据仓库</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">贝叶斯</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">因子投资</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">NLP基础</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">考试</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://www.csdn.net/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>CSDN</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.zhihu.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>知乎</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.huaweicloud.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>华为云</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.aliyun.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>阿里云</a>
            </li>
          
            <li class="search-li">
              <a href="https://leetcode.cn/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>力扣</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.joinquant.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>聚宽</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">我叫王宇涵，东北人，本科和硕士分别毕业于哈尔滨工程大学和大连理工大学，2024年秋招拿到快手、百度、京东、科大讯飞、度小满、华为、荣耀、360等十余家企业offer，目前就职于快手数据平台部，担任数据研发工程师，专注于商业化广告业务。热爱大数据平台开发与数仓开发，技术栈包括但不限于Java、数仓建模、Hadoop、Hive、Spark、Flink、Clickhouse、Doris、数据湖、数据治理等。会不定期分享一些技术文章、业务知识、面试心得和读书笔记。</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>