<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://example.com">
  <title>Python大数据分析与机器学习商业案例实战-part2 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="5. 决策树模型5.1 决策树模型的基本原理5.1.1 决策树模型简介决策树是通过对一系列问题进行If&#x2F;else的推导，最终实现相关决策商业实战中是根据多个特征来预测离职概率，再根据相应的阈值来判断是否离职，例如，离职概率超过50%即认为员工会离职 几个概念：父节点、子节点、根节点、叶子节点 决策树主要是通过连续的逻辑判断得出最后的结论，其关键在于如何建立起这样一棵“树”，例如，根节点应">
<meta property="og:type" content="article">
<meta property="og:title" content="Python大数据分析与机器学习商业案例实战-part2">
<meta property="og:url" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="5. 决策树模型5.1 决策树模型的基本原理5.1.1 决策树模型简介决策树是通过对一系列问题进行If&#x2F;else的推导，最终实现相关决策商业实战中是根据多个特征来预测离职概率，再根据相应的阈值来判断是否离职，例如，离职概率超过50%即认为员工会离职 几个概念：父节点、子节点、根节点、叶子节点 决策树主要是通过连续的逻辑判断得出最后的结论，其关键在于如何建立起这样一棵“树”，例如，根节点应">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(46).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(1).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(2).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(3).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(4).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(5).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(6).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(7).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(8).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(9).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(10).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(11).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(12).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_71_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(13).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_107_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(14).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(15).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(16).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(17).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(18).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(19).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(20).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(21).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(22).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(23).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(24).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(25).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(26).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(27).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(28).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(29).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(30).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(31).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(32).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(33).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(34).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(35).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(36).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_221_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_223_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(37).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(38).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(39).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(40).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(41).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(42).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(43).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(44).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(45).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(47).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(48).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(49).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(50).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(51).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(52).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(53).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(54).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(55).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(56).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_340_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(57).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(58).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(59).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(60).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(61).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(62).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(63).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(64).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(65).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(66).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_387_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(67).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(68).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(69).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(70).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(71).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(72).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(73).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(74).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(75).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(76).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(77).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(78).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(79).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(80).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(81).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(82).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_499_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(83).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(84).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(85).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(86).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(87).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(88).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(89).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(90).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_604_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/output_614_0.png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(91).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(92).png">
<meta property="og:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(93).png">
<meta property="article:published_time" content="2023-02-02T13:13:14.000Z">
<meta property="article:modified_time" content="2023-02-02T14:14:35.521Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="数据科学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/%E4%B8%8B%E8%BD%BD%20(46).png">
  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div> 
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/psb.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/categories">分类</a></li>
	        
			</ul>
		</nav>
		<nav>
			总文章数 15
		</nav>		
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
		        
					<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
		        
					<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>



    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/psb.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
			        
						<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
			        
						<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/categories">分类</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-python大数据分析与机器学习商业案例实战-part2" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python大数据分析与机器学习商业案例实战-part2
    </h1>
  

        
        <a href="/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/" class="archive-article-date">
  	<time datetime="2023-02-02T13:13:14.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-02-02</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="5-决策树模型"><a href="#5-决策树模型" class="headerlink" title="5. 决策树模型"></a>5. 决策树模型</h1><h2 id="5-1-决策树模型的基本原理"><a href="#5-1-决策树模型的基本原理" class="headerlink" title="5.1 决策树模型的基本原理"></a>5.1 决策树模型的基本原理</h2><h3 id="5-1-1-决策树模型简介"><a href="#5-1-1-决策树模型简介" class="headerlink" title="5.1.1 决策树模型简介"></a>5.1.1 决策树模型简介</h3><p>决策树是通过对一系列问题进行If&#x2F;else的推导，最终实现相关决策<br><img src="%E4%B8%8B%E8%BD%BD%20(46).png" alt="下载 (46)"><br>商业实战中是根据多个特征来预测离职概率，再根据相应的阈值来判断是否离职，例如，离职概率超过50%即认为员工会离职</p>
<p>几个概念：父节点、子节点、根节点、叶子节点</p>
<p>决策树主要是通过连续的逻辑判断得出最后的结论，其关键在于如何建立起这样一棵“树”，例如，根节点应该选哪一个特征，选择不同特征会收到不同的效果。其次，收入是一个连续变量。选择收入&lt;10000元或选择收入&lt;100000元作为节点其结果也是不同的</p>
<h3 id="5-1-2-决策树模型的建树依据"><a href="#5-1-2-决策树模型的建树依据" class="headerlink" title="5.1.2 决策树模型的建树依据"></a>5.1.2 决策树模型的建树依据</h3><p><img src="%E4%B8%8B%E8%BD%BD.png" alt="下载"></p>
<p>例如，一个全部都是离职员工的样本中只有一个类别——离职员工，其出现的频率是100%，所以该系统的基尼系数为$1-1^2&#x3D;0$，表示该系统没有混乱，或者说该系统“纯度很高”。而如果样本中一半是离职员工，另一半是未离职员工，那么两个类别个数为2，每个类别出现的频率都为50%，所以基尼系数为$1-(0.5^2+0.5^2)&#x3D;0.5$,其混乱程度很高</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(1).png" alt="下载 (1)"></p>
<p>例如，一个初始样本中有1000个员工，其中已知有400人离职，600人不离职。划分前该系统的基尼系数为$1-(0.4^2+0.6^2)&#x3D;0.48$,下面采用两种方式决定根节点：一是根据“满意度&lt;5”进行分类；二是根据“收入&lt;10000元”进行分类</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(2).png" alt="下载 (2)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(3).png" alt="下载 (3)"></p>
<p>可以看到，划分前的基尼系数为0.48，以满意度&lt;5为根节点进行划分后的基尼系数为0.3，而以收入&lt;10000元为根节点进行划分后的基尼系数为0.45.基尼系数越低表示系统的混乱程度越低，区分度越高，越适合用于分类预测，<strong>因此这里选择满意度&lt;5作为根节点</strong></p>
<p>根节点下面的节点也是也是用类似方法来选择。例如，对于变量“收入”来说，是选择收入&lt;10000元，还是选择收入&lt;100000元作为划分依据，同样通过计算这两种情况下划分后的<strong>基尼系数</strong>来进行判断。若还有其他变量，如“工龄”，“月工时”等，也是通过类似方法计算划分后的基尼系数，<strong>再根据基尼系数判断如何划分节点</strong>，从而搭建出一个较为完善的决策树模型。<strong>采用基尼系数进行运算的决策树也称为CART决策树</strong></p>
<p><strong>补充知识点：信息熵</strong></p>
<p>除了基尼系数，还有一种衡量系统伦乱程度的经典手段——信息熵<br><img src="%E4%B8%8B%E8%BD%BD%20(4).png" alt="下载 (4)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(5).png" alt="下载 (5)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(6).png" alt="下载 (6)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(7).png" alt="下载 (7)"></p>
<p>基尼系数涉及平方运算，而信息熵涉及对数函数运算，因此目前决策树模型默认使用基尼系数作为建树依据，运算速度较快</p>
<h3 id="5-1-3-决策树模型的代码实现"><a href="#5-1-3-决策树模型的代码实现" class="headerlink" title="5.1.3 决策树模型的代码实现"></a>5.1.3 决策树模型的代码实现</h3><p>决策树模型既能做分类分析（<strong>即预测分类变量值</strong>），又能做回归分析（<strong>即预测连续变量值</strong>），对应的模型分别为分类决策树模型（DecisionTreeClassifier）和回归决策树模型（DecisonTreeRegressor）</p>
<p><strong>1.分类决策树模型（DecisionTreeClassifier）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier <span class="comment"># 引入分类决策树模型DecisionTreeClassifier</span></span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] <span class="comment"># X是特征变量，共有5个训练数据，每个数据有两个特征</span></span><br><span class="line">y = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>] <span class="comment"># 目标变量，共有两个类别——0和1</span></span><br><span class="line"></span><br><span class="line">model = DecisionTreeClassifier(random_state=<span class="number">0</span>) <span class="comment"># 引入模型并设置随机状态参数random_state为0，0无意义可以换成其他数字，种子参数，可使每次运行结果一致</span></span><br><span class="line">model.fit(X, y) <span class="comment"># 用fit()函数训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]])) <span class="comment"># 用predict()函数进行预测</span></span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<p>如果要同时预测多个数据，则可以写成如下形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>], [<span class="number">7</span>, <span class="number">7</span>], [<span class="number">9</span>, <span class="number">9</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[0 0 1]
</code></pre>
<p><img src="%E4%B8%8B%E8%BD%BD%20(8).png" alt="下载 (8)"><br>决策树可视化,</p>
<p>X[0]表示数据的第一个特征</p>
<p>X[1]表示数据的第二个特征</p>
<p>gini表示该节点的基尼系数，以根节点为列,$1-(0.4^2+0.6^2)&#x3D;0.48$</p>
<p>sanples表示该节点的样本数</p>
<p>value表示各分类的样本数，例如，根节点中的[2,3]表示分类为0的样本数为2，分类为1的样本数为3</p>
<p>class表示该区块被划分为的类别，它是由value中样本数较多的类别决定的</p>
<p>以数据[5,5]为例，在根节点时，它满足X[1]（即第2个特征数值）小于等于7的条件，所以被划分到左边的子节点。在孩子节点又进行一次判断，判断X[0]是否小于等于2，因为X[0]为5，不满足该条件，所以划分到孩子节点的右边的子节点，而孩子节点的类别class为0，所以[5,5]在该决策树模型中被预测为类别0</p>
<p><strong>决策树可视化不重要，不用看了</strong></p>
<p><strong>2.回归决策树模型（DecisionTreeRegressor）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] <span class="comment"># X是特征变量，共有两个特征</span></span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]  <span class="comment"># 目标变量，为一个连续变量</span></span><br><span class="line"></span><br><span class="line">model = DecisionTreeRegressor(max_depth=<span class="number">2</span>, random_state=<span class="number">0</span>) <span class="comment"># 设置决策树最大深度为2，随机状态参数为0</span></span><br><span class="line">model.fit(X, y) <span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">9</span>, <span class="number">9</span>]])) <span class="comment"># 对数据进行预测</span></span><br></pre></td></tr></table></figure>

<pre><code>[4.5]
</code></pre>
<p><img src="%E4%B8%8B%E8%BD%BD%20(9).png" alt="下载 (9)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(10).png" alt="下载 (10)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(11).png" alt="下载 (11)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(12).png" alt="下载 (12)"></p>
<h2 id="5-2-案例实战：员工离职预测模型搭建"><a href="#5-2-案例实战：员工离职预测模型搭建" class="headerlink" title="5.2 案例实战：员工离职预测模型搭建"></a>5.2 案例实战：员工离职预测模型搭建</h2><h3 id="5-2-1-模型搭建"><a href="#5-2-1-模型搭建" class="headerlink" title="5.2.1 模型搭建"></a>5.2.1 模型搭建</h3><p>通过已有的员工信息和离职表现来搭建相应的员工离职预测模型，可以预测之后的员工是否会离职</p>
<p><strong>1.数据读取与预处理</strong></p>
<p>首先读取员工信息以及其交易离职表现，即是否离职记录，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;员工离职预测模型.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>工资</th>
      <th>满意度</th>
      <th>考核得分</th>
      <th>工程数量</th>
      <th>月工时</th>
      <th>工龄</th>
      <th>离职</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>低</td>
      <td>3.8</td>
      <td>0.53</td>
      <td>2</td>
      <td>157</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>中</td>
      <td>8.0</td>
      <td>0.86</td>
      <td>5</td>
      <td>262</td>
      <td>6</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>中</td>
      <td>1.1</td>
      <td>0.88</td>
      <td>7</td>
      <td>272</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>低</td>
      <td>7.2</td>
      <td>0.87</td>
      <td>5</td>
      <td>223</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>低</td>
      <td>3.7</td>
      <td>0.52</td>
      <td>2</td>
      <td>159</td>
      <td>3</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>数据解读：离职列中，1表示离职，0表示未离职，该表格共有15000组历史数据，前3571组为离职数据，后11429组为非离职员工数据。我们的目的就是根据这些历史数据搭建决策树模型来预测之后员工的离职可能性</p>
<p>处理文本内容，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = df.replace(&#123;<span class="string">&#x27;工资&#x27;</span>: &#123;<span class="string">&#x27;低&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;中&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;高&#x27;</span>: <span class="number">2</span>&#125;&#125;)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>工资</th>
      <th>满意度</th>
      <th>考核得分</th>
      <th>工程数量</th>
      <th>月工时</th>
      <th>工龄</th>
      <th>离职</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3.8</td>
      <td>0.53</td>
      <td>2</td>
      <td>157</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>8.0</td>
      <td>0.86</td>
      <td>5</td>
      <td>262</td>
      <td>6</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1.1</td>
      <td>0.88</td>
      <td>7</td>
      <td>272</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>7.2</td>
      <td>0.87</td>
      <td>5</td>
      <td>223</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3.7</td>
      <td>0.52</td>
      <td>2</td>
      <td>159</td>
      <td>3</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>将表格中的“离职”列表作为目标变量，剩下的字段作为特征变量，通过一个员工的特征来判断其是否会离职</p>
<p><strong>2.提取特征变量和目标变量</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = df.drop(columns=<span class="string">&#x27;离职&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;离职&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p><strong>3.划分训练集和测试集</strong></p>
<p>提取完特征变量和目标变量后，还需要将原来的15000组数据划分为训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment"># 导入train_test_split()函数</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br><span class="line"><span class="comment"># X和y就是之前提取的特征变量和目标变量，test_size是测试集数据所占的比例，这里设置为0.2</span></span><br><span class="line"><span class="comment"># 如果数据量多，也可以将其设置为0.1，即分配更少比例的数据用于测试，分配更多比例的</span></span><br><span class="line"><span class="comment"># 数据用于训练，设置random_state参数是为了每次划分数据的结果保持一致</span></span><br></pre></td></tr></table></figure>

<p><strong>4.模型训练及搭建</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">model = DecisionTreeClassifier(max_depth=<span class="number">3</span>, random_state=<span class="number">123</span>) <span class="comment"># 设置树的最大深度参数为3 </span></span><br><span class="line">model.fit(X_train, y_train) <span class="comment"># 训练函数</span></span><br></pre></td></tr></table></figure>




<pre><code>DecisionTreeClassifier(max_depth=3, random_state=123)
</code></pre>
<p>至此，模型训练完成</p>
<h3 id="5-2-2-模型预测及评估"><a href="#5-2-2-模型预测及评估" class="headerlink" title="5.2.2 模型预测及评估"></a>5.2.2 模型预测及评估</h3><p><strong>1.直接预测是否离职</strong></p>
<p>这里把测试集中的数据导入模型中进行预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred[<span class="number">0</span>:<span class="number">100</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0
 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0]
</code></pre>
<p>y_pred是一个numpy.ndarray类型的数组结构，y_test为Series类型的一维序列结构，都把它们转换成列表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过构造DataFrame进行对比</span></span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果要查看整体的预测准确度，可以采用如下代码：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9573333333333334
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 或者用模型自带的score函数查看预测准确度</span></span><br><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.9573333333333334
</code></pre>
<p><strong>2.预测不离职&amp;离职概率</strong></p>
<p>其实分类决策树模型本质预测的并不是准确的0或1的分类，而是预测其属于某一分类的概率，可以通过如下代码查看预测属于各个分类的概率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred_proba = model.predict_proba(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred_proba[<span class="number">0</span>:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[[0.98526077 0.01473923]
 [0.98526077 0.01473923]
 [0.28600613 0.71399387]
 [0.98526077 0.01473923]
 [0.92283214 0.07716786]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = pd.DataFrame(y_pred_proba, columns=[<span class="string">&#x27;不离职概率&#x27;</span>, <span class="string">&#x27;离职概率&#x27;</span>]) </span><br><span class="line">b.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>不离职概率</th>
      <th>离职概率</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.985261</td>
      <td>0.014739</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.985261</td>
      <td>0.014739</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.286006</td>
      <td>0.713994</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.985261</td>
      <td>0.014739</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.922832</td>
      <td>0.077168</td>
    </tr>
  </tbody>
</table>
</div>



<p>如果想查看离职概率，即查看y_pred_proba的第二列，可以采用如下代码，这个是二维数组选取列的方法，其中逗号前的“:”表示所有行，逗号后面的数字1则表示第二列，如果把数字1改成数字0，则提取第一列不离职概率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred_proba[:,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([0.01473923, 0.01473923, 0.71399387, ..., 0.01473923, 0.94594595,
       0.01473923])
</code></pre>
<p><strong>3.模型预测效果评估</strong></p>
<p>在Python实现上，通过4.3节讲过的代码就可以求出在不同阈值下的命中率（TPR）以及假警报率（FPR）的值，从而可以绘制ROC曲线。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>通过4.3节相关代码可以查看不同阈值下的假警报率和命中率，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;阈值&#x27;</span>] = <span class="built_in">list</span>(thres)</span><br><span class="line">a[<span class="string">&#x27;假警报率&#x27;</span>] = <span class="built_in">list</span>(fpr)</span><br><span class="line">a[<span class="string">&#x27;命中率&#x27;</span>] = <span class="built_in">list</span>(tpr)</span><br><span class="line">a</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>阈值</th>
      <th>假警报率</th>
      <th>命中率</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.247110</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.945946</td>
      <td>0.008232</td>
      <td>0.677746</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.713994</td>
      <td>0.038128</td>
      <td>0.942197</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.077168</td>
      <td>0.159879</td>
      <td>0.969653</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.059406</td>
      <td>0.171577</td>
      <td>0.972543</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.045763</td>
      <td>0.240035</td>
      <td>0.976879</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.014739</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>



<p>第二行表示只有当某员工被预测为离职的概率≥100%（因为概率不会超过100%，所以其实就是被预测为离职的概率等于100%），才判定其离职，此时命中率为24.7%，即所有的实际离职的员工中被预测为离职的员工占24.7%，在这种极端的阈值条件下，该命中率已经算是很高了。第三行表示只有当某员工被预测为离职的概率≥94.6%，才判定其会离职，此时命中率为67.8%，假警报率为0.82%，以此类推</p>
<p>已知了不同阈值下的假警报率和命中率，可通过matplotlib库可绘制ROC曲线，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  <span class="comment"># 当时运行代码时找不到指定文件，升级一下matplotlib包就好了，</span></span><br><span class="line">                                 <span class="comment"># 可能时是当初jupyternotebook版本太老，它自带的三个库版本也老</span></span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_71_0.png" alt="output_71_0"></p>
<p>通过如下代码则可以快速求出模型的AUC值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">score = roc_auc_score(y_test, y_pred_proba[:,<span class="number">1</span>]) <span class="comment"># 传入测试集的目标变量y_test及预测的离职概率</span></span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9736722483245008
</code></pre>
<p><strong>4.特征重要性评估</strong></p>
<p>搭建完模型后，有时还要知道各个特征变量的重要程度，即哪些特征变量在模型中发挥的作用更大，这个重要性程度称为特征重要性。在决策树模型中，一个特征变量对模型整体基尼系数下降的贡献越大，它的特征重要性就越大</p>
<p>通过如下代码可以查看决策树模型中各个特征变量的重要性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure>




<pre><code>array([0.        , 0.59810862, 0.14007392, 0.10638659, 0.00456495,
       0.15086592])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过DataFrame进行展示，并根据重要性进行倒序排列</span></span><br><span class="line">features = X.columns  <span class="comment"># 获取特征名称</span></span><br><span class="line">importances = model.feature_importances_  <span class="comment"># 获取特征重要性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过二维表格形式显示</span></span><br><span class="line">importances_df = pd.DataFrame()</span><br><span class="line">importances_df[<span class="string">&#x27;特征名称&#x27;</span>] = features</span><br><span class="line">importances_df[<span class="string">&#x27;特征重要性&#x27;</span>] = importances</span><br><span class="line">importances_df.sort_values(<span class="string">&#x27;特征重要性&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>特征名称</th>
      <th>特征重要性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>满意度</td>
      <td>0.598109</td>
    </tr>
    <tr>
      <th>5</th>
      <td>工龄</td>
      <td>0.150866</td>
    </tr>
    <tr>
      <th>2</th>
      <td>考核得分</td>
      <td>0.140074</td>
    </tr>
    <tr>
      <th>3</th>
      <td>工程数量</td>
      <td>0.106387</td>
    </tr>
    <tr>
      <th>4</th>
      <td>月工时</td>
      <td>0.004565</td>
    </tr>
    <tr>
      <th>0</th>
      <td>工资</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以看到，特征重要性最高的是“满意度”，而“工资”在模型中特征重要性为0，也就是说它没有发挥作用，这并不符合常理，之所以会有这个结果，在某种程度上是因为我们限制了决策树的最大深度为3层，所以“工资”没有发挥作用的机会，如果增大决策树的最大深度，那么它可能会发挥作用，这一点在5.3.2小节会进行验证。另一个重要的原因是本案例中“工资”不是具体的数值，而是“高”“中”“低”三个档次，这种划分过于宽泛，使得特征变量在决策树模型中发挥的作用较小，如果“工资”是具体的数值，如10000元，那么该特征变量应该会发挥更大的作用</p>
<h2 id="5-3-参数调优-K折交叉验证-amp-GridSearch网格搜索"><a href="#5-3-参数调优-K折交叉验证-amp-GridSearch网格搜索" class="headerlink" title="5.3 参数调优 - K折交叉验证 &amp; GridSearch网格搜索"></a>5.3 参数调优 - K折交叉验证 &amp; GridSearch网格搜索</h2><p>机器学习的各个模型其实都有一些内置的参数，如max_depth（树的最大深度），这种参数又称为超参数，除了这个还有一些参数：</p>
<p><strong>分类决策树模型DecisionTreeClassifier（）的常用超参数</strong>：</p>
<p><strong>criterion</strong>：特征选择标准，取值为’entropy’（信息熵）和’gini’（基尼系数），默认值为’gini’</p>
<p><strong>splitter</strong>：取值为’best’和’random’。’best’指在特征的所有划分点中找出最优的划分点，适合样本量不大的情况；random指随机地在部分划分点中寻找局部最优的划分点，适合样本量非常大的情况，默认值为best</p>
<p><strong>max_depth</strong>：决策树最大深度，取值为int型或None，默认值为None，一般数据或特征较少的时候可以不设置，如果数据或特征较多，可以设置最大深度进行限制</p>
<p><strong>min_samples_split</strong>：子节点往下分裂所需的最小样本数，默认值为2，如果子节点中的样本数小于该值则停止分裂</p>
<p><strong>min_samples_leaf</strong>：叶子节点的最小样本数，默认值为1.如果叶子节点中的样本数小于该值，该叶子节点会和兄弟节点一起被剪枝，即剔除该叶子节点和其兄弟节点，并停止分类</p>
<p><strong>min_weight_fraction_leaf</strong>：叶子节点最小的样本权重和，默认值为0，即不考虑权重问题，如果小于该值，该叶子节点会和兄弟节点一起被剪枝。如果较多样本有缺失值或者样本的分布类别偏差很大，则需要考虑样本权重的问题</p>
<p><strong>max_features</strong>：在划分节点时所考虑的特征值数量的最大值，默认值为None，可以传入int型或float型数据，如果传入的是float型数据，则表示百分比</p>
<p><strong>max_leaf_nodes</strong>：最大叶子节点数，默认值为None，可以传入int型数据</p>
<p><strong>class_weight</strong>：指定类别权重，默认值为None，可以取balanced，代表样本量少的类别所对应的样本权重更高，也可以传入字典来指定权重，该参数主要是为防止训练集中某些类别的样本过多，导致训练的决策树过于偏向这些类别。处理指定参数，还可以使用过采样和欠采样的方法处理样本类别不平衡的问题，在11章讲解</p>
<p><strong>random_state</strong>：当数据量较大或特征变量较多，可能在某个节点划分时，会遇到两个特征变量的信息增益或基尼系数下降值相同的情况，此时决策树模型会默认从中随机选择一个特征变量进行划分，这样可能会导致每次运行程序后生成的决策树不一致。设置random_state参数可以保证每次运行程序后各节点的分裂结果都是一致的，这在特征变量较多、树的深度较深时较为重要</p>
<p>大多数情况下，使用模型的默认参数也能获得较好的结果及预测准确度，然而如果想要获得更准确的结果，就需要对模型的超参数进行调优。例如max_depth取3还是取默认值None（即不限制最大深度，分裂到所有叶子节点的基尼系数都为0）是有讲究的，如果取值过小，可能会导致模型欠拟合，如果取值过大，则会容易过拟合，因此需要一个手段来合理地调节模型参数。</p>
<p>本节介绍调节模型参数的常用方法GridSearch网格搜索，以及常与其搭配使用的K折交叉验证</p>
<h3 id="5-3-1-K折交叉验证"><a href="#5-3-1-K折交叉验证" class="headerlink" title="5.3.1 K折交叉验证"></a>5.3.1 K折交叉验证</h3><p>在机器学习中，因为训练集和测试集的数据划分是随机的，所以有时候会<strong>重复</strong>地使用数据，以便更好地评估模型的有效性，并选出最好的模型，该做法称为<strong>交叉验证</strong>。具体而言就是对原始样本数据进行切分，然后组合成为<strong>多组不同</strong>的训练集和测试集，用训练集训练模型，用测试集评估模型。某次的训练集可能是下次的测试集，故而称为交叉验证。</p>
<p>交叉验证的方法有三种：简单交叉验证，K折交叉验证和留一交叉验证。K折交叉验证应用较为广泛，它是指将数据集随机等分为K份，每一次选取K-1份作为训练集，用剩下的的1份作为测试集，得到K个模型后将者K个模型的平均测试效果作为最终的模型效果<br><img src="%E4%B8%8B%E8%BD%BD%20(13).png"><br>通常来说，如果<strong>训练集相对较小</strong>，则<strong>增大K值</strong>，这样每次迭代过程中将会有更多的数据用于模型训练，同时算法的时间延迟；如果<strong>训练集相对较大</strong>，则<strong>减小K值</strong>，这样可以降低模型在不同的数据块上进行重复拟合性能评估的计算成本，在平均性能的基础上获得模型的准确评估。</p>
<p>除了更精确地评估模型，交叉验证的另一个重要的作用就是利用更精确的评估结果对模型进行<strong>参数调优</strong>，它经常与GridSeatch网格搜索配合使用</p>
<p><strong>前情提要 - 5.2节的模型搭建代码</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.读取数据与简单预处理</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;员工离职预测模型.xlsx&#x27;</span>)</span><br><span class="line">df = df.replace(&#123;<span class="string">&#x27;工资&#x27;</span>: &#123;<span class="string">&#x27;低&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;中&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;高&#x27;</span>: <span class="number">2</span>&#125;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.提取特征变量和目标变量</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;离职&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;离职&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.划分训练集和测试集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.模型训练及搭建</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">model = DecisionTreeClassifier(max_depth=<span class="number">3</span>, random_state=<span class="number">123</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>DecisionTreeClassifier(max_depth=3, random_state=123)
</code></pre>
<p>通过以下代码可以实现K折交叉验证，并获得每次验证的得分结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score  <span class="comment"># 引入交叉验证函数</span></span><br><span class="line">acc = cross_val_score(model, X, y, cv=<span class="number">5</span>) <span class="comment"># 传入参数为模型名称model，特征变量数据X，目标变量数据y，交叉验证的次数cv（即K值）</span></span><br><span class="line">                                         <span class="comment"># 每次随机取4/5的数据用于训练，1/5的数据用于测试，默认交叉验证3次</span></span><br><span class="line">                                         <span class="comment"># 这里没有设置scoring参数，表示默认值accuracy（精确度）作为评估标准</span></span><br><span class="line">acc  <span class="comment"># 打印acc来查看5次交叉验证得到的打分，结果如下</span></span><br></pre></td></tr></table></figure>




<pre><code>array([0.96666667, 0.96066667, 0.959     , 0.96233333, 0.91366667])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">acc.mean()</span><br></pre></td></tr></table></figure>




<pre><code>0.9524666666666667
</code></pre>
<p>以ROC曲线的AUC值作为评估标准，则可以设置scoring参数为roc_auc</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">acc = cross_val_score(model, X, y, scoring=<span class="string">&#x27;roc_auc&#x27;</span>, cv=<span class="number">5</span>)</span><br><span class="line">acc</span><br></pre></td></tr></table></figure>




<pre><code>array([0.97146884, 0.9674637 , 0.96641351, 0.97047305, 0.95030156])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">acc.mean()</span><br></pre></td></tr></table></figure>




<pre><code>0.9652241309284616
</code></pre>
<h3 id="5-3-2-GridSearch网格搜索"><a href="#5-3-2-GridSearch网格搜索" class="headerlink" title="5.3.2 GridSearch网格搜索"></a>5.3.2 GridSearch网格搜索</h3><p>GridSearch网格搜索时一种<strong>穷举搜索</strong>的参数调优手段：遍历所有的候选参数，循环建立模型并评估模型的有效性和准确性，选取<strong>表现最好的参数</strong>作为最终结果。以决策树最大深度参数max_depth为例，我们可以在[1,3,5,7,9]这些值中遍历，以准确度或ROC曲线的AUC值作为评估标准来搜索最合适的max_depth值，如果要同时调节多个模型参数，例如，模型有2个参数，第一个参数有4种可能，第2个参数有5种可能，所有的可能性可以表示成4x5的网格，那么遍历的过程就像是在网格里搜索</p>
<p><strong>1.单参数的参数调优</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV  <span class="comment"># 网格搜索合适的超参数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定参数k的范围</span></span><br><span class="line">parameters = &#123;<span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>]&#125;</span><br><span class="line"><span class="comment"># 构建决策树分类器</span></span><br><span class="line">model = DecisionTreeClassifier()  <span class="comment"># 这里因为要进行参数调优，所以不需要传入固定的参数了</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 网格搜索</span></span><br><span class="line">grid_search = GridSearchCV(model, parameters, scoring=<span class="string">&#x27;roc_auc&#x27;</span>, cv=<span class="number">5</span>)   <span class="comment"># cv=5表示交叉验证5次，默认值为3；scoring=&#x27;roc_auc&#x27;表示通过ROC曲线的AUC值来进行评分，默认通过准确度评分</span></span><br><span class="line">grid_search.fit(X_train, y_train) <span class="comment"># 传入测试数据并开始进行参数调优</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出参数的最优值</span></span><br><span class="line">grid_search.best_params_</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;max_depth&#39;: 7&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过取消如下代码的注释可以查看GridSearchCV函数的官方介绍</span></span><br><span class="line">GridSearchCV?</span><br></pre></td></tr></table></figure>

<p>因为max_depth参数设置了5个候选值，又设置了5折交叉验证，所以对于每个候选值，模型都会运行5遍（公运行5x5&#x3D;25遍），每个候选值都通过5折交叉验证获得一个平均分，根据平均分进行排序，得到决策树的最大深度设置为7时最优</p>
<p><strong>补充知识点：批量生成调参所需数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">parameters = &#123;<span class="string">&#x27;max_depth&#x27;</span>: np.arange(<span class="number">1</span>, <span class="number">10</span>, <span class="number">2</span>)&#125;</span><br></pre></td></tr></table></figure>

<p><strong>参数调优的效果检验</strong></p>
<p>根据max_depth&#x3D;7来重新搭建模型，并进行检测查看新模型的预测准确度及ROC曲线的AUC值来验证参数调优后是否提高了模型的有效性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据max_depth=7来重新搭建模型</span></span><br><span class="line">model = DecisionTreeClassifier(max_depth=<span class="number">7</span>)  <span class="comment"># 这个max_depth参数是可以调节的，之后讲</span></span><br><span class="line">model.fit(X_train, y_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看整体预测准确度</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.982
</code></pre>
<p>与原模型在测试集上的预测准确度0.957相比，参数调优之后预测准确度有所上升。其实预测准确度也可能下降，因为参数调优时是以ROC曲线的AUC值作为评估标准的，而非预测准确度</p>
<p><strong>查看新模型的ROC曲线和AUC值</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看新的AUC值</span></span><br><span class="line"><span class="comment"># 预测不违约&amp;违约概率</span></span><br><span class="line">y_pred_proba = model.predict_proba(X_test)</span><br><span class="line">y_pred_proba[:,<span class="number">1</span>]  <span class="comment"># 如果想单纯的查看违约概率，即查看y_pred_proba的第二列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制ROC曲线，计算AUC值</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制ROC曲线</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_107_0.png" alt="output_107_0"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算AUC值，得到0.987，与参数调优前的AUC值0.973相比，模型有效性的确有所提高</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">score = roc_auc_score(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9878194468097895
</code></pre>
<p>总结：原来获得的AUC值为0.9736，现在获得的AUC值为0.9877，的确提高了模型的预测水平</p>
<p><strong>补充：决策树深度增加时特征重要性的改变</strong></p>
<p>参数调优后，决策树模型的深度从3增加到7，树的子节点和叶子节点都会有所增加，特征重要性也可能发生变化，通过如下代码可以查看参数调优后新模型中各个特征变量的特征重要性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看此时的变量重要性</span></span><br><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure>




<pre><code>array([0.00059222, 0.52718305, 0.13201648, 0.1116004 , 0.07731135,
       0.1512965 ])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一一对应</span></span><br><span class="line">features = X.columns</span><br><span class="line">importances = model.feature_importances_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过表格形式显示</span></span><br><span class="line">importances_df = pd.DataFrame()  <span class="comment"># 创建空二维表格，为之后准备</span></span><br><span class="line">importances_df[<span class="string">&#x27;特征名称&#x27;</span>] = features</span><br><span class="line">importances_df[<span class="string">&#x27;特征重要性&#x27;</span>] = importances</span><br><span class="line"></span><br><span class="line">importances_df.sort_values(<span class="string">&#x27;特征重要性&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>特征名称</th>
      <th>特征重要性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>满意度</td>
      <td>0.527183</td>
    </tr>
    <tr>
      <th>5</th>
      <td>工龄</td>
      <td>0.151297</td>
    </tr>
    <tr>
      <th>2</th>
      <td>考核得分</td>
      <td>0.132016</td>
    </tr>
    <tr>
      <th>3</th>
      <td>工程数量</td>
      <td>0.111600</td>
    </tr>
    <tr>
      <th>4</th>
      <td>月工时</td>
      <td>0.077311</td>
    </tr>
    <tr>
      <th>0</th>
      <td>工资</td>
      <td>0.000592</td>
    </tr>
  </tbody>
</table>
</div>



<p>对比原模型的特征变量的特征重要性，可以发现“工资”的特征重要性从0上升到0.000592，这是因为决策树增加了节点使用“工资”作为分裂的依据，也验证了5.2.2小节末尾的猜测：如果增大决策树的最大深度，那么“工资”可能会发挥作用</p>
<p><strong>2.多参数调优</strong></p>
<p>除了可以进行单参数调优，网格搜索还可以进行多参数调优。下面选择DecisionTreeClassifier()函数的3个超参数max_depth（最大深度），criterion（特征选择标准）和min_samples_split（子节点往下分裂所需的最小样本数），使用GridSearchCV（）函数进行多参数调优</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定决策树分类器中各个参数的范围</span></span><br><span class="line">parameters = &#123;<span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">13</span>], <span class="string">&#x27;criterion&#x27;</span>:[<span class="string">&#x27;gini&#x27;</span>, <span class="string">&#x27;entropy&#x27;</span>], <span class="string">&#x27;min_samples_split&#x27;</span>:[<span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">13</span>, <span class="number">15</span>]&#125;</span><br><span class="line"><span class="comment"># 构建决策树分类器</span></span><br><span class="line">model = DecisionTreeClassifier()  <span class="comment"># 这里因为要进行参数调优，所以不需要传入固定的参数了</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 网格搜索</span></span><br><span class="line">grid_search = GridSearchCV(model, parameters, scoring=<span class="string">&#x27;roc_auc&#x27;</span>, cv=<span class="number">5</span>)</span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得参数的最优值</span></span><br><span class="line">grid_search.best_params_</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 11, &#39;min_samples_split&#39;: 13&#125;
</code></pre>
<p>将criterion设置为entropy信息熵，max_depth设置为11，min_samples_split设置为13时，模型最优，将这些参数的最优值引入模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据多参数调优的结果来重新搭建模型</span></span><br><span class="line">model = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>, max_depth=<span class="number">11</span>, min_samples_split=<span class="number">13</span>)</span><br><span class="line">model.fit(X_train, y_train) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看整体预测准确度</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9823333333333333
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看新的AUC值</span></span><br><span class="line"><span class="comment"># 预测不违约&amp;违约概率</span></span><br><span class="line">y_pred_proba = model.predict_proba(X_test)</span><br><span class="line">y_pred_proba[:,<span class="number">1</span>]  <span class="comment"># 如果想单纯的查看违约概率，即查看y_pred_proba的第二列</span></span><br><span class="line"></span><br><span class="line">score = roc_auc_score(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9880075960970136
</code></pre>
<p>总结：这里多参数调优后发现，模型效果的确有所优化</p>
<p><strong>注意点1：多参数调优和分别单参数调优的区别</strong></p>
<p>多参数调优和单参数分别调优是有区别的，比如有的读者为了省事，对上面的3个参数进行3次单独的单参数调优，然后将结果汇总，这样的做法其实是不严谨的。因为在进行单参数调优的时候，是默认其他参数取默认值的，那么该参数和其他参数都不取默认值的情况就没有考虑进来，也即忽略了多个参数对模型的组合影响。以上面的代码示例来说，使用多参数调优时，它是5<em>2</em>6&#x3D;60种组合可能，而如果是进行3次单参数调优，则只是5+2+6&#x3D;13种组合可能。<br>因此，如果只需要调节一个参数，那么可以使用单参数调优，如果需要调节多个参数，则推荐使用多参数调优。</p>
<p><strong>注意点2：参数取值是给定范围的边界</strong></p>
<p>另外一点需要需要注意的是，<strong>如果使用GridSearchCV()方法所得到的参数取值是给定范围的边界，那么有可能存在范围以外的取值使得模型效果更好</strong>，因此需要我们<strong>额外增加范围，继续调参</strong>。举例来说，倘若上述代码中获得的最佳max_depth值为设定的最大值13，那么实际真正合适的max_depth可能更大，此时便需要将搜索网格重新调整，如将max_depth的搜索范围变成[9, 11, 13, 15, 17]，再重新参数调优。</p>
<p><strong>补充：决策树的前剪枝和后剪枝</strong></p>
<p>决策树剪枝的目的是防止构建的决策树出现<strong>过拟合</strong>。决策树剪枝分为前剪枝和后剪枝</p>
<p><strong>前剪枝</strong>：从上往下剪枝，通常利用超参数进行剪枝。例如，通过限制树的最大深度便能减去该最大深度下面的节点</p>
<p><strong>后剪枝</strong>：从下往上剪枝，大多是根据业务需求剪枝，例如，在违约预测模型中，认为违约概率为45%和50%的两个叶子节点都是高危人群，那么就把这两个叶子节点合并成一个节点</p>
<p>在商业实战中，前剪枝应用的更广泛，参数调优其实也起到了一定的前剪枝作用</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(14).png" alt="下载 (14)"></p>
<h1 id="6-朴素贝叶斯模型"><a href="#6-朴素贝叶斯模型" class="headerlink" title="6 朴素贝叶斯模型"></a>6 朴素贝叶斯模型</h1><h2 id="6-1-朴素贝叶斯模型的算法原理"><a href="#6-1-朴素贝叶斯模型的算法原理" class="headerlink" title="6.1 朴素贝叶斯模型的算法原理"></a>6.1 朴素贝叶斯模型的算法原理</h2><p><img src="%E4%B8%8B%E8%BD%BD%20(15).png" alt="下载 (15)"></p>
<h3 id="6-1-1-一维特征变量下的贝叶斯模型"><a href="#6-1-1-一维特征变量下的贝叶斯模型" class="headerlink" title="6.1.1 一维特征变量下的贝叶斯模型"></a>6.1.1 一维特征变量下的贝叶斯模型</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(16).png" alt="下载 (16)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(17).png" alt="下载 (17)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(18).png" alt="下载 (18)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(19).png" alt="下载 (19)"></p>
<h3 id="6-1-2-二维特征向量下单贝叶斯模型"><a href="#6-1-2-二维特征向量下单贝叶斯模型" class="headerlink" title="6.1.2 二维特征向量下单贝叶斯模型"></a>6.1.2 二维特征向量下单贝叶斯模型</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(20).png" alt="下载 (20)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(21).png" alt="下载 (21)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(22).png" alt="下载 (22)"></p>
<p>（1）独立性假设</p>
<p>在计算该概率之前，我们首先引入朴素贝叶斯模型的独立性假设：朴素贝叶斯模型中各特征之间相互独立，即，因此上式可以写作<br><img src="%E4%B8%8B%E8%BD%BD%20(23).png" alt="下载 (23)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(24).png" alt="下载 (24)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(25).png" alt="下载 (25)"></p>
<h3 id="6-1-3-n维特征变量下的贝叶斯模型"><a href="#6-1-3-n维特征变量下的贝叶斯模型" class="headerlink" title="6.1.3 n维特征变量下的贝叶斯模型"></a>6.1.3 n维特征变量下的贝叶斯模型</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(26).png" alt="下载 (26)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(27).png" alt="下载 (27)"></p>
<h3 id="6-1-4-朴素贝叶斯模型简单代码演示"><a href="#6-1-4-朴素贝叶斯模型简单代码演示" class="headerlink" title="6.1.4 朴素贝叶斯模型简单代码演示"></a>6.1.4 朴素贝叶斯模型简单代码演示</h3><p>通过如下代码引入朴素贝叶斯模型（这里用的是高斯贝叶斯分类器）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]] <span class="comment"># 特征变量，共有两个特征</span></span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>] <span class="comment"># 目标变量，共有两个类别0，1</span></span><br><span class="line"></span><br><span class="line">model = GaussianNB()</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GaussianNB?</span><br></pre></td></tr></table></figure>

<h2 id="6-2-案例实战：肿瘤预测模型"><a href="#6-2-案例实战：肿瘤预测模型" class="headerlink" title="6.2 案例实战：肿瘤预测模型"></a>6.2 案例实战：肿瘤预测模型</h2><h3 id="6-2-1-案例背景"><a href="#6-2-1-案例背景" class="headerlink" title="6.2.1 案例背景"></a>6.2.1 案例背景</h3><h3 id="6-2-2-数据读取与划分"><a href="#6-2-2-数据读取与划分" class="headerlink" title="6.2.2 数据读取与划分"></a>6.2.2 数据读取与划分</h3><p>1.数据读取</p>
<p>首先通过如下代码导入某医院乳腺肿瘤患者的6个特征维度及肿瘤性质的数据。共569个患者，其中良性肿瘤358例，恶性肿瘤211例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;肿瘤数据.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>最大周长</th>
      <th>最大凹陷度</th>
      <th>平均凹陷度</th>
      <th>最大面积</th>
      <th>最大半径</th>
      <th>平均灰度值</th>
      <th>肿瘤性质</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>184.60</td>
      <td>0.2654</td>
      <td>0.14710</td>
      <td>2019.0</td>
      <td>25.38</td>
      <td>17.33</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>158.80</td>
      <td>0.1860</td>
      <td>0.07017</td>
      <td>1956.0</td>
      <td>24.99</td>
      <td>23.41</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>152.50</td>
      <td>0.2430</td>
      <td>0.12790</td>
      <td>1709.0</td>
      <td>23.57</td>
      <td>25.53</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>98.87</td>
      <td>0.2575</td>
      <td>0.10520</td>
      <td>567.7</td>
      <td>14.91</td>
      <td>26.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>152.20</td>
      <td>0.1625</td>
      <td>0.10430</td>
      <td>1575.0</td>
      <td>22.54</td>
      <td>16.67</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>0代表肿瘤为恶性，1代表肿瘤为良性</p>
<p>2.划分特征变量和目标变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = df.drop(columns=<span class="string">&#x27;肿瘤性质&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;肿瘤性质&#x27;</span>]   </span><br></pre></td></tr></table></figure>

<h3 id="6-2-3-模型的搭建与使用"><a href="#6-2-3-模型的搭建与使用" class="headerlink" title="6.2.3 模型的搭建与使用"></a>6.2.3 模型的搭建与使用</h3><p>1.划分训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>2.模型搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB <span class="comment"># 高斯朴素贝叶斯适用于任何连续数值型的数据集</span></span><br><span class="line">nb_clf = GaussianNB()  <span class="comment"># 高斯朴素贝叶斯模型</span></span><br><span class="line">nb_clf.fit(X_train,y_train)</span><br></pre></td></tr></table></figure>




<pre><code>GaussianNB()
</code></pre>
<p>3.模型预测与评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = nb_clf.predict(X_test)</span><br><span class="line">y_pred[:<span class="number">100</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,
       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,
       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,
       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1], dtype=int64)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a =pd.DataFrame() <span class="comment"># 创建一个空DataFrame</span></span><br><span class="line">a[<span class="string">&#x27;预测试&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测试</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以看到前5项的预测准确率为80%，通过如下代码可以查看所有测试集数据的预测精准度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.9473684210526315
</code></pre>
<p>朴素贝叶斯模型属于分类模型，所以也可以利用ROC曲线来评估其预测效果</p>
<p>朴素贝叶斯模型是一种非常典型的机器学习模型，它主要基于贝叶斯公式，在应用过程中会把数据集中的特征看成是相互独立的，而不需要考虑特征时间的关联关系，因此运算速度比较快。相比于其他经典的机器学习模型，朴素贝叶斯模型的泛化能力较弱，不过当样本及特征的数量增加时，其预测效果也是很不错的</p>
<h1 id="7-K近邻算法"><a href="#7-K近邻算法" class="headerlink" title="7 K近邻算法"></a>7 K近邻算法</h1><h2 id="7-1-K近邻算法的原理和代码实现"><a href="#7-1-K近邻算法的原理和代码实现" class="headerlink" title="7.1 K近邻算法的原理和代码实现"></a>7.1 K近邻算法的原理和代码实现</h2><p>又称为KNN算法</p>
<h3 id="7-1-1-K近邻算法的基本原理"><a href="#7-1-1-K近邻算法的基本原理" class="headerlink" title="7.1.1 K近邻算法的基本原理"></a>7.1.1 K近邻算法的基本原理</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(28).png" alt="下载 (28)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(29).png" alt="下载 (29)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(30).png" alt="下载 (30)"></p>
<h3 id="7-1-2-K近邻算法的计算步骤"><a href="#7-1-2-K近邻算法的计算步骤" class="headerlink" title="7.1.2 K近邻算法的计算步骤"></a>7.1.2 K近邻算法的计算步骤</h3><p>1.样本数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;葡萄酒.xlsx&#x27;</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>原始样本</th>
      <th>酒精含量(%)</th>
      <th>苹果酸含量(%)</th>
      <th>分类</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>样本1</td>
      <td>5</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>样本2</td>
      <td>6</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>样本3</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>样本4</td>
      <td>8</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>样本5</td>
      <td>10</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>分类0表示葡萄酒A，分类1为葡萄酒B</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(31).png" alt="下载 (31)"></p>
<p>2.计算距离</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(32).png" alt="下载 (32)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(33).png" alt="下载 (33)"></p>
<p>3.根据K值判定类别</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(34).png" alt="下载 (34)"></p>
<p><strong>补充：数据标准化</strong></p>
<p>本小节使用的演示数据，不同特征变量的量纲级别相差不大，如果把“酒精含量”数据都放大为原来的10倍，“苹果酸含量”数据保持不变，那么两者的量纲级别就相差较大了，此时如果使用K近邻算法来搭建模型，那么“酒精含量”在模型中的重要性将远远超过“苹果酸含量”的重要性，这样会丧失“苹果酸含量”这一特征变量的作用，而且误差也会很大</p>
<p>所以，如果不同特征变量的<strong>量纲级别相差较大</strong>且在建模时<strong>相互影响</strong>，我们通常会对数据进行预处理，该手段称为<strong>数据标准化或数据归一化</strong>。数据标准化的常见方法有<strong>min-max标准化</strong>（也称离差标准化）和<strong>Z-score标准化</strong>（也称均值归一化），将在11.3节详细讲解</p>
<h3 id="7-1-3-K近邻算法的代码实现"><a href="#7-1-3-K近邻算法的代码实现" class="headerlink" title="7.1.3 K近邻算法的代码实现"></a>7.1.3 K近邻算法的代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;葡萄酒.xlsx&#x27;</span>)</span><br><span class="line"><span class="comment"># 特征变量和目标变量的切分</span></span><br><span class="line">X_train = df[[<span class="string">&#x27;酒精含量(%)&#x27;</span>,<span class="string">&#x27;苹果酸含量(%)&#x27;</span>]]</span><br><span class="line">y_train = df[<span class="string">&#x27;分类&#x27;</span>]  </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier <span class="keyword">as</span> KNN</span><br><span class="line">knn = KNN(n_neighbors=<span class="number">3</span>)  <span class="comment"># 近邻参数K为3，默认值为5</span></span><br><span class="line">knn.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsClassifier(n_neighbors=3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型预测：预测单个样本</span></span><br><span class="line">X_test = [[<span class="number">7</span>, <span class="number">1</span>]]  <span class="comment"># X_test为测试集特征变量，即7%的酒精含量及1%的苹果酸含量</span></span><br><span class="line">answer = knn.predict(X_test)  </span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型预测：预测多个样本</span></span><br><span class="line">X_test = [[<span class="number">7</span>, <span class="number">1</span>], [<span class="number">8</span>, <span class="number">3</span>]]  <span class="comment"># 这里能帮助理解为什么要写成二维数组的样式</span></span><br><span class="line">answer = knn.predict(X_test)  </span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>

<pre><code>[0 1]
</code></pre>
<p><strong>补充知识点：K近邻算法回归模型</strong></p>
<p>上述代码是用K近邻算法中的K近邻算法分类模型（KNeighborsClassifier）进行分类分析，K近邻算法还可以做回归分析，对应的模型为K近邻算法回归模型（KNeighborsRegressor）。K近邻算法分类模型将离待预测样本点最近的K个训练样本点中出现次数最多的分类作为待预测样本点的分类，K近邻算法回归模型则将离待预测样本点最近的K个训练样本点的<strong>平均值</strong>作为待预测样本点的分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">model = KNeighborsRegressor(n_neighbors=<span class="number">2</span>)  <span class="comment"># K为2</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[2.5]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNeighborsRegressor?</span><br></pre></td></tr></table></figure>

<h2 id="7-2-案例实战-手写数字识别模型"><a href="#7-2-案例实战-手写数字识别模型" class="headerlink" title="7.2 案例实战 - 手写数字识别模型"></a>7.2 案例实战 - 手写数字识别模型</h2><h3 id="7-2-1-案例背景"><a href="#7-2-1-案例背景" class="headerlink" title="7.2.1 案例背景"></a>7.2.1 案例背景</h3><h3 id="7-2-2-手写数字识别的原理"><a href="#7-2-2-手写数字识别的原理" class="headerlink" title="7.2.2 手写数字识别的原理"></a>7.2.2 手写数字识别的原理</h3><p>1.图像二值化</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(35).png" alt="下载 (35)"></p>
<p>2.二维数组转换为一维数组</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(36).png" alt="下载 (36)"></p>
<p>3.距离计算</p>
<p>手写数字图片处理后形成的1x1024的二维数组可以看成一个行向量，两张图片对应的行向量间的欧式距离可以反映两张图片的相似度。因此，我们可以利用K近邻算法模型计算新样本与原始训练集中各个样本的欧式距离，取新样本的K个近邻点，并以大多数近邻点所在的分类作为新样本的分类</p>
<p>例如，有一个样本手写数字4，其对应的1x1024行向量为：0000…010…111…0011…000</p>
<p>将另一个手写数字x转换成如下1x1024的行向量，假设其中只有中间一个数字不同：0000…110…111…0011…000,</p>
<p>那么手写数字x与样本手写数字4的距离为$|AB|&#x3D;[(0-0)^2+(0-0)^2+…(0-1)^2+(1-1)^2+(0-0)^2+…+(0-0)^2]^(0.5)&#x3D;1$</p>
<h3 id="7-2-3-手写数字识别的代码实现"><a href="#7-2-3-手写数字识别的代码实现" class="headerlink" title="7.2.3 手写数字识别的代码实现"></a>7.2.3 手写数字识别的代码实现</h3><p><strong>1.数据读取</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.读取数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;手写字体识别.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>对应数字</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>...</th>
      <th>1014</th>
      <th>1015</th>
      <th>1016</th>
      <th>1017</th>
      <th>1018</th>
      <th>1019</th>
      <th>1020</th>
      <th>1021</th>
      <th>1022</th>
      <th>1023</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1025 columns</p>
</div>



<p><strong>2.提取特征变量和目标变量</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2.提取特征变量和目标变</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;对应数字&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;对应数字&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p><strong>3.划分训练集和测试集</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.划分训练集和测试集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<p><strong>4.模型搭建</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.模型搭建</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier <span class="keyword">as</span> KNN</span><br><span class="line">knn = KNN(n_neighbors=<span class="number">5</span>) </span><br><span class="line">knn.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsClassifier()
</code></pre>
<p><strong>5.模型预测与评估</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5.模型预测 - 预测数据结果</span></span><br><span class="line">y_pred = knn.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred[<span class="number">0</span>:<span class="number">100</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[5 3 7 8 9 2 1 4 5 8 9 5 9 3 3 2 3 7 9 1 0 0 7 6 6 7 0 9 6 9 1 8 6 9 2 5 2
 4 5 8 3 6 9 4 9 2 7 3 4 9 5 6 7 3 3 8 3 1 5 3 6 7 5 0 3 7 1 4 9 1 5 1 2 6
 9 1 9 5 5 9 2 8 8 4 4 9 4 3 9 8 0 3 4 3 6 8 5 2 9 0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8</td>
      <td>8</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测准确度评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.979328165374677
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型自带的score()函数也可以进行打分</span></span><br><span class="line">score = knn.score(X_test, y_test)</span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.979328165374677
</code></pre>
<h2 id="7-3-图像识别原理详解"><a href="#7-3-图像识别原理详解" class="headerlink" title="7.3 图像识别原理详解"></a>7.3 图像识别原理详解</h2><p>1.图像大小调整及显示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;数字4.png&#x27;</span>)</span><br><span class="line">img = img.resize((<span class="number">32</span>,<span class="number">32</span>))  <span class="comment"># 调整像素</span></span><br><span class="line">img.show()</span><br><span class="line">img</span><br></pre></td></tr></table></figure>




<p><img src="output_221_0.png" alt="output_221_0"></p>
<p>2.图片灰度处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">img = img.convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">img</span><br></pre></td></tr></table></figure>




<p><img src="output_223_0.png" alt="output_223_0"></p>
<p>3.图片二值化处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二值化处理</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img_new = img.point(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x &gt; <span class="number">128</span> <span class="keyword">else</span> <span class="number">1</span>)<span class="comment"># 将色彩数值大于128的像素点赋值为0，反之赋值为1.</span></span><br><span class="line"><span class="comment"># 图像在进行灰度处理后，每一个像素点由一个取值范围为0~255的数字表示，其中0代表黑色，255代表白色</span></span><br><span class="line"><span class="comment"># ，所以这里以128为阈值进行划分，即原来偏白色的区域赋值为0，原来偏黑色的区域赋值为1</span></span><br><span class="line">arr = np.array(img_new) <span class="comment"># 使用array()函数将已经转换成数字01的32x32像素的图片转换为32x32的二维数组，并赋值给arr</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印arr中的每一行</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(arr.shape[<span class="number">0</span>]):<span class="comment"># arr.shape()获取的是数组的行数和列数，arr.shape[0]对应行数，arr.shape[1]则对应列数</span></span><br><span class="line">    <span class="built_in">print</span>(arr[i])</span><br></pre></td></tr></table></figure>

<pre><code>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]
[0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
</code></pre>
<p>4.将二维数组转换成一维数组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr_new = arr.reshape(<span class="number">1</span>, -<span class="number">1</span>) <span class="comment"># 将二维数组转换成一行</span></span><br><span class="line">arr_new</span><br></pre></td></tr></table></figure>




<pre><code>array([[0, 0, 0, ..., 0, 0, 0]], dtype=uint8)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(arr_new.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(1, 1024)
</code></pre>
<p>此时我们可以把这个处理过的图片“数字4”传入到我们上面训练好的knn模型中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">answer = knn.predict(arr_new) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;图片中的数字为：&#x27;</span> + <span class="built_in">str</span>(answer[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>图片中的数字为：4
</code></pre>
<p>用粗一点的笔手写一个数字，然后拍照，传到如下代码的23行位置，亲自试试模型的识别效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 主要分为三步，第一步训练模型，第二步处理图片，第三步导入模型并预测</span></span><br><span class="line"><span class="comment"># 1.训练模型</span></span><br><span class="line"><span class="comment"># 1.1 读取数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;手写字体识别.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.2 提取特征变量和目标变量</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;对应数字&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;对应数字&#x27;</span>]   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.3 划分训练集和测试集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.4 训练模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier <span class="keyword">as</span> KNN</span><br><span class="line">knn = KNN(n_neighbors=<span class="number">5</span>) </span><br><span class="line">knn.fit(X_train, y_train)  <span class="comment"># 自此手写字体识别模型便搭建好了</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.处理图片</span></span><br><span class="line"><span class="comment"># 2.1 图片读取 &amp; 大小调整 &amp; 灰度处理</span></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&#x27;测试图片.png&#x27;</span>)  <span class="comment"># 这里传入手写的图片，注意写对文件路径</span></span><br><span class="line">img = img.resize((<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">img = img.convert(<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 图片二值化处理 &amp; 二维数据转一维数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">img_new = img.point(<span class="keyword">lambda</span> x: <span class="number">0</span> <span class="keyword">if</span> x &gt; <span class="number">128</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line">arr = np.array(img_new)</span><br><span class="line">arr_new = arr.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.预测手写数字</span></span><br><span class="line">answer = knn.predict(arr_new) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;图片中的数字为：&#x27;</span> + <span class="built_in">str</span>(answer[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>图片中的数字为：1
</code></pre>
<h1 id="8-随机森林模型——集成学习模型"><a href="#8-随机森林模型——集成学习模型" class="headerlink" title="8 随机森林模型——集成学习模型"></a>8 随机森林模型——集成学习模型</h1><h2 id="8-1-随机森林模型的原理和代码实现"><a href="#8-1-随机森林模型的原理和代码实现" class="headerlink" title="8.1 随机森林模型的原理和代码实现"></a>8.1 随机森林模型的原理和代码实现</h2><h3 id="8-1-1-集成模型简介"><a href="#8-1-1-集成模型简介" class="headerlink" title="8.1.1 集成模型简介"></a>8.1.1 集成模型简介</h3><p>集成学习模型使用一系列弱学习器（也称为基础模型或基模型）进行学习，并将各个弱学习器的结果进行整合，从而获得比单个学习器更好的学习效果。集成学习模型的常见算法有Bagging算法和Boosting算法。Bagging算法的典型机器学习模型为随机森立，而Boosting算法的典型机器学习模型为AdaBoost，GBDT，XGBoost和LightGBM模型</p>
<p><strong>1.Bagging算法</strong></p>
<p>Bagging算法的原理类似投票，每个弱学习都有一票，最终根据所有弱学习器的投票，按照“少数服从多数”的原则产生最终的预测结果<br><img src="%E4%B8%8B%E8%BD%BD%20(37).png" alt="下载 (37)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(38).png" alt="下载 (38)"></p>
<p><strong>2.Boosting算法</strong></p>
<p>Boosting算法的本质是将弱学习提升为强学习器，Bagging算法对待所有弱学习器一视同仁；而Boosting算法则会对弱学习器区别对待，通俗来将就是“培养精英”和“重视错误”</p>
<p>“培养精英”就是每一轮训练后对预测结果较准确的弱学习器给予较大的权重，对表现不好的则降低权重，这样在最终预测时，“优秀模型”的权重是最大的，相当于它可以投出多票，而“一般模型”只能投出一票或者不能投票</p>
<p>“重视错误”就是在每一轮训练后改变训练集的权重或概率分布，通常提高在前一轮被弱学习器预测错误的样例的权重，降低前一轮被弱学习器预测正确的样例的权重，来<strong>提高弱学习器对预测错误的数据的重视程度</strong>，，从而提高模型的整体预测效果</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(39).png" alt="下载 (39)"></p>
<h3 id="8-1-2-随机森林模型的基本原理"><a href="#8-1-2-随机森林模型的基本原理" class="headerlink" title="8.1.2 随机森林模型的基本原理"></a>8.1.2 随机森林模型的基本原理</h3><p>随机森林（Random Forest）是一种经典的Bagging模型，其弱学习器为决策树模型，如下图所示，随机森林模型会在原始数据集中随机抽样，构成n 个不同的样本数据集，然后根据这些数据集搭建n个不同的决策树模型，最后根据这些决策树模型的平均值（针对回归模型）或者投票情况（针对分类模型）来获取最终结果</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(40).png" alt="下载 (40)"></p>
<p>为了保证模型的泛化能力（通用能力），随机森林模型在建立每棵树时，往往会遵循“数据随机”和“特征随机”这两个基本原则</p>
<p><strong>1.数据随机</strong></p>
<p>从所有数据中有放回地随机抽取数据作为其中一个决策树模型的训练模型。例如，有1000个原始数据，有放回地抽取1000次，构成一组新的数据，用于训练某一个决策树模型</p>
<p><strong>2.特征随机</strong></p>
<p>如果每个样本的特征维度为M，指定一个常数$k&lt;M$,随机从M个特征中选取k个特征，默认k&#x3D;根号M</p>
<p>与单独的决策树模型相比，随机森林模型由于集成了多个决策树，其预测结果会更准确，且不容易造成过拟合现象，泛化能力较强</p>
<h3 id="8-1-3-随机森林模型的代码实现"><a href="#8-1-3-随机森林模型的代码实现" class="headerlink" title="8.1.3 随机森林模型的代码实现"></a>8.1.3 随机森林模型的代码实现</h3><p>和决策树模型一样，随机森林模型既可以做分类分析，也可以做回归分析。</p>
<p>分别对应的模型为随机森林分类模型（RandomForestClassifier）及随机森林回归模型（RandomForestRegressor）。随机森林分类模型的基模型是分类决策树模型（详见5.1.2节），随机森林回归模型的基模型则是回归决策树模型（详见5.1.3节）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机森林分类模型简单代码演示如下所示：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">model = RandomForestClassifier(n_estimators=<span class="number">10</span>, random_state=<span class="number">123</span>) <span class="comment">#设置弱学习器的数量为10，有10个决策树模型作为弱学习器</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机森林回归模型简单代码演示如下所示：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">model = RandomForestRegressor(n_estimators=<span class="number">10</span>, random_state=<span class="number">123</span>)</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[2.8]
</code></pre>
<h2 id="8-2-案例实战：股票涨跌预测模型"><a href="#8-2-案例实战：股票涨跌预测模型" class="headerlink" title="8.2 案例实战：股票涨跌预测模型"></a>8.2 案例实战：股票涨跌预测模型</h2><h3 id="8-2-1-股票基本数据获取-最好直接看tushare官方数据接口文档"><a href="#8-2-1-股票基本数据获取-最好直接看tushare官方数据接口文档" class="headerlink" title="8.2.1 股票基本数据获取(最好直接看tushare官方数据接口文档)"></a>8.2.1 股票基本数据获取(最好直接看tushare官方数据接口文档)</h3><p>注意：截至目前，老接口已经不能用了</p>
<p><strong>1.获取日线行情数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts</span><br><span class="line">ts.set_token(<span class="string">&#x27;6a623020c3e0d5e4b7143b3e50cc56ba8e4b20c3d2ea12909c7620be&#x27;</span>)</span><br><span class="line"><span class="comment"># 以上方法只需要在第一次或者token失效后调用，完成调取tushare数据凭证的设置，正常情况下不需要重复设置</span></span><br><span class="line">pro = ts.pro_api() <span class="comment"># 初始化pro接口</span></span><br><span class="line">df = pro.daily(ts_code=<span class="string">&#x27;000002.SZ&#x27;</span>, start_date=<span class="string">&#x27;20180101&#x27;</span>, end_date=<span class="string">&#x27;20190131&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>trade_date</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000002.SZ</td>
      <td>20190131</td>
      <td>27.39</td>
      <td>28.15</td>
      <td>27.00</td>
      <td>27.75</td>
      <td>27.21</td>
      <td>0.54</td>
      <td>1.9846</td>
      <td>411857.60</td>
      <td>1138512.393</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000002.SZ</td>
      <td>20190130</td>
      <td>26.70</td>
      <td>27.82</td>
      <td>26.63</td>
      <td>27.21</td>
      <td>26.88</td>
      <td>0.33</td>
      <td>1.2277</td>
      <td>592303.18</td>
      <td>1615186.856</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000002.SZ</td>
      <td>20190129</td>
      <td>25.91</td>
      <td>26.88</td>
      <td>25.87</td>
      <td>26.88</td>
      <td>26.06</td>
      <td>0.82</td>
      <td>3.1466</td>
      <td>368071.63</td>
      <td>974279.357</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000002.SZ</td>
      <td>20190128</td>
      <td>26.20</td>
      <td>26.62</td>
      <td>25.86</td>
      <td>26.06</td>
      <td>26.10</td>
      <td>-0.04</td>
      <td>-0.1533</td>
      <td>308906.56</td>
      <td>810288.818</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000002.SZ</td>
      <td>20190125</td>
      <td>25.51</td>
      <td>26.35</td>
      <td>25.49</td>
      <td>26.10</td>
      <td>25.41</td>
      <td>0.69</td>
      <td>2.7155</td>
      <td>451756.17</td>
      <td>1176479.676</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>2.获取分钟级别的数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df = ts.pro_bar(ts_code=<span class="string">&#x27;600000.SH&#x27;</span>,</span><br><span class="line">                    freq=<span class="string">&#x27;1min&#x27;</span>,  <span class="comment"># 目前分钟频度包括1分、5、15、30、60分数据</span></span><br><span class="line">                    start_date=<span class="string">&#x27;2020-01-07 09:00:00&#x27;</span>, </span><br><span class="line">                    end_date=<span class="string">&#x27;2020-01-08 17:00:00&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>trade_time</th>
      <th>open</th>
      <th>close</th>
      <th>high</th>
      <th>low</th>
      <th>vol</th>
      <th>amount</th>
      <th>trade_date</th>
      <th>pre_close</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>600000.SH</td>
      <td>2020-01-08 15:00:00</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>1485837.0</td>
      <td>18305512.0</td>
      <td>20200108</td>
      <td>12.32</td>
    </tr>
    <tr>
      <th>1</th>
      <td>600000.SH</td>
      <td>2020-01-08 14:59:00</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>20200108</td>
      <td>12.32</td>
    </tr>
    <tr>
      <th>2</th>
      <td>600000.SH</td>
      <td>2020-01-08 14:58:00</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>22000.0</td>
      <td>271040.0</td>
      <td>20200108</td>
      <td>12.32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>600000.SH</td>
      <td>2020-01-08 14:57:00</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>12.33</td>
      <td>12.32</td>
      <td>266196.0</td>
      <td>3280959.0</td>
      <td>20200108</td>
      <td>12.32</td>
    </tr>
    <tr>
      <th>4</th>
      <td>600000.SH</td>
      <td>2020-01-08 14:56:00</td>
      <td>12.32</td>
      <td>12.32</td>
      <td>12.33</td>
      <td>12.32</td>
      <td>265829.0</td>
      <td>3275157.0</td>
      <td>20200108</td>
      <td>12.32</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>3.获取指数信息</strong></p>
<p>查看指数基本信息，指数日线行情需要积分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pro.index_basic(market=<span class="string">&#x27;SSE&#x27;</span>)  <span class="comment"># 上交所</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>name</th>
      <th>market</th>
      <th>publisher</th>
      <th>category</th>
      <th>base_date</th>
      <th>base_point</th>
      <th>list_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000001.SH</td>
      <td>上证指数</td>
      <td>SSE</td>
      <td>中证公司</td>
      <td>综合指数</td>
      <td>19901219</td>
      <td>100.00</td>
      <td>19910715</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000002.SH</td>
      <td>上证A指</td>
      <td>SSE</td>
      <td>中证公司</td>
      <td>综合指数</td>
      <td>19901219</td>
      <td>100.00</td>
      <td>19920221</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000003.SH</td>
      <td>上证B指</td>
      <td>SSE</td>
      <td>中证公司</td>
      <td>综合指数</td>
      <td>19920221</td>
      <td>100.00</td>
      <td>19920221</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000004.SH</td>
      <td>上证工业类指数</td>
      <td>SSE</td>
      <td>中证公司</td>
      <td>综合指数</td>
      <td>19930430</td>
      <td>1358.78</td>
      <td>19930503</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000005.SH</td>
      <td>上证商业类指数</td>
      <td>SSE</td>
      <td>中证公司</td>
      <td>综合指数</td>
      <td>19930430</td>
      <td>1358.78</td>
      <td>19930503</td>
    </tr>
  </tbody>
</table>
</div>



<p><strong>通用行情接口</strong></p>
<p>这个比较杂，需要不断熟悉不断学习</p>
<p>ts_code（str	&#x2F;必选）：证券代码，不支持多值输入，多值输入获取结果会有重复记录</p>
<p>api（str	&#x2F;不必选）：pro版api对象，如果初始化了set_token，此参数可以不需要</p>
<p>start_date（str&#x2F;不必选）：开始日期 (日线格式：YYYYMMDD，提取分钟数据请用2019-09-01 09:00:00这种格式)</p>
<p>end_date（str&#x2F;不必选）：结束日期 (日线格式：YYYYMMDD)</p>
<p>asset（str&#x2F;必选）：资产类别：E股票 I沪深指数 C数字货币 FT期货 FD基金 O期权 CB可转债（v1.2.39），默认E</p>
<p>adj（str&#x2F;不必选）：复权类型(只针对股票)：None未复权 qfq前复权 hfq后复权 , 默认None，目前只支持日线复权，同时复权机制是根据设定的end_date参数动态复权，采用分红再投模式</p>
<p>freq（str&#x2F;必选）：数据频度 ：支持分钟(min)&#x2F;日(D)&#x2F;周(W)&#x2F;月(M)K线，其中1min表示1分钟（类推1&#x2F;5&#x2F;15&#x2F;30&#x2F;60分钟） ，默认D。对于分钟数据有600积分用户可以试用（请求2次）</p>
<p>ma（list&#x2F;不必选）：均线，支持任意合理int数值。注：均线是动态计算，要设置一定时间范围才能获得相应的均线，比如5日均线，开始和结束日期参数跨度必须要超过5日。目前只支持单一个股票提取均线，即需要输入ts_code参数。e.g: ma_5表示5日均价，ma_v_5表示5日均量</p>
<p>factors（list&#x2F;不必选）：股票因子（asset&#x3D;’E’有效）支持 tor换手率 vr量比</p>
<p>adjfactor（str&#x2F;不必选）：复权因子，在复权数据时，如果此参数为True，返回的数据中则带复权因子，默认为False。 该功能从1.2.33版本开始生效</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#取上证指数行情数据,权限不够，积分不够</span></span><br><span class="line"></span><br><span class="line">df = ts.pro_bar(ts_code=<span class="string">&#x27;000001.SH&#x27;</span>, asset=<span class="string">&#x27;I&#x27;</span>, start_date=<span class="string">&#x27;20180101&#x27;</span>, end_date=<span class="string">&#x27;20181011&#x27;</span>)</span><br><span class="line">df,head()</span><br></pre></td></tr></table></figure>

<pre><code>抱歉，您没有访问该接口的权限，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。
抱歉，您没有访问该接口的权限，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。
抱歉，您没有访问该接口的权限，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。



---------------------------------------------------------------------------

OSError                                   Traceback (most recent call last)

&lt;ipython-input-30-20166becde73&gt; in &lt;module&gt;
      1 #取上证指数行情数据
      2 
----&gt; 3 df = ts.pro_bar(ts_code=&#39;000001.SH&#39;, asset=&#39;I&#39;, start_date=&#39;20180101&#39;, end_date=&#39;20181011&#39;)
      4 df,head()


E:\anaconda  111\lib\site-packages\tushare\pro\data_pro.py in pro_bar(ts_code, api, start_date, end_date, freq, asset, exchange, adj, ma, factors, adjfactor, offset, limit, contract_type, retry_count)
    194         else:
    195             return data
--&gt; 196     raise IOError(&#39;ERROR.&#39;)
    197 
    198 


OSError: ERROR.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#均线</span></span><br><span class="line"></span><br><span class="line">df = ts.pro_bar(ts_code=<span class="string">&#x27;000001.SZ&#x27;</span>, start_date=<span class="string">&#x27;20180101&#x27;</span>, end_date=<span class="string">&#x27;20181011&#x27;</span>, ma=[<span class="number">5</span>, <span class="number">20</span>, <span class="number">50</span>])</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>trade_date</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>amount</th>
      <th>ma5</th>
      <th>ma_v_5</th>
      <th>ma20</th>
      <th>ma_v_20</th>
      <th>ma50</th>
      <th>ma_v_50</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000001.SZ</td>
      <td>20181011</td>
      <td>10.05</td>
      <td>10.16</td>
      <td>9.70</td>
      <td>9.86</td>
      <td>10.45</td>
      <td>-0.59</td>
      <td>-5.6459</td>
      <td>1995143.83</td>
      <td>1994186.611</td>
      <td>10.474</td>
      <td>1570205.872</td>
      <td>10.2365</td>
      <td>1.068715e+06</td>
      <td>9.7594</td>
      <td>984673.7130</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000001.SZ</td>
      <td>20181010</td>
      <td>10.54</td>
      <td>10.66</td>
      <td>10.38</td>
      <td>10.45</td>
      <td>10.56</td>
      <td>-0.11</td>
      <td>-1.0417</td>
      <td>995200.08</td>
      <td>1045666.180</td>
      <td>10.650</td>
      <td>1347249.772</td>
      <td>10.2460</td>
      <td>1.027931e+06</td>
      <td>9.7498</td>
      <td>957053.2926</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000001.SZ</td>
      <td>20181009</td>
      <td>10.46</td>
      <td>10.70</td>
      <td>10.39</td>
      <td>10.56</td>
      <td>10.45</td>
      <td>0.11</td>
      <td>1.0526</td>
      <td>1064084.26</td>
      <td>1117946.550</td>
      <td>10.702</td>
      <td>1446312.442</td>
      <td>10.2450</td>
      <td>1.042988e+06</td>
      <td>9.7288</td>
      <td>965667.1742</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000001.SZ</td>
      <td>20181008</td>
      <td>10.70</td>
      <td>10.79</td>
      <td>10.45</td>
      <td>10.45</td>
      <td>11.05</td>
      <td>-0.60</td>
      <td>-5.4299</td>
      <td>1686358.52</td>
      <td>1793455.283</td>
      <td>10.700</td>
      <td>1428898.530</td>
      <td>10.2265</td>
      <td>1.025368e+06</td>
      <td>9.7060</td>
      <td>980019.2542</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000001.SZ</td>
      <td>20180928</td>
      <td>10.78</td>
      <td>11.27</td>
      <td>10.78</td>
      <td>11.05</td>
      <td>10.74</td>
      <td>0.31</td>
      <td>2.8864</td>
      <td>2110242.67</td>
      <td>2331358.288</td>
      <td>10.744</td>
      <td>1416530.508</td>
      <td>10.2105</td>
      <td>1.006594e+06</td>
      <td>9.6792</td>
      <td>981377.6318</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#换手率tor，量比vr</span></span><br><span class="line"></span><br><span class="line">df = ts.pro_bar(ts_code=<span class="string">&#x27;000001.SZ&#x27;</span>, start_date=<span class="string">&#x27;20180101&#x27;</span>, end_date=<span class="string">&#x27;20181011&#x27;</span>, factors=[<span class="string">&#x27;tor&#x27;</span>, <span class="string">&#x27;vr&#x27;</span>])</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>

<pre><code>抱歉，您没有访问该接口的权限，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。
抱歉，您没有访问该接口的权限，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。
抱歉，您没有访问该接口的权限，权限的具体详情访问：https://tushare.pro/document/1?doc_id=108。



---------------------------------------------------------------------------

OSError                                   Traceback (most recent call last)

&lt;ipython-input-32-df812ea09fe6&gt; in &lt;module&gt;
      1 #换手率tor，量比vr
      2 
----&gt; 3 df = ts.pro_bar(ts_code=&#39;000001.SZ&#39;, start_date=&#39;20180101&#39;, end_date=&#39;20181011&#39;, factors=[&#39;tor&#39;, &#39;vr&#39;])
      4 df.head()


E:\anaconda  111\lib\site-packages\tushare\pro\data_pro.py in pro_bar(ts_code, api, start_date, end_date, freq, asset, exchange, adj, ma, factors, adjfactor, offset, limit, contract_type, retry_count)
    194         else:
    195             return data
--&gt; 196     raise IOError(&#39;ERROR.&#39;)
    197 
    198 


OSError: ERROR.
</code></pre>
<h3 id="8-2-2-股票衍生变量生成"><a href="#8-2-2-股票衍生变量生成" class="headerlink" title="8.2.2 股票衍生变量生成"></a>8.2.2 股票衍生变量生成</h3><p>学习如何利用股票的基本数据获取一些衍生变量数据，如股票技术分析中常用的均线指标5日均线价格MA5与10日均线价格MA10、对抗强弱指标RSI、动量指标MOM、指数移动平均值EMA，异同移动平均线MACD等——这些在pro中属于技术面因子，需要积分，在聚宽环境中很全很全，建议在聚宽中编写策略</p>
<p>1.获取股票基本数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pro.daily(ts_code=<span class="string">&#x27;000002.SZ&#x27;</span>, start_date=<span class="string">&#x27;20150101&#x27;</span>, end_date=<span class="string">&#x27;20191231&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>trade_date</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000002.SZ</td>
      <td>20191231</td>
      <td>31.35</td>
      <td>32.45</td>
      <td>31.32</td>
      <td>32.18</td>
      <td>31.57</td>
      <td>0.61</td>
      <td>1.9322</td>
      <td>663497.98</td>
      <td>2122966.722</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000002.SZ</td>
      <td>20191230</td>
      <td>31.35</td>
      <td>31.79</td>
      <td>31.02</td>
      <td>31.57</td>
      <td>31.00</td>
      <td>0.57</td>
      <td>1.8387</td>
      <td>915751.42</td>
      <td>2870247.850</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000002.SZ</td>
      <td>20191227</td>
      <td>31.23</td>
      <td>31.32</td>
      <td>30.81</td>
      <td>31.00</td>
      <td>31.12</td>
      <td>-0.12</td>
      <td>-0.3856</td>
      <td>703096.48</td>
      <td>2185106.849</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000002.SZ</td>
      <td>20191226</td>
      <td>30.50</td>
      <td>31.30</td>
      <td>30.50</td>
      <td>31.12</td>
      <td>30.29</td>
      <td>0.83</td>
      <td>2.7402</td>
      <td>888790.74</td>
      <td>2758745.302</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000002.SZ</td>
      <td>20191225</td>
      <td>30.40</td>
      <td>30.63</td>
      <td>30.18</td>
      <td>30.29</td>
      <td>30.38</td>
      <td>-0.09</td>
      <td>-0.2962</td>
      <td>685037.32</td>
      <td>2082008.206</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用set_index()函数将data列设置为行索引</span></span><br><span class="line">df = df.set_index(<span class="string">&#x27;trade_date&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>amount</th>
    </tr>
    <tr>
      <th>trade_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20191231</th>
      <td>000002.SZ</td>
      <td>31.35</td>
      <td>32.45</td>
      <td>31.32</td>
      <td>32.18</td>
      <td>31.57</td>
      <td>0.61</td>
      <td>1.9322</td>
      <td>663497.98</td>
      <td>2122966.722</td>
    </tr>
    <tr>
      <th>20191230</th>
      <td>000002.SZ</td>
      <td>31.35</td>
      <td>31.79</td>
      <td>31.02</td>
      <td>31.57</td>
      <td>31.00</td>
      <td>0.57</td>
      <td>1.8387</td>
      <td>915751.42</td>
      <td>2870247.850</td>
    </tr>
    <tr>
      <th>20191227</th>
      <td>000002.SZ</td>
      <td>31.23</td>
      <td>31.32</td>
      <td>30.81</td>
      <td>31.00</td>
      <td>31.12</td>
      <td>-0.12</td>
      <td>-0.3856</td>
      <td>703096.48</td>
      <td>2185106.849</td>
    </tr>
    <tr>
      <th>20191226</th>
      <td>000002.SZ</td>
      <td>30.50</td>
      <td>31.30</td>
      <td>30.50</td>
      <td>31.12</td>
      <td>30.29</td>
      <td>0.83</td>
      <td>2.7402</td>
      <td>888790.74</td>
      <td>2758745.302</td>
    </tr>
    <tr>
      <th>20191225</th>
      <td>000002.SZ</td>
      <td>30.40</td>
      <td>30.63</td>
      <td>30.18</td>
      <td>30.29</td>
      <td>30.38</td>
      <td>-0.09</td>
      <td>-0.2962</td>
      <td>685037.32</td>
      <td>2082008.206</td>
    </tr>
  </tbody>
</table>
</div>



<p>2.生成简单衍生变量（pro接口已经给出这些数据了）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;close-open&#x27;</span>] = (df[<span class="string">&#x27;close&#x27;</span>] - df[<span class="string">&#x27;open&#x27;</span>])/df[<span class="string">&#x27;open&#x27;</span>]</span><br><span class="line">df[<span class="string">&#x27;high-low&#x27;</span>] = (df[<span class="string">&#x27;high&#x27;</span>] - df[<span class="string">&#x27;low&#x27;</span>])/df[<span class="string">&#x27;low&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># df[&#x27;pre_close&#x27;] = df[&#x27;close&#x27;].shift(1)  # 该列所有往下移一行形成昨日收盘价</span></span><br><span class="line"><span class="comment">#df[&#x27;price_change&#x27;] = df[&#x27;close&#x27;]-df[&#x27;pre_close&#x27;] # 当日股价变化</span></span><br><span class="line"><span class="comment"># df[&#x27;p_change&#x27;] = (df[&#x27;close&#x27;]-df[&#x27;pre_close&#x27;])/df[&#x27;pre_close&#x27;]*100 # 当日股价变化百分比</span></span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>amount</th>
      <th>close-open</th>
      <th>high-low</th>
    </tr>
    <tr>
      <th>trade_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20191231</th>
      <td>000002.SZ</td>
      <td>31.35</td>
      <td>32.45</td>
      <td>31.32</td>
      <td>32.18</td>
      <td>31.57</td>
      <td>0.61</td>
      <td>1.9322</td>
      <td>663497.98</td>
      <td>2122966.722</td>
      <td>0.026475</td>
      <td>0.036079</td>
    </tr>
    <tr>
      <th>20191230</th>
      <td>000002.SZ</td>
      <td>31.35</td>
      <td>31.79</td>
      <td>31.02</td>
      <td>31.57</td>
      <td>31.00</td>
      <td>0.57</td>
      <td>1.8387</td>
      <td>915751.42</td>
      <td>2870247.850</td>
      <td>0.007018</td>
      <td>0.024823</td>
    </tr>
    <tr>
      <th>20191227</th>
      <td>000002.SZ</td>
      <td>31.23</td>
      <td>31.32</td>
      <td>30.81</td>
      <td>31.00</td>
      <td>31.12</td>
      <td>-0.12</td>
      <td>-0.3856</td>
      <td>703096.48</td>
      <td>2185106.849</td>
      <td>-0.007365</td>
      <td>0.016553</td>
    </tr>
    <tr>
      <th>20191226</th>
      <td>000002.SZ</td>
      <td>30.50</td>
      <td>31.30</td>
      <td>30.50</td>
      <td>31.12</td>
      <td>30.29</td>
      <td>0.83</td>
      <td>2.7402</td>
      <td>888790.74</td>
      <td>2758745.302</td>
      <td>0.020328</td>
      <td>0.026230</td>
    </tr>
    <tr>
      <th>20191225</th>
      <td>000002.SZ</td>
      <td>30.40</td>
      <td>30.63</td>
      <td>30.18</td>
      <td>30.29</td>
      <td>30.38</td>
      <td>-0.09</td>
      <td>-0.2962</td>
      <td>685037.32</td>
      <td>2082008.206</td>
      <td>-0.003618</td>
      <td>0.014911</td>
    </tr>
  </tbody>
</table>
</div>



<p>3.生成移动平均线MA值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;MA5&#x27;</span>] = df[<span class="string">&#x27;close&#x27;</span>].sort_index().rolling(<span class="number">5</span>).mean()</span><br><span class="line">df[<span class="string">&#x27;MA10&#x27;</span>] = df[<span class="string">&#x27;close&#x27;</span>].sort_index().rolling(<span class="number">10</span>).mean()</span><br><span class="line"></span><br><span class="line">df.head(<span class="number">15</span>)  <span class="comment"># head(15)表示展示前15行，因为要展示10行以上，才能看到MA10有值</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>amount</th>
      <th>close-open</th>
      <th>high-low</th>
      <th>MA5</th>
      <th>MA10</th>
    </tr>
    <tr>
      <th>trade_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20191218</th>
      <td>000002.SZ</td>
      <td>30.50</td>
      <td>30.96</td>
      <td>30.20</td>
      <td>30.31</td>
      <td>30.45</td>
      <td>-0.14</td>
      <td>-0.4598</td>
      <td>907932.96</td>
      <td>2770950.971</td>
      <td>-0.006230</td>
      <td>0.025166</td>
      <td>29.272</td>
      <td>28.609</td>
    </tr>
    <tr>
      <th>20191217</th>
      <td>000002.SZ</td>
      <td>29.35</td>
      <td>31.34</td>
      <td>29.19</td>
      <td>30.45</td>
      <td>29.45</td>
      <td>1.00</td>
      <td>3.3956</td>
      <td>1596500.08</td>
      <td>4825522.418</td>
      <td>0.037479</td>
      <td>0.073655</td>
      <td>28.810</td>
      <td>28.356</td>
    </tr>
    <tr>
      <th>20191216</th>
      <td>000002.SZ</td>
      <td>28.25</td>
      <td>29.45</td>
      <td>28.15</td>
      <td>29.45</td>
      <td>28.15</td>
      <td>1.30</td>
      <td>4.6181</td>
      <td>1896062.95</td>
      <td>5422583.746</td>
      <td>0.042478</td>
      <td>0.046181</td>
      <td>28.300</td>
      <td>28.111</td>
    </tr>
    <tr>
      <th>20191213</th>
      <td>000002.SZ</td>
      <td>28.18</td>
      <td>28.34</td>
      <td>28.13</td>
      <td>28.15</td>
      <td>28.00</td>
      <td>0.15</td>
      <td>0.5357</td>
      <td>1431370.48</td>
      <td>4039464.921</td>
      <td>-0.001065</td>
      <td>0.007465</td>
      <td>28.044</td>
      <td>27.971</td>
    </tr>
    <tr>
      <th>20191212</th>
      <td>000002.SZ</td>
      <td>28.02</td>
      <td>28.17</td>
      <td>27.94</td>
      <td>28.00</td>
      <td>28.00</td>
      <td>0.00</td>
      <td>0.0000</td>
      <td>563827.86</td>
      <td>1580712.929</td>
      <td>-0.000714</td>
      <td>0.008232</td>
      <td>27.986</td>
      <td>27.926</td>
    </tr>
    <tr>
      <th>20191211</th>
      <td>000002.SZ</td>
      <td>27.99</td>
      <td>28.24</td>
      <td>27.95</td>
      <td>28.00</td>
      <td>27.90</td>
      <td>0.10</td>
      <td>0.3584</td>
      <td>985187.14</td>
      <td>2765688.862</td>
      <td>0.000357</td>
      <td>0.010376</td>
      <td>27.946</td>
      <td>27.906</td>
    </tr>
    <tr>
      <th>20191210</th>
      <td>000002.SZ</td>
      <td>28.08</td>
      <td>28.15</td>
      <td>27.73</td>
      <td>27.90</td>
      <td>28.17</td>
      <td>-0.27</td>
      <td>-0.9585</td>
      <td>685469.29</td>
      <td>1914187.737</td>
      <td>-0.006410</td>
      <td>0.015146</td>
      <td>27.902</td>
      <td>27.906</td>
    </tr>
    <tr>
      <th>20191209</th>
      <td>000002.SZ</td>
      <td>27.96</td>
      <td>28.35</td>
      <td>27.96</td>
      <td>28.17</td>
      <td>27.86</td>
      <td>0.31</td>
      <td>1.1127</td>
      <td>1160606.12</td>
      <td>3267608.704</td>
      <td>0.007511</td>
      <td>0.013948</td>
      <td>27.922</td>
      <td>27.951</td>
    </tr>
    <tr>
      <th>20191206</th>
      <td>000002.SZ</td>
      <td>27.86</td>
      <td>27.88</td>
      <td>27.72</td>
      <td>27.86</td>
      <td>27.80</td>
      <td>0.06</td>
      <td>0.2158</td>
      <td>358417.78</td>
      <td>997431.113</td>
      <td>0.000000</td>
      <td>0.005772</td>
      <td>27.898</td>
      <td>27.999</td>
    </tr>
    <tr>
      <th>20191205</th>
      <td>000002.SZ</td>
      <td>27.95</td>
      <td>27.95</td>
      <td>27.61</td>
      <td>27.80</td>
      <td>27.78</td>
      <td>0.02</td>
      <td>0.0720</td>
      <td>373263.56</td>
      <td>1036876.654</td>
      <td>-0.005367</td>
      <td>0.012314</td>
      <td>27.866</td>
      <td>27.914</td>
    </tr>
    <tr>
      <th>20191204</th>
      <td>000002.SZ</td>
      <td>27.88</td>
      <td>28.00</td>
      <td>27.65</td>
      <td>27.78</td>
      <td>28.00</td>
      <td>-0.22</td>
      <td>-0.7857</td>
      <td>343382.71</td>
      <td>954765.854</td>
      <td>-0.003587</td>
      <td>0.012658</td>
      <td>27.866</td>
      <td>27.809</td>
    </tr>
    <tr>
      <th>20191203</th>
      <td>000002.SZ</td>
      <td>27.97</td>
      <td>28.18</td>
      <td>27.73</td>
      <td>28.00</td>
      <td>28.05</td>
      <td>-0.05</td>
      <td>-0.1783</td>
      <td>596981.60</td>
      <td>1673918.787</td>
      <td>0.001073</td>
      <td>0.016228</td>
      <td>27.910</td>
      <td>27.696</td>
    </tr>
    <tr>
      <th>20191202</th>
      <td>000002.SZ</td>
      <td>27.87</td>
      <td>28.12</td>
      <td>27.86</td>
      <td>28.05</td>
      <td>27.70</td>
      <td>0.35</td>
      <td>1.2635</td>
      <td>1006843.93</td>
      <td>2823613.032</td>
      <td>0.006459</td>
      <td>0.009332</td>
      <td>27.980</td>
      <td>27.568</td>
    </tr>
    <tr>
      <th>20191129</th>
      <td>000002.SZ</td>
      <td>27.83</td>
      <td>27.85</td>
      <td>27.59</td>
      <td>27.70</td>
      <td>27.80</td>
      <td>-0.10</td>
      <td>-0.3597</td>
      <td>448064.84</td>
      <td>1242373.843</td>
      <td>-0.004671</td>
      <td>0.009424</td>
      <td>28.100</td>
      <td>27.405</td>
    </tr>
    <tr>
      <th>20191128</th>
      <td>000002.SZ</td>
      <td>28.01</td>
      <td>28.01</td>
      <td>27.62</td>
      <td>27.80</td>
      <td>28.00</td>
      <td>-0.20</td>
      <td>-0.7143</td>
      <td>439961.62</td>
      <td>1222840.122</td>
      <td>-0.007497</td>
      <td>0.014120</td>
      <td>27.962</td>
      <td>27.284</td>
    </tr>
  </tbody>
</table>
</div>



<p>MA5计算原理：</p>
<p>日期：股票收盘价</p>
<p>1：1.2&#x2F;2：1.4&#x2F;3：1.6&#x2F;4：1.8&#x2F;5：2.0&#x2F;6：2.2</p>
<p>5号的MA均值为(1.2+1.4+1.6+1.8+2.0)&#x2F;5&#x3D;1.6，而六号的MA5均值为(1.4+1.6+1.8+2.0+2.2)&#x2F;5&#x3D;1.8，以此类推。将一段时期内股价的移动平均值连成曲线，即为移动平均线</p>
<p>在计算MA5这样的数据时，因为最开始4天数据量不够，这4天对应的移动平均值为空值NaN，通常用dropna()函数删除空值，以免在后续计算中出现因空值造成的问题</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除空值</span></span><br><span class="line">df.dropna(inplace=<span class="literal">True</span>)  <span class="comment"># 删除空值行，也可以写成df = df.dropna()</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>amount</th>
      <th>close-open</th>
      <th>high-low</th>
      <th>MA5</th>
      <th>MA10</th>
    </tr>
    <tr>
      <th>trade_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20191218</th>
      <td>000002.SZ</td>
      <td>30.50</td>
      <td>30.96</td>
      <td>30.20</td>
      <td>30.31</td>
      <td>30.45</td>
      <td>-0.14</td>
      <td>-0.4598</td>
      <td>907932.96</td>
      <td>2770950.971</td>
      <td>-0.006230</td>
      <td>0.025166</td>
      <td>29.272</td>
      <td>28.609</td>
    </tr>
    <tr>
      <th>20191217</th>
      <td>000002.SZ</td>
      <td>29.35</td>
      <td>31.34</td>
      <td>29.19</td>
      <td>30.45</td>
      <td>29.45</td>
      <td>1.00</td>
      <td>3.3956</td>
      <td>1596500.08</td>
      <td>4825522.418</td>
      <td>0.037479</td>
      <td>0.073655</td>
      <td>28.810</td>
      <td>28.356</td>
    </tr>
    <tr>
      <th>20191216</th>
      <td>000002.SZ</td>
      <td>28.25</td>
      <td>29.45</td>
      <td>28.15</td>
      <td>29.45</td>
      <td>28.15</td>
      <td>1.30</td>
      <td>4.6181</td>
      <td>1896062.95</td>
      <td>5422583.746</td>
      <td>0.042478</td>
      <td>0.046181</td>
      <td>28.300</td>
      <td>28.111</td>
    </tr>
    <tr>
      <th>20191213</th>
      <td>000002.SZ</td>
      <td>28.18</td>
      <td>28.34</td>
      <td>28.13</td>
      <td>28.15</td>
      <td>28.00</td>
      <td>0.15</td>
      <td>0.5357</td>
      <td>1431370.48</td>
      <td>4039464.921</td>
      <td>-0.001065</td>
      <td>0.007465</td>
      <td>28.044</td>
      <td>27.971</td>
    </tr>
    <tr>
      <th>20191212</th>
      <td>000002.SZ</td>
      <td>28.02</td>
      <td>28.17</td>
      <td>27.94</td>
      <td>28.00</td>
      <td>28.00</td>
      <td>0.00</td>
      <td>0.0000</td>
      <td>563827.86</td>
      <td>1580712.929</td>
      <td>-0.000714</td>
      <td>0.008232</td>
      <td>27.986</td>
      <td>27.926</td>
    </tr>
  </tbody>
</table>
</div>



<p>4.股票衍生变量生成库TA-Lib的安装</p>
<p>（这个库安装在了python3.7版本下，所以这里用不了，但实际上这些指标聚宽上都有，这里只是学习了解一下即可）</p>
<p>5.~8.用TA-Lib库生成相对强弱指标RSI值&#x2F;MOM值&#x2F;EMA值&#x2F;MACD值</p>
<p>用pycharm中python3.7版本实现</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(41).png" alt="下载 (41)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(42).png" alt="下载 (42)"></p>
<p>RSI值能够反映短期内股价涨势相对于跌势的强弱，帮助我们更好判断股价的涨跌趋势。RSI值越大，涨势相对于跌势越强，反之则涨势相对于跌势越弱。<br><img src="%E4%B8%8B%E8%BD%BD%20(43).png" alt="下载 (43)"><br>一般N取值为6，12，24，代码参数timeperiod为12</p>
<p>通常情况下，RSI值位于20~80之间，超过80则为超买状态，低于20为超卖状态，等于50则为买卖双方力量均等。例如，如果连续6天股价都是上涨，则6日平均下跌价格为0，6日RSI值为100，表明此时股票买方处于非常强势的地位，但投资者也要警惕此时可能是超买状态，需要预防股价下跌的风险</p>
<p>MOM动量反映了一段时间内股价的涨跌速度，计算公式如下：<br><img src="%E4%B8%8B%E8%BD%BD%20(44).png" alt="下载 (44)"></p>
<p>EMA是以指数式递减加权的移动平均，并根据计算结果进行分析，用于判断股价未来走势的变动趋势。EMA和移动平均线指标MA有点相似，不过计算更复杂，只要知道EMA是一种趋势类指标即可<br><img src="%E4%B8%8B%E8%BD%BD%20(45).png" alt="下载 (45)"><br>对于EMA值而言，近期股价比之前更久远的股价更重要（计算中，近期股价的权重更大)，不像MA那样一视同仁。</p>
<p>此外，在计算MACD时，也会需要计算EMA值，其中N一般选12天和26天，因此α分别为2&#x2F;13和2&#x2F;27,对应的EMA12称为快的指数移动平均线，EMA26称为慢的指数移动平均线</p>
<p>MACD是股票市场上的常用指标，是基于EMA值的衍生变量，MACD是一种趋势类指标，其变化代表着市场趋势的变化，不同K线级别的MACD代表当前级别周期中的买卖趋势。上述代码中MACD，MACDsignal和MACDhist都是MACD值的相关指标<br><img src="%E4%B8%8B%E8%BD%BD%20(47).png" alt="下载 (47)"><br>MACD技术指标图是由两线一柱组成的，快速线为DIF值，慢速线为DEA值，柱形图为MACD值<br><img src="%E4%B8%8B%E8%BD%BD%20(48).png" alt="下载 (48)"></p>
<p>蓝色线DIF，粉色线DEA，柱MACD<br><img src="%E4%B8%8B%E8%BD%BD%20(49).png" alt="下载 (49)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(50).png" alt="下载 (50)"></p>
<h3 id="8-2-3-多因子模型搭建"><a href="#8-2-3-多因子模型搭建" class="headerlink" title="8.2.3 多因子模型搭建"></a>8.2.3 多因子模型搭建</h3><p>本案例中的模型是根据多个特征进行搭建的，在量化金融领域称为多因子模型。股票数据是时间序列数据，与之相关的一些数据处理工作和之前所讲的模型稍有不同</p>
<p>注意：由于talib库只能在python3.7环境下运行，而该环境下没有sklearn库，所以打算将处理好的数据保存为excel文件，再在jupyter notebook中调用</p>
<p><strong>1.引入之后需要用到的库</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts  <span class="comment"># 股票基本数据相关库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  <span class="comment"># 科学计算相关库</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  <span class="comment"># 科学计算相关库  </span></span><br><span class="line"><span class="comment"># import talib  # 股票衍生变量数据相关库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  <span class="comment"># 引入绘图相关库</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier  <span class="comment"># 引入分类决策树模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score  <span class="comment"># 引入准确度评分函数</span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>) <span class="comment"># 忽略警告信息，警告非报错，不影响代码执行</span></span><br></pre></td></tr></table></figure>

<p><strong>2.股票数据处理与衍生变量生成</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(51).png" alt="下载 (51)"></p>
<p>此处将处理好的股票数据打包成excel文件，保存在本笔记同目录中</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(52).png" alt="下载 (52)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df =pd.read_excel(<span class="string">&#x27;股票数据.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>trade_date</th>
      <th>ts_code</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>...</th>
      <th>high-low</th>
      <th>MA5</th>
      <th>MA10</th>
      <th>RSI</th>
      <th>MOM</th>
      <th>EMA12</th>
      <th>EMA26</th>
      <th>MACD</th>
      <th>MACDsignal</th>
      <th>MACDhist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>20191114</td>
      <td>000002.SZ</td>
      <td>26.23</td>
      <td>26.47</td>
      <td>26.07</td>
      <td>26.39</td>
      <td>26.19</td>
      <td>0.20</td>
      <td>0.7637</td>
      <td>378340.59</td>
      <td>...</td>
      <td>0.015343</td>
      <td>26.396</td>
      <td>26.577</td>
      <td>26.694827</td>
      <td>-0.36</td>
      <td>27.116721</td>
      <td>28.154057</td>
      <td>-1.119303</td>
      <td>-1.194937</td>
      <td>0.075634</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20191113</td>
      <td>000002.SZ</td>
      <td>26.28</td>
      <td>26.30</td>
      <td>26.00</td>
      <td>26.19</td>
      <td>26.28</td>
      <td>-0.09</td>
      <td>-0.3425</td>
      <td>346952.18</td>
      <td>...</td>
      <td>0.011538</td>
      <td>26.432</td>
      <td>26.591</td>
      <td>25.231860</td>
      <td>-0.46</td>
      <td>26.974149</td>
      <td>28.008571</td>
      <td>-1.103780</td>
      <td>-1.176706</td>
      <td>0.072926</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20191112</td>
      <td>000002.SZ</td>
      <td>26.32</td>
      <td>26.53</td>
      <td>26.21</td>
      <td>26.28</td>
      <td>26.38</td>
      <td>-0.10</td>
      <td>-0.3791</td>
      <td>363338.48</td>
      <td>...</td>
      <td>0.012209</td>
      <td>26.524</td>
      <td>26.637</td>
      <td>27.190684</td>
      <td>-0.44</td>
      <td>26.867357</td>
      <td>27.880529</td>
      <td>-1.071859</td>
      <td>-1.155737</td>
      <td>0.083877</td>
    </tr>
    <tr>
      <th>3</th>
      <td>20191111</td>
      <td>000002.SZ</td>
      <td>26.58</td>
      <td>26.59</td>
      <td>26.32</td>
      <td>26.38</td>
      <td>26.74</td>
      <td>-0.36</td>
      <td>-1.3463</td>
      <td>463259.32</td>
      <td>...</td>
      <td>0.010258</td>
      <td>26.644</td>
      <td>26.676</td>
      <td>29.431647</td>
      <td>-0.04</td>
      <td>26.792379</td>
      <td>27.769379</td>
      <td>-1.026658</td>
      <td>-1.129921</td>
      <td>0.103263</td>
    </tr>
    <tr>
      <th>4</th>
      <td>20191108</td>
      <td>000002.SZ</td>
      <td>26.69</td>
      <td>26.81</td>
      <td>26.57</td>
      <td>26.74</td>
      <td>26.57</td>
      <td>0.17</td>
      <td>0.6398</td>
      <td>485246.82</td>
      <td>...</td>
      <td>0.009033</td>
      <td>26.740</td>
      <td>26.726</td>
      <td>37.041765</td>
      <td>0.25</td>
      <td>26.784321</td>
      <td>27.693129</td>
      <td>-0.950826</td>
      <td>-1.094102</td>
      <td>0.143276</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 22 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以看到索引变了，再调整一下</span></span><br><span class="line">df = df.set_index(<span class="string">&#x27;trade_date&#x27;</span>)</span><br><span class="line"></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts_code</th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
      <th>pre_close</th>
      <th>change</th>
      <th>pct_chg</th>
      <th>vol</th>
      <th>amount</th>
      <th>...</th>
      <th>high-low</th>
      <th>MA5</th>
      <th>MA10</th>
      <th>RSI</th>
      <th>MOM</th>
      <th>EMA12</th>
      <th>EMA26</th>
      <th>MACD</th>
      <th>MACDsignal</th>
      <th>MACDhist</th>
    </tr>
    <tr>
      <th>trade_date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20191114</th>
      <td>000002.SZ</td>
      <td>26.23</td>
      <td>26.47</td>
      <td>26.07</td>
      <td>26.39</td>
      <td>26.19</td>
      <td>0.20</td>
      <td>0.7637</td>
      <td>378340.59</td>
      <td>996571.596</td>
      <td>...</td>
      <td>0.015343</td>
      <td>26.396</td>
      <td>26.577</td>
      <td>26.694827</td>
      <td>-0.36</td>
      <td>27.116721</td>
      <td>28.154057</td>
      <td>-1.119303</td>
      <td>-1.194937</td>
      <td>0.075634</td>
    </tr>
    <tr>
      <th>20191113</th>
      <td>000002.SZ</td>
      <td>26.28</td>
      <td>26.30</td>
      <td>26.00</td>
      <td>26.19</td>
      <td>26.28</td>
      <td>-0.09</td>
      <td>-0.3425</td>
      <td>346952.18</td>
      <td>906913.752</td>
      <td>...</td>
      <td>0.011538</td>
      <td>26.432</td>
      <td>26.591</td>
      <td>25.231860</td>
      <td>-0.46</td>
      <td>26.974149</td>
      <td>28.008571</td>
      <td>-1.103780</td>
      <td>-1.176706</td>
      <td>0.072926</td>
    </tr>
    <tr>
      <th>20191112</th>
      <td>000002.SZ</td>
      <td>26.32</td>
      <td>26.53</td>
      <td>26.21</td>
      <td>26.28</td>
      <td>26.38</td>
      <td>-0.10</td>
      <td>-0.3791</td>
      <td>363338.48</td>
      <td>957393.717</td>
      <td>...</td>
      <td>0.012209</td>
      <td>26.524</td>
      <td>26.637</td>
      <td>27.190684</td>
      <td>-0.44</td>
      <td>26.867357</td>
      <td>27.880529</td>
      <td>-1.071859</td>
      <td>-1.155737</td>
      <td>0.083877</td>
    </tr>
    <tr>
      <th>20191111</th>
      <td>000002.SZ</td>
      <td>26.58</td>
      <td>26.59</td>
      <td>26.32</td>
      <td>26.38</td>
      <td>26.74</td>
      <td>-0.36</td>
      <td>-1.3463</td>
      <td>463259.32</td>
      <td>1225718.598</td>
      <td>...</td>
      <td>0.010258</td>
      <td>26.644</td>
      <td>26.676</td>
      <td>29.431647</td>
      <td>-0.04</td>
      <td>26.792379</td>
      <td>27.769379</td>
      <td>-1.026658</td>
      <td>-1.129921</td>
      <td>0.103263</td>
    </tr>
    <tr>
      <th>20191108</th>
      <td>000002.SZ</td>
      <td>26.69</td>
      <td>26.81</td>
      <td>26.57</td>
      <td>26.74</td>
      <td>26.57</td>
      <td>0.17</td>
      <td>0.6398</td>
      <td>485246.82</td>
      <td>1296314.035</td>
      <td>...</td>
      <td>0.009033</td>
      <td>26.740</td>
      <td>26.726</td>
      <td>37.041765</td>
      <td>0.25</td>
      <td>26.784321</td>
      <td>27.693129</td>
      <td>-0.950826</td>
      <td>-1.094102</td>
      <td>0.143276</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div>



<p><strong>3.特征变量和目标变量提取</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = df[[<span class="string">&#x27;close&#x27;</span>, <span class="string">&#x27;vol&#x27;</span>, <span class="string">&#x27;close-open&#x27;</span>, <span class="string">&#x27;MA5&#x27;</span>, <span class="string">&#x27;MA10&#x27;</span>, <span class="string">&#x27;high-low&#x27;</span>, <span class="string">&#x27;RSI&#x27;</span>, <span class="string">&#x27;MOM&#x27;</span>, <span class="string">&#x27;EMA12&#x27;</span>, <span class="string">&#x27;MACD&#x27;</span>, <span class="string">&#x27;MACDsignal&#x27;</span>, <span class="string">&#x27;MACDhist&#x27;</span>]]</span><br><span class="line">y = np.where(df[<span class="string">&#x27;change&#x27;</span>].shift(-<span class="number">1</span>)&gt; <span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>首先应该强调的最核心的一点是：应该用当天的股价数据预测下一天的股价涨跌情况，所以目标变量y应该是下一天的股价涨跌情况</p>
<p>其中Numpy库中的where()函数的使用方法如下所示：<br>np.where(判断条件,满足条件的赋值,不满足条件的赋值)</p>
<p>其中df[‘change’].shift(-1)则是利用shift()函数将change（股价变化）这一列往上移动一行，这样就获得了每一行对应的下一天股价涨跌情况。</p>
<p>因此这里的判断条件就是下一天股价是否大于0，如果下一天股价涨了的我们则y赋值为数字1，下一天股价跌了的，则y赋值为数字-1。这个下一天的股价涨跌情况就是我们根据当天股票基本数据以及衍生变量预测的内容。</p>
<p><strong>3.训练集和测试集数据划分</strong></p>
<p>接下来，我们要将原始数据集进行分割，我们要注意到一点，训练集与测试集的划分要按照时间序列划分，而不是像之前利用train_test_split()函数进行划分。原因在于股票价格的变化趋势具有时间性，如果我们随机划分，则会破坏时间性特征，因为我们是根据当天数据来预测下一天的股价涨跌情况，而不是任意一天的股票数据来预测下一天的股价涨跌情况。<br>因此，我们将前90%的数据作为训练集，后10%的数据作为测试集，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_length = X.shape[<span class="number">0</span>]  <span class="comment"># shape属性获取X的行数和列数，shape[0]即表示行数 </span></span><br><span class="line">split = <span class="built_in">int</span>(X_length * <span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">X_train, X_test = X[:split], X[split:]</span><br><span class="line">y_train, y_test = y[:split], y[split:]</span><br></pre></td></tr></table></figure>

<p><strong>4.模型搭建</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = RandomForestClassifier(max_depth=<span class="number">3</span>, n_estimators=<span class="number">10</span>, min_samples_leaf=<span class="number">10</span>, random_state=<span class="number">1</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>RandomForestClassifier(max_depth=3, min_samples_leaf=10, n_estimators=10,
                       random_state=1)
</code></pre>
<p>其中设置的参数：决策树最大深度max_depth设置为3，弱学习器个数n_estimators为10，叶子节点的最小样本数min_samples_lesf为10</p>
<h3 id="8-2-4-模型使用与评估"><a href="#8-2-4-模型使用与评估" class="headerlink" title="8.2.4 模型使用与评估"></a>8.2.4 模型使用与评估</h3><p><strong>1.预测下一天的涨跌情况</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>[ 1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1  1
  1 -1  1  1  1 -1  1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1 -1
  1  1  1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1
 -1 -1  1  1  1 -1 -1 -1 -1]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>-1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看预测概率</span></span><br><span class="line">y_pred_proba = model.predict_proba(X_test)</span><br><span class="line">y_pred_proba[<span class="number">0</span>:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([[0.48342616, 0.51657384],
       [0.52112305, 0.47887695],
       [0.46987305, 0.53012695],
       [0.48293875, 0.51706125],
       [0.45513387, 0.54486613]])
</code></pre>
<p><strong>2.模型准确度评估</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.5523809523809524
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此外，我们还可以通过模型自带的score()函数记性打分，代码如下：</span></span><br><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.5523809523809524
</code></pre>
<p><strong>3.分析数据特征的重要性</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure>




<pre><code>array([0.057474  , 0.21408127, 0.02888772, 0.05994007, 0.0428833 ,
       0.09075887, 0.05632758, 0.16353218, 0.09928015, 0.01865826,
       0.10250797, 0.06566863])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码可以更好的展示特征及其特征重要性：</span></span><br><span class="line">features = X.columns  </span><br><span class="line">importances = model.feature_importances_</span><br><span class="line">a = pd.DataFrame()</span><br><span class="line">a[<span class="string">&#x27;特征&#x27;</span>] = features</span><br><span class="line">a[<span class="string">&#x27;特征重要性&#x27;</span>] = importances</span><br><span class="line">a = a.sort_values(<span class="string">&#x27;特征重要性&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line">a</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>特征</th>
      <th>特征重要性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>vol</td>
      <td>0.214081</td>
    </tr>
    <tr>
      <th>7</th>
      <td>MOM</td>
      <td>0.163532</td>
    </tr>
    <tr>
      <th>10</th>
      <td>MACDsignal</td>
      <td>0.102508</td>
    </tr>
    <tr>
      <th>8</th>
      <td>EMA12</td>
      <td>0.099280</td>
    </tr>
    <tr>
      <th>5</th>
      <td>high-low</td>
      <td>0.090759</td>
    </tr>
    <tr>
      <th>11</th>
      <td>MACDhist</td>
      <td>0.065669</td>
    </tr>
    <tr>
      <th>3</th>
      <td>MA5</td>
      <td>0.059940</td>
    </tr>
    <tr>
      <th>0</th>
      <td>close</td>
      <td>0.057474</td>
    </tr>
    <tr>
      <th>6</th>
      <td>RSI</td>
      <td>0.056328</td>
    </tr>
    <tr>
      <th>4</th>
      <td>MA10</td>
      <td>0.042883</td>
    </tr>
    <tr>
      <th>2</th>
      <td>close-open</td>
      <td>0.028888</td>
    </tr>
    <tr>
      <th>9</th>
      <td>MACD</td>
      <td>0.018658</td>
    </tr>
  </tbody>
</table>
</div>



<p>可见，成交量，动量指标MOM，MACDsignal等对下一天股价涨跌结果预测准确度影响较大</p>
<h3 id="8-2-5-参数调优"><a href="#8-2-5-参数调优" class="headerlink" title="8.2.5 参数调优"></a>8.2.5 参数调优</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV  <span class="comment"># 网格搜索合适的超参数</span></span><br><span class="line"><span class="comment"># 指定分类器中参数的范围</span></span><br><span class="line">parameters = &#123;<span class="string">&#x27;n_estimators&#x27;</span>:[<span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>], <span class="string">&#x27;max_depth&#x27;</span>:[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], <span class="string">&#x27;min_samples_leaf&#x27;</span>:[<span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>]&#125;</span><br><span class="line">new_model = RandomForestClassifier(random_state=<span class="number">1</span>)  <span class="comment"># 构建分类器</span></span><br><span class="line">grid_search = GridSearchCV(new_model, parameters, cv=<span class="number">6</span>, scoring=<span class="string">&#x27;accuracy&#x27;</span>)  <span class="comment"># cv=6表示交叉验证6次，scoring=&#x27;roc_auc&#x27;表示以ROC曲线的AUC评分作为模型评价准则, 默认为&#x27;accuracy&#x27;, 即按准确度评分</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grid_search.fit(X_train, y_train)  <span class="comment"># 传入数据</span></span><br><span class="line">grid_search.best_params_  <span class="comment"># 输出参数的最优值</span></span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;max_depth&#39;: 2, &#39;min_samples_leaf&#39;: 30, &#39;n_estimators&#39;: 20&#125;
</code></pre>
<p>用优化后的参数进行模型搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = RandomForestClassifier(max_depth=<span class="number">2</span>, n_estimators=<span class="number">20</span>, min_samples_leaf=<span class="number">30</span>, random_state=<span class="number">1</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>RandomForestClassifier(max_depth=2, min_samples_leaf=30, n_estimators=20,
                       random_state=1)
</code></pre>
<p>查看模型准确度（还那样哈哈哈）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.5523809523809524
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>-1</td>
    </tr>
  </tbody>
</table>
</div>



<p><img src="%E4%B8%8B%E8%BD%BD%20(53).png" alt="下载 (53)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(54).png" alt="下载 (54)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(55).png" alt="下载 (55)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(56).png" alt="下载 (56)"></p>
<h3 id="8-2-6-收益回测曲线绘制-知道就行了，实战中直接拿聚宽回测"><a href="#8-2-6-收益回测曲线绘制-知道就行了，实战中直接拿聚宽回测" class="headerlink" title="8.2.6 收益回测曲线绘制(知道就行了，实战中直接拿聚宽回测)"></a>8.2.6 收益回测曲线绘制(知道就行了，实战中直接拿聚宽回测)</h3><p>重点看收益回测曲线（净值曲线），也就是看搭建的模型获得的结果是否比不利用模型获得的结果更好</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_test[<span class="string">&#x27;prediction&#x27;</span>] = model.predict(X_test)</span><br><span class="line">X_test[<span class="string">&#x27;p_change&#x27;</span>] = (X_test[<span class="string">&#x27;close&#x27;</span>] - X_test[<span class="string">&#x27;close&#x27;</span>].shift(<span class="number">1</span>)) / X_test[<span class="string">&#x27;close&#x27;</span>].shift(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X_test[<span class="string">&#x27;origin&#x27;</span>] = (X_test[<span class="string">&#x27;p_change&#x27;</span>] + <span class="number">1</span>).cumprod()</span><br><span class="line">X_test[<span class="string">&#x27;strategy&#x27;</span>] = (X_test[<span class="string">&#x27;prediction&#x27;</span>].shift(<span class="number">1</span>) * X_test[<span class="string">&#x27;p_change&#x27;</span>] + <span class="number">1</span>).cumprod()</span><br><span class="line"></span><br><span class="line">X_test[[<span class="string">&#x27;strategy&#x27;</span>, <span class="string">&#x27;origin&#x27;</span>]].tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>strategy</th>
      <th>origin</th>
    </tr>
    <tr>
      <th>trade_date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20150122</th>
      <td>1.032030</td>
      <td>0.951647</td>
    </tr>
    <tr>
      <th>20150121</th>
      <td>0.991752</td>
      <td>0.914506</td>
    </tr>
    <tr>
      <th>20150120</th>
      <td>0.938555</td>
      <td>0.865452</td>
    </tr>
    <tr>
      <th>20150119</th>
      <td>0.952234</td>
      <td>0.852838</td>
    </tr>
    <tr>
      <th>20150116</th>
      <td>0.846604</td>
      <td>0.947442</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码将收益情况删除空值后可视化，并设置X轴刻度自动倾斜：</span></span><br><span class="line">X_test[[<span class="string">&#x27;strategy&#x27;</span>, <span class="string">&#x27;origin&#x27;</span>]].dropna().plot()  <span class="comment"># 我们读取的日期数据是20150101类型</span></span><br><span class="line">                                                <span class="comment"># 的，应该变为2015-01-01类型的再处理</span></span><br><span class="line">plt.gcf().autofmt_xdate()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_340_0.png" alt="output_340_0"></p>
<h1 id="9-AdaBoost与GBDT模型"><a href="#9-AdaBoost与GBDT模型" class="headerlink" title="9 AdaBoost与GBDT模型"></a>9 AdaBoost与GBDT模型</h1><h2 id="9-1-AdaBoost算法原理"><a href="#9-1-AdaBoost算法原理" class="headerlink" title="9.1 AdaBoost算法原理"></a>9.1 AdaBoost算法原理</h2><h3 id="9-1-1-AdaBoost算法的核心思想"><a href="#9-1-1-AdaBoost算法的核心思想" class="headerlink" title="9.1.1 AdaBoost算法的核心思想"></a>9.1.1 AdaBoost算法的核心思想</h3><p>AdaBoost算法是一种有效而实用的Boosting算法，它以一种<strong>高度自适应的方式</strong>按顺序训练弱学习器。针对分类问题，AdaBoost算法根据前一次的分类效果调整数据的权重，在上一个弱学习器中分类错误的样本的权重会在下一个弱学习器中增加，分类正确的样本的权重则相应减少，并且在每一轮迭代时会向模型加入一个新的弱学习器。不断重复调整权重和训练弱学习器，直到误分类数低于预设值或迭代次数达到指定的最大值，最终得到一个强学习器。<strong>其算法的核心思想是调整错误样本的权重，进而迭代升级</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(57).png" alt="下载 (57)"></p>
<h3 id="9-1-2-AdaBoost算法的数学原理概述"><a href="#9-1-2-AdaBoost算法的数学原理概述" class="headerlink" title="9.1.2 AdaBoost算法的数学原理概述"></a>9.1.2 AdaBoost算法的数学原理概述</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(58).png" alt="下载 (58)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(59).png" alt="下载 (59)"></p>
<p><strong>1，初始化各样本的权重（各权重相等）</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(60).png" alt="下载 (60)"></p>
<p><strong>2.计算误差率</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(61).png" alt="下载 (61)"></p>
<p><strong>3.调整弱学习器的权重</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(62).png" alt="下载 (62)"></p>
<p><strong>4.更新样本的权重</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(63).png" alt="下载 (63)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(64).png" alt="下载 (64)"></p>
<p><strong>5.反复迭代</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(65).png" alt="下载 (65)"></p>
<p><strong>补充：正则化项</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(66).png"></p>
<h3 id="9-1-3-AdaBoost算法的数学原理举例"><a href="#9-1-3-AdaBoost算法的数学原理举例" class="headerlink" title="9.1.3 AdaBoost算法的数学原理举例"></a>9.1.3 AdaBoost算法的数学原理举例</h3><p>略（到时候看ppt文档就行了）</p>
<h3 id="9-1-4-AdaBoost算法的简单代码实现"><a href="#9-1-4-AdaBoost算法的简单代码实现" class="headerlink" title="9.1.4 AdaBoost算法的简单代码实现"></a>9.1.4 AdaBoost算法的简单代码实现</h3><p>1.AdaBoost分类模型演示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">model = AdaBoostClassifier(random_state=<span class="number">123</span>)</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<p>2.AdaBoost回归模型演示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostRegressor</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">model = AdaBoostRegressor(random_state=<span class="number">123</span>)</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[3.]
</code></pre>
<h2 id="9-2-案例实战-AdaBoost信用卡精准营销模型"><a href="#9-2-案例实战-AdaBoost信用卡精准营销模型" class="headerlink" title="9.2 案例实战 - AdaBoost信用卡精准营销模型"></a>9.2 案例实战 - AdaBoost信用卡精准营销模型</h2><h3 id="9-2-1-案例背景"><a href="#9-2-1-案例背景" class="headerlink" title="9.2.1 案例背景"></a>9.2.1 案例背景</h3><p>本案例来搭建一个信用卡精准营销模型，该模型也可以应用于其他领域的精准营销，如信托公司信托产品的精准营销</p>
<h3 id="9-2-2-模型搭建"><a href="#9-2-2-模型搭建" class="headerlink" title="9.2.2 模型搭建"></a>9.2.2 模型搭建</h3><p><strong>1.读取数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;信用卡精准营销模型.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>年龄</th>
      <th>月收入（元）</th>
      <th>月消费（元）</th>
      <th>性别</th>
      <th>月消费/月收入</th>
      <th>响应</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>30</td>
      <td>7275</td>
      <td>6062</td>
      <td>0</td>
      <td>0.833265</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>25</td>
      <td>17739</td>
      <td>13648</td>
      <td>0</td>
      <td>0.769378</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>29</td>
      <td>25736</td>
      <td>14311</td>
      <td>0</td>
      <td>0.556069</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23</td>
      <td>14162</td>
      <td>7596</td>
      <td>0</td>
      <td>0.536365</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>27</td>
      <td>15563</td>
      <td>12849</td>
      <td>0</td>
      <td>0.825612</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>目标变量是精准营销后客户是否响应（即客户在营销后是否办了信用卡），取值为1代表营销有效，取值为0代表营销失败。其中有400个客户响应，600个客户没有响应</p>
<p><strong>2.提取特征变量和目标变量</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = df.drop(columns=<span class="string">&#x27;响应&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;响应&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p><strong>3.划分训练集和测试集</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<p><strong>4.模型训练</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line">clf = AdaBoostClassifier(random_state=<span class="number">123</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>AdaBoostClassifier(random_state=123)
</code></pre>
<h3 id="9-2-3-模型预测及评估"><a href="#9-2-3-模型预测及评估" class="headerlink" title="9.2.3 模型预测及评估"></a>9.2.3 模型预测及评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型搭建完毕后，通过如下代码预测测试集数据：</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>[1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0
 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1
 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1
 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1
 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1
 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过和之前章节类似的代码，我们可以将预测值和实际值进行对比：</span></span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看预测准确度</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.85
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看预测分类概率</span></span><br><span class="line">y_pred_proba = clf.predict_proba(X_test)</span><br><span class="line">y_pred_proba[<span class="number">0</span>:<span class="number">5</span>]  <span class="comment"># 查看前5项，第一列为分类为0的概率，第二列为分类为1的概率</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[0.19294615, 0.80705385],
       [0.41359387, 0.58640613],
       [0.42597039, 0.57402961],
       [0.66817389, 0.33182611],
       [0.32850159, 0.67149841]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制ROC曲线</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test.values, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_387_0.png" alt="output_387_0"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看AUC值</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">score = roc_auc_score(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.9559047909673483
</code></pre>
<p>可以看到预测效果很好</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看特征重要性</span></span><br><span class="line">clf.feature_importances_</span><br></pre></td></tr></table></figure>




<pre><code>array([0.18, 0.2 , 0.36, 0.02, 0.24])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过DataFrame的方式展示特征重要性</span></span><br><span class="line">features = X.columns  <span class="comment"># 获取特征名称</span></span><br><span class="line">importances = clf.feature_importances_  <span class="comment"># 获取特征重要性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过二维表格形式显示</span></span><br><span class="line">importances_df = pd.DataFrame()</span><br><span class="line">importances_df[<span class="string">&#x27;特征名称&#x27;</span>] = features</span><br><span class="line">importances_df[<span class="string">&#x27;特征重要性&#x27;</span>] = importances</span><br><span class="line">importances_df.sort_values(<span class="string">&#x27;特征重要性&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>特征名称</th>
      <th>特征重要性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>月消费（元）</td>
      <td>0.36</td>
    </tr>
    <tr>
      <th>4</th>
      <td>月消费/月收入</td>
      <td>0.24</td>
    </tr>
    <tr>
      <th>1</th>
      <td>月收入（元）</td>
      <td>0.20</td>
    </tr>
    <tr>
      <th>0</th>
      <td>年龄</td>
      <td>0.18</td>
    </tr>
    <tr>
      <th>3</th>
      <td>性别</td>
      <td>0.02</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以看到，特征重要性最高的特征变量是“月消费”，其次是“月消费&#x2F;月收入”和“月收入”，“年龄”和“性别”的特征重要性排在最后</p>
<h3 id="9-2-4-模型参数介绍"><a href="#9-2-4-模型参数介绍" class="headerlink" title="9.2.4 模型参数介绍"></a>9.2.4 模型参数介绍</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分类模型，通过如下代码可以查看官方介绍</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line">AdaBoostClassifier?</span><br></pre></td></tr></table></figure>

<p><img src="%E4%B8%8B%E8%BD%BD%20(67).png" alt="下载 (67)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回归模型，通过如下代码可以查看官方介绍</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostRegressor</span><br><span class="line">AdaBoostRegressor?</span><br></pre></td></tr></table></figure>

<p><img src="%E4%B8%8B%E8%BD%BD%20(68).png" alt="下载 (68)"></p>
<h2 id="9-3-GBDT算法原理"><a href="#9-3-GBDT算法原理" class="headerlink" title="9.3 GBDT算法原理"></a>9.3 GBDT算法原理</h2><h3 id="9-1-3-GBDT算法的核心思想"><a href="#9-1-3-GBDT算法的核心思想" class="headerlink" title="9.1.3 GBDT算法的核心思想"></a>9.1.3 GBDT算法的核心思想</h3><p>GBDT是梯度提升树的缩写，它与AdaBoost算法的区别在于：AdaBoost算法根据<strong>分类效果</strong>调整<strong>权重</strong>并不断迭代，最终生成强学习器；GDBT算法则将损失函数的负梯度作为残差的近似值，不断使用残差迭代和拟合回归树，最终生成强学习器。简单来说，AdaBoost算法是<strong>梯度权重</strong>，而GBDT算法则是<strong>拟合残差</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(69).png" alt="下载 (69)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(70).png" alt="下载 (70)"></p>
<p>A，C被划分到左节点，A的实际信用卡额度为8000元，而预测值为10000，因此，A的残差为8000-10000&#x3D;-2000，同理，C的残差为25000-20000&#x3D;5000.B，D被划分到右节点，B的残差为30000-35000&#x3D;-5000，D的残差为40000-35000&#x3D;5000</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(71).png" alt="下载 (71)"></p>
<p>在这棵树中，A，B被划分到左节点，A的实际残差为-2000，而预测的残差为-3000，那么此时A的新残差，即残差的残差为-2000-（-3000）&#x3D;1000，同理，B的新残差为-5000-（-5000）&#x3D;0.C，D被划分到右节点，C的新残差为5000-5000&#x3D;0，D的新残差为5000-5000&#x3D;0.继续用第二棵树产生的新残差去拟合第三棵树，并不断重复此步骤，使残差变小</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(72).png" alt="下载 (72)"></p>
<h3 id="9-3-2-GBDT算法的数学原理概述"><a href="#9-3-2-GBDT算法的数学原理概述" class="headerlink" title="9.3.2 GBDT算法的数学原理概述"></a>9.3.2 GBDT算法的数学原理概述</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(73).png" alt="下载 (73)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(74).png" alt="下载 (74)"></p>
<h3 id="9-3-3-GBDT算法的数学原理举例（略）"><a href="#9-3-3-GBDT算法的数学原理举例（略）" class="headerlink" title="9.3.3 GBDT算法的数学原理举例（略）"></a>9.3.3 GBDT算法的数学原理举例（略）</h3><h3 id="9-3-4-GBDT算法的简单代码实现"><a href="#9-3-4-GBDT算法的简单代码实现" class="headerlink" title="9.3.4 GBDT算法的简单代码实现"></a>9.3.4 GBDT算法的简单代码实现</h3><p>1.GBDT分类模型演示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">model = GradientBoostingClassifier(random_state=<span class="number">123</span>)</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<p>2.GBDT回归模型演示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">model = GradientBoostingRegressor(random_state=<span class="number">123</span>)</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[2.54908866]
</code></pre>
<h2 id="9-4-GBDT案例实战-产品定价模型"><a href="#9-4-GBDT案例实战-产品定价模型" class="headerlink" title="9.4 GBDT案例实战 - 产品定价模型"></a>9.4 GBDT案例实战 - 产品定价模型</h2><h3 id="9-4-1-案例背景"><a href="#9-4-1-案例背景" class="headerlink" title="9.4.1 案例背景"></a>9.4.1 案例背景</h3><p>根据图书页数，纸张，类别，内容，作者及读者等因素对图书进行定价，该产品定价模型也可以用于其他领域的产品定价，如金融产品的定价</p>
<h3 id="9-4-2-模型搭建"><a href="#9-4-2-模型搭建" class="headerlink" title="9.4.2 模型搭建"></a>9.4.2 模型搭建</h3><p>1.读取数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;产品定价模型.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>页数</th>
      <th>类别</th>
      <th>彩印</th>
      <th>纸张</th>
      <th>价格</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>207</td>
      <td>技术类</td>
      <td>0</td>
      <td>双胶纸</td>
      <td>60</td>
    </tr>
    <tr>
      <th>1</th>
      <td>210</td>
      <td>技术类</td>
      <td>0</td>
      <td>双胶纸</td>
      <td>62</td>
    </tr>
    <tr>
      <th>2</th>
      <td>206</td>
      <td>技术类</td>
      <td>0</td>
      <td>双胶纸</td>
      <td>62</td>
    </tr>
    <tr>
      <th>3</th>
      <td>218</td>
      <td>技术类</td>
      <td>0</td>
      <td>双胶纸</td>
      <td>64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>209</td>
      <td>技术类</td>
      <td>0</td>
      <td>双胶纸</td>
      <td>60</td>
    </tr>
  </tbody>
</table>
</div>



<p>类别包技术类，教辅类，办公类3种；纸张包含双胶纸，铜版纸，书写纸3种</p>
<p>用value_counts查看各个分类的数据量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;类别&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>技术类    336
教辅类    333
办公类    331
Name: 类别, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;彩印&#x27;</span>].value_counts() <span class="comment"># 0代表黑白印刷，1为彩色印刷</span></span><br></pre></td></tr></table></figure>




<pre><code>0    648
1    352
Name: 彩印, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;纸张&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>双胶纸    615
铜版纸    196
书写纸    189
Name: 纸张, dtype: int64
</code></pre>
<p>2.分类型文本变量处理</p>
<p>因为“类别”和“纸张”两列是分类型文本变量，所以可以用LabelEncoder（）函数进行数值化处理，便于后续进行拟合，关于LabelEncoder（）函数将在第11章详细地讲解</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">le = LabelEncoder()</span><br><span class="line">df[<span class="string">&#x27;类别&#x27;</span>] = le.fit_transform(df[<span class="string">&#x27;类别&#x27;</span>])  <span class="comment"># 处理类别</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将类别一列处理后，我们可以使用value_counts()方法查看转化效果：</span></span><br><span class="line">df[<span class="string">&#x27;类别&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>1    336
2    333
0    331
Name: 类别, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面我们使用同样的方法处理“纸张”一列：</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">df[<span class="string">&#x27;纸张&#x27;</span>] = le.fit_transform(df[<span class="string">&#x27;纸张&#x27;</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时的表格如下：</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>页数</th>
      <th>类别</th>
      <th>彩印</th>
      <th>纸张</th>
      <th>价格</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>207</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>60</td>
    </tr>
    <tr>
      <th>1</th>
      <td>210</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>62</td>
    </tr>
    <tr>
      <th>2</th>
      <td>206</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>62</td>
    </tr>
    <tr>
      <th>3</th>
      <td>218</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>209</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>60</td>
    </tr>
  </tbody>
</table>
</div>



<p>3.提取特征变量和目标变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = df.drop(columns=<span class="string">&#x27;价格&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;价格&#x27;</span>]  </span><br></pre></td></tr></table></figure>

<p>4.划分训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<p>5.模型训练及搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line">model = GradientBoostingRegressor(random_state=<span class="number">123</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>GradientBoostingRegressor(random_state=123)
</code></pre>
<h3 id="9-4-3-模型预测即评估"><a href="#9-4-3-模型预测即评估" class="headerlink" title="9.4.3 模型预测即评估"></a>9.4.3 模型预测即评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型搭建完毕后，通过如下代码预测测试集数据：</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred[<span class="number">0</span>:<span class="number">50</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[ 71.15004038  79.56199921  68.21751792  90.78788507  78.88479128
  42.28022702  39.27334177  60.74670841  53.59744659  77.65931771
  80.22295545  76.04437155  79.56199921  58.40372895  79.65245266
  44.27997693  53.18177447  35.31452467  92.1798291   58.40372895
  41.96644278  99.50466356  80.22295545  79.69648341  91.45061741
  42.93885741  42.86973046  75.71824996  48.55203652  62.94185778
  39.47077874  61.54190648  95.18389309  51.88118394  65.1293139
  50.17577837  39.54495179  83.63542315  56.24632221 102.1176112
  48.89080247  49.23639342  33.03502962  52.74862135  35.47220867
  35.00370671  53.9446399   74.62364353  35.31452467  53.9446399 ]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过和之前章节类似的代码，我们可以将预测值和实际值进行对比：</span></span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>71.150040</td>
      <td>75</td>
    </tr>
    <tr>
      <th>1</th>
      <td>79.561999</td>
      <td>84</td>
    </tr>
    <tr>
      <th>2</th>
      <td>68.217518</td>
      <td>68</td>
    </tr>
    <tr>
      <th>3</th>
      <td>90.787885</td>
      <td>90</td>
    </tr>
    <tr>
      <th>4</th>
      <td>78.884791</td>
      <td>85</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看预测评分 - 方法1：自带的score函数，本质就是R-squared值（也即统计学中常说的R^2)</span></span><br><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.8741691363311168
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看预测评分 - 方法2：r2_score()函数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2 = r2_score(y_test, model.predict(X_test))</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br></pre></td></tr></table></figure>

<pre><code>0.8741691363311168
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看特征重要性</span></span><br><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure>




<pre><code>array([0.49070203, 0.44718694, 0.04161545, 0.02049558])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过DataFrame的方式展示特征重要性</span></span><br><span class="line">features = X.columns  <span class="comment"># 获取特征名称</span></span><br><span class="line">importances = model.feature_importances_  <span class="comment"># 获取特征重要性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过二维表格形式显示</span></span><br><span class="line">importances_df = pd.DataFrame()</span><br><span class="line">importances_df[<span class="string">&#x27;特征名称&#x27;</span>] = features</span><br><span class="line">importances_df[<span class="string">&#x27;特征重要性&#x27;</span>] = importances</span><br><span class="line">importances_df.sort_values(<span class="string">&#x27;特征重要性&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>特征名称</th>
      <th>特征重要性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>页数</td>
      <td>0.490702</td>
    </tr>
    <tr>
      <th>1</th>
      <td>类别</td>
      <td>0.447187</td>
    </tr>
    <tr>
      <th>2</th>
      <td>彩印</td>
      <td>0.041615</td>
    </tr>
    <tr>
      <th>3</th>
      <td>纸张</td>
      <td>0.020496</td>
    </tr>
  </tbody>
</table>
</div>



<p>可以看到，页数和类别重要性较高</p>
<h3 id="9-4-4-模型参数介绍"><a href="#9-4-4-模型参数介绍" class="headerlink" title="9.4.4 模型参数介绍"></a>9.4.4 模型参数介绍</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回归模型，通过如下代码可以查看官方介绍</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line">GradientBoostingRegressor?</span><br></pre></td></tr></table></figure>

<p><img src="%E4%B8%8B%E8%BD%BD%20(75).png" alt="下载 (75)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(76).png" alt="下载 (76)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(77).png" alt="下载 (77)"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分类模型，通过如下代码可以查看官方介绍</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">GradientBoostingClassifier?</span><br></pre></td></tr></table></figure>

<p>GBDT分类模型的常用参数和GDBT回归模型基本一致，唯一不同的是多了一个loss参数</p>
<p>loss参数：损失函数：取值范围为{‘deviance’,’exponential’}，其中’deviance’为对数损失函数，’exponential’为指数损失函数。默认为’deviance’</p>
<p><strong>补充：损失函数</strong></p>
<p>为了判断模型拟合的效果，我们会用损失函数（Loss Function）来衡量拟合程度，其实质就是根据实际值和预测值间的距离评估模型好坏。常用的损失函数$L(y,f(x))$见下表<br><img src="%E4%B8%8B%E8%BD%BD%20(78).png" alt="下载 (78)"><br>针对离散变量（即分类问题分析），常用0-1损失函数和指数损失函数；针对连续型变量（即回归问题分析)，常用L1范数损失函数和L2范数损失函数。损失函数越小，代表模型拟合的效果越好。下面对损失函数进行一些解释说明：</p>
<p>当y是离散型变量时，对应的问题都是分类问题：</p>
<p>1.实际值y和预测值f(x)都规定取±1</p>
<p>2.假设用1表示正类，-1表示反类，那么yf(x)&gt;0代表预测结果和真实结果一致，因而损失函数低；反之yf(x)&lt;0代表预测结果和真实结果不一致，因而损失函数高</p>
<p>3.以指数损失函数为例，如果实际值y和预测值f(x)一致，例如都为-1，那么此时损失函数为exp(-1x-1x-1)&#x3D;exp(-1)，小于两者不一致时的损失函数exp(1)。</p>
<p>当y时连续型变量时，对应的问题都是回归问题</p>
<p>1.实际值y和预测值f(x)可以取任实数</p>
<p>2.损失函数里面都有|y-f(x)|这一项，而且损失函数是它的增函数，所以当实际值y和预测值f(x)之间差别越大，损失函数越高，反之则越低</p>
<p>3.举个极端的例子，倘若预测值f(x)和实际值y完全一致，那么此时的损失函数为0，也是损失函数最低的情况</p>
<p>理解了损失函数，也就可以理解风险函数。风险函数可以认为是平均意义下的损失，又称为期望函数（expected loss）,其表达式如下：<br><img src="%E4%B8%8B%E8%BD%BD%20(79).png" alt="下载 (79)"><br>其中N为总样本数，yi是样本i的实际值，f(xi)是样本i的预测值</p>
<p>但损失函数也并非越小越好，若损失函数过小，容易出现过拟合。为了避免这个问题，可以在损失函数种加入正则化项或惩罚项，表达式如下：</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(80).png" alt="下载 (80)"></p>
<p>其中λ是正则化系数，J(f)是正则化项，了解即可</p>
<h1 id="10-机器学习神器：XGBoost与LightGBM算法"><a href="#10-机器学习神器：XGBoost与LightGBM算法" class="headerlink" title="10 机器学习神器：XGBoost与LightGBM算法"></a>10 机器学习神器：XGBoost与LightGBM算法</h1><p>这两种算法运行速度快，预测准确率高，且<strong>支持并行操作</strong>，极大地提升了机器学习的效率和效果，无论分类还是回归</p>
<h2 id="10-1-XGBoost算法原理"><a href="#10-1-XGBoost算法原理" class="headerlink" title="10.1 XGBoost算法原理"></a>10.1 XGBoost算法原理</h2><h3 id="10-1-1XGBoost算法的核心思想"><a href="#10-1-1XGBoost算法的核心思想" class="headerlink" title="10.1. 1XGBoost算法的核心思想"></a>10.1. 1XGBoost算法的核心思想</h3><p>最好方法是看文档：<a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/">https://xgboost.readthedocs.io</a></p>
<p>XGBoost算法在某种程度上可以说是GDBT算法的改良版，两者在本质上都是利用了Boosting算法种拟合残差的思想，下图所示为9.3.1小节讲解GDBT算法时提到的信用卡信用额度预测模型，其中初始决策树的预测结果不完全准确，会产生一些残差，因此会用新的决策树来拟合该残差，新的决策树又会产生新的残差，这时再构造新的决策树来拟合新的残差…如此迭代下去，直至符合预先设定的条件为止<br><img src="%E4%B8%8B%E8%BD%BD%20(81).png" alt="下载 (81)"><br>既然XGBoost算法的核心思想与GBDT算法一样，那么其优势又是什么呢？就是下一小节的内容</p>
<h3 id="10-1-2-XGBoost算法的数学原理概述"><a href="#10-1-2-XGBoost算法的数学原理概述" class="headerlink" title="10.1.2 XGBoost算法的数学原理概述"></a>10.1.2 XGBoost算法的数学原理概述</h3><p><img src="%E4%B8%8B%E8%BD%BD%20(82).png" alt="下载 (82)"></p>
<h3 id="10-1-3-XGBoost算法的简单代码实现"><a href="#10-1-3-XGBoost算法的简单代码实现" class="headerlink" title="10.1.3 XGBoost算法的简单代码实现"></a>10.1.3 XGBoost算法的简单代码实现</h3><p>XGBoost模型既可以做分类分析，也可以做回归分析，分别对应的模型为XGBoost分类模型（XGBClassifier）及XGBoost回归模型（XGBRegressor）。</p>
<p>1.分类模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># XGBoost分类模型的引入方式：</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Jupyter Notebook编辑器中，在引入该库后，可以通过如下代码获取官方讲解内容（需取消注释）：</span></span><br><span class="line">XGBClassifier?</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># XGBoost分类模型简单代码演示如下所示：</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]])  </span><br><span class="line"><span class="comment"># 2020年升级后必须是numpy或者DataFrame格式</span></span><br><span class="line"><span class="comment"># XGBoost分类模型的特征变量只支持array数组类型或DataFrame二维表格类型的数据</span></span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">model = XGBClassifier()</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict(np.array([[<span class="number">5</span>, <span class="number">5</span>]])))</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<p>其中X是特征变量，其共有2个特征；y是目标变量；第4行代码使用array数组类型的数据做演示，因为XGBoost分类模型的特征变量不支持直接输入list列表类型的数据，可以传入array数组格式的数据或者DataFrame二维表格格式的数据；第7行引入模型；第8行通过fit()函数训练模型；最后1行通过predict()函数进行预测。</p>
<p>2.回归模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># XGBoost回归模型的引入方式：</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Jupyter Notebook编辑器中，在引入该库后，可以通过如下代码获取官方讲解内容（需取消注释）：</span></span><br><span class="line">XGBRegressor?</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># XGBoost回归模型简单代码演示如下所示：</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]])</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">model = XGBRegressor()</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict(np.array([[<span class="number">5</span>, <span class="number">5</span>]])))</span><br></pre></td></tr></table></figure>

<pre><code>[3.0000014]
</code></pre>
<p>其中X是特征变量，其共有2个特征；y是目标变量；第5行引入模型；第6行通过fit()函数训练模型；最后1行通过predict()函数进行预测。</p>
<h2 id="10-2-XGBoost算法案例实战1：金融反欺诈模型"><a href="#10-2-XGBoost算法案例实战1：金融反欺诈模型" class="headerlink" title="10.2 XGBoost算法案例实战1：金融反欺诈模型"></a>10.2 XGBoost算法案例实战1：金融反欺诈模型</h2><h3 id="10-2-1-案例背景"><a href="#10-2-1-案例背景" class="headerlink" title="10.2.1 案例背景"></a>10.2.1 案例背景</h3><p>信用卡盗刷一般发生在持卡人信息被不法分子窃取后复制卡片进行消费或信用卡被他人冒领后激活并消费等情况下。一旦发生信用卡盗刷，持卡人和银行都会遭到一定的经济损失。因此，通过大数据技术搭建金融反欺诈模型对银行来说尤为重要</p>
<h3 id="10-2-2-模型搭建"><a href="#10-2-2-模型搭建" class="headerlink" title="10.2.2 模型搭建"></a>10.2.2 模型搭建</h3><p>1.读取数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;信用卡交易数据.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>换设备次数</th>
      <th>支付失败次数</th>
      <th>换IP次数</th>
      <th>换IP国次数</th>
      <th>交易金额</th>
      <th>欺诈标签</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>11</td>
      <td>3</td>
      <td>5</td>
      <td>28836</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>6</td>
      <td>1</td>
      <td>4</td>
      <td>21966</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>18199</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>8</td>
      <td>2</td>
      <td>2</td>
      <td>24803</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>10</td>
      <td>5</td>
      <td>0</td>
      <td>26277</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>1代表欺诈，0代表正常交易，本次欺诈样本和非欺诈样本数量之比为4：6</p>
<p>2.提取特征变量和目标变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码将特征变量和目标变量单独提取出来，代码如下：</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;欺诈标签&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;欺诈标签&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>3.划分训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提取完特征变量后，通过如下代码将数据拆分为训练集及测试集：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<p>4.模型训练及搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 划分为训练集和测试集之后，就可以引入XGBoost分类器进行模型训练了，代码如下：</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line">clf = XGBClassifier(n_estimators=<span class="number">100</span>, learning_rate=<span class="number">0.05</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=None, num_parallel_tree=None,
              predictor=None, random_state=None, ...)
</code></pre>
<p>设置弱学习器的最大迭代次数，或者说弱学习器的个数n_estimators参数为100，以及弱学习器的权重缩减系数learning_rate为0.05.其余参数都使用默认值</p>
<h3 id="10-2-3-模型预测及评估"><a href="#10-2-3-模型预测及评估" class="headerlink" title="10.2.3 模型预测及评估"></a>10.2.3 模型预测及评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型搭建完毕后，通过如下代码预测测试集数据：</span></span><br><span class="line">y_pred = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line">y_pred  <span class="comment"># 打印预测结果</span></span><br></pre></td></tr></table></figure>




<pre><code>array([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,
       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,
       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,
       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,
       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,
       1, 1])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过和之前章节类似的代码，我们可以将预测值和实际值进行对比：</span></span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以看到此时前五项的预测准确度为60%，如果想看所有测试集数据的预测准确度，可以使用如下代码：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.875
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们还可以通过XGBClassifier()自带的score()函数来查看模型预测的准确度评分，代码如下，获得的结果同样是0.875。</span></span><br><span class="line">clf.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.875
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># XGBClassifier分类器本质预测的并不是准确的0或1的分类，而是预测其属于某一分类的概率，可以通过predict_proba()函数查看预测属于各个分类的概率，代码如下：</span></span><br><span class="line">y_pred_proba = clf.predict_proba(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred_proba[<span class="number">0</span>:<span class="number">5</span>])  <span class="comment"># 查看前5个预测的概率</span></span><br></pre></td></tr></table></figure>

<pre><code>[[0.8265032  0.1734968 ]
 [0.02098632 0.9790137 ]
 [0.0084281  0.9915719 ]
 [0.8999369  0.1000631 ]
 [0.8290514  0.17094862]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时的y_pred_proba是个二维数组，其中第一列为分类为0（也即非欺诈）的概率，第二列为分类为1（也即欺诈）的概率，因此如果想查看欺诈（分类为1）的概率，可采用如下代码：</span></span><br><span class="line">y_pred_proba[:,<span class="number">1</span>]  <span class="comment"># 分类为1的概率</span></span><br></pre></td></tr></table></figure>




<pre><code>array([0.1734968 , 0.9790137 , 0.9915719 , 0.1000631 , 0.17094862,
       0.05910175, 0.9910392 , 0.09681219, 0.13342692, 0.15539762,
       0.83505297, 0.9910547 , 0.98652124, 0.9880756 , 0.9861544 ,
       0.13701914, 0.15566298, 0.24118835, 0.0716177 , 0.0971779 ,
       0.9872772 , 0.99113035, 0.99113035, 0.20501429, 0.12557584,
       0.12667589, 0.08110589, 0.10515223, 0.10336555, 0.98234504,
       0.11010769, 0.97932315, 0.2966702 , 0.98589283, 0.08400521,
       0.12474764, 0.9780611 , 0.9910547 , 0.839576  , 0.09878331,
       0.17097403, 0.9848075 , 0.17696406, 0.14638832, 0.11671831,
       0.09173213, 0.99113035, 0.08742005, 0.12493847, 0.09407753,
       0.9915719 , 0.15416545, 0.12085281, 0.09074759, 0.99113035,
       0.98910844, 0.07672593, 0.9886723 , 0.11257854, 0.08097712,
       0.11765514, 0.08194721, 0.9873984 , 0.13621715, 0.9903751 ,
       0.09413964, 0.09919545, 0.10474715, 0.06866676, 0.87525785,
       0.9888136 , 0.14974338, 0.11260021, 0.08011292, 0.18638378,
       0.1000631 , 0.07405062, 0.37492937, 0.9857265 , 0.14568247,
       0.09535199, 0.1639911 , 0.07690524, 0.20032772, 0.12399109,
       0.9886723 , 0.10535567, 0.11040998, 0.05972508, 0.9798737 ,
       0.14297816, 0.07451618, 0.10238884, 0.9870812 , 0.99168867,
       0.14201386, 0.10069738, 0.18759497, 0.13318208, 0.1685153 ,
       0.07376712, 0.14112188, 0.11628785, 0.4781888 , 0.09823318,
       0.1437491 , 0.98877805, 0.12747341, 0.12959816, 0.98555124,
       0.07324953, 0.11038433, 0.988771  , 0.10186808, 0.9888966 ,
       0.18757948, 0.13055463, 0.12775792, 0.9915719 , 0.10839844,
       0.21509002, 0.13022642, 0.12395982, 0.07925734, 0.09806271,
       0.97831273, 0.15548192, 0.0955901 , 0.9870221 , 0.9900383 ,
       0.12609024, 0.09053145, 0.07040057, 0.12883253, 0.15853025,
       0.125912  , 0.06919833, 0.99107367, 0.13062388, 0.10572928,
       0.9905813 , 0.07501796, 0.1280026 , 0.8297901 , 0.98045105,
       0.08528069, 0.12226298, 0.98722947, 0.11985523, 0.988342  ,
       0.06767909, 0.0841333 , 0.1600859 , 0.089141  , 0.9910547 ,
       0.1915876 , 0.9905813 , 0.8908516 , 0.9910547 , 0.10125441,
       0.98804003, 0.10338342, 0.8437707 , 0.97890466, 0.98632205,
       0.08181637, 0.08730008, 0.3435277 , 0.10980003, 0.10406717,
       0.15214603, 0.17876908, 0.08273794, 0.23869638, 0.08800983,
       0.08689297, 0.1847994 , 0.98582274, 0.06856089, 0.13558023,
       0.08308174, 0.9865254 , 0.20626086, 0.15845102, 0.8526961 ,
       0.08812908, 0.2054528 , 0.9863707 , 0.10820945, 0.12677956,
       0.9894076 , 0.2759298 , 0.19432847, 0.13334355, 0.08436833,
       0.12110002, 0.9886723 , 0.09794194, 0.9880642 , 0.9905813 ],
      dtype=float32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面我们利用4.3节相关代码绘制ROC曲线来评估模型预测的效果：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_499_0.png" alt="output_499_0"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码求出模型的AUC值：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">score = roc_auc_score(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.8684772657918828
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们可以通过查看各个特征的特征重要性(feature importance)来得出信用卡欺诈行为判断中最重要的特征变量：</span></span><br><span class="line">clf.feature_importances_</span><br></pre></td></tr></table></figure>




<pre><code>array([0.40674362, 0.19018467, 0.04100984, 0.33347663, 0.02858528],
      dtype=float32)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下5.2.2节特征重要性相关知识点进行整理，方便结果呈现，代码如下：</span></span><br><span class="line">features = X.columns  <span class="comment"># 获取特征名称</span></span><br><span class="line">importances = clf.feature_importances_  <span class="comment"># 获取特征重要性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过二维表格形式显示</span></span><br><span class="line">importances_df = pd.DataFrame()</span><br><span class="line">importances_df[<span class="string">&#x27;特征名称&#x27;</span>] = features</span><br><span class="line">importances_df[<span class="string">&#x27;特征重要性&#x27;</span>] = importances</span><br><span class="line">importances_df.sort_values(<span class="string">&#x27;特征重要性&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>特征名称</th>
      <th>特征重要性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>换设备次数</td>
      <td>0.406744</td>
    </tr>
    <tr>
      <th>3</th>
      <td>换IP国次数</td>
      <td>0.333477</td>
    </tr>
    <tr>
      <th>1</th>
      <td>支付失败次数</td>
      <td>0.190185</td>
    </tr>
    <tr>
      <th>2</th>
      <td>换IP次数</td>
      <td>0.041010</td>
    </tr>
    <tr>
      <th>4</th>
      <td>交易金额</td>
      <td>0.028585</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="10-2-4-模型参数调优"><a href="#10-2-4-模型参数调优" class="headerlink" title="10.2.4 模型参数调优"></a>10.2.4 模型参数调优</h3><p>本小节要对前面搭建的XGBoost分类模型进行参数调优。这里选取以下参数进行调优：</p>
<p><strong>max_depth</strong>：弱学习器决策树的最大深度，默认取3</p>
<p><strong>n-estimators</strong>：弱学习器的个数，或者说弱学习器的最大迭代次数，默认取100</p>
<p><strong>learning_rate</strong>：学习率，又称为每个弱学习器的权重缩减系数，取值范围为(0,1]，取值较小意味着要达到一定的学习效果，需要更多迭代次数和更多弱学习器，默认值取0.1，通常用n_estimators和learning_rate一起决定算法的拟合效果，所以这两个参数要一起调优</p>
<hr>
<p>使用GridSearch网格搜索进行参数调优</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV  </span><br><span class="line">parameters = &#123;<span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>], <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">50</span>, <span class="number">100</span>, <span class="number">150</span>], <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.2</span>]&#125;  <span class="comment"># 指定模型中参数的范围</span></span><br><span class="line">clf = XGBClassifier()  <span class="comment"># 构建模型</span></span><br><span class="line">grid_search = GridSearchCV(clf, parameters, scoring=<span class="string">&#x27;roc_auc&#x27;</span>, cv=<span class="number">5</span>) <span class="comment"># 以ROC曲线的AUC值作为模型评估标准，并设置cv参数为5，表示交叉验证5次  </span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面我们将数据传入网格搜索模型并输出参数最优值：</span></span><br><span class="line">grid_search.fit(X_train, y_train)  <span class="comment"># 传入数据</span></span><br><span class="line">grid_search.best_params_  <span class="comment"># 输出参数的最优值</span></span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;learning_rate&#39;: 0.05, &#39;max_depth&#39;: 1, &#39;n_estimators&#39;: 100&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面我们根据新的参数建模，首先重新搭建XGBoost分类器，并将训练集数据传入其中：</span></span><br><span class="line">clf = XGBClassifier(max_depth=<span class="number">1</span>, n_estimators=<span class="number">100</span>, learning_rate=<span class="number">0.05</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.05, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=1, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=None, num_parallel_tree=None,
              predictor=None, random_state=None, ...)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为我们是通过ROC曲线的AUC评分作为模型评价准则来进行参数调优的，因此通过如下代码我们来查看新的AUC值：</span></span><br><span class="line">y_pred_proba = clf.predict_proba(X_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">score = roc_auc_score(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(score)</span><br></pre></td></tr></table></figure>

<pre><code>0.8563218390804598
</code></pre>
<p>将获得的AUC评分打印出来为：0.856，比原来没有调参前的0.866还略微低了些，有的读者可能会奇怪为什么调参后的结果还不如未调参时的结果，通常来说参数调优出现这种情况的概率较小（本案例只有1000条数据），这里出现了也正好给大家解释下出现这种情况的原因。</p>
<p>出现这种情况的原因是因为<strong>交叉验证</strong>，我们来简单回顾下5.3节K折交叉验证的思路：它是将原来的测试数据分为K份（这里cv&#x3D;5，即5份），然后在这K份数据中，选K-1份作为训练数据，剩下的1份作为测试数据，训练K次，获得K个的ROC曲线下的AUC值，然后将K个AUC值取平均，取AUC值的均值为最大情况下的参数为模型的最优参数。注意这里AUC值的获取是基于训练集数据，只不过是将训练集数据中的1&#x2F;K作为测试集数据，这里的测试集数据并不是真正的测试集数据y_test，这也是为什么参数调优后结果反而不如不调优的结果的原因。实际应用中，通常不太会出现调参结果不如不调参的结果，出现这种情况某种程度也是因为数据量较小的原因（像本案例为1000条数据）。其他关于参数调优的其他一些注意点请参考5.3节，这里不再赘述。</p>
<p><strong>补充：XGBoost分类模型的常见超参数</strong><br><img src="%E4%B8%8B%E8%BD%BD%20(83).png" alt="下载 (83)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(84).png" alt="下载 (84)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(85).png" alt="下载 (85)"></p>
<p>至于XGBoost回归模型，大多数参数和上表中列举的XGBoost分类模型的参数一致，略微不同的是，objective参数在回归问题中取值为’reg:linear’,而在二分类问题中一般取值为’binary:logistic’，在多分类问题中一般取值为’multi:softmax’。不过当选择XGBoost回归模型时，该参数会自动切换，所以也无须手动调整</p>
<h2 id="10-3-XGBoost算法案例实战2-信用评分模型"><a href="#10-3-XGBoost算法案例实战2-信用评分模型" class="headerlink" title="10.3 XGBoost算法案例实战2 - 信用评分模型"></a>10.3 XGBoost算法案例实战2 - 信用评分模型</h2><p>本节用XGBoost回归模型搭建一个信用评分卡模型，为了凸显该算法的优越性，还将额外运用多元线性回归模型和GBDT回归模型进行模型搭建，并对比3种模型的效果</p>
<h3 id="10-3-1-案例背景"><a href="#10-3-1-案例背景" class="headerlink" title="10.3.1 案例背景"></a>10.3.1 案例背景</h3><p>为降低不良贷款率，保障自身资金安全，提高风险控制水平，银行等金融机构会根据客户的信用历史资料构建信用评分卡模型给客户评分。根据客户的信用得分，可以预估客户按时还款的可能性，并据此决定是否发放贷款及贷款的额度和利率</p>
<h3 id="10-3-2-多元线性回归模型"><a href="#10-3-2-多元线性回归模型" class="headerlink" title="10.3.2 多元线性回归模型"></a>10.3.2 多元线性回归模型</h3><p>1.读取数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;信用评分卡模型.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>月收入</th>
      <th>年龄</th>
      <th>性别</th>
      <th>历史授信额度</th>
      <th>历史违约次数</th>
      <th>信用评分</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7783</td>
      <td>29</td>
      <td>0</td>
      <td>32274</td>
      <td>3</td>
      <td>73</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7836</td>
      <td>40</td>
      <td>1</td>
      <td>6681</td>
      <td>4</td>
      <td>72</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6398</td>
      <td>25</td>
      <td>0</td>
      <td>26038</td>
      <td>2</td>
      <td>74</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6483</td>
      <td>23</td>
      <td>1</td>
      <td>24584</td>
      <td>4</td>
      <td>65</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5167</td>
      <td>23</td>
      <td>1</td>
      <td>6710</td>
      <td>3</td>
      <td>73</td>
    </tr>
  </tbody>
</table>
</div>



<p>共1000条数据，目标变量是信用评分（取值范围是0~100）</p>
<p>2.提取特征变量和目标变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码将特征变量和目标变量单独提取出来，代码如下：</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;信用评分&#x27;</span>)</span><br><span class="line">Y = df[<span class="string">&#x27;信用评分&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>3.模型训练及搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从Scikit-Learn库中引入LinearRegression()模型进行模型训练，代码如下：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(X,Y)</span><br></pre></td></tr></table></figure>




<pre><code>LinearRegression()
</code></pre>
<p>4.线性回归方程构造</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4.线性回归方程构造</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;各系数为:&#x27;</span> + <span class="built_in">str</span>(model.coef_))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;常数项系数k0为:&#x27;</span> + <span class="built_in">str</span>(model.intercept_))</span><br></pre></td></tr></table></figure>

<pre><code>各系数为:[ 5.58658996e-04  1.62842002e-01  2.18430276e-01  6.69996665e-05
 -1.51063940e+00]
常数项系数k0为:67.1668660385318
</code></pre>
<p>5.模型评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用3.2节模型评估的方法对此多元线性回归模型进行评估，代码如下：</span></span><br><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">X2 = sm.add_constant(X)</span><br><span class="line">est = sm.OLS(Y, X2).fit()</span><br><span class="line">est.summary()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;frozen importlib._bootstrap&gt;:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
</code></pre>
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>信用评分</td>       <th>  R-squared:         </th> <td>   0.629</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.628</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   337.6</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 18 Jan 2023</td> <th>  Prob (F-statistic):</th> <td>2.32e-211</td>
</tr>
<tr>
  <th>Time:</th>                 <td>21:44:33</td>     <th>  Log-Likelihood:    </th> <td> -2969.8</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   5952.</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   994</td>      <th>  BIC:               </th> <td>   5981.</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>  <td>   67.1669</td> <td>    1.121</td> <td>   59.906</td> <td> 0.000</td> <td>   64.967</td> <td>   69.367</td>
</tr>
<tr>
  <th>月收入</th>    <td>    0.0006</td> <td> 8.29e-05</td> <td>    6.735</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>
</tr>
<tr>
  <th>年龄</th>     <td>    0.1628</td> <td>    0.022</td> <td>    7.420</td> <td> 0.000</td> <td>    0.120</td> <td>    0.206</td>
</tr>
<tr>
  <th>性别</th>     <td>    0.2184</td> <td>    0.299</td> <td>    0.730</td> <td> 0.466</td> <td>   -0.369</td> <td>    0.806</td>
</tr>
<tr>
  <th>历史授信额度</th> <td>   6.7e-05</td> <td> 7.78e-06</td> <td>    8.609</td> <td> 0.000</td> <td> 5.17e-05</td> <td> 8.23e-05</td>
</tr>
<tr>
  <th>历史违约次数</th> <td>   -1.5106</td> <td>    0.140</td> <td>  -10.811</td> <td> 0.000</td> <td>   -1.785</td> <td>   -1.236</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>13.180</td> <th>  Durbin-Watson:     </th> <td>   1.996</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  12.534</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.236</td> <th>  Prob(JB):          </th> <td> 0.00190</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.721</td> <th>  Cond. No.          </th> <td>4.27e+05</td>
</tr>
</table><br><br>Warnings:<br>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br>[2] The condition number is large, 4.27e+05. This might indicate that there are<br>strong multicollinearity or other numerical problems.


<p><img src="%E4%B8%8B%E8%BD%BD%20(86).png" alt="下载 (86)"><br>这两个数不高，整体拟合效果一般，可能是因为数据量偏少</p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(87).png" alt="下载 (87)"><br>再观察P值，可发现大部分特征变量的P值都很小（小于0，05)，的确是和目标变量“信用评分”显著相关的，而特征变量“性别”的P值达到了0.466，说明该特征变量与目标变量没有显著相关性。因此在多元线性回归模型中可以舍去“性别”这一特征变量</p>
<h3 id="10-3-3-GXDT回归模型"><a href="#10-3-3-GXDT回归模型" class="headerlink" title="10.3.3 GXDT回归模型"></a>10.3.3 GXDT回归模型</h3><p>1.读取数据并提取特征变量和目标变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里使用第九章讲过的GBDT回归模型同样来做一下回归分析，首先读取1000条信用卡客户的数据并划分特征变量和目标变量，这部分代码和上面线性回归的代码是一样的。</span></span><br><span class="line"><span class="comment"># 1.读取数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;信用评分卡模型.xlsx&#x27;</span>)</span><br><span class="line"><span class="comment"># 2.提取特征变量和目标变量</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;信用评分&#x27;</span>)</span><br><span class="line">y = df[<span class="string">&#x27;信用评分&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>2.划分训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过如下代码划分训练集和测试集数据：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<p>3.模型训练及搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 划分训练集和测试集完成后，就可以从Scikit-Learn库中引入GBDT模型进行模型训练了，代码如下：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingRegressor</span><br><span class="line">model = GradientBoostingRegressor()  <span class="comment"># 使用默认参数</span></span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>GradientBoostingRegressor()
</code></pre>
<p>4.模型预测及评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型搭建完毕后，通过如下代码预测测试集数据：</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[70.77631652 71.40032104 73.73465155 84.52533945 71.09188294 84.9327599
 73.72232388 83.44560704 82.61221486 84.86927209]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过和之前章节类似的代码，我们可以将预测值和实际值进行对比：</span></span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>70.776317</td>
      <td>79</td>
    </tr>
    <tr>
      <th>1</th>
      <td>71.400321</td>
      <td>80</td>
    </tr>
    <tr>
      <th>2</th>
      <td>73.734652</td>
      <td>62</td>
    </tr>
    <tr>
      <th>3</th>
      <td>84.525339</td>
      <td>89</td>
    </tr>
    <tr>
      <th>4</th>
      <td>71.091883</td>
      <td>80</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为GradientBoostingRegressor()是一个回归模型，所以我们通过查看其R-squared值来评判模型的拟合效果：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2 = r2_score(y_test, model.predict(X_test))</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br></pre></td></tr></table></figure>

<pre><code>0.6752289995786536
</code></pre>
<p>第1行代码从Scikit-Learn库中引入r2_score()函数；第2行代码将训练集的真实值和模型预测值传入r2_score()函数，得出R-squared评分为0.675，可以看到这个结果较线性回归模型获得的0.629是有所改善的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们还可以通过GradientBoostingRegressor()自带的score()函数来查看模型预测的效果：</span></span><br><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.6752289995786536
</code></pre>
<h3 id="10-3-4-XGBoost回归模型"><a href="#10-3-4-XGBoost回归模型" class="headerlink" title="10.3.4 XGBoost回归模型"></a>10.3.4 XGBoost回归模型</h3><p>1.读取数据、提取变量并划分训练集和测试集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如下所示，其中前3步读取数据，提取特征变量和目标变量，划分训练集和测试集都与GBDT模型相同，因此不再重复，直接从第四步模型开始讲解：</span></span><br><span class="line"><span class="comment"># 1.读取数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;信用评分卡模型.xlsx&#x27;</span>)</span><br><span class="line"><span class="comment"># 2.提取特征变量和目标变量</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;信用评分&#x27;</span>)</span><br><span class="line">y = df[<span class="string">&#x27;信用评分&#x27;</span>]</span><br><span class="line"><span class="comment"># 3.划分测试集和训练集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br></pre></td></tr></table></figure>

<p>2.模型训练及搭建</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 划分训练集和测试集完成后，就可以从Scikit-Learn库中引入XGBRegressor()模型进行模型训练了，代码如下：</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line">model = XGBRegressor()  <span class="comment"># 使用默认参数</span></span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=None, num_parallel_tree=None,
             predictor=None, random_state=None, ...)
</code></pre>
<p>3.模型预测及评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型搭建完毕后，通过如下代码预测测试集数据：</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[74.62306  69.01495  76.393486 83.88998  71.5683   86.257324 76.0784
 81.38994  81.05504  83.24717 ]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过和之前章节类似的代码，我们可以将预测值和实际值进行对比：</span></span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>74.623062</td>
      <td>79</td>
    </tr>
    <tr>
      <th>1</th>
      <td>69.014954</td>
      <td>80</td>
    </tr>
    <tr>
      <th>2</th>
      <td>76.393486</td>
      <td>62</td>
    </tr>
    <tr>
      <th>3</th>
      <td>83.889977</td>
      <td>89</td>
    </tr>
    <tr>
      <th>4</th>
      <td>71.568298</td>
      <td>80</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为XGBRegressor()是一个回归模型，所以通过查看R-squared来评判模型的拟合效果：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2 = r2_score(y_test, model.predict(X_test))</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br></pre></td></tr></table></figure>

<pre><code>0.5715437436791975
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 我们还可以通过XGBRegressor()自带的score()函数来查看模型预测的效果：</span></span><br><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.5715437436791975
</code></pre>
<p>4.查看特征重要性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过10.2.3节讲过的feature_importances_属性，我们来查看模型的特征重要性：</span></span><br><span class="line">features = X.columns  <span class="comment"># 获取特征名称</span></span><br><span class="line">importances = model.feature_importances_  <span class="comment"># 获取特征重要性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过二维表格形式显示</span></span><br><span class="line">importances_df = pd.DataFrame()</span><br><span class="line">importances_df[<span class="string">&#x27;特征名称&#x27;</span>] = features</span><br><span class="line">importances_df[<span class="string">&#x27;特征重要性&#x27;</span>] = importances</span><br><span class="line">importances_df.sort_values(<span class="string">&#x27;特征重要性&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>特征名称</th>
      <th>特征重要性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>月收入</td>
      <td>0.324461</td>
    </tr>
    <tr>
      <th>4</th>
      <td>历史违约次数</td>
      <td>0.307467</td>
    </tr>
    <tr>
      <th>3</th>
      <td>历史授信额度</td>
      <td>0.202864</td>
    </tr>
    <tr>
      <th>1</th>
      <td>年龄</td>
      <td>0.098869</td>
    </tr>
    <tr>
      <th>2</th>
      <td>性别</td>
      <td>0.066339</td>
    </tr>
  </tbody>
</table>
</div>



<p>5.模型参数调优</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过和10.2.4节类似的代码，我们可以对XGBoost回归模型进行参数调优，代码如下：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV  </span><br><span class="line">parameters = &#123;<span class="string">&#x27;max_depth&#x27;</span>: [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>], <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">50</span>, <span class="number">100</span>, <span class="number">150</span>], <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.2</span>]&#125;  <span class="comment"># 指定模型中参数的范围</span></span><br><span class="line">clf = XGBRegressor()  <span class="comment"># 构建回归模型</span></span><br><span class="line">grid_search = GridSearchCV(model, parameters, scoring=<span class="string">&#x27;r2&#x27;</span>, cv=<span class="number">5</span>) </span><br></pre></td></tr></table></figure>

<p>这里唯一需要注意的是最后一行代码中的scoring参数需要设置成’r2’，其表示的是R-squared值，因为是回归模型，所以参数调优时应该选择R-squared值来进行评判，而不是分类模型中常用的准确度’accuracy’或者ROC曲线对应的AUC值’roc_auc’。</p>
<p>通过如下代码获取最优参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grid_search.fit(X_train, y_train)  <span class="comment"># 传入数据</span></span><br><span class="line">grid_search.best_params_  <span class="comment"># 输出参数的最优值</span></span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;learning_rate&#39;: 0.1, &#39;max_depth&#39;: 3, &#39;n_estimators&#39;: 50&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在模型中设置参数，代码如下：</span></span><br><span class="line">model = XGBRegressor(max_depth=<span class="number">3</span>, n_estimators=<span class="number">50</span>, learning_rate=<span class="number">0.1</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.1, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=3, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=50, n_jobs=None, num_parallel_tree=None,
             predictor=None, random_state=None, ...)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此时再通过r2_score()函数进行模型评估，代码如下（也可以用model.score(X_test, y_test)进行评分，效果一样）：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2 = r2_score(y_test, model.predict(X_test))</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br></pre></td></tr></table></figure>

<pre><code>0.6884477645003766
</code></pre>
<p><strong>补充知识点2：对于XGBoost模型，有必要做很多数据预处理吗？</strong></p>
<p>在传统的机器模型中，我们往往需要做挺多的数据预处理，例如数据的归一化、缺失值及异常值的处理等（这些会在第十一章着重讲解），但是对于XGBoost模型而言，很多预处理都是不需要的，例如对于缺失值而言，XGBoost模型会自动处理，它会通过枚举所有缺失值在当前节点是进入左子树还是右子树来决定缺失值的处理方式。</p>
<p>此外由于XGBoost是基于决策树模型，因此区别于线性回归等模型，像一些特征变换（例如离散化、归一化或者叫作标准化、取log、共线性问题处理等）都不太需要，这也是树模型的一个优点。如果有的读者还不太放心，可以自己尝试下做一下特征变换，例如数据归一化，会发现最终的结果都是一样的。这里给大家简单示范一下，通过如下代码对数据进行Z-score标准化或者叫作归一化(这部分内容也会在11.3节进行讲解)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">X_new = StandardScaler().fit_transform(X)</span><br><span class="line"></span><br><span class="line">X_new  <span class="comment"># 打印标准化后的数据</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[-0.88269208, -1.04890243, -1.01409939, -0.60873764,  0.63591822],
       [-0.86319167,  0.09630122,  0.98609664, -1.55243002,  1.27956013],
       [-1.39227834, -1.46534013, -1.01409939, -0.83867808, -0.0077237 ],
       ...,
       [ 1.44337605,  0.61684833,  0.98609664,  1.01172301, -0.0077237 ],
       [ 0.63723633, -0.21602705,  0.98609664, -0.32732239, -0.0077237 ],
       [ 1.57656755,  0.61684833, -1.01409939,  1.30047599, -0.0077237 ]])
</code></pre>
<p>利用标准化后的数据进行建模，看看是否有差别：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.划分测试集和训练集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.建模</span></span><br><span class="line"><span class="comment"># 划分训练集和测试集完成后，就可以从Scikit-Learn库中引入XGBRegressor()模型进行模型训练了，代码如下：</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line">model = XGBRegressor()  <span class="comment"># 使用默认参数</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为XGBRegressor()是一个回归模型，所以通过查看R-squared来评判模型的拟合效果：</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2 = r2_score(y_test, model.predict(X_test))</span><br><span class="line"><span class="built_in">print</span>(r2)</span><br></pre></td></tr></table></figure>

<pre><code>0.5716150813375576
</code></pre>
<p>此时再对这个X_new通过train_test_split()函数划分测试集和训练集，并进行模型的训练，最后通过r2_score()获得模型评分，会发现结果和没有归一化的数据的结果几乎一样，为0.571。这里也验证了树模型不需要进行特征的归一化或者说标准化，此外树模型对于共线性也不敏感。</p>
<p>通过上面这个演示，也可以得出这么一个读者经常会问到的一个疑问：需不需要进行某种数据预处理？以后如果还有这样的疑问，那么不妨就做一下该数据预处理，如果发现最终结果没有区别，那就能够明白对于该模型不需要做相关数据预处理。<br>当然绝大部分模型都无法自动完成的一步就是特征提取。很多自然语言处理的问题或者图象的问题，没有现成的特征，需要人工去提取这些特征。</p>
<p>综上来说，XGBoost的确比线性模型要省去很多特征工程的步骤，但是特征工程依然是非常必要的，这一结论同样适用于下面即将讲到的LightGBM模型。</p>
<h2 id="10-4-LightGBM算法原理"><a href="#10-4-LightGBM算法原理" class="headerlink" title="10.4 LightGBM算法原理"></a>10.4 LightGBM算法原理</h2><h3 id="10-4-1-LightGBM算法的核心思想"><a href="#10-4-1-LightGBM算法的核心思想" class="headerlink" title="10.4.1 LightGBM算法的核心思想"></a>10.4.1 LightGBM算法的核心思想</h3><p>该算法由微软研发，采用损失函数的负梯度作为当前决策树的残差近似值，去拟合新的决策树，与传统机器学习算法相比，LightGBM具有如下优势：训练效率更高，低内存使用，准确率更高，支持并行化学习，可以处理大规模数据</p>
<h3 id="10-4-2-LightGBM算法的数学原理概述"><a href="#10-4-2-LightGBM算法的数学原理概述" class="headerlink" title="10.4.2 LightGBM算法的数学原理概述"></a>10.4.2 LightGBM算法的数学原理概述</h3><p>最好的方法是看文档：<a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/">https://lightgbm.readthedocs.io</a></p>
<p>下面讲解一下LightGBM算法数学原理的核心知识点</p>
<p><strong>1.基于leaf-wise的决策树生长策略</strong></p>
<p>大部分决策树算法使用的生长策略是level-wise生长策略，即同一层的叶子节点每次都一起分裂，如下图所示。但实际上一些叶子节点的分裂增益较低，这样分裂会增加不小的开销<br><img src="%E4%B8%8B%E8%BD%BD%20(88).png" alt="下载 (88)"></p>
<p>LightGBM算法使用的则是leaf-wise生长策略，每次在当前叶子节点中找出分裂增益最大的叶子节点进行分裂，而不是所有节点都进行分裂，如下图所示，这样可以提高精度。但是，keaf-wise策略在样本量较小是容易造成过拟合，LightGBM算法可以通过参数max_depth限制树的深度来防止过拟合<br><img src="%E4%B8%8B%E8%BD%BD%20(89).png" alt="下载 (89)"></p>
<p><strong>2.直方图算法</strong></p>
<p>直方图分为频数直方图和频率直方图，横坐标为相关数据，纵坐标为该数据出现的频数或频率，用hist()函数绘制如下所示的频数直方图<br><img src="%E4%B8%8B%E8%BD%BD%20(90).png" alt="下载 (90)"><br>直方图算法又称为histogram算法，简单来说，就是先对特征值进行<strong>装箱处理</strong>，将连续的浮点特征值离散化成k个整数，形成一个个箱体（bins），同时构造一个宽度为k的直方图，在遍历数据时，以离散化后的值作为索引在直方图中累计统计量（因此这里是频数直方图)。遍历一次数据后，直方图累计了需要的统计量，再根据直方图的离散值遍历寻找最优分割点。</p>
<p>对于连续特征来说，装箱处理就是特征工程中的离散化。例如， 【0，10） 区间的值都赋值为0，【10,20) 区间的值都赋值为1等。这样就可以把众多的数值划分到有限的分箱中。LightGBM算法中默认的分箱数（bins）为256</p>
<p>举例来说，现在有10000个客户，也就有10000个身高数据，将身高分箱为256份后（例如，身高180-180.2cm的所有客户都分箱为数字200），就变为256个数据，这时再统计每个数值对应的频数（身高180~180.2cm的所有客户为100人，那么数字200对应的频数就是100）.这样在节点分裂时，就不需要按照预排序算法对每个特征都计算10000遍，而只需要计算256遍（分箱数），大大加快了训练速度。</p>
<p>对于分类特征来说，则是将每一种取值放入一个分箱（bin），且当取值的个数大于最大分箱数时，会忽略那些很少出现的分类值。例如，10000个客户的国籍数据，便可以按国家名称进行分箱，如果超过最大分箱数（如256），那么很少出现的国家就会被忽略</p>
<p><strong>3.并行学习</strong></p>
<p>LightGBM算法支持<strong>特征并行</strong>和<strong>数据并行</strong>两种学习方式。传统的特征并行的主要思想是在并行化决策树中寻找最佳分割点，在数据量大时难以加速，同时需要对切分结果进行通信整合。而LightGBM算法在本地保存全部数据，这样就没有了机器间通信所需的开销。此外，传统的数据并行时构建本地直方图，然后进行整合，在全局直方图中寻找最佳切分点。LightGBM算法则使用分散规约（reduce scatter），将直方图合并的任务分给不同的机器，降低通信和计算的开销，并利用直方图做加速训练，进一步减少开销。</p>
<p>除了以上原理，LightGBM算法还包含一些重要的算法思想，如单边梯度采样GOSS算法和互斥特征绑定EFB算法。在GOSS算法中，梯度更大的样本点在计算信息增益时会发挥更重要的作用，当对样本进行下采样保留这些梯度较大的样本点，并随机去掉梯度小的样本点。EFB算法则将互斥特征绑在一起以减少特征维度。</p>
<h3 id="10-4-3-LightGBM算法的简单代码实现"><a href="#10-4-3-LightGBM算法的简单代码实现" class="headerlink" title="10.4.3 LightGBM算法的简单代码实现"></a>10.4.3 LightGBM算法的简单代码实现</h3><p>LightGBM模型既可以做分类分析，也可以做回归分析，分别对应的模型为LightGBM分类模型（LGBMClassifier）及LightGBM回归模型（LGBMRegressor）。</p>
<p>1.分类模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LightGBM分类模型简单代码演示如下所示：</span></span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line"></span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">model = LGBMClassifier()</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[0]
</code></pre>
<p>其中X是特征变量，其共有2个特征；y是目标变量；第5行引入模型；第6行通过fit()函数训练模型；最后1行通过predict()函数进行预测。</p>
<p>2.回归模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Jupyter Notebook编辑器中，在引入该库后，可以通过如下代码获取官方讲解内容：（需取消注释）</span></span><br><span class="line">LGBMRegressor?</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LightGBM回归模型简单代码演示如下所示：</span></span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMRegressor</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]]</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">model = LGBMRegressor()</span><br><span class="line">model.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.predict([[<span class="number">5</span>, <span class="number">5</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[3.]
</code></pre>
<h2 id="10-5-LightGBM算法案例实战1：客户违约预测模型"><a href="#10-5-LightGBM算法案例实战1：客户违约预测模型" class="headerlink" title="10.5 LightGBM算法案例实战1：客户违约预测模型"></a>10.5 LightGBM算法案例实战1：客户违约预测模型</h2><h3 id="10-5-1-案例背景"><a href="#10-5-1-案例背景" class="headerlink" title="10.5.1 案例背景"></a>10.5.1 案例背景</h3><p>银行等金融机构经常会根据客户的个人资料、财产等情况，来预测借款客户是否会违约，从而进行贷前审核，贷中管理，贷后违约处理等工作。金融处理的就是风险，需要在风险和收益间寻求到一个平衡点，现代金融某种程度上便是一个风险定价的过程，通过个人的海量数据，从而对其进行风险评估并进行合适的借款利率定价，这便是一个典型的风险定价过程，这也被称之为大数据风控。</p>
<h3 id="10-5-2-模型搭建"><a href="#10-5-2-模型搭建" class="headerlink" title="10.5.2 模型搭建"></a>10.5.2 模型搭建</h3><p><strong>1.读取数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.读取数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;客户信息及违约表现.xlsx&#x27;</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>收入</th>
      <th>年龄</th>
      <th>性别</th>
      <th>历史授信额度</th>
      <th>历史违约次数</th>
      <th>是否违约</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>462087</td>
      <td>26</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>362324</td>
      <td>32</td>
      <td>0</td>
      <td>13583</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>332011</td>
      <td>52</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>252895</td>
      <td>39</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>352355</td>
      <td>50</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



<p>读取1000条数据，目标变量为是否违约，若违约标记为1，否则标记为0</p>
<p><strong>2.提取特征变量和目标变量&#x2F;3.划分训练集和测试集&#x2F;4.模型训练和搭建</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2.提取特征变量和目标变量</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;是否违约&#x27;</span>)</span><br><span class="line">Y = df[<span class="string">&#x27;是否违约&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.划分训练集和测试集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.模型训练及搭建</span></span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line">model = LGBMClassifier()</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>LGBMClassifier()
</code></pre>
<h3 id="10-5-3-模型预测及评估"><a href="#10-5-3-模型预测及评估" class="headerlink" title="10.5.3 模型预测及评估"></a>10.5.3 模型预测及评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测测试集数据</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>[1 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0
 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 1
 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0
 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1
 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0
 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测值和实际值对比</span></span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">score = accuracy_score(y_pred, y_test)</span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.78
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看得分</span></span><br><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.78
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看预测属于各个分类的概率</span></span><br><span class="line">y_pred_proba = model.predict_proba(X_test)</span><br><span class="line">y_pred_proba</span><br></pre></td></tr></table></figure>




<pre><code>array([[9.23160061e-04, 9.99076840e-01],
       [8.83139907e-01, 1.16860093e-01],
       [1.02049035e-02, 9.89795097e-01],
       [9.98549401e-01, 1.45059936e-03],
       [1.53030489e-01, 8.46969511e-01],
       [9.47957121e-01, 5.20428789e-02],
       [5.93375667e-04, 9.99406624e-01],
       [9.18125428e-01, 8.18745723e-02],
       [9.90917969e-01, 9.08203059e-03],
       [8.37315637e-01, 1.62684363e-01],
       [1.38299904e-02, 9.86170010e-01],
       [5.55705275e-04, 9.99444295e-01],
       [1.62601027e-01, 8.37398973e-01],
       [5.94276287e-01, 4.05723713e-01],
       [5.81701526e-03, 9.94182985e-01],
       [5.84880363e-01, 4.15119637e-01],
       [2.94447586e-01, 7.05552414e-01],
       [1.67458977e-01, 8.32541023e-01],
       [9.90972585e-01, 9.02741502e-03],
       [9.62402687e-01, 3.75973126e-02],
       [2.44305822e-03, 9.97556942e-01],
       [9.73598346e-01, 2.64016536e-02],
       [3.39364870e-03, 9.96606351e-01],
       [3.35544336e-01, 6.64455664e-01],
       [9.82397600e-01, 1.76024003e-02],
       [9.71460059e-01, 2.85399407e-02],
       [9.58518760e-01, 4.14812403e-02],
       [8.07022448e-03, 9.91929776e-01],
       [9.17226788e-01, 8.27732125e-02],
       [9.94194364e-01, 5.80563600e-03],
       [9.86284029e-01, 1.37159709e-02],
       [1.72645621e-02, 9.82735438e-01],
       [9.68614189e-01, 3.13858108e-02],
       [5.01087538e-03, 9.94989125e-01],
       [9.41226193e-01, 5.87738071e-02],
       [4.39429163e-02, 9.56057084e-01],
       [7.91124725e-01, 2.08875275e-01],
       [1.20421033e-02, 9.87957897e-01],
       [8.45566643e-02, 9.15443336e-01],
       [6.03680861e-01, 3.96319139e-01],
       [8.99893050e-01, 1.00106950e-01],
       [9.63688554e-01, 3.63114460e-02],
       [9.06662333e-01, 9.33376674e-02],
       [2.97418960e-03, 9.97025810e-01],
       [9.24191577e-01, 7.58084227e-02],
       [5.46229390e-01, 4.53770610e-01],
       [9.87438641e-01, 1.25613592e-02],
       [1.72400837e-01, 8.27599163e-01],
       [7.43895857e-01, 2.56104143e-01],
       [2.94236130e-03, 9.97057639e-01],
       [1.40762553e-02, 9.85923745e-01],
       [9.99511631e-01, 4.88368640e-04],
       [9.95614617e-01, 4.38538271e-03],
       [8.60804212e-01, 1.39195788e-01],
       [1.40370241e-03, 9.98596298e-01],
       [9.92192539e-01, 7.80746131e-03],
       [3.53639131e-01, 6.46360869e-01],
       [1.63511083e-03, 9.98364889e-01],
       [8.78219029e-01, 1.21780971e-01],
       [7.42675744e-03, 9.92573243e-01],
       [9.58363126e-01, 4.16368742e-02],
       [7.18876748e-01, 2.81123252e-01],
       [9.27168501e-03, 9.90728315e-01],
       [8.89133794e-01, 1.10866206e-01],
       [2.36389045e-03, 9.97636110e-01],
       [8.11413899e-01, 1.88586101e-01],
       [9.95723783e-01, 4.27621695e-03],
       [8.74791781e-01, 1.25208219e-01],
       [6.27761732e-01, 3.72238268e-01],
       [3.29925913e-01, 6.70074087e-01],
       [7.30765531e-01, 2.69234469e-01],
       [9.96324037e-01, 3.67596254e-03],
       [4.90342411e-01, 5.09657589e-01],
       [3.18188822e-03, 9.96818112e-01],
       [9.46898412e-01, 5.31015880e-02],
       [4.88269087e-01, 5.11730913e-01],
       [4.20516319e-01, 5.79483681e-01],
       [9.80219953e-01, 1.97800466e-02],
       [8.04544550e-01, 1.95455450e-01],
       [9.94869285e-01, 5.13071536e-03],
       [9.98352780e-01, 1.64722028e-03],
       [5.51345634e-03, 9.94486544e-01],
       [7.11952213e-01, 2.88047787e-01],
       [4.64253927e-01, 5.35746073e-01],
       [9.48686526e-01, 5.13134743e-02],
       [3.97192849e-01, 6.02807151e-01],
       [8.22145700e-01, 1.77854300e-01],
       [7.20608604e-01, 2.79391396e-01],
       [9.96941974e-01, 3.05802587e-03],
       [3.69200216e-02, 9.63079978e-01],
       [4.68416509e-01, 5.31583491e-01],
       [8.36147573e-01, 1.63852427e-01],
       [9.16274519e-01, 8.37254813e-02],
       [2.56634290e-03, 9.97433657e-01],
       [3.73536529e-03, 9.96264635e-01],
       [4.98355520e-01, 5.01644480e-01],
       [8.16305415e-01, 1.83694585e-01],
       [1.04309175e-01, 8.95690825e-01],
       [7.83779329e-01, 2.16220671e-01],
       [9.78083102e-01, 2.19168975e-02],
       [9.90653791e-01, 9.34620891e-03],
       [8.65661467e-01, 1.34338533e-01],
       [9.13831584e-01, 8.61684159e-02],
       [9.37101199e-01, 6.28988006e-02],
       [1.90620977e-01, 8.09379023e-01],
       [9.32239827e-01, 6.77601733e-02],
       [6.92969039e-04, 9.99307031e-01],
       [9.74408609e-01, 2.55913910e-02],
       [3.53732053e-01, 6.46267947e-01],
       [2.11247791e-01, 7.88752209e-01],
       [9.96303292e-01, 3.69670823e-03],
       [9.44406587e-01, 5.55934132e-02],
       [3.79106068e-02, 9.62089393e-01],
       [9.64609313e-01, 3.53906874e-02],
       [5.41232882e-03, 9.94587671e-01],
       [9.96059538e-01, 3.94046198e-03],
       [9.92143676e-01, 7.85632367e-03],
       [8.42660648e-01, 1.57339352e-01],
       [7.24307887e-03, 9.92756921e-01],
       [9.94312630e-01, 5.68737022e-03],
       [9.15130977e-01, 8.48690229e-02],
       [6.51393245e-01, 3.48606755e-01],
       [2.94340586e-02, 9.70565941e-01],
       [9.87183971e-01, 1.28160289e-02],
       [7.32453035e-01, 2.67546965e-01],
       [9.83352543e-01, 1.66474566e-02],
       [9.81747406e-01, 1.82525938e-02],
       [2.95226633e-02, 9.70477337e-01],
       [1.04715836e-03, 9.98952842e-01],
       [9.32904364e-01, 6.70956356e-02],
       [6.99978847e-01, 3.00021153e-01],
       [5.51184321e-01, 4.48815679e-01],
       [6.75122087e-01, 3.24877913e-01],
       [7.71181218e-01, 2.28818782e-01],
       [9.98413782e-01, 1.58621789e-03],
       [8.76237107e-01, 1.23762893e-01],
       [3.04481117e-01, 6.95518883e-01],
       [9.74363151e-01, 2.56368488e-02],
       [6.33134484e-01, 3.66865516e-01],
       [5.75854374e-01, 4.24145626e-01],
       [2.55537845e-02, 9.74446216e-01],
       [1.85756224e-03, 9.98142438e-01],
       [3.88831138e-02, 9.61116886e-01],
       [9.58731542e-01, 4.12684584e-02],
       [9.36469837e-01, 6.35301629e-02],
       [9.56176915e-01, 4.38230849e-02],
       [6.55053121e-01, 3.44946879e-01],
       [1.94187315e-01, 8.05812685e-01],
       [9.99337468e-01, 6.62531742e-04],
       [3.08437942e-03, 9.96915621e-01],
       [9.96566658e-01, 3.43334162e-03],
       [3.89773650e-01, 6.10226350e-01],
       [9.72082797e-01, 2.79172032e-02],
       [7.59648308e-01, 2.40351692e-01],
       [4.43021427e-04, 9.99556979e-01],
       [9.73066093e-01, 2.69339069e-02],
       [8.92475420e-01, 1.07524580e-01],
       [9.01226920e-01, 9.87730797e-02],
       [3.85327203e-03, 9.96146728e-01],
       [9.94614636e-01, 5.38536368e-03],
       [6.53230403e-04, 9.99346770e-01],
       [9.90987132e-01, 9.01286850e-03],
       [9.96317865e-01, 3.68213528e-03],
       [1.45412215e-01, 8.54587785e-01],
       [8.19346719e-04, 9.99180653e-01],
       [9.80095172e-01, 1.99048277e-02],
       [9.65256843e-01, 3.47431572e-02],
       [4.30306432e-03, 9.95696936e-01],
       [2.98781511e-03, 9.97012185e-01],
       [7.47533693e-01, 2.52466307e-01],
       [9.69449758e-01, 3.05502419e-02],
       [3.01177685e-01, 6.98822315e-01],
       [9.93546223e-01, 6.45377713e-03],
       [8.75033039e-01, 1.24966961e-01],
       [7.31268245e-01, 2.68731755e-01],
       [7.14534775e-01, 2.85465225e-01],
       [6.75215390e-01, 3.24784610e-01],
       [5.23341616e-01, 4.76658384e-01],
       [9.39475283e-01, 6.05247171e-02],
       [5.91353313e-04, 9.99408647e-01],
       [9.65066946e-01, 3.49330539e-02],
       [1.31939747e-02, 9.86806025e-01],
       [9.92408501e-01, 7.59149879e-03],
       [3.57838311e-02, 9.64216169e-01],
       [9.03043369e-01, 9.69566312e-02],
       [8.56581987e-01, 1.43418013e-01],
       [9.32189694e-01, 6.78103060e-02],
       [1.80107268e-03, 9.98198927e-01],
       [6.29906718e-03, 9.93700933e-01],
       [9.80944249e-01, 1.90557512e-02],
       [5.31286915e-03, 9.94687131e-01],
       [9.87155702e-01, 1.28442977e-02],
       [8.05893996e-01, 1.94106004e-01],
       [2.23174191e-01, 7.76825809e-01],
       [2.44490735e-03, 9.97555093e-01],
       [9.86554106e-01, 1.34458941e-02],
       [8.60442181e-03, 9.91395578e-01],
       [6.29328161e-01, 3.70671839e-01],
       [9.70922479e-04, 9.99029078e-01],
       [8.01000572e-04, 9.99198999e-01]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制ROC曲线</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_604_0.png" alt="output_604_0"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AUC值</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">score = roc_auc_score(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.8221950971416945
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征重要性</span></span><br><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure>




<pre><code>array([1175,  668,  118,  895,  126])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">features = X.columns  <span class="comment"># 获取特征名称</span></span><br><span class="line">importances = model.feature_importances_  <span class="comment"># 获取特征重要性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过二维表格形式显示</span></span><br><span class="line">importances_df = pd.DataFrame()</span><br><span class="line">importances_df[<span class="string">&#x27;特征名称&#x27;</span>] = features</span><br><span class="line">importances_df[<span class="string">&#x27;特征重要性&#x27;</span>] = importances</span><br><span class="line">importances_df.sort_values(<span class="string">&#x27;特征重要性&#x27;</span>, ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>特征名称</th>
      <th>特征重要性</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>收入</td>
      <td>1175</td>
    </tr>
    <tr>
      <th>3</th>
      <td>历史授信额度</td>
      <td>895</td>
    </tr>
    <tr>
      <th>1</th>
      <td>年龄</td>
      <td>668</td>
    </tr>
    <tr>
      <th>4</th>
      <td>历史违约次数</td>
      <td>126</td>
    </tr>
    <tr>
      <th>2</th>
      <td>性别</td>
      <td>118</td>
    </tr>
  </tbody>
</table>
</div>



<p>注意：之前学过的机器学习模型的特征重要性为小数，而LightGBM模型的特征重要性均为整数</p>
<h3 id="10-5-4-模型参数调优"><a href="#10-5-4-模型参数调优" class="headerlink" title="10.5.4 模型参数调优"></a>10.5.4 模型参数调优</h3><p>LightGBM分类模型的参数有很多，这里选取以下参数进行调优：</p>
<p>num_leaves：决策树的最大叶子节点数，即决策树最多有多少个叶子节点，默认取31.因为LightGBM模型使用的是leaf-wise生长策略，所以在调节树的复杂度时常用的参数是num_leaves，而不是树的最大深度参数max_depth</p>
<p>n_estimators:弱学习器的个数，或者说是弱学习器的最大迭代次数，默认取100</p>
<p>learning_rate:学习率，又称为每个弱学习器的权重缩减系数，取值范围为（0，1]，默认取0.1.取值较小意味着要达到一定的误分类数或者学习效果，需要更多迭代次数和更多弱学习器。</p>
<p>了解上述参数的含义后，使用GridSearch网格搜索进行参数调优</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数调优</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV  <span class="comment"># 网格搜索合适的超参数</span></span><br><span class="line">parameters = &#123;<span class="string">&#x27;num_leaves&#x27;</span>: [<span class="number">10</span>, <span class="number">15</span>, <span class="number">31</span>], <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>], <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.2</span>]&#125;</span><br><span class="line">model = LGBMClassifier()  <span class="comment"># 构建分类器</span></span><br><span class="line">grid_search = GridSearchCV(model, parameters, scoring=<span class="string">&#x27;roc_auc&#x27;</span>, cv=<span class="number">5</span>)  <span class="comment"># cv=5表示交叉验证5次，scoring=&#x27;roc_auc&#x27;表示以ROC曲线的AUC评分作为模型评价准则</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出参数最优值</span></span><br><span class="line">grid_search.fit(X_train, y_train)  <span class="comment"># 传入数据</span></span><br><span class="line">grid_search.best_params_  <span class="comment"># 输出参数的最优值</span></span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;learning_rate&#39;: 0.2, &#39;n_estimators&#39;: 10, &#39;num_leaves&#39;: 10&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新搭建分类器</span></span><br><span class="line">model = LGBMClassifier(num_leaves=<span class="number">10</span>, n_estimators=<span class="number">10</span>,learning_rate=<span class="number">0.2</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>LGBMClassifier(learning_rate=0.2, n_estimators=10, num_leaves=10)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看ROC曲线</span></span><br><span class="line">y_pred_proba = model.predict_proba(X_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thres = roc_curve(y_test, y_pred_proba[:,<span class="number">1</span>])</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(fpr, tpr)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_614_0.png" alt="output_614_0"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看AUC值</span></span><br><span class="line">y_pred_proba = model.predict_proba(X_test)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line">score = roc_auc_score(y_test, y_pred_proba[:, <span class="number">1</span>])</span><br><span class="line">score</span><br></pre></td></tr></table></figure>




<pre><code>0.8712236801953005
</code></pre>
<p><strong>补充：LightGBM模型常见超参数</strong></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(91).png" alt="下载 (91)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(92).png" alt="下载 (92)"></p>
<p><img src="%E4%B8%8B%E8%BD%BD%20(93).png" alt="下载 (93)"></p>
<h2 id="10-6-LghtGBM算法案例实战2：广告收益回归预测模型"><a href="#10-6-LghtGBM算法案例实战2：广告收益回归预测模型" class="headerlink" title="10.6 LghtGBM算法案例实战2：广告收益回归预测模型"></a>10.6 LghtGBM算法案例实战2：广告收益回归预测模型</h2><h3 id="10-6-1-案例背景"><a href="#10-6-1-案例背景" class="headerlink" title="10.6.1 案例背景"></a>10.6.1 案例背景</h3><p>投资商经常会通过多个不同渠道投放广告，以此来获得经济利益。在本案例中我们选取公司在电视、广播和报纸上的投入，来预测广告收益，这对公司策略的制定是有较重要的意义。</p>
<h3 id="10-6-2-模型搭建"><a href="#10-6-2-模型搭建" class="headerlink" title="10.6.2 模型搭建"></a>10.6.2 模型搭建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_excel(<span class="string">&#x27;广告收益数据.xlsx&#x27;</span>)</span><br><span class="line">df.head()  <span class="comment"># 目标变量是广告收益</span></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>电视</th>
      <th>广播</th>
      <th>报纸</th>
      <th>收益</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>230.1</td>
      <td>37.8</td>
      <td>69.2</td>
      <td>331.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44.5</td>
      <td>39.3</td>
      <td>45.1</td>
      <td>156.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17.2</td>
      <td>45.9</td>
      <td>69.3</td>
      <td>139.5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>151.5</td>
      <td>41.3</td>
      <td>58.5</td>
      <td>277.5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>180.8</td>
      <td>10.8</td>
      <td>58.4</td>
      <td>193.5</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.提取特征变量和目标变量</span></span><br><span class="line">X = df.drop(columns=<span class="string">&#x27;收益&#x27;</span>) </span><br><span class="line">y = df[<span class="string">&#x27;收益&#x27;</span>]  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.划分训练集和测试集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">123</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 模型训练和搭建</span></span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMRegressor</span><br><span class="line">model = LGBMRegressor()</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>




<pre><code>LGBMRegressor()
</code></pre>
<h3 id="10-6-3-模型预测及评估"><a href="#10-6-3-模型预测及评估" class="headerlink" title="10.6.3 模型预测及评估"></a>10.6.3 模型预测及评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测测试数据</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">y_pred[<span class="number">0</span>:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([192.6139063 , 295.11999665, 179.92649365, 293.45888909,
       166.86159398])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测值和实际值对比</span></span><br><span class="line">a = pd.DataFrame()  <span class="comment"># 创建一个空DataFrame </span></span><br><span class="line">a[<span class="string">&#x27;预测值&#x27;</span>] = <span class="built_in">list</span>(y_pred)</span><br><span class="line">a[<span class="string">&#x27;实际值&#x27;</span>] = <span class="built_in">list</span>(y_test)</span><br><span class="line">a.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>预测值</th>
      <th>实际值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>192.613906</td>
      <td>190.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>295.119997</td>
      <td>292.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>179.926494</td>
      <td>171.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>293.458889</td>
      <td>324.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>166.861594</td>
      <td>144.0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 手动输入数据进行预测</span></span><br><span class="line">X = [[<span class="number">71</span>, <span class="number">11</span>, <span class="number">2</span>]]</span><br><span class="line">model.predict(X)</span><br></pre></td></tr></table></figure>




<pre><code>array([140.00420258])
</code></pre>
<p>即电视广告费投入71万元、广播广告费投入11万元、报纸广告费投入2万元时，模型预测的广告收益为140万元</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看R-square</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2 = r2_score(y_test, model.predict(X_test))</span><br><span class="line">r2</span><br></pre></td></tr></table></figure>




<pre><code>0.9570203214455993
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看评分</span></span><br><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.9570203214455993
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 特征重要性</span></span><br><span class="line">model.feature_importances_</span><br></pre></td></tr></table></figure>




<pre><code>array([ 950, 1049,  963])
</code></pre>
<h3 id="10-6-4-模型参数调优"><a href="#10-6-4-模型参数调优" class="headerlink" title="10.6.4 模型参数调优"></a>10.6.4 模型参数调优</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数调优</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV  <span class="comment"># 网格搜索合适的超参数</span></span><br><span class="line">parameters = &#123;<span class="string">&#x27;num_leaves&#x27;</span>: [<span class="number">15</span>, <span class="number">31</span>, <span class="number">62</span>], <span class="string">&#x27;n_estimators&#x27;</span>: [<span class="number">20</span>, <span class="number">30</span>, <span class="number">50</span>, <span class="number">70</span>], <span class="string">&#x27;learning_rate&#x27;</span>: [<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>]&#125;  <span class="comment"># 指定分类器中参数的范围</span></span><br><span class="line">model = LGBMRegressor()  <span class="comment"># 构建模型</span></span><br><span class="line">grid_search = GridSearchCV(model, parameters,scoring=<span class="string">&#x27;r2&#x27;</span>,cv=<span class="number">5</span>) <span class="comment"># cv=5表示交叉验证5次，scoring=&#x27;r2&#x27;表示以R-squared作为模型评价准则</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出参数最优值</span></span><br><span class="line">grid_search.fit(X_train, y_train)  <span class="comment"># 传入数据</span></span><br><span class="line">grid_search.best_params_  <span class="comment"># 输出参数的最优值</span></span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;learning_rate&#39;: 0.3, &#39;n_estimators&#39;: 50, &#39;num_leaves&#39;: 31&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新搭建LightGBM回归模型</span></span><br><span class="line">model = LGBMRegressor(num_leaves=<span class="number">31</span>, n_estimators=<span class="number">50</span>,learning_rate=<span class="number">0.3</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看得分</span></span><br><span class="line">model.score(X_test, y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.9558624845475153
</code></pre>

      

      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>谢谢你请我吃糖果<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    
                    <div class="reward-box-item">
                      <img class="reward-img" src="/img/wechatpay.jpg">
                      <span class="reward-type">微信</span>
                    </div>
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">数据科学</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/机器学习与深度学习//" class="article-tag-list-link color5">机器学习与深度学习</a>
        		</li>
      		
		</ul>
	</div>


      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//pan.baidu.com/share/qrcode?url=http://example.com/2023/02/02/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part2/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2023/02/03/python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part3/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          Python大数据分析与机器学习商业案例实战-part3
        
      </div>
    </a>
  
  
    <a href="/2023/02/02/Python%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-part1/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Python大数据分析与机器学习商业案例实战-part1</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>


<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
        <div class="toc-container tooltip-left">
            <i class="icon-font icon-category"></i>
            <div class="tooltip tooltip-east">
                <span class="tooltip-item">
                </span>
                <span class="tooltip-content">
                    <div class="toc-article">
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#5-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">5. 决策树模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">1.1.</span> <span class="toc-text">5.1 决策树模型的基本原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-1-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.1.</span> <span class="toc-text">5.1.1 决策树模型简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-2-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BB%BA%E6%A0%91%E4%BE%9D%E6%8D%AE"><span class="toc-number">1.1.2.</span> <span class="toc-text">5.1.2 决策树模型的建树依据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-3-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.1.3.</span> <span class="toc-text">5.1.3 决策树模型的代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98%EF%BC%9A%E5%91%98%E5%B7%A5%E7%A6%BB%E8%81%8C%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">1.2.</span> <span class="toc-text">5.2 案例实战：员工离职预测模型搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-1-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">1.2.1.</span> <span class="toc-text">5.2.1 模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-2-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%8F%8A%E8%AF%84%E4%BC%B0"><span class="toc-number">1.2.2.</span> <span class="toc-text">5.2.2 模型预测及评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98-K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-amp-GridSearch%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><span class="toc-number">1.3.</span> <span class="toc-text">5.3 参数调优 - K折交叉验证 &amp; GridSearch网格搜索</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-1-K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">1.3.1.</span> <span class="toc-text">5.3.1 K折交叉验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-2-GridSearch%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><span class="toc-number">1.3.2.</span> <span class="toc-text">5.3.2 GridSearch网格搜索</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">6 朴素贝叶斯模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">2.1.</span> <span class="toc-text">6.1 朴素贝叶斯模型的算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-1-%E4%B8%80%E7%BB%B4%E7%89%B9%E5%BE%81%E5%8F%98%E9%87%8F%E4%B8%8B%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.1.</span> <span class="toc-text">6.1.1 一维特征变量下的贝叶斯模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-2-%E4%BA%8C%E7%BB%B4%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E4%B8%8B%E5%8D%95%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.2.</span> <span class="toc-text">6.1.2 二维特征向量下单贝叶斯模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-3-n%E7%BB%B4%E7%89%B9%E5%BE%81%E5%8F%98%E9%87%8F%E4%B8%8B%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.3.</span> <span class="toc-text">6.1.3 n维特征变量下的贝叶斯模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-4-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8D%95%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA"><span class="toc-number">2.1.4.</span> <span class="toc-text">6.1.4 朴素贝叶斯模型简单代码演示</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98%EF%BC%9A%E8%82%BF%E7%98%A4%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text">6.2 案例实战：肿瘤预测模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-1-%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF"><span class="toc-number">2.2.1.</span> <span class="toc-text">6.2.1 案例背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-2-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E4%B8%8E%E5%88%92%E5%88%86"><span class="toc-number">2.2.2.</span> <span class="toc-text">6.2.2 数据读取与划分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-3-%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8"><span class="toc-number">2.2.3.</span> <span class="toc-text">6.2.3 模型的搭建与使用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">7 K近邻算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.</span> <span class="toc-text">7.1 K近邻算法的原理和代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-1-K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">3.1.1.</span> <span class="toc-text">7.1.1 K近邻算法的基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-2-K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E7%9A%84%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.1.2.</span> <span class="toc-text">7.1.2 K近邻算法的计算步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-3-K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.3.</span> <span class="toc-text">7.1.3 K近邻算法的代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">7.2 案例实战 - 手写数字识别模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-1-%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF"><span class="toc-number">3.2.1.</span> <span class="toc-text">7.2.1 案例背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-2-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">3.2.2.</span> <span class="toc-text">7.2.2 手写数字识别的原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-3-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.2.3.</span> <span class="toc-text">7.2.3 手写数字识别的代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3"><span class="toc-number">3.3.</span> <span class="toc-text">7.3 图像识别原理详解</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A8%A1%E5%9E%8B%E2%80%94%E2%80%94%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">8 随机森林模型——集成学习模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-1-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.1.</span> <span class="toc-text">8.1 随机森林模型的原理和代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-1-%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B"><span class="toc-number">4.1.1.</span> <span class="toc-text">8.1.1 集成模型简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-2-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">4.1.2.</span> <span class="toc-text">8.1.2 随机森林模型的基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-3-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.1.3.</span> <span class="toc-text">8.1.3 随机森林模型的代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-2-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98%EF%BC%9A%E8%82%A1%E7%A5%A8%E6%B6%A8%E8%B7%8C%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">8.2 案例实战：股票涨跌预测模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-1-%E8%82%A1%E7%A5%A8%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96-%E6%9C%80%E5%A5%BD%E7%9B%B4%E6%8E%A5%E7%9C%8Btushare%E5%AE%98%E6%96%B9%E6%95%B0%E6%8D%AE%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3"><span class="toc-number">4.2.1.</span> <span class="toc-text">8.2.1 股票基本数据获取(最好直接看tushare官方数据接口文档)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-2-%E8%82%A1%E7%A5%A8%E8%A1%8D%E7%94%9F%E5%8F%98%E9%87%8F%E7%94%9F%E6%88%90"><span class="toc-number">4.2.2.</span> <span class="toc-text">8.2.2 股票衍生变量生成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-3-%E5%A4%9A%E5%9B%A0%E5%AD%90%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">4.2.3.</span> <span class="toc-text">8.2.3 多因子模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-4-%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-number">4.2.4.</span> <span class="toc-text">8.2.4 模型使用与评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-5-%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98"><span class="toc-number">4.2.5.</span> <span class="toc-text">8.2.5 参数调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-6-%E6%94%B6%E7%9B%8A%E5%9B%9E%E6%B5%8B%E6%9B%B2%E7%BA%BF%E7%BB%98%E5%88%B6-%E7%9F%A5%E9%81%93%E5%B0%B1%E8%A1%8C%E4%BA%86%EF%BC%8C%E5%AE%9E%E6%88%98%E4%B8%AD%E7%9B%B4%E6%8E%A5%E6%8B%BF%E8%81%9A%E5%AE%BD%E5%9B%9E%E6%B5%8B"><span class="toc-number">4.2.6.</span> <span class="toc-text">8.2.6 收益回测曲线绘制(知道就行了，实战中直接拿聚宽回测)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#9-AdaBoost%E4%B8%8EGBDT%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.</span> <span class="toc-text">9 AdaBoost与GBDT模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#9-1-AdaBoost%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">5.1.</span> <span class="toc-text">9.1 AdaBoost算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-1-AdaBoost%E7%AE%97%E6%B3%95%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">5.1.1.</span> <span class="toc-text">9.1.1 AdaBoost算法的核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-2-AdaBoost%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0"><span class="toc-number">5.1.2.</span> <span class="toc-text">9.1.2 AdaBoost算法的数学原理概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-3-AdaBoost%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%BE%E4%BE%8B"><span class="toc-number">5.1.3.</span> <span class="toc-text">9.1.3 AdaBoost算法的数学原理举例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-4-AdaBoost%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">5.1.4.</span> <span class="toc-text">9.1.4 AdaBoost算法的简单代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-2-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-AdaBoost%E4%BF%A1%E7%94%A8%E5%8D%A1%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.2.</span> <span class="toc-text">9.2 案例实战 - AdaBoost信用卡精准营销模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-1-%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF"><span class="toc-number">5.2.1.</span> <span class="toc-text">9.2.1 案例背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-2-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">5.2.2.</span> <span class="toc-text">9.2.2 模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-3-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%8F%8A%E8%AF%84%E4%BC%B0"><span class="toc-number">5.2.3.</span> <span class="toc-text">9.2.3 模型预测及评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-4-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.2.4.</span> <span class="toc-text">9.2.4 模型参数介绍</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-3-GBDT%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">5.3.</span> <span class="toc-text">9.3 GBDT算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-3-GBDT%E7%AE%97%E6%B3%95%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">5.3.1.</span> <span class="toc-text">9.1.3 GBDT算法的核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-2-GBDT%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0"><span class="toc-number">5.3.2.</span> <span class="toc-text">9.3.2 GBDT算法的数学原理概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-3-GBDT%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E4%B8%BE%E4%BE%8B%EF%BC%88%E7%95%A5%EF%BC%89"><span class="toc-number">5.3.3.</span> <span class="toc-text">9.3.3 GBDT算法的数学原理举例（略）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-4-GBDT%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">5.3.4.</span> <span class="toc-text">9.3.4 GBDT算法的简单代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-4-GBDT%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98-%E4%BA%A7%E5%93%81%E5%AE%9A%E4%BB%B7%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.4.</span> <span class="toc-text">9.4 GBDT案例实战 - 产品定价模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-1-%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF"><span class="toc-number">5.4.1.</span> <span class="toc-text">9.4.1 案例背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-2-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">5.4.2.</span> <span class="toc-text">9.4.2 模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-3-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%8D%B3%E8%AF%84%E4%BC%B0"><span class="toc-number">5.4.3.</span> <span class="toc-text">9.4.3 模型预测即评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-4-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.4.4.</span> <span class="toc-text">9.4.4 模型参数介绍</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#10-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%A5%9E%E5%99%A8%EF%BC%9AXGBoost%E4%B8%8ELightGBM%E7%AE%97%E6%B3%95"><span class="toc-number">6.</span> <span class="toc-text">10 机器学习神器：XGBoost与LightGBM算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#10-1-XGBoost%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">6.1.</span> <span class="toc-text">10.1 XGBoost算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-1XGBoost%E7%AE%97%E6%B3%95%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">6.1.1.</span> <span class="toc-text">10.1. 1XGBoost算法的核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-2-XGBoost%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0"><span class="toc-number">6.1.2.</span> <span class="toc-text">10.1.2 XGBoost算法的数学原理概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-3-XGBoost%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.1.3.</span> <span class="toc-text">10.1.3 XGBoost算法的简单代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-2-XGBoost%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E9%87%91%E8%9E%8D%E5%8F%8D%E6%AC%BA%E8%AF%88%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.</span> <span class="toc-text">10.2 XGBoost算法案例实战1：金融反欺诈模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-1-%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF"><span class="toc-number">6.2.1.</span> <span class="toc-text">10.2.1 案例背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-2-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">6.2.2.</span> <span class="toc-text">10.2.2 模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-3-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%8F%8A%E8%AF%84%E4%BC%B0"><span class="toc-number">6.2.3.</span> <span class="toc-text">10.2.3 模型预测及评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-4-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98"><span class="toc-number">6.2.4.</span> <span class="toc-text">10.2.4 模型参数调优</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-3-XGBoost%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%982-%E4%BF%A1%E7%94%A8%E8%AF%84%E5%88%86%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.3.</span> <span class="toc-text">10.3 XGBoost算法案例实战2 - 信用评分模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-1-%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF"><span class="toc-number">6.3.1.</span> <span class="toc-text">10.3.1 案例背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-2-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.3.2.</span> <span class="toc-text">10.3.2 多元线性回归模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-3-GXDT%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.3.3.</span> <span class="toc-text">10.3.3 GXDT回归模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-4-XGBoost%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.3.4.</span> <span class="toc-text">10.3.4 XGBoost回归模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-4-LightGBM%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">6.4.</span> <span class="toc-text">10.4 LightGBM算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-4-1-LightGBM%E7%AE%97%E6%B3%95%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">6.4.1.</span> <span class="toc-text">10.4.1 LightGBM算法的核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-4-2-LightGBM%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0"><span class="toc-number">6.4.2.</span> <span class="toc-text">10.4.2 LightGBM算法的数学原理概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-4-3-LightGBM%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.4.3.</span> <span class="toc-text">10.4.3 LightGBM算法的简单代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-5-LightGBM%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%981%EF%BC%9A%E5%AE%A2%E6%88%B7%E8%BF%9D%E7%BA%A6%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.5.</span> <span class="toc-text">10.5 LightGBM算法案例实战1：客户违约预测模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-5-1-%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF"><span class="toc-number">6.5.1.</span> <span class="toc-text">10.5.1 案例背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-5-2-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">6.5.2.</span> <span class="toc-text">10.5.2 模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-5-3-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%8F%8A%E8%AF%84%E4%BC%B0"><span class="toc-number">6.5.3.</span> <span class="toc-text">10.5.3 模型预测及评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-5-4-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98"><span class="toc-number">6.5.4.</span> <span class="toc-text">10.5.4 模型参数调优</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-6-LghtGBM%E7%AE%97%E6%B3%95%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%982%EF%BC%9A%E5%B9%BF%E5%91%8A%E6%94%B6%E7%9B%8A%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.6.</span> <span class="toc-text">10.6 LghtGBM算法案例实战2：广告收益回归预测模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-6-1-%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF"><span class="toc-number">6.6.1.</span> <span class="toc-text">10.6.1 案例背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-6-2-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">6.6.2.</span> <span class="toc-text">10.6.2 模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-6-3-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%8F%8A%E8%AF%84%E4%BC%B0"><span class="toc-number">6.6.3.</span> <span class="toc-text">10.6.3 模型预测及评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-6-4-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98"><span class="toc-number">6.6.4.</span> <span class="toc-text">10.6.4 模型参数调优</span></a></li></ol></li></ol></li></ol>
                    </div>
                </span>
            </div>
        </div>
        
    </div>
</aside>



  
  
  

  

  

  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2023 John Doe
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">预训练语言模型</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据科学</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">因子投资</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">随笔</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">推荐系统</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据仓库</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">常用算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">聚宽</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://www.csdn.net/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>CSDN</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.zhihu.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>知乎</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.huaweicloud.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>华为云</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.aliyun.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>阿里云</a>
            </li>
          
            <li class="search-li">
              <a href="https://leetcode.cn/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>力扣</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.joinquant.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>聚宽</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">王宇涵//本科：哈尔滨工程大学//研究生：大连理工大学//专业：计算机技术//方向：量化交易与深度学习//热爱大数据平台开发与数仓开发，会分享一些技术文章和读书笔记</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>