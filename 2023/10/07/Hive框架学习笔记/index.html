<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://example.com">
  <title>Hive框架学习笔记 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="第一章 Hive入门1.1 什么是Hive基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。 Hive是一个Hadoop客户端，用于将HQL（Hive SQL）转化成MapReduce程序。 （1）Hive中每张表的数据存储在HDFS （2）Hive分析数据底层的实现是MapReduce（也可配置为Spark或者Tez）  （3）执行程序运行在Yarn">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive框架学习笔记">
<meta property="og:url" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="第一章 Hive入门1.1 什么是Hive基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。 Hive是一个Hadoop客户端，用于将HQL（Hive SQL）转化成MapReduce程序。 （1）Hive中每张表的数据存储在HDFS （2）Hive分析数据底层的实现是MapReduce（也可配置为Spark或者Tez）  （3）执行程序运行在Yarn">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%872.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%873.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_15-12-21.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_15-15-44.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%874.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_18-10-58.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_18-12-02.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_18-13-41.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_18-17-22.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_20-32-27.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_20-32-51.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_21-10-17.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_21-13-20.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-07_21-16-48.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_14-40-04.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_14-41-48.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_14-53-15.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_15-06-49.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_15-23-29.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_15-23-50.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_16-15-03.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_16-15-26.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_16-28-23.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_16-28-47.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_19-30-17.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_19-44-22.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_19-45-03.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_21-17-46.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_21-22-42.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_21-28-54.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-08_21-30-45.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_12-17-14.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_12-18-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_12-40-32.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_12-42-02.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_12-42-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_13-04-13.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_13-14-06.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_13-15-13.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_13-30-17.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_13-45-53.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_13-48-53.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-08-51.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-09-01.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-11-15.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-15-04.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-17-07.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-17-52.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-21-45.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-30-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-32-09.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-40-51.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-49-08.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_15-58-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_16-08-01.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_16-11-07.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_16-13-06.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_20-37-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_20-41-06.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_20-53-11.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_21-10-09.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_21-13-07.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-09_21-43-32.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_12-17-38.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_12-32-16.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_12-42-52.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_12-37-57.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_12-57-18.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_13-50-15.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_13-51-08.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_13-51-59.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_13-52-37.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_14-52-31.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_14-53-15.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_14-58-41.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_15-01-16.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_15-16-09.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_15-21-47.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_15-25-15.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_15-31-30.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_15-34-04.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_15-36-30.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_15-38-51.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_16-17-55.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_21-46-10.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_21-52-37.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_11-06-44.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_11-08-58.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_11-18-24.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_11-23-24.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_11-28-32.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_11-39-08.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_11-45-12.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_11-49-39.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_12-01-19.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_14-50-08.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_14-58-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_15-07-49.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_15-34-02.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-10_20-49-10.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_15-01-17.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_15-06-39.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_15-15-37.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_15-46-21.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_16-11-54.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_16-28-47.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_17-41-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_17-43-45.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_17-50-18.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_17-59-21.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_18-25-40.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_18-26-25.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-17_20-53-58.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_15-55-53.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_15-56-55.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_15-58-10.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-00-44.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-05-59.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-10-33.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-21-36.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-22-27.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-24-10.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-34-30.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-55-01.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_16-56-15.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_20-16-12.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_19-59-55.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_20-29-46.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_20-38-28.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_20-39-09.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_20-52-54.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_20-58-47.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_21-15-06.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_21-17-31.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_21-38-36.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_21-47-50.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_22-06-19.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-18_22-19-32.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-19_09-39-12.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-19_09-48-16.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_19-53-53.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_19-57-23.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_21-52-13.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-11-36.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-13-44.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-15-37.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-16-41.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-18-02.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-19-10.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-20-10.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-21-06.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-21-47.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-22-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-47-25.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-47-50.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_14-59-09.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_15-30-25.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_15-31-04.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_15-31-52.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_16-32-43.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_16-33-27.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_16-34-24.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_16-39-32.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_16-42-51.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_16-45-33.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_19-28-34.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_19-31-55.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_19-40-28.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-10-31_19-44-44.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_15-08-35.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_15-09-23.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_15-12-08.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_15-20-14.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_15-18-40.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_15-23-13.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_15-23-56.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_15-35-02.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_16-27-48.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_19-22-32.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_19-24-28.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_19-47-52.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_20-24-12.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_20-26-33.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_20-35-19.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_20-50-27.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_21-02-32.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_21-19-14.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_21-27-51.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-01_21-32-04.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%87111.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-03_14-59-36.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-03_15-05-06.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-29_15-12-21.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-29_15-16-47.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-03_20-40-41.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-03_21-09-27.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-03_21-37-40.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_13-27-38.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/11%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/12%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/13%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_15-26-23.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/14%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/15%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/16%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/17%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_16-19-16.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/18%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_16-28-49.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/19%E5%9B%BE%E7%89%871.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_17-15-08.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_19-29-39.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_19-30-24.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/wps1.jpg">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_20-50-35.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_20-51-12.png">
<meta property="og:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Snipaste_2023-11-05_20-54-26.png">
<meta property="article:published_time" content="2023-10-07T05:50:56.000Z">
<meta property="article:modified_time" content="2023-11-29T14:15:36.856Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Linux">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%9B%BE%E7%89%871.png">
  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div> 
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/123.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/categories">分类</a></li>
	        
			</ul>
		</nav>
		<nav>
			总文章数 46
		</nav>		
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
		        
					<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
		        
					<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>



    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/123.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
			        
						<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
			        
						<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/categories">分类</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-Hive框架学习笔记" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Hive框架学习笔记
    </h1>
  

        
        <a href="/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2023-10-07T05:50:56.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2023-10-07</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Hive入门"><a href="#第一章-Hive入门" class="headerlink" title="第一章 Hive入门"></a>第一章 Hive入门</h1><h2 id="1-1-什么是Hive"><a href="#1-1-什么是Hive" class="headerlink" title="1.1 什么是Hive"></a>1.1 什么是Hive</h2><p>基于Hadoop的一个<strong>数据仓库工具</strong>，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</p>
<p>Hive是一个Hadoop客户端，用于<strong>将HQL（Hive SQL）转化成MapReduce程序</strong>。</p>
<p>（1）Hive中每张表的数据存储在HDFS</p>
<p>（2）Hive分析数据底层的实现是MapReduce（也可配置为Spark或者Tez） </p>
<p>（3）执行程序运行在Yarn上</p>
<p>为什么使用Hive？</p>
<p>MapReduce如果要实现复杂查询，逻辑开发难度比较大，使用Hive可以提高快速开发的能力，避免书写MapReduce，减少学习成本</p>
<h2 id="1-2-Hive架构原理"><a href="#1-2-Hive架构原理" class="headerlink" title="1.2 Hive架构原理"></a>1.2 Hive架构原理</h2><p>一句话说清hive的架构原理：<strong>Hive架构由用户接口、元数据存储（Metastore）和驱动（解释器、编译器、优化器、执行器等）组成。</strong>用户通过接口创建HQL语句，由Metastore记录对应的元数据，通过一系列驱动进行HQL语句的分析优化和查询计划的生成（或者说翻译成MapReduce程序），生成的查询计划存储在HDFS中，随后在MapReduce调用执行，最后将计算结果返回给用户。</p>
<p><img src="%E5%9B%BE%E7%89%871.png" alt="图片1"></p>
<p>（1）用户接口：Client</p>
<p>CLI（command-line interface）、JDBC&#x2F;ODBC。</p>
<p>①JDBC的移植性比ODBC好；（通常情况下，安装完ODBC驱动程序之后，还需要经过确定的配置才能够应用。而不相同的配置在不相同数据库服务器之间不能够通用。所以，安装一次就需要再配置一次。<strong>JDBC只需要选取适当的JDBC数据库驱动程序，就不需要额外的配置。在安装过程中，JDBC数据库驱动程序会自己完成有关的配置</strong>。）</p>
<p>②两者使用的语言不同，JDBC在Java编程时使用，ODBC一般在C&#x2F;C++编程时使用</p>
<p>（2）元数据：<em><strong>Metastore</strong></em></p>
<p>元数据包括：数据库（默认是default）、表名、表的拥有者、列&#x2F;分区字段、表的类型（是否是外部表）、表的数据所在目录等。</p>
<p>默认存储在自带的derby数据库中，由于derby数据库只支持单客户端访问，生产环境中为了多人开发，推荐使用<strong>MySQL</strong>存储Metastore。</p>
<p>（3）<strong>驱动器：Driver</strong></p>
<p>①解析器（SQLParser）：将SQL字符串转换成抽象语法树（AST）</p>
<p>②语义分析（Semantic Analyzer）：将AST进一步划分为QeuryBlock</p>
<p>③逻辑计划生成器（Logical Plan Gen）：将语法树生成逻辑计划</p>
<p>④逻辑优化器（Logical Optimizer）：对逻辑计划进行优化</p>
<p>⑤物理计划生成器（Physical Plan Gen）：根据优化后的逻辑计划生成物理计划</p>
<p>⑥物理优化器（Physical Optimizer）：对物理计划进行优化</p>
<p>⑦执行器（Execution）：执行该计划，得到查询结果并返回给客户端</p>
<p><img src="%E5%9B%BE%E7%89%872.png" alt="图片2"></p>
<p><img src="%E5%9B%BE%E7%89%873.png" alt="图片3"></p>
<p>（4）Hadoop</p>
<p>使用HDFS进行存储，可以选择MapReduce&#x2F;Tez&#x2F;Spark进行计算。</p>
<h2 id="1-3-Hive-SQL编译成MapReduce的过程"><a href="#1-3-Hive-SQL编译成MapReduce的过程" class="headerlink" title="1.3 Hive SQL编译成MapReduce的过程"></a>1.3 Hive SQL编译成MapReduce的过程</h2><p>（1）词法、语法解析：根据 Antlr 定义的 sql 语法规则，将相关 sql 进行词法、语法解析，转化为抽象语法树 AST Tree</p>
<p>（2）语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock（包括输入源、计算过程、输出）</p>
<p>（3）生成逻辑执行阶段：遍历 QueryBlock，翻译为执行操作树 OperatorTree（TableScanOperator、SelectOperator、FilterOperator、JoinOperator、GroupByOperator、ReduceSinkOperator）</p>
<p>（4）优化逻辑执行计划：谓词下推、多路join等，达到减少MapReduce Job，减少数据传输及shuffle数据量</p>
<p>（5）生成物理执行过程：遍历 OperatorTree，翻译为 MapReduce 任务</p>
<p>（6）优化物理执行过程：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划</p>
<h1 id="第二章-Hive安装"><a href="#第二章-Hive安装" class="headerlink" title="第二章 Hive安装"></a>第二章 Hive安装</h1><h2 id="2-1-Hive安装部署"><a href="#2-1-Hive安装部署" class="headerlink" title="2.1 Hive安装部署"></a>2.1 Hive安装部署</h2><h3 id="2-1-1-安装Hive"><a href="#2-1-1-安装Hive" class="headerlink" title="2.1.1 安装Hive"></a>2.1.1 安装Hive</h3><p>（0）首先确保hadoop集群启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">3026 DataNode</span><br><span class="line">3397 NodeManager</span><br><span class="line">3659 Jps</span><br><span class="line">2876 NameNode</span><br><span class="line">3583 JobHistoryServer</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">3062 NodeManager</span><br><span class="line">2681 DataNode</span><br><span class="line">2906 ResourceManager</span><br><span class="line">3435 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">2914 NodeManager</span><br><span class="line">2820 SecondaryNameNode</span><br><span class="line">2699 DataNode</span><br><span class="line">3055 Jps</span><br></pre></td></tr></table></figure>

<p>（1）把apache-hive-3.1.3-bin.tar.gz上传到Linux的&#x2F;opt&#x2F;software目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 868360</span><br><span class="line">-rw-r--r--. 1 root root 356079876 12月  2 2022 apache-hive-3.1.3-bin.tar.gz  # 在这里</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br></pre></td></tr></table></figure>

<p>（2）解压apache-hive-3.1.3-bin.tar.gz到&#x2F;opt&#x2F;module&#x2F;目录下面</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf apache-hive-3.1.3-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# cd /opt/module/</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x. 10 root root  184 10月  7 14:51 apache-hive-3.1.3-bin</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>（3）修改apache-hive-3.1.3-bin的名称为hive</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mv apache-hive-3.1.3-bin/ hive</span><br><span class="line">[root@hadoop102 module]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x. 13 wyh  wyh  4096 9月  26 12:55 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 10 root root  184 10月  7 14:51 hive   # 在这里</span><br><span class="line">drwxr-xr-x.  7   10  143  245 4月   2 2019 jdk1.8.0_212</span><br></pre></td></tr></table></figure>

<p>（4）修改&#x2F;etc&#x2F;profile.d&#x2F;my_env.sh，添加环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 etc]# vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HIVE_HOME</span></span><br><span class="line">export HIVE_HOME=/opt/module/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">source</span>一下</span></span><br><span class="line">[root@hadoop102 etc]# source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>（5）初始化元数据库（默认是derby数据库）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# bin/schematool -dbType derby -initSchema</span><br></pre></td></tr></table></figure>

<p>至此，Hive的最小化部署已经完成。</p>
<h3 id="2-1-2-启动并使用Hive"><a href="#2-1-2-启动并使用Hive" class="headerlink" title="2.1.2 启动并使用Hive"></a>2.1.2 启动并使用Hive</h3><p>（1）启动Hive</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# bin/hive</span><br></pre></td></tr></table></figure>

<p>（2）使用Hive</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">default</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.416</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<p>如果我们不去声明使用哪个数据库，我们默认使用的就是default数据库</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.03</span> seconds</span><br><span class="line"></span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> stu(id <span class="type">int</span>, name string);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.397</span> seconds</span><br></pre></td></tr></table></figure>

<p>建表语句执行的同时，可以在HDFS的Web端看到相应的路径：也就是说Hive中的表在Hadoop中是目录；Hive中的数据在Hadoop中是文件</p>
<p><img src="Snipaste_2023-10-07_15-12-21.png" alt="Snipaste_2023-10-07_15-12-21"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> stu <span class="keyword">values</span>(<span class="number">1</span>,&quot;ss&quot;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-07_15-15-44.png" alt="Snipaste_2023-10-07_15-15-44" style="zoom:43%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br><span class="line">OK</span><br><span class="line"><span class="number">1</span>	ss</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.114</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<p>（3）derby的问题：原因在于Hive默认使用的元数据库为<em><strong>derby。</strong></em>derby数据库的特点是同一时间只允许一个客户端访问。如果多个Hive客户端同时访问，就会报错。由于在企业开发中，都是多人协作开发，需要多客户端同时访问Hive，怎么解决呢？我们可以将Hive的元数据改为用MySQL存储，MySQL支持多客户端同时访问。</p>
<p><img src="%E5%9B%BE%E7%89%874.png" alt="图片4"></p>
<p>（4）退出hive客户端，在Hive的安装目录下及那个derby.log和metastore_db删除。顺便将HDFS上目录删除</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">hive&gt; </span><span class="language-bash">quit;</span></span><br><span class="line">[root@hadoop102 hive]# rm -rf derby.log metastore_db</span><br></pre></td></tr></table></figure>

<h2 id="2-2-MySQL安装"><a href="#2-2-MySQL安装" class="headerlink" title="2.2 MySQL安装"></a>2.2 MySQL安装</h2><h3 id="2-2-1-安装MySQL"><a href="#2-2-1-安装MySQL" class="headerlink" title="2.2.1 安装MySQL"></a>2.2.1 安装MySQL</h3><p>（1）上传MySQL安装包及MySQL驱动jar包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 1464596</span><br><span class="line">-rw-r--r--. 1 root root 356079876 12月  2 2022 apache-hive-3.1.3-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 609556480 12月  2 2022 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar  # 在这里</span><br><span class="line">-rw-r--r--. 1 root root    985600 12月  2 2022 mysql-connector-java-5.1.37.jar   # 在这里</span><br></pre></td></tr></table></figure>

<p>（2）解压MySQL安装包到&#x2F;opt&#x2F;software&#x2F;mysql_lib</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# mkdir mysql_lib</span><br><span class="line">[root@hadoop102 software]# ll</span><br><span class="line">总用量 1464596</span><br><span class="line">-rw-r--r--. 1 root root 356079876 12月  2 2022 apache-hive-3.1.3-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root       221 9月  19 22:17 edits.xml</span><br><span class="line">-rw-r--r--. 1 root root     19367 9月  19 20:11 fsimage.xml</span><br><span class="line">-rw-r--r--. 1 root root 338075860 8月   5 22:31 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 195013152 8月   5 22:11 jdk-8u212-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--. 1 root root 609556480 12月  2 2022 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span><br><span class="line">-rw-r--r--. 1 root root    985600 12月  2 2022 mysql-connector-java-5.1.37.jar</span><br><span class="line">drwxr-xr-x. 2 root root         6 10月  7 15:30 mysql_lib</span><br><span class="line">[root@hadoop102 software]# tar -xf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar -C mysql_lib/</span><br><span class="line">[root@hadoop102 software]# cd mysql_lib/</span><br><span class="line">[root@hadoop102 mysql_lib]# ll</span><br><span class="line">总用量 595272</span><br><span class="line">-rw-r--r--. 1 7155 31415  45109364 9月  30 2019 mysql-community-client-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415    318768 9月  30 2019 mysql-community-common-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415   7037096 9月  30 2019 mysql-community-devel-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415  49329100 9月  30 2019 mysql-community-embedded-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415  23354908 9月  30 2019 mysql-community-embedded-compat-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415 136837816 9月  30 2019 mysql-community-embedded-devel-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415   4374364 9月  30 2019 mysql-community-libs-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415   1353312 9月  30 2019 mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415 208694824 9月  30 2019 mysql-community-server-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 7155 31415 133129992 9月  30 2019 mysql-community-test-5.7.28-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p>（3）卸载系统自带的mariadb</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# rpm -qa | grep mariadb | xargs sudo rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<p>（4）安装MySQL依赖</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-common-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-common-5.7.28-1.e################################# [100%]</span><br><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-libs-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-libs-5.7.28-1.el7################################# [100%]</span><br><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-libs-compat-5.7.2################################# [100%]</span><br></pre></td></tr></table></figure>

<p>（5）安装mysql-client</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-client-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-client-5.7.28-1.e################################# [100%]</span><br></pre></td></tr></table></figure>

<p>（6）安装mysql-server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-server-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">准备中...                          ################################# [100%]</span><br><span class="line">正在升级/安装...</span><br><span class="line">   1:mysql-community-server-5.7.28-1.e################################# [100%]</span><br></pre></td></tr></table></figure>

<p>（7）启动MySQL</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# systemctl start mysqld</span><br><span class="line">[root@hadoop102 mysql_lib]# systemctl status mysqld</span><br><span class="line">● mysqld.service - MySQL Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 六 2023-10-07 15:42:21 CST; 42s ago</span><br><span class="line">     Docs: man:mysqld(8)</span><br><span class="line">           http://dev.mysql.com/doc/refman/en/using-systemd.html</span><br><span class="line">  Process: 4915 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS)</span><br><span class="line">  Process: 4861 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 4918 (mysqld)</span><br><span class="line">    Tasks: 27</span><br><span class="line">   CGroup: /system.slice/mysqld.service</span><br><span class="line">           └─4918 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line"></span><br><span class="line">10月 07 15:42:17 hadoop102 systemd[1]: Starting MySQL Server...</span><br><span class="line">10月 07 15:42:21 hadoop102 systemd[1]: Started MySQL Server.</span><br></pre></td></tr></table></figure>

<p>（8）查看MySQL密码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# cat /var/log/mysqld.log | grep password</span><br><span class="line">2023-10-07T07:42:18.978817Z 1 [Note] A temporary password is generated for root@localhost: yy54Rff=kwJI</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-配置MySQL"><a href="#2-2-2-配置MySQL" class="headerlink" title="2.2.2 配置MySQL"></a>2.2.2 配置MySQL</h3><p>配置主要是root用户+密码，在任何主机上都能登录MySQL数据库</p>
<p>（1）用刚刚查到的密码进入MySQL</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 mysql_lib]# mysql -uroot -p&#x27;yy54Rff=kwJI&#x27;</span><br><span class="line">mysql: [Warning] Using a password on the command line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.7.28</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span></span><br></pre></td></tr></table></figure>

<p>（2）设置自己的密码（wy<strong><strong>199</strong></strong>8）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 首先更改MySQL密码策略</span><br><span class="line">mysql&gt; set global validate_password_policy=0;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; set global validate_password_length=4;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"># 设置密码</span><br><span class="line">mysql&gt; set password=password(&quot;wy****199****8&quot;);</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>（3）修改user表，把Host表内容修改为%</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update user set host=&quot;%&quot; where user=&quot;root&quot;;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; select user, host from user;</span><br><span class="line">+---------------+-----------+</span><br><span class="line">| user          | host      |</span><br><span class="line">+---------------+-----------+</span><br><span class="line">| root          | %         |</span><br><span class="line">| mysql.session | localhost |</span><br><span class="line">| mysql.sys     | localhost |</span><br><span class="line">+---------------+-----------+</span><br><span class="line">3 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>（4）刷新并退出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; quit;</span><br><span class="line">Bye</span><br></pre></td></tr></table></figure>

<h2 id="2-3-配置Hive元数据存储到MySQL"><a href="#2-3-配置Hive元数据存储到MySQL" class="headerlink" title="2.3 配置Hive元数据存储到MySQL"></a>2.3 配置Hive元数据存储到MySQL</h2><h3 id="2-3-1-配置元数据到MySQL"><a href="#2-3-1-配置元数据到MySQL" class="headerlink" title="2.3.1 配置元数据到MySQL"></a>2.3.1 配置元数据到MySQL</h3><p>（1）新建Hive元数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 登录MySQL</span><br><span class="line"># 创建Hive元数据库</span><br><span class="line">mysql&gt; create database metastore;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; quit;</span><br><span class="line">Bye</span><br></pre></td></tr></table></figure>

<p>（2）将MySQL的JDBC驱动拷贝到Hive的lib目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# cp mysql-connector-java-5.1.37.jar /opt/module/hive/lib/</span><br></pre></td></tr></table></figure>

<p>（3）在$HIVE_HOME&#x2F;conf目录下新建hive-site.xml文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# cd /opt/module/hive/</span><br><span class="line">[root@hadoop102 hive]# ll</span><br><span class="line">总用量 56</span><br><span class="line">drwxr-xr-x. 3 root root   157 10月  7 14:51 bin</span><br><span class="line">drwxr-xr-x. 2 root root  4096 10月  7 14:51 binary-package-licenses</span><br><span class="line">drwxr-xr-x. 2 root root  4096 10月  7 14:51 conf</span><br><span class="line">drwxr-xr-x. 4 root root    34 10月  7 14:51 examples</span><br><span class="line">drwxr-xr-x. 7 root root    68 10月  7 14:51 hcatalog</span><br><span class="line">drwxr-xr-x. 2 root root    44 10月  7 14:51 jdbc</span><br><span class="line">drwxr-xr-x. 4 root root 12288 10月  7 16:06 lib</span><br><span class="line">-rw-rw-r--. 1 root root 20798 8月  11 2022 LICENSE</span><br><span class="line">-rw-rw-r--. 1 root root   230 8月  11 2022 NOTICE</span><br><span class="line">-rw-rw-r--. 1 root root   540 8月  11 2022 RELEASE_NOTES.txt</span><br><span class="line">drwxr-xr-x. 4 root root    35 10月  7 14:51 scripts</span><br><span class="line">[root@hadoop102 hive]# cd conf/</span><br><span class="line">[root@hadoop102 conf]# vim hive-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的URL --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop102:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的Driver--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">	<span class="comment">&lt;!-- jdbc连接的username--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的password --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>wy****19*****8<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Hive默认在HDFS：的工作目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（4）初始化Hive元数据库（修改采用MySQL存储元数据）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# bin/schematool -dbType mysql -initSchema -verbose</span><br></pre></td></tr></table></figure>

<h3 id="2-3-2-验证元数据是否配置成功"><a href="#2-3-2-验证元数据是否配置成功" class="headerlink" title="2.3.2 验证元数据是否配置成功"></a>2.3.2 验证元数据是否配置成功</h3><p>（1）再次启动Hive</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# bin/hive</span><br></pre></td></tr></table></figure>

<p>（2）使用Hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">hive&gt; create table stu(id int, name string);</span><br><span class="line">hive&gt; insert into stu values(1,&quot;ss&quot;);</span><br><span class="line">hive&gt; select * from stu;</span><br></pre></td></tr></table></figure>

<p>一切正常，证明配置成功！！！</p>
<h3 id="2-3-3-查看MySQL中的元数据（了解即可）"><a href="#2-3-3-查看MySQL中的元数据（了解即可）" class="headerlink" title="2.3.3 查看MySQL中的元数据（了解即可）"></a>2.3.3 查看MySQL中的元数据（了解即可）</h3><p>查看元数据库metastore存储的库信息</p>
<p><img src="Snipaste_2023-10-07_18-10-58.png" alt="Snipaste_2023-10-07_18-10-58"></p>
<p>查看元数据库metastore存储的表信息</p>
<p><img src="Snipaste_2023-10-07_18-12-02.png" alt="Snipaste_2023-10-07_18-12-02"></p>
<p>查看元数据库metastore存储的列相关信息</p>
<p><img src="Snipaste_2023-10-07_18-13-41.png" alt="Snipaste_2023-10-07_18-13-41"></p>
<h2 id="2-4-Hive服务部署"><a href="#2-4-Hive服务部署" class="headerlink" title="2.4 Hive服务部署"></a>2.4 Hive服务部署</h2><h3 id="2-4-1-hiveserver2服务"><a href="#2-4-1-hiveserver2服务" class="headerlink" title="2.4.1 hiveserver2服务"></a>2.4.1 hiveserver2服务</h3><p>Hive的hiveserver2服务的作用是提供jdbc&#x2F;odbc接口，为用户提供远程访问Hive数据的功能，例如用户期望在个人电脑中访问远程服务中的Hive数据，就需要用到Hiveserver2。</p>
<img src="Snipaste_2023-10-07_18-17-22.png" alt="Snipaste_2023-10-07_18-17-22" style="zoom:43%;">

<h4 id="（1）用户说明"><a href="#（1）用户说明" class="headerlink" title="（1）用户说明"></a>（1）用户说明</h4><p>在远程访问Hive数据时，客户端并未直接访问Hadoop集群，而是由Hivesever2代理访问。由于Hadoop集群中的数据具备访问权限控制，所以此时需考虑一个问题：那就是访问Hadoop集群的用户身份是谁？是Hiveserver2的启动用户？还是客户端的登录用户？</p>
<p>答案是都有可能，具体是谁，<strong>由Hiveserver2的hive.server2.enable.doAs参数决定</strong>，该参数的含义是是否启用Hiveserver2用户模拟的功能。若启用，则Hiveserver2会模拟成客户端的登录用户去访问Hadoop集群的数据，不启用，则Hivesever2会直接使用启动用户访问Hadoop集群数据。模拟用户的功能，默认是开启的。</p>
<p>未启用：</p>
<img src="Snipaste_2023-10-07_20-32-27.png" alt="Snipaste_2023-10-07_20-32-27" style="zoom:43%;">

<p>启用：</p>
<img src="Snipaste_2023-10-07_20-32-51.png" alt="Snipaste_2023-10-07_20-32-51" style="zoom:43%;">

<p><strong>生产环境，推荐开启用户模拟功能，因为开启后才能保证各用户之间的权限隔离。</strong></p>
<h4 id="（2）hiveserver2部署"><a href="#（2）hiveserver2部署" class="headerlink" title="（2）hiveserver2部署"></a>（2）hiveserver2部署</h4><p>①hadoop端配置</p>
<p>hivesever2的模拟用户功能，依赖于Hadoop提供的proxy user（代理用户功能），只有Hadoop中的代理用户才能模拟其他用户的身份访问Hadoop集群。因此，需要将hiveserver2的启动用户设置为Hadoop的代理用户，配置方式如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# cd /opt/module/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[root@hadoop102 hadoop]# vim core-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--配置所有节点的atguigu用户都可作为代理用户--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--配置atguigu用户能够代理的用户组为任意组--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--配置atguigu用户能够代理的用户为任意用户--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发配置文件</span></span><br><span class="line">[root@hadoop102 hadoop]# xsync core-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启集群</span></span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh stop</span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh start</span><br></pre></td></tr></table></figure>

<p>②Hive端配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# cd /opt/module/hive/conf/</span><br><span class="line">[root@hadoop102 conf]# vim hive-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的端口号 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="（3）测试"><a href="#（3）测试" class="headerlink" title="（3）测试"></a>（3）测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动hiveserver2</span></span><br><span class="line">[root@hadoop102 hive]# bin/hiveserver2 </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">企业中启动hiveserver2</span></span><br><span class="line">[root@hadoop102 hive]# nohup bin/hiveserver2 &gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line">[1] 10500</span><br><span class="line">[root@hadoop102 hive]# jps</span><br><span class="line">10016 JobHistoryServer</span><br><span class="line">10659 Jps</span><br><span class="line">10500 RunJar</span><br><span class="line">9301 NameNode</span><br><span class="line">9482 DataNode</span><br><span class="line">9819 NodeManager</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用命令行客户端beeline进行远程访问</span></span><br><span class="line">[root@hadoop102 hive]# bin/beeline</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/opt/module/hive/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Beeline version 3.1.3 by Apache Hive</span><br><span class="line"><span class="meta prompt_">beeline&gt; </span><span class="language-bash">!connect jdbc:hive2://hadoop102:10000</span></span><br><span class="line">Connecting to jdbc:hive2://hadoop102:10000</span><br><span class="line">Enter username for jdbc:hive2://hadoop102:10000: root</span><br><span class="line">Enter password for jdbc:hive2://hadoop102:10000: </span><br><span class="line">Connected to: Apache Hive (version 3.1.3)</span><br><span class="line">Driver: Hive JDBC (version 3.1.3)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">0: jdbc:hive2://hadoop102:10000&gt; show tables;</span><br><span class="line">INFO  : Compiling command(queryId=root_20231007210619_ce543413-c7bd-4d24-abb6-6351d5b5541f): show tables</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Semantic Analysis Completed (retrial = false)</span><br><span class="line">INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:tab_name, type:string, comment:from deserializer)], properties:null)</span><br><span class="line">INFO  : Completed compiling command(queryId=root_20231007210619_ce543413-c7bd-4d24-abb6-6351d5b5541f); Time taken: 0.579 seconds</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Executing command(queryId=root_20231007210619_ce543413-c7bd-4d24-abb6-6351d5b5541f): show tables</span><br><span class="line">INFO  : Starting task [Stage-0:DDL] in serial mode</span><br><span class="line">INFO  : Completed executing command(queryId=root_20231007210619_ce543413-c7bd-4d24-abb6-6351d5b5541f); Time taken: 0.024 seconds</span><br><span class="line">INFO  : OK</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">+-----------+</span><br><span class="line">| tab_name  |</span><br><span class="line">+-----------+</span><br><span class="line">| stu       |</span><br><span class="line">+-----------+</span><br><span class="line">1 row selected (0.932 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop102:10000&gt; select * from stu;</span><br><span class="line">INFO  : Compiling command(queryId=root_20231007210647_ebd8e686-1d22-4de3-a407-9f97a8451ed3): select * from stu</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Semantic Analysis Completed (retrial = false)</span><br><span class="line">INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:stu.id, type:int, comment:null), FieldSchema(name:stu.name, type:string, comment:null)], properties:null)</span><br><span class="line">INFO  : Completed compiling command(queryId=root_20231007210647_ebd8e686-1d22-4de3-a407-9f97a8451ed3); Time taken: 1.078 seconds</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Executing command(queryId=root_20231007210647_ebd8e686-1d22-4de3-a407-9f97a8451ed3): select * from stu</span><br><span class="line">INFO  : Completed executing command(queryId=root_20231007210647_ebd8e686-1d22-4de3-a407-9f97a8451ed3); Time taken: 0.0 seconds</span><br><span class="line">INFO  : OK</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">+---------+-----------+</span><br><span class="line">| stu.id  | stu.name  |</span><br><span class="line">+---------+-----------+</span><br><span class="line">| 1       | ss        |</span><br><span class="line">+---------+-----------+</span><br><span class="line">1 row selected (1.477 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop102:10000&gt; !quit</span><br><span class="line">Closing: 0: jdbc:hive2://hadoop102:10000</span><br></pre></td></tr></table></figure>

<p>使用Datagrip图形化客户端进行远程访问：</p>
<h4 id="（4）配置Datagrip连接"><a href="#（4）配置Datagrip连接" class="headerlink" title="（4）配置Datagrip连接"></a>（4）配置Datagrip连接</h4><p>①创建连接</p>
<img src="Snipaste_2023-10-07_21-10-17.png" alt="Snipaste_2023-10-07_21-10-17" style="zoom:43%;">

<p>②配置连接属性</p>
<img src="Snipaste_2023-10-07_21-13-20.png" alt="Snipaste_2023-10-07_21-13-20" style="zoom:50%;">

<p>③测试sql执行</p>
<p><img src="Snipaste_2023-10-07_21-16-48.png" alt="Snipaste_2023-10-07_21-16-48"></p>
<h3 id="2-4-2-metastore服务"><a href="#2-4-2-metastore服务" class="headerlink" title="2.4.2 metastore服务"></a>2.4.2 metastore服务</h3><p>Hive的metastore服务的作用是为Hive CLI或者Hiveserver2提供元数据访问接口。metastore有两种运行模式，分别为嵌入式模式和独立服务模式，生产环境中，推荐使用独立服务模式。</p>
<p>直接看独立服务模式：</p>
<p><strong>将metastore服务部署在hadoop102，在hadoop103上部署一个客户端</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">①首先将hadoop102的hive安装包发送到hadoop103</span></span><br><span class="line">[root@hadoop102 hive]# scp -r /opt/module/hive/ hadoop103:/opt/module/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">②查看hive确实成功转发到hadoop103</span></span><br><span class="line">[root@hadoop103 ~]# cd /opt/module/</span><br><span class="line">[root@hadoop103 module]# ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 13 atguigu atguigu 204 9月  14 22:14 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 10 root    root    184 10月  8 12:11 hive</span><br><span class="line">drwxr-xr-x.  7 atguigu atguigu 245 8月   7 17:06 jdk1.8.0_212</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">③在hadoop102上启动metastore服务</span></span><br><span class="line">[root@hadoop102 conf]# nohup hive --service metastore &amp;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">④在hadoop103配置客户端</span></span><br><span class="line">[root@hadoop103 conf]# vim hive-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Hive默认在HDFS的工作目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定hiveserver2连接的端口号 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定metastore服务的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://hadoop102:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">⑤在hadoop103上访问hive</span></span><br><span class="line">[root@hadoop103 hive]# bin/hive</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">stu</span><br><span class="line">test</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.16</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br><span class="line">OK</span><br><span class="line"><span class="number">1</span>	ss</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.234</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<h3 id="2-4-3-编写Hive服务启动脚本"><a href="#2-4-3-编写Hive服务启动脚本" class="headerlink" title="2.4.3 编写Hive服务启动脚本"></a>2.4.3 编写Hive服务启动脚本</h3><p>注意：如果不编写脚本执行以下两个语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动hiveserver2</span></span><br><span class="line">[root@hadoop102 hive]# nohup hive --service hiveserver2 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动metastore服务</span></span><br><span class="line">[root@hadoop102 conf]# nohup hive --service metastore 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看进程，可以看到有两个RunJar，证明这两个服务在后台启动成功</span></span><br><span class="line">[root@hadoop102 hive]# jps</span><br><span class="line">3777 JobHistoryServer</span><br><span class="line">3074 NameNode</span><br><span class="line">4101 RunJar</span><br><span class="line">4854 RunJar</span><br><span class="line">3255 DataNode</span><br><span class="line">3591 NodeManager</span><br><span class="line">5004 Jps</span><br></pre></td></tr></table></figure>

<p>下面来编写Hive服务的启停脚本，实现服务的启动和关闭（类似于myhadoop.sh）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hive]# cd /opt/module/hive/bin</span><br><span class="line">[root@hadoop102 bin]# vim hiveservices.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">HIVE_LOG_DIR=$HIVE_HOME/logs</span><br><span class="line">if [ ! -d $HIVE_LOG_DIR ]</span><br><span class="line">then</span><br><span class="line">	mkdir -p $HIVE_LOG_DIR</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">检查进程是否运行正常，参数1为进程名，参数2为进程端口</span></span><br><span class="line">function check_process()</span><br><span class="line">&#123;</span><br><span class="line">    pid=$(ps -ef 2&gt;/dev/null | grep -v grep | grep -i $1 | awk &#x27;&#123;print $2&#125;&#x27;)</span><br><span class="line">    ppid=$(netstat -nltp 2&gt;/dev/null | grep $2 | awk &#x27;&#123;print $7&#125;&#x27; | cut -d &#x27;/&#x27; -f 1)</span><br><span class="line">    echo $pid</span><br><span class="line">    [[ &quot;$pid&quot; =~ &quot;$ppid&quot; ]] &amp;&amp; [ &quot;$ppid&quot; ] &amp;&amp; return 0 || return 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function hive_start()</span><br><span class="line">&#123;</span><br><span class="line">    metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">    cmd=&quot;nohup hive --service metastore &gt;$HIVE_LOG_DIR/metastore.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    [ -z &quot;$metapid&quot; ] &amp;&amp; eval $cmd || echo &quot;Metastroe服务已启动&quot;</span><br><span class="line">    server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">    cmd=&quot;nohup hive --service hiveserver2 &gt;$HIVE_LOG_DIR/hiveServer2.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    [ -z &quot;$server2pid&quot; ] &amp;&amp; eval $cmd || echo &quot;HiveServer2服务已启动&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function hive_stop()</span><br><span class="line">&#123;</span><br><span class="line">metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">    [ &quot;$metapid&quot; ] &amp;&amp; kill $metapid || echo &quot;Metastore服务未启动&quot;</span><br><span class="line">    server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">    [ &quot;$server2pid&quot; ] &amp;&amp; kill $server2pid || echo &quot;HiveServer2服务未启动&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">    hive_start</span><br><span class="line">    ;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">    hive_stop</span><br><span class="line">    ;;</span><br><span class="line">&quot;restart&quot;)</span><br><span class="line">    hive_stop</span><br><span class="line">    sleep 2</span><br><span class="line">    hive_start</span><br><span class="line">    ;;</span><br><span class="line">&quot;status&quot;)</span><br><span class="line">    check_process HiveMetastore 9083 &gt;/dev/null &amp;&amp; echo &quot;Metastore服务运行正常&quot; || echo &quot;Metastore服务运行异常&quot;</span><br><span class="line">    check_process HiveServer2 10000 &gt;/dev/null &amp;&amp; echo &quot;HiveServer2服务运行正常&quot; || echo &quot;HiveServer2服务运行异常&quot;</span><br><span class="line">    ;;</span><br><span class="line">*)</span><br><span class="line">    echo Invalid Args!</span><br><span class="line">    echo &#x27;Usage: &#x27;$(basename $0)&#x27; start|stop|restart|status&#x27;</span><br><span class="line">    ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加执行权限</span></span><br><span class="line">[root@hadoop102 bin]# chmod +x hiveservices.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试关闭Hive后台服务</span></span><br><span class="line">[root@hadoop102 bin]# hiveservices.sh stop</span><br><span class="line">[root@hadoop102 bin]# jps</span><br><span class="line">3777 JobHistoryServer</span><br><span class="line">3074 NameNode</span><br><span class="line">3255 DataNode</span><br><span class="line">3591 NodeManager</span><br><span class="line">5211 Jps</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">测试启动Hive后台服务</span></span><br><span class="line">[root@hadoop102 bin]# hiveservices.sh start</span><br><span class="line">[root@hadoop102 bin]# jps</span><br><span class="line">3777 JobHistoryServer</span><br><span class="line">3074 NameNode</span><br><span class="line">3255 DataNode</span><br><span class="line">3591 NodeManager</span><br><span class="line">5512 Jps</span><br><span class="line">5274 RunJar</span><br><span class="line">5243 RunJar</span><br></pre></td></tr></table></figure>

<h2 id="2-5-Hive使用技巧"><a href="#2-5-Hive使用技巧" class="headerlink" title="2.5 Hive使用技巧"></a>2.5 Hive使用技巧</h2><h3 id="2-5-1-Hive常用交互命令"><a href="#2-5-1-Hive常用交互命令" class="headerlink" title="2.5.1 Hive常用交互命令"></a>2.5.1 Hive常用交互命令</h3><p>（1）“-e”不进入hive的交互窗口执行hql语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# hive -e &quot;insert into stu values(1,&#x27;aa&#x27;)&quot;</span><br></pre></td></tr></table></figure>

<p>（2）“-f”执行脚本中的hql语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">①/opt/module/hive/下创建datas目录并在datas目录下创建hivef.sql文件</span></span><br><span class="line">[root@hadoop102 bin]# cd /opt/module/hive/</span><br><span class="line">[root@hadoop102 hive]# mkdir datas</span><br><span class="line">[root@hadoop102 hive]# vim hivef.sql</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">②执行文件中的hql语句</span></span><br><span class="line">[root@hadoop102 hive]# hive -f hivef.sql</span><br><span class="line">...</span><br><span class="line">1	aa</span><br><span class="line">1	ss</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">③执行文件中的hql语句并将结果写入文件中</span></span><br><span class="line">[root@hadoop102 hive]# hive -f hivef.sql &gt; /opt/module/hive/datas/hive_result.txt</span><br><span class="line">[root@hadoop102 hive]# cd datas/</span><br><span class="line">[root@hadoop102 datas]# vim hive_result.txt</span><br><span class="line">1       aa</span><br><span class="line">1       ss</span><br></pre></td></tr></table></figure>

<h3 id="2-5-2-Hive参数配置方式"><a href="#2-5-2-Hive参数配置方式" class="headerlink" title="2.5.2 Hive参数配置方式"></a>2.5.2 Hive参数配置方式</h3><p>（1）查看当前所有的配置信息</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span><span class="keyword">set</span>;</span><br></pre></td></tr></table></figure>

<p>（2）参数的配置三种方式</p>
<p>①配置文件方式</p>
<p>默认配置文件：hive-default.xml</p>
<p>用户自定义配置文件：hive-site.xml</p>
<p>注意：<strong>用户自定义配置会覆盖默认配置</strong>。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，<strong>Hive的配置会覆盖Hadoop的配置</strong>。配置文件的设定对本机启动的所有Hive进程都有效。</p>
<p>②命令行参数方式</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动Hive时，可以在命令行添加-hiveconf param=value来设定参数。仅对本次Hive启动有效，例如：</span></span><br><span class="line">[root@hadoop102 datas]# bin/hive -hiveconf mapreduce.job.reduces=10;</span><br></pre></td></tr></table></figure>

<p>③参数声明方式</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在Hql中使用<span class="keyword">set</span>关键字设定参数，仅对本次Hive启动有效</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">10</span>;</span><br><span class="line"># 查看当前参数值</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces;</span><br><span class="line">mapreduce.job.reduces<span class="operator">=</span><span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>上述三种设定方式的优先级依次递增。即<strong>配置文件&lt; 命令行参数</strong>&lt; 参数声明。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</p>
<h3 id="2-5-3-Hive常见属性配置"><a href="#2-5-3-Hive常见属性配置" class="headerlink" title="2.5.3 Hive常见属性配置"></a>2.5.3 Hive常见属性配置</h3><p>（1）Hive客户端显示当前库和表头</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在hive-site.xml中加入如下两个配置:</span></span><br><span class="line">[root@hadoop102 conf]# vim hive-site.xml </span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether to print the names of the columns in query output.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether to include the current database in the Hive prompt.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>此时再打开hive客户端：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu;</span><br><span class="line">OK</span><br><span class="line">stu.id	stu.name</span><br><span class="line"><span class="number">1</span>	aa</span><br><span class="line"><span class="number">1</span>	ss</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.121</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<p>（2）hive运行日志路径配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">首先修改/conf/hive-log4j2.properties.template文件名称为hive-log4j2.properties</span></span><br><span class="line">[root@hadoop102 conf]# mv hive-log4j2.properties.template hive-log4j2.properties</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hive-log4j2.properties文件中修改<span class="built_in">log</span>存放位置</span></span><br><span class="line">[root@hadoop102 conf]# vim hive-log4j2.properties</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 修改配置如下：</span><br><span class="line">property.hive.log.dir=/opt/module/hive/logs</span><br></pre></td></tr></table></figure>

<p>（3）Hive的JVM堆内存设置</p>
<p>新版本的Hive启动的时候，默认申请的JVM堆内存大小为256M，JVM堆内存申请的太小，导致后期开启本地模式，执行复杂的SQL时经常会报错：java.lang.OutOfMemoryError: Java heap space，因此最好提前调整一下HADOOP_HEAPSIZE这个参数。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将/conf下的hive-env.sh.template为hive-env.sh</span></span><br><span class="line">[root@hadoop102 conf]# mv hive-env.sh.template hive-env.sh</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将hive-env.sh其中的参数 <span class="built_in">export</span> HADOOP_HEAPSIZE修改为2048，重启Hive。</span></span><br><span class="line">export HADOOP_HEAPSIZE=2048</span><br><span class="line">[root@hadoop102 conf]# hiveservices.sh restart</span><br></pre></td></tr></table></figure>

<p>（4）关闭Hadoop虚拟内存检查</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">关闭hadoop集群</span></span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh stop</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改配置文件yarn-site.xml</span></span><br><span class="line">[root@hadoop102 hadoop]# pwd</span><br><span class="line">/opt/module/hadoop-3.1.3/etc/hadoop</span><br><span class="line">[root@hadoop102 hadoop]# vim yarn-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加如下配置</span></span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发配置文件</span></span><br><span class="line">[root@hadoop102 hadoop]# xsync yarn-site.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">重启集群</span></span><br><span class="line">[root@hadoop102 hadoop]# myhadoop.sh start</span><br></pre></td></tr></table></figure>

<h1 id="第三章-DDL数据定义"><a href="#第三章-DDL数据定义" class="headerlink" title="第三章 DDL数据定义"></a>第三章 DDL数据定义</h1><h2 id="3-1-数据库（database）"><a href="#3-1-数据库（database）" class="headerlink" title="3.1 数据库（database）"></a>3.1 数据库（database）</h2><h3 id="3-1-1-创建数据库"><a href="#3-1-1-创建数据库" class="headerlink" title="3.1.1 创建数据库"></a>3.1.1 创建数据库</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] database_name</span><br><span class="line">[COMMENT database_comment]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[<span class="keyword">WITH</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...)];</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> 创建一个数据库，不指定路径</span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 若不指定路径，其默认路径为$&#123;hive.metastore.warehouse.dir&#125;<span class="operator">/</span>database_name.db</span><br><span class="line"><span class="keyword">create</span> database db_hive;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_14-40-04.png" alt="Snipaste_2023-10-08_14-40-04"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>创建一个数据库，指定路径</span><br><span class="line"><span class="keyword">create</span> database db_hive2 location <span class="string">&#x27;/db_hive2&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_14-41-48.png" alt="Snipaste_2023-10-08_14-41-48"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>创建一个数据库，带有dbproperties</span><br><span class="line"><span class="keyword">create</span> database db_hive3 <span class="keyword">with</span> dbproperties (<span class="string">&#x27;create_date&#x27;</span><span class="operator">=</span><span class="string">&#x27;2023-10-08&#x27;</span>);</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-查询数据库"><a href="#3-1-2-查询数据库" class="headerlink" title="3.1.2 查询数据库"></a>3.1.2 查询数据库</h3><h4 id="3-1-2-1-展示所有数据库"><a href="#3-1-2-1-展示所有数据库" class="headerlink" title="3.1.2.1 展示所有数据库"></a>3.1.2.1 展示所有数据库</h4><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> DATABASES [<span class="keyword">LIKE</span> <span class="string">&#x27;identifier_with_wildcards&#x27;</span>];</span><br></pre></td></tr></table></figure>

<p>注：like通配表达式说明：*表示任意个任意字符，|表示或的关系。</p>
<p>（2）案例</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> databases ;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">db_hive</span><br><span class="line">db_hive2</span><br><span class="line">db_hive3</span><br><span class="line">default</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> databases <span class="keyword">like</span> <span class="string">&#x27;db_hive*&#x27;</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">db_hive</span><br><span class="line">db_hive2</span><br><span class="line">db_hive3</span><br></pre></td></tr></table></figure>

<h4 id="3-1-2-2-查看数据库信息"><a href="#3-1-2-2-查看数据库信息" class="headerlink" title="3.1.2.2 查看数据库信息"></a>3.1.2.2 查看数据库信息</h4><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DESCRIBE</span> DATABASE [EXTENDED] db_name;</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">describe</span> database extended db_hive3;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_14-53-15.png" alt="Snipaste_2023-10-08_14-53-15"></p>
<h3 id="3-1-3-修改数据库"><a href="#3-1-3-修改数据库" class="headerlink" title="3.1.3 修改数据库"></a>3.1.3 修改数据库</h3><p>用户可以使用alter database命令修改数据库某些信息，其中能够修改的信息包括dbproperties、location、owner user。需要注意的是：修改数据库location，不会改变当前已有表的路径信息，而只是改变后续创建的新表的默认的父目录。</p>
<p>（1）语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 修改dbproperties</span><br><span class="line">ALTER DATABASE database_name SET DBPROPERTIES (property_name=property_value, ...);</span><br><span class="line"></span><br><span class="line">-- 修改location</span><br><span class="line">ALTER DATABASE database_name SET LOCATION hdfs_path;</span><br><span class="line"></span><br><span class="line">-- 修改owner user</span><br><span class="line">ALTER DATABASE database_name SET OWNER USER user_name;</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">alter</span> database db_hive3 <span class="keyword">set</span> dbproperties (<span class="string">&#x27;create_date&#x27;</span><span class="operator">=</span><span class="string">&#x27;2023-10-10&#x27;</span>);</span><br><span class="line"><span class="keyword">describe</span> database extended db_hive3;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_15-06-49.png" alt="Snipaste_2023-10-08_15-06-49"></p>
<h3 id="3-1-4-删除数据库（慎用）"><a href="#3-1-4-删除数据库（慎用）" class="headerlink" title="3.1.4 删除数据库（慎用）"></a>3.1.4 删除数据库（慎用）</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> DATABASE [IF <span class="keyword">EXISTS</span>] database_name [RESTRICT<span class="operator">|</span>CASCADE];</span><br></pre></td></tr></table></figure>

<p>注：RESTRICT：严格模式，若数据库不为空，则会删除失败，默认为该模式。</p>
<p>  CASCADE：级联模式，若数据库不为空，则会将库中的表一并删除。</p>
<h3 id="3-1-5-切换当前数据库"><a href="#3-1-5-切换当前数据库" class="headerlink" title="3.1.5 切换当前数据库"></a>3.1.5 切换当前数据库</h3><p>略</p>
<h2 id="3-2-表（table）"><a href="#3-2-表（table）" class="headerlink" title="3.2 表（table）"></a>3.2 表（table）</h2><h3 id="3-2-1-创建表"><a href="#3-2-1-创建表" class="headerlink" title="3.2.1 创建表"></a>3.2.1 创建表</h3><h4 id="3-2-1-1-语法"><a href="#3-2-1-1-语法" class="headerlink" title="3.2.1.1 语法"></a>3.2.1.1 语法</h4><p>（1）普通建表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [TEMPORARY] [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name   </span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[COMMENT table_comment]</span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) </span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS]</span><br><span class="line">[<span class="type">ROW</span> FORMAT row_format] </span><br><span class="line">[STORED <span class="keyword">AS</span> file_format]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[TBLPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]</span><br></pre></td></tr></table></figure>

<p>关键字说明：</p>
<p>①<strong>TEMPORARY</strong>：临时表，该表只在当前会话可见，会话结束，表会被删除。</p>
<p>②<strong>EXTERNAL</strong>：外部表，与之相对应的是内部表（管理表）。管理表意味着Hive会完全接管该表，包括元数据和HDFS中的数据。而外部表则意味着Hive只接管元数据，而不完全接管HDFS中的数据，外部表指向已经存在于HDFS上的数据。</p>
<p><strong>内部表和外部表的区别，面试可能会问，详见《大数据面试题总结》</strong></p>
<ul>
<li>由external修饰的表为外部表，未被external修饰的表为内部表</li>
<li>内部表由Hive自身管理（包括元数据和HDFS中的数据）；外部表Hive只接管元数据，数据由HDFS管理</li>
<li>删除（drop）内部表会直接删除元数据及HDFS上的文件；删除（drop）外部表仅仅会删除元数据，HDFS上的文件并不会删除</li>
<li>清空（truncate）表操作只能清空内部表，清空外部表将报错</li>
</ul>
<p>③<strong>data_type</strong>（重点）：</p>
<img src="Snipaste_2023-10-08_15-23-29.png" alt="Snipaste_2023-10-08_15-23-29" style="zoom:43%;">

<p>说明decimal(16,2)：代表最多有16位数字，其中后2位是小数，整数部分是14位；如果整数部分超过14位，这个字段就会变成null，如果小数部分不足2位，后面用0补齐两位，小数部分超过两位，超出部分四舍五入。直接写decimal默认是decimal(10,0)。</p>
<p>12345678909876.12</p>
<p>123456789098765——null</p>
<p>12345678909876.1—–12345678909876.10</p>
<p>12345678909876.125—–12345678909876.13</p>
<p>一般而言，在hive中，整数用int，特别多的整数用bigint，小数用double或decimal(推荐)，字符串用string</p>
<img src="Snipaste_2023-10-08_15-23-50.png" alt="Snipaste_2023-10-08_15-23-50" style="zoom:43%;">

<p><strong>Hive的基本数据类型可以相互转换</strong>：</p>
<p><strong>隐式转换（知道就行）</strong>：</p>
<p>a. 任何整数类型都可以隐式地转换为一个范围更广的类型，如tinyint可以转换成int，int可以转换成bigint。</p>
<p>b. 所有整数类型、float和string类型都可以隐式地转换成double。</p>
<p>c. tinyint、smallint、int都可以转换为float。</p>
<p>d. boolean类型不可以转换为任何其它的类型。</p>
<p><strong>显式转换</strong>：</p>
<p>可以借助cast函数完成显示的类型转换</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="string">&#x27;1&#x27;</span> <span class="operator">+</span> <span class="number">2</span>, <span class="built_in">cast</span>(<span class="string">&#x27;1&#x27;</span> <span class="keyword">as</span> <span class="type">int</span>) <span class="operator">+</span> <span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">3,3</span><br><span class="line">第一个3是double类型，第二个3是int类型</span><br></pre></td></tr></table></figure>

<p>④<strong>PARTITIONED BY</strong>（重点）：创建分区表</p>
<p>⑤<strong>CLUSTERED BY … SORTED BY…INTO … BUCKETS</strong>（重点）：创建分桶表</p>
<p>⑥<strong>ROW FORMAT</strong>（重点）：指定SERDE，SERDE是Serializer and Deserializer的简写。Hive使用SERDE序列化和反序列化每行数据。</p>
<img src="Snipaste_2023-10-08_16-15-03.png" alt="Snipaste_2023-10-08_16-15-03" style="zoom:50%;">

<img src="Snipaste_2023-10-08_16-15-26.png" alt="Snipaste_2023-10-08_16-15-26" style="zoom:50%;">

<p>⑦<strong>STORED AS</strong>（重点）：指定文件格式，常用的文件格式有，textfile（默认值），sequence file，orc file、parquet file等等。</p>
<p>⑧<strong>LOCATION</strong>：指定表所对应的HDFS路径，若不指定路径，其默认值${hive.metastore.warehouse.dir}&#x2F;db_name.db&#x2F;table_name</p>
<p>⑨<strong>TBLPROPERTIES</strong>：用于配置表的一些KV键值对参数</p>
<p>（2）Create Table As Select（CTAS）建表</p>
<p>该语法允许用户利用select查询语句返回的结果，直接建表，表的结构和查询语句的结构保持一致，且保证包含select查询语句放回的内容。</p>
<p><img src="Snipaste_2023-10-08_16-28-23.png" alt="Snipaste_2023-10-08_16-28-23"></p>
<p>（3）Create Table Like语法</p>
<p>该语法允许用户复刻一张已经存在的表结构，与上述的CTAS语法不同，该语法创建出来的表中<strong>不包含数据</strong>，只是一个表的框架</p>
<p><img src="Snipaste_2023-10-08_16-28-47.png" alt="Snipaste_2023-10-08_16-28-47"></p>
<h4 id="3-2-1-2-案例"><a href="#3-2-1-2-案例" class="headerlink" title="3.2.1.2 案例"></a>3.2.1.2 案例</h4><h5 id="（1）内部表与外部表"><a href="#（1）内部表与外部表" class="headerlink" title="（1）内部表与外部表"></a>（1）内部表与外部表</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- （1）内部表</span></span><br><span class="line"><span class="comment">-- Hive中默认创建的表都是的内部表，有时也被称为管理表。对于内部表，Hive会完全管理表的元数据和数据文件。</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student(</span><br><span class="line">    id <span class="type">int</span>,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/user/hive/warehouse/student&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>准备其需要的文件如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mkdir /opt/module/datas</span><br><span class="line">[root@hadoop102 module]# vim /opt/module/datas/student.txt</span><br><span class="line">1001	student1</span><br><span class="line">1002	student2</span><br><span class="line">1003	student3</span><br><span class="line">1004	student4</span><br><span class="line">1005	student5</span><br><span class="line">1006	student6</span><br><span class="line">1007	student7</span><br><span class="line">1008	student8</span><br><span class="line">1009	student9</span><br><span class="line">1010	student10</span><br><span class="line">1011	student11</span><br><span class="line">1012	student12</span><br><span class="line">1013	student13</span><br><span class="line">1014	student14</span><br><span class="line">1015	student15</span><br><span class="line">1016	student16</span><br></pre></td></tr></table></figure>

<p>上传文件到Hive表指定的路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# hadoop fs -put student.txt /user/hive/warehouse/student</span><br><span class="line">2023-10-08 19:29:10,755 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<p>在datagrip端就可以查到：</p>
<img src="Snipaste_2023-10-08_19-30-17.png" alt="Snipaste_2023-10-08_19-30-17" style="zoom: 33%;">

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 删除表，其中表结构和数据都被删除了，HDFS上的文件也没了</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- （2）外部表</span></span><br><span class="line"><span class="comment">--     外部表通常可用于处理其他工具上传的数据文件，对于外部表，</span></span><br><span class="line"><span class="comment">-- Hive只负责管理元数据，不负责管理HDFS中的数据文件。</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student(</span><br><span class="line">    id <span class="type">int</span>,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">location <span class="string">&#x27;/user/hive/warehouse/student&#x27;</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上传文件到Hive表指定的路径</span></span><br><span class="line">[root@hadoop102 datas]# hadoop fs -put student.txt /user/hive/warehouse/student</span><br><span class="line">2023-10-08 19:42:09,630 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 删除表，此时HDFS中的数据文件仍然存在</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-08_19-44-22.png" alt="Snipaste_2023-10-08_19-44-22" style="zoom:43%;">

<img src="Snipaste_2023-10-08_19-45-03.png" alt="Snipaste_2023-10-08_19-45-03" style="zoom:43%;">

<h5 id="（2）SERDE和复杂数据类型"><a href="#（2）SERDE和复杂数据类型" class="headerlink" title="（2）SERDE和复杂数据类型"></a>（2）<strong>SERDE和复杂数据类型</strong></h5><p>若现有如下格式的JSON文件需要由Hive进行分析处理，请考虑如何设计表？</p>
<p>注：以下内容为格式化之后的结果，文件中每行数据为一个完整的JSON字符串。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dasongsong&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;friends&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;bingbing&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;lili&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;students&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;xiaohaihai&quot;</span><span class="punctuation">:</span> <span class="number">18</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;xiaoyangyang&quot;</span><span class="punctuation">:</span> <span class="number">16</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;address&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;street&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hui long guan&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span> <span class="string">&quot;beijing&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;postal_code&quot;</span><span class="punctuation">:</span> <span class="number">10010</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>我们可以考虑使用专门负责JSON文件的JSON Serde，设计表字段时，表的字段与JSON字符串中的一级字段保持一致，对于具有嵌套结构的JSON字符串，考虑使用合适复杂数据类型保存其内容。最终设计出的表结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create table teacher</span><br><span class="line">(</span><br><span class="line">    name     string,</span><br><span class="line">    friends  array&lt;string&gt;,</span><br><span class="line">    students map&lt;string,int&gt;,</span><br><span class="line">    address  struct&lt;city:string,street:string,postal_code:int&gt;</span><br><span class="line">)</span><br><span class="line">row format serde &#x27;org.apache.hadoop.hive.serde2.JsonSerDe&#x27;</span><br><span class="line">location &#x27;/user/hive/warehouse/teacher&#x27;;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建文件数据并上传到HIve表指定的路径</span></span><br><span class="line">[root@hadoop102 datas]# vim /opt/module/datas/teacher.txt</span><br><span class="line">&#123;&quot;name&quot;:&quot;dasongsong&quot;,&quot;friends&quot;:[&quot;bingbing&quot;,&quot;lili&quot;],&quot;students&quot;:&#123;&quot;xiaohaihai&quot;:18,&quot;xiaoyangyang&quot;:16&#125;,&quot;address&quot;:&#123;&quot;street&quot;:&quot;hui long guan&quot;,&quot;city&quot;:&quot;beijing&quot;,&quot;postal_code&quot;:10010&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;:&quot;dasongsong&quot;,&quot;friends&quot;:[&quot;bingbing&quot;,&quot;lili&quot;],&quot;students&quot;:&#123;&quot;xiaohaihai&quot;:18,&quot;xiaoyangyang&quot;:16&#125;,&quot;address&quot;:&#123;&quot;street&quot;:&quot;hui long guan&quot;,&quot;city&quot;:&quot;beijing&quot;,&quot;postal_code&quot;:10010&#125;&#125;</span><br><span class="line">[root@hadoop102 datas]# hadoop fs -put teacher.txt /user/hive/warehouse/teacher</span><br><span class="line">2023-10-08 21:16:23,678 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<p>在datagrip端可以看到数据：</p>
<p><img src="Snipaste_2023-10-08_21-17-46.png" alt="Snipaste_2023-10-08_21-17-46"></p>
<p>尝试从复杂数据类型的字段中取值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select friends[0], students[&#x27;xiaohaihai&#x27;], address.city</span><br><span class="line">from teacher;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-08_21-22-42.png" alt="Snipaste_2023-10-08_21-22-42" style="zoom:50%;">

<h5 id="（3）creat-table-select和create-table-like"><a href="#（3）creat-table-select和create-table-like" class="headerlink" title="（3）creat table select和create table like"></a>（3）creat table select和create table like</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- creat table select建出来的表结构和数据都有</span><br><span class="line">create table teacher1 as select * from teacher;</span><br><span class="line">select * from teacher1;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_21-28-54.png" alt="Snipaste_2023-10-08_21-28-54"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- create table like建出来的表只有结构没有里面的数据，是一个空表</span><br><span class="line">create table teacher2 like teacher;</span><br><span class="line">select * from teacher2;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-08_21-30-45.png" alt="Snipaste_2023-10-08_21-30-45"></p>
<h3 id="3-2-2-查看表"><a href="#3-2-2-查看表" class="headerlink" title="3.2.2 查看表"></a>3.2.2 查看表</h3><p>（1）展示所有表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> TABLES [<span class="keyword">IN</span> database_name] <span class="keyword">LIKE</span> [<span class="string">&#x27;identifier_with_wildcards&#x27;</span>];</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show tables like &#x27;stu*&#x27;;</span><br></pre></td></tr></table></figure>

<p>（2）查看表信息</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DESCRIBE</span> [EXTENDED <span class="operator">|</span> FORMATTED] [db_name.]table_name</span><br></pre></td></tr></table></figure>

<p>注：EXTENDED：展示详细信息</p>
<p>​	FORMATTED：对详细信息进行格式化的展示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 查看基本信息</span><br><span class="line">describe teacher;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-09_12-17-14.png" alt="Snipaste_2023-10-09_12-17-14"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 查看更多信息</span><br><span class="line">desc formatted stu;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-09_12-18-43.png" alt="Snipaste_2023-10-09_12-18-43"></p>
<h3 id="3-2-3-修改表"><a href="#3-2-3-修改表" class="headerlink" title="3.2.3 修改表"></a>3.2.3 修改表</h3><p>（1）重命名表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name RENAME <span class="keyword">TO</span> new_table_name</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table stu rename to stu1;</span><br></pre></td></tr></table></figure>

<p>（2）修改列信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- ①增加列：该语句允许用户增加新的列，新增列的位置位于末尾。</span><br><span class="line">-- ALTER TABLE table_name ADD COLUMNS (col_name data_type [COMMENT col_comment], ...)</span><br><span class="line">alter table stu1 add columns(age int);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_12-40-32.png" alt="Snipaste_2023-10-09_12-40-32" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- ②更新列：该语句允许用户修改指定列的列名、数据类型、注释信息以及在表中的位置。</span><br><span class="line">-- ALTER TABLE table_name</span><br><span class="line">-- CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]</span><br><span class="line">alter table stu1 change column age ages double;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_12-42-02.png" alt="Snipaste_2023-10-09_12-42-02" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- ③替换列：该语句允许用户用新的列集替换表中原有的全部列。</span><br><span class="line">-- ALTER TABLE table_name REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)</span><br><span class="line">alter table stu1 replace columns(id int, name string);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_12-42-43.png" alt="Snipaste_2023-10-09_12-42-43" style="zoom:50%;">

<h3 id="3-2-4-删除表"><a href="#3-2-4-删除表" class="headerlink" title="3.2.4 删除表"></a>3.2.4 删除表</h3><p>删除表，同时删除表中的数据和表结构（也可以理解为直接删除表结构，表结构都没了，表中数据自然就没了）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 删除表</span><br><span class="line">-- DROP TABLE [IF EXISTS] table_name;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5-清空表"><a href="#3-2-5-清空表" class="headerlink" title="3.2.5 清空表"></a>3.2.5 清空表</h3><p>清空表，顾名思义，就是保留表结构，清空表中的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 清空表：注意：truncate只能清空管理表，不能删除外部表中数据。</span><br><span class="line">-- TRUNCATE [TABLE] table_name</span><br></pre></td></tr></table></figure>

<h1 id="第四章-DML（数据操作）"><a href="#第四章-DML（数据操作）" class="headerlink" title="第四章 DML（数据操作）"></a>第四章 DML（数据操作）</h1><h2 id="4-1-Load"><a href="#4-1-Load" class="headerlink" title="4.1 Load"></a>4.1 Load</h2><p>Load语句可将文件导入到Hive表中。</p>
<p>（1）语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [LOCAL] INPATH &#x27;filepath&#x27; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)];</span><br></pre></td></tr></table></figure>

<p>关键字说明：</p>
<p>①local：表示从本地加载数据到Hive表；否则从HDFS加载数据到Hive表。</p>
<p>加上local表示从本地<strong>复制</strong>数据到hive表，不加local表示从HDFS上<strong>剪切</strong>数据到hive表</p>
<p>②overwrite：表示覆盖表中已有数据，否则表示追加。</p>
<p>③partition：表示上传到指定分区，若目标是分区表，需指定分区。</p>
<p>（2）案例实操</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- ①首先创建一张表</span><br><span class="line">create table student(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- ②加载本地文件到hive（从本地复制数据到hive表）</span><br><span class="line">load data local inpath &#x27;/opt/module/datas/student.txt&#x27; into table student;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_13-04-13.png" alt="Snipaste_2023-10-09_13-04-13" style="zoom:33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">③上传文件到HDFS</span></span><br><span class="line">[root@hadoop102 datas]# hadoop fs -mkdir /user/atguigu</span><br><span class="line">[root@hadoop102 datas]# hadoop fs -put /opt/module/datas/student.txt /user/atguigu</span><br><span class="line">2023-10-09 13:08:00,034 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- ③加载HDFS上的数据，导入完成后去HDFS上查看文件是否还存在（不存在了）</span><br><span class="line">load data inpath &#x27;/user/atguigu/student.txt&#x27; into table student;</span><br></pre></td></tr></table></figure>

<p>追加操作：</p>
<img src="Snipaste_2023-10-09_13-14-06.png" alt="Snipaste_2023-10-09_13-14-06" style="zoom:50%;">

<p>位于HDFS上的&#x2F;user&#x2F;atguigu&#x2F;student.txt文件已经不在了</p>
<img src="Snipaste_2023-10-09_13-15-13.png" alt="Snipaste_2023-10-09_13-15-13" style="zoom:50%;">

<h2 id="4-2-Insert"><a href="#4-2-Insert" class="headerlink" title="4.2 Insert"></a>4.2 Insert</h2><h3 id="4-2-1-将查询结果插入表中"><a href="#4-2-1-将查询结果插入表中" class="headerlink" title="4.2.1 将查询结果插入表中"></a>4.2.1 将查询结果插入表中</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> (<span class="keyword">INTO</span> <span class="operator">|</span> OVERWRITE) <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] select_statement;</span><br></pre></td></tr></table></figure>

<p>关键字说明：</p>
<p>①INTO：将结果追加到目标表</p>
<p>②OVERWRITE：用结果覆盖原有数据</p>
<p>（2）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 新建一张表</span><br><span class="line">create table student1(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 据查询结果插入数据</span><br><span class="line">insert overwrite table student1</span><br><span class="line">select * from student;</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-将给定Values插入表中"><a href="#4-2-2-将给定Values插入表中" class="headerlink" title="4.2.2 将给定Values插入表中"></a>4.2.2 将给定Values插入表中</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> (<span class="keyword">INTO</span> <span class="operator">|</span> OVERWRITE) <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1[<span class="operator">=</span>val1], partcol2[<span class="operator">=</span>val2] ...)] <span class="keyword">VALUES</span> values_row [, values_row ...]</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 将给定Values插入表中</span><br><span class="line">insert into table student1</span><br><span class="line">values(1,&#x27;wangwu&#x27;),(2,&#x27;zhaoliu&#x27;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_13-30-17.png" alt="Snipaste_2023-10-09_13-30-17" style="zoom:50%;">

<h3 id="4-2-3-将查询结果写入目标路径"><a href="#4-2-3-将查询结果写入目标路径" class="headerlink" title="4.2.3 将查询结果写入目标路径"></a>4.2.3 将查询结果写入目标路径</h3><p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE [<span class="keyword">LOCAL</span>] DIRECTORY directory</span><br><span class="line">  [<span class="type">ROW</span> FORMAT row_format] [STORED <span class="keyword">AS</span> file_format] select_statement;</span><br></pre></td></tr></table></figure>

<p>（2）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 将查询结果写入目标路径(本地路径)</span><br><span class="line">insert overwrite local directory &#x27;/opt/module/datas/student111&#x27;</span><br><span class="line">ROW FORMAT SERDE &#x27;org.apache.hadoop.hive.serde2.JsonSerDe&#x27; -- 以JSON格式存入目标路径</span><br><span class="line">select id,name from student;</span><br></pre></td></tr></table></figure>

<p>再去查看’&#x2F;opt&#x2F;module&#x2F;datas&#x2F;student111’,</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/datas/student111/</span><br><span class="line">[root@hadoop102 student111]# ll</span><br><span class="line">总用量 4</span><br><span class="line">-rw-r--r--. 1 root root 1102 10月  9 13:35 000000_0</span><br><span class="line">[root@hadoop102 student111]# cat 000000_0</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1001</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student1&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1002</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student2&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1003</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student3&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1004</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student4&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1005</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student5&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1006</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student6&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1007</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student7&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1008</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student8&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1009</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student9&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1010</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student10&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1011</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student11&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1012</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student12&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1013</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student13&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1014</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student14&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1015</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student15&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1016</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student16&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1001</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student1&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1002</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student2&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1003</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student3&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1004</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student4&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1005</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student5&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1006</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student6&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1007</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student7&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1008</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student8&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1009</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student9&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1010</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student10&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1011</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student11&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1012</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student12&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1013</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student13&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1014</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student14&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1015</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student15&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="number">1016</span><span class="punctuation">,</span><span class="attr">&quot;_col1&quot;</span><span class="punctuation">:</span><span class="string">&quot;student16&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h2 id="4-3-Export-amp-Import"><a href="#4-3-Export-amp-Import" class="headerlink" title="4.3 Export&amp;Import"></a>4.3 Export&amp;Import</h2><p>Export导出语句可将表的<strong>数据和元数据信息</strong>一并导出到HDFS路径，Import可将Export导出的内容导入Hive，表的数据和元数据信息都会恢复。<strong>Export和Import可用于两个Hive实例之间的数据迁移。</strong></p>
<p>（1）语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 导出</span></span><br><span class="line">EXPORT <span class="keyword">TABLE</span> tablename <span class="keyword">TO</span> <span class="string">&#x27;export_target_path&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 导入</span></span><br><span class="line">IMPORT [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> new_or_original_tablename <span class="keyword">FROM</span> <span class="string">&#x27;source_path&#x27;</span> [LOCATION <span class="string">&#x27;import_target_path&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>（1）案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 导出</span><br><span class="line">export table default.student to &#x27;/user/hive/warehouse/export/student&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_13-45-53.png" alt="Snipaste_2023-10-09_13-45-53" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--导入</span><br><span class="line">import table student2 from &#x27;/user/hive/warehouse/export/student&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_13-48-53.png" alt="Snipaste_2023-10-09_13-48-53" style="zoom:50%;">

<p><strong>注意：因为Hadoop不支持HDFS文件中数据的更改和删除（只能一条条追加数据），所以Hive中也不支持对数据的改写和删除</strong></p>
<h1 id="第五章-查询"><a href="#第五章-查询" class="headerlink" title="第五章 查询"></a>第五章 查询</h1><h2 id="5-1-基础语法"><a href="#5-1-基础语法" class="headerlink" title="5.1 基础语法"></a>5.1 基础语法</h2><p>基本语法</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...</span><br><span class="line">  <span class="keyword">FROM</span> table_reference       <span class="comment">-- 从什么表查</span></span><br><span class="line">  [<span class="keyword">WHERE</span> where_condition]   <span class="comment">-- 过滤</span></span><br><span class="line">  [<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list]        <span class="comment">-- 分组查询</span></span><br><span class="line">   [<span class="keyword">HAVING</span> col_list]          <span class="comment">-- 分组后过滤</span></span><br><span class="line">  [<span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]        <span class="comment">-- 排序</span></span><br><span class="line">  [CLUSTER <span class="keyword">BY</span> col_list</span><br><span class="line">    <span class="operator">|</span> [DISTRIBUTE <span class="keyword">BY</span> col_list] [SORT <span class="keyword">BY</span> col_list]</span><br><span class="line">  ]</span><br><span class="line"> [LIMIT number]                <span class="comment">-- 限制输出的行数</span></span><br></pre></td></tr></table></figure>

<h2 id="5-2-基本查询（Select…from）"><a href="#5-2-基本查询（Select…from）" class="headerlink" title="5.2 基本查询（Select…from）"></a>5.2 基本查询（Select…from）</h2><h3 id="5-2-1-数据准备"><a href="#5-2-1-数据准备" class="headerlink" title="5.2.1 数据准备"></a>5.2.1 数据准备</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module/hive/datas/路径上创建dept.txt文件，并赋值如下内容：部门编号 部门名称 部门位置<span class="built_in">id</span></span></span><br><span class="line">[root@hadoop102 datas]# cd /opt/module/hive/datas/</span><br><span class="line">[root@hadoop102 datas]# vim dept.txt</span><br><span class="line">10	行政部	1700</span><br><span class="line">20	财务部	1800</span><br><span class="line">30	教学部	1900</span><br><span class="line">40	销售部	1700</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在/opt/module/hive/datas/路径上创建emp.txt文件，并赋值如下内容：员工编号 姓名 岗位    薪资  部门</span></span><br><span class="line">[root@hadoop102 datas]# vim emp.txt</span><br><span class="line">7369	张三	研发	800.00	30</span><br><span class="line">7499	李四	财务	1600.00	20</span><br><span class="line">7521	王五	行政	1250.00	10</span><br><span class="line">7566	赵六	销售	2975.00	40</span><br><span class="line">7654	侯七	研发	1250.00	30</span><br><span class="line">7698	马八	研发	2850.00	30</span><br><span class="line">7782	金九	\N	2450.0	30</span><br><span class="line">7788	银十	行政	3000.00	10</span><br><span class="line">7839	小芳	销售	5000.00	40</span><br><span class="line">7844	小明	销售	1500.00	40</span><br><span class="line">7876	小李	行政	1100.00	10</span><br><span class="line">7900	小元	讲师	950.00	30</span><br><span class="line">7902	小海	行政	3000.00	10</span><br><span class="line">7934	小红明	讲师	1300.00	30</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">-- 创建部门表</span><br><span class="line">create table if not exists dept(</span><br><span class="line">    deptno int,    -- 部门编号</span><br><span class="line">    dname string,  -- 部门名称</span><br><span class="line">    loc int        -- 部门位置</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 创建员工表</span><br><span class="line">create table if not exists emp(</span><br><span class="line">    empno int,      -- 员工编号</span><br><span class="line">    ename string,   -- 员工姓名</span><br><span class="line">    job string,     -- 员工岗位（大数据工程师、前端工程师、java工程师）</span><br><span class="line">    sal double,     -- 员工薪资</span><br><span class="line">    deptno int      -- 部门编号</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 导入数据</span><br><span class="line">load data local inpath &#x27;/opt/module/hive/datas/dept.txt&#x27; into table dept;</span><br><span class="line">load data local inpath &#x27;/opt/module/hive/datas/emp.txt&#x27; into table emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-08-51.png" alt="Snipaste_2023-10-09_15-08-51" style="zoom:50%;">

<img src="Snipaste_2023-10-09_15-09-01.png" alt="Snipaste_2023-10-09_15-09-01" style="zoom:50%;">

<h3 id="5-2-2-全表和特定列查询"><a href="#5-2-2-全表和特定列查询" class="headerlink" title="5.2.2 全表和特定列查询"></a>5.2.2 全表和特定列查询</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 全表查询</span><br><span class="line">select * from emp;</span><br><span class="line">-- 选择特定列查询</span><br><span class="line">select empno, ename from emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-11-15.png" alt="Snipaste_2023-10-09_15-11-15" style="zoom:50%;">

<p>注意：</p>
<p>（1）SQL 语言大小写不敏感。 </p>
<p>（2）SQL 可以写在一行或者多行。</p>
<p>（3）关键字不能被缩写也不能分行。</p>
<p>（4）各子句一般要分行写。</p>
<p>（5）使用缩进提高语句的可读性。</p>
<h3 id="5-2-3-列别名"><a href="#5-2-3-列别名" class="headerlink" title="5.2.3 列别名"></a>5.2.3 列别名</h3><p>1）重命名一个列</p>
<p>2）便于计算</p>
<p>3）紧跟列名，也可以在列名和别名之间加入关键字‘AS’（个人习惯，最好加上吧）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 查询名称和部门</span><br><span class="line">select ename AS name,</span><br><span class="line">       deptno dn</span><br><span class="line">from emp;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-15-04.png" alt="Snipaste_2023-10-09_15-15-04" style="zoom:50%;">

<h3 id="5-2-4-Limit语句"><a href="#5-2-4-Limit语句" class="headerlink" title="5.2.4 Limit语句"></a>5.2.4 Limit语句</h3><p>典型的查询会返回多行数据。limit子句用于限制返回的行数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from emp</span><br><span class="line">limit 5;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-17-07.png" alt="Snipaste_2023-10-09_15-17-07" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from emp</span><br><span class="line">limit 2,3;-- 表示从第2行开始，向下抓取3行（行索引从0开始）</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-17-52.png" alt="Snipaste_2023-10-09_15-17-52" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 取第一行数据，以下两种方式都行</span><br><span class="line">select * from emp</span><br><span class="line">limit 0,1;</span><br><span class="line">select * from emp</span><br><span class="line">limit 1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-21-45.png" alt="Snipaste_2023-10-09_15-21-45" style="zoom:50%;">

<h3 id="5-2-5-Where语句"><a href="#5-2-5-Where语句" class="headerlink" title="5.2.5 Where语句"></a>5.2.5 Where语句</h3><p>1）使用where子句，将不满足条件的行过滤掉</p>
<p>2）where子句紧随from子句</p>
<h3 id="5-2-6-关系运算符"><a href="#5-2-6-关系运算符" class="headerlink" title="5.2.6 关系运算符"></a>5.2.6 关系运算符</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select empno as emp_id,</span><br><span class="line">       ename as emp_name</span><br><span class="line">from emp</span><br><span class="line">where sal between 500 and 1000;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-30-43.png" alt="Snipaste_2023-10-09_15-30-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where job in (&#x27;研发&#x27;,&#x27;销售&#x27;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-32-09.png" alt="Snipaste_2023-10-09_15-32-09" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- like进行模糊匹配</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where ename like &#x27;张%&#x27;;--字符”_”表示任意单个字符，而字符”%”表示任意数量的字符</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7369,张三,研发,800,30</span><br></pre></td></tr></table></figure>

<h3 id="5-2-7-逻辑运算符"><a href="#5-2-7-逻辑运算符" class="headerlink" title="5.2.7 逻辑运算符"></a>5.2.7 逻辑运算符</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where ename like &#x27;张%&#x27; or ename like &#x27;赵%&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-40-51.png" alt="Snipaste_2023-10-09_15-40-51" style="zoom:50%;">

<h3 id="5-2-8-聚合函数"><a href="#5-2-8-聚合函数" class="headerlink" title="5.2.8 聚合函数"></a>5.2.8 聚合函数</h3><p>count(*)，表示统计所有行数，包含null值；</p>
<p>count(某列)，表示该列一共有多少行，不包含null值；</p>
<p>max()，求最大值，不包含null，除非所有值都是null；</p>
<p>min()，求最小值，不包含null，除非所有值都是null；</p>
<p>sum()，求和，不包含null。</p>
<p>avg()，求平均值，不包含null。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 求总行数</span><br><span class="line">select count(*)</span><br><span class="line">from emp;--14</span><br><span class="line"></span><br><span class="line">select count(job)</span><br><span class="line">from emp;--13,因为job列中有null值，计数时不算在内</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-49-08.png" alt="Snipaste_2023-10-09_15-49-08" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 求工资的最大值（max）</span><br><span class="line">select max(sal) as max_sal</span><br><span class="line">from emp;--5000</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 求工资的最小值（min）</span><br><span class="line">select min(sal) as min_sal</span><br><span class="line">from emp;--800</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_15-58-43.png" alt="Snipaste_2023-10-09_15-58-43" style="zoom:50%;">

<img src="Snipaste_2023-10-09_16-08-01.png" alt="Snipaste_2023-10-09_16-08-01" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 求工资的总和（sum）</span><br><span class="line">select sum(sal) as sum_sal</span><br><span class="line">from emp;--29025</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_16-11-07.png" alt="Snipaste_2023-10-09_16-11-07" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 求工资的平均值（avg）</span><br><span class="line">select avg(sal) as avg_sal</span><br><span class="line">from emp;--2073.214285714286</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_16-13-06.png" alt="Snipaste_2023-10-09_16-13-06" style="zoom:50%;">

<h2 id="5-3-分组"><a href="#5-3-分组" class="headerlink" title="5.3 分组"></a>5.3 分组</h2><h3 id="5-3-1-Group-By语句"><a href="#5-3-1-Group-By语句" class="headerlink" title="5.3.1 Group By语句"></a>5.3.1 Group By语句</h3><p>Group By语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 计算emp表每个部门的平均工资</span><br><span class="line">select deptno, avg(sal) as avg_sal</span><br><span class="line">from emp</span><br><span class="line">group by deptno;</span><br><span class="line">-- 注意：只要使用了group by ,select语句中只能选择两个字段：一个是group by分组的字段，另外一个是聚合函数字段</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_20-37-43.png" alt="Snipaste_2023-10-09_20-37-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 计算emp中每个部门中每个岗位的最高薪水</span><br><span class="line">select deptno, job, max(sal) as nax_sal</span><br><span class="line">from emp</span><br><span class="line">group by deptno, job;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_20-41-06.png" alt="Snipaste_2023-10-09_20-41-06" style="zoom:50%;">

<h3 id="5-3-2-Having语句"><a href="#5-3-2-Having语句" class="headerlink" title="5.3.2 Having语句"></a>5.3.2 Having语句</h3><p>1）having与where不同点</p>
<p>（1）where后面不能写分组聚合函数，而<strong>having后面可以使用分组聚合函数</strong>。</p>
<p>（2）<strong>having只用于group by分组统计语句</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 计算emp表中每个部门的平均工资大于等于2000的部门编号和平均工资</span><br><span class="line">-- 使用having对group by分组后的表数据进行过滤，和where效果一样，只是这里必须使用having</span><br><span class="line">select deptno, avg(sal) as avg_sal</span><br><span class="line">from emp</span><br><span class="line">group by deptno</span><br><span class="line">having avg_sal &gt;= 2000;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--等价于</span><br><span class="line">select deptno, avg_sal</span><br><span class="line">from(</span><br><span class="line">    select deptno, avg(sal) as avg_sal</span><br><span class="line">    from emp</span><br><span class="line">    group by deptno</span><br><span class="line">        ) t1</span><br><span class="line">where avg_sal &gt;= 2000;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_20-53-11.png" alt="Snipaste_2023-10-09_20-53-11" style="zoom:50%;">

<h2 id="5-4-Join语句"><a href="#5-4-Join语句" class="headerlink" title="5.4 Join语句"></a>5.4 Join语句</h2><h3 id="5-4-1-等值Join"><a href="#5-4-1-等值Join" class="headerlink" title="5.4.1 等值Join"></a>5.4.1 等值Join</h3><p>简单理解Join：即把两张表横向“合并”成一个宽表</p>
<p>Hive支持通常的sql join语句，不等值连接不常用，但Hive3.x也支持，此处不再举例。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门名称。</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_21-10-09.png" alt="Snipaste_2023-10-09_21-10-09" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 根据员工表和部门表中的部门编号相等，查询不同地区的员工数</span><br><span class="line">select d.loc, count(*)</span><br><span class="line">from emp e join dept d</span><br><span class="line">on e.deptno = d.deptno</span><br><span class="line">group by d.loc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_21-13-07.png" alt="Snipaste_2023-10-09_21-13-07" style="zoom:50%;">

<h3 id="5-4-2-内连接"><a href="#5-4-2-内连接" class="headerlink" title="5.4.2 内连接"></a>5.4.2 内连接</h3><p>内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 内连接</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-3-左外连接"><a href="#5-4-3-左外连接" class="headerlink" title="5.4.3 左外连接"></a>5.4.3 左外连接</h3><p>左外连接：join操作符左边表中符合where子句的所有记录将会被返回。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 左外连接</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e left join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-4-右外连接"><a href="#5-4-4-右外连接" class="headerlink" title="5.4.4. 右外连接"></a>5.4.4. 右外连接</h3><p>右外连接：join操作符右边表中符合where子句的所有记录将会被返回。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 右外连接</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e right join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-5-满（全）外连接"><a href="#5-4-5-满（全）外连接" class="headerlink" title="5.4.5 满（全）外连接"></a>5.4.5 满（全）外连接</h3><p>满外连接：将会返回所有表中符合where语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用null值替代。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 满外连接</span><br><span class="line">select e.empno, e.ename, d.deptno</span><br><span class="line">from emp e full join dept d</span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-6-多表连接"><a href="#5-4-6-多表连接" class="headerlink" title="5.4.6 多表连接"></a>5.4.6 多表连接</h3><p>注意：连接n个表，至少需要n-1个连接条件。例如：连接三个表，至少需要两个连接条件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">数据准备：在/opt/module/hive/datas/下：vim location.txt  部门位置<span class="built_in">id</span>  部门位置</span></span><br><span class="line">[root@hadoop102 datas]# vim location.txt</span><br><span class="line">1700	北京</span><br><span class="line">1800	上海</span><br><span class="line">1900	深圳</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 创建位置表</span><br><span class="line">create table if not exists location(</span><br><span class="line">    loc int,           -- 部门位置id</span><br><span class="line">    loc_name string   -- 部门位置</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 导入数据</span><br><span class="line">load data local inpath &#x27;/opt/module/hive/datas/location.txt&#x27; into table location;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 多表连接查询</span><br><span class="line">select e.ename, d.dname, l.loc_name</span><br><span class="line">from emp e join dept d</span><br><span class="line">on e.deptno = d.deptno</span><br><span class="line">join location l</span><br><span class="line">on d.loc = l.loc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-09_21-43-32.png" alt="Snipaste_2023-10-09_21-43-32" style="zoom:50%;">

<p>大多数情况下，Hive会对每对join连接对象启动一个MapReduce任务。本例中会首先启动一个MapReduce job对表e和表d进行连接操作，然后会再启动一个MapReduce job将第一个MapReduce job的输出和表l进行连接操作。</p>
<h3 id="5-4-7-笛卡尔积"><a href="#5-4-7-笛卡尔积" class="headerlink" title="5.4.7 笛卡尔积"></a>5.4.7 笛卡尔积</h3><p>1）笛卡尔集会在下面条件下产生（在实际生产环境中应该避免）</p>
<p>（1）省略连接条件</p>
<p>（2）连接条件无效</p>
<p>（3）所有表中的所有行互相连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 笛卡尔积写法1</span><br><span class="line">select *</span><br><span class="line">from emp, dept;</span><br><span class="line">-- 笛卡尔积写法2</span><br><span class="line">select *</span><br><span class="line">from emp join dept;</span><br><span class="line">-- 笛卡尔积写法3</span><br><span class="line">select *</span><br><span class="line">from emp join dept</span><br><span class="line">on true;</span><br></pre></td></tr></table></figure>

<h3 id="5-4-8-联合（union-amp-union-all）"><a href="#5-4-8-联合（union-amp-union-all）" class="headerlink" title="5.4.8 联合（union&amp;union all）"></a>5.4.8 联合（union&amp;union all）</h3><p>union和union all都是上下拼接sql的结果，这点是和join有区别的，join是左右关联，union和union all是上下拼接。<strong>union去重，union all不去重</strong>。</p>
<p><strong>注意：union连接的一定是select查询语句</strong></p>
<p>union和union all在上下拼接sql结果时有两个要求：</p>
<p>（1）两个sql的结果，列的个数必须相同</p>
<p>（2）两个sql的结果，上下所对应列的类型必须一致</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- 将员工表30部门的员工信息和40部门的员工信息，利用union进行拼接显示。</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where deptno = 30</span><br><span class="line">union</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where deptno = 40;</span><br><span class="line">-- 等价于</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">where deptno in (30, 40);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-17-38.png" alt="Snipaste_2023-10-10_12-17-38" style="zoom:50%;">

<h2 id="5-5-排序"><a href="#5-5-排序" class="headerlink" title="5.5 排序"></a>5.5 排序</h2><h3 id="5-5-1-全局排序（order-by）"><a href="#5-5-1-全局排序（order-by）" class="headerlink" title="5.5.1 全局排序（order by）"></a>5.5.1 全局排序（order by）</h3><p>Order By：<strong>全局排序，只有一个Reduce</strong>。asc（ascend）：升序（默认）；desc（descend）：降序</p>
<p><strong>Order By子句在select语句的结尾</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- 查询员工信息按工资升序排列</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">order by sal;</span><br><span class="line">--查询员工信息按工资降序排列</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">order by sal desc;</span><br><span class="line">-- 按照别名排序：按照员工薪水的2倍排序</span><br><span class="line">select ename, sal *2 as two_sal</span><br><span class="line">from emp</span><br><span class="line">order by two_sal;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-32-16.png" alt="Snipaste_2023-10-10_12-32-16" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--多个列排序：按照部门和工资升序排序。</span><br><span class="line">select ename, deptno, sal</span><br><span class="line">from emp</span><br><span class="line">order by deptno, sal;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-42-52.png" alt="Snipaste_2023-10-10_12-42-52" style="zoom: 33%;">

<p>在生产实践中，order by一般不单独使用，因为单独使用最终会汇总到一个大的reduce中进行全局排序，效率低下也容易出问题。所以往往将<strong>order by结合limit一起使用实现TOPN的效果</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--与limit结合使用</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">order by sal desc</span><br><span class="line">limit 5;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-37-57.png" alt="Snipaste_2023-10-10_12-37-57" style="zoom:50%;">

<hr>
<p>以下三个by是hive中特有的，但在实际的工作当中，很少用</p>
<h3 id="5-5-2-每个Reduce内部排序（sort-by）"><a href="#5-5-2-每个Reduce内部排序（sort-by）" class="headerlink" title="5.5.2 每个Reduce内部排序（sort by）"></a>5.5.2 每个Reduce内部排序（sort by）</h3><p>Sort By：对于大规模的数据集order by的效率非常低。在很多情况下，并不需要全局排序，此时可以使用****Sort by****。</p>
<p>Sort by为每个reduce产生一个排序文件。每个Reduce内部进行排序，对全局结果集来说不是排序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--测试sort by</span><br><span class="line">--设置reduce个数</span><br><span class="line">set mapreduce.job.reduces=3;</span><br><span class="line">--根据部门编号降序查看员工信息</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">sort by deptno desc ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_12-57-18.png" alt="Snipaste_2023-10-10_12-57-18" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--将查询结果导入到文件中（按照部门编号降序排序）</span><br><span class="line">insert overwrite local directory &#x27;/opt/module/hive/datas/sortby-result&#x27;</span><br><span class="line">select * from emp sort by deptno desc;</span><br></pre></td></tr></table></figure>

<p>查看目标路径下的文件：有三个文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# cd /opt/module/hive/datas/sortby-result/</span><br><span class="line">[root@hadoop102 sortby-result]# ll</span><br><span class="line">总用量 12</span><br><span class="line">-rw-r--r--. 1 root root 170 10月 10 12:58 000000_0</span><br><span class="line">-rw-r--r--. 1 root root 176 10月 10 12:58 000001_0</span><br><span class="line">-rw-r--r--. 1 root root  57 10月 10 12:58 000002_0</span><br><span class="line">[root@hadoop102 sortby-result]# cat 000000_0</span><br><span class="line">7844小明销售1500.040</span><br><span class="line">7839小芳销售5000.040</span><br><span class="line">7782金九\N2450.030</span><br><span class="line">7698马八研发2850.030</span><br><span class="line">7654侯七研发1250.030</span><br><span class="line">7788银十行政3000.010</span><br><span class="line">[root@hadoop102 sortby-result]# cat 000001_0</span><br><span class="line">7566赵六销售2975.040</span><br><span class="line">7934小红明讲师1300.030</span><br><span class="line">7900小元讲师950.030</span><br><span class="line">7499李四财务1600.020</span><br><span class="line">7876小李行政1100.010</span><br><span class="line">7521王五行政1250.010</span><br><span class="line">[root@hadoop102 sortby-result]# cat 000002_0</span><br><span class="line">7369张三研发800.030</span><br><span class="line">7902小海行政3000.010</span><br></pre></td></tr></table></figure>

<h3 id="5-5-3-分区（distribute-by）"><a href="#5-5-3-分区（distribute-by）" class="headerlink" title="5.5.3 分区（distribute by）"></a>5.5.3 分区（distribute by）</h3><p>Distribute By：在有些情况下，我们需要控制某个特定行应该到哪个Reducer，通常是为了进行后续的聚集操作。****distribute by*<em><strong>子句可以做这件事。</strong>distribute by</em>*类似MapReduce中partition（自定义分区），进行分区，结合sort by使用。 </p>
<p>对于distribute by进行测试，一定要分配多reduce进行处理，否则无法看到distribute by的效果。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--测试distribute by</span><br><span class="line">--先按照deptno分区，再按照sal排序</span><br><span class="line">set mapreduce.job.reduces=4;</span><br><span class="line">insert overwrite local directory</span><br><span class="line">&#x27;/opt/module/hive/datas/distribute-result&#x27;</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">distribute by deptno</span><br><span class="line">sort by sal desc;</span><br></pre></td></tr></table></figure>

<p>查看目标路径下的文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# cd /opt/module/hive/datas/distribute-result/</span><br><span class="line">[root@hadoop102 distribute-result]# ll</span><br><span class="line">总用量 12</span><br><span class="line">-rw-r--r--. 1 root root 171 10月 10 13:09 000000_0</span><br><span class="line">-rw-r--r--. 1 root root 203 10月 10 13:09 000001_0</span><br><span class="line">-rw-r--r--. 1 root root  29 10月 10 13:09 000002_0</span><br><span class="line">[root@hadoop102 distribute-result]# cat 000000_0</span><br><span class="line">7698马八研发2850.030</span><br><span class="line">7782金九\N2450.030</span><br><span class="line">7934小红明讲师1300.030</span><br><span class="line">7654侯七研发1250.030</span><br><span class="line">7900小元讲师950.030</span><br><span class="line">7369张三研发800.030</span><br><span class="line">[root@hadoop102 distribute-result]# cat 000001_0</span><br><span class="line">7839小芳销售5000.040</span><br><span class="line">7788银十行政3000.010</span><br><span class="line">7902小海行政3000.010</span><br><span class="line">7566赵六销售2975.040</span><br><span class="line">7844小明销售1500.040</span><br><span class="line">7521王五行政1250.010</span><br><span class="line">7876小李行政1100.010</span><br><span class="line">[root@hadoop102 distribute-result]# cat 000002_0</span><br><span class="line">7499李四财务1600.020</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p>distribute by的分区规则是根据分区字段的hash码与reduce的个数进行相除后，余数相同的分到一个区。</p>
<p>Hive要求****distribute by****语句要写在sort by语句之前。</p>
<p>演示完以后mapreduce.job.reduces的值要设置回-1，否则下面分区or分桶表load跑MapReduce的时候会报错。</p>
<h3 id="5-5-4-分区排序（cluster-by）"><a href="#5-5-4-分区排序（cluster-by）" class="headerlink" title="5.5.4 分区排序（cluster by）"></a>5.5.4 分区排序（cluster by）</h3><p>当distribute by和sort by字段相同时，可以使用cluster by方式。</p>
<p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为asc或者desc。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">--测试cluster by</span><br><span class="line">insert overwrite local directory</span><br><span class="line">&#x27;/opt/module/hive/datas/cluster-result&#x27;</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">cluster by deptno;</span><br><span class="line">-- 等价于</span><br><span class="line">insert overwrite local directory</span><br><span class="line">&#x27;/opt/module/hive/datas/cluster-result&#x27;</span><br><span class="line">select *</span><br><span class="line">from emp</span><br><span class="line">distribute by deptno</span><br><span class="line">sort by deptno;</span><br></pre></td></tr></table></figure>

<p>查看文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 distribute-result]# cd /opt/module/hive/datas/cluster-result/</span><br><span class="line">[root@hadoop102 cluster-result]# ll</span><br><span class="line">总用量 12</span><br><span class="line">-rw-r--r--. 1 root root 171 10月 10 13:21 000000_0</span><br><span class="line">-rw-r--r--. 1 root root 203 10月 10 13:21 000001_0</span><br><span class="line">-rw-r--r--. 1 root root  29 10月 10 13:21 000002_0</span><br><span class="line">[root@hadoop102 cluster-result]# cat 000000_0</span><br><span class="line">7934小红明讲师1300.030</span><br><span class="line">7900小元讲师950.030</span><br><span class="line">7782金九\N2450.030</span><br><span class="line">7698马八研发2850.030</span><br><span class="line">7654侯七研发1250.030</span><br><span class="line">7369张三研发800.030</span><br><span class="line">[root@hadoop102 cluster-result]# cat 000001_0</span><br><span class="line">7788银十行政3000.010</span><br><span class="line">7521王五行政1250.010</span><br><span class="line">7902小海行政3000.010</span><br><span class="line">7876小李行政1100.010</span><br><span class="line">7566赵六销售2975.040</span><br><span class="line">7844小明销售1500.040</span><br><span class="line">7839小芳销售5000.040</span><br><span class="line">[root@hadoop102 cluster-result]# cat 000002_0</span><br><span class="line">7499李四财务1600.020</span><br></pre></td></tr></table></figure>

<h1 id="第六章-综合案例练习（初级）"><a href="#第六章-综合案例练习（初级）" class="headerlink" title="第六章 综合案例练习（初级）"></a>第六章 综合案例练习（初级）</h1><p>需要的表一览：</p>
<p>student_info:</p>
<img src="Snipaste_2023-10-10_13-50-15.png" alt="Snipaste_2023-10-10_13-50-15" style="zoom:50%;">

<p>course_info:</p>
<img src="Snipaste_2023-10-10_13-51-08.png" alt="Snipaste_2023-10-10_13-51-08" style="zoom:50%;">

<p>teacher_info:</p>
<img src="Snipaste_2023-10-10_13-51-59.png" alt="Snipaste_2023-10-10_13-51-59" style="zoom:50%;">

<p>score_info:</p>
<img src="Snipaste_2023-10-10_13-52-37.png" alt="Snipaste_2023-10-10_13-52-37" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">--1.查询姓名中带“冰”的学生名单</span><br><span class="line">select *</span><br><span class="line">from student_info</span><br><span class="line">where stu_name like &quot;%冰%&quot;;</span><br><span class="line">--2.查询姓“王”的老师的个数</span><br><span class="line">select count(*) as wang_count</span><br><span class="line">from teacher_info</span><br><span class="line">where tea_name like &quot;%王%&quot;;</span><br><span class="line">--3.检索课程编号为“04”且分数小于60的学生的课程信息，结果按分数降序排列</span><br><span class="line">select *</span><br><span class="line">from score_info</span><br><span class="line">where course_id = &#x27;04&#x27; and score &lt; 60</span><br><span class="line">order by score desc ;</span><br><span class="line">--4.查询数学成绩不及格的学生和其对应的成绩，按照学号升序排序</span><br><span class="line">select s1.stu_id, s1.stu_name, s2.score</span><br><span class="line">from student_info s1 join score_info s2</span><br><span class="line">on s1.stu_id = s2.stu_id</span><br><span class="line">join course_info c</span><br><span class="line">on c.course_id = s2.course_id</span><br><span class="line">where c.course_name = &#x27;数学&#x27; and s2.score &lt; 60</span><br><span class="line">order by s1.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_14-52-31.png" alt="Snipaste_2023-10-10_14-52-31" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--5. 查询编号为“02”的课程的总成绩</span><br><span class="line">select course_id, sum(score) as score_sum</span><br><span class="line">from score_info</span><br><span class="line">group by course_id</span><br><span class="line">having course_id = &#x27;02&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_14-53-15.png" alt="Snipaste_2023-10-10_14-53-15" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--6. 查询参加考试的学生个数(思路：对成绩表中的学号做去重并count)</span><br><span class="line">select count(distinct stu_id) as stu_num</span><br><span class="line">from score_info;--19</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--7. 查询各科成绩最高和最低的分，以如下的形式显示：课程号，最高分，最低分</span><br><span class="line">select course_id, max(score) as max_score, min(score) as min_score</span><br><span class="line">from score_info</span><br><span class="line">group by course_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_14-58-41.png" alt="Snipaste_2023-10-10_14-58-41" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--8. 查询每门课程有多少学生参加了考试（有考试成绩）</span><br><span class="line">select course_id, count(stu_id) as stu_num</span><br><span class="line">from score_info</span><br><span class="line">group by course_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-01-16.png" alt="Snipaste_2023-10-10_15-01-16" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--9. 查询男生、女生人数</span><br><span class="line">select sex, count(*) as count</span><br><span class="line">from student_info</span><br><span class="line">group by sex;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-16-09.png" alt="Snipaste_2023-10-10_15-16-09" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--10.查询平均成绩大于60分的学生的学号和平均成绩</span><br><span class="line">select stu_id, avg(score) as avg_score</span><br><span class="line">from  score_info</span><br><span class="line">group by stu_id</span><br><span class="line">having avg_score &gt; 60;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-21-47.png" alt="Snipaste_2023-10-10_15-21-47" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--11.查询至少选修四门课程的学生学号</span><br><span class="line">select stu_id, count(course_id) as course_num</span><br><span class="line">from score_info</span><br><span class="line">group by stu_id</span><br><span class="line">having course_num &gt;=4;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-25-15.png" alt="Snipaste_2023-10-10_15-25-15" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--12.查询同姓（假设每个学生姓名的第一个字为姓）的学生名单并统计同姓人数大于等于2的姓</span><br><span class="line">select t1.first_name, count(*) as count_first_name</span><br><span class="line">from(</span><br><span class="line">    select stu_id, stu_name, substr(stu_name,0,1) as first_name</span><br><span class="line">    from student_info</span><br><span class="line">        ) t1</span><br><span class="line">group by t1.first_name</span><br><span class="line">having count_first_name &gt;= 2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-31-30.png" alt="Snipaste_2023-10-10_15-31-30" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--13.查询每门课程的平均成绩，结果按平均成绩升序排序，平均成绩相同时，按课程号降序排列</span><br><span class="line">select course_id, avg(score) as avg_score</span><br><span class="line">from score_info</span><br><span class="line">group by course_id</span><br><span class="line">order by avg_score, course_id desc ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-34-04.png" alt="Snipaste_2023-10-10_15-34-04" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--14.统计参加考试人数大于等于15的学科</span><br><span class="line">select course_id, count(stu_id) as exam_num</span><br><span class="line">from score_info</span><br><span class="line">group by course_id</span><br><span class="line">having exam_num &gt;= 15;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-36-30.png" alt="Snipaste_2023-10-10_15-36-30" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--15.查询每个学生的总成绩并按照总成绩降序排序</span><br><span class="line">select stu_id, sum(score) as sum_score</span><br><span class="line">from score_info</span><br><span class="line">group by stu_id</span><br><span class="line">order by sum_score desc ;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-10_15-38-51.png" alt="Snipaste_2023-10-10_15-38-51" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">--16.按照如下格式显示学生的语文、数学、英语三科成绩，没有成绩的输出为0，按照学生的有效平均成绩降序显示</span><br><span class="line">--学生id 语文 数学 英语 有效课程数 有效平均成绩</span><br><span class="line">select</span><br><span class="line">       t4.stu_id as `学生id`,</span><br><span class="line">       nvl(t1.score,0) as `语文`,</span><br><span class="line">       nvl(t2.score,0) as `数学`,</span><br><span class="line">       nvl(t3.score,0) as `英语`,</span><br><span class="line">       `有效课程数`,</span><br><span class="line">       `平均成绩`</span><br><span class="line">from (</span><br><span class="line">    select stu_id, score</span><br><span class="line">    from score_info</span><br><span class="line">    where course_id = &#x27;01&#x27;--查询所有学生的语文成绩</span><br><span class="line">         ) t1</span><br><span class="line">    full join (</span><br><span class="line">        select stu_id, score</span><br><span class="line">        from score_info</span><br><span class="line">        where course_id = &#x27;02&#x27;--查询所有学生的数学成绩</span><br><span class="line">    ) t2 on t1.stu_id = t2.stu_id</span><br><span class="line">    full join (</span><br><span class="line">        select stu_id, score</span><br><span class="line">        from score_info</span><br><span class="line">        where course_id = &#x27;03&#x27;--查询所有学生的英语成绩</span><br><span class="line">    ) t3 on nvl(t1.stu_id, t2.stu_id) = t3.stu_id</span><br><span class="line">    full join (</span><br><span class="line">        select stu_id, count(*) as `有效课程数`, avg(score) as `平均成绩`</span><br><span class="line">        from score_info</span><br><span class="line">        group by stu_id</span><br><span class="line">    ) t4 on coalesce(t1.stu_id, t2.stu_id, t3.stu_id) = t4.stu_id</span><br><span class="line">order by `平均成绩` desc;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- 第二种解法：sum(if()):有条件的聚合</span><br><span class="line">select stu_id                              as `学生id`,</span><br><span class="line">       sum(if(course_id = &quot;01&quot;, score, 0)) as `语文`,</span><br><span class="line">       sum(if(course_id = &quot;02&quot;, score, 0)) as `数学`,</span><br><span class="line">       sum(if(course_id = &quot;03&quot;, score, 0)) as `英语`,</span><br><span class="line">       count(*)                            as `有效课程数`,</span><br><span class="line">       avg(score)                          as `有效平均成绩`</span><br><span class="line">from score_info</span><br><span class="line">group by stu_id</span><br><span class="line">order by `有效平均成绩` desc;</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<p>nvl(expr1, expr2)：若expr1为Null，则返回expr2，否则返回expr1</p>
<p>COALESCE(a1,a2,……,an)：返回a1,a2,……,an中遇到的第一个不为NULL的值</p>
<img src="Snipaste_2023-10-10_16-17-55.png" alt="Snipaste_2023-10-10_16-17-55" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 3.4.3 查询一共参加三门课程且其中一门为语文课程的学生的id和姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id, sum(if(course_id = &#x27;01&#x27;, 1, 0)) as flag</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having count(*) = 3</span><br><span class="line">            and flag = 1</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on t1.stu_id = s.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_21-46-10.png" alt="Snipaste_2023-10-17_21-46-10" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">-- 4.1.1 查询所有课程成绩均小于60分的学生的学号、姓名</span><br><span class="line">-- 思路1：所有课程分数小于60，证明其所有成绩的最高分也小于60，我们只需要把每个学生的成绩最高分筛选出来，再选择小于60的即可</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id,</span><br><span class="line">                max(score) as max_score</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having max_score &lt; 60</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s</span><br><span class="line">              on s.stu_id = t1.stu_id;</span><br><span class="line">              </span><br><span class="line">-- 思路2：所有课程分数均小于60，可以使用sum(if())有条件聚合，只有某个学生的成绩大于等于60就设置为flag为1，否则为0，最后相加flag，</span><br><span class="line">-- 如果flag为0，就说明，所有课程成绩都小于60分</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id, sum(if(score &gt;= 60, 1, 0)) as flag</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having flag = 0</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on s.stu_id = t1.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_21-52-37.png" alt="Snipaste_2023-10-17_21-52-37" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 4.1.2 查询没有学全所有课的学生的学号、姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id, collect_list(course_id) as per_course_list</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having size(per_course_list) &lt; 5</span><br><span class="line">     ) t1</span><br><span class="line">join student_info s on s.stu_id = t1.stu_id</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-06-44.png" alt="Snipaste_2023-10-18_11-06-44" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 4.1.3 查询出只选修了三门课程的全部学生的学号和姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id, collect_list(course_id) as per_course_list</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having size(per_course_list) = 3</span><br><span class="line">     ) t1</span><br><span class="line">join student_info s on s.stu_id = t1.stu_id</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-08-58.png" alt="Snipaste_2023-10-18_11-08-58" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.1 查询有两门及以上的课程不及格的同学的学号及其平均成绩</span><br><span class="line">select stu_id, avg_score</span><br><span class="line">from (</span><br><span class="line">         select stu_id, sum(if(score &lt; 60, 1, 0)) as not_hege_course_ct, avg(score) as avg_score</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having not_hege_course_ct &gt;= 2</span><br><span class="line">     ) t1</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-18-24.png" alt="Snipaste_2023-10-18_11-18-24" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.2 查询所有学生的学号、姓名、选课数、总成绩</span><br><span class="line">select s.stu_id,</span><br><span class="line">       s.stu_name,</span><br><span class="line">       count(sc.course_id) as count_course,</span><br><span class="line">       sum(sc.score)       as sum_score</span><br><span class="line">from student_info s</span><br><span class="line">         left join score_info sc on s.stu_id = sc.stu_id</span><br><span class="line">group by s.stu_id, s.stu_name;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-23-24.png" alt="Snipaste_2023-10-18_11-23-24" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.3 查询平均成绩大于85的所有学生的学号、姓名和平均成绩</span><br><span class="line">select s.stu_id, stu_name, avg_score</span><br><span class="line">from (</span><br><span class="line">         select stu_id, avg(score) avg_score</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having avg_score &gt; 85</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on s.stu_id = t1.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-28-32.png" alt="Snipaste_2023-10-18_11-28-32" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.5 查询出每门课程的及格人数和不及格人数</span><br><span class="line">select c.course_id, course_name, `及格人数`, `不及格人数`</span><br><span class="line">from (</span><br><span class="line">         select course_id,</span><br><span class="line">                sum(if(score &gt;= 60, 1, 0)) as `及格人数`,</span><br><span class="line">                sum(if(score &lt; 60, 1, 0))  as `不及格人数`</span><br><span class="line">         from score_info</span><br><span class="line">         group by course_id</span><br><span class="line">     ) t1</span><br><span class="line">         join course_info c on c.course_id = t1.course_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-39-08.png" alt="Snipaste_2023-10-18_11-39-08" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 5.1.6 查询课程编号为03且课程成绩在80分以上的学生的学号和姓名及课程信息</span><br><span class="line">select s.stu_id, stu_name, score, course_id</span><br><span class="line">from (</span><br><span class="line">         select stu_id, score, course_id</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id = &#x27;03&#x27;</span><br><span class="line">           and score &gt; 80</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on t1.stu_id = s.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-45-12.png" alt="Snipaste_2023-10-18_11-45-12" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.1 课程编号为&quot;01&quot;且课程分数小于60，按分数降序排列的学生信息</span><br><span class="line">select s.stu_id, stu_name, birthday, sex, score</span><br><span class="line">from (</span><br><span class="line">         select stu_id, course_id, score</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id = &#x27;01&#x27;</span><br><span class="line">           and score &lt; 60</span><br><span class="line">     ) t1</span><br><span class="line">join student_info s on s.stu_id = t1.stu_id</span><br><span class="line">order by score desc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_11-49-39.png" alt="Snipaste_2023-10-18_11-49-39" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.2 查询所有课程成绩在70分以上的学生的姓名、课程名称和分数，按分数升序排列</span><br><span class="line">select s.stu_id, stu_name, course_name, score</span><br><span class="line">from (</span><br><span class="line">         select stu_id,</span><br><span class="line">                min(score) min_score</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having min_score &gt;= 70</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on s.stu_id = t1.stu_id</span><br><span class="line">         left join score_info s1 on s.stu_id = s1.stu_id</span><br><span class="line">         left join course_info c on c.course_id = s1.course_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_12-01-19.png" alt="Snipaste_2023-10-18_12-01-19" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.4 查询课程编号为“01”的课程比“02”的课程成绩高的所有学生的学号</span><br><span class="line">select t1.stu_id</span><br><span class="line">from (</span><br><span class="line">         select stu_id, course_id, score</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id = &#x27;01&#x27;</span><br><span class="line">     ) t1</span><br><span class="line">         join</span><br><span class="line">     (</span><br><span class="line">         select stu_id, course_id, score</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id = &#x27;02&#x27;</span><br><span class="line">     ) t2 on t1.stu_id = t2.stu_id</span><br><span class="line">where t1.score &gt; t2.score;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_14-50-08.png" alt="Snipaste_2023-10-18_14-50-08" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.5 查询学过编号为“01”的课程并且也学过编号为“02”的课程的学生的学号、姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id,</span><br><span class="line">                sum(if(course_id = &#x27;01&#x27;, 1, 0)) as c_id_01,</span><br><span class="line">                sum(if(course_id = &#x27;02&#x27;, 1, 0)) as c_id_02</span><br><span class="line">         from score_info</span><br><span class="line">         group by stu_id</span><br><span class="line">         having c_id_01 = 1</span><br><span class="line">            and c_id_02 = 1</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on s.stu_id = t1.stu_id</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_14-58-43.png" alt="Snipaste_2023-10-18_14-58-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.6 查询学过“李体音”老师所教的所有课的同学的学号、姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id in (</span><br><span class="line">             select course_id</span><br><span class="line">             from course_info c</span><br><span class="line">                      join teacher_info t</span><br><span class="line">                           on c.tea_id = t.tea_id</span><br><span class="line">             where tea_name = &#x27;李体音&#x27;</span><br><span class="line">         )</span><br><span class="line">         group by stu_id</span><br><span class="line">         having count(*) = 2</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on t1.stu_id = s.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-07-49.png" alt="Snipaste_2023-10-18_15-07-49" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">-- 5.2.7 [课堂讲解]查询学过“李体音”老师所讲授的任意一门课程的学生的学号、姓名</span><br><span class="line">select s.stu_id, stu_name</span><br><span class="line">from (</span><br><span class="line">         select stu_id</span><br><span class="line">         from score_info</span><br><span class="line">         where course_id in (</span><br><span class="line">             select course_id</span><br><span class="line">             from course_info c</span><br><span class="line">                      join teacher_info t</span><br><span class="line">                           on c.tea_id = t.tea_id</span><br><span class="line">             where tea_name = &#x27;李体音&#x27;</span><br><span class="line">         )</span><br><span class="line">         group by stu_id</span><br><span class="line">     ) t1</span><br><span class="line">         join student_info s on t1.stu_id = s.stu_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-34-02.png" alt="Snipaste_2023-10-18_15-34-02" style="zoom:50%;">





<h1 id="第七章-函数"><a href="#第七章-函数" class="headerlink" title="第七章 函数"></a>第七章 函数</h1><p>Hive提供了大量的内置函数，按照其特点可大致分为如下几类：单行函数、聚合函数、炸裂函数、窗口函数。</p>
<h2 id="7-1-单行函数"><a href="#7-1-单行函数" class="headerlink" title="7.1 单行函数"></a>7.1 单行函数</h2><p>单行函数的特点是一进一出，即输入一行，输出一行。</p>
<p>单行函数按照功能可分为如下几类: 日期函数、字符串函数、集合函数、数学函数、流程控制函数等。</p>
<h3 id="7-1-1-算术运算函数"><a href="#7-1-1-算术运算函数" class="headerlink" title="7.1.1 算术运算函数"></a>7.1.1 算术运算函数</h3><img src="Snipaste_2023-10-10_20-49-10.png" alt="Snipaste_2023-10-10_20-49-10" style="zoom:50%;">

<h3 id="7-1-2-数值函数"><a href="#7-1-2-数值函数" class="headerlink" title="7.1.2 数值函数"></a>7.1.2 数值函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--round：四舍五入</span><br><span class="line">select round(3,3);</span><br><span class="line">--3</span><br><span class="line">-- ceil：向上取整</span><br><span class="line">select ceil(3.1);</span><br><span class="line">--4</span><br><span class="line">-- floor：向下取整</span><br><span class="line">select floor(4.8);</span><br><span class="line">--4</span><br></pre></td></tr></table></figure>

<h3 id="7-1-3-字符串函数"><a href="#7-1-3-字符串函数" class="headerlink" title="7.1.3 字符串函数"></a>7.1.3 字符串函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 1. substring：截取字符串</span><br><span class="line">-- 获取第二个字符以后的所有字符（正向索引从1开始,负向索引从-1开始）</span><br><span class="line">select substring(&quot;atguigu&quot;,2);</span><br><span class="line">--tguigu</span><br><span class="line">-- 获取倒数第三个字符以后的所有字符</span><br><span class="line">select substring(&quot;atguigu&quot;,-3);</span><br><span class="line">--igu</span><br><span class="line">-- 从第3个字符开始，向后获取2个字符</span><br><span class="line">select substring(&quot;atguigu&quot;,3,2);</span><br><span class="line">--gu</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 2.replace ：替换</span><br><span class="line">-- replace(string A, string B, string C)--将字符串A中的子字符串B替换为C。</span><br><span class="line">select replace(&#x27;atguigu&#x27;, &#x27;a&#x27;, &#x27;A&#x27;);</span><br><span class="line">--Atguigu</span><br><span class="line">select replace(&#x27;atguigu&#x27;, &#x27;gu&#x27;, &#x27;GU&#x27;); --全局替换</span><br><span class="line">--atGUiGU</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">--3.regexp_replace：正则替换</span><br><span class="line">/**</span><br><span class="line">    语法：regexp_replace(string A, string B, string C)</span><br><span class="line">    返回值：string</span><br><span class="line">    说明：将字符串A中的符合java正则表达式B的部分替换为C。注意，在有些情况下要使用转义字符。</span><br><span class="line"> */</span><br><span class="line">select regexp_replace(&#x27;100-200&#x27;, &#x27;(\\d+)&#x27;, &#x27;num&#x27;);</span><br><span class="line">--num-num</span><br><span class="line">select regexp_replace(&#x27;abc-1022-def&#x27;, &#x27;[0-9]+&#x27;, &#x27;*&#x27;);</span><br><span class="line">--abc-*-def</span><br><span class="line">select regexp_replace(&#x27;abc-1022-def&#x27;, &#x27;[0-9]&#x27;, &#x27;*&#x27;);</span><br><span class="line">--abc-****-def</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--4.regexp：正则匹配</span><br><span class="line">/**</span><br><span class="line">    语法：字符串 regexp 正则表达式</span><br><span class="line">    返回值：boolean</span><br><span class="line">    说明：若字符串符合正则表达式，则返回true，否则返回false。</span><br><span class="line"> */</span><br><span class="line">select &#x27;string&#x27; regexp &#x27;.*tr.*&#x27;;</span><br><span class="line">--true</span><br><span class="line">select &#x27;dfsaaaa&#x27; regexp &#x27;dfsa+&#x27;;</span><br><span class="line">-- true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--5. repeat：重复字符串</span><br><span class="line">/**</span><br><span class="line">    语法：repeat(string A, int n)</span><br><span class="line">    返回值：string</span><br><span class="line">    说明：将字符串A重复n遍。</span><br><span class="line"> */</span><br><span class="line">select repeat(&#x27;123&#x27;, 3);</span><br><span class="line">-- 123123123</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--6. split ：字符串切割</span><br><span class="line">/**</span><br><span class="line">    语法：split(string str, string pat)</span><br><span class="line">    返回值：array</span><br><span class="line">    说明：按照正则表达式pat匹配到的内容分割str，分割后的字符串，以数组的形式返回。</span><br><span class="line"> */</span><br><span class="line">select split(&#x27;a-b-c-d&#x27;,&#x27;-&#x27;);</span><br><span class="line">-- [&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]</span><br><span class="line">select split(&#x27;192.168.10.102&#x27;, &#x27;\\.&#x27;);</span><br><span class="line">-- [&quot;192&quot;,&quot;168&quot;,&quot;10&quot;,&quot;102&quot;]</span><br><span class="line"></span><br><span class="line">--7. nvl ：替换null值</span><br><span class="line">/**</span><br><span class="line">  语法：nvl(A,B)</span><br><span class="line">  说明：若A的值不为null，则返回A，否则返回B</span><br><span class="line"> */</span><br><span class="line">select nvl(null,1);</span><br><span class="line">--1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--8. concat ：拼接字符串</span><br><span class="line">/**</span><br><span class="line">语法：concat(string A, string B, string C, ……)</span><br><span class="line">返回：string</span><br><span class="line">说明：将A,B,C……等字符拼接为一个字符串</span><br><span class="line"> */</span><br><span class="line">select concat(&#x27;beijing&#x27;,&#x27;-&#x27;,&#x27;shanghai&#x27;,&#x27;-&#x27;,&#x27;shenzhen&#x27;);</span><br><span class="line">-- beijing-shanghai-shenzhen</span><br><span class="line">select &#x27;beijing&#x27;||&#x27;-&#x27;||&#x27;shanghai&#x27;||&#x27;-&#x27;||&#x27;shenzhen&#x27;;</span><br><span class="line">-- beijing-shanghai-shenzhen</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--9.concat_ws：以指定分隔符拼接字符串或者字符串数组</span><br><span class="line">/**</span><br><span class="line">语法：concat_ws(string A, string…| array(string))</span><br><span class="line">返回值：string</span><br><span class="line">说明：使用分隔符A拼接多个字符串，或者一个数组的所有元素。</span><br><span class="line"> */</span><br><span class="line">select concat_ws(&#x27;-&#x27;,&#x27;beijing&#x27;,&#x27;shanghai&#x27;,&#x27;shenzhen&#x27;);</span><br><span class="line">-- beijing-shanghai-shenzhen</span><br><span class="line">select concat_ws(&#x27;-&#x27;,array(&#x27;beijing&#x27;,&#x27;shenzhen&#x27;,&#x27;shanghai&#x27;));</span><br><span class="line">--beijing-shenzhen-shanghai</span><br></pre></td></tr></table></figure>

<p><strong>关于JSON字符串的说明</strong></p>
<p>JSON通常用于Web项目前后端的交互上，做大数据一般不会涉及这个前后端的交互。我们的数据通常来源于业务系统，采集到的数据通常是JSON格式的字符串。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;1001&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">10</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;1001&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">10</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;1001&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">10</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="string">&quot;1001&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;zhangsan&quot;</span><span class="punctuation">,</span></span><br><span class="line">    	<span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">10</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--10.get_json_object：解析json字符串</span><br><span class="line">/**</span><br><span class="line">语法：get_json_object(string json_string, string path)</span><br><span class="line">返回值：string</span><br><span class="line">说明：解析json的字符串json_string，返回path指定的内容。如果输入的json字符串无效，那么返回NULL。</span><br><span class="line"> */</span><br><span class="line">--获取json数组里面的json具体数据，其中$指代的就是传入的Json字符串本身</span><br><span class="line">select get_json_object(&#x27;[&#123;&quot;name&quot;:&quot;大海海&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;25&quot;&#125;,&#123;&quot;name&quot;:&quot;小宋宋&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;47&quot;&#125;]&#x27;,&#x27;$.[0]&#x27;);</span><br><span class="line">--&#123;&quot;name&quot;:&quot;大海海&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;25&quot;&#125;</span><br><span class="line">select get_json_object(&#x27;[&#123;&quot;name&quot;:&quot;大海海&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;25&quot;&#125;,&#123;&quot;name&quot;:&quot;小宋宋&quot;,&quot;sex&quot;:&quot;男&quot;,&quot;age&quot;:&quot;47&quot;&#125;]&#x27;,&#x27;$.[0].name&#x27;);</span><br><span class="line">--大海海</span><br></pre></td></tr></table></figure>

<h3 id="7-1-4-日期函数"><a href="#7-1-4-日期函数" class="headerlink" title="7.1.4 日期函数"></a>7.1.4 日期函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">--1.unix_timestamp：返回当前或指定时间的时间戳</span><br><span class="line">-- 说明：-前面是日期后面是指，日期传进来的具体格式</span><br><span class="line">select unix_timestamp();--如果不传参数，默认返回当前日期的时间戳</span><br><span class="line">-- 1697520215</span><br><span class="line">select unix_timestamp(&#x27;2022/08/08 08-08-08&#x27;,&#x27;yyyy/MM/dd HH-mm-ss&#x27;); --获取指定时间的时间戳</span><br><span class="line">-- 1659946088</span><br><span class="line"></span><br><span class="line">-- 2.from_unixtime：转化UNIX时间戳（从 1970-01-01 00:00:00 UTC 到指定时间的秒数）到当前时区的时间格式</span><br><span class="line">select from_unixtime(1659946088);</span><br><span class="line">-- 2022-08-08 08:08:08</span><br><span class="line">select from_utc_timestamp(cast(1697519302 as BIGINT)*1000, &#x27;GMT+8&#x27;);</span><br><span class="line">-- 2023-10-17 13:08:22.000000000</span><br><span class="line"></span><br><span class="line">-- 3.current_date：当前日期</span><br><span class="line">select current_date;--2023-10-17</span><br><span class="line"></span><br><span class="line">-- 4.current_timestamp：当前的日期加时间，并且精确的毫秒</span><br><span class="line">select current_timestamp;--2023-10-17 13:28:22.389000000</span><br><span class="line"></span><br><span class="line">-- 5.month：获取日期中的月</span><br><span class="line">/*</span><br><span class="line"> 语法：month (string date)</span><br><span class="line"> 返回值：int</span><br><span class="line"> */</span><br><span class="line">select month(&quot;2022-09-08 08:09:45&quot;);  --9</span><br><span class="line"></span><br><span class="line">--6.day：获取日期中的日</span><br><span class="line">/*</span><br><span class="line"> 语法：day (string date)</span><br><span class="line"> 返回值：int</span><br><span class="line"> */</span><br><span class="line">select day(&quot;2022-09-08 08:09:45&quot;);  --8</span><br><span class="line"></span><br><span class="line">--7.hour：获取日期中的小时</span><br><span class="line">select hour(&#x27;2022-08-08 12:08:08&#x27;);  --12</span><br><span class="line"></span><br><span class="line">--8.datediff：两个日期相差的天数（结束日期减去开始日期的天数）</span><br><span class="line">/*</span><br><span class="line"> 语法：datediff(string enddate, string startdate)</span><br><span class="line"> 返回值：int</span><br><span class="line"> */</span><br><span class="line">select datediff(&#x27;2023-08-08&#x27;,&#x27;2022-10-09&#x27;);  --303</span><br><span class="line">select datediff(&#x27;2021-08-08&#x27;,&#x27;2022-10-09&#x27;);  -- -427</span><br><span class="line"></span><br><span class="line">--9.date_add：日期加天数</span><br><span class="line">/*</span><br><span class="line"> 语法：date_add(string startdate, int days)</span><br><span class="line"> 返回值：string</span><br><span class="line"> 说明：返回开始日期 startdate 增加 days 天后的日期</span><br><span class="line"> */</span><br><span class="line">select date_add(&quot;2023-04-18&quot;,100);  --2023-07-27</span><br><span class="line"></span><br><span class="line">--10.date_sub：日期减天数</span><br><span class="line">select date_sub(&quot;2023-04-18&quot;,100);  --2023-01-08</span><br><span class="line"></span><br><span class="line">--11.date_format:将标准日期解析成指定格式字符串</span><br><span class="line">select date_format(&#x27;2023-04-18&#x27;, &#x27;yyyy年-MM月-dd日&#x27;); --2023年-04月-18日</span><br></pre></td></tr></table></figure>

<h3 id="7-1-5-流程控制函数"><a href="#7-1-5-流程控制函数" class="headerlink" title="7.1.5 流程控制函数"></a>7.1.5 流程控制函数</h3><p>（1）case when：条件判断函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 语法一：case when a then b [when c then d]* [else e] end</span><br><span class="line"> 返回值：T</span><br><span class="line"> 说明：如果a为true，则返回b；如果c为true，则返回d；否则返回 e</span><br><span class="line"> */</span><br><span class="line">-- 需求：对表score_info表中的成绩进行等级划分</span><br><span class="line">select stu_id, course_id,</span><br><span class="line">       case</span><br><span class="line">           when score &gt;= 90 then &#x27;A&#x27;</span><br><span class="line">           when score &gt;= 80 then &#x27;B&#x27;</span><br><span class="line">           when score &gt;= 70 then &#x27;C&#x27;</span><br><span class="line">           when score &gt;= 60 then &#x27;D&#x27;</span><br><span class="line">           else &#x27;不及格&#x27;</span><br><span class="line">       end</span><br><span class="line">from db_hive.score_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_15-01-17.png" alt="Snipaste_2023-10-17_15-01-17" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 等值判断</span><br><span class="line"> 语法二： case a when b then c [when d then e]* [else f] end</span><br><span class="line"> 返回值: T</span><br><span class="line"> 说明：如果a等于b，那么返回c；如果a等于d，那么返回e；否则返回f</span><br><span class="line"> */</span><br><span class="line"> select stu_id,</span><br><span class="line">       case course_id</span><br><span class="line">           when 01 then &#x27;语文&#x27;</span><br><span class="line">           when 02 then &#x27;数学&#x27;</span><br><span class="line">           when 03 then &#x27;英语&#x27;</span><br><span class="line">           when 04 then &#x27;体育&#x27;</span><br><span class="line">           when 05 then &#x27;音乐&#x27;</span><br><span class="line">       end,</span><br><span class="line">       score</span><br><span class="line">from db_hive.score_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_15-06-39.png" alt="Snipaste_2023-10-17_15-06-39" style="zoom:50%;">

<p>（2）if：条件判断，类似于java中的三元运算符</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> 语法：if（boolean testCondition, T valueTrue, T valueFalseOrNull）</span><br><span class="line"> 返回值：T</span><br><span class="line"> 说明：当条件testCondition为true时，返回valueTrue；否则返回valueFalseOrNull</span><br><span class="line"> */</span><br><span class="line">select stu_id,course_id,</span><br><span class="line">       `if`(score &gt;= 85, &#x27;高分&#x27;, &#x27;低分&#x27;)</span><br><span class="line">from db_hive.score_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_15-15-37.png" alt="Snipaste_2023-10-17_15-15-37" style="zoom:50%;">

<h3 id="7-1-6-集合函数"><a href="#7-1-6-集合函数" class="headerlink" title="7.1.6 集合函数"></a>7.1.6 集合函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">-- （1）array 声明array集合</span><br><span class="line">/*</span><br><span class="line"> 语法：array(val1, val2, …)</span><br><span class="line"> 说明：根据输入的参数构建数组array类</span><br><span class="line"> */</span><br><span class="line">select `array`(&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;4&#x27;,&#x27;5&#x27;);</span><br><span class="line">-- [&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;]</span><br><span class="line"></span><br><span class="line">-- （2）array_contains: 判断array中是否包含某个元素</span><br><span class="line">select array_contains(`array`(&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;4&#x27;,&#x27;5&#x27;), &#x27;1&#x27;);</span><br><span class="line">-- true</span><br><span class="line"></span><br><span class="line">-- （3）sort_array：将array中的元素排序，默认升序</span><br><span class="line">select sort_array(`array`(2,3,4,5,9,23,67,21));</span><br><span class="line">-- [2,3,4,5,9,21,23,67]</span><br><span class="line"></span><br><span class="line">-- （4）size：集合中元素的个数（集合长度）</span><br><span class="line">select size(`array`(2,3,4,5,9,23,67,21)); --8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--（5）map：创建map集合</span><br><span class="line">/*</span><br><span class="line"> 语法：map (key1, value1, key2, value2, …)</span><br><span class="line"> 说明：根据输入的key和value对构建map类型</span><br><span class="line"> */</span><br><span class="line">select `map`(&#x27;xiaowang&#x27;, 1, &#x27;xiaoliu&#x27;, 2);</span><br><span class="line">-- &#123;&quot;xiaowang&quot;:1,&quot;xiaoliu&quot;:2&#125;</span><br><span class="line"></span><br><span class="line">-- （6）map_keys： 返回map中的key；map_values: 返回map中的value</span><br><span class="line">select map_keys( `map`(&#x27;xiaowang&#x27;, 1, &#x27;xiaoliu&#x27;, 2));</span><br><span class="line">-- [&quot;xiaowang&quot;,&quot;xiaoliu&quot;]</span><br><span class="line"></span><br><span class="line">select map_values(`map`(&#x27;xiaowang&#x27;, 1, &#x27;xiaoliu&#x27;, 2));</span><br><span class="line">-- [1,2]</span><br><span class="line"></span><br><span class="line">-- （7）struct声明struct中的各属性</span><br><span class="line">/*</span><br><span class="line"> 语法：struct(val1, val2, val3, …)</span><br><span class="line"> 说明：根据输入的参数构建结构体struct类</span><br><span class="line"> */</span><br><span class="line">select struct(&#x27;name&#x27;, &#x27;age&#x27;, &#x27;weight&#x27;);</span><br><span class="line">-- &#123;&quot;col1&quot;:&quot;name&quot;,&quot;col2&quot;:&quot;age&quot;,&quot;col3&quot;:&quot;weight&quot;&#125;</span><br><span class="line"></span><br><span class="line">-- （8）named_struct声明struct的属性和值</span><br><span class="line">select named_struct(&#x27;name&#x27;,&#x27;xiaosong&#x27;,&#x27;age&#x27;,18,&#x27;weight&#x27;,80);</span><br><span class="line">-- &#123;&quot;name&quot;:&quot;xiaosong&quot;,&quot;age&quot;:18,&quot;weight&quot;:80&#125;</span><br></pre></td></tr></table></figure>

<h3 id="7-1-7-案例准备"><a href="#7-1-7-案例准备" class="headerlink" title="7.1.7 案例准备"></a>7.1.7 案例准备</h3><p><img src="Snipaste_2023-10-17_15-46-21.png" alt="Snipaste_2023-10-17_15-46-21"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 1）统计每个月的入职人数</span><br><span class="line">select month(replace(hiredate, &#x27;/&#x27;, &#x27;-&#x27;)) as month,count(*) as cn</span><br><span class="line">from employee</span><br><span class="line">group by month(replace(hiredate, &#x27;/&#x27;, &#x27;-&#x27;));</span><br><span class="line">--或</span><br><span class="line">select substr(hiredate, 6, 2) as month, count(*) as cn</span><br><span class="line">from employee</span><br><span class="line">group by substr(hiredate, 6, 2);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_16-11-54.png" alt="Snipaste_2023-10-17_16-11-54" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 2）查询每个人的年龄（年 + 月）</span><br><span class="line">select name, y || &#x27;年&#x27; || m || &#x27;月&#x27; as age</span><br><span class="line">from (</span><br><span class="line">         select name, floor(num_month / 12) y, floor(num_month % 12) m</span><br><span class="line">         from (</span><br><span class="line">                  select name, months_between(current_date(), replace(birthday, &#x27;/&#x27;, &#x27;-&#x27;)) num_month</span><br><span class="line">                  from employee</span><br><span class="line">              ) t1</span><br><span class="line">     ) t2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_16-28-47.png" alt="Snipaste_2023-10-17_16-28-47" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 3）按照薪资，奖金的和进行倒序排序，如果奖金为null，置位0</span><br><span class="line">select name, salary + nvl(bonus, 0) as sal</span><br><span class="line">from employee</span><br><span class="line">order by sal desc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_17-41-43.png" alt="Snipaste_2023-10-17_17-41-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 4）查询每个人有多少个朋友</span><br><span class="line">select name, size(friends) as cnt</span><br><span class="line">from employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_17-43-45.png" alt="Snipaste_2023-10-17_17-43-45" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- 5）查询每个人的孩子的姓名</span><br><span class="line">select name, map_keys(children) ch_name</span><br><span class="line">from employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_17-50-18.png" alt="Snipaste_2023-10-17_17-50-18" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">-- 6）查询每个岗位男女各多少人</span><br><span class="line">select nvl(male.job, female.job) job,</span><br><span class="line">       nvl(male.cnt, 0),</span><br><span class="line">       nvl(female.cnt, 0)</span><br><span class="line">from (</span><br><span class="line">         select job, count(*) as cnt</span><br><span class="line">         from employee</span><br><span class="line">         where sex = &#x27;男&#x27;</span><br><span class="line">         group by job</span><br><span class="line">     ) male</span><br><span class="line">         full join</span><br><span class="line">     (</span><br><span class="line">         select job, count(*) as cnt</span><br><span class="line">         from employee</span><br><span class="line">         where sex = &#x27;女&#x27;</span><br><span class="line">         group by job</span><br><span class="line">     ) female</span><br><span class="line">     on male.job = female.job;</span><br><span class="line"></span><br><span class="line">-- 另外的做法：小技巧：sum-if组合实现</span><br><span class="line">select job,</span><br><span class="line">       sum(if(sex = &#x27;男&#x27;, 1, 0)) as male,</span><br><span class="line">       sum(if(sex = &#x27;女&#x27;, 1, 0)) as female</span><br><span class="line">from employee</span><br><span class="line">group by job;</span><br><span class="line"></span><br><span class="line">select job,</span><br><span class="line">       count(if(sex = &#x27;男&#x27;, 1, null)) as male,</span><br><span class="line">       count(if(sex = &#x27;女&#x27;, 1, null)) as female</span><br><span class="line">from employee</span><br><span class="line">group by job;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_17-59-21.png" alt="Snipaste_2023-10-17_17-59-21" style="zoom:50%;">

<h2 id="7-2-高级聚合函数"><a href="#7-2-高级聚合函数" class="headerlink" title="7.2 高级聚合函数"></a>7.2 高级聚合函数</h2><p>多进一出 （多行传入，一个行输出）。</p>
<p>1）普通聚合：count(),  sum(),  max(),   min(),  avg()等函数，见5.2.8节</p>
<p>2）collect_list 收集并形成list集合，结果<strong>不去重</strong></p>
<p>3）collect_set 收集并形成set集合，结果<strong>去重</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select collect_list(job)</span><br><span class="line">from employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_18-25-40.png" alt="Snipaste_2023-10-17_18-25-40" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select collect_set(job)</span><br><span class="line">from employee;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_18-26-25.png" alt="Snipaste_2023-10-17_18-26-25" style="zoom:50%;">

<h3 id="7-2-1-案例演示"><a href="#7-2-1-案例演示" class="headerlink" title="7.2.1 案例演示"></a>7.2.1 案例演示</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 1）每个月的入职人数以及姓名</span><br><span class="line">select month(replace(hiredate, &#x27;/&#x27;, &#x27;-&#x27;)) as month,</span><br><span class="line">       count(*)                           as cn,</span><br><span class="line">       collect_list(name)                 as name_list</span><br><span class="line">from employee</span><br><span class="line">group by month(replace(hiredate, &#x27;/&#x27;, &#x27;-&#x27;));</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-17_20-53-58.png" alt="Snipaste_2023-10-17_20-53-58" style="zoom:50%;">

<h2 id="7-3-炸裂函数（重难点）"><a href="#7-3-炸裂函数（重难点）" class="headerlink" title="7.3 炸裂函数（重难点）"></a>7.3 炸裂函数（重难点）</h2><h3 id="7-3-1-概述"><a href="#7-3-1-概述" class="headerlink" title="7.3.1 概述"></a>7.3.1 概述</h3><p>UDTF，接收一行数据，输出一行或多行数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- （1）explode(ARRAY&lt;T&gt; a)</span><br><span class="line">select explode(array(1, 2, 3));</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-55-53.png" alt="Snipaste_2023-10-18_15-55-53" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- （2）explode(Map&lt;K,V&gt; m)</span><br><span class="line">select explode(map(&quot;a&quot;,1,&quot;b&quot;,2,&quot;c&quot;,3)) as (key,value);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-56-55.png" alt="Snipaste_2023-10-18_15-56-55" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- （3）posexplode(ARRAY&lt;T&gt; a)</span><br><span class="line">select posexplode(array(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)) as (pos,item);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_15-58-10.png" alt="Snipaste_2023-10-18_15-58-10" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- （4）inline(ARRAY&lt;STRUCT&lt;f1:T1,...,fn:Tn&gt;&gt; a)</span><br><span class="line">select inline(array(named_struct(&quot;id&quot;, 1, &quot;name&quot;, &quot;zs&quot;),</span><br><span class="line">                    named_struct(&quot;id&quot;, 2, &quot;name&quot;, &quot;ls&quot;),</span><br><span class="line">                    named_struct(&quot;id&quot;, 3, &quot;name&quot;, &quot;ww&quot;))) as (id, name);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_16-00-44.png" alt="Snipaste_2023-10-18_16-00-44" style="zoom:50%;">

<p>Latera View 通常与UDTF配合使用。Lateral View可以将UDTF应用到源表的每行数据，将每行数据转换为一行或多行，并将源表中每行的输出结果与该行连接起来，形成一个虚拟表。</p>
<img src="Snipaste_2023-10-18_16-05-59.png" alt="Snipaste_2023-10-18_16-05-59" style="zoom:50%;">

<h3 id="7-3-2-案例演示"><a href="#7-3-2-案例演示" class="headerlink" title="7.3.2 案例演示"></a>7.3.2 案例演示</h3><img src="Snipaste_2023-10-18_16-10-33.png" alt="Snipaste_2023-10-18_16-10-33" style="zoom:50%;">

<p>根据上述电影信息表，统计各分类的电影数量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select movie, split(category, &#x27;,&#x27;) cates</span><br><span class="line">from movie_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_16-21-36.png" alt="Snipaste_2023-10-18_16-21-36" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select movie, cate</span><br><span class="line">from (</span><br><span class="line">         select movie, split(category, &#x27;,&#x27;) cates</span><br><span class="line">         from movie_info</span><br><span class="line">    ) t1 lateral view explode(cates) tmp as cate;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_16-22-27.png" alt="Snipaste_2023-10-18_16-22-27" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">select cate, count(*)</span><br><span class="line">from (</span><br><span class="line">         select movie, cate</span><br><span class="line">         from (</span><br><span class="line">                  select movie, split(category, &#x27;,&#x27;) cates</span><br><span class="line">                  from movie_info</span><br><span class="line">              ) t1 lateral view explode(cates) tmp as cate</span><br><span class="line">     ) t2</span><br><span class="line">group by cate;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_16-24-10.png" alt="Snipaste_2023-10-18_16-24-10" style="zoom:50%;">

<h2 id="7-4-窗口函数（开窗函数）"><a href="#7-4-窗口函数（开窗函数）" class="headerlink" title="7.4 窗口函数（开窗函数）"></a>7.4 窗口函数（开窗函数）</h2><h3 id="7-4-1-概述"><a href="#7-4-1-概述" class="headerlink" title="7.4.1 概述"></a>7.4.1 概述</h3><p>窗口函数，能为每行数据划分一个窗口，然后对窗口范围内的数据进行计算，最后将计算结果返回给该行数据。</p>
<p>窗口函数的语法中主要包括“窗口”和“函数”两部分。<strong>其中“窗口”用于定义计算范围，“函数”用于定义计算逻辑</strong>。</p>
<img src="Snipaste_2023-10-18_16-34-30.png" alt="Snipaste_2023-10-18_16-34-30" style="zoom:50%;">

<p>①<strong>语法-函数：绝大多数的聚合函数都可以配合窗口使用，例如max(),min(),sum(),count(),avg()等。</strong></p>
<p>②<strong>语法-窗口：窗口范围的定义分为两种类型，一种是基于行的，一种是基于值的</strong></p>
<p><img src="Snipaste_2023-10-18_16-55-01.png" alt="Snipaste_2023-10-18_16-55-01"></p>
<p><img src="Snipaste_2023-10-18_16-56-15.png" alt="Snipaste_2023-10-18_16-56-15"></p>
<p>此时order by[column]必须写，表明按照column列的顺序基于行进行窗口范围划分</p>
<p><img src="Snipaste_2023-10-18_20-16-12.png" alt="Snipaste_2023-10-18_20-16-12"></p>
<p><img src="Snipaste_2023-10-18_19-59-55.png" alt="Snipaste_2023-10-18_19-59-55"></p>
<p>此时order by[column]中的column是基于column字段进行窗口范围划分</p>
<p>③<strong>语法-窗口-分区：定义窗口范围时，可以指定分区字段，每个分区单独划分窗口。  语法：partition by</strong></p>
<p><img src="Snipaste_2023-10-18_20-29-46.png" alt="Snipaste_2023-10-18_20-29-46"></p>
<p>④<strong>语法-窗口-缺省</strong></p>
<img src="Snipaste_2023-10-18_20-38-28.png" alt="Snipaste_2023-10-18_20-38-28" style="zoom:50%;">

<p><img src="Snipaste_2023-10-18_20-39-09.png" alt="Snipaste_2023-10-18_20-39-09"></p>
<h3 id="7-4-2-常用窗口函数"><a href="#7-4-2-常用窗口函数" class="headerlink" title="7.4.2 常用窗口函数"></a>7.4.2 常用窗口函数</h3><p>按照功能，常用窗口可划分为如下几类：聚合函数、跨行取值函数、排名函数。</p>
<ul>
<li>聚合函数：max，min，sum，avg，count</li>
<li>跨行取值函数：lead和lag，first_value和last_value</li>
<li>排名函数：rank，dense_rank，row_number</li>
</ul>
<img src="Snipaste_2023-10-18_20-52-54.png" alt="Snipaste_2023-10-18_20-52-54" style="zoom:50%;">

<p><strong>注：lag和lead函数不支持自定义窗口</strong></p>
<img src="Snipaste_2023-10-18_20-58-47.png" alt="Snipaste_2023-10-18_20-58-47" style="zoom:50%;">

<p>注意：这里面的窗口范围是默认的range[第一行，当前行]；所以从上到下的窗口范围依次为：</p>
<p>[2022-01-01, 2022-01-01]		first_date:   2022-01-01		last_date:  2022-01-01</p>
<p>[2022-01-01, 2022-01-02]		first_date:   2022-01-01		last_date:  2022-01-02</p>
<p>[2022-01-01, 2022-01-03]		first_date:   2022-01-01		last_date:  2022-01-03</p>
<p>[2022-01-04, 2022-01-04]		first_date:   2022-01-04		last_date:  2022-01-04</p>
<p>[2022-01-04, 2022-01-05]		first_date:   2022-01-04		last_date:  2022-01-05</p>
<p>[2022-01-04, 2022-01-06]		first_date:   2022-01-04		last_date:  2022-01-06</p>
<img src="Snipaste_2023-10-18_21-15-06.png" alt="Snipaste_2023-10-18_21-15-06" style="zoom:50%;">

<p><strong>注：rank 、dense_rank、row_number不支持自定义窗口。</strong></p>
<h3 id="7-4-3-案例演示"><a href="#7-4-3-案例演示" class="headerlink" title="7.4.3 案例演示"></a>7.4.3 案例演示</h3><img src="Snipaste_2023-10-18_21-17-31.png" alt="Snipaste_2023-10-18_21-17-31" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 1）统计每个用户截至每次下单的累积下单总额</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       sum(order_amount)</span><br><span class="line">           over (partition by user_id order by order_date rows between unbounded preceding and current row ) as sum_so_far</span><br><span class="line">from order_info;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-18_21-38-36.png" alt="Snipaste_2023-10-18_21-38-36" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-- 2）统计每个用户截至每次下单的当月累积下单总额</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       sum(order_amount)</span><br><span class="line">           over (partition by user_id, substring(order_date, 1, 7) order by order_date rows between unbounded preceding and current row) as sum_so_far</span><br><span class="line">from order_info;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-18_21-47-50.png" alt="Snipaste_2023-10-18_21-47-50"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">-- 3）统计每个用户每次下单距离上次下单相隔的天数（首次下单按0天算）</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       nvl(datediff(order_date, last_order_date), 0) as diff</span><br><span class="line">from (</span><br><span class="line">         select order_id,</span><br><span class="line">                user_id,</span><br><span class="line">                user_name,</span><br><span class="line">                order_date,</span><br><span class="line">                order_amount,</span><br><span class="line">                lag(order_date, 1, null) over (partition by user_id order by order_date) as last_order_date</span><br><span class="line">         from order_info</span><br><span class="line">     ) t1;</span><br><span class="line">     </span><br><span class="line">--或者</span><br><span class="line"></span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       datediff(order_date, last_order_date) as diff</span><br><span class="line">from (</span><br><span class="line">         select order_id,</span><br><span class="line">                user_id,</span><br><span class="line">                user_name,</span><br><span class="line">                order_date,</span><br><span class="line">                order_amount,</span><br><span class="line">                lag(order_date, 1, order_date) over (partition by user_id order by order_date) as last_order_date</span><br><span class="line">         from order_info</span><br><span class="line">     ) t1;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-18_22-06-19.png" alt="Snipaste_2023-10-18_22-06-19"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-- 4）查询所有下单记录以及每个用户的每个下单记录所在月份的首/末次下单日期,注意：first_value不需要加窗口范围；last_value需要加窗口范围</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       first_value(order_date, false)</span><br><span class="line">                   over (partition by user_id, substring(order_date, 1, 7) order by order_date)                                                         as first_date,</span><br><span class="line">       last_value(order_date, false)</span><br><span class="line">                  over (partition by user_id, substring(order_date, 1, 7) order by order_date range between unbounded preceding and unbounded following) as last_date</span><br><span class="line">from order_info;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-18_22-19-32.png" alt="Snipaste_2023-10-18_22-19-32"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-- 5）为每个用户的所有下单记录按照订单金额进行排名</span><br><span class="line">select order_id,</span><br><span class="line">       user_id,</span><br><span class="line">       user_name,</span><br><span class="line">       order_date,</span><br><span class="line">       order_amount,</span><br><span class="line">       rank() over (partition by user_id order by order_amount desc )      as rk,</span><br><span class="line">       dense_rank() over (partition by user_id order by order_amount desc) as drk,</span><br><span class="line">       row_number() over (partition by user_id order by order_amount desc) as rn</span><br><span class="line">from order_info;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-10-19_09-39-12.png" alt="Snipaste_2023-10-19_09-39-12"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-- 扩展：分组TOPN:【固定套路，要记住】</span><br><span class="line">-- 查询score_info表中每一门科目的前三名（分数最高的前三个）</span><br><span class="line">select course_id,stu_id,score,rk</span><br><span class="line">from (</span><br><span class="line">         select course_id,</span><br><span class="line">                stu_id,</span><br><span class="line">                score,</span><br><span class="line">                rank() over (partition by course_id order by score desc ) as rk</span><br><span class="line">         from db_hive.score_info</span><br><span class="line">     )t1</span><br><span class="line">where rk in (1,2,3);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-19_09-48-16.png" alt="Snipaste_2023-10-19_09-48-16" style="zoom:50%;">

<h2 id="7-5-自定义函数（用的不多）"><a href="#7-5-自定义函数（用的不多）" class="headerlink" title="7.5 自定义函数（用的不多）"></a>7.5 自定义函数（用的不多）</h2><p>Hive自定义了一些函数，如min，max等，但是数量有限，我们可以通过自定义UDF来方便扩展</p>
<img src="Snipaste_2023-10-31_19-53-53.png" alt="Snipaste_2023-10-31_19-53-53" style="zoom:50%;">

<img src="Snipaste_2023-10-31_19-57-23.png" alt="Snipaste_2023-10-31_19-57-23" style="zoom:50%;">

<h2 id="7-6-自定义UDF函数"><a href="#7-6-自定义UDF函数" class="headerlink" title="7.6 自定义UDF函数"></a>7.6 自定义UDF函数</h2><p>（0）需求：自定义一个UDF实现计算给定基本数据类型的长度，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select my_len(&quot;abcd&quot;);</span><br><span class="line">4</span><br></pre></td></tr></table></figure>

<p>（1）创建一个Maven工程Hive</p>
<p>（2）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（3）创建一个类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyLength</span> <span class="keyword">extends</span> <span class="title class_">GenericUDF</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 判断传进来的参数的类型和长度</span></span><br><span class="line"><span class="comment">     * 约定返回的数据类型</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> ObjectInspector <span class="title function_">initialize</span><span class="params">(ObjectInspector[] arguments)</span> <span class="keyword">throws</span> UDFArgumentException &#123;</span><br><span class="line">        <span class="keyword">if</span> (arguments.length !=<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span>  <span class="keyword">new</span> <span class="title class_">UDFArgumentLengthException</span>(<span class="string">&quot;please give me  only one arg&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!arguments[<span class="number">0</span>].getCategory().equals(ObjectInspector.Category.PRIMITIVE))&#123;</span><br><span class="line">            <span class="keyword">throw</span>  <span class="keyword">new</span> <span class="title class_">UDFArgumentTypeException</span>(<span class="number">1</span>, <span class="string">&quot;i need primitive type arg&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> PrimitiveObjectInspectorFactory.javaIntObjectInspector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解决具体逻辑的</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">evaluate</span><span class="params">(DeferredObject[] arguments)</span> <span class="keyword">throws</span> HiveException &#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">o</span> <span class="operator">=</span> arguments[<span class="number">0</span>].get();</span><br><span class="line">        <span class="keyword">if</span>(o==<span class="literal">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> o.toString().length();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">// 用于获取解释的字符串explain</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getDisplayString</span><span class="params">(String[] strings)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）创建临时函数</p>
<p>①打成jar包上传到服务器&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# ll</span><br><span class="line">总用量 20</span><br><span class="line">drwxr-xr-x. 2 root root  117 10月 10 13:21 cluster-result</span><br><span class="line">-rw-r--r--. 1 root root   72 10月  9 15:04 dept.txt</span><br><span class="line">drwxr-xr-x. 2 root root  117 10月 10 13:16 distribute-result</span><br><span class="line">-rw-r--r--. 1 root root  416 10月  9 15:06 emp.txt</span><br><span class="line">-rw-r--r--. 1 root root   10 10月  8 13:44 hive_result.txt</span><br><span class="line">-rw-r--r--. 1 root root   36 10月  9 21:35 location.txt</span><br><span class="line">-rw-r--r--  1 root root 2983 10月 31 21:38 myudf.jar</span><br><span class="line">drwxr-xr-x. 2 root root  117 10月 10 12:58 sortby-result</span><br></pre></td></tr></table></figure>

<p>②将jar包添加到hive的classpath，临时生效</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add jar /opt/module/hive/datas/myudf.jar;</span><br></pre></td></tr></table></figure>

<p>③创建临时函数与开发好的java class关联</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create temporary function my_len</span><br><span class="line">as &quot;com.atguigu.hive.udf.MyLength&quot;;</span><br></pre></td></tr></table></figure>

<p>④即可在hql中使用自定义的临时函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select my_len(&quot;ghghgh&quot;);--6</span><br></pre></td></tr></table></figure>

<p>注意：临时函数只跟会话有关系，跟库没有关系。只要创建临时函数的会话不断，在当前会话下，任意一个库都可以使用，其他会话全都不能使用。</p>
<p>⑤删除临时函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drop temporary function my_len;</span><br></pre></td></tr></table></figure>

<p>（5）创建永久函数</p>
<p>在hadoop102网页端新建udf文件夹并上传jar包</p>
<img src="Snipaste_2023-10-31_21-52-13.png" alt="Snipaste_2023-10-31_21-52-13" style="zoom:50%;">

<p>执行创建函数的语句：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create function my_len</span><br><span class="line">as &quot;com.atguigu.hive.udf.MyLength&quot;</span><br><span class="line">using jar &quot;hdfs://hadoop102:8020/udf/myudf.jar&quot;;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select my_len(&quot;ghghgh&quot;);--6</span><br></pre></td></tr></table></figure>

<p>注意：永久函数跟会话没有关系，创建函数的会话断了以后，其他会话也可以使用。</p>
<p>永久函数创建的时候，在函数名之前需要自己加上库名，如果不指定库名的话，会默认把当前库的库名给加上。</p>
<p>永久函数使用的时候，需要在指定的库里面操作，或者在其他库里面使用的话加上，<strong>库名.函数名。</strong></p>
<h1 id="第八章-综合案例练习（中级）"><a href="#第八章-综合案例练习（中级）" class="headerlink" title="第八章 综合案例练习（中级）"></a>第八章 综合案例练习（中级）</h1><p>用户信息表：</p>
<img src="Snipaste_2023-10-31_14-11-36.png" alt="Snipaste_2023-10-31_14-11-36" style="zoom:50%;">

<p>商品信息表：</p>
<img src="Snipaste_2023-10-31_14-13-44.png" alt="Snipaste_2023-10-31_14-13-44" style="zoom:50%;">

<p>商品分类信息表：</p>
<img src="Snipaste_2023-10-31_14-15-37.png" alt="Snipaste_2023-10-31_14-15-37" style="zoom:50%;">

<p>订单信息表：</p>
<img src="Snipaste_2023-10-31_14-16-41.png" alt="Snipaste_2023-10-31_14-16-41" style="zoom:50%;">

<p>订单明细表：</p>
<img src="Snipaste_2023-10-31_14-18-02.png" alt="Snipaste_2023-10-31_14-18-02" style="zoom:50%;">

<p>登录明细表：</p>
<img src="Snipaste_2023-10-31_14-19-10.png" alt="Snipaste_2023-10-31_14-19-10" style="zoom:50%;">

<p>商品价格变更明细表：</p>
<img src="Snipaste_2023-10-31_14-20-10.png" alt="Snipaste_2023-10-31_14-20-10" style="zoom:50%;">

<p>配送信息表：</p>
<img src="Snipaste_2023-10-31_14-21-06.png" alt="Snipaste_2023-10-31_14-21-06" style="zoom:50%;">

<p>好友关系表：</p>
<img src="Snipaste_2023-10-31_14-21-47.png" alt="Snipaste_2023-10-31_14-21-47" style="zoom:50%;">

<p>收藏信息表：</p>
<img src="Snipaste_2023-10-31_14-22-43.png" alt="Snipaste_2023-10-31_14-22-43" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--2.1 查询累积销量排名第二的商品</span><br><span class="line">--①查询每个sku_id的商品销量，并按照order_num降序排序,并选取排名第二的这行数据</span><br><span class="line">select sku_id, sum(sku_num) as order_num</span><br><span class="line">from order_detail</span><br><span class="line">group by sku_id</span><br><span class="line">order by order_num desc</span><br><span class="line">limit 1,1;</span><br><span class="line">--②查询①表中的sku_id这列返回</span><br><span class="line">select sku_id</span><br><span class="line">from (</span><br><span class="line">         select sku_id, sum(sku_num) as order_num</span><br><span class="line">         from order_detail</span><br><span class="line">         group by sku_id</span><br><span class="line">         order by order_num desc</span><br><span class="line">         limit 1,1</span><br><span class="line">)t1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_14-47-25.png" alt="Snipaste_2023-10-31_14-47-25" style="zoom:50%;">

<img src="Snipaste_2023-10-31_14-47-50.png" alt="Snipaste_2023-10-31_14-47-50" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">--2.2 查询至少连续三天下单的用户</span><br><span class="line">--思路1</span><br><span class="line">--①查询用户id和下单时间，并去重，三种去重方法（当且仅当user_id和create_date这两个字段同时对应相同时算重复）</span><br><span class="line">select distinct user_id, create_date</span><br><span class="line">from order_info;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">select user_id, create_date</span><br><span class="line">from order_info</span><br><span class="line">group by user_id, create_date;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">select user_id,create_date</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                row_number() over (partition by user_id,create_date) rn</span><br><span class="line">         from order_info</span><br><span class="line">     )t1</span><br><span class="line">where rn = 1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_14-59-09.png" alt="Snipaste_2023-10-31_14-59-09" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--②使用Lead窗口函数，以user_id进行分区且对create_date进行排序，得到新的一列lead2</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       lead(create_date, 2, &#x27;9999-12-31&#x27;) over (partition by user_id order by create_date) as lead2</span><br><span class="line">from (</span><br><span class="line">         select distinct user_id, create_date</span><br><span class="line">         from order_info</span><br><span class="line">     ) t1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_15-30-25.png" alt="Snipaste_2023-10-31_15-30-25" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">--③对查询表②的lead2字段和create_date字段进行减法运算，得到差值diff字段，并筛选diff字段等于2的行</span><br><span class="line">select user_id,</span><br><span class="line">       datediff(lead2, create_date) as diff</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                lead(create_date, 2, &#x27;9999-12-31&#x27;) over (partition by user_id order by create_date) as lead2</span><br><span class="line">         from (</span><br><span class="line">                  select distinct user_id, create_date</span><br><span class="line">                  from order_info</span><br><span class="line">              ) t1</span><br><span class="line">     ) t2</span><br><span class="line">where datediff(lead2, create_date) = 2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_15-31-04.png" alt="Snipaste_2023-10-31_15-31-04" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--④选择查询表③的user_id字段，并去重</span><br><span class="line">select distinct user_id</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                datediff(lead2, create_date) as diff</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         create_date,</span><br><span class="line">                         lead(create_date, 2, &#x27;9999-12-31&#x27;) over (partition by user_id order by create_date) as lead2</span><br><span class="line">                  from (</span><br><span class="line">                           select distinct user_id, create_date</span><br><span class="line">                           from order_info</span><br><span class="line">                       ) t1</span><br><span class="line">              ) t2</span><br><span class="line">         where datediff(lead2, create_date) = 2</span><br><span class="line">)t3;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_15-31-52.png" alt="Snipaste_2023-10-31_15-31-52" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">--2.2 思路2</span><br><span class="line">--使用窗口函数rank()，得到新字段rk，然后让create_date取减rk，得到新列diff，如果diff列中相同结果的个数大于等于3，证明</span><br><span class="line">--存在至少连续三天下单的用户</span><br><span class="line">select distinct user_id</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                diff,</span><br><span class="line">                count(*) cnt</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         create_date,</span><br><span class="line">                         date_sub(create_date, rank() over (partition by user_id order by create_date)) diff</span><br><span class="line">                  from (</span><br><span class="line">                           select distinct user_id, create_date</span><br><span class="line">                           from order_info</span><br><span class="line">                       ) t1</span><br><span class="line">              ) t2</span><br><span class="line">         group by user_id, diff</span><br><span class="line">         having cnt &gt;= 3</span><br><span class="line">     )t3;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">--2.2 思路3</span><br><span class="line">--使用count(*) over(partition by user_id order by ts range between 86400 preceding and 86400 following)</span><br><span class="line">--如果得到该列数据大于等于3证明存在至少连续三天下单的用户</span><br><span class="line">select distinct user_id</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                ts,</span><br><span class="line">                count(*) over (partition by user_id order by ts range between 86400 preceding and 86400 following) cnt</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         unix_timestamp(create_date, &#x27;yyyy-MM-dd&#x27;) ts</span><br><span class="line">                  from (</span><br><span class="line">                           select distinct user_id, create_date</span><br><span class="line">                           from order_info</span><br><span class="line">                       ) t1</span><br><span class="line">              ) t2</span><br><span class="line">     )t3</span><br><span class="line">where cnt &gt;= 3;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--2.3 查询各品类销售商品的种类数及销量最高的商品</span><br><span class="line">--①查询不同商品id的销售量</span><br><span class="line">select sku_id,</span><br><span class="line">       sum(sku_num) order_num</span><br><span class="line">from order_detail</span><br><span class="line">group by sku_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-32-43.png" alt="Snipaste_2023-10-31_16-32-43" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">--②将查询表①join上sku_info表和category_info表，按照商品分类给销量进行升序排列，并统计每个商品分类下的商品数</span><br><span class="line">select od.sku_id,</span><br><span class="line">                sku.name,</span><br><span class="line">                sku.category_id,</span><br><span class="line">                cate.category_name,</span><br><span class="line">                order_num,</span><br><span class="line">                rank() over (partition by sku.category_id order by order_num desc ) rk,</span><br><span class="line">                count(distinct od.sku_id) over (partition by sku.category_id)      sku_cnt</span><br><span class="line">         from (</span><br><span class="line">                  select sku_id,</span><br><span class="line">                         sum(sku_num) order_num</span><br><span class="line">                  from order_detail</span><br><span class="line">                  group by sku_id</span><br><span class="line">              ) od</span><br><span class="line">                  left join</span><br><span class="line">              sku_info sku</span><br><span class="line">              on od.sku_id = sku.sku_id</span><br><span class="line">                  left join</span><br><span class="line">              category_info cate</span><br><span class="line">              on sku.category_id = cate.category_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-33-27.png" alt="Snipaste_2023-10-31_16-33-27" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">--③对表②进行过滤rk=1（销量最高）</span><br><span class="line">select category_id,</span><br><span class="line">       category_name,</span><br><span class="line">       sku_id,</span><br><span class="line">       name,</span><br><span class="line">       order_num,</span><br><span class="line">       sku_cnt</span><br><span class="line">from (</span><br><span class="line">         select od.sku_id,</span><br><span class="line">                sku.name,</span><br><span class="line">                sku.category_id,</span><br><span class="line">                cate.category_name,</span><br><span class="line">                order_num,</span><br><span class="line">                rank() over (partition by sku.category_id order by order_num desc) rk,</span><br><span class="line">                count(distinct od.sku_id) over (partition by sku.category_id)      sku_cnt</span><br><span class="line">         from (</span><br><span class="line">                  select sku_id,</span><br><span class="line">                         sum(sku_num) order_num</span><br><span class="line">                  from order_detail</span><br><span class="line">                  group by sku_id</span><br><span class="line">              ) od</span><br><span class="line">                  left join</span><br><span class="line">              sku_info sku</span><br><span class="line">              on od.sku_id = sku.sku_id</span><br><span class="line">                  left join</span><br><span class="line">              category_info cate</span><br><span class="line">              on sku.category_id = cate.category_id</span><br><span class="line">     ) t1</span><br><span class="line">where rk = 1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-34-24.png" alt="Snipaste_2023-10-31_16-34-24" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--2.4 查询用户的累计消费金额及VIP等级</span><br><span class="line">-- 从订单信息表(order_info)中统计每个用户截止其每个下单日期的累积消费金额，以及每个用户在其每个下单日期的VIP等级。</span><br><span class="line">-- 用户vip等级根据累积消费金额计算，计算规则如下：</span><br><span class="line">-- 设累积消费总额为X，</span><br><span class="line">-- 若0=&lt;X&lt;10000,则vip等级为普通会员</span><br><span class="line">-- 若10000&lt;=X&lt;30000,则vip等级为青铜会员</span><br><span class="line">-- 若30000&lt;=X&lt;50000,则vip等级为白银会员</span><br><span class="line">-- 若50000&lt;=X&lt;80000,则vip为黄金会员</span><br><span class="line">-- 若80000&lt;=X&lt;100000,则vip等级为白金会员</span><br><span class="line">-- 若X&gt;=100000,则vip等级为钻石会员</span><br><span class="line"></span><br><span class="line">--①每个用户在每一天的消费金额</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       sum(total_amount) amount_by_day</span><br><span class="line">from order_info</span><br><span class="line">group by user_id, create_date;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-39-32.png" alt="Snipaste_2023-10-31_16-39-32" style="zoom: 33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--②每个用户的累计消费金额</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       sum(amount_by_day) over(partition by user_id order by create_date) amount_so_far</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                sum(total_amount) amount_by_day</span><br><span class="line">         from order_info</span><br><span class="line">         group by user_id, create_date</span><br><span class="line">     )t1;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-42-51.png" alt="Snipaste_2023-10-31_16-42-51" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">--③加上对应等级</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       amount_so_far,</span><br><span class="line">       case</span><br><span class="line">           when amount_so_far &gt;= 100000 then &#x27;钻石会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 80000 then &#x27;白金会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 50000 then &#x27;黄金会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 30000 then &#x27;白银会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 10000 then &#x27;青铜会员&#x27;</span><br><span class="line">           when amount_so_far &gt;= 0 then &#x27;普通会员&#x27;</span><br><span class="line">           end vip_level</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                sum(amount_by_day) over (partition by user_id order by create_date) amount_so_far</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         create_date,</span><br><span class="line">                         sum(total_amount) amount_by_day</span><br><span class="line">                  from order_info</span><br><span class="line">                  group by user_id, create_date</span><br><span class="line">              ) t1</span><br><span class="line">     )t2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_16-45-33.png" alt="Snipaste_2023-10-31_16-45-33" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">--2.5 查询首次下单后第二天连续下单的用户比率</span><br><span class="line">-- 从订单信息表(order_info)中查询首次下单后第二天仍然下单的用户占所有下单用户的比例，结果保留一位小数，使用百分数显示</span><br><span class="line">--①对用户和下单日期进行去重，以用户id进行分组并且给日期排序</span><br><span class="line">select user_id,</span><br><span class="line">       create_date,</span><br><span class="line">       rank() over (partition by user_id order by create_date) rk</span><br><span class="line">from (</span><br><span class="line">         select distinct user_id, create_date</span><br><span class="line">         from order_info</span><br><span class="line">)t1</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_19-28-34.png" alt="Snipaste_2023-10-31_19-28-34" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">--②过滤查询表①中的rk &lt;= 2的行</span><br><span class="line">select user_id,create_date</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                create_date,</span><br><span class="line">                rank() over (partition by user_id order by create_date) rk</span><br><span class="line">         from (</span><br><span class="line">                  select distinct user_id, create_date</span><br><span class="line">                  from order_info</span><br><span class="line">              ) t1</span><br><span class="line">     )t2</span><br><span class="line">where rk &lt;= 2;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_19-31-55.png" alt="Snipaste_2023-10-31_19-31-55" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">--③将查询表②中的每个用户的两个日期分成第一次下单日期和第二次下单日期</span><br><span class="line">select user_id,</span><br><span class="line">       min(create_date) first_create_date,</span><br><span class="line">       max(create_date) second_create_date</span><br><span class="line">from (</span><br><span class="line">         select user_id, create_date</span><br><span class="line">         from (</span><br><span class="line">                  select user_id,</span><br><span class="line">                         create_date,</span><br><span class="line">                         rank() over (partition by user_id order by create_date) rk</span><br><span class="line">                  from (</span><br><span class="line">                           select distinct user_id, create_date</span><br><span class="line">                           from order_info</span><br><span class="line">                       ) t1</span><br><span class="line">              ) t2</span><br><span class="line">         where rk &lt;= 2</span><br><span class="line">)t3</span><br><span class="line">group by user_id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_19-40-28.png" alt="Snipaste_2023-10-31_19-40-28" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">--④求比例</span><br><span class="line">select concat(round(sum(`if`(datediff(second_create_date,first_create_date) = 1,1,0))/count(*)*100,1),&#x27;%&#x27;) percentage</span><br><span class="line">from (</span><br><span class="line">         select user_id,</span><br><span class="line">                min(create_date) first_create_date,</span><br><span class="line">                max(create_date) second_create_date</span><br><span class="line">         from (</span><br><span class="line">                  select user_id, create_date</span><br><span class="line">                  from (</span><br><span class="line">                           select user_id,</span><br><span class="line">                                  create_date,</span><br><span class="line">                                  rank() over (partition by user_id order by create_date) rk</span><br><span class="line">                           from (</span><br><span class="line">                                    select distinct user_id, create_date</span><br><span class="line">                                    from order_info</span><br><span class="line">                                ) t1</span><br><span class="line">                       ) t2</span><br><span class="line">                  where rk &lt;= 2</span><br><span class="line">              ) t3</span><br><span class="line">         group by user_id</span><br><span class="line">     )t4;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-10-31_19-44-44.png" alt="Snipaste_2023-10-31_19-44-44" style="zoom:50%;">

<h1 id="第九章-分区表和分桶表"><a href="#第九章-分区表和分桶表" class="headerlink" title="第九章 分区表和分桶表"></a>第九章 分区表和分桶表</h1><h2 id="9-1-分区表"><a href="#9-1-分区表" class="headerlink" title="9.1 分区表"></a>9.1 分区表</h2><p>Hive中的分区就是把一张大表的数据按照业务需要分散的存储到多个目录，每个目录就称为该表的一个分区。在查询时通过where子句中的表达式选择查询所需要的分区，这样的查询效率会提高很多。</p>
<h3 id="9-1-1-分区表基本语法"><a href="#9-1-1-分区表基本语法" class="headerlink" title="9.1.1 分区表基本语法"></a>9.1.1 分区表基本语法</h3><h4 id="1-创建分区表"><a href="#1-创建分区表" class="headerlink" title="1. 创建分区表"></a>1. 创建分区表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--算上分区字段一共四个字段</span><br><span class="line">create table dept_partition</span><br><span class="line">(</span><br><span class="line">    deptno int,    --部门编号</span><br><span class="line">    dname  string, --部门名称</span><br><span class="line">    loc    string  --部门位置</span><br><span class="line">)</span><br><span class="line">    partitioned by (day string)</span><br><span class="line">    row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<h4 id="2-分区表读写数据"><a href="#2-分区表读写数据" class="headerlink" title="2. 分区表读写数据"></a>2. 分区表读写数据</h4><p>（1）写数据-load</p>
<p>在&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;路径上创建文件dept_20220401.log，并输入如下内容。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 datas]# vim dept_20220401.log</span><br><span class="line"></span><br><span class="line">10	行政部	1700</span><br><span class="line">20	财务部	1800</span><br></pre></td></tr></table></figure>

<p>装载语句：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/hive/datas/dept_20220401.log&#x27;</span><br><span class="line">into table dept_partition</span><br><span class="line">partition(day=&#x27;20220401&#x27;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-08-35.png" alt="Snipaste_2023-11-01_15-08-35" style="zoom:33%;">

<p>（2）写数据-insert</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 将day=&#x27;20220401&#x27;分区的数据插入到day=&#x27;20220402&#x27;分区，可执行如下装载语句</span><br><span class="line">insert overwrite table dept_partition partition (day = &#x27;20220402&#x27;)</span><br><span class="line">select deptno, dname, loc</span><br><span class="line">from dept_partition</span><br><span class="line">where day = &#x27;20220401&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-09-23.png" alt="Snipaste_2023-11-01_15-09-23" style="zoom:33%;">

<p>（3）读数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 查询分区表数据时，可以将分区字段看作表的伪列，可像使用其他字段一样使用分区字段。</span><br><span class="line">select deptno, dname, loc ,day</span><br><span class="line">from dept_partition</span><br><span class="line">where day = &#x27;20220401&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-12-08.png" alt="Snipaste_2023-11-01_15-12-08" style="zoom:33%;">

<h4 id="3-分区表基本操作"><a href="#3-分区表基本操作" class="headerlink" title="3. 分区表基本操作"></a>3. 分区表基本操作</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- 1）查看所有分区信息</span><br><span class="line">show partitions dept_partition;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-20-14.png" alt="Snipaste_2023-11-01_15-20-14" style="zoom:33%;">

<p>当然查看hadoop102web端也能看到：</p>
<img src="Snipaste_2023-11-01_15-18-40.png" alt="Snipaste_2023-11-01_15-18-40" style="zoom:50%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 2）增加分区</span><br><span class="line">--（1）创建单个分区</span><br><span class="line">alter table dept_partition</span><br><span class="line">add partition(day=&#x27;20220403&#x27;); --执行这个命令相当于在HDFS上增加了一个目录，并在hive的元数据中增加了一条分区信息</span><br><span class="line">show partitions dept_partition;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-23-13.png" alt="Snipaste_2023-11-01_15-23-13" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--（2）同时创建多个分区（分区之间不能有逗号）</span><br><span class="line">alter table dept_partition</span><br><span class="line">add partition(day=&#x27;20220404&#x27;) partition(day=&#x27;20220405&#x27;);</span><br><span class="line">show partitions dept_partition;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-23-56.png" alt="Snipaste_2023-11-01_15-23-56" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-- 3）删除分区</span><br><span class="line">-- （1）删除单个分区</span><br><span class="line">alter table dept_partition</span><br><span class="line">drop partition (day=&#x27;20220403&#x27;);</span><br><span class="line">-- （2）同时删除多个分区（分区之间必须有逗号）</span><br><span class="line">alter table dept_partition</span><br><span class="line">drop partition (day=&#x27;20220404&#x27;), partition(day=&#x27;20220405&#x27;);</span><br></pre></td></tr></table></figure>

<p>4）修复分区</p>
<p>Hive将分区表的所有分区信息都保存在了元数据中，只有元数据与HDFS上的分区路径一致时，分区表才能正常读写数据。若用户手动创建&#x2F;删除分区路径，Hive都是感知不到的，这样就会导致Hive的元数据和HDFS的分区路径不一致。再比如，若分区表为外部表，用户执行drop partition命令后，分区元数据会被删除，而HDFS的分区路径不会被删除，同样会导致Hive的元数据和HDFS的分区路径不一致。</p>
<p>若出现元数据和HDFS路径不一致的情况，可通过如下几种手段进行修复。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alter table dept_partition add partition (day = &#x27;20220403&#x27;);</span><br><span class="line">alter table dept_partition drop partition (day = &#x27;20220403&#x27;);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_15-35-02.png" alt="Snipaste_2023-11-01_15-35-02" style="zoom:50%;">

<h3 id="9-1-2-二级分区表"><a href="#9-1-2-二级分区表" class="headerlink" title="9.1.2 二级分区表"></a>9.1.2 二级分区表</h3><p>思考：如果一天内的日志数据量也很大，如何再将数据拆分?答案是二级分区表，例如可以在按天分区的基础上，再对每天的数据按小时进行分区。</p>
<p>在实际项目中，分区表都是按照时间分区的。因为Hive做的是批处理（离线处理），也就是Hive攒下一批数据后做一次统一的处理，大多数离线项目中，一批也就是一天</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">-- 1）二级分区表建表语句</span><br><span class="line">create table dept_partition2(</span><br><span class="line">    deptno int,    -- 部门编号</span><br><span class="line">    dname string, -- 部门名称</span><br><span class="line">    loc string     -- 部门位置</span><br><span class="line">)</span><br><span class="line">partitioned by (day string, hour string) --采用二级分区</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 2）数据装载语句</span><br><span class="line">load data local inpath &#x27;/opt/module/hive/datas/dept_20220401.log&#x27;</span><br><span class="line">into table dept_partition2</span><br><span class="line">partition(day=&#x27;20220401&#x27;, hour=&#x27;12&#x27;);</span><br><span class="line">-- 3）查询分区数据</span><br><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from dept_partition2</span><br><span class="line">where day=&#x27;20220401&#x27; and hour=&#x27;12&#x27;;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_16-27-48.png" alt="Snipaste_2023-11-01_16-27-48" style="zoom:33%;">

<h3 id="9-1-3-动态分区"><a href="#9-1-3-动态分区" class="headerlink" title="9.1.3 动态分区"></a>9.1.3 动态分区</h3><p>动态分区是指向分区表insert数据时，被写往的分区不由用户指定，而是由每行数据的最后一个字段的值来动态的决定。<strong>使用动态分区，可只用一个insert语句将数据写入多个分区。</strong></p>
<p>（1）动态分区相关参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">-- （1）动态分区功能总开关（默认true，开启）</span><br><span class="line">set hive.exec.dynamic.partition=true;</span><br><span class="line">-- （2）严格模式和非严格模式</span><br><span class="line">-- 动态分区的模式，默认strict（严格模式），要求必须指定至少一个分区为静态分区，nonstrict（非严格模式）允许所有的分区字段都使用动态分区。</span><br><span class="line">set hive.exec.dynamic.partition.mode=nonstrict;</span><br><span class="line">-- （3）一条insert语句可同时创建的最大的分区个数，默认为1000。</span><br><span class="line">set hive.exec.max.dynamic.partitions=1000;</span><br><span class="line">-- （4）单个Mapper或者Reducer可同时创建的最大的分区个数，默认为100。</span><br><span class="line">set hive.exec.max.dynamic.partitions.pernode=100;</span><br><span class="line">-- （5）一条insert语句可以创建的最大的文件个数，默认100000。</span><br><span class="line">set hive.exec.max.created.files=100000;</span><br><span class="line">-- （6）当查询结果为空时且进行动态分区时，是否抛出异常，默认false。</span><br><span class="line">set hive.error.on.empty.partition=false;</span><br></pre></td></tr></table></figure>

<p>（2）案例实操</p>
<p>需求：将dept表中的数据按照地区（loc字段），插入到目标表dept_partition_dynamic的相应分区中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">-- （1）创建目标分区表</span><br><span class="line">create table dept_partition_dynamic(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">partitioned by (loc int)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">-- 2）设置动态分区</span><br><span class="line">set hive.exec.dynamic.partition.mode = nonstrict;</span><br><span class="line">insert into table dept_partition_dynamic</span><br><span class="line">partition(loc)  --不需要声明指定某个分区，只需要声明分区字段即可</span><br><span class="line">select</span><br><span class="line">    deptno,</span><br><span class="line">    dname,</span><br><span class="line">    loc  --按照loc字段的值进行动态分区</span><br><span class="line">from default.dept;</span><br><span class="line">-- （3）查看目标分区表的分区情况</span><br><span class="line">show partitions dept_partition_dynamic;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_19-22-32.png" alt="Snipaste_2023-11-01_19-22-32" style="zoom:33%;">

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select *from dept_partition_dynamic;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_19-24-28.png" alt="Snipaste_2023-11-01_19-24-28" style="zoom:33%;">

<p>在HDFS中：&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;partition_bucket.db&#x2F;dept_partition_dynamic&#x2F;loc&#x3D;1700目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">10	行政部</span><br><span class="line">40	销售部</span><br></pre></td></tr></table></figure>

<p>&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;partition_bucket.db&#x2F;dept_partition_dynamic&#x2F;loc&#x3D;1800目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">20	财务部</span><br></pre></td></tr></table></figure>

<p>&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;partition_bucket.db&#x2F;dept_partition_dynamic&#x2F;loc&#x3D;1900目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">30	教学部</span><br></pre></td></tr></table></figure>

<h2 id="9-2-分桶表"><a href="#9-2-分桶表" class="headerlink" title="9.2 分桶表"></a>9.2 分桶表</h2><p>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围划分，分区针对的是数据的存储路径，分桶针对的是数据文件。</p>
<p>分桶表的基本原理是，首先为每行数据计算一个指定字段的数据的hash值，然后模以（%）一个指定的分桶数，最后将取模运算结果相同的行，写入同一个文件中，这个文件就称为一个分桶（bucket）。将数据按照指定的字段进行分成多个桶中去，说白了就是将数据按照字段进行划分，可以将数据按照字段划分到<strong>多个文件</strong>当中去。</p>
<p>一个表没有分区直接分桶，就将表整体去分桶。如果一个表已经分区了，就在每个分好区的表内进行分桶。</p>
<h3 id="9-2-1-分桶表基本语法"><a href="#9-2-1-分桶表基本语法" class="headerlink" title="9.2.1 分桶表基本语法"></a>9.2.1 分桶表基本语法</h3><p>（1）建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table stu_buck(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">clustered by(id) [sorted by(id)] into 4 buckets  --分桶字段是表中已经存在的字段，分4个桶,[还可以按id字段进行排序，分桶排序表]</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<p>（2）数据装载</p>
<p>在&#x2F;opt&#x2F;module&#x2F;hive&#x2F;datas&#x2F;路径上创建student.txt文件，并输入如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1001	student1</span><br><span class="line">1002	student2</span><br><span class="line">1003	student3</span><br><span class="line">1004	student4</span><br><span class="line">1005	student5</span><br><span class="line">1006	student6</span><br><span class="line">1007	student7</span><br><span class="line">1008	student8</span><br><span class="line">1009	student9</span><br><span class="line">1010	student10</span><br><span class="line">1011	student11</span><br><span class="line">1012	student12</span><br><span class="line">1013	student13</span><br><span class="line">1014	student14</span><br><span class="line">1015	student15</span><br><span class="line">1016	student16</span><br></pre></td></tr></table></figure>

<p>（3）导入数据到分桶表中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/hive/datas/student.txt&#x27;</span><br><span class="line">into table stu_buck;</span><br></pre></td></tr></table></figure>

<p>（4）查看创建的分桶表中是否分成4个桶</p>
<p><img src="Snipaste_2023-11-01_19-47-52.png" alt="Snipaste_2023-11-01_19-47-52"></p>
<p>（5）观察每个分桶表中的数据，实际上是按照id字段的hash值分桶的</p>
<p>000000_0:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1016	student16</span><br><span class="line">1012	student12</span><br><span class="line">1008	student8</span><br><span class="line">1004	student4</span><br></pre></td></tr></table></figure>

<p>000001_0:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1009	student9</span><br><span class="line">1005	student5</span><br><span class="line">1001	student1</span><br><span class="line">1013	student13</span><br></pre></td></tr></table></figure>

<p>000002_0:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1010	student10</span><br><span class="line">1002	student2</span><br><span class="line">1006	student6</span><br><span class="line">1014	student14</span><br></pre></td></tr></table></figure>

<p>000003_0:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1003	student3</span><br><span class="line">1011	student11</span><br><span class="line">1007	student7</span><br><span class="line">1015	student15</span><br></pre></td></tr></table></figure>

<h1 id="第十章-文件格式和压缩"><a href="#第十章-文件格式和压缩" class="headerlink" title="第十章 文件格式和压缩"></a>第十章 文件格式和压缩</h1><h2 id="10-1-Hadoop压缩概述"><a href="#10-1-Hadoop压缩概述" class="headerlink" title="10.1 Hadoop压缩概述"></a>10.1 Hadoop压缩概述</h2><img src="Snipaste_2023-11-01_20-24-12.png" alt="Snipaste_2023-11-01_20-24-12" style="zoom:50%;">

<img src="Snipaste_2023-11-01_20-26-33.png" alt="Snipaste_2023-11-01_20-26-33" style="zoom:50%;">

<h2 id="10-2-Hive文件格式"><a href="#10-2-Hive文件格式" class="headerlink" title="10.2 Hive文件格式"></a>10.2 Hive文件格式</h2><p>为Hive表中的数据选择一个合适的文件格式，对提高查询性能的提高是十分有益的。Hive表数据的存储格式，可以选择text file、orc、parquet、sequence file等。</p>
<h3 id="10-2-1-Text-File"><a href="#10-2-1-Text-File" class="headerlink" title="10.2.1 Text File"></a>10.2.1 Text File</h3><p>文本文件是Hive默认使用的文件格式，文本文件中的一行内容，就对应Hive表中的一行记录。默认格式，数据不做压缩，磁盘开销大，数据解析开销大。</p>
<p>建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create table textfile_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure>

<h3 id="10-2-2-ORC"><a href="#10-2-2-ORC" class="headerlink" title="10.2.2 ORC"></a>10.2.2 ORC</h3><p>ORC（Optimized Row Columnar）file format是Hive 0.11版里引入的一种****列式存储****的文件格式。ORC文件能够提高Hive读写数据和处理数据的性能。与列式存储相对的是行式存储，下图是两者的对比：</p>
<img src="Snipaste_2023-11-01_20-35-19.png" alt="Snipaste_2023-11-01_20-35-19" style="zoom:50%;">

<p>（1）行存储的特点</p>
<p>查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。select *效率高</p>
<p>（2）列存储的特点</p>
<p>因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法。select 某些字段 效率高</p>
<p><strong>前文提到的text file和sequence file都是基于行存储的，orc和parquet是基于列式存储的。</strong></p>
<p><img src="Snipaste_2023-11-01_20-50-27.png" alt="Snipaste_2023-11-01_20-50-27"></p>
<p>每个Orc文件由Header、Body和Tail三部分组成。</p>
<p>其中Header内容为ORC，用于表示文件类型。</p>
<p>Body由1个或多个stripe组成，每个stripe一般为HDFS的块大小，每一个stripe包含多条记录，这些记录按照列进行独立存储，每个stripe里有三部分组成，分别是Index Data，Row Data，Stripe Footer。</p>
<p><strong>Index Data：</strong>一个轻量级的index，默认是为各列每隔1W行做一个索引。每个索引会记录第n万行的位置，和最近一万行的最大值和最小值等信息。</p>
<p><strong>Row Data：</strong>存的是具体的数据，按列进行存储，并对每个列进行编码，分成多个Stream来存储。</p>
<p><strong>Stripe Footer：</strong>存放的是各个Stream的位置以及各column的编码信息。</p>
<p>Tail由File Footer和PostScript组成。File Footer中保存了各Stripe的其实位置、索引长度、数据长度等信息，各Column的统计信息等；PostScript记录了整个文件的压缩类型以及File Footer的长度信息等。</p>
<p>在读取ORC文件时，会先从最后一个字节读取PostScript长度，进而读取到PostScript，从里面解析到File Footer长度，进而读取FileFooter，从中解析到各个Stripe信息，再读各个Stripe，<strong>即从后往前读。</strong></p>
<p>（3）建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table orc_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as orc</span><br><span class="line">tblproperties (property_name=property_value, ...);  --设置参数</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_21-02-32.png" alt="Snipaste_2023-11-01_21-02-32" style="zoom:50%;">

<p>其中orc.stripe.size应该设置成和Hadoop中block大小一致，故最好设置成128M（134217728）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">create table test_orc</span><br><span class="line">(</span><br><span class="line">    id int,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">stored as orc;</span><br><span class="line"></span><br><span class="line">show create table test_orc;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_21-19-14.png" alt="Snipaste_2023-11-01_21-19-14" style="zoom:50%;">

<h3 id="10-2-3-Parquet"><a href="#10-2-3-Parquet" class="headerlink" title="10.2.3 Parquet"></a>10.2.3 Parquet</h3><p>Parquet文件是Hadoop生态中的一个通用的文件格式，它也是一个列式存储的文件格式。</p>
<p><img src="Snipaste_2023-11-01_21-27-51.png" alt="Snipaste_2023-11-01_21-27-51"></p>
<p>上图展示了一个Parquet文件的基本结构，文件的首尾都是该文件的Magic Code，用于校验它是否是一个Parquet文件。</p>
<p>首尾中间由若干个Row Group和一个Footer（File Meta Data）组成。</p>
<p>每个Row Group包含多个Column Chunk，每个Column Chunk包含多个Page。以下是Row Group、Column Chunk和Page三个概念的说明：</p>
<p><strong>行组（Row Group）</strong>：一个行组对应逻辑表中的若干行。 </p>
<p><strong>列块（Column Chunk）</strong>：一个行组中的一列保存在一个列块中。 </p>
<p><strong>页（Page）</strong>：一个列块的数据会划分为若干个页。 </p>
<p>Footer（File Meta Data）中存储了每个行组（Row Group）中的每个列快（Column Chunk）的元数据信息，元数据信息包含了该列的数据类型、该列的编码方式、该类的Data Page位置等信息。</p>
<p>（1）建表语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Create table parquet_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as parquet</span><br><span class="line">tblproperties (property_name=property_value, ...);  --设置参数</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-01_21-32-04.png" alt="Snipaste_2023-11-01_21-32-04" style="zoom:50%;">

<p>三种文件格式的性能比较：</p>
<p>压缩比比较：ORC&gt;Parquet&gt;textFile</p>
<p>存储文件的查询效率比较：ORC&gt;TextFile&gt;Parquet</p>
<h2 id="10-3-压缩"><a href="#10-3-压缩" class="headerlink" title="10.3 压缩"></a>10.3 压缩</h2><p>在Hive表中和计算过程中，保持数据的压缩，对磁盘空间的有效利用和提高查询性能都是十分有益的。</p>
<p><strong>表中的压缩即为表中存储的数据的压缩，计算过程的压缩即为MapReduce各个阶段输出的数据的压缩。</strong></p>
<h3 id="10-3-1-Hive表数据进行压缩"><a href="#10-3-1-Hive表数据进行压缩" class="headerlink" title="10.3.1 Hive表数据进行压缩"></a>10.3.1 Hive表数据进行压缩</h3><p>在Hive中，不同文件类型的表，声明数据压缩的方式是不同的。</p>
<p>（1）TextFile</p>
<p>若一张表的文件类型为TextFile，若需要对该表中的数据进行压缩，多数情况下，无需在建表语句做出声明。直接将压缩后的文件导入到该表即可，Hive在查询表中数据时，可自动识别其压缩格式，进行解压。</p>
<p>需要注意的是，在执行往表中导入数据的SQL语句时，用户需设置以下参数，来保证写入表中的数据是被压缩的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--SQL语句的最终输出结果是否压缩</span><br><span class="line">set hive.exec.compress.output=true;</span><br><span class="line">--输出结果的压缩格式（以下示例为snappy）</span><br><span class="line">set mapreduce.output.fileoutputformat.compress.codec =org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>

<p>（2）ORC</p>
<p>若一张表的文件类型为ORC，若需要对该表数据进行压缩，需在建表语句中声明压缩格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table orc_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as orc</span><br><span class="line">tblproperties (&quot;orc.compress&quot;=&quot;snappy&quot;);</span><br></pre></td></tr></table></figure>

<p>（3）Parquet</p>
<p>若一张表的文件类型为Parquet，若需要对该表数据进行压缩，需在建表语句中声明压缩格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">create table orc_table</span><br><span class="line">(column_specs)</span><br><span class="line">stored as parquet</span><br><span class="line">tblproperties (&quot;parquet.compression&quot;=&quot;snappy&quot;);</span><br></pre></td></tr></table></figure>

<h3 id="10-3-2-计算过程中使用压缩"><a href="#10-3-2-计算过程中使用压缩" class="headerlink" title="10.3.2 计算过程中使用压缩"></a>10.3.2 计算过程中使用压缩</h3><p>（1）单个MR的中间结果进行压缩</p>
<p>单个MR的中间结果是指Mapper输出的数据，对其进行压缩可降低shuffle阶段的网络IO，可通过以下参数进行配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--开启MapReduce中间数据压缩功能</span><br><span class="line">set mapreduce.map.output.compress=true;</span><br><span class="line">--设置MapReduce中间数据数据的压缩方式（以下示例为snappy）</span><br><span class="line">set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>

<p>（2）单条SQL语句的中间结果进行压缩</p>
<p>单条SQL语句的中间结果是指，两个MR（一条SQL语句可能需要通过MR进行计算）之间的临时数据，可通过以下参数进行配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--是否对两个MR之间的临时数据进行压缩</span><br><span class="line">set hive.exec.compress.intermediate=true;</span><br><span class="line">--压缩格式（以下示例为snappy）</span><br><span class="line">set hive.intermediate.compression.codec= org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure>

<h1 id="第十一章-企业级调优"><a href="#第十一章-企业级调优" class="headerlink" title="第十一章 企业级调优"></a>第十一章 企业级调优</h1><h2 id="11-1-计算资源配置"><a href="#11-1-计算资源配置" class="headerlink" title="11.1 计算资源配置"></a>11.1 计算资源配置</h2><h3 id="11-1-1-Yarn资源配置"><a href="#11-1-1-Yarn资源配置" class="headerlink" title="11.1.1 Yarn资源配置"></a>11.1.1 Yarn资源配置</h3><p>（1）Yarn配置说明</p>
<p>需要调整的Yarn参数均与CPU、内存等资源有关，核心配置参数如下</p>
<p>①yarn.nodemanager.resource.memory-mb</p>
<p>该参数的含义是，一个NodeManager节点分配给Container使用的内存。该参数的配置，取决于NodeManager所在节点的总内存容量和该节点运行的其他服务的数量。</p>
<p>考虑上述因素，此处可将该参数设置为64G，如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>65536<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>②yarn.nodemanager.resource.cpu-vcores</p>
<p>该参数的含义是，一个NodeManager节点分配给Container使用的CPU核数。该参数的配置，同样取决于NodeManager所在节点的总CPU核数和该节点运行的其他服务。</p>
<p>考虑上述因素，此处可将该参数设置为16。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>16<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>③yarn.scheduler.maximum-allocation-mb</p>
<p>该参数的含义是，单个Container能够使用的最大内存。推荐配置如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>16384<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>④yarn.scheduler.minimum-allocation-mb</p>
<p>该参数的含义是，单个Container能够使用的最小内存，推荐配置如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）Yarn配置实操</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd /opt/module/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[root@hadoop102 hadoop]# vim yarn-site.xml </span><br></pre></td></tr></table></figure>

<p>修改之后，分发配置文件，并重启Yarn</p>
<p>注意：以上参数要根据自己电脑的配置调整。16G运存的电脑建议不要调整了。</p>
<h3 id="11-1-2-MapRuduce资源配置"><a href="#11-1-2-MapRuduce资源配置" class="headerlink" title="11.1.2 MapRuduce资源配置"></a>11.1.2 MapRuduce资源配置</h3><p>MapReduce资源配置主要包括Map Task的内存和CPU核数，以及Reduce Task的内存和CPU核数。核心配置参数如下：</p>
<p>1）mapreduce.map.memory.mb	</p>
<p>该参数的含义是，单个Map Task申请的container容器内存大小，其默认值为1024。该值不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。</p>
<p>该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.map.memory.mb=2048;</span><br></pre></td></tr></table></figure>

<p>2）mapreduce.map.cpu.vcores	</p>
<p>该参数的含义是，单个Map Task申请的container容器cpu核数，其默认值为1。该值一般无需调整。</p>
<p>3）mapreduce.reduce.memory.mb		</p>
<p>该参数的含义是，单个Reduce Task申请的container容器内存大小，其默认值为1024。该值同样不能超出yarn.scheduler.maximum-allocation-mb和yarn.scheduler.minimum-allocation-mb规定的范围。</p>
<p>该参数需要根据不同的计算任务单独进行配置，在hive中，可直接使用如下方式为每个SQL语句单独进行配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapreduce.reduce.memory.mb=2048;</span><br></pre></td></tr></table></figure>

<p>4）mapreduce.reduce.cpu.vcores	</p>
<p>该参数的含义是，单个Reduce Task申请的container容器cpu核数，其默认值为1。该值一般无需调整。</p>
<h2 id="11-2-测试用表（略）"><a href="#11-2-测试用表（略）" class="headerlink" title="11.2 测试用表（略）"></a>11.2 测试用表（略）</h2><h2 id="11-3-Explain查看执行计划（重点）"><a href="#11-3-Explain查看执行计划（重点）" class="headerlink" title="11.3 Explain查看执行计划（重点）"></a>11.3 Explain查看执行计划（重点）</h2><h3 id="11-3-1-Explain执行计划概述"><a href="#11-3-1-Explain执行计划概述" class="headerlink" title="11.3.1 Explain执行计划概述"></a>11.3.1 Explain执行计划概述</h3><p>Explain呈现的执行计划，由一系列Stage组成，这一系列Stage具有依赖关系，每个Stage对应一个MapReduce Job，或者一个文件系统操作等。</p>
<p>若某个Stage对应的一个MapReduce Job，其Map端和Reduce端的计算逻辑分别由Map Operator Tree和Reduce Operator Tree进行描述，Operator Tree由一系列的Operator组成，一个Operator代表在Map或Reduce阶段的一个单一的逻辑操作，例如TableScan Operator，Select Operator，Join Operator等。</p>
<p>下图是由一个执行计划绘制而成：</p>
<img src="图片111.png" alt="图片111" style="zoom: 67%;">

<p>常见的Operator及其作用如下：</p>
<ul>
<li>TableScan：表扫描操作，通常map端第一个操作肯定是表扫描操作</li>
<li>Select Operator：选取操作</li>
<li>Group By Operator：分组聚合操作</li>
<li>Reduce Output Operator：输出到 reduce 操作</li>
<li>Filter Operator：过滤操作</li>
<li>Join Operator：join 操作</li>
<li>File Output Operator：文件输出操作</li>
<li>Fetch Operator 客户端获取数据操作</li>
</ul>
<h3 id="11-3-2-基本语法"><a href="#11-3-2-基本语法" class="headerlink" title="11.3.2 基本语法"></a>11.3.2 基本语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN [FORMATTED | EXTENDED | DEPENDENCY] query-sql</span><br></pre></td></tr></table></figure>

<p>注：FORMATTED、EXTENDED、DEPENDENCY关键字为可选项，各自作用如下。</p>
<ul>
<li>FORMATTED：将执行计划以JSON字符串的形式输出</li>
<li>EXTENDED：输出执行计划中的额外信息，通常是读写的文件名等信息</li>
<li>DEPENDENCY：输出执行计划读取的表及分区</li>
</ul>
<h3 id="11-3-3-案例实操"><a href="#11-3-3-案例实操" class="headerlink" title="11.3.3 案例实操"></a>11.3.3 案例实操</h3><p>（1）部署可视化工具</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# cd dist/</span><br><span class="line">[root@hadoop102 dist]# python -m SimpleHTTPServer 8900</span><br><span class="line">Serving HTTP on 0.0.0.0 port 8900 ...</span><br></pre></td></tr></table></figure>

<p>（2）访问hadoop102:8900</p>
<p><img src="Snipaste_2023-11-03_14-59-36.png" alt="Snipaste_2023-11-03_14-59-36"></p>
<p>（3）查看下面这条语句的执行计划</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">explain formatted</span><br><span class="line">select order_id,</span><br><span class="line">       sum(sku_num) num</span><br><span class="line">from order_detail</span><br><span class="line">group by order_id;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;STAGE DEPENDENCIES&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Stage-1&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;ROOT STAGE&quot;</span><span class="punctuation">:</span><span class="string">&quot;TRUE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;Stage-0&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;DEPENDENT STAGES&quot;</span><span class="punctuation">:</span><span class="string">&quot;Stage-1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;STAGE PLANS&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Stage-1&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Map Reduce&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Map Operator Tree:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;TableScan&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;alias:&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_detail&quot;</span><span class="punctuation">,</span><span class="attr">&quot;columns:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;order_id&quot;</span><span class="punctuation">,</span><span class="string">&quot;sku_num&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;database:&quot;</span><span class="punctuation">:</span><span class="string">&quot;functions&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 99 Data size: 2756 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;table:&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_detail&quot;</span><span class="punctuation">,</span><span class="attr">&quot;isTempTable:&quot;</span><span class="punctuation">:</span><span class="string">&quot;false&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;TS_0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;children&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Select Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;expressions:&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_id (type: string), sku_num (type: int)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;columnExprMap:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;BLOCK__OFFSET__INSIDE__FILE&quot;</span><span class="punctuation">:</span><span class="string">&quot;BLOCK__OFFSET__INSIDE__FILE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;INPUT__FILE__NAME&quot;</span><span class="punctuation">:</span><span class="string">&quot;INPUT__FILE__NAME&quot;</span><span class="punctuation">,</span><span class="attr">&quot;ROW__ID&quot;</span><span class="punctuation">:</span><span class="string">&quot;ROW__ID&quot;</span><span class="punctuation">,</span><span class="attr">&quot;create_date&quot;</span><span class="punctuation">:</span><span class="string">&quot;create_date&quot;</span><span class="punctuation">,</span><span class="attr">&quot;order_detail_id&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_detail_id&quot;</span><span class="punctuation">,</span><span class="attr">&quot;order_id&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_id&quot;</span><span class="punctuation">,</span><span class="attr">&quot;price&quot;</span><span class="punctuation">:</span><span class="string">&quot;price&quot;</span><span class="punctuation">,</span><span class="attr">&quot;sku_id&quot;</span><span class="punctuation">:</span><span class="string">&quot;sku_id&quot;</span><span class="punctuation">,</span><span class="attr">&quot;sku_num&quot;</span><span class="punctuation">:</span><span class="string">&quot;sku_num&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;outputColumnNames:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;order_id&quot;</span><span class="punctuation">,</span><span class="string">&quot;sku_num&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 99 Data size: 2756 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;SEL_7&quot;</span><span class="punctuation">,</span><span class="attr">&quot;children&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Group By Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;aggregations:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;sum(sku_num)&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;columnExprMap:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_id&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;keys:&quot;</span><span class="punctuation">:</span><span class="string">&quot;order_id (type: string)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;mode:&quot;</span><span class="punctuation">:</span><span class="string">&quot;hash&quot;</span><span class="punctuation">,</span><span class="attr">&quot;outputColumnNames:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;_col0&quot;</span><span class="punctuation">,</span><span class="string">&quot;_col1&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 99 Data size: 2756 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;GBY_8&quot;</span><span class="punctuation">,</span><span class="attr">&quot;children&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Reduce Output Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;columnExprMap:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;KEY._col0&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;VALUE._col0&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;key expressions:&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col0 (type: string)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;sort order:&quot;</span><span class="punctuation">:</span><span class="string">&quot;+&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Map-reduce partition columns:&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col0 (type: string)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 99 Data size: 2756 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;value expressions:&quot;</span><span class="punctuation">:</span><span class="string">&quot;_col1 (type: bigint)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;RS_9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;Execution mode:&quot;</span><span class="punctuation">:</span><span class="string">&quot;vectorized&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Reduce Operator Tree:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Group By Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;aggregations:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;sum(VALUE._col0)&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;columnExprMap:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;_col0&quot;</span><span class="punctuation">:</span><span class="string">&quot;KEY._col0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;keys:&quot;</span><span class="punctuation">:</span><span class="string">&quot;KEY._col0 (type: string)&quot;</span><span class="punctuation">,</span><span class="attr">&quot;mode:&quot;</span><span class="punctuation">:</span><span class="string">&quot;mergepartial&quot;</span><span class="punctuation">,</span><span class="attr">&quot;outputColumnNames:&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;_col0&quot;</span><span class="punctuation">,</span><span class="string">&quot;_col1&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 49 Data size: 1364 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;GBY_4&quot;</span><span class="punctuation">,</span><span class="attr">&quot;children&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;File Output Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;compressed:&quot;</span><span class="punctuation">:</span><span class="string">&quot;false&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Statistics:&quot;</span><span class="punctuation">:</span><span class="string">&quot;Num rows: 49 Data size: 1364 Basic stats: COMPLETE Column stats: NONE&quot;</span><span class="punctuation">,</span><span class="attr">&quot;table:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;input format:&quot;</span><span class="punctuation">:</span><span class="string">&quot;org.apache.hadoop.mapred.SequenceFileInputFormat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;output format:&quot;</span><span class="punctuation">:</span><span class="string">&quot;org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat&quot;</span><span class="punctuation">,</span><span class="attr">&quot;serde:&quot;</span><span class="punctuation">:</span><span class="string">&quot;org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;FS_6&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;Stage-0&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;Fetch Operator&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;limit:&quot;</span><span class="punctuation">:</span><span class="string">&quot;-1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;Processor Tree:&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;ListSink&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;OperatorId:&quot;</span><span class="punctuation">:</span><span class="string">&quot;LIST_SINK_10&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2023-11-03_15-05-06.png" alt="Snipaste_2023-11-03_15-05-06"></p>
<p>案例2：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain select sum(score) from score_info;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">STAGE DEPENDENCIES<span class="punctuation">:</span>   <span class="comment">//各个 stage 之间的依赖性</span></span><br><span class="line">  Stage<span class="number">-1</span> is a root stage        <span class="comment">//Stage-1 是根 stage，说明这是开始的 stage</span></span><br><span class="line">  Stage<span class="number">-0</span> depends on stages<span class="punctuation">:</span> Stage<span class="number">-1</span>        <span class="comment">//Stage-0 依赖 Stage-1，Stage-1 执行完成后执行Stage-0</span></span><br><span class="line"><span class="string">&quot;&quot;</span></span><br><span class="line">STAGE PLANS<span class="punctuation">:</span>     <span class="comment">//各个 stage 的执行计划</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-1</span></span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree<span class="punctuation">:</span>     <span class="comment">//MAP 端的执行计划树</span></span><br><span class="line">          TableScan       <span class="comment">//TableScan：表扫描操作，map 端第一个操作肯定是加载表，所以就是表扫描操作</span></span><br><span class="line">            alias<span class="punctuation">:</span> score_info     <span class="comment">//alias：表名称</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8130</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE  <span class="comment">//Statistics：表统计信息，包含表中数据条数，数据大小等</span></span><br><span class="line">            Select Operator     <span class="comment">//Select Operator： 选取操作</span></span><br><span class="line">              expressions<span class="punctuation">:</span> score (type<span class="punctuation">:</span> int)      <span class="comment">//expressions：需要的字段名称及字段类型</span></span><br><span class="line">              outputColumnNames<span class="punctuation">:</span> score        <span class="comment">//outputColumnNames：输出的列名称</span></span><br><span class="line">              Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8130</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE <span class="comment">//Statistics：表统计信息，包含表中数据条数，数据大小等</span></span><br><span class="line">              Group By Operator    <span class="comment">//Group By Operator：分组聚合操作</span></span><br><span class="line">                aggregations<span class="punctuation">:</span> sum(score)     <span class="comment">//aggregations：显示聚合函数信息</span></span><br><span class="line">                mode<span class="punctuation">:</span> hash      <span class="comment">//mode：聚合模式，值有 hash：随机聚合，就是 hash partition；partial：局部聚合；final：最终聚合</span></span><br><span class="line">                outputColumnNames<span class="punctuation">:</span> _col0      <span class="comment">//outputColumnNames：聚合之后输出列名</span></span><br><span class="line">                Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE  <span class="comment">//Statistics： 表统计信息，包含分组聚合之后的数据条数，数据大小等</span></span><br><span class="line">                Reduce Output Operator    <span class="comment">//Reduce Output Operator：输出到 reduce 操作</span></span><br><span class="line">                  sort order<span class="punctuation">:</span>   <span class="comment">//sort order：值为空 不排序；值为 + 正序排序，值为 - 倒序排序；值为 +- 排序的列为两列，第一列为正序，第二列为倒序</span></span><br><span class="line">                  Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">                  value expressions<span class="punctuation">:</span> _col0 (type<span class="punctuation">:</span> bigint)</span><br><span class="line">      Execution mode<span class="punctuation">:</span> vectorized</span><br><span class="line">      Reduce Operator Tree<span class="punctuation">:</span>     <span class="comment">//Reduce 端的执行计划树</span></span><br><span class="line">        Group By Operator    <span class="comment">//Group By Operator：分组聚合操作</span></span><br><span class="line">          aggregations<span class="punctuation">:</span> sum(VALUE._col0)</span><br><span class="line">          mode<span class="punctuation">:</span> mergepartial</span><br><span class="line">          outputColumnNames<span class="punctuation">:</span> _col0</span><br><span class="line">          Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">          File Output Operator    <span class="comment">//File Output Operator：文件输出操作</span></span><br><span class="line">            compressed<span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span>     <span class="comment">//compressed：是否压缩</span></span><br><span class="line">            Statistics<span class="punctuation">:</span> Num rows<span class="punctuation">:</span> <span class="number">1</span> Data size<span class="punctuation">:</span> <span class="number">8</span> Basic stats<span class="punctuation">:</span> COMPLETE Column stats<span class="punctuation">:</span> NONE</span><br><span class="line">            table<span class="punctuation">:</span>     <span class="comment">//table：表的信息，包含输入输出文件格式化方式，序列化方式等</span></span><br><span class="line">                input format<span class="punctuation">:</span> org.apache.hadoop.mapred.SequenceFileInputFormat</span><br><span class="line">                output format<span class="punctuation">:</span> org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span><br><span class="line">                serde<span class="punctuation">:</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"><span class="string">&quot;&quot;</span></span><br><span class="line">  Stage<span class="punctuation">:</span> Stage<span class="number">-0</span></span><br><span class="line">    Fetch Operator     <span class="comment">//Fetch Operator 客户端获取数据操作</span></span><br><span class="line">      limit<span class="punctuation">:</span> <span class="number">-1</span>      <span class="comment">//limit，值为 -1 表示不限制条数，其他值为限制的条数</span></span><br><span class="line">      Processor Tree<span class="punctuation">:</span></span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>

<p><strong>一个 HIVE 查询被转换为一个由一个或多个 stage 组成的序列（有向无环图 DAG）。这些 stage 可以是 MapReduce stage，也可以是负责元数据存储的 stage，也可以是负责文件系统的操作（比如移动和重命名）的 stage</strong>。</p>
<p>对于两个写法不同的sql，我们可以观察它们的执行过程，来看两者的效率高低</p>
<p>案例3：explian dependency的用法</p>
<img src="Snipaste_2023-11-29_15-12-21.png" alt="Snipaste_2023-11-29_15-12-21" style="zoom: 50%;">

<p><strong>使用 explain dependency 查看 SQL 查询非分区普通表</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain dependency select s_age,count(1) num from student_orc;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_tb _orc&quot;</span><span class="punctuation">,</span><span class="string">&quot;tabl</span></span><br><span class="line"><span class="string">etype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><strong>使用 explain dependency 查看 SQL 查询分区表</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain dependency select s_age,count(1) num from student_orc_partition;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@ part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=3&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=4&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=5&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=6&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=7&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=8&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-29_15-16-47.png" alt="Snipaste_2023-11-29_15-16-47" style="zoom:50%;">

<p>explain dependency的实际应用</p>
<p>①识别看似等价的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--代码1：</span><br><span class="line">select</span><br><span class="line">a.s_no</span><br><span class="line">from student_orc_partition a</span><br><span class="line">inner join</span><br><span class="line">student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part and a.part&gt;=1 and a.part&lt;=2;</span><br><span class="line"></span><br><span class="line">--代码2：</span><br><span class="line">select</span><br><span class="line">a.s_no</span><br><span class="line">from student_orc_partition a</span><br><span class="line">inner join</span><br><span class="line">student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part</span><br><span class="line">where a.part&gt;=1 and a.part&lt;=2;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//代码1的explain dependency结果：</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//代码2的explain dependency结果：</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;default@student_orc_partition@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span> <span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>通过上面的输出结果可以看到，其实上述的两个 SQL 并不等价，代码 1 在内连接（inner join）中的连接条件（on）中加入非等值的过滤条件后，并没有将内连接的左右两个表按照过滤条件进行过滤，内连接在执行时会多读取 part&#x3D;0 的分区数据。而在代码 2 中，会过滤掉不符合条件的分区。</p>
<p>②识别SQL读取数据范围的差别</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--代码 1：</span><br><span class="line">explain dependency</span><br><span class="line">select</span><br><span class="line">a.s_no</span><br><span class="line">from student_orc_partition a</span><br><span class="line">left join</span><br><span class="line">student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part and b.part&gt;=1 and b.part&lt;=2;</span><br><span class="line"></span><br><span class="line">--代码 2：</span><br><span class="line">explain dependency</span><br><span class="line">select</span><br><span class="line">a.s_no</span><br><span class="line">from student_orc_partition a</span><br><span class="line">left join</span><br><span class="line">student_orc_partition_only b</span><br><span class="line">on a.s_no=b.s_no and a.part=b.part and a.part&gt;=1 and a.part&lt;=2;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//代码 1 的 explain dependency 结果：</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;default@student_orc_partition@part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> …中间省略 <span class="number">7</span> 个分区</span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=2&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="comment">//代码 2 的 explain dependency 结果：</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;input_partitions&quot;</span><span class="punctuation">:</span></span><br><span class="line"><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> …中间省略 <span class="number">7</span> 个分区</span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition@part=9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=0&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=1&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> …中间省略 <span class="number">7</span> 个分区</span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;partitionName&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only@part=9&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;input_tables&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span><span class="attr">&quot;tablename&quot;</span><span class="punctuation">:</span><span class="string">&quot;default@student_orc_partition_only&quot;</span><span class="punctuation">,</span><span class="attr">&quot;tabletype&quot;</span><span class="punctuation">:</span><span class="string">&quot;MANAGED_TABLE&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>可以看到，对左外连接在连接条件中加入非等值过滤的条件，<strong>如果过滤条件是作用于右表（b 表）有起到过滤的效果，则右表只要扫描两个分区即可，但是左表（a表）会进行全表扫描。如果过滤条件是针对左表，则完全没有起到过滤的作用，那么两个表将进行全表扫描</strong>。这时的情况就如同全外连接一样都需要对两个数据进行全表扫描。</p>
<p>案例4：explain authorization的用法</p>
<p>通过 explain authorization 可以知道当前 SQL 访问的数据来源（INPUTS） 和数据输出（OUTPUTS），以及当前 Hive 的访问用户 （CURRENT_USER）和操作（OPERATION）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">explain authorization</span><br><span class="line">select variance(s_score) from student_tb_orc;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">INPUTS<span class="punctuation">:</span>  <span class="comment">//数据来源</span></span><br><span class="line">default@student_tb_orc</span><br><span class="line">OUTPUTS<span class="punctuation">:</span>   <span class="comment">//输出路径</span></span><br><span class="line">hdfs<span class="punctuation">:</span><span class="comment">//node01:8020/tmp/hive/hdfs/cbf182a5-8258-4157-9194- 90f1475a3ed5/-mr-10000</span></span><br><span class="line">CURRENT_USER<span class="punctuation">:</span>   <span class="comment">//当前操作用户</span></span><br><span class="line">hdfs</span><br><span class="line">OPERATION<span class="punctuation">:</span>   <span class="comment">//操作类型</span></span><br><span class="line">QUERY</span><br><span class="line">AUTHORIZATION_FAILURES<span class="punctuation">:</span></span><br><span class="line">No privilege &#x27;Select&#x27; found for inputs <span class="punctuation">&#123;</span> database<span class="punctuation">:</span>default<span class="punctuation">,</span> table<span class="punctuation">:</span>student_ tb_orc<span class="punctuation">,</span></span><br><span class="line">columnName<span class="punctuation">:</span>s_score<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<h2 id="11-4-HQL语法优化之分组聚合优化"><a href="#11-4-HQL语法优化之分组聚合优化" class="headerlink" title="11.4 HQL语法优化之分组聚合优化"></a>11.4 HQL语法优化之分组聚合优化</h2><h3 id="11-4-1-优化说明"><a href="#11-4-1-优化说明" class="headerlink" title="11.4.1 优化说明"></a>11.4.1 优化说明</h3><p>Hive中未经优化的分组聚合，是通过一个MapReduce Job实现的。Map端负责读取数据，并按照分组字段分区，通过Shuffle，将数据发往Reduce端，各组数据在Reduce端完成最终的聚合运算。</p>
<p>Hive对分组聚合的优化<strong>主要围绕着减少Shuffle数据量进行</strong>，具体做法是map-side聚合。所谓map-side聚合，就是在map端维护一个hash table，利用其完成部分的聚合，然后将部分聚合的结果，按照分组字段分区，发送至reduce端，完成最终的聚合。map-side聚合能有效减少shuffle的数据量，提高分组聚合运算的效率。</p>
<p>map-side 聚合相关的参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--启用map-side聚合</span><br><span class="line">set hive.map.aggr=true;</span><br><span class="line"></span><br><span class="line">--用于检测源表数据是否适合进行map-side聚合。检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。</span><br><span class="line">set hive.map.aggr.hash.min.reduction=0.5;</span><br><span class="line"></span><br><span class="line">--用于检测源表是否适合map-side聚合的条数。</span><br><span class="line">set hive.groupby.mapaggr.checkinterval=100000;</span><br><span class="line"></span><br><span class="line">--map-side聚合所用的hash table，占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。</span><br><span class="line">set hive.map.aggr.hash.force.flush.memory.threshold=0.9;</span><br></pre></td></tr></table></figure>

<h2 id="11-5-HQL语法优化之Join优化"><a href="#11-5-HQL语法优化之Join优化" class="headerlink" title="11.5 HQL语法优化之Join优化"></a>11.5 HQL语法优化之Join优化</h2><h3 id="11-5-1-Join算法概述"><a href="#11-5-1-Join算法概述" class="headerlink" title="11.5.1 Join算法概述"></a>11.5.1 Join算法概述</h3><p>Hive拥有多种join算法，包括Common Join，Map Join，Bucket Map Join，Sort Merge Buckt Map Join等，下面对每种join算法做简要说明：</p>
<p>（1）Common Join</p>
<p>Common Join是Hive中最稳定的join算法，其通过一个MapReduce Job完成一个join操作。Map端负责读取join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。如下图所示：</p>
<img src="Snipaste_2023-11-03_20-40-41.png" alt="Snipaste_2023-11-03_20-40-41" style="zoom:50%;">

<p>需要<strong>注意</strong>的是，sql语句中的join操作和执行计划中的Common Join任务并非一对一的关系，一个sql语句中的<strong>相邻</strong>的且<strong>关联字段相同</strong>的多个join操作可以合并为一个Common Join任务。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">    a.val, </span><br><span class="line">    b.val, </span><br><span class="line">    c.val </span><br><span class="line">from a </span><br><span class="line">join b on (a.key = b.key1) </span><br><span class="line">join c on (c.key = b.key1)</span><br></pre></td></tr></table></figure>

<p>上述sql语句中两个join操作的关联字段均为b表的key1字段，则该语句中的两个join操作可由一个Common Join任务实现，也就是可通过一个Map Reduce任务实现。 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">select </span><br><span class="line">    a.val, </span><br><span class="line">    b.val, </span><br><span class="line">    c.val </span><br><span class="line">from a </span><br><span class="line">join b on (a.key = b.key1) </span><br><span class="line">join c on (c.key = b.key2)</span><br></pre></td></tr></table></figure>

<p>上述sql语句中的两个join操作关联字段各不相同，则该语句的两个join操作需要各自通过一个Common Join任务实现，也就是通过两个Map Reduce任务实现。</p>
<p>（2）Map Join</p>
<p>Map Join算法可以通过两个只有map阶段的Job完成一个join操作。其适用场景为大表join小表。若某join操作满足要求，则第一个Job会读取小表数据，将其制作为hash table，并上传至Hadoop分布式缓存（本质上是上传至HDFS）。第二个Job会先从分布式缓存中读取小表数据，并缓存在Map Task的内存中，然后扫描大表数据，这样在map端即可完成关联操作。如下图所示：</p>
<img src="Snipaste_2023-11-03_21-09-27.png" alt="Snipaste_2023-11-03_21-09-27" style="zoom:50%;">

<p>（3）Bucket Map Join</p>
<p>Bucket Map Join是对Map Join算法的改进，其打破了Map Join只适用于大表join小表的限制，可用于大表join大表的场景。</p>
<p>Bucket Map Join的核心思想是：<strong>若能保证参与join的表均为分桶表，且关联字段为分桶字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍</strong>，就能保证参与join的两张表的分桶之间具有明确的关联关系，所以就可以在两表的分桶间进行Map Join操作了。这样一来，第二个Job的Map端就无需再缓存小表的全表数据了，而只需缓存其所需的分桶即可。其原理如图所示：</p>
<img src="Snipaste_2023-11-03_21-37-40.png" alt="Snipaste_2023-11-03_21-37-40" style="zoom:50%;">

<p>（4）Sort Merge Bucket Map Join</p>
<p>Sort Merge Bucket Map Join（简称SMB Map Join）基于Bucket Map Join。SMB Map Join要求，<strong>参与join的表均为分桶表，且需保证分桶内的数据是有序的，且分桶字段、排序字段和关联字段为相同字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍。</strong></p>
<p>SMB Map Join同Bucket Join一样，同样是利用两表各分桶之间的关联关系，在分桶之间进行join操作，不同的是，分桶之间的join操作的实现原理。Bucket Map Join，两个分桶之间的join实现原理为Hash Join算法；而SMB Map Join，两个分桶之间的join实现原理为Sort Merge Join算法。</p>
<p>Hash Join和Sort Merge Join均为关系型数据库中常见的Join实现算法。Hash Join的原理相对简单，就是对参与join的一张表构建hash table，然后扫描另外一张表，然后进行逐行匹配。Sort Merge Join需要在两张按照关联字段排好序的表中进行，其原理如图所示：</p>
<img src="Snipaste_2023-11-05_13-27-38.png" alt="Snipaste_2023-11-05_13-27-38" style="zoom:50%;">

<p>Hive中的SMB Map Join就是对两个分桶的数据按照上述思路进行Join操作。可以看出，SMB Map Join与Bucket Map Join相比，在进行Join操作时，Map端是无需对整个Bucket构建hash table，也无需在Map端缓存整个Bucket数据的，每个Mapper只需按顺序逐个key读取两个分桶的数据进行join即可。</p>
<h3 id="11-5-2-Map-Join"><a href="#11-5-2-Map-Join" class="headerlink" title="11.5.2 Map Join"></a>11.5.2 Map Join</h3><h4 id="11-5-2-1-优化说明"><a href="#11-5-2-1-优化说明" class="headerlink" title="11.5.2.1 优化说明"></a>11.5.2.1 优化说明</h4><p>Map Join有两种触发方式，一种是用户在SQL语句中增加hint提示（过时了不推荐），另外一种是Hive优化器根据参与join表的数据量大小，自动触发。 </p>
<p>Hive在编译SQL语句阶段，起初所有的join操作均采用Common Join算法实现。</p>
<p>之后在物理优化阶段，Hive会根据每个Common Join任务所需表的大小判断该Common Join任务是否能够转换为Map Join任务，若满足要求，便将Common Join任务自动转换为Map Join任务。</p>
<p>但有些Common Join任务所需的表大小，在SQL的编译阶段是未知的（例如对子查询进行join操作），所以这种Common Join任务是否能转换成Map Join任务在编译阶是无法确定的。</p>
<p>针对这种情况，Hive会在编译阶段生成一个条件任务（Conditional Task），其下会包含一个计划列表，计划列表中包含转换后的Map Join任务以及原有的Common Join任务。最终具体采用哪个计划，是在运行时决定的。大致思路如下图所示：</p>
<p><img src="11%E5%9B%BE%E7%89%871.png" alt="11图片1"></p>
<p>Map join自动转换的具体判断逻辑如下图所示：</p>
<p>注意：a left join b：大表是a</p>
<p>​           a inner join b：大表是a或b</p>
<p>​      	 a right join b：大表是b</p>
<p>​		   a full join b：不能进行map join，只能进行common join</p>
<p><img src="12%E5%9B%BE%E7%89%871.png" alt="12图片1"></p>
<p>图中涉及到的参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--启动Map Join自动转换</span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line"></span><br><span class="line">--一个Common Join operator转为Map Join operator的判断条件,若该Common Join相关的表中,存在n-1张表的已知大小总和&lt;=该值,则生成一个Map Join计划,此时可能存在多种n-1张表的组合均满足该条件,则hive会为每种满足条件的组合均生成一个Map Join计划,同时还会保留原有的Common Join计划作为后备(back up)计划,实际运行时,优先执行Map Join计划，若不能执行成功，则启动Common Join后备计划。</span><br><span class="line">set hive.mapjoin.smalltable.filesize=250000;</span><br><span class="line"></span><br><span class="line">--开启无条件转Map Join</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line"></span><br><span class="line">--无条件转Map Join时的小表之和阈值,若一个Common Join operator相关的表中，存在n-1张表的大小总和&lt;=该值,此时hive便不会再为每种n-1张表的组合均生成Map Join计划,同时也不会保留Common Join作为后备计划。而是只生成一个最优的Map Join计划。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask.size=10000000;</span><br></pre></td></tr></table></figure>

<h4 id="11-5-2-2-优化案例"><a href="#11-5-2-2-优化案例" class="headerlink" title="11.5.2.2 优化案例"></a>11.5.2.2 优化案例</h4><p>（1）示例SQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from order_detail od</span><br><span class="line">join product_info product on od.product_id = product.id</span><br><span class="line">join province_info province on od.province_id = province.id;</span><br></pre></td></tr></table></figure>

<p>（2）优化前</p>
<p>上述SQL语句共有三张表进行两次join操作，且两次join操作的关联字段不同。故优化前的执行计划应该包含两个Common Join operator，也就是由两个MapReduce任务实现。执行计划如下图所示：</p>
<img src="13图片1.png" alt="13图片1" style="zoom:50%;">

<p>（3）优化思路</p>
<img src="Snipaste_2023-11-05_15-26-23.png" alt="Snipaste_2023-11-05_15-26-23" style="zoom:50%;">

<p>三张表中，product_info和province_info数据量较小，可考虑将其作为小表，进行Map Join优化。</p>
<p><strong>方案1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--启用Map Join自动转换。 </span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line">--不使用无条件转Map Join。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=false;</span><br><span class="line">--调整hive.mapjoin.smalltable.filesize参数，使其大于等于product_info。 </span><br><span class="line">set hive.mapjoin.smalltable.filesize=25285707;</span><br></pre></td></tr></table></figure>

<p>样可保证将两个Common Join operator均可转为Map Join operator，并保留Common Join作为后备计划，保证计算任务的稳定。调整完的执行计划如下图：</p>
<p><img src="14%E5%9B%BE%E7%89%871.png" alt="14图片1"></p>
<p><strong>方案2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--启用Map Join自动转换。</span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line">--使用无条件转Map Join。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line">--调整hive.auto.convert.join.noconditionaltask.size参数，使其大于等于product_info和province_info之和。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask.size=25286076;</span><br></pre></td></tr></table></figure>

<p>这样可直接将两个Common Join operator转为两个Map Join operator，并且由于两个Map Join operator的小表大小之和小于等于hive.auto.convert.join.noconditionaltask.size，故两个Map Join operator任务可合并为同一个。这个方案计算效率最高，但需要的内存也是最多的。</p>
<p><img src="15%E5%9B%BE%E7%89%871.png" alt="15图片1"></p>
<p><strong>方案3：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--启用Map Join自动转换。</span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line">--使用无条件转Map Join。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line">--调整hive.auto.convert.join.noconditionaltask.size参数，使其等于product_info。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask.size=25285707;</span><br></pre></td></tr></table></figure>

<p>这样可直接将两个Common Join operator转为Map Join operator，但不会将两个Map Join的任务合并。该方案计算效率比方案二低，但需要的内存也更少。</p>
<p>调整完的执行计划如下图：</p>
<p><img src="16%E5%9B%BE%E7%89%871.png" alt="16图片1"></p>
<h3 id="11-5-3-Bucket-Map-Join"><a href="#11-5-3-Bucket-Map-Join" class="headerlink" title="11.5.3 Bucket Map Join"></a>11.5.3 Bucket Map Join</h3><h4 id="11-5-3-1-优化说明"><a href="#11-5-3-1-优化说明" class="headerlink" title="11.5.3.1 优化说明"></a>11.5.3.1 优化说明</h4><p>Bucket Map Join不支持自动转换，发须通过用户在SQL语句中提供如下Hint提示，并配置如下相关参数，方可使用。注意，在MR引擎下的Hive已经烂尾了，在Hive on spark上是可以进行自动转换的。</p>
<p>（1）Hint提示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select /*+ mapjoin(ta) */</span><br><span class="line">    ta.id,</span><br><span class="line">    tb.id</span><br><span class="line">from table_a ta</span><br><span class="line">join table_b tb on ta.id=tb.id;</span><br></pre></td></tr></table></figure>

<p>（2）相关参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--关闭cbo优化，cbo会导致hint信息被忽略</span><br><span class="line">set hive.cbo.enable=false;</span><br><span class="line">--map join hint默认会被忽略(因为已经过时)，需将如下参数设置为false</span><br><span class="line">set hive.ignore.mapjoin.hint=false;</span><br><span class="line">--启用bucket map join优化功能</span><br><span class="line">set hive.optimize.bucketmapjoin = true;</span><br></pre></td></tr></table></figure>

<h4 id="11-5-3-2-优化案例"><a href="#11-5-3-2-优化案例" class="headerlink" title="11.5.3.2 优化案例"></a>11.5.3.2 优化案例</h4><p>（1）示例SQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from order_detail</span><br><span class="line">    where dt=&#x27;2020-06-14&#x27;</span><br><span class="line">)od</span><br><span class="line">join(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from payment_detail</span><br><span class="line">    where dt=&#x27;2020-06-14&#x27;</span><br><span class="line">)pd</span><br><span class="line">on od.id=pd.order_detail_id;</span><br></pre></td></tr></table></figure>

<p>（2）优化前</p>
<p>上述SQL语句共有两张表一次join操作，故优化前的执行计划应包含一个Common Join任务，通过一个MapReduce Job实现。执行计划如下图所示：</p>
<img src="17图片1.png" alt="17图片1" style="zoom:50%;">

<p>（3）优化思路</p>
<img src="Snipaste_2023-11-05_16-19-16.png" alt="Snipaste_2023-11-05_16-19-16" style="zoom:50%;">

<p>张表都相对较大，若采用普通的Map Join算法，则Map端需要较多的内存来缓存数据，当然可以选择为Map段分配更多的内存，来保证任务运行成功。但是，Map端的内存不可能无上限的分配，所以当参与Join的表数据量均过大时，就可以考虑采用Bucket Map Join算法。下面演示如何使用Bucket Map Join。</p>
<p>首先需要依据源表创建两个分桶表，order_detail建议分16个bucket，payment_detail建议分8个bucket,注意<strong>分桶个数</strong>的倍数关系以及<strong>分桶字段</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">--订单表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">drop table if exists order_detail_bucketed;</span><br><span class="line">create table order_detail_bucketed(</span><br><span class="line">    id           string comment &#x27;订单id&#x27;,</span><br><span class="line">    user_id      string comment &#x27;用户id&#x27;,</span><br><span class="line">    product_id   string comment &#x27;商品id&#x27;,</span><br><span class="line">    province_id  string comment &#x27;省份id&#x27;,</span><br><span class="line">    create_time  string comment &#x27;下单时间&#x27;,</span><br><span class="line">    product_num  int comment &#x27;商品件数&#x27;,</span><br><span class="line">    total_amount decimal(16, 2) comment &#x27;下单金额&#x27;</span><br><span class="line">)</span><br><span class="line">clustered by (id) into 16 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">--支付表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">drop table if exists payment_detail_bucketed;</span><br><span class="line">create table payment_detail_bucketed(</span><br><span class="line">    id              string comment &#x27;支付id&#x27;,</span><br><span class="line">    order_detail_id string comment &#x27;订单明细id&#x27;,</span><br><span class="line">    user_id         string comment &#x27;用户id&#x27;,</span><br><span class="line">    payment_time    string comment &#x27;支付时间&#x27;,</span><br><span class="line">    total_amount    decimal(16, 2) comment &#x27;支付金额&#x27;</span><br><span class="line">)</span><br><span class="line">clustered by (order_detail_id) into 8 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<p>然后向两个分桶表导入数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">--订单表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">insert overwrite table order_detail_bucketed</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    user_id,</span><br><span class="line">    product_id,</span><br><span class="line">    province_id,</span><br><span class="line">    create_time,</span><br><span class="line">    product_num,</span><br><span class="line">    total_amount   </span><br><span class="line">from order_detail</span><br><span class="line">where dt=&#x27;2020-06-14&#x27;;</span><br><span class="line"></span><br><span class="line">--分桶表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">insert overwrite table payment_detail_bucketed</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    order_detail_id,</span><br><span class="line">    user_id,</span><br><span class="line">    payment_time,</span><br><span class="line">    total_amount</span><br><span class="line">from payment_detail</span><br><span class="line">where dt=&#x27;2020-06-14&#x27;;</span><br></pre></td></tr></table></figure>

<p>然后设置以下参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--关闭cbo优化，cbo会导致hint信息被忽略，需将如下参数修改为false</span><br><span class="line">set hive.cbo.enable=false;</span><br><span class="line">--map join hint默认会被忽略(因为已经过时)，需将如下参数修改为false</span><br><span class="line">set hive.ignore.mapjoin.hint=false;</span><br><span class="line">--启用bucket map join优化功能,默认不启用，需将如下参数修改为true</span><br><span class="line">set hive.optimize.bucketmapjoin = true;</span><br></pre></td></tr></table></figure>

<p>最后在重写SQL语句，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select /*+ mapjoin(pd) */</span><br><span class="line">    *</span><br><span class="line">from order_detail_bucketed od</span><br><span class="line">join payment_detail_bucketed pd on od.id = pd.order_detail_id;</span><br></pre></td></tr></table></figure>

<p>优化后的执行计划如图所示：</p>
<p><img src="18%E5%9B%BE%E7%89%871.png" alt="18图片1"></p>
<h3 id="11-5-4-Sort-Merge-Bucket-Map-Join"><a href="#11-5-4-Sort-Merge-Bucket-Map-Join" class="headerlink" title="11.5.4 Sort Merge Bucket Map Join"></a>11.5.4 Sort Merge Bucket Map Join</h3><h4 id="11-5-4-1-优化说明"><a href="#11-5-4-1-优化说明" class="headerlink" title="11.5.4.1 优化说明"></a>11.5.4.1 优化说明</h4><p>Sort Merge Bucket Map Join有两种触发方式，包括Hint提示和自动转换。Hint提示已过时，不推荐使用。下面是自动转换的相关参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--启动Sort Merge Bucket Map Join优化</span><br><span class="line">set hive.optimize.bucketmapjoin.sortedmerge=true;</span><br><span class="line">--使用自动转换SMB Join</span><br><span class="line">set hive.auto.convert.sortmerge.join=true;</span><br></pre></td></tr></table></figure>

<h4 id="11-5-4-2-优化案例"><a href="#11-5-4-2-优化案例" class="headerlink" title="11.5.4.2 优化案例"></a>11.5.4.2 优化案例</h4><p>（1）示例SQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from order_detail</span><br><span class="line">    where dt=&#x27;2020-06-14&#x27;</span><br><span class="line">)od</span><br><span class="line">join(</span><br><span class="line">    select</span><br><span class="line">        *</span><br><span class="line">    from payment_detail</span><br><span class="line">    where dt=&#x27;2020-06-14&#x27;</span><br><span class="line">)pd</span><br><span class="line">on od.id=pd.order_detail_id;</span><br></pre></td></tr></table></figure>

<p>（2）优化前</p>
<p>上述SQL语句共有两张表一次join操作，故优化前的执行计划应包含一个Common Join任务，通过一个MapReduce Job实现。</p>
<p>（3）优化思路</p>
<img src="Snipaste_2023-11-05_16-28-49.png" alt="Snipaste_2023-11-05_16-28-49" style="zoom:50%;">

<p>两张表都相对较大，除了可以考虑采用Bucket Map Join算法，还可以考虑SMB Join。相较于Bucket Map Join，SMB Map Join对分桶大小是没有要求的。下面演示如何使用SMB Map Join。</p>
<p>首先需要依据源表创建两个的有序的分桶表，order_detail建议分16个bucket，payment_detail建议分8个bucket,注意****分桶个数*<em><strong>的倍数关系以及</strong>分桶字段和排序字段</em>*。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">--订单表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">drop table if exists order_detail_sorted_bucketed;</span><br><span class="line">create table order_detail_sorted_bucketed(</span><br><span class="line">    id           string comment &#x27;订单id&#x27;,</span><br><span class="line">    user_id      string comment &#x27;用户id&#x27;,</span><br><span class="line">    product_id   string comment &#x27;商品id&#x27;,</span><br><span class="line">    province_id  string comment &#x27;省份id&#x27;,</span><br><span class="line">    create_time  string comment &#x27;下单时间&#x27;,</span><br><span class="line">    product_num  int comment &#x27;商品件数&#x27;,</span><br><span class="line">    total_amount decimal(16, 2) comment &#x27;下单金额&#x27;</span><br><span class="line">)</span><br><span class="line">clustered by (id) sorted by(id) into 16 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"></span><br><span class="line">--支付表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">drop table if exists payment_detail_sorted_bucketed;</span><br><span class="line">create table payment_detail_sorted_bucketed(</span><br><span class="line">    id              string comment &#x27;支付id&#x27;,</span><br><span class="line">    order_detail_id string comment &#x27;订单明细id&#x27;,</span><br><span class="line">    user_id         string comment &#x27;用户id&#x27;,</span><br><span class="line">    payment_time    string comment &#x27;支付时间&#x27;,</span><br><span class="line">    total_amount    decimal(16, 2) comment &#x27;支付金额&#x27;</span><br><span class="line">)</span><br><span class="line">clustered by (order_detail_id) sorted by(order_detail_id) into 8 buckets</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<p>然后向两个分桶表导入数据。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">--订单表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">insert overwrite table order_detail_sorted_bucketed</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    user_id,</span><br><span class="line">    product_id,</span><br><span class="line">    province_id,</span><br><span class="line">    create_time,</span><br><span class="line">    product_num,</span><br><span class="line">    total_amount   </span><br><span class="line">from order_detail</span><br><span class="line">where dt=&#x27;2020-06-14&#x27;;</span><br><span class="line"></span><br><span class="line">--分桶表</span><br><span class="line">hive (default)&gt; </span><br><span class="line">insert overwrite table payment_detail_sorted_bucketed</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    order_detail_id,</span><br><span class="line">    user_id,</span><br><span class="line">    payment_time,</span><br><span class="line">    total_amount</span><br><span class="line">from payment_detail</span><br><span class="line">where dt=&#x27;2020-06-14&#x27;;</span><br></pre></td></tr></table></figure>

<p>然后设置以下参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--启动Sort Merge Bucket Map Join优化</span><br><span class="line">set hive.optimize.bucketmapjoin.sortedmerge=true;</span><br><span class="line">--使用自动转换SMB Join</span><br><span class="line">set hive.auto.convert.sortmerge.join=true;</span><br></pre></td></tr></table></figure>

<p>最后在重写SQL语句，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from order_detail_sorted_bucketed od</span><br><span class="line">join payment_detail_sorted_bucketed pd</span><br><span class="line">on od.id = pd.order_detail_id;</span><br></pre></td></tr></table></figure>

<p>优化后的执行计如图所示：</p>
<img src="19图片1.png" alt="19图片1" style="zoom:50%;">

<h2 id="11-6-HQL语法优化之数据倾斜"><a href="#11-6-HQL语法优化之数据倾斜" class="headerlink" title="11.6 HQL语法优化之数据倾斜"></a>11.6 HQL语法优化之数据倾斜</h2><h3 id="11-6-1-数据倾斜概述"><a href="#11-6-1-数据倾斜概述" class="headerlink" title="11.6.1 数据倾斜概述"></a>11.6.1 数据倾斜概述</h3><p>数据倾斜问题，通常是指参与计算的数据分布不均，即某个key或者某些key的数据量远超其他key，导致在shuffle阶段，大量相同key的数据被发往同一个Reduce，进而导致该Reduce所需的时间远超其他Reduce，成为整个任务的瓶颈。</p>
<p>Hive中的数据倾斜常出现在分组聚合和join操作的场景中，下面分别介绍在上述两种场景下的优化思路。</p>
<h3 id="11-6-2-分组聚合导致的数据倾斜"><a href="#11-6-2-分组聚合导致的数据倾斜" class="headerlink" title="11.6.2 分组聚合导致的数据倾斜"></a>11.6.2 分组聚合导致的数据倾斜</h3><h4 id="11-6-2-1-优化说明"><a href="#11-6-2-1-优化说明" class="headerlink" title="11.6.2.1 优化说明"></a>11.6.2.1 优化说明</h4><p>前文提到过，Hive中未经优化的分组聚合，是通过一个MapReduce Job实现的。Map端负责读取数据，并按照分组字段分区，通过Shuffle，将数据发往Reduce端，各组数据在Reduce端完成最终的聚合运算。</p>
<p>如果group by分组字段的值分布不均，就可能导致大量相同的key进入同一Reduce，从而导致数据倾斜问题。</p>
<p>由分组聚合导致的数据倾斜问题，有以下两种解决思路：</p>
<h5 id="（1）Map-Side聚合"><a href="#（1）Map-Side聚合" class="headerlink" title="（1）Map-Side聚合"></a>（1）Map-Side聚合</h5><p>开启Map-Side聚合后，数据会现在Map端完成部分聚合工作。这样一来即便原始数据是倾斜的，经过Map端的初步聚合后，发往Reduce的数据也就不再倾斜了。最佳状态下，Map-端聚合能完全屏蔽数据倾斜问题。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--启用map-side聚合</span><br><span class="line">set hive.map.aggr=true;</span><br><span class="line"></span><br><span class="line">--用于检测源表数据是否适合进行map-side聚合。检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。</span><br><span class="line">set hive.map.aggr.hash.min.reduction=0.5;</span><br><span class="line"></span><br><span class="line">--用于检测源表是否适合map-side聚合的条数。</span><br><span class="line">set hive.groupby.mapaggr.checkinterval=100000;</span><br><span class="line"></span><br><span class="line">--map-side聚合所用的hash table，占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。</span><br><span class="line">set hive.map.aggr.hash.force.flush.memory.threshold=0.9;</span><br></pre></td></tr></table></figure>

<h5 id="（2）Skew-GroupBy优化"><a href="#（2）Skew-GroupBy优化" class="headerlink" title="（2）Skew-GroupBy优化"></a>（2）Skew-GroupBy优化</h5><p>Skew-GroupBy的原理是启动两个MR任务，第一个MR按照随机数分区，将数据分散发送到Reduce，完成部分聚合，第二个MR按照分组字段分区，完成最终聚合。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--启用分组聚合数据倾斜优化</span><br><span class="line">set hive.groupby.skewindata=true;</span><br></pre></td></tr></table></figure>

<h3 id="11-6-3-Join导致的数据倾斜"><a href="#11-6-3-Join导致的数据倾斜" class="headerlink" title="11.6.3 Join导致的数据倾斜"></a>11.6.3 Join导致的数据倾斜</h3><h4 id="11-6-3-1-优化说明"><a href="#11-6-3-1-优化说明" class="headerlink" title="11.6.3.1 优化说明"></a>11.6.3.1 优化说明</h4><p>前文提到过，未经优化的join操作，默认是使用common join算法，也就是通过一个MapReduce Job完成计算。Map端负责读取join操作所需表的数据，并按照关联字段进行分区，通过Shuffle，将其发送到Reduce端，相同key的数据在Reduce端完成最终的Join操作。</p>
<p>如果关联字段的值分布不均，就可能导致大量相同的key进入同一Reduce，从而导致数据倾斜问题。</p>
<p>由join导致的数据倾斜问题，有如下三种解决方案：</p>
<h5 id="（1）map-join"><a href="#（1）map-join" class="headerlink" title="（1）map join"></a>（1）map join</h5><p>使用map join算法，join操作仅在map端就能完成，没有shuffle操作，没有reduce阶段，自然不会产生reduce端的数据倾斜。该方案适用于大表join小表时发生数据倾斜的场景。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--启动Map Join自动转换</span><br><span class="line">set hive.auto.convert.join=true;</span><br><span class="line"></span><br><span class="line">--一个Common Join operator转为Map Join operator的判断条件,若该Common Join相关的表中,存在n-1张表的大小总和&lt;=该值,则生成一个Map Join计划,此时可能存在多种n-1张表的组合均满足该条件,则hive会为每种满足条件的组合均生成一个Map Join计划,同时还会保留原有的Common Join计划作为后备(back up)计划,实际运行时,优先执行Map Join计划，若不能执行成功，则启动Common Join后备计划。</span><br><span class="line">set hive.mapjoin.smalltable.filesize=250000;</span><br><span class="line"></span><br><span class="line">--开启无条件转Map Join</span><br><span class="line">set hive.auto.convert.join.noconditionaltask=true;</span><br><span class="line"></span><br><span class="line">--无条件转Map Join时的小表之和阈值,若一个Common Join operator相关的表中，存在n-1张表的大小总和&lt;=该值,此时hive便不会再为每种n-1张表的组合均生成Map Join计划,同时也不会保留Common Join作为后备计划。而是只生成一个最优的Map Join计划。</span><br><span class="line">set hive.auto.convert.join.noconditionaltask.size=10000000;</span><br></pre></td></tr></table></figure>

<h5 id="（2）skew-join"><a href="#（2）skew-join" class="headerlink" title="（2）skew join"></a>（2）skew join</h5><p>skew join的原理是，为倾斜的大key单独启动一个map join任务进行计算，其余key进行正常的common join。原理图如下：</p>
<p><img src="Snipaste_2023-11-05_17-15-08.png" alt="Snipaste_2023-11-05_17-15-08"></p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--启用skew join优化</span><br><span class="line">set hive.optimize.skewjoin=true;</span><br><span class="line">--触发skew join的阈值，若某个key的行数超过该参数值，则触发</span><br><span class="line">set hive.skewjoin.key=100000;</span><br></pre></td></tr></table></figure>

<p>这种方案对参与join的源表大小没有要求，但是对两表中倾斜的key的数据量有要求，要求一张表中的倾斜key的数据量比较小（方便走mapjoin）。</p>
<h5 id="（3）调整SQL语句"><a href="#（3）调整SQL语句" class="headerlink" title="（3）调整SQL语句"></a>（3）调整SQL语句</h5><p>若参与join的两表均为大表，其中一张表的数据是倾斜的，此时也可通过以下方式对SQL语句进行相应的调整。</p>
<p>假设原始SQL语句如下：A，B两表均为大表，且其中一张表的数据是倾斜的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from A</span><br><span class="line">join B</span><br><span class="line">on A.id=B.id;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-05_19-29-39.png" alt="Snipaste_2023-11-05_19-29-39" style="zoom:50%;">

<p>图中1001为倾斜的大key，可以看到，其被发往了同一个Reduce进行处理。</p>
<p>调整SQL语句如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from(</span><br><span class="line">    select --打散操作</span><br><span class="line">        concat(id,&#x27;_&#x27;,cast(rand()*2 as int)) id,</span><br><span class="line">        value</span><br><span class="line">    from A</span><br><span class="line">)ta</span><br><span class="line">join(</span><br><span class="line">    select --扩容操作</span><br><span class="line">        concat(id,&#x27;_&#x27;,0) id,</span><br><span class="line">        value</span><br><span class="line">    from B</span><br><span class="line">    union all</span><br><span class="line">    select</span><br><span class="line">        concat(id,&#x27;_&#x27;,1) id,</span><br><span class="line">        value</span><br><span class="line">    from B</span><br><span class="line">)tb</span><br><span class="line">on ta.id=tb.id;</span><br></pre></td></tr></table></figure>

<p>调整之后的SQL语句执行计划如下图所示：</p>
<img src="Snipaste_2023-11-05_19-30-24.png" alt="Snipaste_2023-11-05_19-30-24" style="zoom:50%;">

<h2 id="11-7-HQL语法优化之任务并行度"><a href="#11-7-HQL语法优化之任务并行度" class="headerlink" title="11.7 HQL语法优化之任务并行度"></a>11.7 HQL语法优化之任务并行度</h2><h3 id="11-7-1-优化说明"><a href="#11-7-1-优化说明" class="headerlink" title="11.7.1 优化说明"></a>11.7.1 优化说明</h3><p>对于一个分布式的计算任务而言，设置一个合适的并行度十分重要。Hive的计算任务由MapReduce完成，故并行度的调整需要分为Map端和Reduce端。</p>
<h4 id="11-7-1-1-Map端并行度"><a href="#11-7-1-1-Map端并行度" class="headerlink" title="11.7.1.1 Map端并行度"></a>11.7.1.1 Map端并行度</h4><p>Map端的并行度，也就是Map的个数。是由输入文件的切片数决定的。一般情况下，Map端的并行度无需手动调整。</p>
<p>以下特殊情况可考虑调整map端并行度：</p>
<p>（1）查询的表中存在大量小文件</p>
<p>按照Hadoop默认的切片策略，一个小文件会单独启动一个map task负责计算。若查询的表中存在大量小文件，则会启动大量map task，造成计算资源的浪费。这种情况下，可以使用Hive提供的CombineHiveInputFormat，多个小文件合并为一个切片，从而控制map task个数。相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>

<p>（2）map端有复杂的查询逻辑</p>
<p>若SQL语句中有正则替换、json解析等复杂耗时的查询逻辑时，map端的计算会相对慢一些。若想加快计算速度，在计算资源充足的情况下，可考虑增大map端的并行度，令map task多一些，每个map task计算的数据少一些。相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--一个切片的最大值</span><br><span class="line">set mapreduce.input.fileinputformat.split.maxsize=256000000;</span><br></pre></td></tr></table></figure>

<h4 id="11-7-1-2-Reduce端的并行度"><a href="#11-7-1-2-Reduce端的并行度" class="headerlink" title="11.7.1.2 Reduce端的并行度"></a>11.7.1.2 Reduce端的并行度</h4><p>Reduce端的并行度，也就是Reduce个数。相对来说，更需要关注。Reduce端的并行度，可由用户自己指定，也可由Hive自行根据该MR Job输入的文件大小进行估算。</p>
<p>Reduce端的并行度的相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--指定Reduce端并行度，默认值为-1，表示用户未指定</span><br><span class="line">set mapreduce.job.reduces;</span><br><span class="line">--Reduce端并行度最大值</span><br><span class="line">set hive.exec.reducers.max;</span><br><span class="line">--单个Reduce Task计算的数据量，用于估算Reduce并行度</span><br><span class="line">set hive.exec.reducers.bytes.per.reducer;</span><br></pre></td></tr></table></figure>

<p>Reduce端并行度的确定逻辑如下：</p>
<p>若指定参数<strong>mapreduce.job.reduces</strong>的值为一个非负整数，则Reduce并行度为指定值。否则，Hive自行估算Reduce并行度，估算逻辑如下：</p>
<p>假设Job输入的文件大小为<em><strong>*totalInputBytes*</strong></em></p>
<p>参数****hive.exec.reducers.bytes.per.reducer****的值为bytesPerReducer。</p>
<p>参数****hive.exec.reducers.max****的值为maxReducers。</p>
<p>则Reduce端的并行度为：</p>
<p><img src="wps1.jpg" alt="img"> </p>
<p>根据上述描述，可以看出，Hive自行估算Reduce并行度时，是以整个MR Job输入的文件大小作为依据的。因此，在某些情况下其估计的并行度很可能并不准确，此时就需要用户根据实际情况来指定Reduce并行度了。</p>
<h2 id="11-8-HQL语法优化之小文件合并"><a href="#11-8-HQL语法优化之小文件合并" class="headerlink" title="11.8 HQL语法优化之小文件合并"></a>11.8 HQL语法优化之小文件合并</h2><h3 id="HIve中小文件产生的原因"><a href="#HIve中小文件产生的原因" class="headerlink" title="HIve中小文件产生的原因"></a>HIve中小文件产生的原因</h3><p>（1）直接向表中插入数据：每次插入都会产生一个文件，多次插入少量数据就会出现多个小文件</p>
<p>（2）通过load方式加载数据，每导入一个文件hive表就会产生一个文件</p>
<p>（3）通过查询方式加载数据（最常见）：其中，文件数量&#x3D;ReduceTask数量×分区数（只有map阶段就是，文件数量&#x3D;MapTask数量×分区数）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table A  select s_id,c_name,s_score from B;</span><br></pre></td></tr></table></figure>

<h3 id="小文件过多的危害"><a href="#小文件过多的危害" class="headerlink" title="小文件过多的危害"></a>小文件过多的危害</h3><p>（1）对于HDFS而言，其本身就不适合存储大量小文件，小文件过多会导致NameNode元数据特别大，占用内存太多，影响HDFS性能。</p>
<p>（2）对Hive而言，在进行查询时，每个小文件都会启动一个Map任务来完成，Map任务启动和初始化的时间远远大于逻辑处理的时间，本末倒置，造成资源浪费</p>
<h3 id="11-8-1-优化说明"><a href="#11-8-1-优化说明" class="headerlink" title="11.8.1 优化说明"></a>11.8.1 优化说明</h3><p>小文件合并优化，分为两个方面，分别是Map端输入的小文件合并，和Reduce端输出的小文件合并。</p>
<h4 id="11-8-1-1-Map端输入文件合并"><a href="#11-8-1-1-Map端输入文件合并" class="headerlink" title="11.8.1.1 Map端输入文件合并"></a>11.8.1.1 Map端输入文件合并</h4><p>合并Map端输入的小文件，是指将多个小文件划分到一个切片中，进而由一个Map Task去处理。目的是防止为单个小文件启动一个Map Task，浪费计算资源。</p>
<p>相关参数为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--可将多个小文件切片，合并为一个切片，进而由一个map任务处理</span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure>

<h4 id="11-8-1-2-Reduce端文件合并"><a href="#11-8-1-2-Reduce端文件合并" class="headerlink" title="11.8.1.2 Reduce端文件合并"></a>11.8.1.2 Reduce端文件合并</h4><p>合并Reduce端输出的小文件，是指将多个小文件合并成大文件。目的是减少HDFS小文件数量。其原理是根据计算任务输出文件的平均大小进行判断，若符合条件，则单独启动一个额外的任务进行合并。</p>
<p>相关参数为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">--开启合并map only任务输出的小文件</span><br><span class="line">set hive.merge.mapfiles=true;</span><br><span class="line"></span><br><span class="line">--开启合并map reduce任务输出的小文件</span><br><span class="line">set hive.merge.mapredfiles=true;</span><br><span class="line"></span><br><span class="line">--合并后的文件大小</span><br><span class="line">set hive.merge.size.per.task=256000000;</span><br><span class="line"></span><br><span class="line">--触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并</span><br><span class="line">set hive.merge.smallfiles.avgsize=16000000;</span><br></pre></td></tr></table></figure>

<h4 id="11-8-1-3-减少Reduce的数量"><a href="#11-8-1-3-减少Reduce的数量" class="headerlink" title="11.8.1.3 减少Reduce的数量"></a>11.8.1.3 减少Reduce的数量</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--reduce 的个数决定了输出的文件的个数，所以可以调整reduce的个数控制hive表的文件数量</span><br><span class="line">set mapreduce.job.reduces=10;</span><br></pre></td></tr></table></figure>

<h4 id="11-8-1-4-使用Hive自带的concatenate命令，自动合并小文件"><a href="#11-8-1-4-使用Hive自带的concatenate命令，自动合并小文件" class="headerlink" title="11.8.1.4 使用Hive自带的concatenate命令，自动合并小文件"></a>11.8.1.4 使用Hive自带的concatenate命令，自动合并小文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--对于非分区表</span><br><span class="line">alter table A concatenate;</span><br><span class="line"></span><br><span class="line">--对于分区表</span><br><span class="line">alter table B partition(day=20201224) concatenate;</span><br><span class="line">--使用concatenate命令合并小文件时不能指定合并后的文件数量，但可以多次执行该命令。 </span><br><span class="line">--当多次使用concatenate后文件数量不在变化，这个跟参数 mapreduce.input.fileinputformat.split.minsize=256mb 的设置有关，可设定每个文件的最小size。</span><br></pre></td></tr></table></figure>

<h4 id="11-8-1-5-使用hadoop的archive将小文件归档"><a href="#11-8-1-5-使用hadoop的archive将小文件归档" class="headerlink" title="11.8.1.5 使用hadoop的archive将小文件归档"></a>11.8.1.5 使用hadoop的archive将小文件归档</h4><p>Hadoop Archive简称HAR，是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样在减少namenode内存使用的同时，仍然允许对文件进行透明的访问</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">--用来控制归档是否可用</span><br><span class="line">set hive.archive.enabled=true;</span><br><span class="line">--通知Hive在创建归档时是否可以设置父目录</span><br><span class="line">set hive.archive.har.parentdir.settable=true;</span><br><span class="line">--控制需要归档文件的大小</span><br><span class="line">set har.partfile.size=1099511627776;</span><br><span class="line"></span><br><span class="line">--使用以下命令进行归档</span><br><span class="line">ALTER TABLE A ARCHIVE PARTITION(dt=&#x27;2020-12-24&#x27;, hr=&#x27;12&#x27;);</span><br><span class="line"></span><br><span class="line">--对已归档的分区恢复为原文件</span><br><span class="line">ALTER TABLE A UNARCHIVE PARTITION(dt=&#x27;2020-12-24&#x27;, hr=&#x27;12&#x27;);</span><br></pre></td></tr></table></figure>

<h2 id="11-9-其他优化"><a href="#11-9-其他优化" class="headerlink" title="11.9 其他优化"></a>11.9 其他优化</h2><h3 id="11-9-1-CBO优化"><a href="#11-9-1-CBO优化" class="headerlink" title="11.9.1 CBO优化"></a>11.9.1 CBO优化</h3><h4 id="11-9-1-1-优化说明"><a href="#11-9-1-1-优化说明" class="headerlink" title="11.9.1.1 优化说明"></a>11.9.1.1 优化说明</h4><p>CBO是指Cost based Optimizer，即基于计算成本的优化。</p>
<p>在Hive中，计算成本模型考虑到了：数据的行数、CPU、本地IO、HDFS IO、网络IO等方面。Hive会计算同一SQL语句的不同执行计划的计算成本，并选出成本最低的执行计划。目前CBO在hive的MR引擎下主要用于join的优化，例如多表join的join顺序。</p>
<p>相关参数为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--是否启用cbo优化 </span><br><span class="line">set hive.cbo.enable=true;</span><br></pre></td></tr></table></figure>

<h4 id="11-9-1-2-优化案例"><a href="#11-9-1-2-优化案例" class="headerlink" title="11.9.1.2 优化案例"></a>11.9.1.2 优化案例</h4><p>（1）示例SQL语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select</span><br><span class="line">    *</span><br><span class="line">from order_detail od</span><br><span class="line">join product_info product on od.product_id=product.id</span><br><span class="line">join province_info province on od.province_id=province.id;</span><br></pre></td></tr></table></figure>

<p>（2）关闭CBO优化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--关闭cbo优化 </span><br><span class="line">set hive.cbo.enable=false;</span><br><span class="line"></span><br><span class="line">--为了测试效果更加直观，关闭map join自动转换</span><br><span class="line">set hive.auto.convert.join=false;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-05_20-50-35.png" alt="Snipaste_2023-11-05_20-50-35" style="zoom:50%;">

<p>（3）开启CBO优化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">--开启cbo优化 </span><br><span class="line">set hive.cbo.enable=true;</span><br><span class="line">--为了测试效果更加直观，关闭map join自动转换</span><br><span class="line">set hive.auto.convert.join=false;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2023-11-05_20-51-12.png" alt="Snipaste_2023-11-05_20-51-12" style="zoom:50%;">

<p>（4）总结</p>
<p>根据上述案例可以看出，CBO优化对于执行计划中join顺序是有影响的，其之所以会将province_info的join顺序提前，是因为province info的数据量较小，将其提前，会有更大的概率使得中间结果的数据量变小，从而使整个计算任务的数据量减小，也就是使计算成本变小。</p>
<h3 id="11-9-2-谓词下推"><a href="#11-9-2-谓词下推" class="headerlink" title="11.9.2 谓词下推"></a>11.9.2 谓词下推</h3><h4 id="11-9-2-1-优化说明"><a href="#11-9-2-1-优化说明" class="headerlink" title="11.9.2.1 优化说明"></a>11.9.2.1 优化说明</h4><p>谓词下推（predicate pushdown）是指，尽量将过滤操作前移，以减少后续计算步骤的数据量。</p>
<p>相关参数为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">--是否启动谓词下推（predicate pushdown）优化</span><br><span class="line">set hive.optimize.ppd = true;</span><br></pre></td></tr></table></figure>

<p>需要注意的是：</p>
<p>CBO优化也会完成一部分的谓词下推优化工作，因为在执行计划中，谓词越靠前，整个计划的计算成本就会越低。</p>
<h3 id="11-9-3-矢量化查询"><a href="#11-9-3-矢量化查询" class="headerlink" title="11.9.3 矢量化查询"></a>11.9.3 矢量化查询</h3><p>Hive的矢量化查询优化，依赖于CPU的矢量化计算，CPU的矢量化计算的基本原理如下图：</p>
<img src="Snipaste_2023-11-05_20-54-26.png" alt="Snipaste_2023-11-05_20-54-26" style="zoom:50%;">

<p>Hive的矢量化查询，可以极大的提高一些典型查询场景（例如scans, filters, aggregates, and joins）下的CPU使用效率。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.vectorized.execution.enabled=true;</span><br></pre></td></tr></table></figure>

<p>若执行计划中，出现“Execution mode: vectorized”字样，即表明使用了矢量化计算。</p>
<h3 id="11-9-4-Fetch抓取"><a href="#11-9-4-Fetch抓取" class="headerlink" title="11.9.4 Fetch抓取"></a>11.9.4 Fetch抓取</h3><p>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：select * from emp;在这种情况下，Hive可以简单地读取emp对应的存储目录下的文件，然后输出查询结果到控制台。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--是否在特定场景转换为fetch 任务</span><br><span class="line">--设置为none表示不转换</span><br><span class="line">--设置为minimal表示支持select *，分区字段过滤，Limit等</span><br><span class="line">--设置为more表示支持select 任意字段,包括函数，过滤，和limit等</span><br><span class="line">set hive.fetch.task.conversion=more;</span><br></pre></td></tr></table></figure>

<h3 id="11-9-5-本地模式"><a href="#11-9-5-本地模式" class="headerlink" title="11.9.5 本地模式"></a>11.9.5 本地模式</h3><h4 id="11-9-5-1-优化说明"><a href="#11-9-5-1-优化说明" class="headerlink" title="11.9.5.1 优化说明"></a>11.9.5.1 优化说明</h4><p>大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p>
<p>相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--开启自动转换为本地模式</span><br><span class="line">set hive.exec.mode.local.auto=true;  </span><br><span class="line"></span><br><span class="line">--设置local MapReduce的最大输入数据量，当输入数据量小于这个值时采用local  MapReduce的方式，默认为134217728，即128M</span><br><span class="line">set hive.exec.mode.local.auto.inputbytes.max=50000000;</span><br><span class="line"></span><br><span class="line">--设置local MapReduce的最大输入文件个数，当输入文件个数小于这个值时采用local MapReduce的方式，默认为4</span><br><span class="line">set hive.exec.mode.local.auto.input.files.max=10;</span><br></pre></td></tr></table></figure>

<h3 id="11-9-6-并行模式"><a href="#11-9-6-并行模式" class="headerlink" title="11.9.6 并行模式"></a>11.9.6 并行模式</h3><p>Hive会将一个SQL语句转化成一个或者多个Stage，每个Stage对应一个MR Job。默认情况下，Hive同时只会执行一个Stage。但是某SQL语句可能会包含多个Stage，但这多个Stage可能并非完全互相依赖，也就是说有些Stage是可以并行执行的。此处提到的并行执行就是指这些Stage的并行执行。相关参数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">--启用并行执行优化</span><br><span class="line">set hive.exec.parallel=true;       </span><br><span class="line">    </span><br><span class="line">--同一个sql允许最大并行度，默认为8</span><br><span class="line">set hive.exec.parallel.thread.number=8;</span><br></pre></td></tr></table></figure>

<h3 id="11-9-7-严格模式"><a href="#11-9-7-严格模式" class="headerlink" title="11.9.7 严格模式"></a>11.9.7 严格模式</h3><p>Hive可以通过设置某些参数防止危险操作：</p>
<p>（1）分区表不使用分区过滤</p>
<p>将hive.strict.checks.no.partition.filter设置为true时，对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p>
<p>（2）使用order by没有limit过滤</p>
<p>将hive.strict.checks.orderby.no.limit设置为true时，对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reduce中进行处理，强制要求用户增加这个limit语句可以防止Reduce额外执行很长一段时间（开启了limit可以在数据进入到Reduce之前就减少一部分数据）。</p>
<p>（3）笛卡尔积</p>
<p>将hive.strict.checks.cartesian.product设置为true时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p>
<h2 id="11-10-Hive数据抽样"><a href="#11-10-Hive数据抽样" class="headerlink" title="11.10 Hive数据抽样"></a>11.10 Hive数据抽样</h2><p>当数据规模不断膨胀时，我们需要找到一个数据的子集来加快数据分析效率。因此我们就需要通过筛选和分析数据集为了进行<strong>模式 &amp; 趋势识别</strong>。目前来说有三种方式来进行抽样：<strong>随机抽样</strong>，<strong>桶表抽样</strong>，和<strong>块抽样</strong></p>
<h3 id="11-10-1-随机抽样"><a href="#11-10-1-随机抽样" class="headerlink" title="11.10.1 随机抽样"></a>11.10.1 随机抽样</h3><p>关键词：<strong>rand()函数</strong>。</p>
<p>使用 rand()函数进行随机抽样，limit 关键字限制抽样返回的数据，其中 rand函数前的 distribute 和 sort 关键字可以保证数据在 mapper 和 reducer 阶段是随机分布的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select * from table_name</span><br><span class="line">where col=xxx</span><br><span class="line">distribute by rand() sort by rand()</span><br><span class="line">limit num;</span><br></pre></td></tr></table></figure>

<h3 id="11-10-2-块抽样"><a href="#11-10-2-块抽样" class="headerlink" title="11.10.2 块抽样"></a>11.10.2 块抽样</h3><p>关键词：<strong>tablesample()函数</strong>。</p>
<ol>
<li>tablesample(n percent) 根据 hive 表数据的大小按比例抽取数据，并保存到新的 hive 表中。如：抽取原 hive 表中 10%的数据</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from xxx tablesample(10 percent)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>tablesample(nM) 指定抽样数据的大小，单位为 M。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from xxx tablesample(20M)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>tablesample(n rows) 指定抽样数据的行数，其中 n 代表每个 map 任务均取 n 行数据，map 数量可通过 hive 表的简单查询语句确认（关键词：numberof mappers: x)</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from xxx tablesample(100 rows)</span><br></pre></td></tr></table></figure>

<h3 id="11-10-3-桶表抽样"><a href="#11-10-3-桶表抽样" class="headerlink" title="11.10.3 桶表抽样"></a>11.10.3 桶表抽样</h3><p>关键词：**tablesample (bucket x out of y [on colname])**。</p>
<p>其中 x 是要抽样的桶编号，桶编号从 1 开始，colname 表示抽样的列，y 表示桶的数量。hive 中分桶其实就是根据某一个字段 Hash 取模，放入指定数据的桶中，比如将表 table_1 按照 ID 分成 100 个桶，其算法是 hash(id) % 100，这样，hash(id) %100 &#x3D; 0 的数据被放到第一个桶中，hash(id) % 100 &#x3D; 1 的记录被放到第二个桶中。创建分桶表的关键语句为：CLUSTER BY 语句。</p>
<p>例如：将表随机分成 10 组，抽取其中的第一个桶的数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select * from table_01</span><br><span class="line">tablesample(bucket 1 out of 10 on rand())</span><br></pre></td></tr></table></figure>

<h2 id="11-11-Hive计算引擎"><a href="#11-11-Hive计算引擎" class="headerlink" title="11.11 Hive计算引擎"></a>11.11 Hive计算引擎</h2><p>目前 Hive 支持 MapReduce、Tez 和 Spark 三种计算引擎</p>
<ol>
<li>MapReduce：这是Hive最初使用的计算引擎，也是Hadoop生态系统中的主要计算模型。MapReduce通过将任务分解成多个小任务（Map和Reduce阶段）来处理数据，这使得它非常适合大规模数据处理。然而，MapReduce的批处理特性使得它在处理交互式查询和实时数据处理方面不够高效。</li>
<li>Tez：完全基于内存，Tez将MapReduce的两次扫描优化为一次扫描，提高了查询性能。<strong>一般用于快速出结果，数据量较小的场景</strong></li>
<li>Spark：Spark是另一种高性能的计算引擎，它提供了内存计算和DAG（有向无环图）执行引擎，使得数据处理速度更快。<strong>一般处理天指标</strong></li>
</ol>
<h1 id="第十二章-Hive千亿级数据倾斜"><a href="#第十二章-Hive千亿级数据倾斜" class="headerlink" title="第十二章 Hive千亿级数据倾斜"></a>第十二章 Hive千亿级数据倾斜</h1><h2 id="12-1-数据倾斜问题的本质原因"><a href="#12-1-数据倾斜问题的本质原因" class="headerlink" title="12.1 数据倾斜问题的本质原因"></a>12.1 数据倾斜问题的本质原因</h2><p>（1）map端：如果文件使用GZIP压缩等不支持文件分割操作的压缩方式时，若该不可分割的文件超大，被一个map读取时，就会发生map阶段的数据倾斜。</p>
<p>（2）reduce端（更容易出现）：map 到 reduce 会经过 shuffle 阶段，在 shuffle 中默认会按照 key进行 hash，<strong>如果相同的 key 过多，那么 hash 的结果就是大量相同的 key 进入到同一个 reduce 中</strong>，导致数据倾斜</p>
<p>简而言之：旱的旱死涝的涝死</p>
<h2 id="12-2-数据倾斜解决方案"><a href="#12-2-数据倾斜解决方案" class="headerlink" title="12.2 数据倾斜解决方案"></a>12.2 数据倾斜解决方案</h2><h3 id="12-2-1-空值引发的数据倾斜"><a href="#12-2-1-空值引发的数据倾斜" class="headerlink" title="12.2.1 空值引发的数据倾斜"></a>12.2.1 空值引发的数据倾斜</h3><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><p>实际业务中有些大量的 null 值或者一些无意义的数据参与到计算作业中，表中有大量的 null 值，如果表之间进行 join 操作，就会有 shuffle 产生，<strong>这样所有的 null 值都会被分配到一个 reduce 中，必然产生数据倾斜。</strong></p>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>①可以直接不让 null 值参与 join 操作，即不让 null 值有 shuffle 阶段</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM log a</span><br><span class="line">JOIN users b</span><br><span class="line">ON a.user_id IS NOT NULL</span><br><span class="line">AND a.user_id = b.user_id</span><br><span class="line">UNION ALL</span><br><span class="line">SELECT *</span><br><span class="line">FROM log a</span><br><span class="line">WHERE a.user_id IS NULL;</span><br></pre></td></tr></table></figure>

<p>②因为 null 值参与 shuffle 时的 hash 结果是一样的，那么我们可以给null 值随机赋值，这样它们的 hash 结果就不一样，就会进到不同的 reduce 中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM log a</span><br><span class="line">LEFT JOIN users b ON CASE</span><br><span class="line">WHEN a.user_id IS NULL THEN concat(&#x27;hive_&#x27;, rand())</span><br><span class="line">ELSE a.user_id</span><br><span class="line">END = b.user_id;</span><br></pre></td></tr></table></figure>

<h3 id="12-2-2-不同数据类型引发的数据倾斜"><a href="#12-2-2-不同数据类型引发的数据倾斜" class="headerlink" title="12.2.2 不同数据类型引发的数据倾斜"></a>12.2.2 不同数据类型引发的数据倾斜</h3><h4 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h4><p>对于两个表join，表a中需要 join的字段key为 int，表b中key 字段既有string类型也有 int 类型。当按照 key 进行两个表的 join 操作时，默认的 Hash 操作会按 int 型的 id 来进行分配，这样所有的 string 类型都被分配成同一个 id，结果就是所有的 string 类型的字段进入到一个 reduce 中，引发数据倾斜。</p>
<h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p>如果 key 字段既有 string 类型也有 int 类型，默认的 hash 就都会按 int 类型来分配，那我们直接把 int 类型都转为 string 就好了，这样 key 字段都为 string，hash 时就按照 string 类型分配了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT *</span><br><span class="line">FROM users a</span><br><span class="line">LEFT JOIN logs b ON a.usr_id = CAST(b.user_id AS string);</span><br></pre></td></tr></table></figure>

<h3 id="12-2-3-不可拆分大文件引发的数据倾斜"><a href="#12-2-3-不可拆分大文件引发的数据倾斜" class="headerlink" title="12.2.3 不可拆分大文件引发的数据倾斜"></a>12.2.3 不可拆分大文件引发的数据倾斜</h3><h4 id="原因-2"><a href="#原因-2" class="headerlink" title="原因"></a>原因</h4><p>如果文件使用GZIP压缩等不支持文件分割操作的压缩方式时，若该不可分割的文件超大，被一个map读取时，就会发生map阶段的数据倾斜。</p>
<h4 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h4><p>这种数据倾斜问题没有什么好的解决方案，只能将使用 GZIP 压缩等不支持文件分割的文件转为 bzip 和 zip 等支持文件分割的压缩方式。所以，<strong>我们在对文件进行压缩时，为避免因不可拆分大文件而引发数据读取的倾斜，在数据压缩的时候可以采用 bzip2 和 Zip 等支持文件分割的压缩算法</strong>。</p>
<h3 id="12-2-4-数据膨胀引发的数据倾斜"><a href="#12-2-4-数据膨胀引发的数据倾斜" class="headerlink" title="12.2.4 数据膨胀引发的数据倾斜"></a>12.2.4 数据膨胀引发的数据倾斜</h3><h4 id="原因-3"><a href="#原因-3" class="headerlink" title="原因"></a>原因</h4><p>在多维聚合计算时，如果进行分组聚合的字段过多，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select a，b，c，count（1）from log group by a，b，c with rollup;</span><br></pre></td></tr></table></figure>

<p>如果上面的 log 表的数据量很大，并且 Map 端的聚合不能很好地起到数据压缩的情况下，会导致 Map 端产出的数据急速膨胀，这种情况容易导致作业内存溢出的异常。如果 log 表含有数据倾斜 key，会加剧 Shuffle 过程的数据倾斜。</p>
<h4 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h4><p>在 Hive 中可以通过参数 hive.new.job.grouping.set.cardinality 配置的方式自动控制作业的拆解，该参数默认值是 30。表示针对 groupingsets&#x2F;rollups&#x2F;cubes 这类多维聚合的操作，如果最后拆解的键组合大于该值，会启用新的任务去处理大于该值之外的组合。如果在处理数据时，某个分组聚合的列有较大的倾斜，可以适当调小该值。</p>
<h3 id="12-2-5-表join连接时引发的数据倾斜"><a href="#12-2-5-表join连接时引发的数据倾斜" class="headerlink" title="12.2.5 表join连接时引发的数据倾斜"></a>12.2.5 表join连接时引发的数据倾斜</h3><p>去看前面的内容，此处略</p>
<h3 id="12-2-6-确实无法减少数据量引发的数据倾斜"><a href="#12-2-6-确实无法减少数据量引发的数据倾斜" class="headerlink" title="12.2.6 确实无法减少数据量引发的数据倾斜"></a>12.2.6 确实无法减少数据量引发的数据倾斜</h3><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>这类问题最直接的方式就是调整 reduce 所执行的内存大小。调整 reduce 的内存大小使用 mapreduce.reduce.memory.mb 这个配置</p>

      

      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>谢谢您的支持<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    
                    <div class="reward-box-item">
                      <img class="reward-img" src="/img/wechatpay.jpg">
                      <span class="reward-type">微信</span>
                    </div>
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//pan.baidu.com/share/qrcode?url=http://example.com/2023/10/07/Hive%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2023/10/11/scala%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          scala语言学习笔记
        
      </div>
    </a>
  
  
    <a href="/2023/08/05/Hadoop%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Hadoop框架学习笔记</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>


<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
        <div class="toc-container tooltip-left">
            <i class="icon-font icon-category"></i>
            <div class="tooltip tooltip-east">
                <span class="tooltip-item">
                </span>
                <span class="tooltip-content">
                    <div class="toc-article">
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-Hive%E5%85%A5%E9%97%A8"><span class="toc-number">1.</span> <span class="toc-text">第一章 Hive入门</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E4%BB%80%E4%B9%88%E6%98%AFHive"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 什么是Hive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-Hive%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 Hive架构原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-Hive-SQL%E7%BC%96%E8%AF%91%E6%88%90MapReduce%E7%9A%84%E8%BF%87%E7%A8%8B"><span class="toc-number">1.3.</span> <span class="toc-text">1.3 Hive SQL编译成MapReduce的过程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-Hive%E5%AE%89%E8%A3%85"><span class="toc-number">2.</span> <span class="toc-text">第二章 Hive安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Hive%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 Hive安装部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1-%E5%AE%89%E8%A3%85Hive"><span class="toc-number">2.1.1.</span> <span class="toc-text">2.1.1 安装Hive</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-2-%E5%90%AF%E5%8A%A8%E5%B9%B6%E4%BD%BF%E7%94%A8Hive"><span class="toc-number">2.1.2.</span> <span class="toc-text">2.1.2 启动并使用Hive</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-MySQL%E5%AE%89%E8%A3%85"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 MySQL安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-%E5%AE%89%E8%A3%85MySQL"><span class="toc-number">2.2.1.</span> <span class="toc-text">2.2.1 安装MySQL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-%E9%85%8D%E7%BD%AEMySQL"><span class="toc-number">2.2.2.</span> <span class="toc-text">2.2.2 配置MySQL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E9%85%8D%E7%BD%AEHive%E5%85%83%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%88%B0MySQL"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 配置Hive元数据存储到MySQL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-%E9%85%8D%E7%BD%AE%E5%85%83%E6%95%B0%E6%8D%AE%E5%88%B0MySQL"><span class="toc-number">2.3.1.</span> <span class="toc-text">2.3.1 配置元数据到MySQL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-%E9%AA%8C%E8%AF%81%E5%85%83%E6%95%B0%E6%8D%AE%E6%98%AF%E5%90%A6%E9%85%8D%E7%BD%AE%E6%88%90%E5%8A%9F"><span class="toc-number">2.3.2.</span> <span class="toc-text">2.3.2 验证元数据是否配置成功</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-3-%E6%9F%A5%E7%9C%8BMySQL%E4%B8%AD%E7%9A%84%E5%85%83%E6%95%B0%E6%8D%AE%EF%BC%88%E4%BA%86%E8%A7%A3%E5%8D%B3%E5%8F%AF%EF%BC%89"><span class="toc-number">2.3.3.</span> <span class="toc-text">2.3.3 查看MySQL中的元数据（了解即可）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-Hive%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 Hive服务部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-1-hiveserver2%E6%9C%8D%E5%8A%A1"><span class="toc-number">2.4.1.</span> <span class="toc-text">2.4.1 hiveserver2服务</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E7%94%A8%E6%88%B7%E8%AF%B4%E6%98%8E"><span class="toc-number">2.4.1.1.</span> <span class="toc-text">（1）用户说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%882%EF%BC%89hiveserver2%E9%83%A8%E7%BD%B2"><span class="toc-number">2.4.1.2.</span> <span class="toc-text">（2）hiveserver2部署</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E6%B5%8B%E8%AF%95"><span class="toc-number">2.4.1.3.</span> <span class="toc-text">（3）测试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E9%85%8D%E7%BD%AEDatagrip%E8%BF%9E%E6%8E%A5"><span class="toc-number">2.4.1.4.</span> <span class="toc-text">（4）配置Datagrip连接</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-2-metastore%E6%9C%8D%E5%8A%A1"><span class="toc-number">2.4.2.</span> <span class="toc-text">2.4.2 metastore服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-3-%E7%BC%96%E5%86%99Hive%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC"><span class="toc-number">2.4.3.</span> <span class="toc-text">2.4.3 编写Hive服务启动脚本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-Hive%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 Hive使用技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-1-Hive%E5%B8%B8%E7%94%A8%E4%BA%A4%E4%BA%92%E5%91%BD%E4%BB%A4"><span class="toc-number">2.5.1.</span> <span class="toc-text">2.5.1 Hive常用交互命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-2-Hive%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F"><span class="toc-number">2.5.2.</span> <span class="toc-text">2.5.2 Hive参数配置方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-3-Hive%E5%B8%B8%E8%A7%81%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE"><span class="toc-number">2.5.3.</span> <span class="toc-text">2.5.3 Hive常见属性配置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-DDL%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89"><span class="toc-number">3.</span> <span class="toc-text">第三章 DDL数据定义</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%88database%EF%BC%89"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 数据库（database）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-1-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">3.1.1.</span> <span class="toc-text">3.1.1 创建数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-2-%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">3.1.2.</span> <span class="toc-text">3.1.2 查询数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-1-%E5%B1%95%E7%A4%BA%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">3.1.2.1 展示所有数据库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-2-%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%A1%E6%81%AF"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">3.1.2.2 查看数据库信息</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-3-%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">3.1.3.</span> <span class="toc-text">3.1.3 修改数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-4-%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%88%E6%85%8E%E7%94%A8%EF%BC%89"><span class="toc-number">3.1.4.</span> <span class="toc-text">3.1.4 删除数据库（慎用）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-5-%E5%88%87%E6%8D%A2%E5%BD%93%E5%89%8D%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">3.1.5.</span> <span class="toc-text">3.1.5 切换当前数据库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-%E8%A1%A8%EF%BC%88table%EF%BC%89"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 表（table）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1-%E5%88%9B%E5%BB%BA%E8%A1%A8"><span class="toc-number">3.2.1.</span> <span class="toc-text">3.2.1 创建表</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-1-%E8%AF%AD%E6%B3%95"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">3.2.1.1 语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-2-%E6%A1%88%E4%BE%8B"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">3.2.1.2 案例</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E5%86%85%E9%83%A8%E8%A1%A8%E4%B8%8E%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="toc-number">3.2.1.2.1.</span> <span class="toc-text">（1）内部表与外部表</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89SERDE%E5%92%8C%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">3.2.1.2.2.</span> <span class="toc-text">（2）SERDE和复杂数据类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%883%EF%BC%89creat-table-select%E5%92%8Ccreate-table-like"><span class="toc-number">3.2.1.2.3.</span> <span class="toc-text">（3）creat table select和create table like</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2-%E6%9F%A5%E7%9C%8B%E8%A1%A8"><span class="toc-number">3.2.2.</span> <span class="toc-text">3.2.2 查看表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-%E4%BF%AE%E6%94%B9%E8%A1%A8"><span class="toc-number">3.2.3.</span> <span class="toc-text">3.2.3 修改表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-4-%E5%88%A0%E9%99%A4%E8%A1%A8"><span class="toc-number">3.2.4.</span> <span class="toc-text">3.2.4 删除表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-5-%E6%B8%85%E7%A9%BA%E8%A1%A8"><span class="toc-number">3.2.5.</span> <span class="toc-text">3.2.5 清空表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-DML%EF%BC%88%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">第四章 DML（数据操作）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-Load"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 Load</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-Insert"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 Insert</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1-%E5%B0%86%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E6%8F%92%E5%85%A5%E8%A1%A8%E4%B8%AD"><span class="toc-number">4.2.1.</span> <span class="toc-text">4.2.1 将查询结果插入表中</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-2-%E5%B0%86%E7%BB%99%E5%AE%9AValues%E6%8F%92%E5%85%A5%E8%A1%A8%E4%B8%AD"><span class="toc-number">4.2.2.</span> <span class="toc-text">4.2.2 将给定Values插入表中</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-3-%E5%B0%86%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E5%86%99%E5%85%A5%E7%9B%AE%E6%A0%87%E8%B7%AF%E5%BE%84"><span class="toc-number">4.2.3.</span> <span class="toc-text">4.2.3 将查询结果写入目标路径</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-Export-amp-Import"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 Export&amp;Import</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-%E6%9F%A5%E8%AF%A2"><span class="toc-number">5.</span> <span class="toc-text">第五章 查询</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 基础语法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-%E5%9F%BA%E6%9C%AC%E6%9F%A5%E8%AF%A2%EF%BC%88Select%E2%80%A6from%EF%BC%89"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 基本查询（Select…from）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-1-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">5.2.1.</span> <span class="toc-text">5.2.1 数据准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-2-%E5%85%A8%E8%A1%A8%E5%92%8C%E7%89%B9%E5%AE%9A%E5%88%97%E6%9F%A5%E8%AF%A2"><span class="toc-number">5.2.2.</span> <span class="toc-text">5.2.2 全表和特定列查询</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-3-%E5%88%97%E5%88%AB%E5%90%8D"><span class="toc-number">5.2.3.</span> <span class="toc-text">5.2.3 列别名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-4-Limit%E8%AF%AD%E5%8F%A5"><span class="toc-number">5.2.4.</span> <span class="toc-text">5.2.4 Limit语句</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-5-Where%E8%AF%AD%E5%8F%A5"><span class="toc-number">5.2.5.</span> <span class="toc-text">5.2.5 Where语句</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-6-%E5%85%B3%E7%B3%BB%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="toc-number">5.2.6.</span> <span class="toc-text">5.2.6 关系运算符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-7-%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="toc-number">5.2.7.</span> <span class="toc-text">5.2.7 逻辑运算符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-8-%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0"><span class="toc-number">5.2.8.</span> <span class="toc-text">5.2.8 聚合函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-%E5%88%86%E7%BB%84"><span class="toc-number">5.3.</span> <span class="toc-text">5.3 分组</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-1-Group-By%E8%AF%AD%E5%8F%A5"><span class="toc-number">5.3.1.</span> <span class="toc-text">5.3.1 Group By语句</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-2-Having%E8%AF%AD%E5%8F%A5"><span class="toc-number">5.3.2.</span> <span class="toc-text">5.3.2 Having语句</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-Join%E8%AF%AD%E5%8F%A5"><span class="toc-number">5.4.</span> <span class="toc-text">5.4 Join语句</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-1-%E7%AD%89%E5%80%BCJoin"><span class="toc-number">5.4.1.</span> <span class="toc-text">5.4.1 等值Join</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-2-%E5%86%85%E8%BF%9E%E6%8E%A5"><span class="toc-number">5.4.2.</span> <span class="toc-text">5.4.2 内连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-3-%E5%B7%A6%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="toc-number">5.4.3.</span> <span class="toc-text">5.4.3 左外连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-4-%E5%8F%B3%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="toc-number">5.4.4.</span> <span class="toc-text">5.4.4. 右外连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-5-%E6%BB%A1%EF%BC%88%E5%85%A8%EF%BC%89%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="toc-number">5.4.5.</span> <span class="toc-text">5.4.5 满（全）外连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-6-%E5%A4%9A%E8%A1%A8%E8%BF%9E%E6%8E%A5"><span class="toc-number">5.4.6.</span> <span class="toc-text">5.4.6 多表连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-7-%E7%AC%9B%E5%8D%A1%E5%B0%94%E7%A7%AF"><span class="toc-number">5.4.7.</span> <span class="toc-text">5.4.7 笛卡尔积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-8-%E8%81%94%E5%90%88%EF%BC%88union-amp-union-all%EF%BC%89"><span class="toc-number">5.4.8.</span> <span class="toc-text">5.4.8 联合（union&amp;union all）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-%E6%8E%92%E5%BA%8F"><span class="toc-number">5.5.</span> <span class="toc-text">5.5 排序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-1-%E5%85%A8%E5%B1%80%E6%8E%92%E5%BA%8F%EF%BC%88order-by%EF%BC%89"><span class="toc-number">5.5.1.</span> <span class="toc-text">5.5.1 全局排序（order by）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-2-%E6%AF%8F%E4%B8%AAReduce%E5%86%85%E9%83%A8%E6%8E%92%E5%BA%8F%EF%BC%88sort-by%EF%BC%89"><span class="toc-number">5.5.2.</span> <span class="toc-text">5.5.2 每个Reduce内部排序（sort by）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-3-%E5%88%86%E5%8C%BA%EF%BC%88distribute-by%EF%BC%89"><span class="toc-number">5.5.3.</span> <span class="toc-text">5.5.3 分区（distribute by）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-4-%E5%88%86%E5%8C%BA%E6%8E%92%E5%BA%8F%EF%BC%88cluster-by%EF%BC%89"><span class="toc-number">5.5.4.</span> <span class="toc-text">5.5.4 分区排序（cluster by）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E7%BB%83%E4%B9%A0%EF%BC%88%E5%88%9D%E7%BA%A7%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">第六章 综合案例练习（初级）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%E7%AB%A0-%E5%87%BD%E6%95%B0"><span class="toc-number">7.</span> <span class="toc-text">第七章 函数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-%E5%8D%95%E8%A1%8C%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.</span> <span class="toc-text">7.1 单行函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-1-%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.1.</span> <span class="toc-text">7.1.1 算术运算函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-2-%E6%95%B0%E5%80%BC%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.2.</span> <span class="toc-text">7.1.2 数值函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-3-%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.3.</span> <span class="toc-text">7.1.3 字符串函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-4-%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.4.</span> <span class="toc-text">7.1.4 日期函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-5-%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.5.</span> <span class="toc-text">7.1.5 流程控制函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-6-%E9%9B%86%E5%90%88%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.6.</span> <span class="toc-text">7.1.6 集合函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-7-%E6%A1%88%E4%BE%8B%E5%87%86%E5%A4%87"><span class="toc-number">7.1.7.</span> <span class="toc-text">7.1.7 案例准备</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-%E9%AB%98%E7%BA%A7%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0"><span class="toc-number">7.2.</span> <span class="toc-text">7.2 高级聚合函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-1-%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">7.2.1.</span> <span class="toc-text">7.2.1 案例演示</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-%E7%82%B8%E8%A3%82%E5%87%BD%E6%95%B0%EF%BC%88%E9%87%8D%E9%9A%BE%E7%82%B9%EF%BC%89"><span class="toc-number">7.3.</span> <span class="toc-text">7.3 炸裂函数（重难点）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-1-%E6%A6%82%E8%BF%B0"><span class="toc-number">7.3.1.</span> <span class="toc-text">7.3.1 概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-2-%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">7.3.2.</span> <span class="toc-text">7.3.2 案例演示</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-4-%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0%EF%BC%88%E5%BC%80%E7%AA%97%E5%87%BD%E6%95%B0%EF%BC%89"><span class="toc-number">7.4.</span> <span class="toc-text">7.4 窗口函数（开窗函数）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-1-%E6%A6%82%E8%BF%B0"><span class="toc-number">7.4.1.</span> <span class="toc-text">7.4.1 概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-2-%E5%B8%B8%E7%94%A8%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0"><span class="toc-number">7.4.2.</span> <span class="toc-text">7.4.2 常用窗口函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-3-%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="toc-number">7.4.3.</span> <span class="toc-text">7.4.3 案例演示</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-5-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%EF%BC%88%E7%94%A8%E7%9A%84%E4%B8%8D%E5%A4%9A%EF%BC%89"><span class="toc-number">7.5.</span> <span class="toc-text">7.5 自定义函数（用的不多）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-6-%E8%87%AA%E5%AE%9A%E4%B9%89UDF%E5%87%BD%E6%95%B0"><span class="toc-number">7.6.</span> <span class="toc-text">7.6 自定义UDF函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%85%AB%E7%AB%A0-%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E7%BB%83%E4%B9%A0%EF%BC%88%E4%B8%AD%E7%BA%A7%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">第八章 综合案例练习（中级）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E5%88%86%E5%8C%BA%E8%A1%A8%E5%92%8C%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="toc-number">9.</span> <span class="toc-text">第九章 分区表和分桶表</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#9-1-%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="toc-number">9.1.</span> <span class="toc-text">9.1 分区表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-1-%E5%88%86%E5%8C%BA%E8%A1%A8%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="toc-number">9.1.1.</span> <span class="toc-text">9.1.1 分区表基本语法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%88%9B%E5%BB%BA%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="toc-number">9.1.1.1.</span> <span class="toc-text">1. 创建分区表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%88%86%E5%8C%BA%E8%A1%A8%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE"><span class="toc-number">9.1.1.2.</span> <span class="toc-text">2. 分区表读写数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E5%88%86%E5%8C%BA%E8%A1%A8%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="toc-number">9.1.1.3.</span> <span class="toc-text">3. 分区表基本操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-2-%E4%BA%8C%E7%BA%A7%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="toc-number">9.1.2.</span> <span class="toc-text">9.1.2 二级分区表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-3-%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA"><span class="toc-number">9.1.3.</span> <span class="toc-text">9.1.3 动态分区</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-2-%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="toc-number">9.2.</span> <span class="toc-text">9.2 分桶表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-1-%E5%88%86%E6%A1%B6%E8%A1%A8%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="toc-number">9.2.1.</span> <span class="toc-text">9.2.1 分桶表基本语法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E7%AB%A0-%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E5%92%8C%E5%8E%8B%E7%BC%A9"><span class="toc-number">10.</span> <span class="toc-text">第十章 文件格式和压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#10-1-Hadoop%E5%8E%8B%E7%BC%A9%E6%A6%82%E8%BF%B0"><span class="toc-number">10.1.</span> <span class="toc-text">10.1 Hadoop压缩概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-2-Hive%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F"><span class="toc-number">10.2.</span> <span class="toc-text">10.2 Hive文件格式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-1-Text-File"><span class="toc-number">10.2.1.</span> <span class="toc-text">10.2.1 Text File</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-2-ORC"><span class="toc-number">10.2.2.</span> <span class="toc-text">10.2.2 ORC</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-3-Parquet"><span class="toc-number">10.2.3.</span> <span class="toc-text">10.2.3 Parquet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-3-%E5%8E%8B%E7%BC%A9"><span class="toc-number">10.3.</span> <span class="toc-text">10.3 压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-1-Hive%E8%A1%A8%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%8E%8B%E7%BC%A9"><span class="toc-number">10.3.1.</span> <span class="toc-text">10.3.1 Hive表数据进行压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-2-%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E4%B8%AD%E4%BD%BF%E7%94%A8%E5%8E%8B%E7%BC%A9"><span class="toc-number">10.3.2.</span> <span class="toc-text">10.3.2 计算过程中使用压缩</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0-%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%B0%83%E4%BC%98"><span class="toc-number">11.</span> <span class="toc-text">第十一章 企业级调优</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-1-%E8%AE%A1%E7%AE%97%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE"><span class="toc-number">11.1.</span> <span class="toc-text">11.1 计算资源配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-1-Yarn%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE"><span class="toc-number">11.1.1.</span> <span class="toc-text">11.1.1 Yarn资源配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-2-MapRuduce%E8%B5%84%E6%BA%90%E9%85%8D%E7%BD%AE"><span class="toc-number">11.1.2.</span> <span class="toc-text">11.1.2 MapRuduce资源配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-2-%E6%B5%8B%E8%AF%95%E7%94%A8%E8%A1%A8%EF%BC%88%E7%95%A5%EF%BC%89"><span class="toc-number">11.2.</span> <span class="toc-text">11.2 测试用表（略）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-3-Explain%E6%9F%A5%E7%9C%8B%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">11.3.</span> <span class="toc-text">11.3 Explain查看执行计划（重点）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-3-1-Explain%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E6%A6%82%E8%BF%B0"><span class="toc-number">11.3.1.</span> <span class="toc-text">11.3.1 Explain执行计划概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-3-2-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="toc-number">11.3.2.</span> <span class="toc-text">11.3.2 基本语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-3-3-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">11.3.3.</span> <span class="toc-text">11.3.3 案例实操</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-4-HQL%E8%AF%AD%E6%B3%95%E4%BC%98%E5%8C%96%E4%B9%8B%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E4%BC%98%E5%8C%96"><span class="toc-number">11.4.</span> <span class="toc-text">11.4 HQL语法优化之分组聚合优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-4-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.4.1.</span> <span class="toc-text">11.4.1 优化说明</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-5-HQL%E8%AF%AD%E6%B3%95%E4%BC%98%E5%8C%96%E4%B9%8BJoin%E4%BC%98%E5%8C%96"><span class="toc-number">11.5.</span> <span class="toc-text">11.5 HQL语法优化之Join优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-5-1-Join%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="toc-number">11.5.1.</span> <span class="toc-text">11.5.1 Join算法概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-5-2-Map-Join"><span class="toc-number">11.5.2.</span> <span class="toc-text">11.5.2 Map Join</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-2-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.5.2.1.</span> <span class="toc-text">11.5.2.1 优化说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-2-2-%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B"><span class="toc-number">11.5.2.2.</span> <span class="toc-text">11.5.2.2 优化案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-5-3-Bucket-Map-Join"><span class="toc-number">11.5.3.</span> <span class="toc-text">11.5.3 Bucket Map Join</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-3-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.5.3.1.</span> <span class="toc-text">11.5.3.1 优化说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-3-2-%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B"><span class="toc-number">11.5.3.2.</span> <span class="toc-text">11.5.3.2 优化案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-5-4-Sort-Merge-Bucket-Map-Join"><span class="toc-number">11.5.4.</span> <span class="toc-text">11.5.4 Sort Merge Bucket Map Join</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-4-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.5.4.1.</span> <span class="toc-text">11.5.4.1 优化说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-5-4-2-%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B"><span class="toc-number">11.5.4.2.</span> <span class="toc-text">11.5.4.2 优化案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-6-HQL%E8%AF%AD%E6%B3%95%E4%BC%98%E5%8C%96%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">11.6.</span> <span class="toc-text">11.6 HQL语法优化之数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-6-1-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E6%A6%82%E8%BF%B0"><span class="toc-number">11.6.1.</span> <span class="toc-text">11.6.1 数据倾斜概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-6-2-%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">11.6.2.</span> <span class="toc-text">11.6.2 分组聚合导致的数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-6-2-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.6.2.1.</span> <span class="toc-text">11.6.2.1 优化说明</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89Map-Side%E8%81%9A%E5%90%88"><span class="toc-number">11.6.2.1.1.</span> <span class="toc-text">（1）Map-Side聚合</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89Skew-GroupBy%E4%BC%98%E5%8C%96"><span class="toc-number">11.6.2.1.2.</span> <span class="toc-text">（2）Skew-GroupBy优化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-6-3-Join%E5%AF%BC%E8%87%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">11.6.3.</span> <span class="toc-text">11.6.3 Join导致的数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-6-3-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.6.3.1.</span> <span class="toc-text">11.6.3.1 优化说明</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89map-join"><span class="toc-number">11.6.3.1.1.</span> <span class="toc-text">（1）map join</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89skew-join"><span class="toc-number">11.6.3.1.2.</span> <span class="toc-text">（2）skew join</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E8%B0%83%E6%95%B4SQL%E8%AF%AD%E5%8F%A5"><span class="toc-number">11.6.3.1.3.</span> <span class="toc-text">（3）调整SQL语句</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-7-HQL%E8%AF%AD%E6%B3%95%E4%BC%98%E5%8C%96%E4%B9%8B%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="toc-number">11.7.</span> <span class="toc-text">11.7 HQL语法优化之任务并行度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-7-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.7.1.</span> <span class="toc-text">11.7.1 优化说明</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-7-1-1-Map%E7%AB%AF%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="toc-number">11.7.1.1.</span> <span class="toc-text">11.7.1.1 Map端并行度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-7-1-2-Reduce%E7%AB%AF%E7%9A%84%E5%B9%B6%E8%A1%8C%E5%BA%A6"><span class="toc-number">11.7.1.2.</span> <span class="toc-text">11.7.1.2 Reduce端的并行度</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-8-HQL%E8%AF%AD%E6%B3%95%E4%BC%98%E5%8C%96%E4%B9%8B%E5%B0%8F%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6"><span class="toc-number">11.8.</span> <span class="toc-text">11.8 HQL语法优化之小文件合并</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HIve%E4%B8%AD%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BA%A7%E7%94%9F%E7%9A%84%E5%8E%9F%E5%9B%A0"><span class="toc-number">11.8.1.</span> <span class="toc-text">HIve中小文件产生的原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E6%96%87%E4%BB%B6%E8%BF%87%E5%A4%9A%E7%9A%84%E5%8D%B1%E5%AE%B3"><span class="toc-number">11.8.2.</span> <span class="toc-text">小文件过多的危害</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-8-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.8.3.</span> <span class="toc-text">11.8.1 优化说明</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-8-1-1-Map%E7%AB%AF%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6"><span class="toc-number">11.8.3.1.</span> <span class="toc-text">11.8.1.1 Map端输入文件合并</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-8-1-2-Reduce%E7%AB%AF%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6"><span class="toc-number">11.8.3.2.</span> <span class="toc-text">11.8.1.2 Reduce端文件合并</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-8-1-3-%E5%87%8F%E5%B0%91Reduce%E7%9A%84%E6%95%B0%E9%87%8F"><span class="toc-number">11.8.3.3.</span> <span class="toc-text">11.8.1.3 减少Reduce的数量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-8-1-4-%E4%BD%BF%E7%94%A8Hive%E8%87%AA%E5%B8%A6%E7%9A%84concatenate%E5%91%BD%E4%BB%A4%EF%BC%8C%E8%87%AA%E5%8A%A8%E5%90%88%E5%B9%B6%E5%B0%8F%E6%96%87%E4%BB%B6"><span class="toc-number">11.8.3.4.</span> <span class="toc-text">11.8.1.4 使用Hive自带的concatenate命令，自动合并小文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-8-1-5-%E4%BD%BF%E7%94%A8hadoop%E7%9A%84archive%E5%B0%86%E5%B0%8F%E6%96%87%E4%BB%B6%E5%BD%92%E6%A1%A3"><span class="toc-number">11.8.3.5.</span> <span class="toc-text">11.8.1.5 使用hadoop的archive将小文件归档</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-9-%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96"><span class="toc-number">11.9.</span> <span class="toc-text">11.9 其他优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-9-1-CBO%E4%BC%98%E5%8C%96"><span class="toc-number">11.9.1.</span> <span class="toc-text">11.9.1 CBO优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-9-1-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.9.1.1.</span> <span class="toc-text">11.9.1.1 优化说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-9-1-2-%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B"><span class="toc-number">11.9.1.2.</span> <span class="toc-text">11.9.1.2 优化案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-9-2-%E8%B0%93%E8%AF%8D%E4%B8%8B%E6%8E%A8"><span class="toc-number">11.9.2.</span> <span class="toc-text">11.9.2 谓词下推</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-9-2-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.9.2.1.</span> <span class="toc-text">11.9.2.1 优化说明</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-9-3-%E7%9F%A2%E9%87%8F%E5%8C%96%E6%9F%A5%E8%AF%A2"><span class="toc-number">11.9.3.</span> <span class="toc-text">11.9.3 矢量化查询</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-9-4-Fetch%E6%8A%93%E5%8F%96"><span class="toc-number">11.9.4.</span> <span class="toc-text">11.9.4 Fetch抓取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-9-5-%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F"><span class="toc-number">11.9.5.</span> <span class="toc-text">11.9.5 本地模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#11-9-5-1-%E4%BC%98%E5%8C%96%E8%AF%B4%E6%98%8E"><span class="toc-number">11.9.5.1.</span> <span class="toc-text">11.9.5.1 优化说明</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-9-6-%E5%B9%B6%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">11.9.6.</span> <span class="toc-text">11.9.6 并行模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-9-7-%E4%B8%A5%E6%A0%BC%E6%A8%A1%E5%BC%8F"><span class="toc-number">11.9.7.</span> <span class="toc-text">11.9.7 严格模式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-10-Hive%E6%95%B0%E6%8D%AE%E6%8A%BD%E6%A0%B7"><span class="toc-number">11.10.</span> <span class="toc-text">11.10 Hive数据抽样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-10-1-%E9%9A%8F%E6%9C%BA%E6%8A%BD%E6%A0%B7"><span class="toc-number">11.10.1.</span> <span class="toc-text">11.10.1 随机抽样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-10-2-%E5%9D%97%E6%8A%BD%E6%A0%B7"><span class="toc-number">11.10.2.</span> <span class="toc-text">11.10.2 块抽样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-10-3-%E6%A1%B6%E8%A1%A8%E6%8A%BD%E6%A0%B7"><span class="toc-number">11.10.3.</span> <span class="toc-text">11.10.3 桶表抽样</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-11-Hive%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E"><span class="toc-number">11.11.</span> <span class="toc-text">11.11 Hive计算引擎</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0-Hive%E5%8D%83%E4%BA%BF%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">12.</span> <span class="toc-text">第十二章 Hive千亿级数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#12-1-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98%E7%9A%84%E6%9C%AC%E8%B4%A8%E5%8E%9F%E5%9B%A0"><span class="toc-number">12.1.</span> <span class="toc-text">12.1 数据倾斜问题的本质原因</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-2-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">12.2.</span> <span class="toc-text">12.2 数据倾斜解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-1-%E7%A9%BA%E5%80%BC%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">12.2.1.</span> <span class="toc-text">12.2.1 空值引发的数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0"><span class="toc-number">12.2.1.1.</span> <span class="toc-text">原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">12.2.1.2.</span> <span class="toc-text">解决方案</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-2-%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">12.2.2.</span> <span class="toc-text">12.2.2 不同数据类型引发的数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0-1"><span class="toc-number">12.2.2.1.</span> <span class="toc-text">原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-1"><span class="toc-number">12.2.2.2.</span> <span class="toc-text">解决方案</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-3-%E4%B8%8D%E5%8F%AF%E6%8B%86%E5%88%86%E5%A4%A7%E6%96%87%E4%BB%B6%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">12.2.3.</span> <span class="toc-text">12.2.3 不可拆分大文件引发的数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0-2"><span class="toc-number">12.2.3.1.</span> <span class="toc-text">原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-2"><span class="toc-number">12.2.3.2.</span> <span class="toc-text">解决方案</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-4-%E6%95%B0%E6%8D%AE%E8%86%A8%E8%83%80%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">12.2.4.</span> <span class="toc-text">12.2.4 数据膨胀引发的数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0-3"><span class="toc-number">12.2.4.1.</span> <span class="toc-text">原因</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-3"><span class="toc-number">12.2.4.2.</span> <span class="toc-text">解决方案</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-5-%E8%A1%A8join%E8%BF%9E%E6%8E%A5%E6%97%B6%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">12.2.5.</span> <span class="toc-text">12.2.5 表join连接时引发的数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-2-6-%E7%A1%AE%E5%AE%9E%E6%97%A0%E6%B3%95%E5%87%8F%E5%B0%91%E6%95%B0%E6%8D%AE%E9%87%8F%E5%BC%95%E5%8F%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">12.2.6.</span> <span class="toc-text">12.2.6 确实无法减少数据量引发的数据倾斜</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="toc-number">12.2.6.1.</span> <span class="toc-text">解决办法</span></a></li></ol></li></ol></li></ol></li></ol>
                    </div>
                </span>
            </div>
        </div>
        
    </div>
</aside>



  
  
  

  

  

  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2023 John Doe
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据科学</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">因子投资</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">随笔</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">推荐系统</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据仓库</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">常用算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">聚宽</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">贝叶斯</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">NLP基础</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">考试</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">项目</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">面试</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://www.csdn.net/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>CSDN</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.zhihu.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>知乎</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.huaweicloud.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>华为云</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.aliyun.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>阿里云</a>
            </li>
          
            <li class="search-li">
              <a href="https://leetcode.cn/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>力扣</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.joinquant.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>聚宽</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">王宇涵//本科：哈尔滨工程大学//研究生：大连理工大学//专业：计算机技术//方向：量化交易与深度学习//热爱大数据平台开发与数仓开发，会分享一些技术文章和读书笔记</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>