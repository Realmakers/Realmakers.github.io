<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://example.com">
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div> 
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/123.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/categories">分类</a></li>
	        
			</ul>
		</nav>
		<nav>
			总文章数 58
		</nav>		
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
		        
					<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
		        
					<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>



    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/img/123.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Realmakers" title="github"><i class="icon-github"></i></a>
			        
						<a class="qq" target="_blank" href="/3558084726" title="qq"><i class="icon-qq"></i></a>
			        
						<a class="mail" target="_blank" href="mailto: 17745182605@163.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/categories">分类</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-数据仓库建模指南" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/22/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E6%A8%A1%E6%8C%87%E5%8D%97/">数据仓库建模指南</a>
    </h1>
  

        
        <a href="/2025/05/22/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E6%A8%A1%E6%8C%87%E5%8D%97/" class="archive-article-date">
  	<time datetime="2025-05-22T10:52:53.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2025-05-22</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2025/05/22/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E6%A8%A1%E6%8C%87%E5%8D%97/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-计算广告业务知识总结" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/13/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">计算广告业务知识总结</a>
    </h1>
  

        
        <a href="/2025/05/13/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/" class="archive-article-date">
  	<time datetime="2025-05-13T13:57:50.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2025-05-13</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="互联网思维之“三个不要”"><a href="#互联网思维之“三个不要”" class="headerlink" title="互联网思维之“三个不要”"></a>互联网思维之“三个不要”</h1><p>“不要命”：用<strong>股权激励</strong>让程序员以996方式工作</p>
<p>“不要脸”：无底线<strong>迎合用户</strong>的产品与营销方式</p>
<p>“不要钱”：<strong>免费倾销</strong>加<strong>后向变现</strong>的商业模式</p>
<h1 id="什么是“免费模式”？"><a href="#什么是“免费模式”？" class="headerlink" title="什么是“免费模式”？"></a>什么是“免费模式”？</h1><p>免费模式的本质：能够个性化传播信息的产品，售价都会趋向其<strong>边际成本</strong></p>
<p>免费模式举例：</p>
<ul>
<li>网站，应用：边际成本约等于0</li>
<li>手机、电视：边际成本约等于量产成本</li>
</ul>
<p>免费模式目的：获得其他资产，通过<strong>后向渠道变现</strong></p>
<h1 id="互联网三项可变现核心资产"><a href="#互联网三项可变现核心资产" class="headerlink" title="互联网三项可变现核心资产"></a>互联网三项可变现核心资产</h1><ul>
<li>品牌：根据用户熟悉的形象提高付费内容<strong>关注程度</strong>——大V</li>
<li>数据：根据用户偏好程度提高付费内容<strong>投放效率</strong>——个性化</li>
<li>流量：在正常（Organic）内容里夹带<strong>付费（Sponsored）内容</strong>——规模化</li>
</ul>
<h1 id="流量变现与技术变现"><a href="#流量变现与技术变现" class="headerlink" title="流量变现与技术变现"></a>流量变现与技术变现</h1><p><img src="image-20250522191603845.png" alt="image-20250522191603845"></p>
<p>没有数据资产，技术是没有意义的</p>
<h1 id="品牌属性变现"><a href="#品牌属性变现" class="headerlink" title="品牌属性变现"></a>品牌属性变现</h1><p><img src="image-20250522192029058.png" alt="image-20250522192029058"></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">随笔</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/其他//" class="article-tag-list-link color3">其他</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2025/05/13/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E4%B8%9A%E5%8A%A1%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Flink编程中的Java基础" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/08/Flink%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84Java%E5%9F%BA%E7%A1%80/">Flink编程中的Java基础</a>
    </h1>
  

        
        <a href="/2025/05/08/Flink%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84Java%E5%9F%BA%E7%A1%80/" class="archive-article-date">
  	<time datetime="2025-05-08T07:00:32.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2025-05-08</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>Flink编程主要分为DataStream API、Table API和SQL API，目前大部分互联网大厂的实时数仓部分都会使用Flink的SQL API或者自研SQL语法，DataStream API、Table API只有在平台开发或者写一些UDF的时候用到，本文主要是讲一下在进行DataStream API、Table API编程中的常用的Java基础，以便在看Flink代码的时候可以轻松应对和梳理。需要注意的是，本文讲述的Java基础并不包括通用的Java知识如面向对象、IO流、网络编程、多线程、集合、泛型、反射。</p>
</blockquote>
<h1 id="第一章-Lambda表达式"><a href="#第一章-Lambda表达式" class="headerlink" title="第一章 Lambda表达式"></a>第一章 Lambda表达式</h1><h2 id="1-1-引子"><a href="#1-1-引子" class="headerlink" title="1.1 引子"></a>1.1 引子</h2><p>在FLink编程中的DataStream API经常会遇到各种算子，这种算子分为单流，多流，或者流的转换，常用的单流算子如Map、Fliter、FlatMap等，如下展示了FLink DataStream API中的Map操作</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//sensorDS是数据源，具体是什么不重要</span></span><br><span class="line"><span class="comment">//方式1：使用匿名实现类</span></span><br><span class="line">SingleOutputStreamOperator&lt;String&gt; mapDS = sensorDS.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;WaterSensor, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">map</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> value.id;<span class="comment">//return value.getId();</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">mapDS.print();</span><br><span class="line"></span><br><span class="line"><span class="comment">//方式2：使用lambda表达式</span></span><br><span class="line">sensorDS.map(v1 -&gt; v1.id).print();</span><br><span class="line"></span><br><span class="line"><span class="comment">//方式3：定义一个类来实现MapFunction接口</span></span><br><span class="line">sensorDS.map(<span class="keyword">new</span> <span class="title class_">MyMapFunction</span>()).print();</span><br><span class="line"><span class="comment">//在另一个包中定义以下类</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyMapFunction</span> <span class="keyword">implements</span> <span class="title class_">MapFunction</span>&lt;WaterSensor,String&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">map</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> value.id;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，sensorDS.map(…)中的map()实际上是Flink中的一个方法，具体方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;R&gt; <span class="title function_">map</span><span class="params">(MapFuntion&lt;T,R&gt; mapper)</span><span class="comment">//当然，map()方法不只有MapFuntion&lt;T,R&gt;这一个接口</span></span><br></pre></td></tr></table></figure>

<p>map()方法以一个MapFuntion&lt;T,R&gt;接口为参数，<strong>我们需要实现的就是MapFunction&lt;T,R&gt;接口中的R map(T in)方法的重写</strong>。</p>
<p>其中方法3是最标准的写法，先定义一个类来实现MapFunction接口，然后在另一个包中定义我们的类，这种写法复杂不推荐。</p>
<p>方法1使用了匿名内部类，在直接map(new 接口&lt;T,R&gt;(){重写方法})，比较常用，但是还是不够简洁。</p>
<p>方法2使用了lambda表达式，最简洁，接下来进行介绍</p>
<h2 id="1-2-IDEA中的JDK版本查看与设置"><a href="#1-2-IDEA中的JDK版本查看与设置" class="headerlink" title="1.2 IDEA中的JDK版本查看与设置"></a>1.2 IDEA中的JDK版本查看与设置</h2><p>目前本机中下载的JDK版本</p>
<p><img src="image-20250508201135551.png" alt="image-20250508201135551"></p>
<p>修改某个模块的JDK版本</p>
<p><img src="image-20250508200956490.png" alt="image-20250508200956490"></p>
<p>JDK各版本下载地址：</p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.oracle.com/java/technologies/downloads/archive/</span><br></pre></td></tr></table></figure>

<h2 id="1-3-Lambda表达式概述"><a href="#1-3-Lambda表达式概述" class="headerlink" title="1.3 Lambda表达式概述"></a>1.3 Lambda表达式概述</h2><p>Lambda 是一个<strong>匿名函数</strong>，我们可以把 Lambda 表达式理解为是<strong>一段可以传递的代码</strong>（将代码像数据一样进行传递）。使用它可以写出更简洁、更灵活的代码。作为一种更紧凑的代码风格，使Java的语言表达能力得到了提升。</p>
<p><strong>重要：Lambda表达式代替的结构是new 接口&lt;T,R&gt;(){重写方法}</strong></p>
<p>简单举例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">*  使用“lambda形参列表 -&gt; lambda体“代替&quot;new 接口()&#123;重写方法&#125;”</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">r1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;我爱北京天安门&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Lambda表达式的写法</span></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">r2</span> <span class="operator">=</span> () -&gt; System.out.println(<span class="string">&quot;我爱上海东方明珠&quot;</span>);</span><br></pre></td></tr></table></figure>

<h2 id="1-4-Lambda表达式的语法"><a href="#1-4-Lambda表达式的语法" class="headerlink" title="1.4 Lambda表达式的语法"></a>1.4 Lambda表达式的语法</h2><p>Lambda 表达式：在Java 8 语言中引入的一种新的语法元素和操作符。这个操作符为 “<code>-&gt;</code>” ， 该操作符被称为 <code>Lambda 操作符</code>或<code>箭头操作符</code>。它将 Lambda 分为两个部分：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">()-&gt;&#123;&#125;</span><br><span class="line">解释：</span><br><span class="line">    ()：重写方法的参数位置</span><br><span class="line">    -&gt;：将参数传递到方法体中</span><br><span class="line">&#123;&#125;：</span><br></pre></td></tr></table></figure>

<ul>
<li>左侧：<strong>指定了 Lambda 表达式需要的参数列表，也就是需要重写的接口中的抽象方法的形参列表。</strong></li>
<li>右侧：<strong>指定了 Lambda 体，是抽象方法的实现逻辑，也即 Lambda 表达式要执行的功能，也就是需要重写的接口中的抽象方法的方法体。</strong></li>
<li>Lambda表达式只能代替接口中只有一个抽象方法的场景</li>
</ul>
<p><strong>语法格式一：</strong>无参，无返回值</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//未使用Lambda表达式</span></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">r1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Runnable</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;我爱北京天安门&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//使用Lambda表达式</span></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">r2</span> <span class="operator">=</span> () -&gt; &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;我爱北京故宫&quot;</span>);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<img src="image-20250508205904238.png" alt="image-20250508205904238" style="zoom:50%;">

<p><strong>语法格式二：</strong>Lambda 需要一个参数，但是没有返回值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//未使用Lambda表达式</span></span><br><span class="line">Consumer&lt;String&gt; con = <span class="keyword">new</span> <span class="title class_">Consumer</span>&lt;String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(String s)</span> &#123;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//使用Lambda表达式</span></span><br><span class="line">Consumer&lt;String&gt; con1 = (String s) -&gt; &#123;</span><br><span class="line">    System.out.println(s);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<img src="image-20250508210013080.png" alt="image-20250508210013080" style="zoom: 50%;">

<p><strong>语法格式三：</strong>数据类型可以省略，因为可由编译器推断得出，称为“类型推断”</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//语法格式三使用前</span></span><br><span class="line">Consumer&lt;String&gt; con1 = (String s) -&gt; &#123;</span><br><span class="line">    System.out.println(s);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//语法格式三使用后</span></span><br><span class="line">Consumer&lt;String&gt; con2 = (s) -&gt; &#123;</span><br><span class="line">    System.out.println(s);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<img src="image-20250508210239444.png" alt="image-20250508210239444" style="zoom:50%;">

<p><strong>语法格式四：</strong>Lambda 若只需要一个参数时，参数的小括号可以省略</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//语法格式四使用前</span></span><br><span class="line">Consumer&lt;String&gt; con1 = (s) -&gt; &#123;</span><br><span class="line">    System.out.println(s);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//语法格式四使用后</span></span><br><span class="line">Consumer&lt;String&gt; con2 = s -&gt; &#123;</span><br><span class="line">    System.out.println(s);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<p><strong>语法格式五：</strong>Lambda 需要两个或以上的参数，多条执行语句，并且可以有返回值</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//语法格式五使用前</span></span><br><span class="line">Comparator&lt;Integer&gt; com1 = <span class="keyword">new</span> <span class="title class_">Comparator</span>&lt;Integer&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(Integer o1, Integer o2)</span> &#123;</span><br><span class="line">        System.out.println(o1);</span><br><span class="line">        System.out.println(o2);</span><br><span class="line">        <span class="keyword">return</span> o1.compareTo(o2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//语法格式五使用后</span></span><br><span class="line">Comparator&lt;Integer&gt; com2 = (o1,o2) -&gt; &#123;</span><br><span class="line">    System.out.println(o1);</span><br><span class="line">    System.out.println(o2);</span><br><span class="line">    <span class="keyword">return</span> o1.compareTo(o2);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<img src="image-20250508212536387.png" alt="image-20250508212536387" style="zoom:50%;">

<p><strong>语法格式六：</strong>当 Lambda 体只有一条语句时，return 与大括号若有，都可以省略</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//语法格式六使用前</span></span><br><span class="line">Comparator&lt;Integer&gt; com1 = (o1,o2) -&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> o1.compareTo(o2);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//语法格式六使用后</span></span><br><span class="line">Comparator&lt;Integer&gt; com2 = (o1,o2) -&gt; o1.compareTo(o2);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//语法格式六使用前</span></span><br><span class="line">Consumer&lt;String&gt; con1 = s -&gt; &#123;</span><br><span class="line">    System.out.println(s);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//语法格式六使用后</span></span><br><span class="line">Consumer&lt;String&gt; con2 = s -&gt; System.out.println(s);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="第二章-函数式-Functional-接口"><a href="#第二章-函数式-Functional-接口" class="headerlink" title="第二章 函数式(Functional)接口"></a>第二章 函数式(Functional)接口</h1><h2 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h2><ul>
<li>只包含<code>一个抽象方法</code>（Single Abstract Method，简称SAM）的接口，称为函数式接口。当然该接口可以包含其他非抽象方法。</li>
<li>你可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda 表达式抛出一个受检异常(即：非运行时异常)，那么该异常需要在目标接口的抽象方法上进行声明）。</li>
<li>我们可以在一个接口上使用 <code>@FunctionalInterface</code> 注解，这样做可以检查它是否是一个函数式接口。同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接口。</li>
<li>在<code>java.util.function</code>包下定义了Java 8 的丰富的函数式接口</li>
</ul>
<p><strong>简单的说，在Java8中，Lambda表达式就是一个函数式接口的实例。这就是Lambda表达式和函数式接口的关系。也就是说，只要一个对象是函数式接口的实例，那么该对象就可以用Lambda表达式来表示。</strong></p>
<p><img src="image-20220527111442115.png" alt="image-20220527111442115"></p>
<h2 id="2-2-四大核心函数式接口"><a href="#2-2-四大核心函数式接口" class="headerlink" title="2.2 四大核心函数式接口"></a>2.2 四大核心函数式接口</h2><table>
<thead>
<tr>
<th>函数式接口</th>
<th>称谓</th>
<th>参数类型</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td><code>Consumer&lt;T&gt;</code></td>
<td>消费型接口</td>
<td>T</td>
<td><strong>有参数无返回值</strong>；对类型为T的对象应用操作，包含方法：  <code>void accept(T t)</code></td>
</tr>
<tr>
<td><code>Supplier&lt;T&gt;</code></td>
<td>供给型接口</td>
<td>无</td>
<td><strong>无参数有返回值</strong>；返回类型为T的对象，包含方法：<code>T get()</code></td>
</tr>
<tr>
<td><code>Function&lt;T, R&gt;</code></td>
<td>函数型接口</td>
<td>T</td>
<td><strong>有参数有返回值</strong>；对类型为T的对象应用操作，并返回结果。结果是R类型的对象。包含方法：<code>R apply(T t)</code></td>
</tr>
<tr>
<td><code>Predicate&lt;T&gt;</code></td>
<td>判断型接口</td>
<td>T</td>
<td><strong>有参数，只返回布尔值</strong>；确定类型为T的对象是否满足某约束，并返回 boolean 值。包含方法：<code>boolean test(T t)</code></td>
</tr>
</tbody></table>
<h3 id="2-2-1-消费型接口"><a href="#2-2-1-消费型接口" class="headerlink" title="2.2.1 消费型接口"></a>2.2.1 消费型接口</h3><p>消费型接口的抽象方法特点：有形参，但是返回值类型是void</p>
<table>
<thead>
<tr>
<th>接口名</th>
<th>抽象方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>BiConsumer&lt;T,U&gt;</td>
<td>void accept(T t, U u)</td>
<td>接收两个对象用于完成功能</td>
</tr>
<tr>
<td>DoubleConsumer</td>
<td>void accept(double value)</td>
<td>接收一个double值</td>
</tr>
<tr>
<td>IntConsumer</td>
<td>void accept(int value)</td>
<td>接收一个int值</td>
</tr>
<tr>
<td>LongConsumer</td>
<td>void accept(long value)</td>
<td>接收一个long值</td>
</tr>
<tr>
<td>ObjDoubleConsumer<T></T></td>
<td>void accept(T t, double value)</td>
<td>接收一个对象和一个double值</td>
</tr>
<tr>
<td>ObjIntConsumer<T></T></td>
<td>void accept(T t, int value)</td>
<td>接收一个对象和一个int值</td>
</tr>
<tr>
<td>ObjLongConsumer<T></T></td>
<td>void accept(T t, long value)</td>
<td>接收一个对象和一个long值</td>
</tr>
</tbody></table>
<h3 id="2-2-2-供给型接口"><a href="#2-2-2-供给型接口" class="headerlink" title="2.2.2 供给型接口"></a>2.2.2 供给型接口</h3><p>这类接口的抽象方法特点：无参，但是有返回值</p>
<table>
<thead>
<tr>
<th>接口名</th>
<th>抽象方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>BooleanSupplier</td>
<td>boolean getAsBoolean()</td>
<td>返回一个boolean值</td>
</tr>
<tr>
<td>DoubleSupplier</td>
<td>double getAsDouble()</td>
<td>返回一个double值</td>
</tr>
<tr>
<td>IntSupplier</td>
<td>int getAsInt()</td>
<td>返回一个int值</td>
</tr>
<tr>
<td>LongSupplier</td>
<td>long getAsLong()</td>
<td>返回一个long值</td>
</tr>
</tbody></table>
<h3 id="2-2-3-函数型接口"><a href="#2-2-3-函数型接口" class="headerlink" title="2.2.3 函数型接口"></a>2.2.3 函数型接口</h3><p>这类接口的抽象方法特点：既有参数又有返回值</p>
<table>
<thead>
<tr>
<th>接口名</th>
<th>抽象方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>UnaryOperator<T></T></td>
<td>T apply(T t)</td>
<td>接收一个T类型对象，返回一个T类型对象结果</td>
</tr>
<tr>
<td>DoubleFunction<R></R></td>
<td>R apply(double value)</td>
<td>接收一个double值，返回一个R类型对象</td>
</tr>
<tr>
<td>IntFunction<R></R></td>
<td>R apply(int value)</td>
<td>接收一个int值，返回一个R类型对象</td>
</tr>
<tr>
<td>LongFunction<R></R></td>
<td>R apply(long value)</td>
<td>接收一个long值，返回一个R类型对象</td>
</tr>
<tr>
<td>ToDoubleFunction<T></T></td>
<td>double applyAsDouble(T value)</td>
<td>接收一个T类型对象，返回一个double</td>
</tr>
<tr>
<td>ToIntFunction<T></T></td>
<td>int applyAsInt(T value)</td>
<td>接收一个T类型对象，返回一个int</td>
</tr>
<tr>
<td>ToLongFunction<T></T></td>
<td>long applyAsLong(T value)</td>
<td>接收一个T类型对象，返回一个long</td>
</tr>
<tr>
<td>DoubleToIntFunction</td>
<td>int applyAsInt(double value)</td>
<td>接收一个double值，返回一个int结果</td>
</tr>
<tr>
<td>DoubleToLongFunction</td>
<td>long applyAsLong(double value)</td>
<td>接收一个double值，返回一个long结果</td>
</tr>
<tr>
<td>IntToDoubleFunction</td>
<td>double applyAsDouble(int value)</td>
<td>接收一个int值，返回一个double结果</td>
</tr>
<tr>
<td>IntToLongFunction</td>
<td>long applyAsLong(int value)</td>
<td>接收一个int值，返回一个long结果</td>
</tr>
<tr>
<td>LongToDoubleFunction</td>
<td>double applyAsDouble(long value)</td>
<td>接收一个long值，返回一个double结果</td>
</tr>
<tr>
<td>LongToIntFunction</td>
<td>int applyAsInt(long value)</td>
<td>接收一个long值，返回一个int结果</td>
</tr>
<tr>
<td>DoubleUnaryOperator</td>
<td>double applyAsDouble(double operand)</td>
<td>接收一个double值，返回一个double</td>
</tr>
<tr>
<td>IntUnaryOperator</td>
<td>int applyAsInt(int operand)</td>
<td>接收一个int值，返回一个int结果</td>
</tr>
<tr>
<td>LongUnaryOperator</td>
<td>long applyAsLong(long operand)</td>
<td>接收一个long值，返回一个long结果</td>
</tr>
<tr>
<td>BiFunction&lt;T,U,R&gt;</td>
<td>R apply(T t, U u)</td>
<td>接收一个T类型和一个U类型对象，返回一个R类型对象结果</td>
</tr>
<tr>
<td>BinaryOperator<T></T></td>
<td>T apply(T t, T u)</td>
<td>接收两个T类型对象，返回一个T类型对象结果</td>
</tr>
<tr>
<td>ToDoubleBiFunction&lt;T,U&gt;</td>
<td>double applyAsDouble(T t, U u)</td>
<td>接收一个T类型和一个U类型对象，返回一个double</td>
</tr>
<tr>
<td>ToIntBiFunction&lt;T,U&gt;</td>
<td>int applyAsInt(T t, U u)</td>
<td>接收一个T类型和一个U类型对象，返回一个int</td>
</tr>
<tr>
<td>ToLongBiFunction&lt;T,U&gt;</td>
<td>long applyAsLong(T t, U u)</td>
<td>接收一个T类型和一个U类型对象，返回一个long</td>
</tr>
<tr>
<td>DoubleBinaryOperator</td>
<td>double applyAsDouble(double left, double right)</td>
<td>接收两个double值，返回一个double结果</td>
</tr>
<tr>
<td>IntBinaryOperator</td>
<td>int applyAsInt(int left, int right)</td>
<td>接收两个int值，返回一个int结果</td>
</tr>
<tr>
<td>LongBinaryOperator</td>
<td>long applyAsLong(long left, long right)</td>
<td>接收两个long值，返回一个long结果</td>
</tr>
</tbody></table>
<h3 id="2-2-4-判断型接口"><a href="#2-2-4-判断型接口" class="headerlink" title="2.2.4 判断型接口"></a>2.2.4 判断型接口</h3><p>这类接口的抽象方法特点：有参，但是返回值类型是boolean结果。</p>
<table>
<thead>
<tr>
<th>接口名</th>
<th>抽象方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>BiPredicate&lt;T,U&gt;</td>
<td>boolean test(T t, U u)</td>
<td>接收两个对象</td>
</tr>
<tr>
<td>DoublePredicate</td>
<td>boolean test(double value)</td>
<td>接收一个double值</td>
</tr>
<tr>
<td>IntPredicate</td>
<td>boolean test(int value)</td>
<td>接收一个int值</td>
</tr>
<tr>
<td>LongPredicate</td>
<td>boolean test(long value)</td>
<td>接收一个long值</td>
</tr>
</tbody></table>
<h2 id="2-3-函数式接口的例子"><a href="#2-3-函数式接口的例子" class="headerlink" title="2.3 函数式接口的例子"></a>2.3 函数式接口的例子</h2><h3 id="2-3-1-自定义函数式接口的例子"><a href="#2-3-1-自定义函数式接口的例子" class="headerlink" title="2.3.1 自定义函数式接口的例子"></a>2.3.1 自定义函数式接口的例子</h3><p>首先自定义一个函数式接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">USB</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">open</span><span class="params">(String s)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test01</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">USB</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">open</span><span class="params">(String s)</span> &#123;</span><br><span class="line">                System.out.println(s+<span class="string">&quot;开启了&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);<span class="comment">//调用方法，函数式接口作为方法参数传递</span></span><br><span class="line">        System.out.println(<span class="string">&quot;=====lambda========&quot;</span>);</span><br><span class="line">        method(s -&gt; System.out.println(s+<span class="string">&quot;开启了&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> usb 以 USB 接口类型作为参数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(USB usb)</span>&#123;</span><br><span class="line">        usb.open(<span class="string">&quot;鼠标&quot;</span>);<span class="comment">//使用接口对象调用方法</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-2-供给型接口的例子-Supplier"><a href="#2-3-2-供给型接口的例子-Supplier" class="headerlink" title="2.3.2 供给型接口的例子-Supplier"></a>2.3.2 供给型接口的例子-Supplier</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>Supplier接口</span><br><span class="line">    java.util.function.Supplier&lt;T&gt;接口，它意味着“供给”-&gt;我们想要什么它就给什么</span><br><span class="line"><span class="number">2.</span>方法：</span><br><span class="line">    T <span class="title function_">get</span><span class="params">()</span> -&gt; 我们想要什么，get方法就可以返回什么</span><br><span class="line">    </span><br><span class="line"><span class="number">3.</span>需求：</span><br><span class="line">    使用Supplier接口作为方法的参数</span><br><span class="line">    用lambda表达式求出<span class="type">int</span>数组中最大值</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Supplier</span>&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Gets a result.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> a result</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    T <span class="title function_">get</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo1Supplier</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">Supplier</span>&lt;Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Integer <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="type">int</span>[] arr = &#123;<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">7</span>&#125;;</span><br><span class="line">                Arrays.sort(arr);</span><br><span class="line">                <span class="keyword">return</span> arr[arr.length-<span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);<span class="comment">//调用方法，函数式接口作为方法参数传递。使用匿名内部类重写get方法</span></span><br><span class="line">        System.out.println(<span class="string">&quot;==========lambda============&quot;</span>);</span><br><span class="line">        method(()-&gt;&#123;</span><br><span class="line">            <span class="type">int</span>[] arr = &#123;<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">7</span>&#125;;</span><br><span class="line">            Arrays.sort(arr);</span><br><span class="line">            <span class="keyword">return</span> arr[arr.length-<span class="number">1</span>];</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(Supplier&lt;Integer&gt; supplier)</span>&#123;</span><br><span class="line">        <span class="type">Integer</span> <span class="variable">max</span> <span class="operator">=</span> supplier.get();<span class="comment">//让get方法返回一个数组最大值</span></span><br><span class="line">        System.out.println(<span class="string">&quot;max = &quot;</span> + max);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="image-20250513102024115.png" alt="image-20250513102024115" style="zoom: 50%;">

<h3 id="2-3-3-消费型接口的例子-Consumer"><a href="#2-3-3-消费型接口的例子-Consumer" class="headerlink" title="2.3.3 消费型接口的例子-Consumer"></a>2.3.3 消费型接口的例子-Consumer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">java.util.function.Consumer&lt;T&gt;-&gt;消费型接口-&gt;操作</span><br><span class="line">    方法：</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(T t)</span>,意味着一个指定泛型的数据</span><br><span class="line">    </span><br><span class="line">“消费”就是“操作”，至于怎么操作，就看重写accept方法之后，方法体怎么写了</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Consumer</span>&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Performs this operation on the given argument.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> t the input argument</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(T t)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Returns a composed &#123;<span class="doctag">@code</span> Consumer&#125; that performs, in sequence, this</span></span><br><span class="line"><span class="comment">     * operation followed by the &#123;<span class="doctag">@code</span> after&#125; operation. If performing either</span></span><br><span class="line"><span class="comment">     * operation throws an exception, it is relayed to the caller of the</span></span><br><span class="line"><span class="comment">     * composed operation.  If performing this operation throws an exception,</span></span><br><span class="line"><span class="comment">     * the &#123;<span class="doctag">@code</span> after&#125; operation will not be performed.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> after the operation to perform after this operation</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> a composed &#123;<span class="doctag">@code</span> Consumer&#125; that performs in sequence this</span></span><br><span class="line"><span class="comment">     * operation followed by the &#123;<span class="doctag">@code</span> after&#125; operation</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> NullPointerException if &#123;<span class="doctag">@code</span> after&#125; is null</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">default</span> Consumer&lt;T&gt; <span class="title function_">andThen</span><span class="params">(Consumer&lt;? <span class="built_in">super</span> T&gt; after)</span> &#123;</span><br><span class="line">        Objects.requireNonNull(after);</span><br><span class="line">        <span class="keyword">return</span> (T t) -&gt; &#123; accept(t); after.accept(t); &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo02Consumer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">Consumer</span>&lt;String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(String s)</span> &#123;</span><br><span class="line">                System.out.println(s.length());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;hello&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;=====lambda========&quot;</span>);</span><br><span class="line">        method(s -&gt; System.out.println(s.length()), <span class="string">&quot;hello&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(Consumer&lt;String&gt; consumer, String s)</span></span><br><span class="line">    &#123;</span><br><span class="line">        consumer.accept(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="image-20250513104026553.png" alt="image-20250513104026553" style="zoom: 50%;">

<h3 id="2-3-4-函数型接口的例子-Function"><a href="#2-3-4-函数型接口的例子-Function" class="headerlink" title="2.3.4 函数型接口的例子-Function"></a>2.3.4 函数型接口的例子-Function</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java.util.function.Function&lt;T,R&gt;接口用来根据一个类型的数据得到另一个类型的数据</span><br><span class="line">    方法：</span><br><span class="line">      R <span class="title function_">apply</span><span class="params">(T t)</span>根据类型T参数获取类型R的结果</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Function</span>&lt;T, R&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Applies this function to the given argument.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> t the function argument</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> the function result</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    R <span class="title function_">apply</span><span class="params">(T t)</span>;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo03Function</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">Function</span>&lt;Integer, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">apply</span><span class="params">(Integer integer)</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> integer + <span class="string">&quot;&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="number">100</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========lambda============&quot;</span>);</span><br><span class="line">        method(integer -&gt; integer + <span class="string">&quot;&quot;</span>, <span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(Function&lt;Integer, String&gt; function, Integer number)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> function.apply(number);</span><br><span class="line">        System.out.println(<span class="string">&quot;s = &quot;</span> + (s+<span class="number">1</span>));<span class="comment">//1001</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="image-20250513105311741.png" alt="image-20250513105311741" style="zoom: 50%;">

<h3 id="2-3-5-判断型接口的例子-Predicate"><a href="#2-3-5-判断型接口的例子-Predicate" class="headerlink" title="2.3.5 判断型接口的例子-Predicate"></a>2.3.5 判断型接口的例子-Predicate</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">java.util.function.Predicate&lt;T&gt;接口，-&gt;判断型接口</span><br><span class="line">    <span class="type">boolean</span> <span class="title function_">test</span><span class="params">(T t)</span>-&gt;用于判断的方法，返回值为<span class="type">boolean</span>型</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Predicate</span>&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Evaluates this predicate on the given argument.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> t the input argument</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> &#123;<span class="doctag">@code</span> true&#125; if the input argument matches the predicate,</span></span><br><span class="line"><span class="comment">     * otherwise &#123;<span class="doctag">@code</span> false&#125;</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">boolean</span> <span class="title function_">test</span><span class="params">(T t)</span>;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo04Predicate</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">Predicate</span>&lt;String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">test</span><span class="params">(String s)</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> s.length() == <span class="number">7</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;hello&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;=====lambda========&quot;</span>);</span><br><span class="line">        method(s -&gt; s.length() == <span class="number">7</span>, <span class="string">&quot;hello&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(Predicate&lt;String&gt; predicate, String s)</span> &#123;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> predicate.test(s);</span><br><span class="line">        System.out.println(<span class="string">&quot;b = &quot;</span> + b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-4-接口实现类作为实参传递的例子"><a href="#2-4-接口实现类作为实参传递的例子" class="headerlink" title="2.4 接口实现类作为实参传递的例子"></a>2.4 接口实现类作为实参传递的例子</h2><p>在Spark和Flink的各类算子中，大多数算子都是以接口实现类作为实参的，这种使用new接口以匿名内部类传递实参的形式就可以写成lambda表达式，以Collections工具</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义一个javabean</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> Integer age;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">(String name, Integer age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">getAge</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(Integer age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Person&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;name=&#x27;&quot;</span> + name + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, age=&quot;</span> + age +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    ArrayList&lt;Person&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    list.add(<span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Tom&quot;</span>,<span class="number">12</span>));</span><br><span class="line">    list.add(<span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Jerry&quot;</span>,<span class="number">22</span>));</span><br><span class="line">    list.add(<span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Jim&quot;</span>,<span class="number">32</span>));</span><br><span class="line">    list.add(<span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Mike&quot;</span>,<span class="number">42</span>));</span><br><span class="line">    list.add(<span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;Jack&quot;</span>,<span class="number">52</span>));</span><br><span class="line">    <span class="comment">//匿名内部类形式；sort方法的参数为一个list集合和一个Comparator接口实现类</span></span><br><span class="line">    <span class="comment">//public static &lt;T&gt; void sort(List&lt;T&gt; list, Comparator&lt;? super T&gt; c) &#123;</span></span><br><span class="line">    <span class="comment">//    list.sort(c);</span></span><br><span class="line">    <span class="comment">//&#125;</span></span><br><span class="line">    Collections.sort(list, <span class="keyword">new</span> <span class="title class_">Comparator</span>&lt;Person&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(Person o1, Person o2)</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> o1.getAge() - o2.getAge();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="comment">//lambda表达式形式：</span></span><br><span class="line">    Collections.sort(list,(Person o1,Person o2) -&gt; o1.getAge() - o2.getAge());</span><br><span class="line">    System.out.println(list);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Person&#123;name=&#x27;Tom&#x27;, age=12&#125;, Person&#123;name=&#x27;Jerry&#x27;, age=22&#125;, Person&#123;name=&#x27;Jim&#x27;, age=32&#125;, Person&#123;name=&#x27;Mike&#x27;, age=42&#125;, Person&#123;name=&#x27;Jack&#x27;, age=52&#125;]</span><br></pre></td></tr></table></figure>

<h1 id="第三章-Stream流"><a href="#第三章-Stream流" class="headerlink" title="第三章 Stream流"></a>第三章 Stream流</h1><p><strong>Stream流中的”流”不是特指”IO流”,它是一种”流式编程”(编程方式),可以看做是”流水线”</strong></p>
<p><strong>类似于Flink中的流处理</strong></p>
<h2 id="3-1-引子"><a href="#3-1-引子" class="headerlink" title="3.1 引子"></a>3.1 引子</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo01Stream</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        ArrayList&lt;String&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        list.add(<span class="string">&quot;张三丰&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;张无忌&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;张翠山&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;张三&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;张良&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;刘德华&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;黎明&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//使用stream流</span></span><br><span class="line">        <span class="comment">//将list转成stream流对象</span></span><br><span class="line">        Stream&lt;String&gt; stream = list.stream();</span><br><span class="line">        <span class="comment">//filter是stream对象调用的方法，类比Flink中的算子</span></span><br><span class="line">        stream.filter(s -&gt; s.startsWith(<span class="string">&quot;张&quot;</span>))</span><br><span class="line">                .filter(s -&gt; s.length() == <span class="number">3</span>)</span><br><span class="line">                .forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">张三丰</span><br><span class="line">张无忌</span><br><span class="line">张翠山</span><br></pre></td></tr></table></figure>

<h2 id="3-2-Stream流的获取"><a href="#3-2-Stream流的获取" class="headerlink" title="3.2 Stream流的获取"></a>3.2 Stream流的获取</h2><p>**1. 针对集合：Collection中的方法 **</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;E&gt; strem</span><br></pre></td></tr></table></figure>

<p><strong>2. 针对数组：Stream接口中的静态方法</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> &lt;T&gt; Stream&lt;T&gt; <span class="title function_">of</span><span class="params">(T...values)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo02Stream</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//1.针对集合:Collection中的方法</span></span><br><span class="line">        <span class="comment">//Stream&lt;E&gt; stream()</span></span><br><span class="line">        ArrayList&lt;String&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        list.add(<span class="string">&quot;张三丰&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;张无忌&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;张翠山&quot;</span>);</span><br><span class="line">        list.add(<span class="string">&quot;张三&quot;</span>);</span><br><span class="line">        Stream&lt;String&gt; stream = list.stream();</span><br><span class="line">        System.out.println(stream);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.针对数组:Stream接口中的静态方法:</span></span><br><span class="line">        <span class="comment">//static &lt;T&gt; Stream&lt;T&gt; of(T... values)</span></span><br><span class="line">        Stream&lt;Integer&gt; stream1 = Stream.of(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-3-Stream流的方法"><a href="#3-3-Stream流的方法" class="headerlink" title="3.3 Stream流的方法"></a>3.3 Stream流的方法</h2><h3 id="3-3-1-forEach"><a href="#3-3-1-forEach" class="headerlink" title="3.3.1 forEach"></a>3.3.1 forEach</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">forEach : 逐一处理-&gt;遍历</span><br><span class="line"><span class="keyword">void</span> <span class="title function_">forEach</span><span class="params">(Consumer&lt;? <span class="built_in">super</span> T&gt; action)</span>;</span><br><span class="line"></span><br><span class="line">注意:forEach方法是一个[终结方法],使用完之后,Stream流不能用了</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; s1 = Stream.of(<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line">s1.forEach(s -&gt; System.out.println(s));</span><br><span class="line"><span class="comment">//张三丰</span></span><br><span class="line"><span class="comment">//张无忌</span></span><br><span class="line"><span class="comment">//张翠山</span></span><br><span class="line"><span class="comment">//张三</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-2-count"><a href="#3-3-2-count" class="headerlink" title="3.3.2 count"></a>3.3.2 count</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>作用:统计元素个数</span><br><span class="line"><span class="number">2.</span>注意:count也是一个终结方法</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; s1 = Stream.of(<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line"><span class="type">long</span> <span class="variable">count_num</span> <span class="operator">=</span> s1.count();</span><br><span class="line">System.out.println(count_num);<span class="comment">//4</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-3-filter"><a href="#3-3-3-filter" class="headerlink" title="3.3.3 filter"></a>3.3.3 filter</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>方法:Stream&lt;T&gt; <span class="title function_">filter</span><span class="params">(Predicate&lt;? <span class="built_in">super</span> T&gt; predicate)</span>方法,返回一个新的Stream流对象</span><br><span class="line"><span class="number">2.</span>作用:根据某个条件进行元素过滤</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; s1 = Stream.of(<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line">s1.filter(s -&gt; s.length() == <span class="number">2</span>).forEach(s -&gt; System.out.println(s));</span><br><span class="line"><span class="comment">//张三</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-4-limit"><a href="#3-3-4-limit" class="headerlink" title="3.3.4 limit"></a>3.3.4 limit</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>Stream&lt;T&gt; <span class="title function_">limit</span><span class="params">(<span class="type">long</span> maxSize)</span>:获取Stream流对象中的前n个元素,返回一个新的Stream流对象</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; s1 = Stream.of(<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line">s1.limit(<span class="number">2</span>).forEach(s -&gt; System.out.println(s));</span><br><span class="line"><span class="comment">//张三丰</span></span><br><span class="line"><span class="comment">//张无忌</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-5-skip"><a href="#3-3-5-skip" class="headerlink" title="3.3.5 skip"></a>3.3.5 skip</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;T&gt; <span class="title function_">skip</span><span class="params">(<span class="type">long</span> n)</span>: 跳过Stream流对象中的前n个元素,返回一个新的Stream流对象</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; s1 = Stream.of(<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line">s1.skip(<span class="number">2</span>).forEach(s -&gt; System.out.println(s));</span><br><span class="line"><span class="comment">//张翠山</span></span><br><span class="line"><span class="comment">//张三</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-6-concat"><a href="#3-3-6-concat" class="headerlink" title="3.3.6 concat"></a>3.3.6 concat</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>方法:<span class="keyword">static</span> &lt;T&gt; Stream&lt;T&gt; <span class="title function_">concat</span><span class="params">(Stream&lt;? extends T&gt; a, Stream&lt;? extends T&gt; b)</span>:两个流合成一个流</span><br><span class="line">    Stream.concat(s1, s2)</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; s1 = Stream.of(<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line">Stream&lt;String&gt; s2 = Stream.of(<span class="string">&quot;腾讯&quot;</span>, <span class="string">&quot;阿里&quot;</span>, <span class="string">&quot;百度&quot;</span>, <span class="string">&quot;京东&quot;</span>);</span><br><span class="line">Stream&lt;String&gt; concat_s = Stream.concat(s1, s2);</span><br><span class="line">concat_s.forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<h3 id="3-3-7-collect"><a href="#3-3-7-collect" class="headerlink" title="3.3.7 collect"></a>3.3.7 collect</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">从Stream流对象转成集合对象，使用Stream接口方法collect()</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;String&gt; s1 = Stream.of(<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line">List&lt;String&gt; list = s1.collect(Collectors.toList());</span><br><span class="line">System.out.println(list);<span class="comment">//[张三丰, 张无忌, 张翠山, 张三]</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-8-distinct"><a href="#3-3-8-distinct" class="headerlink" title="3.3.8 distinct"></a>3.3.8 distinct</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;T&gt; <span class="title function_">distinct</span><span class="params">()</span></span><br><span class="line">元素去重复,依赖hashCode和equals方法</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//基本元素类型去重</span></span><br><span class="line">Stream&lt;String&gt; s1 = Stream.of(<span class="string">&quot;张三丰&quot;</span>, <span class="string">&quot;张无忌&quot;</span>, <span class="string">&quot;张翠山&quot;</span>, <span class="string">&quot;张三&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line">s1.distinct().forEach(s -&gt; System.out.println(s));</span><br><span class="line"><span class="comment">//张三丰</span></span><br><span class="line"><span class="comment">//张无忌</span></span><br><span class="line"><span class="comment">//张翠山</span></span><br><span class="line"><span class="comment">//张三</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//类去重</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">(String name, <span class="type">int</span> age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAge</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(<span class="type">int</span> age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Person&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;name=&#x27;&quot;</span> + name + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, age=&quot;</span> + age +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 重写equals方法</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object o)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span> == o) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (!(o <span class="keyword">instanceof</span> Person)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="type">Person</span> <span class="variable">person</span> <span class="operator">=</span> (Person) o;</span><br><span class="line">        <span class="keyword">return</span> getAge() == person.getAge() &amp;&amp; Objects.equals(getName(), person.getName());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hashCode</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Objects.hash(getName(), getAge());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Stream&lt;Person&gt; s2 = Stream.of(<span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;张三&quot;</span>, <span class="number">10</span>), <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;张三&quot;</span>, <span class="number">10</span>), <span class="keyword">new</span> <span class="title class_">Person</span>(<span class="string">&quot;张无忌&quot;</span>, <span class="number">30</span>));</span><br><span class="line">        s2.distinct().forEach(p -&gt; System.out.println(p));</span><br><span class="line">        <span class="comment">//Person&#123;name=&#x27;张三&#x27;, age=10&#125;</span></span><br><span class="line">        <span class="comment">//Person&#123;name=&#x27;张无忌&#x27;, age=30&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="3-3-9-转换流中的类型"><a href="#3-3-9-转换流中的类型" class="headerlink" title="3.3.9 转换流中的类型"></a>3.3.9 转换流中的类型</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;R&gt; <span class="title function_">map</span><span class="params">(Function&lt;T,R&gt; mapper)</span>-&gt; 转换流中的数据类型</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Stream&lt;Integer&gt; s1 = Stream.of(<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>);</span><br><span class="line">s1.map(i-&gt;i+<span class="string">&quot;_s&quot;</span>).forEach(s-&gt;System.out.println(s));</span><br><span class="line"><span class="comment">//10_s</span></span><br><span class="line"><span class="comment">//20_s</span></span><br><span class="line"><span class="comment">//30_s</span></span><br><span class="line"><span class="comment">//40_s</span></span><br><span class="line"><span class="comment">//50_s</span></span><br></pre></td></tr></table></figure>

<h1 id="第四章-方法引用与构造器引用"><a href="#第四章-方法引用与构造器引用" class="headerlink" title="第四章 方法引用与构造器引用"></a>第四章 方法引用与构造器引用</h1><p>Lambda表达式是可以简化函数式接口的变量或形参赋值的语法。而方法引用和构造器引用是为了简化Lambda表达式的。</p>
<h2 id="4-1-方法引用"><a href="#4-1-方法引用" class="headerlink" title="4.1 方法引用"></a>4.1 方法引用</h2><p>当要传递给Lambda体的操作，已经有实现的方法了，可以使用方法引用！</p>
<p>方法引用可以看做是Lambda表达式深层次的表达。换句话说，方法引用就是Lambda表达式，也就是函数式接口的一个实例，通过方法的名字来指向一个方法，可以认为是Lambda表达式的一个语法糖。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>概述:引用方法</span><br><span class="line"><span class="number">2.</span>啥时候使用:</span><br><span class="line">  a.被引用的方法要写在重写方法里面</span><br><span class="line">  b.被引用的方法从参数上,返回值上要和所在重写方法一致,而且引用的方法最好是操作重写方法的参数值的</span><br><span class="line">  c.干掉重写方法的参数;干掉-&gt;;干掉被引用方法的参数 -&gt; 将被引用方法的.改成::    </span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo01Method</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        Stream&lt;String&gt; stream = Stream.of(<span class="string">&quot;张三&quot;</span>, <span class="string">&quot;李四&quot;</span>, <span class="string">&quot;王五&quot;</span>, <span class="string">&quot;赵六&quot;</span>);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * accept是重写方法：  参数类型为String</span></span><br><span class="line"><span class="comment">         *                   无返回值</span></span><br><span class="line"><span class="comment">         *                   </span></span><br><span class="line"><span class="comment">         * accept方法里面有println方法：println参数类型为String，</span></span><br><span class="line"><span class="comment">         *                           println没有返回值，</span></span><br><span class="line"><span class="comment">         *                           println方法操作accept方法的参数值</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        stream.forEach(<span class="keyword">new</span> <span class="title class_">Consumer</span>&lt;String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(String s)</span> &#123;</span><br><span class="line">                System.out.println(s);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========lambda===========&quot;</span>);</span><br><span class="line">        stream.forEach(s -&gt; System.out.println(s));</span><br><span class="line">        System.out.println(<span class="string">&quot;==========method===========&quot;</span>);</span><br><span class="line">        stream.forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-2-对象名–引用成员方法"><a href="#4-2-对象名–引用成员方法" class="headerlink" title="4.2 对象名–引用成员方法"></a>4.2 对象名–引用成员方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>使用对象名引用成员方法</span><br><span class="line">  格式:</span><br><span class="line">    对象::成员方法名</span><br><span class="line">         </span><br><span class="line"><span class="number">2.</span>需求:</span><br><span class="line">    函数式接口:Supplier</span><br><span class="line">        java.util.function.Supplier&lt;T&gt;接口</span><br><span class="line">    抽象方法:</span><br><span class="line">        T <span class="title function_">get</span><span class="params">()</span>。用来获取一个泛型参数指定类型的对象数据。</span><br><span class="line">        Supplier接口使用什么泛型,就可以使用get方法获取一个什么类型的数据</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo02Method</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">Supplier</span>&lt;String&gt;() &#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * get为重写方法：无参数，返回值为String</span></span><br><span class="line"><span class="comment">             * trim在get中，无参数，返回值为String</span></span><br><span class="line"><span class="comment">             * 考虑使用方法引用</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot; abc &quot;</span>.trim();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========lambda===========&quot;</span>);</span><br><span class="line">        method(() -&gt; <span class="string">&quot; abc &quot;</span>.trim());</span><br><span class="line">        System.out.println(<span class="string">&quot;==========method===========&quot;</span>);</span><br><span class="line">        method(<span class="string">&quot; abc &quot;</span>::trim);</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(Supplier&lt;String&gt; supplier)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> supplier.get();</span><br><span class="line">        System.out.println(<span class="string">&quot;s = &quot;</span> + s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-3-类名–引用静态方法"><a href="#4-3-类名–引用静态方法" class="headerlink" title="4.3 类名–引用静态方法"></a>4.3 类名–引用静态方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">类名--引用静态方法</span><br><span class="line">    格式:</span><br><span class="line">      类名::静态成员方法</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo03Method</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">Supplier</span>&lt;Double&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Double <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> Math.random();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========lambda===========&quot;</span>);</span><br><span class="line">        method(() -&gt; Math.random());</span><br><span class="line">        System.out.println(<span class="string">&quot;==========method引用===========&quot;</span>);</span><br><span class="line">        method(Math::random);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(Supplier&lt;Double&gt; supplier)</span> &#123;</span><br><span class="line">        <span class="type">Double</span> <span class="variable">d</span> <span class="operator">=</span> supplier.get();</span><br><span class="line">        System.out.println(<span class="string">&quot;aDouble = &quot;</span> + d);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-4-类–构造引用"><a href="#4-4-类–构造引用" class="headerlink" title="4.4 类–构造引用"></a>4.4 类–构造引用</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> 类--构造方法引用</span><br><span class="line">   格式:</span><br><span class="line">     构造方法名称::<span class="keyword">new</span></span><br><span class="line">             </span><br><span class="line"><span class="number">2.</span>需求:</span><br><span class="line">    函数式接口:Function</span><br><span class="line">        java.util.function.Function&lt;T,R&gt;接口</span><br><span class="line">    抽象方法:</span><br><span class="line">        R <span class="title function_">apply</span><span class="params">(T t)</span>，根据类型T的参数获取类型R的结果。用于数类型转换</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo04Method</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">Function</span>&lt;String, Person&gt;() &#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * apply为重写方法：参数为String，返回值为Person对象</span></span><br><span class="line"><span class="comment">             * new Person(s):一个String参数的构造方法，返回值为Person对象，</span></span><br><span class="line"><span class="comment">             *   操作的参数就是apply方法的参数</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Person <span class="title function_">apply</span><span class="params">(String s)</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Person</span>(s);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,  <span class="string">&quot;王宇涵&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========lambda===========&quot;</span>);</span><br><span class="line">        method((String s) -&gt; <span class="keyword">new</span> <span class="title class_">Person</span>(s), <span class="string">&quot;王宇涵&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========method===========&quot;</span>);</span><br><span class="line">        method(Person::<span class="keyword">new</span>, <span class="string">&quot;王宇涵&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(Function&lt;String,Person&gt; function, String name)</span>&#123;</span><br><span class="line">        <span class="type">Person</span> <span class="variable">p</span> <span class="operator">=</span> function.apply(name);</span><br><span class="line">        System.out.println(p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="4-5-数组–数组引用"><a href="#4-5-数组–数组引用" class="headerlink" title="4.5 数组–数组引用"></a>4.5 数组–数组引用</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">数组--数组引用</span><br><span class="line">     格式:</span><br><span class="line">          数组的数据类型[]::<span class="keyword">new</span></span><br><span class="line">          <span class="title class_">int</span>[]::<span class="keyword">new</span>  创建一个<span class="type">int</span>型的数组</span><br><span class="line">          <span class="type">double</span>[]::<span class="keyword">new</span>  创建于一个<span class="type">double</span>型的数组</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Demo05Method</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        method(<span class="keyword">new</span> <span class="title class_">Function</span>&lt;Integer, <span class="type">int</span>[]&gt;() &#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * apply：重写的方法，参数为Integer，返回值为int[]</span></span><br><span class="line"><span class="comment">             * new int[integer]:一个int[]的构造方法，参数为Integer,返回值为int[]，</span></span><br><span class="line"><span class="comment">             *                  操作的参数就是apply方法的参数</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="type">int</span>[] apply(Integer integer) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">int</span>[integer];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,<span class="number">10</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========lambda===========&quot;</span>);</span><br><span class="line">        method((Integer integer) -&gt; <span class="keyword">new</span> <span class="title class_">int</span>[integer], <span class="number">10</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;==========method===========&quot;</span>);</span><br><span class="line">        method(<span class="type">int</span>[]::<span class="keyword">new</span>, <span class="number">10</span>);</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">(Function&lt;Integer,<span class="type">int</span>[]&gt; function, Integer len)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] arr= function.apply(len);</span><br><span class="line">        System.out.println(arr.length);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2025/05/08/Flink%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84Java%E5%9F%BA%E7%A1%80/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-DeepSeek使用指南" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/05/07/DeepSeek%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">DeepSeek使用指南</a>
    </h1>
  

        
        <a href="/2025/05/07/DeepSeek%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" class="archive-article-date">
  	<time datetime="2025-05-07T12:46:41.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2025-05-07</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">随笔</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/其他//" class="article-tag-list-link color3">其他</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2025/05/07/DeepSeek%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-LLM时代下数仓工程师的思考" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/17/LLM%E6%97%B6%E4%BB%A3%E4%B8%8B%E6%95%B0%E4%BB%93%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E6%80%9D%E8%80%83/">LLM时代下数仓工程师的思考</a>
    </h1>
  

        
        <a href="/2025/03/17/LLM%E6%97%B6%E4%BB%A3%E4%B8%8B%E6%95%B0%E4%BB%93%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E6%80%9D%E8%80%83/" class="archive-article-date">
  	<time datetime="2025-03-17T07:44:41.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2025-03-17</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>当1765年瓦特改良的蒸汽机开始轰鸣，最优秀的马车夫突然发现：自己精心打磨的驾驭技艺，在铁轨延伸的方向上正快速贬值。两个半世纪后的今天，数据工程师们站在相似的十字路口——我们构建的Hive表如同精心饲养的汗血宝马，却在GPT-4o理解业务需求的瞬间，目睹SQL正在蜕变为大模型的母语。</p>
<p>每天埋首于需求文档与ETL流程的你，是否在某次晨会突然惊觉：讨论架构设计的白板前，同事开始用”Fine-tuning”替代”Join优化”？当CEO的工作报告里，”Agent”出现的频次超过”Data Lake”，那些沉淀了五年的数仓建模经验，究竟是一张抵御变革的盾牌，还是束缚视野的镣铐？</p>
<p>这场静默的生产力革命正在重新分割数据版图：特征工程被神经网络的表征学习解构，数据血缘在RAG架构下重构，甚至数据治理的权威性都在被AI的置信度算法挑战。在数仓开发这个看似坚如磐石的基础领域，我们既可能是最后一批守护古典数据美学的匠人，也可能成为第一批驾驭智能涌现的探路者。问题的核心不在于岗位存亡，而在于如何将手中的HQL脚本，锻造成打开新生产资料大门的密钥。</p>
<p>当数据管道开始自我进化，真正的破局点或许藏在三个灵魂拷问里：你的数据资产是否具备反哺模型的元学习能力？你的业务洞察能否转化为AI可理解的领域知识图谱？你的技术护城河究竟修筑在算力堆砌的河床上，还是扎根于数据价值链的断层带？</p>
</blockquote>
<p>作为一个互联网大厂的数据开发工程师（日常的工作主要是数仓开发，做业务需求），在大模型普及的今天，如何破局?如何掌握生产资料?在数仓开发这个赛道上不断积累经验知识，拥有持续赚钱的能力?笔者有几点建议。</p>
<h1 id="一、破局关键：从“工具型开发”到“业务-技术双驱动”"><a href="#一、破局关键：从“工具型开发”到“业务-技术双驱动”" class="headerlink" title="一、破局关键：从“工具型开发”到“业务+技术双驱动”"></a>一、破局关键：从“工具型开发”到“业务+技术双驱动”</h1><p>大模型的普及会替代部分重复性工作（如基础ETL、简单SQL开发），但也会创造新机会。你需要：</p>
<ol>
<li><strong>避免成为“SQL Boy”</strong><ul>
<li>警惕仅停留在编写业务SQL、做表关联的层面，需向上理解数据体系设计（例如OneData方法论）、向下掌握底层数据架构（如实时数仓、湖仓一体）。</li>
<li>掌握数据治理能力（元数据管理、数据质量监控、成本优化），这是大模型短期内难以替代的领域。</li>
</ul>
</li>
<li><strong>强化业务洞察能力</strong><ul>
<li>深入理解所在行业的业务逻辑（如电商的GMV拆解、广告的ROI归因），成为“懂数据的业务专家”。</li>
<li>推动数仓设计贴合业务需求：例如设计用户行为分析模型时，结合大模型的预测能力优化用户分群策略。</li>
</ul>
</li>
</ol>
<h1 id="二、掌握生产资料：从“数据管道工”到“数据资产架构师”"><a href="#二、掌握生产资料：从“数据管道工”到“数据资产架构师”" class="headerlink" title="二、掌握生产资料：从“数据管道工”到“数据资产架构师”"></a><strong>二、掌握生产资料：从“数据管道工”到“数据资产架构师”</strong></h1><p>生产资料的核心是<strong>“不可复制的资源”</strong>，对数据工程师而言，需聚焦以下方向：</p>
<ol>
<li><strong>构建领域专属知识库</strong><ul>
<li>将业务经验沉淀为文档、工具或方法论（例如电商行业的指标体系模板、金融风控的数据血缘图谱）。</li>
<li>结合大模型能力，封装行业解决方案（如用LLM自动生成数据质量报告、基于业务知识库的SQL代码生成器）。</li>
</ul>
</li>
<li><strong>掌控核心数据资产</strong><ul>
<li>主导关键数据模型的设计（如用户画像宽表、实时大屏指标聚合层），成为团队中唯一清楚其业务含义和技术细节的人。</li>
<li>推动数据资产服务化：将数仓表封装成API或特征库，直接对接算法团队或业务系统。</li>
</ul>
</li>
</ol>
<h1 id="三、技术升级：拥抱大模型，但不止于大模型"><a href="#三、技术升级：拥抱大模型，但不止于大模型" class="headerlink" title="三、技术升级：拥抱大模型，但不止于大模型"></a><strong>三、技术升级：拥抱大模型，但不止于大模型</strong></h1><ol>
<li><strong>用大模型提效，而非替代自身</strong><ul>
<li>工具层面：用Copilot等工具加速SQL&#x2F;Shell脚本编写，用AI生成数据血缘文档。</li>
<li>架构层面：探索大模型与数仓的结合（如用向量数据库加速非结构化数据处理、基于LLM的自动化数据标注）。</li>
</ul>
</li>
<li><strong>深耕数据工程硬技能</strong><ul>
<li>实时计算：Flink&#x2F;ClickHouse在实时数仓中的应用。</li>
<li>数据湖技术：Delta Lake&#x2F;Iceberg与数仓的融合实践。</li>
<li>成本与性能优化：数据压缩、存储分层、计算资源调度。</li>
</ul>
</li>
</ol>
<h1 id="四、扩展能力边界：向“数据产品经理”和“AI工程师”靠拢"><a href="#四、扩展能力边界：向“数据产品经理”和“AI工程师”靠拢" class="headerlink" title="四、扩展能力边界：向“数据产品经理”和“AI工程师”靠拢"></a><strong>四、扩展能力边界：向“数据产品经理”和“AI工程师”靠拢</strong></h1><ol>
<li><strong>数据产品化能力</strong><ul>
<li>将数仓输出包装成自助分析平台、BI看板或API服务，直接赋能业务方。</li>
<li>学习产品思维：用户需求分析、埋点设计、A&#x2F;B测试支持。</li>
</ul>
</li>
<li><strong>AI工程化能力</strong><ul>
<li>学习特征工程、模型部署（如TensorFlow Serving），参与AI项目的数据供给环节。</li>
<li>理解大模型的数据需求：如何为LLM训练准备高质量领域数据。</li>
</ul>
</li>
</ol>
<h1 id="五、长期护城河：打造个人知识复利"><a href="#五、长期护城河：打造个人知识复利" class="headerlink" title="五、长期护城河：打造个人知识复利"></a><strong>五、长期护城河：打造个人知识复利</strong></h1><ol>
<li><strong>构建可迁移的经验体系</strong><ul>
<li>抽象通用能力：例如跨行业的数据建模方法论（维度建模、Data Vault）。</li>
<li>积累技术选型经验：不同场景下数仓技术栈的对比（Hive vs Spark vs Flink）。</li>
</ul>
</li>
<li><strong>输出影响力</strong><ul>
<li>内部：推动技术分享，主导数据治理规范制定。</li>
<li>外部：通过技术博客、开源项目（如自定义Flink Connector）建立行业声誉。</li>
</ul>
</li>
</ol>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">随笔</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/其他//" class="article-tag-list-link color3">其他</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2025/03/17/LLM%E6%97%B6%E4%BB%A3%E4%B8%8B%E6%95%B0%E4%BB%93%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E6%80%9D%E8%80%83/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-关于我" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/03/16/%E5%85%B3%E4%BA%8E%E6%88%91/">关于我</a>
    </h1>
  

        
        <a href="/2025/03/16/%E5%85%B3%E4%BA%8E%E6%88%91/" class="archive-article-date">
  	<time datetime="2025-03-16T09:32:21.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2025-03-16</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>我叫王宇涵，黑龙江人，目前居住在北京。本科和硕士分别毕业于哈尔滨工程大学和大连理工大学，2024年秋招拿到快手、百度、京东、科大讯飞、度小满、华为、荣耀、360、TCL、海尔十余家企业offer，目前就职于快手数据平台部，担任数据研发工程师，专注于商业化广告业务（广告智能创编分发平台）。热爱数仓开发与数据平台开发，技术栈包括但不限于Java、数仓建模、Hadoop、Hive、Spark、Flink、Clickhouse、Doris、数据湖、数据治理等。会不定期分享一些技术文章、业务知识、面试心得和读书笔记。</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">随笔</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/其他//" class="article-tag-list-link color3">其他</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2025/03/16/%E5%85%B3%E4%BA%8E%E6%88%91/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-软技能-代码之外的生存之道" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2025/01/09/%E8%BD%AF%E6%8A%80%E8%83%BD-%E4%BB%A3%E7%A0%81%E4%B9%8B%E5%A4%96%E7%9A%84%E7%94%9F%E5%AD%98%E4%B9%8B%E9%81%93/">软技能-代码之外的生存之道</a>
    </h1>
  

        
        <a href="/2025/01/09/%E8%BD%AF%E6%8A%80%E8%83%BD-%E4%BB%A3%E7%A0%81%E4%B9%8B%E5%A4%96%E7%9A%84%E7%94%9F%E5%AD%98%E4%B9%8B%E9%81%93/" class="archive-article-date">
  	<time datetime="2025-01-09T13:45:23.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2025-01-09</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一篇-职业"><a href="#第一篇-职业" class="headerlink" title="第一篇 职业"></a>第一篇 职业</h1><blockquote>
<p>职业的发展的驱动力一定是来自个体自身，记住：工作是属于公司的，而职业生涯却是属于自己的</p>
</blockquote>
<h2 id="1-经营自己的职业生涯就像经营一家企业"><a href="#1-经营自己的职业生涯就像经营一家企业" class="headerlink" title="1. 经营自己的职业生涯就像经营一家企业"></a>1. 经营自己的职业生涯就像经营一家企业</h2><p>永远不要有打工的心态，我们的角色是把自己当作一家企业去思考，要转变心态，把mentor、leader或者业务方、产品经理当作我们的软件开发企业的某个客户。</p>
<p>而一个企业的盈利之道就是要有一个产品或者服务，对于程序员，我们所能提供的服务就是创建软件（一个软件项目，一个优化项目，一张表等等）。像企业一样，我们需要持续不断地改进和完善<strong>自己的产品</strong>，这种服务必须具备有形的价值，不仅仅是这款软件的价值是什么，还要让它与成千上万别的程序员所提供的服务有何不同。</p>
<p>而仅有产品和服务是不够的，<strong>想赚到钱，就必须让潜在客户了解该产品或服务</strong>，<strong>产品营销做得越好，就能给服务定越高的价格，也越有机会吸引更多的潜在客户</strong>。</p>
<p>要做到：</p>
<ul>
<li>专注于我们正在提供怎样的服务，以及如何<strong>营销</strong>这项服务</li>
<li>想法设法提升我们的服务</li>
<li>思考我们可以专注为哪一特定类型的客户或行业提供特定的服务</li>
<li>集中精力成为一名专家，专门为<strong>某一特定类型</strong>的客户提供专业的整体服务</li>
</ul>
<h2 id="2-如何给自己设定好职业目标"><a href="#2-如何给自己设定好职业目标" class="headerlink" title="2. 如何给自己设定好职业目标"></a>2. 如何给自己设定好职业目标</h2>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">随笔</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/其他//" class="article-tag-list-link color3">其他</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2025/01/09/%E8%BD%AF%E6%8A%80%E8%83%BD-%E4%BB%A3%E7%A0%81%E4%B9%8B%E5%A4%96%E7%9A%84%E7%94%9F%E5%AD%98%E4%B9%8B%E9%81%93/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Flink框架学习笔记" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/06/27/Flink%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Flink框架学习笔记</a>
    </h1>
  

        
        <a href="/2024/06/27/Flink%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2024-06-27T07:40:22.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2024-06-27</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Flink概述"><a href="#第一章-Flink概述" class="headerlink" title="第一章 Flink概述"></a>第一章 Flink概述</h1><h2 id="1-1-Flink是什么"><a href="#1-1-Flink是什么" class="headerlink" title="1.1 Flink是什么"></a>1.1 Flink是什么</h2><p><img src="Snipaste_2024-06-27_23-03-07.png" alt="Snipaste_2024-06-27_23-03-07"></p>
<p><img src="Snipaste_2024-06-27_23-03-36.png" alt="Snipaste_2024-06-27_23-03-36"></p>
<p><img src="Snipaste_2024-06-27_23-08-56.png" alt="Snipaste_2024-06-27_23-08-56"></p>
<h2 id="1-2-Flink特点"><a href="#1-2-Flink特点" class="headerlink" title="1.2 Flink特点"></a>1.2 Flink特点</h2><p><img src="Snipaste_2024-06-28_09-15-39.png" alt="Snipaste_2024-06-28_09-15-39"></p>
<h2 id="1-3-Flink-vs-SparkStreaming"><a href="#1-3-Flink-vs-SparkStreaming" class="headerlink" title="1.3 Flink vs SparkStreaming"></a>1.3 <strong>Flink vs SparkStreaming</strong></h2><p><img src="Snipaste_2024-06-28_09-18-13.png" alt="Snipaste_2024-06-28_09-18-13"></p>
<table>
<thead>
<tr>
<th></th>
<th>Flink</th>
<th>Streaming</th>
</tr>
</thead>
<tbody><tr>
<td>计算模型</td>
<td>流计算</td>
<td>微批处理</td>
</tr>
<tr>
<td>时间语义</td>
<td>事件时间、处理时间</td>
<td>处理时间</td>
</tr>
<tr>
<td>窗口</td>
<td>多、灵活</td>
<td>少、不灵活（窗口必须是批次的整数倍）</td>
</tr>
<tr>
<td>状态</td>
<td>有</td>
<td>没有</td>
</tr>
<tr>
<td>流式SQL</td>
<td>有</td>
<td>没有</td>
</tr>
</tbody></table>
<h2 id="1-4-Flink的应用场景"><a href="#1-4-Flink的应用场景" class="headerlink" title="1.4 Flink的应用场景"></a>1.4 Flink的应用场景</h2><p><img src="Snipaste_2024-06-28_09-27-02.png" alt="Snipaste_2024-06-28_09-27-02"></p>
<h2 id="1-5-Flink分层API"><a href="#1-5-Flink分层API" class="headerlink" title="1.5 Flink分层API"></a>1.5 Flink分层API</h2><p><img src="Snipaste_2024-06-28_09-30-44.png" alt="Snipaste_2024-06-28_09-30-44"></p>
<h1 id="第二章-Flink快速上手"><a href="#第二章-Flink快速上手" class="headerlink" title="第二章 Flink快速上手"></a>第二章 Flink快速上手</h1><h2 id="2-1-创建项目"><a href="#2-1-创建项目" class="headerlink" title="2.1 创建项目"></a>2.1 创建项目</h2><p>（1）创建Maven工程</p>
<img src="Snipaste_2024-06-28_09-49-43.png" alt="Snipaste_2024-06-28_09-49-43" style="zoom:43%;">

<p>（2）添加项目依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.17.0<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="2-2-WordCount代码编写"><a href="#2-2-WordCount代码编写" class="headerlink" title="2.2 WordCount代码编写"></a>2.2 WordCount代码编写</h2><p>需求：统计一段文字中，每个单词出现的频次。</p>
<p>环境准备：在src&#x2F;main&#x2F;java目录下，新建一个包，命名为com.atguigu.wc</p>
<h3 id="2-2-1-批处理（已过时）"><a href="#2-2-1-批处理（已过时）" class="headerlink" title="2.2.1 批处理（已过时）"></a>2.2.1 批处理（已过时）</h3><p>批处理基本思路：先逐行读入文件数据，然后将每一行文字拆分成单词；接着按照单词分组，统计每组数据的个数，就是对应单词的频次。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountBatchDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//TODO 1.创建执行环境</span></span><br><span class="line">        <span class="type">ExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 2.读取数据：从文件中读取</span></span><br><span class="line">        DataSource&lt;String&gt; lineDS = env.readTextFile(<span class="string">&quot;input/word.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 3.切分、转换（word,1）</span></span><br><span class="line">        FlatMapOperator&lt;String, Tuple2&lt;String, Integer&gt;&gt; wordAndOne = lineDS.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="comment">//TODO 3.1 按照空格切分单词</span></span><br><span class="line">                String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                <span class="comment">//TODO 3.2 将单词转换为(word,1)</span></span><br><span class="line">                <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                    Tuple2&lt;String, Integer&gt; wordTuple2 = Tuple2.of(word, <span class="number">1</span>);</span><br><span class="line">                    <span class="comment">//TODO 3.3 使用Collector向下游发送数据</span></span><br><span class="line">                    out.collect(wordTuple2);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.按照word分组</span></span><br><span class="line">        UnsortedGrouping&lt;Tuple2&lt;String, Integer&gt;&gt; wordAndOneGroupby = wordAndOne.groupBy(<span class="number">0</span>);<span class="comment">//按照二元组的索引0去分组</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 5.各分组内聚合</span></span><br><span class="line">        AggregateOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = wordAndOneGroupby.sum(<span class="number">1</span>);<span class="comment">//按照二元组的索引1去聚合</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 6.输出</span></span><br><span class="line">        sum.print();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(flink,1)</span><br><span class="line">(world,1)</span><br><span class="line">(hello,3)</span><br><span class="line">(java,1)</span><br></pre></td></tr></table></figure>

<p>需要注意的是，这种代码的实现方式，是基于DataSet API的，也就是我们对数据的处理转换，是看作数据集来进行操作的。事实上Flink本身是流批统一的处理架构，批量的数据集本质上也是流，没有必要用两套不同的API来实现。所以从Flink 1.12开始，官方推荐的做法是直接使用DataStream API，在提交任务时通过将执行模式设为BATCH来进行批处理：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">bin/flink run -Dexecution.runtime-mode=BATCH BatchWordCount.jar</span></span><br></pre></td></tr></table></figure>

<p>这样，DataSet API就没什么用了，在实际应用中我们只要维护一套DataStream API就可以。这里只是为了方便大家理解，我们依然用DataSet API做了批处理的实现。</p>
<h3 id="2-2-2-流处理"><a href="#2-2-2-流处理" class="headerlink" title="2.2.2 流处理"></a>2.2.2 流处理</h3><p>对于Flink而言，流才是整个处理逻辑的底层核心，所以流批统一之后的DataStream API更加强大，可以直接处理批处理和流处理的所有场景。</p>
<p>下面我们就针对不同类型的输入数据源，用具体的代码来实现流处理。</p>
<h4 id="（1）读取文件"><a href="#（1）读取文件" class="headerlink" title="（1）读取文件"></a>（1）读取文件</h4><p>我们同样试图读取文档words.txt中的数据，并统计每个单词出现的频次。整体思路与之前的批处理非常类似，代码模式也基本一致。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountStreamDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//TODO 1.创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//TODO 2.读取数据：从文件读</span></span><br><span class="line">        DataStreamSource&lt;String&gt; lineDS = env.readTextFile(<span class="string">&quot;input/word.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 3.处理数据:切分、转换、分组、聚合</span></span><br><span class="line">        <span class="comment">//TODO 3.1 切分，转换</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; flatMapStream = lineDS.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="comment">//按照空格切分</span></span><br><span class="line">                String[] words = value.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                    out.collect(Tuple2.of(word, <span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//TODO 3.2 分组</span></span><br><span class="line">        KeyedStream&lt;Tuple2&lt;String, Integer&gt;, String&gt; keyByStream = flatMapStream.keyBy(<span class="keyword">new</span> <span class="title class_">KeySelector</span>&lt;Tuple2&lt;String, Integer&gt;, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">getKey</span><span class="params">(Tuple2&lt;String, Integer&gt; value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> value.f0;<span class="comment">//选择二元组的第一个数据当作Key</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//TODO 3.3 聚合</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sumStream = keyByStream.sum(<span class="number">1</span>);<span class="comment">//按照二元组的索引1聚合</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.输出数据</span></span><br><span class="line">        sumStream.print();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//TODO 5.执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 接口A，里面有一个方法a()</span></span><br><span class="line"><span class="comment"> * 正常写法：定义一个class B 实现接口A，方法a()</span></span><br><span class="line"><span class="comment"> * B b = new B()</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 匿名实现类： new A()&#123;</span></span><br><span class="line"><span class="comment"> *       a()&#123;&#125;</span></span><br><span class="line"><span class="comment"> *      &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">13&gt; (flink,1)</span><br><span class="line">9&gt; (world,1)</span><br><span class="line">5&gt; (hello,1)</span><br><span class="line">3&gt; (java,1)</span><br><span class="line">5&gt; (hello,2)</span><br><span class="line">5&gt; (hello,3)</span><br></pre></td></tr></table></figure>

<p>主要观察与批处理程序BatchWordCount的不同：</p>
<ul>
<li>创建执行环境的不同，流处理程序使用的是StreamExecutionEnvironment。</li>
<li>转换处理之后，得到的数据对象类型不同。</li>
<li>分组操作调用的是keyBy方法，可以传入一个匿名函数作为键选择器（KeySelector），指定当前分组的key是什么。</li>
<li>代码末尾需要调用env的execute方法，开始执行任务。</li>
</ul>
<h4 id="（2）读取socket文本流"><a href="#（2）读取socket文本流" class="headerlink" title="（2）读取socket文本流"></a>（2）读取socket文本流</h4><p>在实际的生产环境中，真正的数据流其实是无界的，有开始却没有结束，这就要求我们需要持续地处理捕获的数据。为了模拟这种场景，可以监听socket端口，然后向该端口不断的发送数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountStreamUnboundedDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//TODO 1.创建执行环境</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 2.读取数据：socket</span></span><br><span class="line">        DataStreamSource&lt;String&gt; socketDS = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 3.处理数据:切分、转换、分组、聚合</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                (String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out) -&gt; &#123;</span><br><span class="line">                    String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                    <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                        out.collect(Tuple2.of(word, <span class="number">1</span>));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        ).returns(Types.TUPLE(Types.STRING,Types.INT)).keyBy(</span><br><span class="line">                (Tuple2&lt;String, Integer&gt; value) -&gt; value.f0</span><br><span class="line">        ).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.输出</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 5.执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在hadoop102上执行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# nc -lk 7777</span><br></pre></td></tr></table></figure>

<p>在hadoop102主机中输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello flink hello</span><br></pre></td></tr></table></figure>

<p>在控制台显示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">5&gt; (hello,1)</span><br><span class="line">13&gt; (flink,1)</span><br><span class="line">5&gt; (hello,2)</span><br></pre></td></tr></table></figure>

<p>在hadoop102主机中输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello flink</span><br></pre></td></tr></table></figure>

<p>在控制台显示</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5&gt; (hello,3)</span><br><span class="line">13&gt; (flink,2)</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<p>Flink还具有一个类型提取系统，可以分析函数的输入和返回类型，自动获取类型信息，从而获得对应的序列化器和反序列化器。但是，由于Java中泛型擦除的存在，在某些特殊情况下（比如Lambda表达式中），自动提取的信息是不够精细的——只告诉Flink当前的元素由“船头、船身、船尾”构成，根本无法重建出“大船”的模样；这时就需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。</p>
<p>因为对于flatMap里传入的Lambda表达式，系统只能推断出返回的是Tuple2类型，而无法得到Tuple2&lt;String, Long&gt;。只有显式地告诉系统当前的返回类型，才能正确地解析出完整数据。</p>
<h1 id="第三章-Flink部署"><a href="#第三章-Flink部署" class="headerlink" title="第三章 Flink部署"></a>第三章 Flink部署</h1><h2 id="3-1-集群角色"><a href="#3-1-集群角色" class="headerlink" title="3.1 集群角色"></a>3.1 集群角色</h2><p><img src="Snipaste_2024-06-28_21-45-26.png" alt="Snipaste_2024-06-28_21-45-26"></p>
<h2 id="3-2-Flink集群搭建"><a href="#3-2-Flink集群搭建" class="headerlink" title="3.2 Flink集群搭建"></a>3.2 Flink集群搭建</h2><h3 id="3-2-1-集群启动"><a href="#3-2-1-集群启动" class="headerlink" title="3.2.1 集群启动"></a>3.2.1 集群启动</h3><h4 id="（0）集群规划"><a href="#（0）集群规划" class="headerlink" title="（0）集群规划"></a>（0）集群规划</h4><table>
<thead>
<tr>
<th>节点服务器</th>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>角色</td>
<td>JobManager<br>TaskManager</td>
<td>TaskManager</td>
<td>TaskManager</td>
</tr>
</tbody></table>
<h4 id="（1）下载并解压安装包"><a href="#（1）下载并解压安装包" class="headerlink" title="（1）下载并解压安装包"></a>（1）下载并解压安装包</h4><p>下载安装包flink-1.17.0-bin-scala_2.12.tgz，将该jar包上传到hadoop102节点服务器的&#x2F;opt&#x2F;software路径上。</p>
<p>在&#x2F;opt&#x2F;software路径上解压flink-1.17.0-bin-scala_2.12.tgz到&#x2F;opt&#x2F;module路径上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf flink-1.17.0-bin-scala_2.12.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<h4 id="（2）修改集群配置"><a href="#（2）修改集群配置" class="headerlink" title="（2）修改集群配置"></a>（2）修改集群配置</h4><p>进入conf路径，修改flink-conf.yaml文件，指定hadoop102节点服务器为JobManager</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# cd conf/</span><br><span class="line">[root@hadoop102 conf]# vim flink-conf.yaml</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JobManager节点地址.</span></span><br><span class="line">jobmanager.rpc.address: hadoop102</span><br><span class="line">jobmanager.bind-host: 0.0.0.0</span><br><span class="line">rest.address: hadoop102</span><br><span class="line">rest.bind-address: 0.0.0.0</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TaskManager节点地址.需要配置为当前机器名</span></span><br><span class="line">taskmanager.bind-host: 0.0.0.0</span><br><span class="line">taskmanager.host: hadoop102</span><br></pre></td></tr></table></figure>

<p>修改workers文件，指定hadoop102、hadoop103和hadoop104为TaskManager</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim workers</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure>

<p>修改masters文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim masters</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop102:8081</span><br></pre></td></tr></table></figure>

<p>另外，在flink-conf.yaml文件中还可以对集群中的JobManager和TaskManager组件进行优化配置，主要配置项如下：</p>
<ul>
<li>jobmanager.memory.process.size：对JobManager进程可使用到的全部内存进行配置，包括JVM元空间和其他开销，默认为1600M，可以根据集群规模进行适当调整。</li>
<li>taskmanager.memory.process.size：对TaskManager进程可使用到的全部内存进行配置，包括JVM元空间和其他开销，默认为1728M，可以根据集群规模进行适当调整。</li>
<li>taskmanager.numberOfTaskSlots：对每个TaskManager能够分配的Slot数量进行配置，默认为1，可根据TaskManager所在的机器能够提供给Flink的CPU数量决定。所谓Slot就是TaskManager中具体运行一个任务所分配的计算资源。</li>
<li>parallelism.default：Flink任务执行的并行度，默认为1。优先级低于代码中进行的并行度配置和任务提交时使用参数指定的并行度数量。</li>
</ul>
<p>关于Slot和并行度的概念，我们会在下一章做详细讲解。</p>
<h4 id="（3）分发安装目录"><a href="#（3）分发安装目录" class="headerlink" title="（3）分发安装目录"></a>（3）分发安装目录</h4><p>配置修改完毕后，将Flink安装目录发给另外两个节点服务器。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]$ xsync flink-1.17.0/</span><br></pre></td></tr></table></figure>

<p>修改hadoop103的 taskmanager.host</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop103 conf]$ vim flink-conf.yaml</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TaskManager节点地址.需要配置为当前机器名</span></span><br><span class="line">taskmanager.host: hadoop103</span><br></pre></td></tr></table></figure>

<p>修改hadoop104的 taskmanager.host</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop104 conf]$ vim flink-conf.yaml</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">TaskManager节点地址.需要配置为当前机器名</span></span><br><span class="line">taskmanager.host: hadoop104</span><br></pre></td></tr></table></figure>

<h4 id="（4）启动集群"><a href="#（4）启动集群" class="headerlink" title="（4）启动集群"></a>（4）启动集群</h4><p>在hadoop102节点服务器上执行start-cluster.sh启动Flink集群：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/start-cluster.sh </span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host hadoop102.</span><br><span class="line">Starting taskexecutor daemon on host hadoop102.</span><br><span class="line">Starting taskexecutor daemon on host hadoop103.</span><br><span class="line">Starting taskexecutor daemon on host hadoop104.</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">5644 Jps</span><br><span class="line">5501 TaskManagerRunner</span><br><span class="line">5150 StandaloneSessionClusterEntrypoint</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">4727 Jps</span><br><span class="line">4633 TaskManagerRunner</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">5635 Jps</span><br><span class="line">5544 TaskManagerRunner</span><br></pre></td></tr></table></figure>

<h4 id="（5）访问WebUI"><a href="#（5）访问WebUI" class="headerlink" title="（5）访问WebUI"></a>（5）访问WebUI</h4><p>启动成功后，同样可以访问<a href="http://hadoop102:8081对flink集群和任务进行监控管理。">http://hadoop102:8081对flink集群和任务进行监控管理。</a></p>
<p><img src="Snipaste_2024-06-30_11-09-16.png" alt="Snipaste_2024-06-30_11-09-16"></p>
<p>这里可以明显看到，当前集群的TaskManager数量为3；由于默认每个TaskManager的Slot数量为1，所以总Slot数和可用Slot数都为3。</p>
<h3 id="3-2-2-向集群提交作业"><a href="#3-2-2-向集群提交作业" class="headerlink" title="3.2.2 向集群提交作业"></a>3.2.2 向集群提交作业</h3><h4 id="（1）环境准备"><a href="#（1）环境准备" class="headerlink" title="（1）环境准备"></a>（1）环境准备</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]$ nc -lk 7777</span><br></pre></td></tr></table></figure>

<h4 id="（2）添加依赖，程序打包"><a href="#（2）添加依赖，程序打包" class="headerlink" title="（2）添加依赖，程序打包"></a>（2）添加依赖，程序打包</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-shade-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.2.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>shade<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">artifactSet</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>com.google.code.findbugs:jsr305<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>org.slf4j:*<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>log4j:*<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">artifactSet</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">filters</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">filter</span>&gt;</span></span><br><span class="line">                                <span class="comment">&lt;!-- Do not copy the signatures in the META-INF folder.</span></span><br><span class="line"><span class="comment">                                Otherwise, this might cause SecurityExceptions when using the JAR. --&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">artifact</span>&gt;</span>*:*<span class="tag">&lt;/<span class="name">artifact</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.SF<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.DSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.RSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">filters</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">transformers</span> <span class="attr">combine.children</span>=<span class="string">&quot;append&quot;</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">transformer</span></span></span><br><span class="line"><span class="tag">                                    <span class="attr">implementation</span>=<span class="string">&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">transformers</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>使用maven工具进行打包</p>
<p>打包完成后，在target目录下即可找到所需JAR包，JAR包会有两个，FlinkTutorial-1.0-SNAPSHOT.jar和FlinkTutorial-1.0-SNAPSHOT-jar-with-dependencies.jar，因为集群中已经具备任务运行所需的所有依赖，所以建议使用FlinkTutorial1.17-1.0-SNAPSHOT.jar</p>
<p><img src="Snipaste_2024-07-01_11-12-13.png" alt="Snipaste_2024-07-01_11-12-13"></p>
<h4 id="（3）在WebUI上提交作业"><a href="#（3）在WebUI上提交作业" class="headerlink" title="（3）在WebUI上提交作业"></a>（3）在WebUI上提交作业</h4><p><img src="Snipaste_2024-07-01_11-15-03.png" alt="Snipaste_2024-07-01_11-15-03"></p>
<p>主要配置程序入口主类的全类名，任务运行的并行度，任务运行所需的配置参数和保存点路径等，如下图所示，配置完成后，即可点击按钮“Submit”，将任务提交到集群运行</p>
<p><img src="Snipaste_2024-07-01_11-18-32.png" alt="Snipaste_2024-07-01_11-18-32"></p>
<p>任务提交成功之后，可点击左侧导航栏的“Running Jobs”查看程序运行列表情况</p>
<p><img src="Snipaste_2024-07-01_11-19-27.png" alt="Snipaste_2024-07-01_11-19-27"></p>
<p>在socket端口中输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hello flink</span><br><span class="line">hello spark</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-01_11-24-09.png" alt="Snipaste_2024-07-01_11-24-09"></p>
<p>跳转到task运行日志中，点击Stdout查看输出</p>
<p><img src="Snipaste_2024-07-01_11-25-14.png" alt="Snipaste_2024-07-01_11-25-14"></p>
<p>点击该任务，可以查看任务运行的具体情况，也可以通过点击“Cancel Job”结束任务运行。</p>
<p><img src="Snipaste_2024-07-01_11-27-03.png" alt="Snipaste_2024-07-01_11-27-03"></p>
<h4 id="（4）命令行提交作业"><a href="#（4）命令行提交作业" class="headerlink" title="（4）命令行提交作业"></a>（4）命令行提交作业</h4><p>在hadoop102中执行以下命令启动netcat。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# nc -lk 7777</span><br></pre></td></tr></table></figure>

<p>先把jar包直接上传到目录flink-1.17.0下。进入到flink的安装路径下，在命令行使用flink run命令提交作业</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink run -m hadoop102:8081 -c com.atguigu.wc.WordCountStreamUnboundedDemo  ./FlinnkTutorial1.17-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<p>这里的参数 -m指定了提交到的JobManager，-c指定了入口类</p>
<p>在WebUI中查看</p>
<p><img src="Snipaste_2024-07-01_17-33-00.png" alt="Snipaste_2024-07-01_17-33-00"></p>
<p>在&#x2F;opt&#x2F;module&#x2F;flink-1.17.0&#x2F;log路径中，可以查看TaskManager节点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# cd log</span><br><span class="line">[root@hadoop102 log]# ll</span><br><span class="line">总用量 264</span><br><span class="line">-rw-r--r-- 1 root root   8852 7月   1 17:31 flink-root-client-hadoop102.log</span><br><span class="line">-rw-r--r-- 1 root root 102838 7月   1 17:35 flink-root-standalonesession-0-hadoop102.log</span><br><span class="line">-rw-r--r-- 1 root root  27703 6月  30 11:10 flink-root-standalonesession-0-hadoop102.log.1</span><br><span class="line">-rw-r--r-- 1 root root      0 7月   1 11:14 flink-root-standalonesession-0-hadoop102.out</span><br><span class="line">-rw-r--r-- 1 root root  45400 7月   1 17:35 flink-root-taskexecutor-0-hadoop102.log</span><br><span class="line">-rw-r--r-- 1 root root  35395 6月  30 11:03 flink-root-taskexecutor-0-hadoop102.log.1</span><br><span class="line">-rw-r--r-- 1 root root  29531 6月  30 11:10 flink-root-taskexecutor-0-hadoop102.log.2</span><br><span class="line">-rw-r--r-- 1 root root    100 7月   1 17:33 flink-root-taskexecutor-0-hadoop102.out</span><br><span class="line">[root@hadoop102 log]# cat flink-root-taskexecutor-0-hadoop102.out</span><br><span class="line">(hello,1)</span><br><span class="line">(flink,1)</span><br><span class="line">(hello,2)</span><br><span class="line">(spark,1)</span><br><span class="line">(hello,1)</span><br><span class="line">(hello,2)</span><br><span class="line">(spark,1)</span><br><span class="line">(hello,3)</span><br><span class="line">(flink,1)</span><br><span class="line">(flink,2)</span><br></pre></td></tr></table></figure>

<h2 id="3-3-部署模式"><a href="#3-3-部署模式" class="headerlink" title="3.3 部署模式"></a>3.3 部署模式</h2><p>在一些应用场景中，对于集群资源分配和占用的方式，可能会有特定的需求。Flink为各种场景提供了不同的部署模式，主要有以下三种：会话模式（Session Mode）、单作业模式（Per-Job Mode）、应用模式（Application Mode）。</p>
<p>它们的区别主要在于：集群的生命周期以及资源的分配方式；以及应用的main方法到底在哪里执行——客户端（Client）还是JobManager。</p>
<h3 id="3-3-1-会话模式（Session-Mode）"><a href="#3-3-1-会话模式（Session-Mode）" class="headerlink" title="3.3.1 会话模式（Session Mode）"></a>3.3.1 会话模式（Session Mode）</h3><p><img src="Snipaste_2024-07-01_20-18-48.png" alt="Snipaste_2024-07-01_20-18-48"></p>
<h3 id="3-3-2-单作业模式（Per-Job-Mode）（实际应用的首选）"><a href="#3-3-2-单作业模式（Per-Job-Mode）（实际应用的首选）" class="headerlink" title="3.3.2 单作业模式（Per-Job Mode）（实际应用的首选）"></a>3.3.2 单作业模式（Per-Job Mode）（实际应用的首选）</h3><p><img src="Snipaste_2024-07-01_21-45-33.png" alt="Snipaste_2024-07-01_21-45-33"></p>
<h3 id="3-3-3-应用模式（Application-Mode）"><a href="#3-3-3-应用模式（Application-Mode）" class="headerlink" title="3.3.3 应用模式（Application Mode）"></a>3.3.3 应用模式（Application Mode）</h3><p><img src="Snipaste_2024-07-01_21-47-56.png" alt="Snipaste_2024-07-01_21-47-56"></p>
<p>这里我们所讲到的部署模式，相对是比较抽象的概念。实际应用时，一般需要和资源管理平台结合起来，选择特定的模式来分配资源、部署应用。接下来，我们就针对不同的资源提供者的场景，具体介绍Flink的部署方式。</p>
<h2 id="3-4-Standalone运行模式（了解）"><a href="#3-4-Standalone运行模式（了解）" class="headerlink" title="3.4 Standalone运行模式（了解）"></a>3.4 Standalone运行模式（了解）</h2><p>独立模式是独立运行的，不依赖任何外部的资源管理平台；当然独立也是有代价的：如果资源不足，或者出现故障，没有自动扩展或重分配资源的保证，必须手动处理。所以独立模式一般只用在开发测试或作业非常少的场景下。</p>
<h3 id="3-4-1-会话模式部署"><a href="#3-4-1-会话模式部署" class="headerlink" title="3.4.1 会话模式部署"></a>3.4.1 会话模式部署</h3><p>我们在第3.2节用的就是Standalone集群的会话模式部署。</p>
<p>提前启动集群，并通过Web页面客户端提交任务（可以多个任务，但是集群资源固定）。</p>
<img src="Snipaste_2024-07-02_15-33-52.png" alt="Snipaste_2024-07-02_15-33-52" style="zoom:50%;">

<h3 id="3-4-2-单作业模式部署"><a href="#3-4-2-单作业模式部署" class="headerlink" title="3.4.2 单作业模式部署"></a>3.4.2 单作业模式部署</h3><p>Flink的Standalone集群并不支持单作业模式部署。因为单作业模式需要借助一些资源管理平台。</p>
<h3 id="3-4-3-应用部署模式"><a href="#3-4-3-应用部署模式" class="headerlink" title="3.4.3 应用部署模式"></a>3.4.3 应用部署模式</h3><p>应用模式下不会提前创建集群，所以不能调用start-cluster.sh脚本。我们可以使用同样在bin目录下的standalone-job.sh来创建一个JobManager。</p>
<img src="Snipaste_2024-07-02_15-37-21.png" alt="Snipaste_2024-07-02_15-37-21" style="zoom:43%;">

<p>具体步骤如下：</p>
<p>（1）环境准备。在hadoop102中执行以下命令启动netcat。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# nc -lk 7777</span><br></pre></td></tr></table></figure>

<p>（2）进入到Flink的安装路径下，将应用程序的jar包放到lib&#x2F;目录下。（jar包只能放在lib&#x2F;目录下）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# mv FlinnkTutorial1.17-1.0-SNAPSHOT.jar lib</span><br></pre></td></tr></table></figure>

<p>（3）执行以下命令，启动JobManager。这里我们直接指定作业入口类，脚本会到lib目录扫描所有的jar包。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/standalone-job.sh start --job-classname com.atguigu.wc.WordCountStreamUnboundedDemo</span><br><span class="line">Starting standalonejob daemon on host hadoop102.</span><br></pre></td></tr></table></figure>

<p>（4）同样是使用bin目录下的脚本，启动TaskManager。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/taskmanager.sh start</span><br><span class="line">Starting taskexecutor daemon on host hadoop102.</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flink-1.17.0]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">38224 StandaloneApplicationClusterEntryPoint</span><br><span class="line">38641 TaskManagerRunner</span><br><span class="line">38743 Jps</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">34843 Jps</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">36040 Jps</span><br></pre></td></tr></table></figure>

<p>（5）在hadoop102上模拟发送单词数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# nc -lk 7777</span><br><span class="line">hello flink flink</span><br></pre></td></tr></table></figure>

<p>（6）在hadoop102:8081地址中观察输出数据</p>
<p><img src="Snipaste_2024-07-02_15-55-48.png" alt="Snipaste_2024-07-02_15-55-48"></p>
<p>（7）如果希望停掉集群，同样可以使用脚本，命令如下。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/taskmanager.sh stop</span><br><span class="line">Stopping taskexecutor daemon (pid: 38641) on host hadoop102.</span><br><span class="line">[root@hadoop102 flink-1.17.0]# bin/standalone-job.sh stop</span><br><span class="line">No standalonejob daemon (pid: 38224) is running anymore on hadoop102.</span><br></pre></td></tr></table></figure>

<h2 id="3-5-YARN运行模式（重点）"><a href="#3-5-YARN运行模式（重点）" class="headerlink" title="3.5 YARN运行模式（重点）"></a>3.5 YARN运行模式（重点）</h2><p>YARN上部署的过程是：客户端把Flink应用提交给Yarn的ResourceManager，Yarn的ResourceManager会向Yarn的NodeManager申请容器。在这些容器上，Flink会部署JobManager和TaskManager的实例，从而启动集群。Flink会根据运行在JobManger上的作业所需要的Slot数量动态分配TaskManager资源。</p>
<h3 id="3-5-1-相关准备和配置"><a href="#3-5-1-相关准备和配置" class="headerlink" title="3.5.1 相关准备和配置"></a>3.5.1 相关准备和配置</h3><p>（1）配置环境变量，增加环境变量配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# vim /etc/profile.d/my_env.sh </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Flink需要</span></span><br><span class="line">export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop</span><br><span class="line">export HADOOP_CLASSPATH=`hadoop classpath`</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flink-1.17.0]# source /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>（2）启动Hadoop集群，包括HDFS和YARN。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# myhadoop.sh start</span><br></pre></td></tr></table></figure>

<p>（3）在hadoop102中执行以下命令启动netcat。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# nc -lk 7777</span><br></pre></td></tr></table></figure>

<h3 id="3-5-2-会话模式部署"><a href="#3-5-2-会话模式部署" class="headerlink" title="3.5.2 会话模式部署"></a>3.5.2 会话模式部署</h3><p>YARN的会话模式与独立集群略有不同，需要首先申请一个YARN会话（YARN Session）来启动Flink集群。具体步骤如下：</p>
<p>（1）开启YARN会话，启动flink集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/yarn-session.sh -nm test</span><br></pre></td></tr></table></figure>

<p>可用参数解读：</p>
<ul>
<li>-d：分离模式，如果你不想让Flink YARN客户端一直前台运行，可以使用这个参数，即使关掉当前对话窗口，YARN session也可以后台运行。</li>
<li>-jm（–jobManagerMemory）：配置JobManager所需内存，默认单位MB。</li>
<li>-nm（–name）：配置在YARN UI界面上显示的任务名。</li>
<li>-qu（–queue）：指定YARN队列名。</li>
<li>-tm（–taskManager）：配置每个TaskManager所使用内存。</li>
</ul>
<p>注意：Flink1.11.0版本不再使用-n参数和-s参数分别指定TaskManager数量和slot数量，YARN会按照需求动态分配TaskManager和slot。所以从这个意义上讲，YARN的会话模式也不会把集群资源固定，同样是动态分配的。</p>
<p>查看<a target="_blank" rel="noopener" href="http://hadoop103:8088/cluster">All Applications</a>可以看到：</p>
<p><img src="Snipaste_2024-07-02_16-48-43.png" alt="Snipaste_2024-07-02_16-48-43"></p>
<p>YARN Session启动之后会给出一个Web UI地址以及一个YARN application ID，如下所示，用户可以通过Web UI或者命令行两种方式提交作业。</p>
<p><img src="Snipaste_2024-07-02_16-50-05.png" alt="Snipaste_2024-07-02_16-50-05"></p>
<p>点击网站进入flink WebUI</p>
<p><img src="Snipaste_2024-07-02_16-51-07.png" alt="Snipaste_2024-07-02_16-51-07"></p>
<p>（2）提交作业</p>
<p>使用WebUI提交作业和Standalone部署模式基本相同，略。</p>
<p>下面介绍通过命令行提交作业</p>
<p>执行以下命令将该任务提交到已经开启的Yarn-Session中运行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink run -c com.atguigu.wc.WordCountStreamUnboundedDemo lib/FlinnkTutorial1.17-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<p>客户端可以自行确定JobManager的地址，也可以通过-m或者-jobmanager参数指定JobManager的地址，JobManager的地址在YARN Session的启动页面中可以找到。会自动找到YARN放在YARN上提交</p>
<p><img src="Snipaste_2024-07-02_17-15-32.png" alt="Snipaste_2024-07-02_17-15-32"></p>
<p><strong>从上图中可以看到我们创建的Yarn-Session实际上是一个Yarn的Application，并且有唯一的Application ID。每一个flink集群就是Yarn的一个Application</strong></p>
<p>也可以通过Flink的Web UI页面查看提交任务的运行情况，如下图所示</p>
<p><img src="Snipaste_2024-07-02_17-16-47.png" alt="Snipaste_2024-07-02_17-16-47"></p>
<h3 id="3-5-3-单作业模式部署"><a href="#3-5-3-单作业模式部署" class="headerlink" title="3.5.3 单作业模式部署"></a>3.5.3 单作业模式部署</h3><p>不用事先启动flink集群，执行提交jar包作业，提交的同时就会启动flink集群</p>
<p>（1）执行提交命令作业</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink run -d -t yarn-per-job -c com.atguigu.wc.WordCountStreamUnboundedDemo lib/FlinnkTutorial1.17-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<p>（2）在YARN的ResourceManager界面查看执行情况。</p>
<p><img src="Snipaste_2024-07-02_17-37-07.png" alt="Snipaste_2024-07-02_17-37-07"></p>
<p>点击可以打开Flink Web UI页面进行监控，如下图所示</p>
<p><img src="Snipaste_2024-07-02_17-38-13.png" alt="Snipaste_2024-07-02_17-38-13"></p>
<p>（3）可以使用命令行查看或取消作业，命令如下。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# bin/flink list -t yarn-per-job -Dyarn.application.id=application_1719909188146_0002</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">------------------ Running/Restarting Jobs -------------------</span><br><span class="line">02.07.2024 17:28:12 : 4c04db8a8463bd97f3177f51f1d640f8 : Flink Streaming Job (RUNNING)</span><br><span class="line">--------------------------------------------------------------</span><br><span class="line">No scheduled jobs.</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink cancel -t yarn-per-job -Dyarn.application.id=application_1719909188146_0002 4c04db8a8463bd97f3177f51f1d640f8</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-02_17-43-39.png" alt="Snipaste_2024-07-02_17-43-39"></p>
<p><img src="Snipaste_2024-07-02_17-44-26.png" alt="Snipaste_2024-07-02_17-44-26"></p>
<h3 id="3-5-4-应用模式部署（推荐生产环境中使用）"><a href="#3-5-4-应用模式部署（推荐生产环境中使用）" class="headerlink" title="3.5.4 应用模式部署（推荐生产环境中使用）"></a>3.5.4 应用模式部署（推荐生产环境中使用）</h3><p>应用模式同样非常简单，与单作业模式类似，直接执行flink run-application命令即可。</p>
<p>（1）命令行提交</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink run-application -t yarn-application -c com.atguigu.wc.WordCountStreamUnboundedDemo lib/FlinnkTutorial1.17-1.0-SNAPSHOT.jar </span><br></pre></td></tr></table></figure>

<p>在命令行中查看或取消作业</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY</span><br><span class="line"></span><br><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink cancel -t yarn-application -Dyarn.application.id=application_XXXX_YY &lt;jobId&gt;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-02_20-27-56.png" alt="Snipaste_2024-07-02_20-27-56"></p>
<p>（2）上传HDFS提交</p>
<p>可以通过yarn.provided.lib.dirs配置选项指定位置，将flink的依赖上传到远程</p>
<p>上传flink的lib和plugins到HDFS上</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# hadoop fs -mkdir /flink-dist</span><br><span class="line">[root@hadoop102 flink-1.17.0]# hadoop fs -put lib/ /flink-dist</span><br><span class="line">[root@hadoop102 flink-1.17.0]# hadoop fs -put plugins/ /flink-dist</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_10-07-58.png" alt="Snipaste_2024-07-03_10-07-58"></p>
<p>上传自己的jar包到HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# hadoop fs -mkdir /flink-jars</span><br><span class="line">[root@hadoop102 flink-1.17.0]# hadoop fs -put FlinkTutorial-1.0-SNAPSHOT.jar /flink-jars</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_10-10-59.png" alt="Snipaste_2024-07-03_10-10-59"></p>
<p>（3）提交作业</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink run-application -t yarn-application -Dyarn.provided.lib.dirs=&quot;hdfs://hadoop102:8020/flink-dist&quot; -c com.atguigu.wc.WordCountStreamUnboundedDemo hdfs://hadoop102:8020/flink-jars/FlinnkTutorial1.17-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_10-16-42.png" alt="Snipaste_2024-07-03_10-16-42"></p>
<p><img src="Snipaste_2024-07-03_10-17-10.png" alt="Snipaste_2024-07-03_10-17-10"></p>
<p>这种方式下，flink本身的依赖和用户jar可以预先上传到HDFS，而不需要单独发送到集群，这就使得作业提交更加轻量了。</p>
<h2 id="3-6-K8S-运行模式（了解）"><a href="#3-6-K8S-运行模式（了解）" class="headerlink" title="3.6 K8S 运行模式（了解）"></a>3.6 K8S 运行模式（了解）</h2><p>容器化部署是如今业界流行的一项技术，基于Docker镜像运行能够让用户更加方便地对应用进行管理和运维。容器管理工具中最为流行的就是Kubernetes（k8s），而Flink也在最近的版本中支持了k8s部署模式。基本原理与YARN是类似的，具体配置可以参见官网说明，这里我们就不做过多讲解了。</p>
<h2 id="3-7-历史服务器"><a href="#3-7-历史服务器" class="headerlink" title="3.7 历史服务器"></a>3.7 历史服务器</h2><p>运行 Flink job 的集群一旦停止，只能去 yarn 或本地磁盘上查看日志，不再可以查看作业挂掉之前的运行的 Web UI，很难清楚知道作业在挂的那一刻到底发生了什么。如果我们还没有 Metrics 监控的话，那么完全就只能通过日志去分析和定位问题了，所以如果能还原之前的 Web UI，我们可以通过 UI 发现和定位一些问题。</p>
<p>Flink提供了历史服务器，用来在相应的 Flink 集群关闭后查询已完成作业的统计信息。我们都知道只有当作业处于运行中的状态，才能够查看到相关的WebUI统计信息。通过 History Server 我们才能查询这些已完成作业的统计信息，无论是正常退出还是异常退出。</p>
<p>此外，它对外提供了 REST API，它接受 HTTP 请求并使用 JSON 数据进行响应。Flink 任务停止后，JobManager 会将已经完成任务的统计信息进行存档，History Server 进程则在任务停止后可以对任务统计信息进行查询。比如：最后一次的 Checkpoint、任务运行时的相关配置。</p>
<p>（1）创建存储目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# hadoop fs -mkdir -p /logs/flink-job</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_10-30-15.png" alt="Snipaste_2024-07-03_10-30-15"></p>
<p>（2）在flink-config.yaml中添加如下配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jobmanager.archive.fs.dir: hdfs://hadoop102:8020/logs/flink-job</span><br><span class="line">historyserver.web.address: hadoop102</span><br><span class="line">historyserver.web.port: 8082</span><br><span class="line">historyserver.archive.fs.dir: hdfs://hadoop102:8020/logs/flink-job</span><br><span class="line">historyserver.archive.fs.refresh-interval: 5000</span><br></pre></td></tr></table></figure>

<p>（3）启动历史服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/historyserver.sh start</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="http://hadoop102:8082/#/overview">Apache Flink Web Dashboard</a></p>
<p><img src="Snipaste_2024-07-03_10-37-27.png" alt="Snipaste_2024-07-03_10-37-27"></p>
<p>（4）启动一个flink集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink run-application -t yarn-application -c com.atguigu.wc.WordCountStreamUnboundedDemo lib/FlinnkTutorial1.17-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<p>进入Yarn界面：</p>
<p><img src="Snipaste_2024-07-03_10-40-23.png" alt="Snipaste_2024-07-03_10-40-23"></p>
<p>现在取消掉job</p>
<p><img src="Snipaste_2024-07-03_10-41-01.png" alt="Snipaste_2024-07-03_10-41-01"></p>
<p>在yarn界面点击history进入历史服务器界面</p>
<p><img src="Snipaste_2024-07-03_10-41-33.png" alt="Snipaste_2024-07-03_10-41-33"></p>
<p>可以看到已经被取消掉的job的历史信息</p>
<p><img src="Snipaste_2024-07-03_10-42-15.png" alt="Snipaste_2024-07-03_10-42-15"></p>
<p>在hdfs上也能看见归档的文件</p>
<p><img src="Snipaste_2024-07-03_10-54-46.png" alt="Snipaste_2024-07-03_10-54-46"></p>
<h1 id="第四章-Flink运行时架构"><a href="#第四章-Flink运行时架构" class="headerlink" title="第四章 Flink运行时架构"></a>第四章 Flink运行时架构</h1><h2 id="4-1-系统架构"><a href="#4-1-系统架构" class="headerlink" title="4.1 系统架构"></a>4.1 系统架构</h2><p><img src="Snipaste_2024-07-03_16-07-53.png" alt="Snipaste_2024-07-03_16-07-53"></p>
<h3 id="（1）作业管理器（JobManager）"><a href="#（1）作业管理器（JobManager）" class="headerlink" title="（1）作业管理器（JobManager）"></a>（1）作业管理器（JobManager）</h3><p>JobManager是一个Flink集群中任务管理和调度的核心，是控制应用执行的主进程。也就是说，每个应用都应该被唯一的JobManager所控制执行。</p>
<p>JobManger又包含3个不同的组件。</p>
<h4 id="1）JobMaster"><a href="#1）JobMaster" class="headerlink" title="1）JobMaster"></a>1）JobMaster</h4><p>JobMaster是JobManager中最核心的组件，负责处理单独的作业（Job）。<strong>所以JobMaster和具体的Job是一一对应的，多个Job可以同时运行在一个Flink集群中, 每个Job都有一个自己的JobMaster。</strong>需要注意在早期版本的Flink中，没有JobMaster的概念；而JobManager的概念范围较小，实际指的就是现在所说的JobMaster。</p>
<p>在作业提交时，JobMaster会先接收到要执行的应用。JobMaster会把JobGraph转换成一个物理层面的数据流图，这个图被叫作“执行图”（ExecutionGraph），它包含了所有可以并发执行的任务。JobMaster会向资源管理器（ResourceManager）发出请求，申请执行任务必要的资源。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上。</p>
<p>而在运行过程中，JobMaster会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。</p>
<h4 id="2）资源管理器（ResourceManager）"><a href="#2）资源管理器（ResourceManager）" class="headerlink" title="2）资源管理器（ResourceManager）"></a>2）资源管理器（ResourceManager）</h4><p>ResourceManager主要负责资源的分配和管理，在Flink 集群中只有一个。所谓“资源”，主要是指TaskManager的任务槽（task slots）。任务槽就是Flink集群中的资源调配单元，包含了机器用来执行计算的一组CPU和内存资源。每一个任务（Task）都需要分配到一个slot上执行。</p>
<p>这里注意要把Flink内置的ResourceManager和其他资源管理平台（比如YARN）的ResourceManager区分开。</p>
<h4 id="3）分发器（Dispatcher）"><a href="#3）分发器（Dispatcher）" class="headerlink" title="3）分发器（Dispatcher）"></a>3）分发器（Dispatcher）</h4><p>Dispatcher主要负责提供一个REST接口，用来提交应用，并且负责为每一个新提交的作业启动一个新的JobMaster 组件。Dispatcher也会启动一个Web UI，用来方便地展示和监控作业执行的信息。Dispatcher在架构中并不是必需的，在不同的部署模式下可能会被忽略掉。</p>
<h3 id="（2）任务管理器（TaskManager）"><a href="#（2）任务管理器（TaskManager）" class="headerlink" title="（2）任务管理器（TaskManager）"></a>（2）任务管理器（TaskManager）</h3><p>TaskManager是Flink中的工作进程，数据流的具体计算就是它来做的。Flink集群中必须至少有一个TaskManager；每一个TaskManager都包含了一定数量的任务槽（task slots）。<strong>Slot是资源调度的最小单位，slot的数量限制了TaskManager能够并行处理的任务数量。</strong></p>
<p>启动之后，TaskManager会向资源管理器注册它的slots；收到资源管理器的指令后，TaskManager就会将一个或者多个槽位提供给JobMaster调用，JobMaster就可以分配任务来执行了。</p>
<p>在执行过程中，TaskManager可以缓冲数据，还可以跟其他运行同一应用的TaskManager交换数据。</p>
<h2 id="4-2-核心概念"><a href="#4-2-核心概念" class="headerlink" title="4.2 核心概念"></a>4.2 核心概念</h2><h3 id="4-2-1-并行度（Parallelism）"><a href="#4-2-1-并行度（Parallelism）" class="headerlink" title="4.2.1 并行度（Parallelism）"></a>4.2.1 并行度（Parallelism）</h3><h4 id="4-2-1-1-并行子任务和并行度"><a href="#4-2-1-1-并行子任务和并行度" class="headerlink" title="4.2.1.1 并行子任务和并行度"></a>4.2.1.1 并行子任务和并行度</h4><p>当要处理的数据量非常大时，我们可以把一个算子操作，“复制”多份到多个节点，数据来了之后就可以到其中任意一个执行。这样一来，一个算子任务就被拆分成了多个并行的“子任务”（subtasks），再将它们分发到不同节点，就真正实现了并行计算。</p>
<p>在Flink执行过程中，每一个算子（operator）可以包含一个或多个子任务（operator subtask），这些子任务在不同的线程、不同的物理机或不同的容器中完全独立地执行。</p>
<p><img src="Snipaste_2024-07-03_16-55-10.png" alt="Snipaste_2024-07-03_16-55-10"></p>
<p>一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。这样，包含并行子任务的数据流，就是并行数据流，它需要多个分区（stream partition）来分配并行任务。一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。</p>
<p>例如：如上图所示，当前数据流中有source、map、window、sink四个算子，其中sink算子的并行度为1，其他算子的并行度都为2。所以这段流处理程序的并行度就是2。</p>
<h4 id="4-2-1-2-并行度的设置"><a href="#4-2-1-2-并行度的设置" class="headerlink" title="4.2.1.2 并行度的设置"></a>4.2.1.2 并行度的设置</h4><p>在Flink中，可以用不同的方法来设置并行度，它们的有效范围和优先级别也是不同的。</p>
<p>（1）代码中设置</p>
<p>我们在代码中，可以很简单地在算子后跟着调用setParallelism()方法，来设置当前算子的并行度：</p>
<p>以下代码使用WebUI配置，使得在IDEA写的代码也能直接通过WebUI查看job</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountStreamUnboundedDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//TODO 1.创建执行环境</span></span><br><span class="line"><span class="comment">//        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span></span><br><span class="line">        <span class="comment">//IDEA运行时，也可以看到WebUI，一般用于本地测试（需要引入一个依赖）flink-runtime-web</span></span><br><span class="line">        <span class="comment">//在IDEA运行，不指定并行度，默认就是电脑的线程数</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(<span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line">        <span class="comment">//TODO 2.读取数据：socket</span></span><br><span class="line">        DataStreamSource&lt;String&gt; socketDS = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 3.处理数据:切分、转换、分组、聚合</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                (String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out) -&gt; &#123;</span><br><span class="line">                    String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                    <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                        out.collect(Tuple2.of(word, <span class="number">1</span>));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        ).setParallelism(<span class="number">2</span>).returns(Types.TUPLE(Types.STRING,Types.INT)).keyBy(</span><br><span class="line">                (Tuple2&lt;String, Integer&gt; value) -&gt; value.f0</span><br><span class="line">        ).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.输出</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 5.执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>点击<a target="_blank" rel="noopener" href="http://localhost:8081/#/overview">Apache Flink Web Dashboard</a>查看WebUI</p>
<p><img src="Snipaste_2024-07-03_20-53-58.png" alt="Snipaste_2024-07-03_20-53-58"></p>
<p>这种方式设置的并行度，只针对当前算子有效。</p>
<p>另外，我们也可以直接调用执行环境的setParallelism()方法，全局设定并行度：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.setParallelism(<span class="number">3</span>);</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountStreamUnboundedDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//TODO 1.创建执行环境</span></span><br><span class="line"><span class="comment">//        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span></span><br><span class="line">        <span class="comment">//IDEA运行时，也可以看到WebUI，一般用于本地测试（需要引入一个依赖）flink-runtime-web</span></span><br><span class="line">        <span class="comment">//在IDEA运行，不指定并行度，默认就是电脑的线程数</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(<span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line">        env.setParallelism(<span class="number">3</span>);</span><br><span class="line">        <span class="comment">//TODO 2.读取数据：socket</span></span><br><span class="line">        DataStreamSource&lt;String&gt; socketDS = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 3.处理数据:切分、转换、分组、聚合</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                (String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out) -&gt; &#123;</span><br><span class="line">                    String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                    <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                        out.collect(Tuple2.of(word, <span class="number">1</span>));</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        ).returns(Types.TUPLE(Types.STRING,Types.INT)).keyBy(</span><br><span class="line">                (Tuple2&lt;String, Integer&gt; value) -&gt; value.f0</span><br><span class="line">        ).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.输出</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 5.执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_20-57-46.png" alt="Snipaste_2024-07-03_20-57-46"></p>
<p><strong>注意：算子的并行度优先级高于env全局指定</strong></p>
<p>我们一般不会在程序中设置全局并行度，因为如果在程序中对全局并行度进行硬编码，会导致无法动态扩容。</p>
<p>这里要注意的是，由于keyBy不是算子，所以无法对keyBy设置并行度。</p>
<p>（2）提交应用时设置</p>
<p>在使用flink run命令提交应用时，可以增加-p参数来指定当前应用程序执行的并行度，它的作用类似于执行环境的全局设置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 flink-1.17.0]# bin/flink run -p 2 -c com.atguigu.wc.WordCountStreamUnboundedDemo lib/FlinnkTutorial1.17-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<p>如果我们直接在Web UI上提交作业，也可以在对应输入框中直接添加并行度。</p>
<p><img src="%E5%9B%BE%E7%89%871.png" alt="图片1"></p>
<p><strong>注意：在代码中算子的优先级&gt;代码中env全局指定优先级&gt;提交-p的优先级&gt;配置文件</strong></p>
<h3 id="4-2-2-算子链（Operator-Chain）"><a href="#4-2-2-算子链（Operator-Chain）" class="headerlink" title="4.2.2 算子链（Operator Chain）"></a>4.2.2 算子链（Operator Chain）</h3><h4 id="4-2-2-1-算子间的数据传输"><a href="#4-2-2-1-算子间的数据传输" class="headerlink" title="4.2.2.1 算子间的数据传输"></a>4.2.2.1 算子间的数据传输</h4><p><img src="Snipaste_2024-07-03_21-56-15.png" alt="Snipaste_2024-07-03_21-56-15"></p>
<p>一个数据流在算子之间传输数据的形式可以是一对一（one-to-one）的直通（forwarding）模式，也可以是打乱的重分区（redistributing）模式，具体是哪一种形式，取决于算子的种类。</p>
<p>（1）一对一（One-to-one，forwarding）</p>
<p>这种模式下，数据流维护着分区以及元素的顺序。比如图中的source和map算子，source算子读取数据之后，可以直接发送给map算子做处理，它们之间不需要重新分区，也不需要调整数据的顺序。这就意味着map 算子的子任务，看到的元素个数和顺序跟source 算子的子任务产生的完全一样，保证着“一对一”的关系。map、filter、flatMap等算子都是这种one-to-one的对应关系。<strong>这种关系类似于Spark中的窄依赖。</strong></p>
<p>（2）重分区（Redistributing）</p>
<p>在这种模式下，数据流的分区会发生改变。比如图中的map和后面的keyBy&#x2F;window算子之间，以及keyBy&#x2F;window算子和Sink算子之间，都是这样的关系。</p>
<p>每一个算子的子任务，会根据数据传输的策略，把数据发送到不同的下游目标任务。这些传输方式都会引起重分区的过程，这一过程类似于Spark中的shuffle。</p>
<h4 id="4-2-2-2-合并算子链"><a href="#4-2-2-2-合并算子链" class="headerlink" title="4.2.2.2 合并算子链"></a>4.2.2.2 合并算子链</h4><p>在Flink中，<strong>并行度相同的一对一（one to one）算子操作，可以直接链接在一起形成一个“大”的任务（task）</strong>，这样原来的算子就成为了真正任务里的一部分，如下图所示。每个task会被一个线程执行。这样的技术被称为“算子链”（Operator Chain）。</p>
<img src="Snipaste_2024-07-03_22-07-54.png" alt="Snipaste_2024-07-03_22-07-54" style="zoom:50%;">

<p>上图中Source和map之间满足了算子链的要求，所以可以直接合并在一起，形成了一个任务；因为并行度为2，所以合并后的任务也有两个并行子任务。这样，这个数据流图所表示的作业最终会有5个任务，由5个线程并行执行。</p>
<p>将算子链接成task是非常有效的优化：可以减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。</p>
<p>Flink默认会按照算子链的原则进行链接合并，如果我们想要禁止合并或者自行定义，也可以在代码中对算子做一些特定的设置：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 禁用算子链</span></span><br><span class="line">.map(word -&gt; Tuple2.of(word, <span class="number">1L</span>)).disableChaining();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从当前算子开始新链</span></span><br><span class="line">.map(word -&gt; Tuple2.of(word, <span class="number">1L</span>)).startNewChain()</span><br></pre></td></tr></table></figure>

<p>举个例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UnboundedStreamOperatorChainDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">//TODO 1.创建执行环境</span></span><br><span class="line"><span class="comment">//        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span></span><br><span class="line">        <span class="comment">//IDEA运行时，也可以看到WebUI，一般用于本地测试（需要引入一个依赖）flink-runtime-web</span></span><br><span class="line">        <span class="comment">//在IDEA运行，不指定并行度，默认就是电脑的线程数</span></span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(<span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//TODO 2.读取数据：socket</span></span><br><span class="line">        DataStreamSource&lt;String&gt; socketDS = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 3.处理数据:切分、转换、分组、聚合</span></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                        (String s, Collector&lt;String&gt; out) -&gt; &#123;</span><br><span class="line">                            String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                            <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                                out.collect(word);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                )</span><br><span class="line">                .returns(Types.STRING)</span><br><span class="line">                .map(word -&gt; Tuple2.of(word, <span class="number">1</span>))</span><br><span class="line">                .returns(Types.TUPLE(Types.STRING, Types.INT))</span><br><span class="line">                .keyBy(value -&gt; value.f0)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.输出</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 5.执行</span></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_23-38-59.png" alt="Snipaste_2024-07-03_23-38-59"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//执行全局禁用算子链</span></span><br><span class="line">env.disableOperatorChaining();</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_23-46-44.png" alt="Snipaste_2024-07-03_23-46-44"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 禁用某个算子的算子链</span></span><br><span class="line">SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                        (String s, Collector&lt;String&gt; out) -&gt; &#123;</span><br><span class="line">                            String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                            <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                                out.collect(word);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                ).disableChaining()</span><br><span class="line">                .returns(Types.STRING)</span><br><span class="line">                .map(word -&gt; Tuple2.of(word, <span class="number">1</span>))</span><br><span class="line">                .returns(Types.TUPLE(Types.STRING, Types.INT))</span><br><span class="line">                .keyBy(value -&gt; value.f0)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.输出</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 5.执行</span></span><br><span class="line">        env.execute();</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_23-55-33.png" alt="Snipaste_2024-07-03_23-55-33"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从当前算子开始新链</span></span><br><span class="line">SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                        (String s, Collector&lt;String&gt; out) -&gt; &#123;</span><br><span class="line">                            String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                            <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                                out.collect(word);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                ).startNewChain()</span><br><span class="line">                .returns(Types.STRING)</span><br><span class="line">                .map(word -&gt; Tuple2.of(word, <span class="number">1</span>))</span><br><span class="line">                .returns(Types.TUPLE(Types.STRING, Types.INT))</span><br><span class="line">                .keyBy(value -&gt; value.f0)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.输出</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 5.执行</span></span><br><span class="line">        env.execute();</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-03_23-59-49.png" alt="Snipaste_2024-07-03_23-59-49"></p>
<p><strong>总结</strong>：</p>
<ul>
<li>全局禁用算子链：env.disableOperatorChaining();</li>
<li>某个算子不参与链化：算子A.disableChaining(), 算子A不会与前面和后面的算子串在一起</li>
<li>从某个算子开启新链条：算子A.startNewChain()，算子A不与前面串在一起，从A开始正常链化</li>
</ul>
<h3 id="4-2-3-任务槽（Task-Slots）"><a href="#4-2-3-任务槽（Task-Slots）" class="headerlink" title="4.2.3 任务槽（Task Slots）"></a>4.2.3 任务槽（Task Slots）</h3><p>（1）任务槽</p>
<p>Flink中每一个TaskManager都是一个JVM进程，它可以启动多个独立的线程，来并行执行多个子任务（subtask）。</p>
<p>很显然，TaskManager的计算资源是有限的，并行的任务越多，每个线程的资源就会越少。那一个TaskManager到底能并行处理多少个任务呢？为了控制并发量，我们需要在TaskManager上对每个任务运行所占用的资源做出明确的划分，这就是所谓的任务槽（task slots）。</p>
<p>每个任务槽（task slot）其实表示了TaskManager拥有计算资源的一个<strong>固定大小</strong>的子集。这些资源就是用来独立执行一个子任务的。</p>
<p><img src="Snipaste_2024-07-04_09-51-43.png" alt="Snipaste_2024-07-04_09-51-43"></p>
<p>（2）任务槽数量的设置</p>
<p>在Flink的&#x2F;opt&#x2F;module&#x2F;flink-1.17.0&#x2F;conf&#x2F;flink-conf.yaml配置文件中，可以设置TaskManager的slot数量，默认是1个slot。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">taskmanager.numberOfTaskSlots: 8</span><br></pre></td></tr></table></figure>

<p>需要注意的是，slot目前仅仅用来隔离内存，不会涉及CPU的隔离。在具体应用时，可以将slot数量配置为机器的CPU核心数，尽量避免不同任务之间对CPU的竞争。这也是开发环境默认并行度设为机器CPU数量的原因。 </p>
<p>（3）任务对任务槽的共享</p>
<p><img src="Snipaste_2024-07-04_12-35-27.png" alt="Snipaste_2024-07-04_12-35-27"></p>
<p>默认情况下，Flink是允许子任务共享slot的。如果我们保持sink任务并行度为1不变，而作业提交时设置全局并行度为6，那么前两个任务节点就会各自有6个并行子任务，整个流处理程序则有13个子任务。如上图所示，<strong>只要属于同一个作业，那么对于不同任务节点（算子）的并行子任务，就可以放到同一个slot上执行。</strong>所以对于第一个任务节点source→map，它的6个并行子任务必须分到不同的slot上，而第二个任务节点keyBy&#x2F;window&#x2F;apply的并行子任务却可以和第一个任务节点source→map共享slot。</p>
<p>当我们将资源密集型和非密集型的任务同时放到一个slot中，它们就可以自行分配对资源占用的比例，从而保证最重的活平均分配给所有的TaskManager。</p>
<p><strong>slot共享另一个好处就是允许我们保存完整的作业管道。这样一来，即使某个TaskManager出现故障宕机，其他节点也可以完全不受影响，作业的任务可以继续执行。</strong></p>
<p>当然，Flink默认是允许slot共享的，如果希望某个算子对应的任务完全独占一个slot，或者只有某一部分算子共享slot，我们也可以通过设置“slot共享组”手动指定：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.map(word -&gt; Tuple2.of(word, <span class="number">1L</span>)).slotSharingGroup(<span class="string">&quot;1&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>这样，只有属于同一个slot共享组的子任务，才会开启slot共享；不同组之间的任务是完全隔离的，必须分配到不同的slot上。<strong>在这种场景下，总共需要的slot数量，就是各个slot共享组最大并行度的总和。</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                        (String s, Collector&lt;String&gt; out) -&gt; &#123;</span><br><span class="line">                            String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                            <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                                out.collect(word);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                )</span><br><span class="line">                .returns(Types.STRING)</span><br><span class="line">                <span class="comment">//这里将map算子设定为&quot;aaa&quot;solt共享组，没设定solt组默认为&quot;default&quot;</span></span><br><span class="line">                .map(word -&gt; Tuple2.of(word, <span class="number">1</span>)).slotSharingGroup(<span class="string">&quot;aaa&quot;</span>)</span><br><span class="line">                .returns(Types.TUPLE(Types.STRING, Types.INT))</span><br><span class="line">                .keyBy(value -&gt; value.f0)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 4.输出</span></span><br><span class="line">        sum.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 5.执行</span></span><br><span class="line">        env.execute();</span><br></pre></td></tr></table></figure>

<h3 id="4-2-4-任务槽和并行度的关系"><a href="#4-2-4-任务槽和并行度的关系" class="headerlink" title="4.2.4 任务槽和并行度的关系"></a>4.2.4 任务槽和并行度的关系</h3><p>任务槽和并行度都跟程序的并行执行有关，但两者是完全不同的概念。简单来说任务槽是静态的概念，是指TaskManager具有的并发执行能力，可以通过参数taskmanager.numberOfTaskSlots进行配置；而并行度是动态概念，也就是TaskManager运行程序时实际使用的并发能力，可以通过参数parallelism.default进行配置。</p>
<p>举例说明：假设一共有3个TaskManager，每一个TaskManager中的slot数量设置为3个，那么一共有9个task slot，表示集群最多能并行执行9个同一算子的子任务。</p>
<p>而我们定义word count程序的处理操作是四个转换算子：</p>
<p>source→ flatmap→ reduce→ sink</p>
<p>当所有算子并行度相同时，容易看出source和flatmap可以合并算子链，于是最终有三个任务节点。</p>
<p><img src="Snipaste_2024-07-04_13-28-00.png" alt="Snipaste_2024-07-04_13-28-00"></p>
<p><img src="Snipaste_2024-07-04_13-28-08.png" alt="Snipaste_2024-07-04_13-28-08"></p>
<p><img src="Snipaste_2024-07-04_13-28-16.png" alt="Snipaste_2024-07-04_13-28-16"></p>
<p><img src="Snipaste_2024-07-04_13-28-30.png" alt="Snipaste_2024-07-04_13-28-30"></p>
<p><strong>slot数量与并行度的关系</strong></p>
<ul>
<li>slot是一种静态的概念，表示最大的并发上限</li>
<li>并行度是一种动态的概念，表示实际运行占用了几个</li>
<li>要求：slot数量 &gt;&#x3D; job并行度（算子最大并行度），job才能运行</li>
<li>如果是yarn模式，动态申请，申请TaskManager的数量 &#x3D; job并行度 &#x2F; 每个TM的slot数量，向上取整</li>
</ul>
<h2 id="4-3-作业的提交流程"><a href="#4-3-作业的提交流程" class="headerlink" title="4.3 作业的提交流程"></a>4.3 作业的提交流程</h2><h3 id="4-3-1-Standalone会话模式作业提交流程"><a href="#4-3-1-Standalone会话模式作业提交流程" class="headerlink" title="4.3.1 Standalone会话模式作业提交流程"></a>4.3.1 Standalone会话模式作业提交流程</h3><p><img src="Snipaste_2024-07-04_17-33-19.png" alt="Snipaste_2024-07-04_17-33-19"></p>
<h3 id="4-3-2-逻辑流图-x2F-作业图-x2F-执行图-x2F-物理流图"><a href="#4-3-2-逻辑流图-x2F-作业图-x2F-执行图-x2F-物理流图" class="headerlink" title="4.3.2 逻辑流图&#x2F;作业图&#x2F;执行图&#x2F;物理流图"></a>4.3.2 逻辑流图&#x2F;作业图&#x2F;执行图&#x2F;物理流图</h3><p>我们已经彻底了解了由代码生成任务的过程，现在来做个梳理总结。</p>
<p>逻辑流图（StreamGraph）→ 作业图（JobGraph）→ 执行图（ExecutionGraph）→ 物理图（Physical Graph）。</p>
<p><img src="Snipaste_2024-07-04_17-39-52.png" alt="Snipaste_2024-07-04_17-39-52"></p>
<p><img src="Snipaste_2024-07-04_17-41-14.png" alt="Snipaste_2024-07-04_17-41-14"></p>
<p>1）逻辑流图（StreamGraph）</p>
<p>这是根据用户通过 DataStream API编写的代码生成的最初的DAG图，用来表示程序的拓扑结构。这一步一般在客户端完成。</p>
<p>2）作业图（JobGraph）</p>
<p>StreamGraph经过优化后生成的就是作业图（JobGraph），这是提交给 JobManager 的数据结构，确定了当前作业中所有任务的划分。主要的优化为：将多个符合条件的节点链接在一起合并成一个任务节点，形成算子链，这样可以减少数据交换的消耗。JobGraph一般也是在客户端生成的，在作业提交时传递给JobMaster。</p>
<p>我们提交作业之后，打开Flink自带的Web UI，点击作业就能看到对应的作业图。</p>
<p><img src="Snipaste_2024-07-03_23-46-44.png" alt="Snipaste_2024-07-03_23-46-44"></p>
<p>3）执行图（ExecutionGraph）（最重要）</p>
<p>JobMaster收到JobGraph后，会根据它来生成执行图（ExecutionGraph）。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。与JobGraph最大的区别就是按照并行度对并行子任务进行了拆分，并明确了任务间数据传输的方式。</p>
<p>4）物理图（Physical Graph）</p>
<p>JobMaster生成执行图后，会将它分发给TaskManager；各个TaskManager会根据执行图部署任务，最终的物理执行过程也会形成一张“图”，一般就叫作物理图（Physical Graph）。这只是具体执行层面的图，并不是一个具体的数据结构。</p>
<p>物理图主要就是在执行图的基础上，进一步确定数据存放的位置和收发的具体方式。有了物理图，TaskManager就可以对传递来的数据进行处理计算了。</p>
<h3 id="4-3-3-Yarn应用模式作业提交流程"><a href="#4-3-3-Yarn应用模式作业提交流程" class="headerlink" title="4.3.3 Yarn应用模式作业提交流程"></a>4.3.3 Yarn应用模式作业提交流程</h3><p><img src="Snipaste_2024-07-04_17-51-07.png" alt="Snipaste_2024-07-04_17-51-07"></p>
<h1 id="第五章-DataStream-API"><a href="#第五章-DataStream-API" class="headerlink" title="第五章 DataStream API"></a>第五章 DataStream API</h1><p>DataStream API是Flink的核心层API。一个Flink程序，其实就是对DataStream的各种转换。具体来说，代码基本上都由以下几部分构成：</p>
<p><img src="Snipaste_2024-07-04_17-54-00.png" alt="Snipaste_2024-07-04_17-54-00"></p>
<h2 id="5-1-执行环境（Execution-Environment）"><a href="#5-1-执行环境（Execution-Environment）" class="headerlink" title="5.1 执行环境（Execution Environment）"></a>5.1 执行环境（Execution Environment）</h2><p>Flink程序可以在各种上下文环境中运行：我们可以在本地JVM中执行程序，也可以提交到远程集群上运行。</p>
<p>不同的环境，代码的提交运行的过程会有所不同。这就要求我们在提交作业执行计算时，首先必须获取当前Flink的运行环境，从而建立起与Flink框架之间的联系。</p>
<h3 id="5-1-1-创建执行环境"><a href="#5-1-1-创建执行环境" class="headerlink" title="5.1.1 创建执行环境"></a>5.1.1 创建执行环境</h3><p>我们要获取的执行环境，是StreamExecutionEnvironment类的对象，这是所有Flink程序的基础。在代码中创建执行环境的方式，就是调用这个类的静态方法，具体有以下三种。</p>
<p>1）getExecutionEnvironment（<strong>开发用这个</strong>）</p>
<p>最简单的方式，就是直接调用getExecutionEnvironment方法。它会根据当前运行的上下文直接得到正确的结果：如果程序是独立运行的，就返回一个本地执行环境；如果是创建了jar包，然后从命令行调用它并提交到集群执行，那么就返回集群的执行环境。也就是说，这个方法会根据当前运行的方式，自行决定该返回什么样的运行环境。这种方式，用起来简单高效，是最常用的一种创建执行环境的方式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br></pre></td></tr></table></figure>

<p>2）createLocalEnvironment</p>
<p>这个方法返回一个本地执行环境。可以在调用时传入一个参数，指定默认的并行度；如果不传入，则默认并行度就是本地的CPU核心数。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">LocalStreamEnvironment</span> <span class="variable">env1</span> <span class="operator">=</span> StreamExecutionEnvironment.createLocalEnvironment();</span><br></pre></td></tr></table></figure>

<p>3）createRemoteEnvironment</p>
<p>这个方法返回集群执行环境。需要在调用时指定JobManager的主机名和端口号，并指定要在集群中运行的Jar包。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env2</span> <span class="operator">=</span> StreamExecutionEnvironment</span><br><span class="line">        .createRemoteEnvironment(<span class="string">&quot;hadoop102&quot;</span>,<span class="number">8081</span>,<span class="string">&quot;/opt/module/File.jar&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>在获取到程序执行环境后，我们还可以对执行环境进行灵活的设置。比如可以全局设置程序的并行度、禁用算子链，还可以定义程序的时间语义、配置容错机制。</p>
<h3 id="5-1-2-执行模式"><a href="#5-1-2-执行模式" class="headerlink" title="5.1.2 执行模式"></a>5.1.2 执行模式</h3><p>从Flink 1.12开始，官方推荐的做法是直接使用DataStream API，在提交任务时通过将执行模式设为BATCH来进行批处理。不建议使用DataSet API。</p>
<p>DataStream API执行模式包括：流执行模式、批执行模式和自动模式。<strong>实际应用中一般不会在代码中配置，而是使用命令行，这样更加灵活。</strong></p>
<ul>
<li>流执行模式（Streaming）</li>
</ul>
<p>这是DataStream API最经典的模式，一般用于需要持续实时处理的无界数据流。默认情况下，程序使用的就是Streaming执行模式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.setRuntimeMode(RuntimeExecutionMode.STREAMING);</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -Dexecution.runtime-mode=STREAMING ...</span><br></pre></td></tr></table></figure>

<ul>
<li>批执行模式（Batch）</li>
</ul>
<p>专门用于批处理的执行模式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.setRuntimeMode(RuntimeExecutionMode.BATCH);</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -Dexecution.runtime-mode=BATCH ...</span><br></pre></td></tr></table></figure>

<ul>
<li>自动模式（AutoMatic）</li>
</ul>
<p>在这种模式下，将由程序根据输入数据源是否有界，来自动选择执行模式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env.setRuntimeMode(RuntimeExecutionMode.AUTOMATIC);</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flink run -Dexecution.runtime-mode=AUTOMATIC ...</span><br></pre></td></tr></table></figure>

<h3 id="5-1-3-触发程序执行"><a href="#5-1-3-触发程序执行" class="headerlink" title="5.1.3 触发程序执行"></a>5.1.3 触发程序执行</h3><p>需要注意的是，写完输出（sink）操作并不代表程序已经结束。因为当main()方法被调用时，其实只是定义了作业的每个执行操作，然后添加到数据流图中；这时并没有真正处理数据——因为数据可能还没来。Flink是由事件驱动的，只有等到数据到来，才会触发真正的计算，这也被称为“延迟执行”或“懒执行”。</p>
<p>所以我们需要显式地调用执行环境的execute()方法，来触发程序执行。execute()方法将一直等待作业完成，然后返回一个执行结果（JobExecutionResult）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//默认env.execute()触发一个flink job，一个main方法可以调用多个execute，但是没意义，指定到第一个就会阻塞住</span></span><br><span class="line">env.execute();</span><br><span class="line"><span class="comment">//一个main方法可以调用多个executeAsync，有几个executeAsync就会有几个flink job；异步触发，不阻塞</span></span><br><span class="line">env.executeAsync();</span><br></pre></td></tr></table></figure>

<h2 id="5-2-源算子"><a href="#5-2-源算子" class="headerlink" title="5.2 源算子"></a>5.2 源算子</h2><p>Flink可以从各种来源获取数据，然后构建DataStream进行转换处理。一般将数据的输入来源称为数据源（data source），而读取数据的算子就是源算子（source operator）。所以，source就是我们整个处理程序的输入端。</p>
<p>从Flink1.12开始，主要使用流批统一的新Source架构：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataStreamSource&lt;String&gt; stream = env.fromSource(…)</span><br></pre></td></tr></table></figure>

<p>Flink直接提供了很多预实现的接口，此外还有很多外部连接工具也帮我们实现了对应的Source，通常情况下足以应对我们的实际需求。</p>
<h3 id="5-2-1-准备工作"><a href="#5-2-1-准备工作" class="headerlink" title="5.2.1 准备工作"></a>5.2.1 准备工作</h3><p>WaterSensor类</p>
<table>
<thead>
<tr>
<th>字段名</th>
<th>数据类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>String</td>
<td>水位传感器类型</td>
</tr>
<tr>
<td>ts</td>
<td>Long</td>
<td>传感器记录时间戳</td>
</tr>
<tr>
<td>vc</td>
<td>Integer</td>
<td>水位记录</td>
</tr>
</tbody></table>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WaterSensor</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> String id;</span><br><span class="line">    <span class="keyword">public</span> Long ts;</span><br><span class="line">    <span class="keyword">public</span> Integer vc;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WaterSensor</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WaterSensor</span><span class="params">(String id, Long ts, Integer vc)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">        <span class="built_in">this</span>.ts = ts;</span><br><span class="line">        <span class="built_in">this</span>.vc = vc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(String id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">getTs</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ts;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setTs</span><span class="params">(Long ts)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.ts = ts;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">getVc</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> vc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setVc</span><span class="params">(Integer vc)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.vc = vc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;WaterSensor&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;id=&#x27;&quot;</span> + id + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, ts=&quot;</span> + ts +</span><br><span class="line">                <span class="string">&quot;, vc=&quot;</span> + vc +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object o)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span> == o) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (!(o <span class="keyword">instanceof</span> WaterSensor)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="type">WaterSensor</span> <span class="variable">that</span> <span class="operator">=</span> (WaterSensor) o;</span><br><span class="line">        <span class="keyword">return</span> Objects.equals(getId(), that.getId()) &amp;&amp; Objects.equals(getTs(), that.getTs()) &amp;&amp; Objects.equals(getVc(), that.getVc());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hashCode</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Objects.hash(getId(), getTs(), getVc());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里需要注意，我们定义的WaterSensor，有这样几个特点：</p>
<ul>
<li>类是公有（public）的</li>
<li>有一个无参的构造方法</li>
<li>所有属性都是公有（public）的</li>
<li>所有属性的类型都是可以序列化的</li>
</ul>
<p>Flink会把这样的类作为一种特殊的POJO（Plain Ordinary Java Object简单的Java对象，实际就是普通JavaBeans）数据类型来对待，方便数据的解析和序列化。另外我们在类中还重写了toString方法，主要是为了测试输出显示更清晰。</p>
<p>我们这里自定义的POJO类会在后面的代码中频繁使用，所以在后面的代码中碰到，把这里的POJO类导入就好了。</p>
<h3 id="5-2-2-从集合中读取数据"><a href="#5-2-2-从集合中读取数据" class="headerlink" title="5.2.2 从集合中读取数据"></a>5.2.2 从集合中读取数据</h3><p>最简单的读取数据的方式，就是在代码中直接创建一个Java集合，然后调用执行环境的fromCollection方法进行读取。这相当于将数据临时存储到内存中，形成特殊的数据结构后，作为数据源使用，一般用于测试。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"><span class="comment">//TODO 从集合读取数据</span></span><br><span class="line">DataStreamSource&lt;Integer&gt; source = env.fromCollection(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>));<span class="comment">//从集合读取</span></span><br><span class="line">DataStreamSource&lt;Integer&gt; source1 = env.fromElements(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>);<span class="comment">//直接填写数据</span></span><br><span class="line"></span><br><span class="line">source.print();</span><br><span class="line">source1.print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">env.execute();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">16&gt; 4</span><br><span class="line">8&gt; 4</span><br><span class="line">15&gt; 3</span><br><span class="line">6&gt; 2</span><br><span class="line">14&gt; 2</span><br><span class="line">5&gt; 1</span><br><span class="line">7&gt; 3</span><br><span class="line">13&gt; 1</span><br></pre></td></tr></table></figure>

<p><strong>注意：前面的数字代表并行度编号</strong></p>
<h3 id="5-2-3-从文件读取数据"><a href="#5-2-3-从文件读取数据" class="headerlink" title="5.2.3 从文件读取数据"></a>5.2.3 从文件读取数据</h3><p>真正的实际应用中，自然不会直接将数据写在代码中。通常情况下，我们会从存储介质中获取数据，一个比较常见的方式就是读取日志文件。这也是批处理中最常见的读取方式。</p>
<p>读取文件，需要添加文件连接器依赖:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-files<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">    <span class="comment">//设置并行度为1</span></span><br><span class="line">    env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 从文件读，新source架构</span></span><br><span class="line">    FileSource&lt;String&gt; fileSource = FileSource.forRecordStreamFormat(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">TextLineInputFormat</span>(),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;input/word.txt&quot;</span>)</span><br><span class="line">    ).build();</span><br><span class="line"></span><br><span class="line">    DataStreamSource&lt;String&gt; source = env.fromSource(fileSource, WatermarkStrategy.noWatermarks(), <span class="string">&quot;FileSource&quot;</span>);</span><br><span class="line">    source.print();</span><br><span class="line">    </span><br><span class="line">    env.execute();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hello flink</span><br><span class="line">hello world</span><br><span class="line">hello java</span><br></pre></td></tr></table></figure>

<p>说明：</p>
<ul>
<li>参数可以是目录，也可以是文件；还可以从HDFS目录下读取，使用路径hdfs:&#x2F;&#x2F;…；</li>
<li>路径可以是相对路径，也可以是绝对路径；</li>
<li>相对路径是从系统属性user.dir获取路径：idea下是project的根目录，standalone模式下是集群节点根目录；</li>
</ul>
<h3 id="5-2-4-从Socket读取数据"><a href="#5-2-4-从Socket读取数据" class="headerlink" title="5.2.4 从Socket读取数据"></a>5.2.4 从Socket读取数据</h3><p>不论从集合还是文件，我们读取的其实都是有界数据。在流处理的场景中，数据往往是无界的。</p>
<p>我们之前用到的读取socket文本流，就是流处理场景。但是这种方式由于吞吐量小、稳定性较差，一般也是用于测试。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;String&gt; stream = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br></pre></td></tr></table></figure>

<h3 id="5-2-5-从Kafka读取数据"><a href="#5-2-5-从Kafka读取数据" class="headerlink" title="5.2.5 从Kafka读取数据"></a>5.2.5 从Kafka读取数据</h3><p>Flink官方提供了连接工具flink-connector-kafka，直接帮我们实现了一个消费者FlinkKafkaConsumer，它就是用来读取Kafka数据的SourceFunction。</p>
<p>所以想要以Kafka作为数据源获取数据，我们只需要引入Kafka连接器的依赖。Flink官方提供的是一个通用的Kafka连接器，它会自动跟踪最新版本的Kafka客户端。目前最新版本只支持0.10.0版本以上的Kafka。这里我们需要导入的依赖如下。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">&lt;/dependency</span><br></pre></td></tr></table></figure>

<p>开启zookeeper和kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# zk.sh start</span><br><span class="line">[root@hadoop102 ~]# kf.sh start</span><br></pre></td></tr></table></figure>

<p>开启Kafka生产者</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# kafka-console-producer.sh --broker-list hadoop102:9092 --topic topic_1</span><br></pre></td></tr></table></figure>

<p>运行如下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">    env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 从kafka读：新Source架构</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * kafka消费者的参数：</span></span><br><span class="line"><span class="comment">     *      auto.reset.offsets</span></span><br><span class="line"><span class="comment">     *            earliest:如果有offset，从offset继续消费，如果没有offset，从最早消费</span></span><br><span class="line"><span class="comment">     *            latest：如果有offset，从offset继续消费，如果欸有offset，从最新消费</span></span><br><span class="line"><span class="comment">     * flink的kafkasource，offset消费策略：offsetsInitializer，默认是earliest</span></span><br><span class="line"><span class="comment">     *            earliest：一定从最早消费</span></span><br><span class="line"><span class="comment">     *            latest：一定从最新消费</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    KafkaSource&lt;String&gt; kafkaSource = KafkaSource.&lt;String&gt;builder()</span><br><span class="line">            .setBootstrapServers(<span class="string">&quot;hadoop102:9092&quot;</span>) <span class="comment">//指定kafka节点的地址和端口</span></span><br><span class="line">            .setGroupId(<span class="string">&quot;root&quot;</span>) <span class="comment">//指定消费者组id</span></span><br><span class="line">            .setTopics(<span class="string">&quot;topic_1&quot;</span>) <span class="comment">//指定消费的Topic</span></span><br><span class="line">            .setValueOnlyDeserializer(<span class="keyword">new</span> <span class="title class_">SimpleStringSchema</span>()) <span class="comment">//指定反序列化器，只对value进行反序列化</span></span><br><span class="line">            .setStartingOffsets(OffsetsInitializer.latest()) <span class="comment">//flink消费kafka的策略</span></span><br><span class="line">            .build();</span><br><span class="line">    env.fromSource(kafkaSource, WatermarkStrategy.noWatermarks(),<span class="string">&quot;KafkaSourceDemo&quot;</span>).print();</span><br><span class="line"></span><br><span class="line">    env.execute();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在kafka生产者端输入数据在flink消费者端就能收到数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# kafka-console-producer.sh --broker-list hadoop102:9092 --topic topic_1</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">1,2,3,4,5</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-05_16-48-19.png" alt="Snipaste_2024-07-05_16-48-19"></p>
<h3 id="5-2-6-从数据生成器读取数据"><a href="#5-2-6-从数据生成器读取数据" class="headerlink" title="5.2.6 从数据生成器读取数据"></a>5.2.6 从数据生成器读取数据</h3><p>Flink从1.11开始提供了一个内置的DataGen 连接器，主要是用于生成一些随机数，用于在没有数据源的时候，进行流任务的测试以及性能测试等。1.17提供了新的Source写法，需要导入依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-datagen<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">    <span class="comment">//如果有n个并行度，最大值设为a，将数据均分为n份，a/n，比如最大值100，并行度2，每个并行度生成50个，其中一个是0-49，另一个是50-100</span></span><br><span class="line">    env.setParallelism(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 数据生成器Source，四个参数</span></span><br><span class="line"><span class="comment">     *     第一个参数：GeneratorFunction接口，需要实现重写map方法，输入类型固定是Long</span></span><br><span class="line"><span class="comment">     *     第二个参数：long类型，自动生成的数字序列（从1自增）的最大值，达到这个值就停止了</span></span><br><span class="line"><span class="comment">     *     第三个参数：限速策略，比如每秒生成几条数据</span></span><br><span class="line"><span class="comment">     *     第四个参数：返回的类型</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    DataGeneratorSource&lt;String&gt; dataGeneratorSource = <span class="keyword">new</span> <span class="title class_">DataGeneratorSource</span>&lt;&gt;(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">GeneratorFunction</span>&lt;Long, String&gt;() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> String <span class="title function_">map</span><span class="params">(Long value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="string">&quot;Number:&quot;</span> + value;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="number">10</span>,</span><br><span class="line">            RateLimiterStrategy.perSecond(<span class="number">1</span>),</span><br><span class="line">            Types.STRING</span><br><span class="line">    );</span><br><span class="line">    env.fromSource(dataGeneratorSource, WatermarkStrategy.noWatermarks(),<span class="string">&quot;DataGenerator&quot;</span>).print();</span><br><span class="line">    env.execute();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Number:0</span><br><span class="line">Number:1</span><br><span class="line">Number:2</span><br><span class="line">Number:3</span><br><span class="line">Number:4</span><br><span class="line">Number:5</span><br><span class="line">Number:6</span><br><span class="line">Number:7</span><br><span class="line">Number:8</span><br><span class="line">Number:9</span><br></pre></td></tr></table></figure>

<p><strong>注意：如果想要无界流的效果，可以将第三个参数设置为Long.MAX_VALUE</strong></p>
<h3 id="5-2-7-Flink支持的数据类型"><a href="#5-2-7-Flink支持的数据类型" class="headerlink" title="5.2.7 Flink支持的数据类型"></a>5.2.7 Flink支持的数据类型</h3><h4 id="5-2-7-1-Flink的类型系统"><a href="#5-2-7-1-Flink的类型系统" class="headerlink" title="5.2.7.1 Flink的类型系统"></a>5.2.7.1 Flink的类型系统</h4><p>Flink使用“类型信息”（TypeInformation）来统一表示数据类型。TypeInformation类是Flink中所有类型描述符的基类。它涵盖了类型的一些基本属性，并为每个数据类型生成特定的序列化器、反序列化器和比较器。</p>
<h4 id="5-2-7-2-Flink支持的数据类型"><a href="#5-2-7-2-Flink支持的数据类型" class="headerlink" title="5.2.7.2 Flink支持的数据类型"></a>5.2.7.2 Flink支持的数据类型</h4><p>对于常见的Java和Scala数据类型，Flink都是支持的。Flink在内部，Flink对支持不同的类型进行了划分，这些类型可以在<strong>Types工具类</strong>中找到：</p>
<p>（1）基本类型</p>
<p>所有Java基本类型及其包装类，再加上Void、String、Date、BigDecimal和BigInteger。</p>
<p>（2）数组类型</p>
<p>包括基本类型数组（PRIMITIVE_ARRAY）和对象数组（OBJECT_ARRAY）。</p>
<p>（3）复合数据类型</p>
<ul>
<li><p>Java元组类型（TUPLE）：这是Flink内置的元组类型，是Java API的一部分。最多25个字段，也就是从Tuple0~Tuple25，不支持空字段。</p>
</li>
<li><p>Scala 样例类及Scala元组：不支持空字段。</p>
</li>
<li><p>行类型（ROW）：可以认为是具有任意个字段的元组，并支持空字段。</p>
</li>
<li><p>POJO：Flink自定义的类似于Java bean模式的类。</p>
</li>
</ul>
<p>（4）辅助类型</p>
<p>Option、Either、List、Map等。</p>
<p>（5）泛型类型（GENERIC）</p>
<p>Flink支持所有的Java类和Scala类。不过如果没有按照上面POJO类型的要求来定义，就会被Flink当作泛型类来处理。Flink会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由Flink本身序列化的，而是由Kryo序列化的。</p>
<p>在这些类型中，元组类型和POJO类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为Flink的POJO类型。</p>
<p>Flink对POJO类型的要求如下：</p>
<ul>
<li><p>类是公有（public）的</p>
</li>
<li><p>有一个无参的构造方法（构造器）</p>
</li>
<li><p>所有属性都是公有（public）的</p>
</li>
<li><p>所有属性的类型都是可以序列化的</p>
</li>
</ul>
<h4 id="5-2-7-3-类型提示（Type-Hints）"><a href="#5-2-7-3-类型提示（Type-Hints）" class="headerlink" title="5.2.7.3 类型提示（Type Hints）"></a>5.2.7.3 类型提示（Type Hints）</h4><p>Flink还具有一个类型提取系统，可以分析函数的输入和返回类型，自动获取类型信息，从而获得对应的序列化器和反序列化器。但是，由于Java中泛型擦除的存在，在某些特殊情况下（比如Lambda表达式中），自动提取的信息是不够精细的——只告诉Flink当前的元素由“船头、船身、船尾”构成，根本无法重建出“大船”的模样；这时就需要显式地提供类型信息，才能使应用程序正常工作或提高其性能。</p>
<p>为了解决这类问题，Java API提供了专门的“类型提示”（type hints）。</p>
<p>回忆一下之前的word count流处理程序，我们在将String类型的每个词转换成（word， count）二元组后，就明确地用returns指定了返回的类型。因为对于map里传入的Lambda表达式，系统只能推断出返回的是Tuple2类型，而无法得到Tuple2&lt;String, Long&gt;。只有显式地告诉系统当前的返回类型，才能正确地解析出完整数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.map(word -&gt; Tuple2.of(word, <span class="number">1L</span>))</span><br><span class="line">.returns(Types.TUPLE(Types.STRING, Types.LONG));</span><br></pre></td></tr></table></figure>

<p>Flink还专门提供了TypeHint类，它可以捕获泛型的类型信息，并且一直记录下来，为运行时提供足够的信息。我们同样可以通过.returns()方法，明确地指定转换之后的DataStream里元素的类型。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">returns(<span class="keyword">new</span> <span class="title class_">TypeHint</span>&lt;Tuple2&lt;Integer, SomeType&gt;&gt;()&#123;&#125;)</span><br></pre></td></tr></table></figure>

<p>之前的写法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                (String s, Collector&lt;String&gt; out) -&gt; &#123;</span><br><span class="line">                    String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                    <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                        out.collect(word);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        ).startNewChain()</span><br><span class="line">        .returns(Types.STRING)</span><br><span class="line">        .map(word -&gt; Tuple2.of(word, <span class="number">1</span>))</span><br><span class="line">        .returns(Types.TUPLE(Types.STRING, Types.INT))</span><br><span class="line">        .keyBy(value -&gt; value.f0)</span><br><span class="line">        .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<p>type hints写法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; sum = socketDS.flatMap(</span><br><span class="line">                (String s, Collector&lt;String&gt; out) -&gt; &#123;</span><br><span class="line">                    String[] words = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                    <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                        out.collect(word);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        ).startNewChain()</span><br><span class="line">        .returns(<span class="keyword">new</span> <span class="title class_">TypeHint</span>&lt;String&gt;() &#123;&#125;)</span><br><span class="line">        .map(word -&gt; Tuple2.of(word, <span class="number">1</span>))</span><br><span class="line">        .returns(<span class="keyword">new</span> <span class="title class_">TypeHint</span>&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;&#125;)</span><br><span class="line">        .keyBy(value -&gt; value.f0)</span><br><span class="line">        .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<h2 id="5-3-转换算子（Transformation）"><a href="#5-3-转换算子（Transformation）" class="headerlink" title="5.3 转换算子（Transformation）"></a>5.3 转换算子（Transformation）</h2><p>数据源读入数据之后，我们就可以使用各种转换算子，将一个或多个DataStream转换为新的DataStream。</p>
<h3 id="5-3-1-基本转换算子（map-x2F-filter-x2F-flatMap）"><a href="#5-3-1-基本转换算子（map-x2F-filter-x2F-flatMap）" class="headerlink" title="5.3.1 基本转换算子（map&#x2F;filter&#x2F;flatMap）"></a>5.3.1 基本转换算子（map&#x2F;filter&#x2F;flatMap）</h3><h4 id="（1）-映射（map）"><a href="#（1）-映射（map）" class="headerlink" title="（1） 映射（map）"></a>（1） 映射（map）</h4><p>map是大家非常熟悉的大数据操作算子，主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，就是一个“<strong>一一映射</strong>”，消费一个元素就产出一个元素。</p>
<blockquote>
<p>注意：不一定输入和输出的数据类型就相同，map就是输入1输出1，数对上就行，可能输入一只猫输出来一条狗</p>
</blockquote>
<img src="Snipaste_2024-07-12_12-53-47.png" alt="Snipaste_2024-07-12_12-53-47" style="zoom:33%;">

<p>我们只需要基于DataStream调用map()方法就可以进行转换处理。方法需要传入的参数是接口MapFunction的实现；返回值类型还是DataStream，不过泛型（流中的元素类型）可能改变。</p>
<p>下面的代码用不同的方式，实现了提取WaterSensor中的id字段的功能。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO 1 获取数据源</span></span><br><span class="line">DataStreamSource&lt;WaterSensor&gt; sensorDS = env.fromElements(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;s1&quot;</span>, <span class="number">1L</span>, <span class="number">1</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;s2&quot;</span>, <span class="number">2L</span>, <span class="number">2</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;s3&quot;</span>, <span class="number">3L</span>, <span class="number">4</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO 2 使用map算子提取每条WaterSensor数据的id并做打印</span></span><br><span class="line"><span class="comment">//方式1：使用匿名实现类</span></span><br><span class="line">SingleOutputStreamOperator&lt;String&gt; mapDS = sensorDS.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;WaterSensor, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">map</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> value.id;<span class="comment">//return value.getId();</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">mapDS.print();</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//方式2：使用lambda表达式</span></span><br><span class="line">sensorDS.map(v1 -&gt; v1.id).print();</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//方式3：定义一个类来实现MapFunction接口</span></span><br><span class="line">sensorDS.map(<span class="keyword">new</span> <span class="title class_">MyMapFunction</span>()).print();</span><br><span class="line"></span><br><span class="line"><span class="comment">//在另一个包中定义以下类</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyMapFunction</span> <span class="keyword">implements</span> <span class="title class_">MapFunction</span>&lt;WaterSensor,String&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">map</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> value.id;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面代码中，MapFunction实现类的泛型类型，与输入数据类型和输出数据的类型有关。在实现MapFunction接口的时候，<strong>需要指定两个泛型</strong>，分别是<strong>输入事件</strong>和<strong>输出事件</strong>的类型，还需要<strong>重写一个map()方法</strong>，定义从一个输入事件转换为另一个输出事件的具体逻辑。</p>
<h4 id="（2）-过滤（filter）"><a href="#（2）-过滤（filter）" class="headerlink" title="（2） 过滤（filter）"></a>（2） 过滤（filter）</h4><p>filter转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为true则元素正常输出，若为false则元素被过滤掉。</p>
<img src="Snipaste_2024-07-12_16-39-31.png" alt="Snipaste_2024-07-12_16-39-31" style="zoom:33%;">

<p><strong>进行filter转换之后的新数据流的数据类型与原数据流是相同的</strong>。filter转换需要传入的参数需要实现FilterFunction接口，而FilterFunction内要实现filter()方法，就相当于一个返回布尔类型的条件表达式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: FilterDemo</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.transform</span></span><br><span class="line"><span class="comment"> * Description:下面的代码会将数据流中传感器id为sensor_1的数据过滤出来</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/7/14 0014 14:09</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 1 获取数据源</span></span><br><span class="line">        DataStreamSource&lt;WaterSensor&gt; SensorDS = env.fromElements(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_2&quot;</span>, <span class="number">2L</span>, <span class="number">39</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_3&quot;</span>, <span class="number">3L</span>, <span class="number">33</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">4L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">88</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 2 使用filter算子</span></span><br><span class="line">        SensorDS.filter(<span class="keyword">new</span> <span class="title class_">FilterFunction</span>&lt;WaterSensor&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">filter</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;sensor_1&quot;</span>.equals(value.getId());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=4, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=88&#125;</span><br></pre></td></tr></table></figure>

<h4 id="（3）-扁平映射（flatMap）"><a href="#（3）-扁平映射（flatMap）" class="headerlink" title="（3） 扁平映射（flatMap）"></a>（3） 扁平映射（flatMap）</h4><p>flatMap操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生0到多个元素。flatMap可以认为是“扁平化”（flatten）和“映射”（map）两步操作的结合，也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理。</p>
<img src="Snipaste_2024-07-14_16-50-39.png" alt="Snipaste_2024-07-14_16-50-39" style="zoom:33%;">

<p>同map一样，flatMap也可以使用Lambda表达式或者FlatMapFunction接口实现类的方式来进行传参，返回值类型取决于所传参数的具体逻辑，可以与原数据流相同，也可以不同。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: FlatmapDemo</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.transform</span></span><br><span class="line"><span class="comment"> * Description: 如果输入的数据是sensor_1，只打印vc；如果输入的数据是sensor_2，既打印ts又打印vc。</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/7/14 0014 16:53</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlatmapDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 1 获取数据源</span></span><br><span class="line">        DataStreamSource&lt;WaterSensor&gt; SensorDS = env.fromElements(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_2&quot;</span>, <span class="number">2L</span>, <span class="number">39</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_3&quot;</span>, <span class="number">3L</span>, <span class="number">33</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">4L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">88</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 2 使用flatmap算子操作：一进多出</span></span><br><span class="line">        SingleOutputStreamOperator&lt;String&gt; flatMapDS = SensorDS.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;WaterSensor, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(WaterSensor value, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">if</span> (<span class="string">&quot;sensor_1&quot;</span>.equals(value.getId())) &#123;</span><br><span class="line">                    out.collect(value.getVc().toString());</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;sensor_2&quot;</span>.equals(value.getId())) &#123;</span><br><span class="line">                    out.collect(value.getVc().toString());</span><br><span class="line">                    out.collect(value.getTs().toString());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        flatMapDS.print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">20</span><br><span class="line">39</span><br><span class="line">2</span><br><span class="line">20</span><br><span class="line">88</span><br></pre></td></tr></table></figure>

<p><strong>map怎么控制一进一出：return</strong></p>
<p><strong>flatmap怎么控制一进多出：通过Collector来输出，调用几次就输出几条</strong></p>
<h3 id="5-3-2-聚合算子（Aggregation）"><a href="#5-3-2-聚合算子（Aggregation）" class="headerlink" title="5.3.2 聚合算子（Aggregation）"></a>5.3.2 聚合算子（Aggregation）</h3><p>计算的结果不仅依赖当前数据，还跟之前的数据有关，相当于要把所有数据聚在一起进行汇总合并——这就是所谓的“聚合”（Aggregation），类似于MapReduce中的reduce操作。</p>
<h4 id="（1）-按键分区（keyBy）"><a href="#（1）-按键分区（keyBy）" class="headerlink" title="（1） 按键分区（keyBy）"></a>（1） 按键分区（keyBy）</h4><p>对于Flink而言，DataStream是没有直接进行聚合的API的。因为我们对海量数据做聚合肯定要进行分区并行处理，这样才能提高效率。所以在Flink中，要做聚合，需要先进行分区；这个操作就是通过keyBy来完成的。</p>
<p>keyBy是聚合前必须要用到的一个算子。keyBy通过指定键（key），可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务。</p>
<p>基于不同的key，流中的数据将被分配到不同的分区中去；这样一来，所有具有相同的key的数据，都将被发往同一个分区。</p>
<img src="Snipaste_2024-07-14_17-13-53.png" alt="Snipaste_2024-07-14_17-13-53" style="zoom:33%;">

<p>在内部，是通过计算key的哈希值（hash code），对分区数进行取模运算来实现的。所以这里key如果是POJO的话，必须要重写hashCode()方法。</p>
<p>keyBy()方法需要传入一个参数，这个参数指定了一个或一组key。有很多不同的方法来指定key：比如对于Tuple数据类型，可以指定字段的位置或者多个位置的组合；对于POJO类型，可以指定字段的名称（String）；另外，还可以传入Lambda表达式或者实现一个键选择器（KeySelector），用于说明从数据中提取key的逻辑。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KeybyDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 1 获取数据源</span></span><br><span class="line">        DataStreamSource&lt;WaterSensor&gt; SensorDS = env.fromElements(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_2&quot;</span>, <span class="number">2L</span>, <span class="number">39</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_3&quot;</span>, <span class="number">3L</span>, <span class="number">33</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">4L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">88</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 2 按照WaterSensor的id进行分组</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1.返回的是一个KeyedStream，键控流</span></span><br><span class="line"><span class="comment">         * 2.KeyBy不是转换算子，只是对数据进行重分区，不能设置并行度</span></span><br><span class="line"><span class="comment">         * 3.KeyBy分组 与 分区 的关系：</span></span><br><span class="line"><span class="comment">         *  （1）KeyBy是对数据分组，保证相同Key的数据在同一个分区</span></span><br><span class="line"><span class="comment">         *  （2）分区：一个子任务，可以理解为一个分区，一个分区（子任务）中可以存在多个分组（key）</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        KeyedStream&lt;WaterSensor, String&gt; sensorKS = SensorDS.keyBy(<span class="keyword">new</span> <span class="title class_">KeySelector</span>&lt;WaterSensor, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">getKey</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> value.getId();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        sensorKS.print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1&gt; WaterSensor&#123;id=&#x27;sensor_2&#x27;, ts=2, vc=39&#125;</span><br><span class="line">2&gt; WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">1&gt; WaterSensor&#123;id=&#x27;sensor_3&#x27;, ts=3, vc=33&#125;</span><br><span class="line">2&gt; WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=4, vc=20&#125;</span><br><span class="line">2&gt; WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=88&#125;</span><br></pre></td></tr></table></figure>

<h4 id="（2）简单聚合（sum-x2F-min-x2F-max-x2F-minBy-x2F-maxBy）"><a href="#（2）简单聚合（sum-x2F-min-x2F-max-x2F-minBy-x2F-maxBy）" class="headerlink" title="（2）简单聚合（sum&#x2F;min&#x2F;max&#x2F;minBy&#x2F;maxBy）"></a>（2）简单聚合（sum&#x2F;min&#x2F;max&#x2F;minBy&#x2F;maxBy）</h4><p>有了按键分区的数据流KeyedStream，我们就可以基于它进行聚合操作了。Flink为我们内置实现了一些最基本、最简单的聚合API，主要有以下几种：</p>
<ul>
<li>sum()：在输入流上，对指定的字段做叠加求和的操作。</li>
<li>min()：在输入流上，对指定的字段求最小值。</li>
<li>max()：在输入流上，对指定的字段求最大值。</li>
<li>minBy()：与min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而minBy()则会返回包含字段最小值的整条数据。</li>
<li>maxBy()：与max()类似，在输入流上针对指定字段求最大值。两者区别与min()&#x2F;minBy()完全一致。</li>
</ul>
<p>简单聚合算子使用非常方便，语义也非常明确。这些聚合方法调用时，也需要传入参数；但并不像基本转换算子那样需要实现自定义函数，只要说明聚合指定的字段就可以了。指定字段的方式有两种：指定位置，和指定名称。</p>
<p>对于元组类型的数据，可以使用这两种方式来指定字段。需要注意的是，元组中字段的名称，是以f0、f1、f2、…来命名的。</p>
<p>如果数据流的类型是POJO类，那么就只能通过字段名称来指定，不能通过位置来指定了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">    env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 1 获取数据源</span></span><br><span class="line">    DataStreamSource&lt;WaterSensor&gt; SensorDS = env.fromElements(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">20</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_2&quot;</span>, <span class="number">2L</span>, <span class="number">39</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_3&quot;</span>, <span class="number">3L</span>, <span class="number">33</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">4L</span>, <span class="number">20</span>),</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">88</span>)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">//TODO 2 简单聚合算子</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1.必须在KeyBy之后才能调用</span></span><br><span class="line"><span class="comment">     * 2.分组内的聚合，对同一个key的数据进行聚合</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    KeyedStream&lt;WaterSensor, String&gt; sensorKS = SensorDS.keyBy(<span class="keyword">new</span> <span class="title class_">KeySelector</span>&lt;WaterSensor, String&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> String <span class="title function_">getKey</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            <span class="keyword">return</span> value.getId();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    </span><br><span class="line">    sensorKS.sum(<span class="string">&quot;vc&quot;</span>).print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    env.execute();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_2&#x27;, ts=2, vc=39&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_3&#x27;, ts=3, vc=33&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=40&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=128&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensorKS.min(<span class="string">&quot;vc&quot;</span>).print();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_2&#x27;, ts=2, vc=39&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_3&#x27;, ts=3, vc=33&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensorKS.max(<span class="string">&quot;vc&quot;</span>).print();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_2&#x27;, ts=2, vc=39&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_3&#x27;, ts=3, vc=33&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=88&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * max/maxBy的区别：</span></span><br><span class="line"><span class="comment"> *    max：只会取比较字段的最大值，非比较字段保留第一次的值</span></span><br><span class="line"><span class="comment"> *    maxBy：取比较字段最大的值，同时非比较字段取最大值这条数据的</span></span><br><span class="line"><span class="comment"> * min/minBy同理</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">sensorKS.minBy(<span class="string">&quot;vc&quot;</span>).print();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_2&#x27;, ts=2, vc=39&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_3&#x27;, ts=3, vc=33&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensorKS.maxBy(<span class="string">&quot;vc&quot;</span>).print();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_2&#x27;, ts=2, vc=39&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_3&#x27;, ts=3, vc=33&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=88&#125;</span><br></pre></td></tr></table></figure>

<p>简单聚合算子返回的，同样是一个SingleOutputStreamOperator，也就是从KeyedStream又转换成了常规的DataStream。所以可以这样理解：keyBy和聚合是成对出现的，先分区、后聚合，得到的依然是一个DataStream。而且经过简单聚合之后的数据流，元素的数据类型保持不变。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;WaterSensor&gt; maxByDS = sensorKS.maxBy(<span class="string">&quot;vc&quot;</span>);</span><br><span class="line">maxByDS.print();</span><br></pre></td></tr></table></figure>

<p>一个聚合算子，会为每一个key保存一个聚合的值，在Flink中我们把它叫作“状态”（state）。所以每当有一个新的数据输入，算子就会更新保存的聚合结果，并发送一个带有更新后聚合值的事件到下游算子。对于无界流来说，这些状态是永远不会被清除的，所以我们使用聚合算子，应该只用在含有有限个key的数据流上。</p>
<h4 id="（3）归约聚合（reduce）"><a href="#（3）归约聚合（reduce）" class="headerlink" title="（3）归约聚合（reduce）"></a>（3）归约聚合（reduce）</h4><p>reduce可以对已有的数据进行归约处理，把每一个新输入的数据和当前已经归约出来的值，再做一个聚合计算。</p>
<p>reduce操作也会将KeyedStream转换为DataStream。它不会改变流的元素数据类型，所以<strong>输出类型和输入类型是一样的。</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ReduceDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 1 获取数据源</span></span><br><span class="line">        DataStreamSource&lt;WaterSensor&gt; SensorDS = env.fromElements(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_2&quot;</span>, <span class="number">2L</span>, <span class="number">39</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_3&quot;</span>, <span class="number">3L</span>, <span class="number">33</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">4L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">88</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 2 reduce</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1.必须在KeyBy之后才能调用</span></span><br><span class="line"><span class="comment">         * 2.两两聚合，输入类型=输出类型，类型不能变</span></span><br><span class="line"><span class="comment">         * 3.每个key的第一条数据来的时候，不会执行reduce方法，存起来，直接输出</span></span><br><span class="line"><span class="comment">         * 4.reduce方法中的两个参数</span></span><br><span class="line"><span class="comment">         *     value1：之前的计算结果，存状态</span></span><br><span class="line"><span class="comment">         *     value2：现在来的数据</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        KeyedStream&lt;WaterSensor, String&gt; sensorKS = SensorDS.keyBy(<span class="keyword">new</span> <span class="title class_">KeySelector</span>&lt;WaterSensor, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">getKey</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> value.getId();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;WaterSensor&gt; reduceDS = sensorKS.reduce(<span class="keyword">new</span> <span class="title class_">ReduceFunction</span>&lt;WaterSensor&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> WaterSensor <span class="title function_">reduce</span><span class="params">(WaterSensor value1, WaterSensor value2)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;value1 = &quot;</span> + value1);</span><br><span class="line">                System.out.println(<span class="string">&quot;value2 = &quot;</span> + value2);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(value1.id, value2.ts, value1.vc + value2.vc);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        reduceDS.print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_2&#x27;, ts=2, vc=39&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_3&#x27;, ts=3, vc=33&#125;</span><br><span class="line">value1 = WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">value2 = WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=4, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=4, vc=40&#125;</span><br><span class="line">value1 = WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=4, vc=40&#125;</span><br><span class="line">value2 = WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=88&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=128&#125;</span><br></pre></td></tr></table></figure>

<p>reduce同简单聚合算子一样，也要针对每一个key保存状态。因为状态不会清空，所以我们需要将reduce算子作用在一个有限key的流上。</p>
<h3 id="5-3-3-用户自定义函数（UDF）"><a href="#5-3-3-用户自定义函数（UDF）" class="headerlink" title="5.3.3 用户自定义函数（UDF）"></a>5.3.3 用户自定义函数（UDF）</h3><p>用户自定义函数（user-defined function，UDF），即用户可以根据自身需求，重新实现算子的逻辑。</p>
<p>用户自定义函数分为：函数类、匿名函数、富函数类。</p>
<h4 id="（1）函数类（Function-Classes）"><a href="#（1）函数类（Function-Classes）" class="headerlink" title="（1）函数类（Function Classes）"></a>（1）函数类（Function Classes）</h4><p>Flink暴露了所有UDF函数的接口，具体实现方式为接口或者抽象类，例如MapFunction、FilterFunction、ReduceFunction等。所以用户可以自定义一个函数类，实现对应的接口。</p>
<p>需求：用来从用户的点击数据中筛选包含“sensor_1”的内容：</p>
<p>方式一：实现FilterFunction接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransFunctionUDF</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;WaterSensor&gt; SensorDS = env.fromElements(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_2&quot;</span>, <span class="number">2L</span>, <span class="number">39</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_3&quot;</span>, <span class="number">3L</span>, <span class="number">33</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">4L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">88</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        SensorDS.filter(<span class="keyword">new</span> <span class="title class_">UserFilter</span>()).print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserFilter</span> <span class="keyword">implements</span> <span class="title class_">FilterFunction</span>&lt;WaterSensor&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">filter</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;sensor_1&quot;</span>.equals(value.getId());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=4, vc=20&#125;</span><br><span class="line">WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=1, vc=88&#125;</span><br></pre></td></tr></table></figure>

<p>方式一的优化：自定义类时使用构造器传参</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransFunctionUDF</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;WaterSensor&gt; SensorDS = env.fromElements(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_2&quot;</span>, <span class="number">2L</span>, <span class="number">39</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_3&quot;</span>, <span class="number">3L</span>, <span class="number">33</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">4L</span>, <span class="number">20</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">WaterSensor</span>(<span class="string">&quot;sensor_1&quot;</span>, <span class="number">1L</span>, <span class="number">88</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        SensorDS.filter(<span class="keyword">new</span> <span class="title class_">UserFilter</span>(<span class="string">&quot;sensor_1&quot;</span>)).print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserFilter</span> <span class="keyword">implements</span> <span class="title class_">FilterFunction</span>&lt;WaterSensor&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> String id;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">UserFilter</span><span class="params">(String id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">filter</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.id.equals(value.getId());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>方式二：通过匿名类来实现FilterFunction接口：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SensorDS.filter(<span class="keyword">new</span> <span class="title class_">FilterFunction</span>&lt;WaterSensor&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">filter</span><span class="params">(WaterSensor value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;sensor_1&quot;</span>.equals(value.getId());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).print();</span><br></pre></td></tr></table></figure>

<p>方式三：采用匿名函数（Lambda）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SensorDS.filter(v1 -&gt; <span class="string">&quot;sensor_1&quot;</span>.equals(v1.getId())).print();</span><br></pre></td></tr></table></figure>

<h4 id="（2）富函数类（Rich-Function-Classes）"><a href="#（2）富函数类（Rich-Function-Classes）" class="headerlink" title="（2）富函数类（Rich Function Classes）"></a>（2）富函数类（Rich Function Classes）</h4><p>“富函数类”也是DataStream API提供的一个函数类的接口，所有的Flink函数类都有其Rich版本。富函数类一般是以抽象类的形式出现的。例如：RichMapFunction、RichFilterFunction、RichReduceFunction等。</p>
<p>与常规函数类的不同主要在于，富函数类可以获取运行环境的上下文，并拥有一些生命周期方法，所以可以实现更复杂的功能。</p>
<p>Rich Function有生命周期的概念。典型的生命周期方法有：</p>
<ul>
<li>open()方法，是Rich Function的初始化方法，也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如map()或者filter()方法被调用之前，open()会首先被调用。</li>
<li>close()方法，是生命周期中的最后一个调用的方法，类似于结束方法。一般用来做一些清理工作。</li>
</ul>
<p>需要注意的是，这里的生命周期方法，对于一个并行子任务来说只会调用一次；而对应的，实际工作方法，例如RichMapFunction中的map()，在每条数据到来后都会触发一次调用。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RichFunctionDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;Integer&gt; source = env.fromElements(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 构建相应的富函数类，重写open，map和close方法</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1.多了生命周期管理方法：</span></span><br><span class="line"><span class="comment">         *     open():每个子任务，在启动时，调用一次</span></span><br><span class="line"><span class="comment">         *     close():每个子任务，在结束时，调用一次</span></span><br><span class="line"><span class="comment">         *           如果是flink程序异常挂掉，不会调用close</span></span><br><span class="line"><span class="comment">         *           如果是正常调用cancel Job命令，可以close</span></span><br><span class="line"><span class="comment">         * 2.多了一个运行时上下文</span></span><br><span class="line"><span class="comment">         *    可以获取一些运行时的环境信息，比如子任务编号、名称、其他。。。</span></span><br><span class="line"><span class="comment">         * 3.对于无界流，每个子任务启动时调用一次open()，然后随着数据过来算子方法对数据进行处理，当每个子任务结束时调用一次close()方法</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        source.map(<span class="keyword">new</span> <span class="title class_">RichMapFunction</span>&lt;Integer, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="built_in">super</span>.open(parameters);</span><br><span class="line">                <span class="comment">//获取上下文</span></span><br><span class="line">                <span class="type">RuntimeContext</span> <span class="variable">context</span> <span class="operator">=</span> getRuntimeContext();</span><br><span class="line">                <span class="comment">//获取子任务的索引编号，例如并行度是3，索引编号就有0，1，2</span></span><br><span class="line">                <span class="type">int</span> <span class="variable">indexOfThisSubtask</span> <span class="operator">=</span> context.getIndexOfThisSubtask();</span><br><span class="line">                <span class="comment">//获取子任务的名字</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">taskNameWithSubtasks</span> <span class="operator">=</span> context.getTaskNameWithSubtasks();</span><br><span class="line">                System.out.println(<span class="string">&quot;子任务编号=&quot;</span> + indexOfThisSubtask + <span class="string">&quot;启动，子任务名称=&quot;</span> + taskNameWithSubtasks + <span class="string">&quot;,调用open()&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Integer <span class="title function_">map</span><span class="params">(Integer value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> value + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="built_in">super</span>.close();</span><br><span class="line">                System.out.println(<span class="string">&quot;子任务编号=&quot;</span> + getRuntimeContext().getIndexOfThisSubtask()</span><br><span class="line">                        + <span class="string">&quot;启动，子任务名称=&quot;</span> + getRuntimeContext().getTaskNameWithSubtasks() + <span class="string">&quot;,调用close()&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">子任务编号=7启动，子任务名称=Map -&gt; Sink: Print to Std. Out (8/16)#0,调用open()</span><br><span class="line">子任务编号=15启动，子任务名称=Map -&gt; Sink: Print to Std. Out (16/16)#0,调用open()</span><br><span class="line">子任务编号=9启动，子任务名称=Map -&gt; Sink: Print to Std. Out (10/16)#0,调用open()</span><br><span class="line">子任务编号=14启动，子任务名称=Map -&gt; Sink: Print to Std. Out (15/16)#0,调用open()</span><br><span class="line">子任务编号=12启动，子任务名称=Map -&gt; Sink: Print to Std. Out (13/16)#0,调用open()</span><br><span class="line">子任务编号=8启动，子任务名称=Map -&gt; Sink: Print to Std. Out (9/16)#0,调用open()</span><br><span class="line">子任务编号=6启动，子任务名称=Map -&gt; Sink: Print to Std. Out (7/16)#0,调用open()</span><br><span class="line">子任务编号=3启动，子任务名称=Map -&gt; Sink: Print to Std. Out (4/16)#0,调用open()</span><br><span class="line">子任务编号=2启动，子任务名称=Map -&gt; Sink: Print to Std. Out (3/16)#0,调用open()</span><br><span class="line">子任务编号=11启动，子任务名称=Map -&gt; Sink: Print to Std. Out (12/16)#0,调用open()</span><br><span class="line">子任务编号=10启动，子任务名称=Map -&gt; Sink: Print to Std. Out (11/16)#0,调用open()</span><br><span class="line">子任务编号=13启动，子任务名称=Map -&gt; Sink: Print to Std. Out (14/16)#0,调用open()</span><br><span class="line">子任务编号=5启动，子任务名称=Map -&gt; Sink: Print to Std. Out (6/16)#0,调用open()</span><br><span class="line">子任务编号=4启动，子任务名称=Map -&gt; Sink: Print to Std. Out (5/16)#0,调用open()</span><br><span class="line">子任务编号=0启动，子任务名称=Map -&gt; Sink: Print to Std. Out (1/16)#0,调用open()</span><br><span class="line">子任务编号=1启动，子任务名称=Map -&gt; Sink: Print to Std. Out (2/16)#0,调用open()</span><br><span class="line">5&gt; 2</span><br><span class="line">7&gt; 4</span><br><span class="line">6&gt; 3</span><br><span class="line">8&gt; 5</span><br><span class="line">子任务编号=0启动，子任务名称=Map -&gt; Sink: Print to Std. Out (1/16)#0,调用close()</span><br><span class="line">子任务编号=9启动，子任务名称=Map -&gt; Sink: Print to Std. Out (10/16)#0,调用close()</span><br><span class="line">子任务编号=2启动，子任务名称=Map -&gt; Sink: Print to Std. Out (3/16)#0,调用close()</span><br><span class="line">子任务编号=15启动，子任务名称=Map -&gt; Sink: Print to Std. Out (16/16)#0,调用close()</span><br><span class="line">子任务编号=3启动，子任务名称=Map -&gt; Sink: Print to Std. Out (4/16)#0,调用close()</span><br><span class="line">子任务编号=14启动，子任务名称=Map -&gt; Sink: Print to Std. Out (15/16)#0,调用close()</span><br><span class="line">子任务编号=13启动，子任务名称=Map -&gt; Sink: Print to Std. Out (14/16)#0,调用close()</span><br><span class="line">子任务编号=11启动，子任务名称=Map -&gt; Sink: Print to Std. Out (12/16)#0,调用close()</span><br><span class="line">子任务编号=8启动，子任务名称=Map -&gt; Sink: Print to Std. Out (9/16)#0,调用close()</span><br><span class="line">子任务编号=10启动，子任务名称=Map -&gt; Sink: Print to Std. Out (11/16)#0,调用close()</span><br><span class="line">子任务编号=7启动，子任务名称=Map -&gt; Sink: Print to Std. Out (8/16)#0,调用close()</span><br><span class="line">子任务编号=5启动，子任务名称=Map -&gt; Sink: Print to Std. Out (6/16)#0,调用close()</span><br><span class="line">子任务编号=4启动，子任务名称=Map -&gt; Sink: Print to Std. Out (5/16)#0,调用close()</span><br><span class="line">子任务编号=12启动，子任务名称=Map -&gt; Sink: Print to Std. Out (13/16)#0,调用close()</span><br><span class="line">子任务编号=1启动，子任务名称=Map -&gt; Sink: Print to Std. Out (2/16)#0,调用close()</span><br><span class="line">子任务编号=6启动，子任务名称=Map -&gt; Sink: Print to Std. Out (7/16)#0,调用close()</span><br></pre></td></tr></table></figure>

<h3 id="5-3-4-物理分区算子（Physical-Partitioning）"><a href="#5-3-4-物理分区算子（Physical-Partitioning）" class="headerlink" title="5.3.4 物理分区算子（Physical Partitioning）"></a>5.3.4 物理分区算子（Physical Partitioning）</h3><p>常见的物理分区策略有：随机分配（Random）、轮询分配（Round-Robin）、重缩放（Rescale）和广播（Broadcast）。</p>
<p>总结：flink提供的分区器：</p>
<p>①随机分区Random</p>
<p>②轮询分区Round-Robin</p>
<p>③重缩放分区Rescale</p>
<p>④广播分区Broadcast</p>
<p>⑤全局分区Global</p>
<p>⑥KeyBy分区：按照key去发送，相同key发往同一个子任务</p>
<p>⑦one-to-one：Forward分区器</p>
<p>⑧自定义分区</p>
<h4 id="（1）随机分区（shuffle）"><a href="#（1）随机分区（shuffle）" class="headerlink" title="（1）随机分区（shuffle）"></a>（1）随机分区（shuffle）</h4><p>最简单的重分区方式就是直接“洗牌”。通过调用DataStream的.shuffle()方法，将数据随机地分配到下游算子的并行任务中去。</p>
<p>随机分区服从均匀分布（uniform distribution），所以可以把流中的数据随机打乱，均匀地传递到下游任务分区。因为是完全随机的，所以对于同样的输入数据, 每次执行得到的结果也不会相同。</p>
<img src="Snipaste_2024-07-17_13-59-26.png" alt="Snipaste_2024-07-17_13-59-26" style="zoom:33%;">

<p>我们可以做个简单测试：将数据读入之后直接打印到控制台，将输出的并行度设置为2，中间经历一次shuffle。执行多次，观察结果是否相同。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PartitionDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        env.setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;String&gt; socketDS = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//shuffle随机分区：random.nextInt（下游算子并行度）</span></span><br><span class="line">        socketDS.shuffle().print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2&gt; 2</span><br><span class="line">1&gt; 22</span><br><span class="line">2&gt; 11</span><br><span class="line">1&gt; 332</span><br><span class="line">2&gt; 1</span><br><span class="line">2&gt; 232</span><br><span class="line">1&gt; 44</span><br></pre></td></tr></table></figure>

<h4 id="（2）轮询分区（Round-Robin）"><a href="#（2）轮询分区（Round-Robin）" class="headerlink" title="（2）轮询分区（Round-Robin）"></a>（2）轮询分区（Round-Robin）</h4><p>轮询，简单来说就是“发牌”，按照先后顺序将数据做依次分发。通过调用DataStream的.rebalance()方法，就可以实现轮询重分区。rebalance使用的是Round-Robin负载均衡算法，可以将输入流数据平均分配到下游的并行任务中去。</p>
<img src="Snipaste_2024-07-17_14-08-10.png" alt="Snipaste_2024-07-17_14-08-10" style="zoom:33%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//rebalance轮询:nextChannelToSendTO = (nextChannelToSendTo + ) % 下游算子并行度</span></span><br><span class="line"><span class="comment">//如果是数据源倾斜的场景，source读进来之后，调用rebalance，就可以解决 数据源的 数据倾斜</span></span><br><span class="line">socketDS.rebalance().print();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1&gt; 2</span><br><span class="line">2&gt; 2</span><br><span class="line">1&gt; 2</span><br><span class="line">2&gt; 2</span><br><span class="line">1&gt; 2</span><br><span class="line">2&gt; 2</span><br><span class="line">1&gt; 2</span><br></pre></td></tr></table></figure>

<h4 id="（3）重缩放分区（rescale）"><a href="#（3）重缩放分区（rescale）" class="headerlink" title="（3）重缩放分区（rescale）"></a>（3）重缩放分区（rescale）</h4><p>重缩放分区和轮询分区非常相似。当调用rescale()方法时，其实底层也是使用Round-Robin算法进行轮询，但是只会将数据<strong>轮询发送到下游并行任务的一部分中</strong>。rescale的做法是分成小团体，发牌人<strong>只给自己团体内的所有人轮流发牌</strong>。</p>
<img src="Snipaste_2024-07-17_14-15-50.png" alt="Snipaste_2024-07-17_14-15-50" style="zoom:33%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//rescale重缩放轮询：实现轮询，局部组队，比rebalance更高效</span></span><br><span class="line">socketDS.rescale().print();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1&gt; a</span><br><span class="line">2&gt; b</span><br><span class="line">1&gt; c</span><br><span class="line">2&gt; d</span><br><span class="line">1&gt; d</span><br><span class="line">2&gt; d</span><br></pre></td></tr></table></figure>

<h4 id="（4）广播（breadcast）"><a href="#（4）广播（breadcast）" class="headerlink" title="（4）广播（breadcast）"></a>（4）广播（breadcast）</h4><p>这种方式其实不应该叫做“重分区”，因为经过广播之后，数据会在不同的分区都保留一份，可能进行重复处理。可以通过调用DataStream的broadcast()方法，将输入数据复制并发送到下游算子的所有并行任务中去。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//broadcast广播：发送给下游所有的子任务</span></span><br><span class="line">socketDS.broadcast().print();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">2&gt; a</span><br><span class="line">1&gt; a</span><br><span class="line">2&gt; 1</span><br><span class="line">1&gt; 1</span><br><span class="line">2&gt; 2</span><br><span class="line">1&gt; 2</span><br><span class="line">2&gt; 3</span><br><span class="line">1&gt; 3</span><br></pre></td></tr></table></figure>

<h4 id="（5）全局分区（global）"><a href="#（5）全局分区（global）" class="headerlink" title="（5）全局分区（global）"></a>（5）全局分区（global）</h4><p>全局分区也是一种特殊的分区方式。这种做法非常极端，通过调用.global()方法，会将所有的输入流数据都发送到下游算子的第一个并行子任务中去。这就相当于强行让下游任务并行度变成了1，所以使用这个操作需要非常谨慎，可能对程序造成很大的压力。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//global全局：全部发往第一个子任务</span></span><br><span class="line">socketDS.global().print();</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1&gt; 1</span><br><span class="line">1&gt; 2</span><br><span class="line">1&gt; 3</span><br><span class="line">1&gt; 4</span><br><span class="line">1&gt; 5</span><br><span class="line">1&gt; 6</span><br><span class="line">1&gt; 7</span><br></pre></td></tr></table></figure>

<h4 id="（6）自定义分区（Custom）"><a href="#（6）自定义分区（Custom）" class="headerlink" title="（6）自定义分区（Custom）"></a>（6）自定义分区（Custom）</h4><p>当Flink提供的所有分区策略都不能满足用户的需求时，我们可以通过使用partitionCustom()方法来自定义分区策略。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PartitionCustomDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        env.setParallelism(<span class="number">2</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; source = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//partitionCustom(),里面第一个参数是用户自定义的分区类逻辑，第二个参数是key值的计算逻辑</span></span><br><span class="line">        source.partitionCustom(<span class="keyword">new</span> <span class="title class_">MyPartitioner</span>(),v1 -&gt; v1).print();</span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span>&lt;String&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String key, <span class="type">int</span> numPartitions)</span> &#123;<span class="comment">//key就是每一条数据的key，numPartitioner为下游分区数</span></span><br><span class="line">        <span class="comment">//本方法实现的分区逻辑是将数据进行分区数取模分区</span></span><br><span class="line">        <span class="keyword">return</span> Integer.parseInt(key) % numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2&gt; 1</span><br><span class="line">1&gt; 2</span><br><span class="line">2&gt; 3</span><br><span class="line">1&gt; 4</span><br><span class="line">2&gt; 5</span><br><span class="line">1&gt; 6</span><br></pre></td></tr></table></figure>

<h3 id="5-3-5-分流"><a href="#5-3-5-分流" class="headerlink" title="5.3.5 分流"></a>5.3.5 分流</h3><p>所谓“分流”，就是将一条数据流拆分成完全独立的两条、甚至多条流。也就是基于一个DataStream，定义一些筛选条件，将符合条件的数据拣选出来放到对应的流里。</p>
<img src="Snipaste_2024-07-17_21-25-24.png" alt="Snipaste_2024-07-17_21-25-24" style="zoom: 50%;">

<h4 id="（1）简单实现"><a href="#（1）简单实现" class="headerlink" title="（1）简单实现"></a>（1）简单实现</h4><p>其实根据条件筛选数据的需求，本身非常容易实现：只要针对同一条流多次独立调用.filter()方法进行筛选，就可以得到拆分之后的流了。</p>
<p>案例需求：读取一个整数数字流，将数据流划分为奇数流和偶数流。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SplitFlowByFilterDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;String&gt; socketDS = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 使用filter来实现</span></span><br><span class="line">         <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 缺点：同一个数据，要处理两遍（调用两次filter）</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        socketDS.filter(v1 -&gt; Integer.parseInt(v1) % <span class="number">2</span> == <span class="number">0</span>).print(<span class="string">&quot;偶数流&quot;</span>);</span><br><span class="line">        socketDS.filter(v1 -&gt; Integer.parseInt(v1) % <span class="number">2</span> == <span class="number">1</span>).print(<span class="string">&quot;奇数流&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">奇数流:1&gt; 3</span><br><span class="line">奇数流:2&gt; 5</span><br><span class="line">偶数流:2&gt; 6</span><br><span class="line">偶数流:1&gt; 8</span><br><span class="line">奇数流:1&gt; 99</span><br></pre></td></tr></table></figure>

<h4 id="（2）使用侧输出流"><a href="#（2）使用侧输出流" class="headerlink" title="（2）使用侧输出流"></a>（2）使用侧输出流</h4><p>简单来说，只需要调用上下文ctx的.output()方法，就可以输出任意类型的数据了。而侧输出流的标记和提取，都离不开一个“输出标签”（OutputTag），指定了侧输出流的id和类型。</p>
<p>代码实现：将WaterSensor按照Id类型进行分流。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SideOutputDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; source = env.socketTextStream(<span class="string">&quot;hadoop102&quot;</span>, <span class="number">7777</span>);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;WaterSensor&gt; MapSource = source.map(<span class="keyword">new</span> <span class="title class_">WaterSensorMapFunction</span>());</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * TODO 使用侧输出流 实现分流</span></span><br><span class="line"><span class="comment">         * 需求：watersensor的数据，按照id值进行分流</span></span><br><span class="line"><span class="comment">         * 补充知识点：这里使用了process算子，这属于底层API，前面的map、filter算子属于datastream api算子</span></span><br><span class="line"><span class="comment">         * ProcessFunction&lt;,&gt; 第一个泛型是输入数据的类型，第二个泛型是主流的数据类型</span></span><br><span class="line"><span class="comment">         * </span></span><br><span class="line"><span class="comment">         * </span></span><br><span class="line"><span class="comment">         * 总结步骤：</span></span><br><span class="line"><span class="comment">         *      1.使用process算子</span></span><br><span class="line"><span class="comment">         *      2.定义OutputTag对象</span></span><br><span class="line"><span class="comment">         *      3.调用ctx.output</span></span><br><span class="line"><span class="comment">         *      4.通过主流获取侧流</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//创建OutputTag对象，第一个参数是标签名，第二个参数是放入侧输出流中的数据的类型，Typeinformation</span></span><br><span class="line">        OutputTag&lt;WaterSensor&gt; sensor_1Tag = <span class="keyword">new</span> <span class="title class_">OutputTag</span>&lt;&gt;(<span class="string">&quot;sensor_1&quot;</span>, Types.POJO(WaterSensor.class));</span><br><span class="line"></span><br><span class="line">        OutputTag&lt;WaterSensor&gt; sensor_2Tag = <span class="keyword">new</span> <span class="title class_">OutputTag</span>&lt;&gt;(<span class="string">&quot;sensor_2&quot;</span>, Types.POJO(WaterSensor.class));</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;WaterSensor&gt; process = MapSource.process(<span class="keyword">new</span> <span class="title class_">ProcessFunction</span>&lt;WaterSensor, WaterSensor&gt;() &#123;</span><br><span class="line">            <span class="comment">/**</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> value 输入值.</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> ctx A &#123;<span class="doctag">@link</span> Context&#125;允许查询元素的时间戳，并获得 a &#123;<span class="doctag">@link</span> TimerService&#125;用于注册计时器和查询时间.</span></span><br><span class="line"><span class="comment">             *            上下文仅在调用此方法期间有效，不要存储它。</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@param</span> out 用于返回结果值的收集器.（即主流数据）</span></span><br><span class="line"><span class="comment">             * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(WaterSensor value, ProcessFunction&lt;WaterSensor, WaterSensor&gt;.Context ctx, Collector&lt;WaterSensor&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> value.getId();</span><br><span class="line">                <span class="keyword">if</span> (<span class="string">&quot;sensor_1&quot;</span>.equals(id)) &#123;</span><br><span class="line">                    <span class="comment">//如果是sensor_1放到侧输出流sensor_1中</span></span><br><span class="line">                    <span class="comment">//output()函数是处理支流数据的，第一个参数是支流标签对象，需要new一个OutputTag对象；第二个参数是放入该支流的数据，可以直接放value，也可以进行简单的数据处理</span></span><br><span class="line">                    ctx.output(sensor_1Tag, value);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;sensor_2&quot;</span>.equals(id)) &#123;</span><br><span class="line">                    <span class="comment">//如果是sensor_2放到侧输出流sensor_2中</span></span><br><span class="line">                    ctx.output(sensor_2Tag, value);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//非sensor_1、sensor_2的数据，放到主流中</span></span><br><span class="line">                    out.collect(value);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//直接打印出来的数据是主流数据</span></span><br><span class="line">        process.print(<span class="string">&quot;主流非sensor_1,sensor_2&quot;</span>);</span><br><span class="line">        <span class="comment">//从主流中，根据标签获取侧输出流</span></span><br><span class="line">        process.getSideOutput(sensor_1Tag).print(<span class="string">&quot;测流sensor_1&quot;</span>);</span><br><span class="line">        process.getSideOutput(sensor_2Tag).print(<span class="string">&quot;测流sensor_2&quot;</span>);</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在7777端口输入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sensor_1,22,33</span><br><span class="line">sensor_2,22,45</span><br><span class="line">sensor_4,33,89</span><br></pre></td></tr></table></figure>

<p>控制台输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">测流sensor_1&gt; WaterSensor&#123;id=&#x27;sensor_1&#x27;, ts=22, vc=33&#125;</span><br><span class="line">测流sensor_2&gt; WaterSensor&#123;id=&#x27;sensor_2&#x27;, ts=22, vc=45&#125;</span><br><span class="line">主流非sensor_1,sensor_2&gt; WaterSensor&#123;id=&#x27;sensor_4&#x27;, ts=33, vc=89&#125;</span><br></pre></td></tr></table></figure>

<h3 id="5-3-6-基本合流操作"><a href="#5-3-6-基本合流操作" class="headerlink" title="5.3.6 基本合流操作"></a>5.3.6 基本合流操作</h3><p>在实际应用中，我们经常会遇到来源不同的多条流，需要将它们的数据进行联合处理。所以Flink中合流的操作会更加普遍，对应的API也更加丰富。</p>
<h4 id="（1）联合（Union）"><a href="#（1）联合（Union）" class="headerlink" title="（1）联合（Union）"></a>（1）联合（Union）</h4><p>最简单的合流操作，就是直接将多条流合在一起，叫作流的“联合”（union）。联合操作要求必须流中的数据类型必须相同，合并之后的新流会包括所有流中的元素，数据类型不变。</p>
<img src="Snipaste_2024-07-20_11-19-11.png" alt="Snipaste_2024-07-20_11-19-11" style="zoom:33%;">

<p>在代码中，我们只要基于DataStream直接调用.union()方法，传入其他DataStream作为参数，就可以实现流的联合了；得到的依然是一个DataStream：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream1.union(stream2, stream3, ...)</span><br></pre></td></tr></table></figure>

<p>注意：union()的参数可以是多个DataStream，所以联合操作可以实现多条流的合并。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UnionDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;Integer&gt; source1 = env.fromElements(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">        DataStreamSource&lt;Integer&gt; source2 = env.fromElements(<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; source3 = env.fromElements(<span class="string">&quot;111&quot;</span>, <span class="string">&quot;222&quot;</span>, <span class="string">&quot;333&quot;</span>, <span class="string">&quot;444&quot;</span>,<span class="string">&quot;555&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * TODO union:合并数据流</span></span><br><span class="line"><span class="comment">         * 1. 流的数据类型必须一致</span></span><br><span class="line"><span class="comment">         * 2. 一次可以合并多条流</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        DataStream&lt;Integer&gt; union = source1.union(source2).union(source3.map(v1 -&gt; Integer.valueOf(v1)));</span><br><span class="line">        union.print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">111</span><br><span class="line">222</span><br><span class="line">333</span><br><span class="line">444</span><br><span class="line">555</span><br><span class="line">11</span><br><span class="line">22</span><br><span class="line">33</span><br><span class="line">44</span><br><span class="line">55</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td></tr></table></figure>

<h4 id="（2）连接（Connect）"><a href="#（2）连接（Connect）" class="headerlink" title="（2）连接（Connect）"></a>（2）连接（Connect）</h4><p>流的联合虽然简单，不过受限于数据类型不能改变，灵活性大打折扣，所以实际应用较少出现。除了联合（union），Flink还提供了另外一种方便的合流操作——连接（connect）。</p>
<h5 id="连接流（ConnectedStreams）"><a href="#连接流（ConnectedStreams）" class="headerlink" title="连接流（ConnectedStreams）"></a>连接流（ConnectedStreams）</h5><p><img src="Snipaste_2024-07-20_13-59-00.png" alt="Snipaste_2024-07-20_13-59-00"></p>
<p>代码实现：需要分为两步：首先基于一条DataStream调用.connect()方法，传入另外一条DataStream作为参数，将两条流连接起来，得到一个ConnectedStreams；然后再调用同处理方法得到DataStream。这里可以的调用的同处理方法有.map()&#x2F;.flatMap()，以及.process()方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConnectDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;Integer&gt; source1 = env.fromElements(<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>, <span class="number">55</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; source2 = env.fromElements(<span class="string">&quot;Sjj&quot;</span>, <span class="string">&quot;Whh&quot;</span>, <span class="string">&quot;Ihh&quot;</span>, <span class="string">&quot;Phh&quot;</span>,<span class="string">&quot;Rj&quot;</span>);</span><br><span class="line"></span><br><span class="line">        ConnectedStreams&lt;Integer, String&gt; connect = source1.connect(source2);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 对ConnectedStreams调用map方法重写的是CoMapFunction接口匿名类，</span></span><br><span class="line"><span class="comment">         *   其中第一个泛型是数据流1的类型，第二个泛型是数据流2的泛型，第三个泛型是输出数据的类型</span></span><br><span class="line"><span class="comment">         *   调用map后返回的类型变为SingleOutputStreamOperator</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        SingleOutputStreamOperator&lt;String&gt; result = connect.map(<span class="keyword">new</span> <span class="title class_">CoMapFunction</span>&lt;Integer, String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">map1</span><span class="params">(Integer value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> value * <span class="number">2</span> + <span class="string">&quot;&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">map2</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        result.print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">22</span><br><span class="line">Sjj</span><br><span class="line">44</span><br><span class="line">Whh</span><br><span class="line">66</span><br><span class="line">Ihh</span><br><span class="line">88</span><br><span class="line">Phh</span><br><span class="line">110</span><br><span class="line">Rj</span><br></pre></td></tr></table></figure>

<p>上面的代码中，ConnectedStreams有两个类型参数，分别表示内部包含的两条流各自的数据类型；由于需要“一国两制”，因此调用.map()方法时传入的不再是一个简单的MapFunction，而是一个<strong>CoMapFunction</strong>，表示分别对两条流中的数据执行map操作。这个接口有三个类型参数，依次表示第一条流、第二条流，以及合并后的流中的数据类型。需要实现的方法也非常直白：**.map1()就是对第一条流中数据的map操作，.map2()则是针对第二条流。**</p>
<h5 id="CoProcessFunction"><a href="#CoProcessFunction" class="headerlink" title="CoProcessFunction"></a>CoProcessFunction</h5><p>与CoMapFunction类似，如果是调用.map()就需要传入一个CoMapFunction，需要实现map1()、map2()两个方法；而调用.process()时，传入的则是一个CoProcessFunction。它也是“处理函数”家族中的一员，用法非常相似。它需要实现的就是processElement1()、processElement2()两个方法，在每个数据到来时，会根据来源的流调用其中的一个方法进行处理。</p>
<p>值得一提的是，ConnectedStreams也可以直接调用.keyBy()进行按键分区的操作，得到的还是一个ConnectedStreams：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">connectedStreams.keyBy(keySelector1, keySelector2);</span><br></pre></td></tr></table></figure>

<p>这里传入两个参数keySelector1和keySelector2，是两条流中各自的键选择器；当然也可以直接传入键的位置值（keyPosition），或者键的字段名（field），这与普通的keyBy用法完全一致。ConnectedStreams进行keyBy操作，其实就是把两条流中key相同的数据放到了一起，然后针对来源的流再做各自处理，这在一些场景下非常有用。</p>
<p>案例需求：连接两条流，输出能根据id匹配上的数据（类似inner join效果）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConnectKeyByDemo1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        DataStreamSource&lt;Tuple2&lt;Integer, String&gt;&gt; source1 = env.fromElements(</span><br><span class="line">                Tuple2.of(<span class="number">1</span>, <span class="string">&quot;a1&quot;</span>),</span><br><span class="line">                Tuple2.of(<span class="number">1</span>, <span class="string">&quot;a2&quot;</span>),</span><br><span class="line">                Tuple2.of(<span class="number">2</span>, <span class="string">&quot;b&quot;</span>),</span><br><span class="line">                Tuple2.of(<span class="number">3</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        DataStreamSource&lt;Tuple3&lt;Integer, String, Integer&gt;&gt; source2 = env.fromElements(</span><br><span class="line">                Tuple3.of(<span class="number">1</span>, <span class="string">&quot;aa1&quot;</span>, <span class="number">1</span>),</span><br><span class="line">                Tuple3.of(<span class="number">1</span>, <span class="string">&quot;aa2&quot;</span>, <span class="number">2</span>),</span><br><span class="line">                Tuple3.of(<span class="number">2</span>, <span class="string">&quot;bb&quot;</span>, <span class="number">1</span>),</span><br><span class="line">                Tuple3.of(<span class="number">3</span>, <span class="string">&quot;cc&quot;</span>, <span class="number">1</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        ConnectedStreams&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;&gt; connect = source1.connect(source2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 多并行度下，需要根据 关联条件进行 keyby，才能保证 key相同的数据到一起去，才能匹配上</span></span><br><span class="line">        ConnectedStreams&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;&gt; connectKeyby = connect.keyBy(s1 -&gt; s1.f0, s2 -&gt; s2.f0);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 实现互相匹配的效果：  两条流，，不一定谁的数据先来</span></span><br><span class="line"><span class="comment">         *  1、每条流，有数据来，存到一个变量中</span></span><br><span class="line"><span class="comment">         *      hashmap</span></span><br><span class="line"><span class="comment">         *      =》key=id，第一个字段值</span></span><br><span class="line"><span class="comment">         *      =》value=List&lt;数据&gt;</span></span><br><span class="line"><span class="comment">         *  2、每条流有数据来的时候，除了存变量中， 不知道对方是否有匹配的数据，要去另一条流存的变量中 查找是否有匹配上的</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        SingleOutputStreamOperator&lt;String&gt; process = connectKeyby.process(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">CoProcessFunction</span>&lt;Tuple2&lt;Integer, String&gt;, Tuple3&lt;Integer, String, Integer&gt;, String&gt;() &#123;</span><br><span class="line">                    <span class="comment">// 每条流定义一个hashmap，用来存数据</span></span><br><span class="line">                    Map&lt;Integer, List&lt;Tuple2&lt;Integer, String&gt;&gt;&gt; s1Cache = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">                    Map&lt;Integer, List&lt;Tuple3&lt;Integer, String, Integer&gt;&gt;&gt; s2Cache = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                    <span class="comment">/**</span></span><br><span class="line"><span class="comment">                     * 第一条流的处理逻辑</span></span><br><span class="line"><span class="comment">                     * <span class="doctag">@param</span> value 第一条流的数据</span></span><br><span class="line"><span class="comment">                     * <span class="doctag">@param</span> ctx   上下文</span></span><br><span class="line"><span class="comment">                     * <span class="doctag">@param</span> out   采集器</span></span><br><span class="line"><span class="comment">                     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement1</span><span class="params">(Tuple2&lt;Integer, String&gt; value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                        <span class="type">Integer</span> <span class="variable">id</span> <span class="operator">=</span> value.f0;</span><br><span class="line">                        <span class="comment">// TODO 1. s1的数据来了，就存到变量中</span></span><br><span class="line">                        <span class="keyword">if</span> (!s1Cache.containsKey(id)) &#123;</span><br><span class="line">                            <span class="comment">// 1.1 如果key不存在，说明是该key的第一条数据，初始化，put进map中</span></span><br><span class="line">                            List&lt;Tuple2&lt;Integer, String&gt;&gt; s1Values = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                            s1Values.add(value);</span><br><span class="line">                            s1Cache.put(id, s1Values);</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="comment">// 1.2 key存在，不是该key的第一条数据，直接添加到 value的list中</span></span><br><span class="line">                            s1Cache.get(id).add(value);</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// TODO 2.去 s2Cache中查找是否有id能匹配上的,匹配上就输出，没有就不输出</span></span><br><span class="line">                        <span class="keyword">if</span> (s2Cache.containsKey(id)) &#123;</span><br><span class="line">                            <span class="keyword">for</span> (Tuple3&lt;Integer, String, Integer&gt; s2Element : s2Cache.get(id)) &#123;</span><br><span class="line">                                out.collect(<span class="string">&quot;s1:&quot;</span> + value + <span class="string">&quot;&lt;========&gt;&quot;</span> + <span class="string">&quot;s2:&quot;</span> + s2Element);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">/**</span></span><br><span class="line"><span class="comment">                     * 第二条流的处理逻辑</span></span><br><span class="line"><span class="comment">                     * <span class="doctag">@param</span> value 第二条流的数据</span></span><br><span class="line"><span class="comment">                     * <span class="doctag">@param</span> ctx   上下文</span></span><br><span class="line"><span class="comment">                     * <span class="doctag">@param</span> out   采集器</span></span><br><span class="line"><span class="comment">                     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">                     */</span></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement2</span><span class="params">(Tuple3&lt;Integer, String, Integer&gt; value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                        <span class="type">Integer</span> <span class="variable">id</span> <span class="operator">=</span> value.f0;</span><br><span class="line">                        <span class="comment">// TODO 1. s2的数据来了，就存到变量中</span></span><br><span class="line">                        <span class="keyword">if</span> (!s2Cache.containsKey(id)) &#123;</span><br><span class="line">                            <span class="comment">// 1.1 如果key不存在，说明是该key的第一条数据，初始化，put进map中</span></span><br><span class="line">                            List&lt;Tuple3&lt;Integer, String, Integer&gt;&gt; s2Values = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                            s2Values.add(value);</span><br><span class="line">                            s2Cache.put(id, s2Values);</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="comment">// 1.2 key存在，不是该key的第一条数据，直接添加到 value的list中</span></span><br><span class="line">                            s2Cache.get(id).add(value);</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// TODO 2.去 s1Cache中查找是否有id能匹配上的,匹配上就输出，没有就不输出</span></span><br><span class="line">                        <span class="keyword">if</span> (s1Cache.containsKey(id)) &#123;</span><br><span class="line">                            <span class="keyword">for</span> (Tuple2&lt;Integer, String&gt; s1Element : s1Cache.get(id)) &#123;</span><br><span class="line">                                out.collect(<span class="string">&quot;s1:&quot;</span> + s1Element + <span class="string">&quot;&lt;========&gt;&quot;</span> + <span class="string">&quot;s2:&quot;</span> + value);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        process.print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">2&gt; s1:(1,a1)&lt;========&gt;s2:(1,aa1,1)</span><br><span class="line">2&gt; s1:(1,a1)&lt;========&gt;s2:(1,aa2,2)</span><br><span class="line">2&gt; s1:(1,a2)&lt;========&gt;s2:(1,aa1,1)</span><br><span class="line">2&gt; s1:(1,a2)&lt;========&gt;s2:(1,aa2,2)</span><br><span class="line">2&gt; s1:(2,b)&lt;========&gt;s2:(2,bb,1)</span><br><span class="line">2&gt; s1:(3,c)&lt;========&gt;s2:(3,cc,1)</span><br></pre></td></tr></table></figure>

<h2 id="5-4-输出算子（Sink）"><a href="#5-4-输出算子（Sink）" class="headerlink" title="5.4 输出算子（Sink）"></a>5.4 输出算子（Sink）</h2><p>Flink作为数据处理框架，最终还是要把计算处理的结果写入外部存储，为外部应用提供支持。</p>
<h3 id="5-4-1-连接到外部系统"><a href="#5-4-1-连接到外部系统" class="headerlink" title="5.4.1 连接到外部系统"></a>5.4.1 连接到外部系统</h3><p>Flink的DataStream API专门提供了向外部写入数据的方法：addSink。与addSource类似，addSink方法对应着一个“Sink”算子，主要就是用来实现与外部系统连接、并将数据提交写入的；Flink程序中所有对外的输出操作，一般都是利用Sink算子完成的。</p>
<p>目前，Sink算子的创建是通过调用DataStream的.sinkTo()方法实现的</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream.sinkTo(…)</span><br></pre></td></tr></table></figure>

<p>当然，Sink多数情况下同样并不需要我们自己实现。之前我们一直在使用的print方法其实就是一种Sink，它表示将数据流写入标准控制台打印输出。Flink官方为我们提供了一部分的框架的Sink连接器。</p>
<h3 id="5-4-2-输出到文件"><a href="#5-4-2-输出到文件" class="headerlink" title="5.4.2 输出到文件"></a>5.4.2 输出到文件</h3><p>Flink专门提供了一个流式文件系统的连接器：FileSink，为批处理和流处理提供了一个统一的Sink，它可以将分区文件写入Flink支持的文件系统。</p>
<p>FileSink支持行编码（Row-encoded）和批量编码（Bulk-encoded）格式。这两种不同的方式都有各自的构建器（builder），可以直接调用FileSink的静态方法：</p>
<ul>
<li>行编码： FileSink.forRowFormat（basePath，rowEncoder）。</li>
<li>批量编码： FileSink.forBulkFormat（basePath，bulkWriterFactory）。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SinkFile</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//必须开启checkpoint，否则一直都是.inprogress</span></span><br><span class="line">        env.enableCheckpointing(<span class="number">2000</span>, CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 数据生成器Source，四个参数</span></span><br><span class="line"><span class="comment">         *     第一个参数：GeneratorFunction接口，需要实现重写map方法，输入类型固定是Long</span></span><br><span class="line"><span class="comment">         *     第二个参数：long类型，自动生成的数字序列（从1自增）的最大值，达到这个值就停止了</span></span><br><span class="line"><span class="comment">         *     第三个参数：限速策略，比如每秒生成几条数据</span></span><br><span class="line"><span class="comment">         *     第四个参数：返回的类型</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        DataGeneratorSource&lt;String&gt; dataGeneratorSource = <span class="keyword">new</span> <span class="title class_">DataGeneratorSource</span>&lt;&gt;(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">GeneratorFunction</span>&lt;Long, String&gt;() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="keyword">public</span> String <span class="title function_">map</span><span class="params">(Long value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                        <span class="keyword">return</span> <span class="string">&quot;Number:&quot;</span> + value;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="number">100</span>,</span><br><span class="line">                RateLimiterStrategy.perSecond(<span class="number">5</span>),</span><br><span class="line">                Types.STRING</span><br><span class="line">        );</span><br><span class="line">        DataStreamSource&lt;String&gt; dataGenerator = env.fromSource(dataGeneratorSource, WatermarkStrategy.noWatermarks(), <span class="string">&quot;DataGenerator&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 输出到文件系统</span></span><br><span class="line">        FileSink&lt;String&gt; fileSink = FileSink</span><br><span class="line">                <span class="comment">//输出行式存储的文件，指定路径、指定编码</span></span><br><span class="line">                .&lt;String&gt;forRowFormat(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;e:/flink_tmp&quot;</span>), <span class="keyword">new</span> <span class="title class_">SimpleStringEncoder</span>&lt;&gt;(<span class="string">&quot;UTF-8&quot;</span>))</span><br><span class="line">                <span class="comment">//输出文件的一些配置：文件名的前缀、后缀</span></span><br><span class="line">                .withOutputFileConfig(OutputFileConfig.builder()</span><br><span class="line">                        .withPartPrefix(<span class="string">&quot;atguigu-&quot;</span>)</span><br><span class="line">                        .withPartSuffix(<span class="string">&quot;.log&quot;</span>)</span><br><span class="line">                        .build()</span><br><span class="line">                )</span><br><span class="line">                <span class="comment">//按照目录分桶：如下就是每一个小时每个目录</span></span><br><span class="line">                .withBucketAssigner(<span class="keyword">new</span> <span class="title class_">DateTimeBucketAssigner</span>&lt;&gt;(<span class="string">&quot;yyyy-MM-dd HH&quot;</span>, ZoneId.systemDefault()))</span><br><span class="line">                <span class="comment">//文件滚动策略：1分钟或1kb</span></span><br><span class="line">                .withRollingPolicy(DefaultRollingPolicy.builder()</span><br><span class="line">                        .withRolloverInterval(Duration.ofMinutes(<span class="number">1</span>))</span><br><span class="line">                        .withMaxPartSize(<span class="keyword">new</span> <span class="title class_">MemorySize</span>(<span class="number">1024</span>))</span><br><span class="line">                        .build()</span><br><span class="line">                ).build();</span><br><span class="line"></span><br><span class="line">        dataGenerator.sinkTo(fileSink);</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-07-21_15-36-45.png" alt="Snipaste_2024-07-21_15-36-45"></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2024/06/27/Flink%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-spark框架学习笔记" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/05/25/spark%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">spark框架学习笔记</a>
    </h1>
  

        
        <a href="/2024/05/25/spark%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="archive-article-date">
  	<time datetime="2024-05-25T14:26:31.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2024-05-25</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一章-Spark概述"><a href="#第一章-Spark概述" class="headerlink" title="第一章 Spark概述"></a>第一章 Spark概述</h1><h2 id="1-1-Spark基础概念介绍"><a href="#1-1-Spark基础概念介绍" class="headerlink" title="1.1 Spark基础概念介绍"></a>1.1 Spark基础概念介绍</h2><h3 id="1-1-1-Spark模式"><a href="#1-1-1-Spark模式" class="headerlink" title="1.1.1 Spark模式"></a>1.1.1 Spark模式</h3><p>Spark是一种基于<strong>内存</strong>的快速、通用、可扩展的大数据分析计算引擎。Spark是基于MR开发的。有以下三种模式：</p>
<p>（1）<strong>单机</strong>：单进程，单节点（注意，单机不是指只有一台机器，仍然有很多台机器，只是在一个机器上只运行一个进程，只有一个节点；生产环境中不会使用，因为浪费资源）</p>
<p>（2）<strong>伪分布式</strong>：多进程，单节点（在一个机器上运行多个进程）</p>
<p>（3）<strong>分布式</strong>：多进程，多节点（生产环境中使用）</p>
<img src="Snipaste_2024-05-26_09-49-52.png" alt="Snipaste_2024-05-26_09-49-52" style="zoom:73%;">

<p>分布式（无论是分布式计算、分布式存储还是分布式消息传输）的核心是切分数据，减少数据规模</p>
<img src="Snipaste_2024-05-26_09-54-23.png" alt="Snipaste_2024-05-26_09-54-23" style="zoom:63%;">

<p>Driver：驱动器；Executor：执行器</p>
<h3 id="1-1-2-框架与系统"><a href="#1-1-2-框架与系统" class="headerlink" title="1.1.2 框架与系统"></a>1.1.2 框架与系统</h3><p><img src="Snipaste_2024-05-26_10-31-32.png" alt="Snipaste_2024-05-26_10-31-32"></p>
<h3 id="1-1-3-spark与MR的关系"><a href="#1-1-3-spark与MR的关系" class="headerlink" title="1.1.3 spark与MR的关系"></a>1.1.3 spark与MR的关系</h3><p><img src="Snipaste_2024-05-26_10-46-07.png" alt="Snipaste_2024-05-26_10-46-07"></p>
<p>spark为什么快？基于<strong>内存</strong>实现数据的流转</p>
<p>当内存资源很紧张的时候，spark程序可能跑不起来，而使用MR虽然慢，但是最终可以跑完。</p>
<p><img src="Snipaste_2024-05-26_13-37-34.png" alt="Snipaste_2024-05-26_13-37-34"></p>
<h2 id="1-2-Spark内置模块"><a href="#1-2-Spark内置模块" class="headerlink" title="1.2 Spark内置模块"></a>1.2 Spark内置模块</h2><p><img src="Snipaste_2024-05-26_13-51-55.png" alt="Snipaste_2024-05-26_13-51-55"></p>
<p><strong>Spark Core</strong>：实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集(Resilient Distributed DataSet，简称RDD)的API定义。 </p>
<p><strong>Spark SQL</strong>：是Spark用来操作结构化数据的程序包。通过Spark SQL，我们可以使用 SQL或者Apache Hive版本的HQL来查询数据。Spark SQL支持多种数据源，比如Hive表、Parquet以及JSON等。</p>
<p><strong>Spark Streaming</strong>：是Spark提供的对实时数据进行流式计算的组件。提供了用来操作数据流的API，并且与Spark Core中的 RDD API高度对应。 </p>
<p><strong>Spark MLlib</strong>：提供常见的机器学习功能的程序库。包括分类、回归、聚类、协同过滤等，还提供了模型评估、数据 导入等额外的支持功能。 </p>
<p><strong>Spark GraphX</strong>：主要用于图形并行计算和图挖掘系统的组件。</p>
<p><strong>集群管理器</strong>：Spark设计为可以高效地在一个计算节点到数千个计算节点之间伸缩计算。为了实现这样的要求，同时获得最大灵活性，Spark支持在各种集群管理器（Cluster Manager）上运行，包括Hadoop YARN、Apache Mesos，以及Spark自带的一个简易调度器，叫作独立调度器。</p>
<h2 id="1-3-Spark特点"><a href="#1-3-Spark特点" class="headerlink" title="1.3 Spark特点"></a>1.3 Spark特点</h2><p><img src="Snipaste_2024-05-26_14-24-34.png" alt="Snipaste_2024-05-26_14-24-34"></p>
<h1 id="第二章-Spark的运行模式"><a href="#第二章-Spark的运行模式" class="headerlink" title="第二章 Spark的运行模式"></a>第二章 Spark的运行模式</h1><p><img src="Snipaste_2024-05-26_14-40-47.png" alt="Snipaste_2024-05-26_14-40-47"></p>
<p>部署Spark集群大体上分为两种模式：<em><strong>*单机模式与集群模式*</strong></em></p>
<p>大多数分布式框架都支持单机模式，方便开发者调试框架的运行环境。但是在生产环境中，并不会使用单机模式。因此，后续直接按照集群模式部署Spark集群。</p>
<p>下面详细列举了Spark目前支持的部署模式。</p>
<p>（1）<strong>Local模式：</strong>在本地部署单个Spark服务</p>
<p>（2）<strong>Standalone模式</strong>：Spark自带的任务调度模式。（国内不常用）</p>
<p>（3）<strong>YARN模式</strong>：Spark使用Hadoop的YARN组件进行资源与任务调度。（国内最常用）</p>
<p>（4）<strong>Mesos模式</strong>：Spark使用Mesos平台进行资源与任务的调度。（国内很少用）</p>
<img src="Snipaste_2024-05-26_14-44-35.png" alt="Snipaste_2024-05-26_14-44-35" style="zoom: 80%;">

<h2 id="2-1-Spark安装地址"><a href="#2-1-Spark安装地址" class="headerlink" title="2.1 Spark安装地址"></a>2.1 Spark安装地址</h2><p>1）官网地址：<a target="_blank" rel="noopener" href="http://spark.apache.org/">http://spark.apache.org/</a></p>
<p>2）文档查看地址：<a target="_blank" rel="noopener" href="https://spark.apache.org/docs/3.3.1/">https://spark.apache.org/docs/3.3.1/</a></p>
<p>3）下载地址：<a target="_blank" rel="noopener" href="https://spark.apache.org/downloads.html">https://spark.apache.org/downloads.html</a></p>
<p><a target="_blank" rel="noopener" href="https://archive.apache.org/dist/spark/">https://archive.apache.org/dist/spark/</a></p>
<h2 id="2-2-Local模式"><a href="#2-2-Local模式" class="headerlink" title="2.2 Local模式"></a>2.2 Local模式</h2><p>Local模式就是运行在一台计算机上的模式，通常就是用于在本机上练手和测试。</p>
<h3 id="2-2-1-安装使用"><a href="#2-2-1-安装使用" class="headerlink" title="2.2.1 安装使用"></a>2.2.1 安装使用</h3><p>（1）上传并解压Spark安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 software]# tar -zxvf spark-3.3.1-bin-hadoop3.tgz -C /opt/module/</span><br></pre></td></tr></table></figure>

<p>查看文件内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark-3.3.1-bin-hadoop3]# ll</span><br><span class="line">总用量 124</span><br><span class="line">drwxr-xr-x 2 110302528 wyh  4096 10月 15 2022 bin</span><br><span class="line">drwxr-xr-x 2 110302528 wyh   198 10月 15 2022 conf</span><br><span class="line">drwxr-xr-x 5 110302528 wyh    50 10月 15 2022 data</span><br><span class="line">drwxr-xr-x 4 110302528 wyh    29 10月 15 2022 examples</span><br><span class="line">drwxr-xr-x 2 110302528 wyh 12288 10月 15 2022 jars</span><br><span class="line">drwxr-xr-x 4 110302528 wyh    38 10月 15 2022 kubernetes</span><br><span class="line">-rw-r--r-- 1 110302528 wyh 22940 10月 15 2022 LICENSE</span><br><span class="line">drwxr-xr-x 2 110302528 wyh  4096 10月 15 2022 licenses</span><br><span class="line">-rw-r--r-- 1 110302528 wyh 57842 10月 15 2022 NOTICE</span><br><span class="line">drwxr-xr-x 9 110302528 wyh   311 10月 15 2022 python</span><br><span class="line">drwxr-xr-x 3 110302528 wyh    17 10月 15 2022 R</span><br><span class="line">-rw-r--r-- 1 110302528 wyh  4461 10月 15 2022 README.md</span><br><span class="line">-rw-r--r-- 1 110302528 wyh   165 10月 15 2022 RELEASE</span><br><span class="line">drwxr-xr-x 2 110302528 wyh  4096 10月 15 2022 sbin</span><br><span class="line">drwxr-xr-x 2 110302528 wyh    42 10月 15 2022 yarn</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin：binary二进制文件，即一些.sh脚本文件和.cmd可执行命令</span><br><span class="line">conf：配置文件</span><br><span class="line">data：数据文件，分为mllib，streaming，graphX的示例训练计算数据</span><br><span class="line">examples：官方的案例jar包和源码</span><br><span class="line">jars：spark运行所依赖的所有jar包</span><br><span class="line">sbin：以‘s’开头的可执行命令，比如start，stop等</span><br></pre></td></tr></table></figure>

<p>修改文件名：</p>
<p>（这里之所以修改成spark是因为我们已经将SPARK_HOME设置为了spark，详见vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 module]# mv spark-3.3.1-bin-hadoop3/ spark</span><br></pre></td></tr></table></figure>

<p>（2）官方求PI案例</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# bin/spark-submit --class org.apache.spark.examples.SparkPi --master local[2] ./examples/jars/spark-examples_2.12-3.3.1.jar 10</span><br></pre></td></tr></table></figure>

<p>解释：执行bin文件下的spark-submit脚本，该脚本的参数如下：</p>
<p>① –class：表示要执行程序的主类；</p>
<p>② –master local[2]</p>
<blockquote>
<p>local: 没有指定线程数，则所有计算都运行在一个线程当中，没有任何并行计算</p>
<p>local[K]:指定使用K个Core来运行计算，比如local[2]就是运行2个Core来执行</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">20/09/20 09:30:53 INFO TaskSetManager:</span><br><span class="line">20/09/15 10:15:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)</span><br><span class="line">20/09/15 10:15:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>local[*]：默认模式。自动帮你按照CPU最多核来设置线程数。比如CPU有8核，Spark帮你自动设置8个线程计算。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">20/09/20 09:30:53 INFO TaskSetManager:</span><br><span class="line">20/09/15 10:15:58 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)</span><br><span class="line">20/09/15 10:15:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)</span><br><span class="line">20/09/15 10:15:58 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)</span><br><span class="line">20/09/15 10:15:58 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)</span><br><span class="line">20/09/15 10:15:58 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)</span><br><span class="line">20/09/15 10:15:58 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)</span><br><span class="line">20/09/15 10:15:59 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)</span><br><span class="line">20/09/15 10:15:59 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)</span><br></pre></td></tr></table></figure>

<p>③ spark-examples_2.12-3.3.1.jar：要运行的程序；</p>
<p>④ 10：要运行程序的输入参数（计算圆周率π的次数，计算次数越多，准确率越高）；</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pi is roughly 3.1433551433551434</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong>如果不知道jar中具体的类名情况，可以使用jar tf <jarfile>命令查看</jarfile></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# jar tf examples/jars/spark-examples_2.12-3.3.1.jar </span><br><span class="line">META-INF/</span><br><span class="line">META-INF/MANIFEST.MF</span><br><span class="line">META-INF/DEPENDENCIES</span><br><span class="line">employees.json</span><br><span class="line">org/</span><br><span class="line">org/apache/</span><br><span class="line">org/apache/spark/</span><br><span class="line">org/apache/spark/examples/</span><br><span class="line">org/apache/spark/examples/DFSReadWriteTest.class</span><br><span class="line">org/apache/spark/examples/HdfsTest.class</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/LocalKMeans$</span><span class="language-bash">.class</span></span><br><span class="line">org/apache/spark/examples/LocalPi.class</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/MiniReadWriteTest$</span><span class="language-bash">$anon<span class="variable">$1</span>.class</span></span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/SparkHdfsLR$</span><span class="language-bash">.class</span></span><br><span class="line">org/apache/spark/examples/SparkLR.class</span><br><span class="line">org/apache/spark/examples/SparkRemoteFileTest.class</span><br><span class="line">org/apache/spark/examples/graphx/</span><br><span class="line">org/apache/spark/examples/graphx/ComprehensiveExample.class</span><br><span class="line">org/apache/spark/examples/graphx/PageRankExample.class</span><br><span class="line">org/apache/spark/examples/ml/</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/ALSExample$</span><span class="language-bash">$typecreator5<span class="variable">$1</span>.class</span></span><br><span class="line">org/apache/spark/examples/ml/BinarizerExample.class</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/BucketizerExample$</span><span class="language-bash">.class</span></span><br><span class="line">......</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/SparkPi$</span><span class="language-bash">.class</span></span><br><span class="line">......</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/PowerIterationClusteringExample$</span><span class="language-bash">$typecreator1<span class="variable">$1</span>.class</span></span><br><span class="line">org/apache/spark/examples/ml/QuantileDiscretizerExample.class</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/RandomForestExample$</span><span class="language-bash">.class</span></span><br><span class="line">org/apache/spark/examples/ml/RobustScalerExample.class</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/StopWordsRemoverExample$</span><span class="language-bash">.class</span></span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/SummarizerExample$</span><span class="language-bash">$typecreator6<span class="variable">$1</span>.class</span></span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/TokenizerExample$</span><span class="language-bash">$typecreator1<span class="variable">$1</span>.class</span></span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/UnivariateFeatureSelectorExample$</span><span class="language-bash">$typecreator5<span class="variable">$1</span>.class</span></span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/ml/VectorAssemblerExample$</span><span class="language-bash">$typecreator1<span class="variable">$1</span>.class</span></span><br><span class="line">......</span><br><span class="line">org/apache/spark/examples/streaming/HdfsWordCount.class</span><br><span class="line">org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.class</span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/streaming/RawNetworkGrep$</span><span class="language-bash">.class</span></span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/streaming/SparkSessionSingleton$</span><span class="language-bash">.class</span></span><br><span class="line"><span class="meta prompt_">org/apache/spark/examples/streaming/WordExcludeList$</span><span class="language-bash">.class</span></span><br><span class="line">people.txt</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-05-28_17-15-30.png" alt="Snipaste_2024-05-28_17-15-30"></p>
<h3 id="2-2-2-查看任务运行详情"><a href="#2-2-2-查看任务运行详情" class="headerlink" title="2.2.2 查看任务运行详情"></a>2.2.2 查看任务运行详情</h3><p>（1）再次运行求PI任务，增加任务次数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# bin/spark-submit --class org.apache.spark.examples.SparkPi --master local[2] ./examples/jars/spark-examples_2.12-3.3.1.jar 1000</span><br></pre></td></tr></table></figure>

<p>（2）在任务运行期间，可登录<a href="http://hadoop102:4040查看程序运行结果">http://hadoop102:4040查看程序运行结果</a></p>
<p><img src="image-2024052817%E5%BE%97%E5%88%B02223628.png" alt="image-2024052817得到2223628"></p>
<h2 id="2-3-Yarn模式（重点）"><a href="#2-3-Yarn模式（重点）" class="headerlink" title="2.3 Yarn模式（重点）"></a>2.3 Yarn模式（重点）</h2><h3 id="2-3-1-安装使用"><a href="#2-3-1-安装使用" class="headerlink" title="2.3.1 安装使用"></a>2.3.1 安装使用</h3><p>（1）修改hadoop配置文件&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3&#x2F;etc&#x2F;hadoop&#x2F;yarn-site.xml</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 hadoop]# pwd</span><br><span class="line">/opt/module/hadoop-3.1.3/etc/hadoop</span><br><span class="line">[root@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）分发配置文件</p>
<p>（3）修改&#x2F;opt&#x2F;module&#x2F;spark&#x2F;conf&#x2F;spark-env.sh，添加YARN_CONF_DIR配置，保证后续运行任务的路径都变成集群路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# mv spark-env.sh.template spark-env.sh</span><br><span class="line">[root@hadoop102 conf]# vim spark-env.sh</span><br><span class="line">YARN_CONF_DIR=/opt/module/hadoop-3.1.3/etc/hadoop</span><br></pre></td></tr></table></figure>

<p>（4）启动hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# myhadoop.sh start</span><br></pre></td></tr></table></figure>

<p>（5）执行一个程序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn ./examples/jars/spark-examples_2.12-3.3.1.jar 10</span><br></pre></td></tr></table></figure>

<p>参数：–master yarn，表示Yarn方式运行；–deploy-mode表示客户端方式运行程序</p>
<p>执行成功！</p>
<p>执行该程序时，后台有4个进程，分别是SparkSubmit提交进程，ExecutorLauncher管理进程，两个YarnCoarseGrainedExecutorBackend作业进程，程序执行完毕后全都被kill掉并释放资源</p>
<p>查看<a target="_blank" rel="noopener" href="http://hadoop103:8088/cluster">All Applications</a>页面，点击History，查看历史页面</p>
<p><img src="Snipaste_2024-05-28_22-42-37.png" alt="Snipaste_2024-05-28_22-42-37"></p>
<p>点击logs，可查看作业运行日志</p>
<p><img src="Snipaste_2024-05-28_22-44-05.png" alt="Snipaste_2024-05-28_22-44-05"></p>
<h3 id="2-3-2-配置历史服务"><a href="#2-3-2-配置历史服务" class="headerlink" title="2.3.2 配置历史服务"></a>2.3.2 配置历史服务</h3><p>（1）修改spark-default.conf.template名称</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# mv spark-defaults.conf.template spark-defaults.conf</span><br></pre></td></tr></table></figure>

<p>（2）修改spark-default.conf文件，配置日志存储路径</p>
<p>先创建路径：</p>
<img src="Snipaste_2024-05-28_22-51-04.png" alt="Snipaste_2024-05-28_22-51-04" style="zoom: 33%;">

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim spark-defaults.conf </span><br><span class="line">spark.eventLog.enabled          true</span><br><span class="line">spark.eventLog.dir               hdfs://hadoop102:8020/directory</span><br></pre></td></tr></table></figure>

<p>（3）修改spark-env.sh文件，添加如下配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 conf]# vim spark-env.sh</span><br><span class="line">export SPARK_HISTORY_OPTS=&quot;</span><br><span class="line">-Dspark.history.ui.port=18080 </span><br><span class="line">-Dspark.history.fs.logDirectory=hdfs://hadoop102:8020/directory </span><br><span class="line">-Dspark.history.retainedApplications=30&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">参数1含义：WEBUI访问的端口号为18080</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">参数2含义：指定历史服务器日志存储路径（读）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">参数3含义：指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</span></span><br></pre></td></tr></table></figure>

<h3 id="2-3-3-配置查看历史日志"><a href="#2-3-3-配置查看历史日志" class="headerlink" title="2.3.3 配置查看历史日志"></a>2.3.3 配置查看历史日志</h3><p>为了能从Yarn上关联到Spark历史服务器，需要配置spark历史服务器关联路径。</p>
<p><strong>目的：点击yarn（8088）上spark任务的history按钮，进入的是spark历史服务器（18080），而不再是yarn历史服务器（19888）。</strong></p>
<p>（1）修改配置文件&#x2F;opt&#x2F;module&#x2F;spark&#x2F;conf&#x2F;spark-defaults.conf，添加如下内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.yarn.historyServer.address=hadoop102:18080</span><br><span class="line">spark.history.ui.port=18080</span><br></pre></td></tr></table></figure>

<p>（2）启动spark历史服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# sbin/start-history-server.sh </span><br></pre></td></tr></table></figure>

<p>（3）重新提交任务到yarn</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn ./examples/jars/spark-examples_2.12-3.3.1.jar 10</span><br></pre></td></tr></table></figure>

<p>（4）查看<a target="_blank" rel="noopener" href="http://hadoop103:8088/cluster">All Applications</a>页面，点击History，查看历史页面</p>
<p><img src="Snipaste_2024-05-28_23-03-38.png" alt="Snipaste_2024-05-28_23-03-38"></p>
<p>即跳转到了<a target="_blank" rel="noopener" href="http://hadoop102:18080/%E9%A1%B5%E9%9D%A2">http://hadoop102:18080/页面</a></p>
<p><img src="Snipaste_2024-05-28_23-05-06.png" alt="Snipaste_2024-05-28_23-05-06"></p>
<p>点击描述信息，可以看到更详细的信息：</p>
<p><img src="Snipaste_2024-05-28_23-07-51.png" alt="Snipaste_2024-05-28_23-07-51"></p>
<h3 id="2-3-4-运行流程"><a href="#2-3-4-运行流程" class="headerlink" title="2.3.4 运行流程"></a>2.3.4 运行流程</h3><p>Spark有yarn-client和yarn-cluster两种模式，主要区别在于：<strong>Driver程序的运行节点</strong>。</p>
<p><strong>yarn-client</strong>：Driver程序运行在客户端，适用于交互、调试，希望立即看到app的输出。在输出日志中可以找到计算结果</p>
<p><img src="Snipaste_2024-05-28_23-16-34.png" alt="Snipaste_2024-05-28_23-16-34"></p>
<p><img src="Snipaste_2024-05-28_23-18-34.png" alt="Snipaste_2024-05-28_23-18-34"></p>
<p><strong>yarn-cluster</strong>：Driver程序运行在由ResourceManager启动的APPMaster，适用于生产环境。在输出日志中不会展示计算结果</p>
<p><img src="Snipaste_2024-05-28_23-16-43.png" alt="Snipaste_2024-05-28_23-16-43"></p>
<p><img src="Snipaste_2024-05-28_23-29-33.png" alt="Snipaste_2024-05-28_23-29-33"></p>
<p>（1）客户端模式（默认）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.12-3.3.1.jar 10</span><br></pre></td></tr></table></figure>

<p>（2）集群模式</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster ./examples/jars/spark-examples_2.12-3.3.1.jar 10</span><br></pre></td></tr></table></figure>

<p>查看<a target="_blank" rel="noopener" href="http://hadoop103:8088/cluster">All Applications</a>页面，点击History，查看历史页面，跳转到<a target="_blank" rel="noopener" href="http://hadoop102:18080/%E9%A1%B5%E9%9D%A2%EF%BC%8C%E7%82%B9%E5%87%BBExecutors">http://hadoop102:18080/页面，点击Executors</a></p>
<p><img src="Snipaste_2024-05-28_23-27-48.png" alt="Snipaste_2024-05-28_23-27-48"></p>
<p>点击driver中的stdout</p>
<p><img src="Snipaste_2024-05-28_23-28-14.png" alt="Snipaste_2024-05-28_23-28-14"></p>
<p>即可看到计算结果：</p>
<p><img src="Snipaste_2024-05-28_23-29-07.png" alt="Snipaste_2024-05-28_23-29-07"></p>
<h2 id="2-4-Standalone模式（了解）"><a href="#2-4-Standalone模式（了解）" class="headerlink" title="2.4 Standalone模式（了解）"></a>2.4 Standalone模式（了解）</h2><p>Standalone模式是Spark自带的资源调度引擎，构建一个由Master + Worker构成的Spark集群，Spark运行在集群中。</p>
<p>这个要和Hadoop中的Standalone区别开来。这里的Standalone是指只用Spark来搭建一个集群，不需要借助Hadoop的Yarn和Mesos等其他框架。</p>
<img src="Snipaste_2024-05-28_23-31-28.png" alt="Snipaste_2024-05-28_23-31-28" style="zoom:50%;">

<h2 id="2-5-Mesos模式（了解）"><a href="#2-5-Mesos模式（了解）" class="headerlink" title="2.5 Mesos模式（了解）"></a>2.5 Mesos模式（了解）</h2><p>Spark客户端直接连接Mesos；不需要额外构建Spark集群。国内应用比较少，更多的是运用Yarn调度。</p>
<h2 id="2-6-几种模式对比"><a href="#2-6-几种模式对比" class="headerlink" title="2.6 几种模式对比"></a>2.6 几种模式对比</h2><table>
<thead>
<tr>
<th>模式</th>
<th>Spark安装机器数</th>
<th>需启动的进程</th>
<th>所属者</th>
</tr>
</thead>
<tbody><tr>
<td>Local</td>
<td>1</td>
<td>无</td>
<td>Spark</td>
</tr>
<tr>
<td>Standalone</td>
<td>3</td>
<td>Master及Worker</td>
<td>Spark</td>
</tr>
<tr>
<td>Yarn</td>
<td>1</td>
<td>Yarn及HDFS</td>
<td>Hadoop</td>
</tr>
</tbody></table>
<h2 id="2-7-端口号总结"><a href="#2-7-端口号总结" class="headerlink" title="2.7 端口号总结"></a>2.7 端口号总结</h2><p>1）Spark查看当前Spark-shell运行任务情况端口号：4040</p>
<p>2）Spark历史服务器端口号：18080		（类比于Hadoop历史服务器端口号：19888）</p>
<h1 id="第三章-RDD概述"><a href="#第三章-RDD概述" class="headerlink" title="第三章 RDD概述"></a>第三章 RDD概述</h1><p><img src="Snipaste_2024-05-29_14-05-54.png" alt="Snipaste_2024-05-29_14-05-54"></p>
<h2 id="3-1-什么是RDD"><a href="#3-1-什么是RDD" class="headerlink" title="3.1 什么是RDD"></a>3.1 什么是RDD</h2><p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据抽象。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。RDD不保存数据。</p>
<p>RDD类比工厂生产。RDD控制全局，它说生产才能生产，每一个生产工序一旦制定好就不能修改，生产工序不存储物料，可以同时多条生产线同时工作。</p>
<p><img src="Snipaste_2024-05-29_14-28-47.png" alt="Snipaste_2024-05-29_14-28-47"></p>
<p><img src="Snipaste_2024-05-29_14-35-04.png" alt="Snipaste_2024-05-29_14-35-04"></p>
<p>先举java中处理IO流的场景</p>
<img src="Snipaste_2024-05-29_14-46-20.png" alt="Snipaste_2024-05-29_14-46-20" style="zoom:50%;">

<img src="Snipaste_2024-05-29_14-46-45.png" alt="Snipaste_2024-05-29_14-46-45" style="zoom:50%;">

<img src="Snipaste_2024-05-29_14-47-12.png" alt="Snipaste_2024-05-29_14-47-12" style="zoom:50%;">

<p><img src="Snipaste_2024-05-29_14-49-50.png" alt="Snipaste_2024-05-29_14-49-50"></p>
<h2 id="3-2-RDD五大特性"><a href="#3-2-RDD五大特性" class="headerlink" title="3.2 RDD五大特性"></a>3.2 RDD五大特性</h2><p><img src="Snipaste_2024-05-29_14-51-22.png" alt="Snipaste_2024-05-29_14-51-22"></p>
<h1 id="第四章-RDD编程"><a href="#第四章-RDD编程" class="headerlink" title="第四章 RDD编程"></a>第四章 RDD编程</h1><h2 id="4-1-RDD的创建"><a href="#4-1-RDD的创建" class="headerlink" title="4.1 RDD的创建"></a>4.1 RDD的创建</h2><p>在Spark中创建RDD的创建方式可以分为三种：从集合中创建RDD、从外部存储创建RDD、从其他RDD创建。</p>
<h3 id="4-1-1-IDEA环境准备"><a href="#4-1-1-IDEA环境准备" class="headerlink" title="4.1.1 IDEA环境准备"></a>4.1.1 IDEA环境准备</h3><p>（1）创建一个maven工程，工程名叫SparkCore</p>
<img src="Snipaste_2024-05-29_15-11-01.png" alt="Snipaste_2024-05-29_15-11-01" style="zoom:50%;">

<p>注意对maven的设置：</p>
<img src="Snipaste_2024-05-29_15-12-15.png" alt="Snipaste_2024-05-29_15-12-15">

<p>（2）创建包名：com.atguigu.createrdd</p>
<p>（3）在pom文件中添加spark-core的依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（4）如果不希望运行时打印大量日志，可以在resources文件夹中添加log4j2.properties文件，并添加日志配置信息</p>
<img src="Snipaste_2024-05-29_15-20-25.png" alt="Snipaste_2024-05-29_15-20-25" style="zoom:50%;">

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># Set everything to be logged to the console</span><br><span class="line">rootLogger.level = ERROR</span><br><span class="line">rootLogger.appenderRef.stdout.ref = console</span><br><span class="line"></span><br><span class="line"># In the pattern layout configuration below, we specify an explicit `%ex` conversion </span><br><span class="line"># pattern for logging Throwables. If this was omitted, then (by default) Log4J would </span><br><span class="line"># implicitly add an `%xEx` conversion pattern which logs stacktraces with additional </span><br><span class="line"># class packaging information. That extra information can sometimes add a substantial </span><br><span class="line"># performance overhead, so we disable it in our default logging config. </span><br><span class="line"># For more information, see SPARK-39361. </span><br><span class="line">appender.console.type = Console</span><br><span class="line">appender.console.name = console</span><br><span class="line">appender.console.target = SYSTEM_ERR</span><br><span class="line">appender.console.layout.type = PatternLayout</span><br><span class="line">appender.console.layout.pattern = %d&#123;yy/MM/dd HH:mm:ss&#125; %p %c&#123;1&#125;: %m%n%ex</span><br><span class="line"></span><br><span class="line"># Set the default spark-shell/spark-sql log level to WARN. When running the </span><br><span class="line"># spark-shell/spark-sql, the log level for these classes is used to overwrite </span><br><span class="line"># the root logger&#x27;s log level, so that the user can have different defaults </span><br><span class="line"># for the shell and regular Spark apps. </span><br><span class="line">logger.repl.name = org.apache.spark.repl.Main</span><br><span class="line">logger.repl.level = warn</span><br><span class="line">logger.thriftserver.name = org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver</span><br><span class="line">logger.thriftserver.level = warn</span><br><span class="line"></span><br><span class="line"># Settings to quiet third party logs that are too verbose </span><br><span class="line">logger.jetty1.name = org.sparkproject.jetty</span><br><span class="line">logger.jetty1.level = warn</span><br><span class="line">logger.jetty2.name = org.sparkproject.jetty.util.component.AbstractLifeCycle</span><br><span class="line">logger.jetty2.level = error</span><br><span class="line">logger.replexprTyper.name = org.apache.spark.repl.SparkIMain$exprTyper</span><br><span class="line">logger.replexprTyper.level = info</span><br><span class="line">logger.replSparkILoopInterpreter.name = org.apache.spark.repl.SparkILoop$SparkILoopInterpreter</span><br><span class="line">logger.replSparkILoopInterpreter.level = info</span><br><span class="line">logger.parquet1.name = org.apache.parquet</span><br><span class="line">logger.parquet1.level = error</span><br><span class="line">logger.parquet2.name = parquet</span><br><span class="line">logger.parquet2.level = error</span><br><span class="line"></span><br><span class="line"># SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support </span><br><span class="line">logger.RetryingHMSHandler.name = org.apache.hadoop.hive.metastore.RetryingHMSHandler</span><br><span class="line">logger.RetryingHMSHandler.level = fatal</span><br><span class="line">logger.FunctionRegistry.name = org.apache.hadoop.hive.ql.exec.FunctionRegistry</span><br><span class="line">logger.FunctionRegistry.level = error</span><br><span class="line"></span><br><span class="line"># For deploying Spark ThriftServer </span><br><span class="line"># SPARK-34128: Suppress undesirable TTransportException warnings involved in THRIFT-4805 </span><br><span class="line">appender.console.filter.1.type = RegexFilter</span><br><span class="line">appender.console.filter.1.regex = .*Thrift error occurred during processing of message.*</span><br><span class="line">appender.console.filter.1.onMatch = deny appender.console.filter.1.onMismatch = neutral</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2-创建IDEA快捷键"><a href="#4-1-2-创建IDEA快捷键" class="headerlink" title="4.1.2 创建IDEA快捷键"></a>4.1.2 创建IDEA快捷键</h3><img src="Snipaste_2024-05-29_15-26-49.png" alt="Snipaste_2024-05-29_15-26-49" style="zoom: 33%;">

<h3 id="4-1-3-异常处理"><a href="#4-1-3-异常处理" class="headerlink" title="4.1.3 异常处理"></a>4.1.3 异常处理</h3><p>略</p>
<h3 id="4-1-4-从集合中创建"><a href="#4-1-4-从集合中创建" class="headerlink" title="4.1.4 从集合中创建"></a>4.1.4 从集合中创建</h3><p>从单值类型的集合中（内存中）创建RDD：parallelize</p>
<p>从KV类型的集合中创建RDD：parallelizePairs</p>
<p><strong>重要代码：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Object&gt; rdd = jsc.parallelize(</span><br><span class="line">        Arrays.asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.createrdd;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark02_RDD_Memory</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.createrdd</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/5/29 0029 15:45</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark02_RDD_Memory</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>();</span><br><span class="line">        conf.setMaster(<span class="string">&quot;local&quot;</span>);</span><br><span class="line">        conf.setAppName(<span class="string">&quot;spark&quot;</span>);</span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 构建RDD数据处理模型</span></span><br><span class="line">        <span class="comment">//     利用环境对象对接内存数据源，构建RDD对象</span></span><br><span class="line">        List&lt;String&gt; names = Arrays.asList(<span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;lisi&quot;</span>, <span class="string">&quot;wangwu&quot;</span>);<span class="comment">//创建一个集合对象</span></span><br><span class="line">        <span class="comment">//TODO parallelize方法可以传递参数：集合</span></span><br><span class="line">        <span class="comment">//  RDD数据模型中存在泛型&lt;string&gt;</span></span><br><span class="line">        JavaRDD&lt;String&gt; rdd = jsc.parallelize(names); <span class="comment">//将集合对象包装为rdd对象</span></span><br><span class="line"></span><br><span class="line">        List&lt;String&gt; collect = rdd.collect();<span class="comment">//使用rdd中封装的方法collect()，目的是将rdd中的数据收集起来，当然还是一个集合</span></span><br><span class="line">        <span class="keyword">for</span>(String s: collect)&#123;</span><br><span class="line">            System.out.println(s);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        jsc.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-05-29_16-00-17.png" alt="Snipaste_2024-05-29_16-00-17"></p>
<h3 id="4-1-5-从外部存储系统的数据集创建"><a href="#4-1-5-从外部存储系统的数据集创建" class="headerlink" title="4.1.5 从外部存储系统的数据集创建"></a>4.1.5 从外部存储系统的数据集创建</h3><p>由外部存储系统的数据集创建RDD包括：本地的文件系统，还有所有Hadoop支持的数据集，比如HDFS、HBase等。</p>
<p>（1）数据准备</p>
<p><img src="Snipaste_2024-05-29_16-13-08.png" alt="Snipaste_2024-05-29_16-13-08"></p>
<p>（2）创建RDD</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.createrdd;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark03_RDD_Disk</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.createrdd</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/5/29 0029 16:07</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark03_RDD_Disk</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 构建RDD数据处理模型，</span></span><br><span class="line">        <span class="comment">//  利用环境对象对接磁盘数据（文件），构建RDD对象</span></span><br><span class="line">        <span class="comment">// textFile方法可以传递一个参数：文件路径</span></span><br><span class="line">        JavaRDD&lt;String&gt; rdd = jsc.textFile(<span class="string">&quot;D:\\idea-maven-space\\SparkCore\\src\\main\\data\\test.txt&quot;</span>);</span><br><span class="line">        List&lt;String&gt; collect = rdd.collect();</span><br><span class="line">        collect.forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-1-6-从其他RDD创建"><a href="#4-1-6-从其他RDD创建" class="headerlink" title="4.1.6 从其他RDD创建"></a>4.1.6 从其他RDD创建</h3><p>主要是通过一个RDD运算完后，再产生新的RDD，详见4.3节</p>
<h2 id="4-2-分区规则"><a href="#4-2-分区规则" class="headerlink" title="4.2 分区规则"></a>4.2 分区规则</h2><h3 id="4-2-1-从集合创建RDD"><a href="#4-2-1-从集合创建RDD" class="headerlink" title="4.2.1 从集合创建RDD"></a>4.2.1 从集合创建RDD</h3><p>（1）创建一个包名：com.atguigu.partition</p>
<p>（2）代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.partition;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Array;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark02_RDD_Memory_Partition</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.partition</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/5/29 0029 16:36</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark02_RDD_Memory_Partition</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO RDD可以将数据进行切片（减小规模），也称之为分区，这个分区操作是底层完成的</span></span><br><span class="line">        <span class="comment">//   local环境中分区数量和环境的核数相关，但是一般不推荐</span></span><br><span class="line">        <span class="comment">//   分区数量需要手动设定</span></span><br><span class="line">        <span class="comment">//        Spark在读取集合数据时，分区设定存在3种不同场合</span></span><br><span class="line">        <span class="comment">//             1.优先使用方法参数</span></span><br><span class="line">        <span class="comment">//             2.使用配置参数：spark.default.parallelism</span></span><br><span class="line">        <span class="comment">//             3.采用环境默认总核值</span></span><br><span class="line">        List&lt;String&gt; names = Arrays.asList(<span class="string">&quot;zhangsan&quot;</span>, <span class="string">&quot;lisi&quot;</span>, <span class="string">&quot;wangwu&quot;</span>);</span><br><span class="line">        <span class="comment">// parallelize方法可以传递两个参数</span></span><br><span class="line">        <span class="comment">//    第一个参数表示对接的数据源的集合</span></span><br><span class="line">        <span class="comment">//    第二个参数表示切片（分区）的数量，可以不需要制定，spark会采用默认指进行分区（切片），从配置对象中获取配置参数：spark.default.parallelism（默认并行度），</span></span><br><span class="line">        <span class="comment">//    如果配置参数不存在，那么默认取值为totalCores（当前环境总的虚拟核数），</span></span><br><span class="line">        JavaRDD&lt;String&gt; rdd = jsc.parallelize(names,<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 将数据模型分区后的数据保存到磁盘文件中</span></span><br><span class="line">        <span class="comment">//  saveASTextFile方法可以传递一个参数，表示输出的文件路径，路径可以是绝对路径，也可以是相对路径</span></span><br><span class="line">        <span class="comment">//  IDEA默认的相对路径以项目的根目录为准</span></span><br><span class="line">        rdd.saveAsTextFile(<span class="string">&quot;output&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-05-29_17-00-40.png" alt="Snipaste_2024-05-29_17-00-40"></p>
<p>spark分区数据的存储基本原则：平均分</p>
<p>【part-00000】-&gt; “zhangsan”</p>
<p>【part-00001】-&gt; “lisi”</p>
<p>【part-00002】-&gt; “wangwu”</p>
<h3 id="4-2-2-从文件创建RDD"><a href="#4-2-2-从文件创建RDD" class="headerlink" title="4.2.2 从文件创建RDD"></a>4.2.2 从文件创建RDD</h3><p>src&#x2F;main&#x2F;data&#x2F;test.txt存储着如下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.partition;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark03_RDD_Disk</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.createrdd</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/5/29 0029 16:07</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark03_RDD_Disk_Partition</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO Spark读取文件可以传递路径，这个路径可以是绝对路径，也可以是相对路径</span></span><br><span class="line">        <span class="comment">//   IDEA中默认的相对路径以项目的根路径为基准，不是以模块的根路径为基准</span></span><br><span class="line">        JavaRDD&lt;String&gt; rdd = jsc.textFile(<span class="string">&quot;src/main/data/test.txt&quot;</span>,<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO 文件数据源分区设定也存在多个位置</span></span><br><span class="line">        <span class="comment">//      1.textFile可以传递第二个参数：minPartition（最小分区数）</span></span><br><span class="line">        <span class="comment">//              参数可以不需要传递的，那么Spark会采用默认值：minPartition = math.min(defaultParallelism, 2)</span></span><br><span class="line">        <span class="comment">//      2.使用配置参数：spark.default.parallelism =&gt; math.min(spark.default.parallelism, 2)</span></span><br><span class="line">        <span class="comment">//      3.采用环境默认总核值 =&gt; math.min(总核数, 2)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO Spark框架是基于MR开发的，</span></span><br><span class="line">        <span class="comment">//      Spark框架文件的操作没有自己的实现，采用MR库（Hadoop）来实现</span></span><br><span class="line">        <span class="comment">//      当前读取文件的切片数量不是由Spark决定的，而是由Hadoop决定的</span></span><br><span class="line">        <span class="comment">//      具体的分区个数需要经过公式计算</span></span><br><span class="line">        <span class="comment">//      首先获取文件的总长度  totalSize</span></span><br><span class="line">        <span class="comment">//      计算平均长度  goalSize = totalSize / numSplits</span></span><br><span class="line">        <span class="comment">//      获取块大小 128M</span></span><br><span class="line">        <span class="comment">//      计算切分大小  splitSize = Math.max(minSize, Math.min(goalSize, blockSize));</span></span><br><span class="line">        <span class="comment">//      最后使用splitSize  按照1.1倍原则切分整个文件   得到几个分区就是几个分区</span></span><br><span class="line">        <span class="comment">//      实际开发中   只需要看文件总大小 / 填写的分区数  和块大小比较  谁小拿谁进行切分</span></span><br><span class="line">        rdd.saveAsTextFile(<span class="string">&quot;output2&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-05-30_19-55-14.png" alt="Snipaste_2024-05-30_19-55-14"></p>
<p>注意：getSplits文件返回的是切片规划，真正读取是在compute方法中创建LineRecordReader读取的，有两个关键变量： start &#x3D; split.getStart()	  end &#x3D; start + split.getLength</p>
<p>①分区数量的计算方式:</p>
<p>totalSize &#x3D; 10</p>
<p>goalSize &#x3D; 10 &#x2F; 3 &#x3D; 3(byte) 表示每个分区存储3字节的数据</p>
<p>分区数&#x3D; totalSize&#x2F; goalSize &#x3D; 10 &#x2F;3 &#x3D;&gt; 3,3,4</p>
<p>4子节大于3子节的1.1倍,符合hadoop切片1.1倍的策略,因此会多创建一个分区,即一共有4个分区  3,3,3,1</p>
<p>②Spark读取文件，采用的是hadoop的方式读取，所以一行一行读取，跟字节数没有关系</p>
<p>③数据读取位置计算是以偏移量为单位来进行计算的。</p>
<h2 id="4-3-Transformation转换算子"><a href="#4-3-Transformation转换算子" class="headerlink" title="4.3 Transformation转换算子"></a>4.3 Transformation转换算子</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> operate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple1;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark01_Operate</span></span><br><span class="line"><span class="comment"> * Package: com.atguigu.operate</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/6/1 0001 22:12</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//  TODO RDD的方法</span></span><br><span class="line">        JavaRDD&lt;Object&gt; rdd = jsc.parallelize(</span><br><span class="line">                Arrays.asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">0</span>)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO RDD的方法有很多，主要讲解核心、重要的方法</span></span><br><span class="line">        <span class="comment">//  学习的重点：名字，输入，输出</span></span><br><span class="line">        <span class="comment">//  RDD的方法有很多，但是分为两类：1.转换：将数据向后流转</span></span><br><span class="line">        <span class="comment">//                            2.行动：打开数据开关</span></span><br><span class="line">        <span class="comment">//  RDD方法处理数据的分类：1.单值：1, &quot;abc&quot;, new User(), new ArrayList()</span></span><br><span class="line">        <span class="comment">//                     2.键值: KV =&gt; (Key, Value)</span></span><br><span class="line">        <span class="comment">//  TODO JDK1.8以后也存在元组，采用特殊的类：TupleX，X代表元素的个数</span></span><br><span class="line">        Tuple1&lt;String&gt; abc = <span class="keyword">new</span> <span class="title class_">Tuple1</span>&lt;&gt;(<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">        Tuple2&lt;String, Integer&gt; abc1 = <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;abc&quot;</span>, <span class="number">1001</span>);</span><br><span class="line">        <span class="comment">//访问元组数据需要使用顺序号</span></span><br><span class="line">        System.out.println(abc1._1);<span class="comment">//abc</span></span><br><span class="line">        System.out.println(abc1._2);<span class="comment">//1001</span></span><br><span class="line">        <span class="comment">//元组最大的数据容量为22</span></span><br><span class="line"><span class="comment">//        new Tuple22&lt;&gt;()</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-3-1-Value类型（指输入类型为单值的）"><a href="#4-3-1-Value类型（指输入类型为单值的）" class="headerlink" title="4.3.1 Value类型（指输入类型为单值的）"></a>4.3.1 Value类型（指输入类型为单值的）</h3><p><strong>转换算子中的参数，即重写的接口。该接口重写的call方法中的参数v1代表调用该方法的rdd中的单个数据。如果rdd中是集合，v1代表集合中的一个值；如果rdd中是二维集合，v1代表二维集合中的一个一维集合。</strong></p>
<h4 id="4-3-1-1-map-映射"><a href="#4-3-1-1-map-映射" class="headerlink" title="4.3.1.1 map()映射"></a>4.3.1.1 map()映射</h4><h5 id="（1）语法"><a href="#（1）语法" class="headerlink" title="（1）语法"></a>（1）语法</h5><p>参数f是一个函数可以写作匿名子类，它可以接收一个参数。当某个RDD执行map方法时，会遍历该RDD中的每一个数据项，并依次应用f函数，从而产生一个新的RDD。即，这个新RDD中的每一个元素都是原来RDD中每一个元素依次应用f函数而得到的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> operate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark01_Operate_Transform_Map</span></span><br><span class="line"><span class="comment"> * Package: operate</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/6/1 0001 23:54</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Transform_Map_1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//  TODO RDD的方法</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(</span><br><span class="line">                Arrays.asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),<span class="number">2</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">//  TODO RDD的转换方法：Map</span></span><br><span class="line">        <span class="comment">//     对单值数据进行处理</span></span><br><span class="line">        <span class="comment">// map:映射（K-&gt;V），将K转换成V</span></span><br><span class="line">        <span class="comment">//  使用场景：制定值转换为其他的值的时候</span></span><br><span class="line">        <span class="comment">// TODO map方法的作用就是将传入的A转换为B，但没有限制A和B的关系</span></span><br><span class="line">        <span class="comment">//map()有一个参数f，可以写作匿名子类，Function接口的泛型约束中，第一个泛型约束Integer代表输入rdd的泛型类型</span></span><br><span class="line">        <span class="comment">//第二个泛型约束Object代表输出rdd的泛型类型</span></span><br><span class="line">        JavaRDD&lt;Object&gt; newRDD = rdd.map(<span class="keyword">new</span> <span class="title class_">Function</span>&lt;Integer, Object&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Object <span class="title function_">call</span><span class="params">(Integer v1)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> v1 * <span class="number">2</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//我们明确输入输出的rdd泛型都是整形：</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; newRDD1 = rdd.map(<span class="keyword">new</span> <span class="title class_">Function</span>&lt;Integer, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Integer <span class="title function_">call</span><span class="params">(Integer v1)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> v1 * <span class="number">2</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//输入rdd整形，输出rdd为字符串类型</span></span><br><span class="line">        JavaRDD&lt;String&gt; newRDD2 = rdd.map(<span class="keyword">new</span> <span class="title class_">Function</span>&lt;Integer, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">call</span><span class="params">(Integer v1)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> v1 + <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 如果Java中接口采用注解@FunctionalInterface声明，那么接口的使用就可以采用JDK</span></span><br><span class="line">        <span class="comment">// 提供的函数式编程的语法实现（lambda表达式）</span></span><br><span class="line">        <span class="comment">// 1.return可以省略：map方法就需要返回值，所以不用return</span></span><br><span class="line">        <span class="comment">// 2.分号可以省略：可以采用换行的方式表示代码逻辑</span></span><br><span class="line">        <span class="comment">// 3.大括号 可以省略：如果逻辑代码只有一行</span></span><br><span class="line">        <span class="comment">// 4.小括号 可以省略：参数列表中的参数只有一个</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; newRDD3 = rdd.map(</span><br><span class="line">                (v1) -&gt; &#123;</span><br><span class="line">                    <span class="keyword">return</span> v1 * <span class="number">2</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//v1 -&gt; v1 * 2</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;String&gt; newRDD4 = rdd.map(</span><br><span class="line">                (v1) -&gt; &#123;</span><br><span class="line">                    <span class="keyword">return</span> v1 + <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5.参数和箭头 可以省略：参数在逻辑中只使用了一次（需要有对象来实现功能）(类名::方法名)</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; newRDD5 = rdd.map(NumberTest::mul);</span><br><span class="line">        JavaRDD&lt;String&gt; newRDD6 = rdd.map(NumberTest::mul2);</span><br><span class="line"></span><br><span class="line">        newRDD.collect().forEach(System.out::println);<span class="comment">//2 4 6 8</span></span><br><span class="line">        newRDD1.collect().forEach(System.out::println);<span class="comment">//2 4 6 8</span></span><br><span class="line">        newRDD2.collect().forEach(System.out::println);<span class="comment">//1abc 2abc 3abc 4abc</span></span><br><span class="line">        newRDD3.collect().forEach(System.out::println);<span class="comment">//2 4 6 8</span></span><br><span class="line">        newRDD4.collect().forEach(System.out::println);<span class="comment">//1abc 2abc 3abc 4abc</span></span><br><span class="line">        newRDD5.collect().forEach(System.out::println);<span class="comment">//2 4 6 8</span></span><br><span class="line">        newRDD6.collect().forEach(System.out::println);<span class="comment">//1abc 2abc 3abc 4abc</span></span><br><span class="line">        rdd.collect().forEach(System.out::println);<span class="comment">//1 2 3 4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NumberTest</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">int</span> <span class="title function_">mul</span><span class="params">(Integer num)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> num * <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">mul2</span><span class="params">(Integer num)</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> num + <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> operate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark01_Operate_Transform_Map_2</span></span><br><span class="line"><span class="comment"> * Package: operate</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/6/2 0002 10:49</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Transform_Map_2</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">// TODO 函数式编程最简单的方法</span></span><br><span class="line">        jsc.parallelize(Arrays.asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),<span class="number">2</span>)</span><br><span class="line">                .map(NumberTest::mul)</span><br><span class="line">                        .collect()</span><br><span class="line">                                .forEach(System.out::println);<span class="comment">//2 4 6 8</span></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="（2）分区"><a href="#（2）分区" class="headerlink" title="（2）分区"></a>（2）分区</h5><p><img src="Snipaste_2024-06-02_14-14-28.png" alt="Snipaste_2024-06-02_14-14-28"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> operate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark01_Operate_Transform_Map_3</span></span><br><span class="line"><span class="comment"> * Package: operate</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *  经过map方法后的rdd分区问题</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/6/2 0002 13:33</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Transform_Map_3</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">        JavaRDD&lt;Integer&gt; newRDD = rdd.map(v1 -&gt; v1 * <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        rdd.saveAsTextFile(<span class="string">&quot;output3&quot;</span>);</span><br><span class="line">        newRDD.saveAsTextFile(<span class="string">&quot;output4&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-02_14-16-53.png" alt="Snipaste_2024-06-02_14-16-53" style="zoom:43%;">

<p>可以看到，新创建的RDD分区数量和之前旧的RDD数量保持一致；数据流转所在的分区编号不变</p>
<h5 id="（3）数据流转顺序"><a href="#（3）数据流转顺序" class="headerlink" title="（3）数据流转顺序"></a>（3）数据流转顺序</h5><p><img src="Snipaste_2024-06-02_14-22-11.png" alt="Snipaste_2024-06-02_14-22-11"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> operate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark01_Operate_Transform_Map_4</span></span><br><span class="line"><span class="comment"> * Package: operate</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/6/2 0002 14:22</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Transform_Map_4</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>),<span class="number">1</span>);</span><br><span class="line">        JavaRDD&lt;Integer&gt; rdd1 = rdd.map(</span><br><span class="line">                (v1) -&gt; &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;@&quot;</span> + v1);</span><br><span class="line">                    <span class="keyword">return</span> v1;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Integer&gt; rdd2 = rdd1.map(</span><br><span class="line">                (v1) -&gt; &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;###&quot;</span> + v1);</span><br><span class="line">                    <span class="keyword">return</span> v1;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        rdd2.collect();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-02_14-30-27.png" alt="Snipaste_2024-06-02_14-30-27" style="zoom:43%;">

<p>rdd会对<strong>一个数据做从始至终的操作，操作完毕一个数据后再操作另外的数据</strong>，如上面的代码，将rdd中的数据1进行操作后进入rdd1在进行操作进入rdd2，然后再处理数据2</p>
<h4 id="4-3-1-2-filter-过滤"><a href="#4-3-1-2-filter-过滤" class="headerlink" title="4.3.1.2 filter()过滤"></a>4.3.1.2 filter()过滤</h4><p>接收一个返回值为布尔类型的函数作为参数。当某个RDD调用filter方法时，会对该RDD中每一个元素应用f函数，如果返回值类型为true，则该元素会被添加到新的RDD中。</p>
<img src="Snipaste_2024-06-02_16-28-32.png" alt="Snipaste_2024-06-02_16-28-32" style="zoom:50%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> operate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark01_Operate_Transform_Filter</span></span><br><span class="line"><span class="comment"> * Package: operate</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/6/2 0002 14:36</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Transform_Filter</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//TODO RDD的转换方法：filter（过滤）</span></span><br><span class="line">        <span class="comment">// RDD可以根据制定的过滤规则对单值数据进行筛选过滤</span></span><br><span class="line">        <span class="comment">// 如果满足数据规则（返回结果为true），则数据会保留，不满足数据则会丢弃（返回结果为false）</span></span><br><span class="line">        <span class="comment">// filter方法在执行过程中可能出现数据倾斜的情况，需要慎重考虑</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>));</span><br><span class="line">        JavaRDD&lt;Integer&gt; filterRDD = rdd.filter(<span class="keyword">new</span> <span class="title class_">Function</span>&lt;Integer, Boolean&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Boolean <span class="title function_">call</span><span class="params">(Integer v1)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;<span class="comment">//将传入的所有数据都返回</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//函数式编程写法</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; filterRDD1 = rdd.filter(</span><br><span class="line">                v1 -&gt; <span class="literal">true</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Integer&gt; filterRDD2 = rdd.filter(v1 -&gt; v1 % <span class="number">2</span> == <span class="number">1</span>);<span class="comment">//只保留奇数，此处可以将v1 % 2 == 1理解成为sql中的where条件</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; filterRDD3 = rdd.filter(v1 -&gt; v1 &gt; <span class="number">2</span>);<span class="comment">//保留大于2的数据</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        filterRDD.collect().forEach(System.out::println);<span class="comment">//1 2 3 4</span></span><br><span class="line">        filterRDD1.collect().forEach(System.out::println);<span class="comment">//1 2 3 4</span></span><br><span class="line">        filterRDD2.collect().forEach(System.out::println);<span class="comment">//1 3</span></span><br><span class="line">        filterRDD3.collect().forEach(System.out::println);<span class="comment">//3 4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="4-3-1-3-flatMap-扁平化"><a href="#4-3-1-3-flatMap-扁平化" class="headerlink" title="4.3.1.3 flatMap()扁平化"></a>4.3.1.3 flatMap()扁平化</h4><h5 id="（1）语法-集合的例子"><a href="#（1）语法-集合的例子" class="headerlink" title="（1）语法-集合的例子"></a>（1）语法-集合的例子</h5><p>与map操作类似，将RDD中的每一个元素通过应用f函数依次转换为新的元素，并封装到RDD中。</p>
<p>区别：在flatMap操作中，f函数的返回值是一个集合，并且会将每一个该集合中的元素拆分出来放到新的RDD中。</p>
<p><img src="Snipaste_2024-06-02_17-30-01.png" alt="Snipaste_2024-06-02_17-30-01"></p>
<p><img src="Snipaste_2024-06-02_17-36-07.png" alt="Snipaste_2024-06-02_17-36-07"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> operate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.FlatMapFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName: Spark01_Operate_Transform_FlatMap</span></span><br><span class="line"><span class="comment"> * Package: operate</span></span><br><span class="line"><span class="comment"> * Description:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Author</span> 宇涵 王</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Create</span> 2024/6/2 0002 16:56</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Version</span> 1.0</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Transform_FlatMap</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//TODO RDD的转换方法：flatmap</span></span><br><span class="line">        <span class="comment">// flat(数据扁平化) + map(映射)</span></span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; data = Arrays.asList(</span><br><span class="line">                Arrays.asList(<span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">                Arrays.asList(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">        );<span class="comment">//此处数据是二维集合</span></span><br><span class="line">        JavaRDD&lt;List&lt;Integer&gt;&gt; rdd = jsc.parallelize(data, <span class="number">2</span>);</span><br><span class="line">        <span class="comment">//1. 输入是&lt;List&lt;Integer&gt;，输出是list的迭代器，只起到扁平化的作用</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; flatMapRDD = rdd.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;List&lt;Integer&gt;, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Iterator&lt;Integer&gt; <span class="title function_">call</span><span class="params">(List&lt;Integer&gt; list)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> list.iterator();<span class="comment">//flatMap方法最后一定要返回一个集合的迭代器</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//函数式编程写法</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; flatMapRDD2 = rdd.flatMap(</span><br><span class="line">                (list) -&gt; list.iterator()<span class="comment">//flatMap方法最后一定要返回一个集合的迭代器</span></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 输入是&lt;List&lt;Integer&gt;，输出是经过map处理的迭代器，起到扁平化+map的作用</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; flatMapRDD3 = rdd.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;List&lt;Integer&gt;, Integer&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Iterator&lt;Integer&gt; <span class="title function_">call</span><span class="params">(List&lt;Integer&gt; list)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                ArrayList&lt;Integer&gt; nums = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                list.forEach(</span><br><span class="line">                        v1 -&gt; nums.add(v1 * <span class="number">2</span>)</span><br><span class="line">                );</span><br><span class="line">                <span class="keyword">return</span> nums.iterator();<span class="comment">//flatMap方法最后一定要返回一个集合的迭代器</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="comment">//函数式编程写法</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; flatMapRDD4 = rdd.flatMap(</span><br><span class="line">                (list) -&gt; &#123;</span><br><span class="line">                    ArrayList&lt;Integer&gt; nums = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                    list.forEach(</span><br><span class="line">                            v1 -&gt; nums.add(v1 * <span class="number">2</span>)</span><br><span class="line">                    );</span><br><span class="line">                    <span class="keyword">return</span> nums.iterator();<span class="comment">//flatMap方法最后一定要返回一个集合的迭代器</span></span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        flatMapRDD.collect().forEach(System.out::println);<span class="comment">//1 2 3 4</span></span><br><span class="line">        flatMapRDD2.collect().forEach(System.out::println);<span class="comment">//1 2 3 4</span></span><br><span class="line">        flatMapRDD3.collect().forEach(System.out::println);<span class="comment">//2 4 6 8</span></span><br><span class="line">        flatMapRDD4.collect().forEach(System.out::println);<span class="comment">//2 4 6 8</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果以上写法难以理解，可以写成多个rdd</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Transform_FlatMap</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//TODO RDD的转换方法：flatmap</span></span><br><span class="line">        <span class="comment">// flat(数据扁平化) + map(映射)</span></span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; data = Arrays.asList(</span><br><span class="line">                Arrays.asList(<span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">                Arrays.asList(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">        );<span class="comment">//此处数据是二维列表</span></span><br><span class="line">        JavaRDD&lt;List&lt;Integer&gt;&gt; rdd = jsc.parallelize(data, <span class="number">2</span>);</span><br><span class="line">        <span class="comment">//扁平化</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; flatMapRDD2 = rdd.flatMap(</span><br><span class="line">                (list) -&gt; list.iterator()<span class="comment">//flatMap方法最后一定要返回一个集合的迭代器</span></span><br><span class="line">        );</span><br><span class="line">        <span class="comment">//map</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; rdd1 = flatMapRDD2.map(v1 -&gt; v1 * <span class="number">2</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//JavaRDD&lt;Integer&gt; rdd1 = rdd.flatmap((list) -&gt; list.iterator()).map(v1 -&gt; v1 * 2);</span></span><br><span class="line">        </span><br><span class="line">        rdd1.collect().forEach(System.out::println);<span class="comment">//2 4 6 8</span></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//这种写法是套娃的简便写法</span></span><br><span class="line">JavaRDD&lt;Integer&gt; rdd1 = rdd.flatmap((list) -&gt; list.iterator()).map(v1 -&gt; v1 * <span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-03_17-25-06.png" alt="Snipaste_2024-06-03_17-25-06"></p>
<h5 id="（2）语法-文件的例子"><a href="#（2）语法-文件的例子" class="headerlink" title="（2）语法-文件的例子"></a>（2）语法-文件的例子</h5><p>在举一个文件的例子：</p>
<img src="Snipaste_2024-06-02_23-11-28.png" alt="Snipaste_2024-06-02_23-11-28" style="zoom:50%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; rdd = jsc.textFile(<span class="string">&quot;src/main/data/test1.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">rdd.collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<p>这样打印出来是按行的，即将一行看作整体，整体打印：</p>
<img src="Snipaste_2024-06-02_23-17-07.png" alt="Snipaste_2024-06-02_23-17-07" style="zoom:33%;">

<p>下面我们像将其一个单词一个单词打印出来，将一行扁平化为多个再打印</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; rdd = jsc.textFile(<span class="string">&quot;src/main/data/test1.txt&quot;</span>);</span><br><span class="line">JavaRDD&lt;String&gt; newRDD = rdd.flatMap(</span><br><span class="line">        line -&gt; Arrays.asList(line.split(<span class="string">&quot; &quot;</span>)).iterator()<span class="comment">//flatMap方法最后一定要返回一个集合的迭代器</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">newRDD.collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-02_23-52-43.png" alt="Snipaste_2024-06-02_23-52-43" style="zoom:50%;">

<h4 id="4-3-1-4-groupBy-分组"><a href="#4-3-1-4-groupBy-分组" class="headerlink" title="4.3.1.4 groupBy()分组"></a>4.3.1.4 groupBy()分组</h4><h5 id="（1）语法-1"><a href="#（1）语法-1" class="headerlink" title="（1）语法"></a>（1）语法</h5><p>功能说明：分组，按照传入函数的返回值进行分组。将每一条数据增加一个标记（返回值），相同标记的数据会放置一个组中（将相同的key对应的值放入一个迭代器），这个标记其实就是组名。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">JavaPairRDD&lt;Boolean, Iterable&lt;Integer&gt;&gt; groupByRDD = rdd.groupBy(</span><br><span class="line">        v1 -&gt; v1 % <span class="number">2</span> == <span class="number">0</span><span class="comment">//按照v1 % 2 == 0将数据进行分组</span></span><br><span class="line">);<span class="comment">//得到的结果是一个KV键值对的RDD</span></span><br><span class="line">groupByRDD.collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-03_00-24-02.png" alt="Snipaste_2024-06-03_00-24-02" style="zoom:50%;">

<h5 id="（2）Shuffle"><a href="#（2）Shuffle" class="headerlink" title="（2）Shuffle"></a>（2）Shuffle</h5><p><img src="Snipaste_2024-06-03_19-39-26.png" alt="Snipaste_2024-06-03_19-39-26"></p>
<p><strong>一个组必须在一个分区，一个分区可以存放多个组</strong></p>
<p><img src="Snipaste_2024-06-03_21-40-14.png" alt="Snipaste_2024-06-03_21-40-14"></p>
<p><img src="Snipaste_2024-06-03_21-44-51.png" alt="Snipaste_2024-06-03_21-44-51"></p>
<p><strong>Shuffle操作一定会落盘。即使只有一条数据</strong></p>
<p><strong>shuffle操作有可能会导致资源浪费，比如上图中的第三个Executor没有进行数据处理。Spark中含有shuffle操作的方法都有改变分区的能力</strong></p>
<p><strong>RDD的分区和Task之间有关系，有几个分区就有几个Task。Shuffle会将完整的计算流程一分为二，其中一部分任务会写磁盘，另一部分任务会读磁盘；写磁盘的操作不完成，不允许读磁盘</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>),<span class="number">2</span>);</span><br><span class="line">rdd.groupBy(v1 -&gt; v1 % <span class="number">2</span> == <span class="number">0</span>).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-03_22-35-48.png" alt="Snipaste_2024-06-03_22-35-48"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//初始设定三个分区</span></span><br><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>),<span class="number">3</span>);</span><br><span class="line"><span class="comment">// TODO 含有shuffle操作的方法都具有改变分区的能力，即可以设定分区参数</span></span><br><span class="line"><span class="comment">// 只有两个分组，所以只分成两个区</span></span><br><span class="line">rdd.groupBy(v1 -&gt; v1 % <span class="number">2</span> == <span class="number">0</span>,<span class="number">2</span>).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-03_22-53-44.png" alt="Snipaste_2024-06-03_22-53-44"></p>
<h4 id="4-3-1-5-distinct-去重"><a href="#4-3-1-5-distinct-去重" class="headerlink" title="4.3.1.5 distinct()去重"></a>4.3.1.5 distinct()去重</h4><p>功能说明：对内部的元素去重，并将去重后的元素放到新的RDD中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), <span class="number">3</span>);</span><br><span class="line"><span class="comment">// TODO distinct去重</span></span><br><span class="line"><span class="comment">//  hashSet去重，是单点去重</span></span><br><span class="line"><span class="comment">//  distinct，是分布式去重，采用分组+shuffle的处理方式</span></span><br><span class="line">rdd.distinct().collect().forEach(System.out::println);<span class="comment">//1 2</span></span><br></pre></td></tr></table></figure>

<h4 id="4-3-1-6-sortBy-排序"><a href="#4-3-1-6-sortBy-排序" class="headerlink" title="4.3.1.6 sortBy()排序"></a>4.3.1.6 sortBy()排序</h4><p>该操作用于排序数据。在排序之前，可以将数据通过f函数进行处理，之后按照f函数处理的结果进行排序，默认为正序排列。排序后新产生的RDD的分区数与原RDD的分区数一致。Spark的排序结果是全局有序。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO sortBy方法：按照指定的排序规则对数据进行排序</span></span><br><span class="line"><span class="comment">//    sortBy方法可以传递三个参数：</span></span><br><span class="line"><span class="comment">//         ①排序规则：spark会为每一个数据增加一个标记，然后按照标记对数据进行排序</span></span><br><span class="line"><span class="comment">//         ②排序方式：升序true，降序false</span></span><br><span class="line"><span class="comment">//         ③分区数量（由此可知sortBy是有shuffle的）</span></span><br><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">33</span>, <span class="number">11</span>), <span class="number">2</span>);</span><br><span class="line">rdd.saveAsTextFile(<span class="string">&quot;output5&quot;</span>);</span><br><span class="line">rdd.sortBy(v1 -&gt; v1,<span class="literal">true</span>,<span class="number">2</span>).saveAsTextFile(<span class="string">&quot;output6&quot;</span>);</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-04_14-24-11.png" alt="Snipaste_2024-06-04_14-24-11" style="zoom:50%;">

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">33</span>, <span class="number">11</span>), <span class="number">2</span>);</span><br><span class="line"><span class="comment">//按照字符串规则排序</span></span><br><span class="line">rdd.sortBy(v1 -&gt; <span class="string">&quot;&quot;</span> + v1,<span class="literal">true</span>,<span class="number">2</span>).collect().forEach(System.out::println);<span class="comment">//1 11 2 3 33 4</span></span><br></pre></td></tr></table></figure>

<h4 id="4-3-1-7-coalesce-合并（缩减）分区"><a href="#4-3-1-7-coalesce-合并（缩减）分区" class="headerlink" title="4.3.1.7 coalesce()合并（缩减）分区"></a>4.3.1.7 coalesce()合并（缩减）分区</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>), <span class="number">2</span>);<span class="comment">//[1,3,5] [2,4,6]</span></span><br><span class="line"></span><br><span class="line">JavaRDD&lt;Integer&gt; filterRDD = rdd.filter(v1 -&gt; v1 % <span class="number">2</span> == <span class="number">0</span>);</span><br><span class="line"><span class="comment">//TODO 改变分区，</span></span><br><span class="line"><span class="comment">//    合并分区：缩减分区</span></span><br><span class="line"><span class="comment">//    coalesce方法默认没有shuffle功能，所以数据不会被打乱重新组合，所以扩大分区是无法实现的</span></span><br><span class="line"><span class="comment">//    coalesce方法可以设定第二个shuffle参数，如果设定shuffle功能为true，则可以扩大分区</span></span><br><span class="line">JavaRDD&lt;Integer&gt; coalesceRDD = filterRDD.coalesce(<span class="number">1</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; coalesceRDD2 = filterRDD.coalesce(<span class="number">3</span>, <span class="literal">true</span>);</span><br><span class="line">coalesceRDD.saveAsTextFile(<span class="string">&quot;output7&quot;</span>);</span><br><span class="line">coalesceRDD2.saveAsTextFile(<span class="string">&quot;output8&quot;</span>);</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-05_16-52-41.png" alt="Snipaste_2024-06-05_16-52-41"></p>
<p><img src="Snipaste_2024-06-05_16-57-09.png" alt="Snipaste_2024-06-05_16-57-09"></p>
<h4 id="4-3-1-8-repatition-重分区"><a href="#4-3-1-8-repatition-重分区" class="headerlink" title="4.3.1.8 repatition()重分区"></a>4.3.1.8 repatition()重分区</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>), <span class="number">2</span>);<span class="comment">//[1,3,5] [2,4,6]</span></span><br><span class="line"></span><br><span class="line">JavaRDD&lt;Integer&gt; filterRDD = rdd.filter(v1 -&gt; v1 % <span class="number">2</span> == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//TODO 重分区</span></span><br><span class="line"><span class="comment">//   repartition方法其实就是设定shuffle为true的coalesce方法</span></span><br><span class="line">filterRDD.repartition(<span class="number">3</span>).saveAsTextFile(<span class="string">&quot;output9&quot;</span>);</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-05_17-53-33.png" alt="Snipaste_2024-06-05_17-53-33"></p>
<p><strong>缩减分区：coalesce</strong></p>
<p><strong>扩大分区：repartition</strong></p>
<h3 id="4-3-2-Key-Value类型"><a href="#4-3-2-Key-Value类型" class="headerlink" title="4.3.2 Key-Value类型"></a>4.3.2 Key-Value类型</h3><h4 id="4-3-2-1-对数据的提前处理"><a href="#4-3-2-1-对数据的提前处理" class="headerlink" title="4.3.2.1 对数据的提前处理"></a>4.3.2.1 对数据的提前处理</h4><p>（1）对于原数据为Tuple类型的情况：使用parallelizePairs()方法创建RDD</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO KV类型一般表示2元组</span></span><br><span class="line"><span class="comment">//  Spark RDD对整体数据的处理就称之为单值类型的数据处理</span></span><br><span class="line"><span class="comment">//  Spark RDD对KV数据个体的处理就称之为KV类型的数据处理：K和V不作为整体使用</span></span><br><span class="line">Tuple2&lt;String, Integer&gt; a = <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>);</span><br><span class="line">Tuple2&lt;String, Integer&gt; b = <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="number">2</span>);</span><br><span class="line">Tuple2&lt;String, Integer&gt; c = <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;c&quot;</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">//parallelizePairs()：表示从KV类型的集合中创建RDD</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; rdd = jsc.parallelizePairs(Arrays.asList(a, b, c));</span><br><span class="line"><span class="comment">//mapValues()：针对于(K,V)形式的类型只对V进行操作</span></span><br><span class="line">rdd.mapValues(v1 -&gt; v1 * <span class="number">2</span>).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(a,2)</span><br><span class="line">(b,4)</span><br><span class="line">(c,6)</span><br></pre></td></tr></table></figure>

<p>（2）对于原数据为单值类型的情况</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>));</span><br><span class="line"><span class="comment">// TODO 单值类型数据可以和KV类型进行转换</span></span><br><span class="line"><span class="comment">//   将单值类型转换为KV对</span></span><br><span class="line">rdd.mapToPair(v1 -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer,Integer&gt;(v1, v1))</span><br><span class="line">        .mapValues(v1 -&gt; v1 * <span class="number">2</span>)</span><br><span class="line">        .collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(1,2)</span><br><span class="line">(2,4)</span><br><span class="line">(3,6)</span><br><span class="line">(4,8)</span><br></pre></td></tr></table></figure>

<p>（3）对groupBy方法的补充说明</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line"><span class="comment">//TODO groupBy：按照指定的规则对数据进行分组</span></span><br><span class="line"><span class="comment">//          给每一个数据增加一个标记，相同的标记的数据会放置在一个组中，这个标记就是组名</span></span><br><span class="line"><span class="comment">//          groupBy的结果就是KV类型的数据</span></span><br><span class="line"><span class="comment">//按照奇偶进行分组</span></span><br><span class="line">JavaPairRDD&lt;Boolean, Iterable&lt;Integer&gt;&gt; rdd1 = rdd.groupBy(v1 -&gt; v1 % <span class="number">2</span> == <span class="number">0</span>);<span class="comment">//(false,[1,3])  (true,[2,4])</span></span><br><span class="line"><span class="comment">//再将每个分组中的所有V求和</span></span><br><span class="line">rdd1.mapValues(</span><br><span class="line">        iter -&gt; &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            Iterator&lt;Integer&gt; iterator = iter.iterator();</span><br><span class="line">            <span class="keyword">while</span> (iterator.hasNext())&#123;</span><br><span class="line">                <span class="type">Integer</span> <span class="variable">num</span> <span class="operator">=</span> iterator.next();</span><br><span class="line">                sum = sum + num;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> sum;</span><br><span class="line">        &#125;</span><br><span class="line">).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-04_16-14-35.png" alt="Snipaste_2024-06-04_16-14-35"></p>
<h4 id="4-3-2-2-mapValues-只对V进行操作"><a href="#4-3-2-2-mapValues-只对V进行操作" class="headerlink" title="4.3.2.2 mapValues()只对V进行操作"></a>4.3.2.2 mapValues()只对V进行操作</h4><h5 id="（1）语法-2"><a href="#（1）语法-2" class="headerlink" title="（1）语法"></a>（1）语法</h5><p>针对于(K,V)形式的类型只对V进行操作</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO KV类型一般表示2元组</span></span><br><span class="line"><span class="comment">//  Spark RDD对整体数据的处理就称之为单值类型的数据处理</span></span><br><span class="line"><span class="comment">//  Spark RDD对KV数据个体的处理就称之为KV类型的数据处理：K和V不作为整体使用</span></span><br><span class="line">Tuple2&lt;String, Integer&gt; a = <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>);</span><br><span class="line">Tuple2&lt;String, Integer&gt; b = <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="number">2</span>);</span><br><span class="line">Tuple2&lt;String, Integer&gt; c = <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;c&quot;</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">//parallelizePairs()：表示从KV类型的集合中创建RDD</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; rdd = jsc.parallelizePairs(Arrays.asList(a, b, c));</span><br><span class="line"><span class="comment">//mapValues()：针对于(K,V)形式的类型只对V进行操作</span></span><br><span class="line">rdd.mapValues(v1 -&gt; v1 * <span class="number">2</span>).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(a,2)</span><br><span class="line">(b,4)</span><br><span class="line">(c,6)</span><br></pre></td></tr></table></figure>

<h5 id="（2）wordCount"><a href="#（2）wordCount" class="headerlink" title="（2）wordCount"></a>（2）wordCount</h5><img src="Snipaste_2024-06-04_16-23-36.png" alt="Snipaste_2024-06-04_16-23-36" style="zoom:50%;">

<p>groupBy+mapValues</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO 分组聚合</span></span><br><span class="line"><span class="comment">//   1.读取文件</span></span><br><span class="line">JavaRDD&lt;String&gt; lineRDD = jsc.textFile(<span class="string">&quot;src/main/data/word.txt&quot;</span>);</span><br><span class="line"><span class="comment">//   2.将文件数据进行分解（扁平化）</span></span><br><span class="line">JavaRDD&lt;String&gt; wordRDD = lineRDD.flatMap(line -&gt; Arrays.asList(line.split(<span class="string">&quot; &quot;</span>)).iterator());</span><br><span class="line"><span class="comment">//   3.将相同的单词分到一个组中</span></span><br><span class="line">JavaPairRDD&lt;String, Iterable&lt;String&gt;&gt; wordGroupRDD = wordRDD.groupBy(word -&gt; word);</span><br><span class="line"><span class="comment">//   4.计算每个单词的组中的数量即可</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; wordCountRDD = wordGroupRDD.mapValues(</span><br><span class="line">        iter -&gt; &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (String s : iter) &#123;</span><br><span class="line">                len++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> len;</span><br><span class="line">        &#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">wordCountRDD.collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(Flink,1)</span><br><span class="line">(Hive,4)</span><br><span class="line">(Spark,2)</span><br><span class="line">(Flume,3)</span><br><span class="line">(Hadoop,5)</span><br></pre></td></tr></table></figure>

<h4 id="4-3-2-3-groupByKey-按照K重新分组"><a href="#4-3-2-3-groupByKey-按照K重新分组" class="headerlink" title="4.3.2.3 groupByKey()按照K重新分组"></a>4.3.2.3 groupByKey()按照K重新分组</h4><h5 id="（1）分组"><a href="#（1）分组" class="headerlink" title="（1）分组"></a>（1）分组</h5><p>groupByKey对每个key进行操作，但只生成一个seq，并不进行聚合。该操作可以指定分区器或者分区数（默认使用HashPartitioner）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO groupByKey方法作用是将KV类型的数据直接按照K对V进行分组，但不聚合</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; rdd = jsc.parallelizePairs(Arrays.asList(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="number">2</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">3</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="number">4</span>)</span><br><span class="line">));</span><br><span class="line">rdd.groupByKey().collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(a,[1, 3])</span><br><span class="line">(b,[2, 4])</span><br></pre></td></tr></table></figure>

<h5 id="（2）wordCount-1"><a href="#（2）wordCount-1" class="headerlink" title="（2）wordCount"></a>（2）wordCount</h5><p>groupByKey+mapValues</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">jsc.parallelizePairs(Arrays.asList(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">1</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>,<span class="number">2</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">3</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>,<span class="number">4</span>)</span><br><span class="line">)).groupByKey().mapValues(</span><br><span class="line">        iter -&gt; &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (Integer integer : iter) &#123;</span><br><span class="line">                sum += integer;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> sum;</span><br><span class="line">        &#125;</span><br><span class="line">).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(a,4)</span><br><span class="line">(b,6)</span><br></pre></td></tr></table></figure>

<h4 id="4-3-2-4-reduceByKey-按照K聚合V"><a href="#4-3-2-4-reduceByKey-按照K聚合V" class="headerlink" title="4.3.2.4 reduceByKey()按照K聚合V"></a>4.3.2.4 reduceByKey()按照K聚合V</h4><p>该操作可以将RDD[K,V]中的元素按照相同的K对V进行聚合。其存在多种重载形式，还可以设置新RDD的分区数。</p>
<h5 id="（1）语法-3"><a href="#（1）语法-3" class="headerlink" title="（1）语法"></a>（1）语法</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(a,4)</span><br><span class="line">(b,6)</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//另外一种简便写法（类名::方法名），在此处Integer::sum发挥了重要作用，这种分组聚合计算也可以计算max和min</span></span><br><span class="line">rdd.reduceByKey(Integer::sum).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(a,4)</span><br><span class="line">(b,6)</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.reduceByKey(Integer::max).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(a,3)</span><br><span class="line">(b,4)</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.reduceByKey(Integer::min).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(a,1)</span><br><span class="line">(b,2)</span><br></pre></td></tr></table></figure>

<h5 id="（2）wordCount-2"><a href="#（2）wordCount-2" class="headerlink" title="（2）wordCount"></a>（2）wordCount</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO 将分组聚合功能进行简化-reduceByKey</span></span><br><span class="line"><span class="comment">//   reduceByKey方法的作用：将KV类型的数据按照 K 对 V 进行reduce（将多个值聚合成一个值）操作</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; rdd = jsc.parallelizePairs(Arrays.asList(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="number">2</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">3</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="number">4</span>)</span><br><span class="line">));</span><br><span class="line">rdd.reduceByKey(</span><br><span class="line">        (v1,v2) -&gt; v1 + v2</span><br><span class="line">).collect().forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"><span class="comment">//另外一种简便写法（类名::方法名），在此处Integer::sum发挥了重要作用，这种分组聚合计算也可以计算max和min</span></span><br><span class="line">rdd.reduceByKey(Integer::sum).collect().forEach(System.out::println);</span><br><span class="line">rdd.reduceByKey(Integer::max).collect().forEach(System.out::println);</span><br><span class="line">rdd.reduceByKey(Integer::min).collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<h4 id="4-3-2-5-sortByKey-按照K进行排序"><a href="#4-3-2-5-sortByKey-按照K进行排序" class="headerlink" title="4.3.2.5  sortByKey()按照K进行排序"></a>4.3.2.5  sortByKey()按照K进行排序</h4><p>在一个(K,V)的RDD上调用，K必须实现Ordered接口，返回一个按照key进行排序的(K,V)的RDD </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;String, Integer&gt; rdd = jsc.parallelizePairs(Arrays.asList(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="number">2</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">3</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="number">4</span>)</span><br><span class="line">));</span><br><span class="line"></span><br><span class="line"><span class="comment">//TODO sortByKey方法</span></span><br><span class="line"><span class="comment">//     按照K排序，参数true升序，false降序</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; sortRDD = rdd.sortByKey();</span><br><span class="line">sortRDD.collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(a,1)</span><br><span class="line">(a,3)</span><br><span class="line">(b,2)</span><br><span class="line">(b,4)</span><br></pre></td></tr></table></figure>

<p>实现排序接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Transform_KV_sortByKey_1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaPairRDD&lt;User, Integer&gt; rdd = jsc.parallelizePairs(Arrays.asList(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">User</span>(<span class="number">30</span>, <span class="number">2000</span>), <span class="number">1</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">User</span>(<span class="number">40</span>, <span class="number">3000</span>), <span class="number">2</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">User</span>(<span class="number">30</span>, <span class="number">3000</span>), <span class="number">3</span>),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">User</span>(<span class="number">40</span>, <span class="number">2500</span>), <span class="number">4</span>)</span><br><span class="line">        ));</span><br><span class="line">        <span class="comment">//sortByKey方法要求数据中的K必须可以进行比较，实现Comparable接口</span></span><br><span class="line">        rdd.sortByKey().collect().forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span>,Comparable&lt;User&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="variable">age</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="variable">amount</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;User&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;age=&quot;</span> + age +</span><br><span class="line">                <span class="string">&quot;, amount=&quot;</span> + amount +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">User</span><span class="params">(<span class="type">int</span> age, <span class="type">int</span> amount)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">        <span class="built_in">this</span>.amount = amount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 方法返回值为整形数据，表示数据比较结果（状态）</span></span><br><span class="line"><span class="comment">     * 如果为大于0的整数，那么表示当前对象比其他的对象大</span></span><br><span class="line"><span class="comment">     * 如果为小于0的整数，那么表示当前对象比其他的对象小</span></span><br><span class="line"><span class="comment">     * 如果等于0，那么表示当前对象和其他的对象一样大</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(User other)</span> &#123;</span><br><span class="line">        <span class="comment">//按照年龄升序排序，如果年龄相同，再按照工资升序排序</span></span><br><span class="line"><span class="comment">//        return this.age - other.age;</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.age &lt; other.age)&#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.age &gt; other.age)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">this</span>.amount &lt; other.amount)&#123;</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.amount &gt; other.amount)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(User&#123;age=30, amount=2000&#125;,1)</span><br><span class="line">(User&#123;age=30, amount=3000&#125;,3)</span><br><span class="line">(User&#123;age=40, amount=2500&#125;,4)</span><br><span class="line">(User&#123;age=40, amount=3000&#125;,2)</span><br></pre></td></tr></table></figure>

<p>如何对kv对中的V进行</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;String, Integer&gt; rdd = jsc.parallelizePairs(Arrays.asList(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">4</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">2</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="number">9</span>)</span><br><span class="line">));</span><br><span class="line"><span class="comment">//由于sortByKey只能按照key进行排序，当我们key相同的时候，想要对V进行排序，可以按照如下方法做</span></span><br><span class="line"><span class="comment">//使用mapToPair方法将KV对的键值交换，并且使得输出还是KV格式，在按照key进行排序，再使用mapToPair将KV对的键值进行交换</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; rdd1 = rdd.mapToPair(</span><br><span class="line">        kv -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(kv._2, kv._1)</span><br><span class="line">).sortByKey().mapToPair(</span><br><span class="line">        kv -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(kv._2, kv._1)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">rdd1.collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(a,1)</span><br><span class="line">(a,2)</span><br><span class="line">(a,4)</span><br><span class="line">(a,9)</span><br></pre></td></tr></table></figure>

<h4 id="4-3-2-6-reduceByKey和groupByKey区别"><a href="#4-3-2-6-reduceByKey和groupByKey区别" class="headerlink" title="4.3.2.6 reduceByKey和groupByKey区别"></a>4.3.2.6 reduceByKey和groupByKey区别</h4><p>1）reduceByKey：按照key进行聚合，在shuffle之前有combine（预聚合）操作，返回结果是RDD[K,V]。</p>
<p>2）groupByKey：按照key进行分组，直接进行shuffle。</p>
<p>3）开发指导：在不影响业务逻辑的前提下，优先选用reduceByKey。求和操作不影响业务逻辑，求平均值影响业务逻辑。影响业务逻辑时建议先对数据类型进行转换再合并。</p>
<p><img src="Snipaste_2024-06-05_15-50-41.png" alt="Snipaste_2024-06-05_15-50-41"></p>
<p><img src="Snipaste_2024-06-05_15-51-23.png" alt="Snipaste_2024-06-05_15-51-23"></p>
<h2 id="4-4-WordCount程序在环境中执行"><a href="#4-4-WordCount程序在环境中执行" class="headerlink" title="4.4 WordCount程序在环境中执行"></a>4.4 WordCount程序在环境中执行</h2><p>（1）将项目打成jar包</p>
<p><img src="Snipaste_2024-06-05_15-59-29.png" alt="Snipaste_2024-06-05_15-59-29"></p>
<p>（2）将打包好的jar包SparkCore_plus-1.0-SNAPSHOT.jar上传到&#x2F;opt&#x2F;module&#x2F;spark&#x2F;examples&#x2F;jars&#x2F;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 jars]# ll</span><br><span class="line">总用量 1672</span><br><span class="line">-rw-r--r-- 1 110302528 wyh    78803 10月 15 2022 scopt_2.12-3.7.1.jar</span><br><span class="line">-rw-r--r-- 1 root      root   60468 6月   5 15:59 SparkCore_plus-1.0-SNAPSHOT.jar</span><br><span class="line">-rw-r--r-- 1 110302528 wyh  1567445 10月 15 2022 spark-examples_2.12-3.3.1.jar</span><br></pre></td></tr></table></figure>

<p>（3）执行程序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 spark]# bin/spark-submit --class operate.Spark01_Operate_Transform_KV_wordCount_2 --master yarn ./examples/jars/SparkCore_plus-1.0-SNAPSHOT.jar 10</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(b,6)</span><br><span class="line">(a,4)</span><br></pre></td></tr></table></figure>

<p>执行成功！</p>
<h2 id="4-5-Action行动算子"><a href="#4-5-Action行动算子" class="headerlink" title="4.5 Action行动算子"></a>4.5 Action行动算子</h2><p>行动算子是触发了整个作业的执行。因为转换算子都是懒加载，并不会立即执行。</p>
<h3 id="4-5-1-collect-以数组的形式返回数据集"><a href="#4-5-1-collect-以数组的形式返回数据集" class="headerlink" title="4.5.1 collect()以数组的形式返回数据集"></a>4.5.1 collect()以数组的形式返回数据集</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; mapRDD = rdd.map(v1 -&gt; &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;v1 = &quot;</span> + v1);</span><br><span class="line">    <span class="keyword">return</span> v1 * <span class="number">2</span>;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//TODO collect()方法就是RDD行动算子</span></span><br><span class="line"><span class="comment">//    RDD的行动算子会触发作业（Job）的执行</span></span><br><span class="line">mapRDD.collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">v1 = 1</span><br><span class="line">v1 = 3</span><br><span class="line">v1 = 2</span><br><span class="line">v1 = 4</span><br><span class="line">2</span><br><span class="line">4</span><br><span class="line">6</span><br><span class="line">8</span><br></pre></td></tr></table></figure>

<p><strong>注意：如果没有mapRDD.collect().forEach(System.out::println);语句，以上结果都不会打印出来，因为转换算子是懒加载，不会立即执行，只有行动算子才会触发作业的执行</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; mapRDD = rdd.map(v1 -&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> v1 * <span class="number">2</span>;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//TODO collect()方法就是RDD行动算子</span></span><br><span class="line"><span class="comment">//    RDD的行动算子会触发作业（Job）的执行</span></span><br><span class="line">mapRDD.collect();</span><br><span class="line">mapRDD.collect();</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">&quot;计算完毕&quot;</span>);</span><br><span class="line"><span class="comment">//https://localhost:4040</span></span><br><span class="line">Thread.sleep(<span class="number">100000L</span>);</span><br></pre></td></tr></table></figure>

<p>以上代码执行了两次collect()方法，在监控界面就可以看到两个job作业</p>
<p><img src="Snipaste_2024-06-06_15-41-58.png" alt="Snipaste_2024-06-06_15-41-58"></p>
<p><img src="Snipaste_2024-06-06_20-04-28.png" alt="Snipaste_2024-06-06_20-04-28"></p>
<p><img src="Snipaste_2024-06-06_20-05-03.png" alt="Snipaste_2024-06-06_20-05-03"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line"><span class="comment">//TODO Spark的计算全部都是在Executor端执行</span></span><br><span class="line"><span class="comment">//   Spark在编写代码时，调用转换算子，并不会真正执行，因为只是在Driver端组合功能</span></span><br><span class="line"><span class="comment">//   所以当前的代码其实就是在Driver端执行</span></span><br><span class="line"><span class="comment">//   所以当前main方法也称之为driver方法，当前运行main线程，也称之为Driver线程</span></span><br><span class="line"><span class="comment">//   转换算子中的逻辑代码是在Executor端执行的，并不会在Driver端调用和执行</span></span><br><span class="line"><span class="comment">//   RDD封装的逻辑其实就是转换算子中的逻辑</span></span><br><span class="line">JavaRDD&lt;Integer&gt; mapRDD = rdd.map(v1 -&gt; v1 * <span class="number">2</span>);</span><br><span class="line"><span class="comment">//TODO collect方法就是行动算子，会触发Job的执行</span></span><br><span class="line"><span class="comment">//     collect方法就是将Executor端执行的结果按照分区的顺序拉取（采集）回到Driver端，将结果组合成集合对象</span></span><br><span class="line"><span class="comment">//     collect方法可能会导致多个Executor的大量数据拉取到Driver端，导致内存溢出，生产环境慎用</span></span><br><span class="line">mapRDD.collect().forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<h3 id="4-5-2-count-返回RDD中元素个数"><a href="#4-5-2-count-返回RDD中元素个数" class="headerlink" title="4.5.2 count()返回RDD中元素个数"></a>4.5.2 count()返回RDD中元素个数</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; mapRDD = rdd.map(v1 -&gt; v1 * <span class="number">2</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; filterRDD = rdd.filter(v1 -&gt; v1 % <span class="number">2</span> == <span class="number">0</span>);</span><br><span class="line"><span class="comment">//TODO count获取结果数量</span></span><br><span class="line">System.out.println(rdd.count());<span class="comment">//4</span></span><br><span class="line">System.out.println(mapRDD.count());<span class="comment">//4</span></span><br><span class="line">System.out.println(filterRDD.count());<span class="comment">//2</span></span><br></pre></td></tr></table></figure>

<h3 id="4-5-3-first-返回RDD中的第一个元素"><a href="#4-5-3-first-返回RDD中的第一个元素" class="headerlink" title="4.5.3 first()返回RDD中的第一个元素"></a>4.5.3 first()返回RDD中的第一个元素</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; mapRDD = rdd.map(v1 -&gt; v1 * <span class="number">2</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; filterRDD = rdd.filter(v1 -&gt; v1 % <span class="number">2</span> != <span class="number">0</span>);</span><br><span class="line"><span class="comment">//TODO first获取结果的第一个</span></span><br><span class="line">System.out.println(rdd.first());<span class="comment">//1</span></span><br><span class="line">System.out.println(mapRDD.first());<span class="comment">//2</span></span><br><span class="line">System.out.println(filterRDD.first());<span class="comment">//1</span></span><br></pre></td></tr></table></figure>

<h3 id="4-5-4-take-返回由RDD前n个元素组成的数组"><a href="#4-5-4-take-返回由RDD前n个元素组成的数组" class="headerlink" title="4.5.4 take()返回由RDD前n个元素组成的数组"></a>4.5.4 take()返回由RDD前n个元素组成的数组</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; mapRDD = rdd.map(v1 -&gt; v1 * <span class="number">2</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; filterRDD = rdd.filter(v1 -&gt; v1 % <span class="number">2</span> != <span class="number">0</span>);</span><br><span class="line"><span class="comment">//TODO take从结果中获取前N个元素组成数据</span></span><br><span class="line">System.out.println(rdd.take(<span class="number">3</span>));<span class="comment">//[1, 2, 3]</span></span><br><span class="line">System.out.println(mapRDD.take(<span class="number">4</span>));<span class="comment">//[2, 4, 6, 8]</span></span><br><span class="line">System.out.println(filterRDD.take(<span class="number">2</span>));<span class="comment">//[1, 3]</span></span><br></pre></td></tr></table></figure>

<h3 id="4-5-5-countByKey-统计每种key的个数"><a href="#4-5-5-countByKey-统计每种key的个数" class="headerlink" title="4.5.5 countByKey()统计每种key的个数"></a>4.5.5 countByKey()统计每种key的个数</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;String, String&gt; rdd = jsc.parallelizePairs(Arrays.asList(</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;@234&quot;</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;233&quot;</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="string">&quot;$%%&amp;^&quot;</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;b&quot;</span>, <span class="string">&quot;(*)&amp;&quot;</span>),</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;c&quot;</span>, <span class="string">&quot;_+(&quot;</span>)</span><br><span class="line">));</span><br><span class="line"><span class="comment">//TODO countBuKey:将结果按照Key计算数量</span></span><br><span class="line">Map&lt;String, Long&gt; map = rdd.countByKey();</span><br><span class="line">System.out.println(map);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;a=2, b=2, c=1&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-5-6-save相关算子"><a href="#4-5-6-save相关算子" class="headerlink" title="4.5.6 save相关算子"></a>4.5.6 save相关算子</h3><h4 id="（1）saveAsTextFile-path-保存成Text文件"><a href="#（1）saveAsTextFile-path-保存成Text文件" class="headerlink" title="（1）saveAsTextFile(path)保存成Text文件"></a>（1）saveAsTextFile(path)保存成Text文件</h4><p>将数据集的元素以textfile的形式保存到HDFS文件系统或者其他支持的文件系统，对于每个元素，Spark将会调用toString方法，将它装换为文件中的文本</p>
<h4 id="（2）saveAsObjectFile-path-序列化成对象保存到文件"><a href="#（2）saveAsObjectFile-path-序列化成对象保存到文件" class="headerlink" title="（2）saveAsObjectFile(path) 序列化成对象保存到文件"></a>（2）saveAsObjectFile(path) 序列化成对象保存到文件</h4><p>用于将RDD中的元素序列化成对象，存储到文件中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">rdd.saveAsTextFile(<span class="string">&quot;output10&quot;</span>);</span><br><span class="line">rdd.saveAsObjectFile(<span class="string">&quot;output11&quot;</span>);</span><br></pre></td></tr></table></figure>

<h3 id="4-5-7-foreach-遍历RDD中每一个元素"><a href="#4-5-7-foreach-遍历RDD中每一个元素" class="headerlink" title="4.5.7 foreach()遍历RDD中每一个元素"></a>4.5.7 foreach()遍历RDD中每一个元素</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line"><span class="comment">//此处的foreach是spark中的行动算子，每次处理一个数据，分布式循环，在Executor端循环</span></span><br><span class="line">rdd.foreach(v1 -&gt; System.out.println(v1));<span class="comment">//1 3 2 4</span></span><br><span class="line"><span class="comment">//此处的forEach是java中的迭代器接口实现方法，单点循环</span></span><br><span class="line">rdd.collect().forEach(System.out::println);<span class="comment">//1 2 3 4</span></span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-10_10-05-25.png" alt="Snipaste_2024-06-10_10-05-25"></p>
<h3 id="4-5-8-foreachPartition-遍历RDD中每一个分区"><a href="#4-5-8-foreachPartition-遍历RDD中每一个分区" class="headerlink" title="4.5.8 foreachPartition ()遍历RDD中每一个分区"></a>4.5.8 foreachPartition ()遍历RDD中每一个分区</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line"><span class="comment">//此处的foreach是spark中的行动算子，每次处理一个数据，分布式循环，在Executor端循环，执行效率低，但是占内存比较小</span></span><br><span class="line">rdd.foreach(v1 -&gt; System.out.println(v1));<span class="comment">//1 3 2 4</span></span><br><span class="line"><span class="comment">//foreachPartition ()遍历RDD中每一个分区，每次处理一个分区中的所有数据，执行效率高，但是依托于内存大小</span></span><br><span class="line">rdd.foreachPartition(</span><br><span class="line">        iter -&gt; &#123;</span><br><span class="line">            <span class="keyword">while</span> (iter.hasNext())&#123;</span><br><span class="line">                System.out.print(iter.next());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">);<span class="comment">//3 4      </span></span><br><span class="line">  <span class="comment">//1 2</span></span><br></pre></td></tr></table></figure>

<h2 id="4-6-序列化"><a href="#4-6-序列化" class="headerlink" title="4.6 序列化"></a>4.6 序列化</h2><h3 id="4-6-1-序列化异常"><a href="#4-6-1-序列化异常" class="headerlink" title="4.6.1 序列化异常"></a>4.6.1 序列化异常</h3><p>在实际开发中我们往往需要自己定义一些对于RDD的操作，那么此时需要注意的是，初始化工作是在Driver端进行的，而实际运行程序是在Executor端进行的，这就涉及到了跨进程通信，是需要序列化的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Action_other</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line">        <span class="comment">//TODO 对象是在Driver端创建的</span></span><br><span class="line">        <span class="type">Student</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Student</span>();</span><br><span class="line">        rdd.foreach(</span><br><span class="line">                <span class="comment">//TODO 在Executor端循环遍历的时候使用到了Driver端对象</span></span><br><span class="line">                <span class="comment">//  运行过程中，就需要将Driver端的对象通过网络传递到Executor端，否则无法使用</span></span><br><span class="line">                <span class="comment">//  这里传输对象必须要实现可序列化接口，否则无法传递</span></span><br><span class="line">                v1 -&gt; System.out.println(s.age + v1)</span><br><span class="line"></span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Student</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="variable">age</span> <span class="operator">=</span> <span class="number">30</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="Snipaste_2024-06-10_16-40-22.png" alt="Snipaste_2024-06-10_16-40-22"></p>
<p><strong>RDD算子（方法）的逻辑代码是在Executor端执行的，其余的代码都是在Driver中执行的</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">33</span><br><span class="line">31</span><br><span class="line">34</span><br><span class="line">32</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Spark01_Operate_Action_other2</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaRDD&lt;String&gt; rdd = jsc.parallelize(Arrays.asList(<span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;Hive&quot;</span>, <span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Flink&quot;</span>), <span class="number">2</span>);</span><br><span class="line">        <span class="type">Search</span> <span class="variable">search</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Search</span>(<span class="string">&quot;H&quot;</span>);</span><br><span class="line">        search.match(rdd);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Search</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String query;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Search</span><span class="params">(String query)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.query = query;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">match</span><span class="params">(JavaRDD&lt;String&gt; rdd)</span>&#123;</span><br><span class="line">        rdd.filter(s -&gt; s.startsWith(query)==<span class="literal">true</span>).collect().forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hadoop</span><br><span class="line">Hive</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = jsc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>);</span><br><span class="line"><span class="comment">//写法1：不需要序列化</span></span><br><span class="line">rdd.foreach(v1 -&gt; System.out.println(v1));</span><br><span class="line"><span class="comment">//写法2：需要序列化，但是别人的类又序列化不了，所以这种写法不正确</span></span><br><span class="line"><span class="comment">//TODO JDK1.8的函数式编程其实采用的是对象模拟出来的</span></span><br><span class="line"><span class="comment">//rdd.foreach(System.out::println);</span></span><br></pre></td></tr></table></figure>

<h3 id="4-6-2-Kryo序列化框架"><a href="#4-6-2-Kryo序列化框架" class="headerlink" title="4.6.2 Kryo序列化框架"></a>4.6.2 Kryo序列化框架</h3><p>参考地址: <a target="_blank" rel="noopener" href="https://github.com/EsotericSoftware/kryo">https://github.com/EsotericSoftware/kryo</a></p>
<p>Java的序列化能够序列化任何的类。但是比较重，序列化后对象的体积也比较大。</p>
<p>Spark出于性能的考虑，Spark2.0开始支持另外一种Kryo序列化机制。Kryo速度是Serializable的10倍。当RDD在Shuffle数据的时候，简单数据类型、数组和字符串类型已经在Spark内部使用Kryo来序列化。</p>
<p>在pom中添加依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.esotericsoftware<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kryo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.0.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="4-7-依赖关系"><a href="#4-7-依赖关系" class="headerlink" title="4.7 依赖关系"></a>4.7 依赖关系</h2><h3 id="4-7-1-查看血缘关系"><a href="#4-7-1-查看血缘关系" class="headerlink" title="4.7.1 查看血缘关系"></a>4.7.1 查看血缘关系</h3><p>RDD只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列Lineage（血统）记录下来，以便恢复丢失的分区。RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p>
<p><img src="Snipaste_2024-06-12_14-54-43.png" alt="Snipaste_2024-06-12_14-54-43"></p>
<p><img src="Snipaste_2024-06-12_14-55-10.png" alt="Snipaste_2024-06-12_14-55-10"></p>
<h4 id="（1）打印血缘关系"><a href="#（1）打印血缘关系" class="headerlink" title="（1）打印血缘关系"></a>（1）打印血缘关系</h4><p>通过toDebugString()查看血缘关系</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Dep</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;HotCategoryTop10&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaRDD&lt;String&gt; dataRDD = jsc.textFile(<span class="string">&quot;src/main/data/user_visit_action.txt&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(dataRDD.toDebugString());</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;String&gt; filterRDD = dataRDD.filter(</span><br><span class="line">                line -&gt; &#123;</span><br><span class="line">                    String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">                    <span class="keyword">return</span> <span class="string">&quot;null&quot;</span>.equals(s[<span class="number">5</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(filterRDD.toDebugString());</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, HotCategory&gt; kvRDD = filterRDD.flatMap(</span><br><span class="line">                line -&gt; &#123;</span><br><span class="line">                    String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">                    <span class="keyword">if</span> (!<span class="string">&quot;-1&quot;</span>.equals(s[<span class="number">6</span>])) &#123;</span><br><span class="line">                        <span class="comment">//TODO 点击数据</span></span><br><span class="line">                        <span class="keyword">return</span> Arrays.asList(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(s[<span class="number">6</span>], <span class="number">1L</span>, <span class="number">0L</span>, <span class="number">0L</span>)).iterator();</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="string">&quot;null&quot;</span>.equals(s[<span class="number">8</span>])) &#123;</span><br><span class="line">                        <span class="comment">//TODO 下单数据</span></span><br><span class="line">                        String[] ids = s[<span class="number">8</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                        List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                        <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                            objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">1L</span>, <span class="number">0L</span>));</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> objs.iterator();</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">//TODO 支付数据</span></span><br><span class="line">                        String[] ids = s[<span class="number">10</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                        List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                        <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                            objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">0L</span>, <span class="number">1L</span>));</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> objs.iterator();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        ).mapToPair(</span><br><span class="line">                obj -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(obj.getId(), obj)</span><br><span class="line">        );</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(kvRDD.toDebugString());</span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, HotCategory&gt; objCountRDD = kvRDD.reduceByKey(</span><br><span class="line">                (obj1, obj2) -&gt; &#123;</span><br><span class="line">                    obj1.setClickCount(obj1.getClickCount() + obj2.getClickCount());</span><br><span class="line">                    obj1.setOrderCount(obj1.getOrderCount() + obj2.getOrderCount());</span><br><span class="line">                    obj1.setPayCount(obj1.getPayCount() + obj2.getPayCount());</span><br><span class="line">                    <span class="keyword">return</span> obj1;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(objCountRDD.toDebugString());</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;HotCategory&gt; mapRDD = objCountRDD.map(kv -&gt; kv._2);</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(mapRDD.toDebugString());</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;HotCategory&gt; sortByRDD = mapRDD.sortBy(obj -&gt; obj, <span class="literal">true</span>, <span class="number">2</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(sortByRDD.toDebugString());</span><br><span class="line"></span><br><span class="line">        sortByRDD.take(<span class="number">10</span>).forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">************************************</span><br><span class="line">(2) src/main/data/user_visit_action.txt MapPartitionsRDD[1] at textFile at Dep.java:32 []</span><br><span class="line"> |  src/main/data/user_visit_action.txt HadoopRDD[0] at textFile at Dep.java:32 []</span><br><span class="line">************************************</span><br><span class="line">(2) MapPartitionsRDD[2] at filter at Dep.java:36 []</span><br><span class="line"> |  src/main/data/user_visit_action.txt MapPartitionsRDD[1] at textFile at Dep.java:32 []</span><br><span class="line"> |  src/main/data/user_visit_action.txt HadoopRDD[0] at textFile at Dep.java:32 []</span><br><span class="line">************************************</span><br><span class="line">(2) MapPartitionsRDD[4] at mapToPair at Dep.java:69 []</span><br><span class="line"> |  MapPartitionsRDD[3] at flatMap at Dep.java:45 []</span><br><span class="line"> |  MapPartitionsRDD[2] at filter at Dep.java:36 []</span><br><span class="line"> |  src/main/data/user_visit_action.txt MapPartitionsRDD[1] at textFile at Dep.java:32 []</span><br><span class="line"> |  src/main/data/user_visit_action.txt HadoopRDD[0] at textFile at Dep.java:32 []</span><br><span class="line">************************************</span><br><span class="line">(2) ShuffledRDD[5] at reduceByKey at Dep.java:75 []</span><br><span class="line"> +-(2) MapPartitionsRDD[4] at mapToPair at Dep.java:69 []</span><br><span class="line">    |  MapPartitionsRDD[3] at flatMap at Dep.java:45 []</span><br><span class="line">    |  MapPartitionsRDD[2] at filter at Dep.java:36 []</span><br><span class="line">    |  src/main/data/user_visit_action.txt MapPartitionsRDD[1] at textFile at Dep.java:32 []</span><br><span class="line">    |  src/main/data/user_visit_action.txt HadoopRDD[0] at textFile at Dep.java:32 []</span><br><span class="line">************************************</span><br><span class="line">(2) MapPartitionsRDD[6] at map at Dep.java:86 []</span><br><span class="line"> |  ShuffledRDD[5] at reduceByKey at Dep.java:75 []</span><br><span class="line"> +-(2) MapPartitionsRDD[4] at mapToPair at Dep.java:69 []</span><br><span class="line">    |  MapPartitionsRDD[3] at flatMap at Dep.java:45 []</span><br><span class="line">    |  MapPartitionsRDD[2] at filter at Dep.java:36 []</span><br><span class="line">    |  src/main/data/user_visit_action.txt MapPartitionsRDD[1] at textFile at Dep.java:32 []</span><br><span class="line">    |  src/main/data/user_visit_action.txt HadoopRDD[0] at textFile at Dep.java:32 []</span><br><span class="line">************************************</span><br><span class="line">(2) MapPartitionsRDD[11] at sortBy at Dep.java:90 []</span><br><span class="line"> |  ShuffledRDD[10] at sortBy at Dep.java:90 []</span><br><span class="line"> +-(2) MapPartitionsRDD[7] at sortBy at Dep.java:90 []</span><br><span class="line">    |  MapPartitionsRDD[6] at map at Dep.java:86 []</span><br><span class="line">    |  ShuffledRDD[5] at reduceByKey at Dep.java:75 []</span><br><span class="line">    +-(2) MapPartitionsRDD[4] at mapToPair at Dep.java:69 []</span><br><span class="line">       |  MapPartitionsRDD[3] at flatMap at Dep.java:45 []</span><br><span class="line">       |  MapPartitionsRDD[2] at filter at Dep.java:36 []</span><br><span class="line">       |  src/main/data/user_visit_action.txt MapPartitionsRDD[1] at textFile at Dep.java:32 []</span><br><span class="line">       |  src/main/data/user_visit_action.txt HadoopRDD[0] at textFile at Dep.java:32 []</span><br></pre></td></tr></table></figure>

<h3 id="4-7-2-窄依赖和宽依赖"><a href="#4-7-2-窄依赖和宽依赖" class="headerlink" title="4.7.2 窄依赖和宽依赖"></a>4.7.2 窄依赖和宽依赖</h3><h4 id="（1）打印依赖关系"><a href="#（1）打印依赖关系" class="headerlink" title="（1）打印依赖关系"></a>（1）打印依赖关系</h4><p>通过rdd().dependencies()方法打印依赖关系</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Dep2</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;HotCategoryTop10&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaRDD&lt;String&gt; dataRDD = jsc.textFile(<span class="string">&quot;src/main/data/user_visit_action.txt&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(dataRDD.rdd().dependencies());<span class="comment">//List(org.apache.spark.OneToOneDependency@63538bb4)</span></span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;String&gt; filterRDD = dataRDD.filter(</span><br><span class="line">                line -&gt; &#123;</span><br><span class="line">                    String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">                    <span class="keyword">return</span> <span class="string">&quot;null&quot;</span>.equals(s[<span class="number">5</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(filterRDD.rdd().dependencies());<span class="comment">//List(org.apache.spark.OneToOneDependency@6504a875)</span></span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, HotCategory&gt; kvRDD = filterRDD.flatMap(</span><br><span class="line">                line -&gt; &#123;</span><br><span class="line">                    String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">                    <span class="keyword">if</span> (!<span class="string">&quot;-1&quot;</span>.equals(s[<span class="number">6</span>])) &#123;</span><br><span class="line">                        <span class="comment">//TODO 点击数据</span></span><br><span class="line">                        <span class="keyword">return</span> Arrays.asList(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(s[<span class="number">6</span>], <span class="number">1L</span>, <span class="number">0L</span>, <span class="number">0L</span>)).iterator();</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="string">&quot;null&quot;</span>.equals(s[<span class="number">8</span>])) &#123;</span><br><span class="line">                        <span class="comment">//TODO 下单数据</span></span><br><span class="line">                        String[] ids = s[<span class="number">8</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                        List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                        <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                            objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">1L</span>, <span class="number">0L</span>));</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> objs.iterator();</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">//TODO 支付数据</span></span><br><span class="line">                        String[] ids = s[<span class="number">10</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                        List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                        <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                            objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">0L</span>, <span class="number">1L</span>));</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> objs.iterator();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        ).mapToPair(</span><br><span class="line">                obj -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(obj.getId(), obj)</span><br><span class="line">        );</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(kvRDD.rdd().dependencies());<span class="comment">//List(org.apache.spark.OneToOneDependency@63a28987)</span></span><br><span class="line"></span><br><span class="line">        JavaPairRDD&lt;String, HotCategory&gt; objCountRDD = kvRDD.reduceByKey(</span><br><span class="line">                (obj1, obj2) -&gt; &#123;</span><br><span class="line">                    obj1.setClickCount(obj1.getClickCount() + obj2.getClickCount());</span><br><span class="line">                    obj1.setOrderCount(obj1.getOrderCount() + obj2.getOrderCount());</span><br><span class="line">                    obj1.setPayCount(obj1.getPayCount() + obj2.getPayCount());</span><br><span class="line">                    <span class="keyword">return</span> obj1;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(objCountRDD.rdd().dependencies());<span class="comment">//List(org.apache.spark.ShuffleDependency@4f4c88f9)</span></span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;HotCategory&gt; mapRDD = objCountRDD.map(kv -&gt; kv._2);</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(mapRDD.rdd().dependencies());<span class="comment">//List(org.apache.spark.OneToOneDependency@17410c07)</span></span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;HotCategory&gt; sortByRDD = mapRDD.sortBy(obj -&gt; obj, <span class="literal">true</span>, <span class="number">2</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;************************************&quot;</span>);</span><br><span class="line">        System.out.println(sortByRDD.rdd().dependencies());<span class="comment">//List(org.apache.spark.OneToOneDependency@6d33a66e)</span></span><br><span class="line"></span><br><span class="line">        sortByRDD.take(<span class="number">10</span>).forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="（2）窄依赖"><a href="#（2）窄依赖" class="headerlink" title="（2）窄依赖"></a>（2）窄依赖</h4><p>OneToOneDependency</p>
<p>RDD的依赖关系本质上并不是RDD对象的关系，说的是RDD对象中分区数据的关系</p>
<p>窄依赖表示每一个父RDD的Partition最多被子RDD的一个Partition使用（一对一or多对一），窄依赖我们形象的比喻为独生子女。</p>
<img src="Snipaste_2024-06-12_15-39-39.png" alt="Snipaste_2024-06-12_15-39-39" style="zoom:50%;">

<p><img src="Snipaste_2024-06-12_15-51-19.png" alt="Snipaste_2024-06-12_15-51-19"></p>
<h4 id="（3）宽依赖"><a href="#（3）宽依赖" class="headerlink" title="（3）宽依赖"></a>（3）宽依赖</h4><p>宽依赖表示同一个父RDD的Partition被多个子RDD的Partition依赖（只能是一对多），会引起Shuffle，总结：宽依赖我们形象的比喻为超生。</p>
<img src="Snipaste_2024-06-12_15-40-17.png" alt="Snipaste_2024-06-12_15-40-17" style="zoom:50%;">

<img src="Snipaste_2024-06-12_15-55-48.png" alt="Snipaste_2024-06-12_15-55-48" style="zoom:50%;">

<p>具有宽依赖的<em>transformations</em>包括：<em>sort</em>、<em>reduceByKey</em>、<em>groupByKey</em>、<em>join</em>和调用<em>rePartition</em>函数的任何操作。</p>
<p>宽依赖对Spark去评估一个transformations有更加重要的影响，比如对性能的影响。</p>
<p>在不影响业务要求的情况下，要尽量避免使用有宽依赖的转换算子，因为有宽依赖，就一定会走shuffle，影响性能。</p>
<h3 id="4-7-3-stage任务划分"><a href="#4-7-3-stage任务划分" class="headerlink" title="4.7.3 stage任务划分"></a>4.7.3 stage任务划分</h3><h4 id="（1）总述"><a href="#（1）总述" class="headerlink" title="（1）总述"></a>（1）总述</h4><p><img src="Snipaste_2024-06-12_16-41-22.png" alt="Snipaste_2024-06-12_16-41-22"></p>
<h4 id="（2）DAG有向无环图"><a href="#（2）DAG有向无环图" class="headerlink" title="（2）DAG有向无环图"></a>（2）DAG有向无环图</h4><p>DAG（Directed Acyclic Graph）有向无环图是由点和线组成的拓扑图形，该图形具有方向，不会闭环。例如，DAG记录了RDD的转换过程和任务的阶段。</p>
<h4 id="（3）任务运行的整体流程"><a href="#（3）任务运行的整体流程" class="headerlink" title="（3）任务运行的整体流程"></a>（3）任务运行的整体流程</h4><p><img src="Snipaste_2024-06-12_16-43-50.png" alt="Snipaste_2024-06-12_16-43-50"></p>
<p><img src="Snipaste_2024-06-12_16-44-15.png" alt="Snipaste_2024-06-12_16-44-15"></p>
<h4 id="（4）RDD任务切分中间分为：Application、Job、Stage和Task"><a href="#（4）RDD任务切分中间分为：Application、Job、Stage和Task" class="headerlink" title="（4）RDD任务切分中间分为：Application、Job、Stage和Task"></a>（4）RDD任务切分中间分为：Application、Job、Stage和Task</h4><p>Application：初始化一个SparkContext即生成一个Application；</p>
<p>Job：一个Action算子就会生成一个Job；</p>
<p>Stage：Stage等于宽依赖的个数加1；</p>
<p>Task：一个Stage阶段中，最后一个RDD的分区个数就是Task的个数。</p>
<p>注意：Application-&gt;Job-&gt;Stage-&gt;Task每一层都是1对n的关系。即一个Application对应多个Job，一个Job对应多个Stage，一个Stage对应多个Task</p>
<p><img src="Snipaste_2024-06-12_16-46-44.png" alt="Snipaste_2024-06-12_16-46-44"></p>
<h4 id="（5）例子"><a href="#（5）例子" class="headerlink" title="（5）例子"></a>（5）例子</h4><p>如下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Dep</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;HotCategoryTop10&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaRDD&lt;String&gt; dataRDD = jsc.textFile(<span class="string">&quot;src/main/data/user_visit_action.txt&quot;</span>);</span><br><span class="line">        JavaRDD&lt;String&gt; filterRDD = dataRDD.filter(</span><br><span class="line">                line -&gt; &#123;</span><br><span class="line">                    String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">                    <span class="keyword">return</span> <span class="string">&quot;null&quot;</span>.equals(s[<span class="number">5</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        JavaRDD&lt;HotCategory&gt; flatRDD = filterRDD.flatMap(</span><br><span class="line">                line -&gt; &#123;</span><br><span class="line">                    String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">                    <span class="keyword">if</span> (!<span class="string">&quot;-1&quot;</span>.equals(s[<span class="number">6</span>])) &#123;</span><br><span class="line">                        <span class="comment">//TODO 点击数据</span></span><br><span class="line">                        <span class="keyword">return</span> Arrays.asList(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(s[<span class="number">6</span>], <span class="number">1L</span>, <span class="number">0L</span>, <span class="number">0L</span>)).iterator();</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="string">&quot;null&quot;</span>.equals(s[<span class="number">8</span>])) &#123;</span><br><span class="line">                        <span class="comment">//TODO 下单数据</span></span><br><span class="line">                        String[] ids = s[<span class="number">8</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                        List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                        <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                            objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">1L</span>, <span class="number">0L</span>));</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> objs.iterator();</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">//TODO 支付数据</span></span><br><span class="line">                        String[] ids = s[<span class="number">10</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                        List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                        <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                            objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">0L</span>, <span class="number">1L</span>));</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> objs.iterator();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        JavaPairRDD&lt;String, HotCategory&gt; kvRDD = flatRDD.mapToPair(</span><br><span class="line">                obj -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(obj.getId(), obj)</span><br><span class="line">        );</span><br><span class="line">        JavaPairRDD&lt;String, HotCategory&gt; objCountRDD = kvRDD.reduceByKey(</span><br><span class="line">                (obj1, obj2) -&gt; &#123;</span><br><span class="line">                    obj1.setClickCount(obj1.getClickCount() + obj2.getClickCount());</span><br><span class="line">                    obj1.setOrderCount(obj1.getOrderCount() + obj2.getOrderCount());</span><br><span class="line">                    obj1.setPayCount(obj1.getPayCount() + obj2.getPayCount());</span><br><span class="line">                    <span class="keyword">return</span> obj1;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        JavaRDD&lt;HotCategory&gt; mapRDD = objCountRDD.map(kv -&gt; kv._2);</span><br><span class="line">        JavaRDD&lt;HotCategory&gt; sortByRDD = mapRDD.sortBy(obj -&gt; obj, <span class="literal">true</span>, <span class="number">2</span>);</span><br><span class="line">        sortByRDD.take(<span class="number">10</span>).forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Job个数</strong>：2个。解释：行动算子take()触发一个job，sortBy（或者sortByKey）这类的转换算子由于源码中调用该方法也会调用collect或者save等行动算子，所以sortBy（或者sotrByKey）也会触发一个job。</p>
<p><img src="Snipaste_2024-06-12_17-20-52.png" alt="Snipaste_2024-06-12_17-20-52"></p>
<p><strong>stage个数</strong>：宽依赖个数+1；对于job1，有两个stage；对于job0，有两个stage</p>
<img src="Snipaste_2024-06-12_17-24-19.png" alt="Snipaste_2024-06-12_17-24-19" style="zoom: 33%;">

<p>注意：如果存在shuffle过程，系统会自动进行缓存，UI界面显示skipped的部分。</p>
<img src="Snipaste_2024-06-12_17-25-49.png" alt="Snipaste_2024-06-12_17-25-49" style="zoom:33%;">

<p><strong>Task个数</strong>：一个Stage阶段中，最后一个RDD的分区个数就是Task的个数</p>
<p><img src="Snipaste_2024-06-12_17-33-30.png" alt="Snipaste_2024-06-12_17-33-30"></p>
<p><img src="Snipaste_2024-06-12_17-34-47.png" alt="Snipaste_2024-06-12_17-34-47"></p>
<p><img src="Snipaste_2024-06-12_17-36-10.png" alt="Snipaste_2024-06-12_17-36-10"></p>
<p><strong>任务（分区）的数量应该设定为多少?简单可以理解为就是资源核数，一旦推荐分区数量为资源核数的2~3倍</strong></p>
<h2 id="4-8-RDD持久化"><a href="#4-8-RDD持久化" class="headerlink" title="4.8 RDD持久化"></a>4.8 RDD持久化</h2><p>RDD不保存数据，如果同一个RDD重复使用的场合，那么数据就会从头执行，导致数据重复，计算重复</p>
<h3 id="4-8-1-RDD-Cache缓存"><a href="#4-8-1-RDD-Cache缓存" class="headerlink" title="4.8.1 RDD Cache缓存"></a>4.8.1 RDD Cache缓存</h3><p>RDD通过Cache或者Persist方法将前面的计算结果缓存，默认情况下会把数据以序列化的形式缓存在JVM的堆内存中。但是并不是这两个方法被调用时立即缓存，而是触发后面的action算子时，该RDD将会被缓存在计算节点的内存中，并供后面重用。</p>
<p><img src="Snipaste_2024-06-12_19-28-26.png" alt="Snipaste_2024-06-12_19-28-26"></p>
<p><strong>例子</strong>：不使用持久化方法，如果一个RDD重复使用，数据还会从头执行，导致数据重复，计算重复</p>
<p><img src="Snipaste_2024-06-12_19-30-18.png" alt="Snipaste_2024-06-12_19-30-18"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt; data = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">1</span>));</span><br><span class="line">data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>));</span><br><span class="line">data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">3</span>));</span><br><span class="line">data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">4</span>));</span><br><span class="line"></span><br><span class="line">JavaRDD&lt;Tuple2&lt;String, Integer&gt;&gt; rdd = jsc.parallelize(data, <span class="number">2</span>);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; mapRDD = rdd.mapToPair(</span><br><span class="line">        kv -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;*******************&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> kv;</span><br><span class="line">        &#125;</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; wordCountRDD = mapRDD.reduceByKey(Integer::sum);</span><br><span class="line">wordCountRDD.collect();</span><br><span class="line">System.out.println(<span class="string">&quot;计算1完毕&quot;</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;########################################&quot;</span>);</span><br><span class="line">JavaPairRDD&lt;String, Iterable&lt;Integer&gt;&gt; groupRDD = mapRDD.groupByKey();</span><br><span class="line">groupRDD.collect();</span><br><span class="line">System.out.println(<span class="string">&quot;计算2完毕&quot;</span>);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">计算1完毕</span><br><span class="line">########################################</span><br><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">计算2完毕</span><br></pre></td></tr></table></figure>

<p>使用cache方法，将数据保存到缓存中，后续操作可以直接使用，不再重复计算；在即将重复使用的交叉点（图中树的分叉节点）处，令即将重复使用的RDD调用cache()方法即可。</p>
<p><img src="Snipaste_2024-06-12_19-32-28.png" alt="Snipaste_2024-06-12_19-32-28"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt; data = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">1</span>));</span><br><span class="line">data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>));</span><br><span class="line">data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">3</span>));</span><br><span class="line">data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">4</span>));</span><br><span class="line"></span><br><span class="line">JavaRDD&lt;Tuple2&lt;String, Integer&gt;&gt; rdd = jsc.parallelize(data, <span class="number">2</span>);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; mapRDD = rdd.mapToPair(</span><br><span class="line">        kv -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;*******************&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> kv;</span><br><span class="line">        &#125;</span><br><span class="line">);</span><br><span class="line">mapRDD.cache();</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; wordCountRDD = mapRDD.reduceByKey(Integer::sum);</span><br><span class="line">wordCountRDD.collect();</span><br><span class="line">System.out.println(<span class="string">&quot;计算1完毕&quot;</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;########################################&quot;</span>);</span><br><span class="line">JavaPairRDD&lt;String, Iterable&lt;Integer&gt;&gt; groupRDD = mapRDD.groupByKey();</span><br><span class="line">groupRDD.collect();</span><br><span class="line">System.out.println(<span class="string">&quot;计算2完毕&quot;</span>);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">*******************</span><br><span class="line">计算1完毕</span><br><span class="line">########################################</span><br><span class="line">计算2完毕</span><br></pre></td></tr></table></figure>

<h3 id="4-8-2-RDD-persist缓存"><a href="#4-8-2-RDD-persist缓存" class="headerlink" title="4.8.2 RDD persist缓存"></a>4.8.2 RDD persist缓存</h3><p><img src="Snipaste_2024-06-15_13-57-52.png" alt="Snipaste_2024-06-15_13-57-52"></p>
<p>cache底层调用的就是persist方法,缓存级别默认用的是MEMORY_ONLY，也就是cache()方法等同于persist(StorageLevel.MEMORY_ONLY())</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mapRDD.cache();</span><br><span class="line">mapRDD.persist(StorageLevel.MEMORY_ONLY());</span><br></pre></td></tr></table></figure>

<p>查看源码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> <span class="type">NONE</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">DISK_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">DISK_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">DISK_ONLY_3</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">MEMORY_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">MEMORY_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">MEMORY_AND_DISK</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">val</span> <span class="type">OFF_HEAP</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>注意：默认的存储级别都是仅在内存存储一份。在存储级别的末尾加上“_2”表示持久化的数据存为两份。SER：表示序列化。</p>
<p><img src="Snipaste_2024-06-15_13-45-49.png" alt="Snipaste_2024-06-15_13-45-49"></p>
<p>缓存有可能丢失，或者存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列转换，丢失的数据会被重算，由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。</p>
<p>Spark会自动对一些Shuffle操作的中间数据做持久化操作（比如：reduceByKey）。这样做的目的是为了当一个节点Shuffle失败了避免重新计算整个输入。但是，在实际使用的时候，如果想重用数据，仍然建议调用persist或cache。如下图，灰色部分代表跳过，说明reduceByKey是从缓存中取的RDD数据</p>
<img src="Snipaste_2024-06-12_17-24-19-17184310067242.png" alt="Snipaste_2024-06-12_17-24-19" style="zoom: 33%;">

<h3 id="4-8-3-RDD-CheckPoint检查点"><a href="#4-8-3-RDD-CheckPoint检查点" class="headerlink" title="4.8.3 RDD CheckPoint检查点"></a>4.8.3 RDD CheckPoint检查点</h3><h4 id="（1）检查点概述"><a href="#（1）检查点概述" class="headerlink" title="（1）检查点概述"></a>（1）检查点概述</h4><p><img src="Snipaste_2024-06-16_11-18-34.png" alt="Snipaste_2024-06-16_11-18-34"></p>
<p>1）检查点：是通过将RDD中间结果写入磁盘。</p>
<p>2）为什么要做检查点？</p>
<p>由于血缘依赖过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果检查点之后有节点出现问题，可以从检查点开始重做血缘，减少了开销。</p>
<p>3）检查点存储路径：Checkpoint的数据通常是存储在HDFS等容错、高可用的文件系统</p>
<p>4）检查点数据存储格式为：二进制的文件</p>
<p>5）检查点切断血缘：在Checkpoint的过程中，该RDD的所有依赖于父RDD中的信息将全部被移除。</p>
<p>6）检查点触发时间：对RDD进行Checkpoint操作并不会马上被执行，必须执行Action操作才能触发。但是检查点为了数据安全，会从血缘关系的最开始执行一遍。</p>
<p><img src="Snipaste_2024-06-16_11-21-34.png" alt="Snipaste_2024-06-16_11-21-34"></p>
<p><img src="Snipaste_2024-06-16_11-22-15.png" alt="Snipaste_2024-06-16_11-22-15"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Dep4_checkpoint</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line">        <span class="comment">//TODO 设定检查点路径：推荐HDFS共享文件系统，也可以使用本地文件路径</span></span><br><span class="line">        jsc.setCheckpointDir(<span class="string">&quot;cp&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt; data = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">1</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">3</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">4</span>));</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Tuple2&lt;String, Integer&gt;&gt; rdd = jsc.parallelize(data, <span class="number">2</span>);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; mapRDD = rdd.mapToPair(</span><br><span class="line">                kv -&gt; &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;*******************&quot;</span>);</span><br><span class="line">                    <span class="keyword">return</span> kv;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        <span class="comment">//TODO 设置检查点，检查点操作的目的是希望RDD结果长时间的保存，所以需要保证数据的安全，会从头再跑一边，</span></span><br><span class="line">        <span class="comment">//  所以性能比较低，未来提高效率，spark推荐在检查点之前，执行cache方法，将数据缓存</span></span><br><span class="line">        mapRDD.cache();</span><br><span class="line">        mapRDD.checkpoint();</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; wordCountRDD = mapRDD.reduceByKey(Integer::sum);</span><br><span class="line">        wordCountRDD.collect();</span><br><span class="line">        System.out.println(<span class="string">&quot;计算1完毕&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;########################################&quot;</span>);</span><br><span class="line">        JavaPairRDD&lt;String, Iterable&lt;Integer&gt;&gt; groupRDD = mapRDD.groupByKey();</span><br><span class="line">        groupRDD.collect();</span><br><span class="line">        System.out.println(<span class="string">&quot;计算2完毕&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-16_11-37-39.png" alt="Snipaste_2024-06-16_11-37-39" style="zoom:50%;">

<h4 id="（2）缓存和检查点区别"><a href="#（2）缓存和检查点区别" class="headerlink" title="（2）缓存和检查点区别"></a>（2）缓存和检查点区别</h4><p>（1）Cache缓存只是将数据保存起来，不切断血缘依赖。Checkpoint检查点切断血缘依赖。</p>
<p>（2）Cache缓存的数据通常存储在磁盘、内存等地方，可靠性低。Checkpoint的数据通常存储在HDFS等容错、高可用的文件系统，可靠性高。</p>
<p>（3）建议对checkpoint()的RDD使用Cache缓存，这样checkpoint的job只需从Cache缓存中读取数据即可，否则需要再从头计算一次RDD。</p>
<p>（4）如果使用完了缓存，可以通过unpersist()方法释放缓存。</p>
<p><img src="Snipaste_2024-06-16_11-43-22.png" alt="Snipaste_2024-06-16_11-43-22"></p>
<h4 id="（3）检查点存储到HDFS集群"><a href="#（3）检查点存储到HDFS集群" class="headerlink" title="（3）检查点存储到HDFS集群"></a>（3）检查点存储到HDFS集群</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 修改用户名称</span></span><br><span class="line">System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>,<span class="string">&quot;atguigu&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.创建配置对象</span></span><br><span class="line"><span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 创建sparkContext</span></span><br><span class="line"><span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 需要设置路径.需要提前在HDFS集群上创建/checkpoint路径</span></span><br><span class="line">jsc.setCheckpointDir(<span class="string">&quot;hdfs://hadoop102:8020/checkpoint&quot;</span>);</span><br></pre></td></tr></table></figure>

<h2 id="4-9-键值对RDD数据分区"><a href="#4-9-键值对RDD数据分区" class="headerlink" title="4.9 键值对RDD数据分区"></a>4.9 键值对RDD数据分区</h2><p>Spark目前支持Hash分区、Range分区和用户自定义分区。Hash分区为当前的默认分区。分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle后进入哪个分区和Reduce的个数。</p>
<p>（1）只有Key-Value类型的pairRDD才有分区器，非Key-Value类型的RDD分区的值是None</p>
<p>（2）每个RDD的分区ID范围：0~numPartitions-1，决定这个值是属于那个分区的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Part</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt; data = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">1</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">2</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">3</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;a&quot;</span>,<span class="number">4</span>));</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Tuple2&lt;String, Integer&gt;&gt; rdd = jsc.parallelize(data, <span class="number">3</span>);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; mapRDD = rdd.mapToPair(kv -&gt; kv);</span><br><span class="line">        <span class="comment">// 获取分区器</span></span><br><span class="line">        System.out.println(mapRDD.partitioner());<span class="comment">//Optional.empty</span></span><br><span class="line">        mapRDD.saveAsTextFile(<span class="string">&quot;mapRDD_out&quot;</span>);</span><br><span class="line">        <span class="comment">//part-00000:(a,1)</span></span><br><span class="line">        <span class="comment">//part-00001:(a,2)</span></span><br><span class="line">        <span class="comment">//part-00002:(a,3),(a,4)</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; reduceRDD = mapRDD.reduceByKey(Integer::sum);</span><br><span class="line">        <span class="comment">// 获取分区器</span></span><br><span class="line">        System.out.println(reduceRDD.partitioner());<span class="comment">//Optional[org.apache.spark.HashPartitioner@3]</span></span><br><span class="line">        reduceRDD.saveAsTextFile(<span class="string">&quot;reduceRDD_out&quot;</span>);</span><br><span class="line">        <span class="comment">//part-00000:空</span></span><br><span class="line">        <span class="comment">//part-00001:(a,10)</span></span><br><span class="line">        <span class="comment">//part-00002:空</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 数据分区的规则</span></span><br><span class="line">        <span class="comment">//  计算后数据所在的分区是通过Spark的内部计算（分区规则）完成的，尽可能让数据均衡（散列）一些，但是不是平均分</span></span><br><span class="line">        <span class="comment">//TODO reduceByKey方法需要传递两个参数</span></span><br><span class="line">        <span class="comment">//   1.第一个参数表示数据分区的逻辑，参数可以不用传递，使用时，会使用默认的分区规则：HashPartitioner</span></span><br><span class="line">        <span class="comment">//    HashPartitioner中有getPartition一个方法，getPartition需要传递一个参数Key，然后方法需要返回一个值，表示分区编号，分区编号从0开始</span></span><br><span class="line">        <span class="comment">//    逻辑：分区编号  &lt;= Key.hashCode % partNum（哈希取余）</span></span><br><span class="line">        <span class="comment">//   2.第二个参数表示数据聚合的逻辑</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4-9-1-Hash分区"><a href="#4-9-1-Hash分区" class="headerlink" title="4.9.1  Hash分区"></a>4.9.1  Hash分区</h3><p><img src="Snipaste_2024-06-16_18-06-27.png" alt="Snipaste_2024-06-16_18-06-27"></p>
<h3 id="4-9-2-Range分区"><a href="#4-9-2-Range分区" class="headerlink" title="4.9.2 Range分区"></a>4.9.2 Range分区</h3><p><img src="Snipaste_2024-06-16_18-06-49.png" alt="Snipaste_2024-06-16_18-06-49"></p>
<h3 id="4-9-3-自定义分区"><a href="#4-9-3-自定义分区" class="headerlink" title="4.9.3 自定义分区"></a>4.9.3 自定义分区</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Part_1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        ArrayList&lt;Tuple2&lt;String, Integer&gt;&gt; data = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;nba&quot;</span>,<span class="number">1</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;cba&quot;</span>,<span class="number">2</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;nba&quot;</span>,<span class="number">3</span>));</span><br><span class="line">        data.add(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="string">&quot;wnba&quot;</span>,<span class="number">4</span>));</span><br><span class="line"></span><br><span class="line">        JavaRDD&lt;Tuple2&lt;String, Integer&gt;&gt; rdd = jsc.parallelize(data, <span class="number">3</span>);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; mapRDD = rdd.mapToPair(kv -&gt; kv);</span><br><span class="line">        <span class="comment">//自定义分区</span></span><br><span class="line">        mapRDD.reduceByKey(<span class="keyword">new</span> <span class="title class_">MyPartitioner</span>(<span class="number">3</span>),Integer::sum).saveAsTextFile(<span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//TODO 自定义分区器</span></span><br><span class="line"><span class="comment">// 1.创建自定义类</span></span><br><span class="line"><span class="comment">// 2.继承抽象类Partitioner</span></span><br><span class="line"><span class="comment">// 3.重写方法</span></span><br><span class="line"><span class="comment">// 4.构建对象，在算子中使用</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyPartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> numPartitions;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyPartitioner</span><span class="params">(<span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.numPartitions = numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//TODO 指定分区的数量</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">numPartitions</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//根据数据的Key来获取数据存储的分区编号，编号从0开始</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Object key)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;nba&quot;</span>.equals(key))&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;wnba&quot;</span>.equals(key))&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object o)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span> == o) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (!(o <span class="keyword">instanceof</span> MyPartitioner)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="type">MyPartitioner</span> <span class="variable">that</span> <span class="operator">=</span> (MyPartitioner) o;</span><br><span class="line">        <span class="keyword">return</span> numPartitions == that.numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hashCode</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Objects.hash(numPartitions);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-16_18-21-24.png" alt="Snipaste_2024-06-16_18-21-24" style="zoom:50%;">

<h2 id="4-10-SparkUI的查看"><a href="#4-10-SparkUI的查看" class="headerlink" title="4.10 SparkUI的查看"></a>4.10 SparkUI的查看</h2><p>job相关：</p>
<ul>
<li>多一段sql多一个job</li>
<li>多一个广播多一个job</li>
<li>扫描分区大于32个，也会多一个job，用于读取全部分区文件的HDFS路径存储到Driver中</li>
</ul>
<p>stage相关：</p>
<ul>
<li>stage数&#x3D;宽依赖数+n（读表数量），分为MapStage（只有Shuffle Write，即读表过程）和ReduceStage（有Shuffle Read）</li>
<li>MapStage中的task数&#x3D;128切片数，小文件情况（与MapReduce的task数意义相同）</li>
<li>ReduceStage中的task数 &#x3D; <code>spark.sql.shuffle.partitions = 200</code>（默认值）（与MapReduce的task数意义相同）</li>
</ul>
<p><img src="image.png" alt="image"></p>
<p>![image (1)](Flink框架学习笔记&#x2F;image (1).png)</p>
<p>![image (2)](Flink框架学习笔记&#x2F;image (2).png)</p>
<p>查看DAG：</p>
<img src="image (3).png" alt="image (3)" style="zoom:33%;">

<p>定位问题所在点：</p>
<p>步骤1：点击stage按钮，将所有stage进行运行时间的倒序排列，查看只有shuffle Read且耗时较长的stage3</p>
<p>![image (4)](Flink框架学习笔记&#x2F;image (4).png)</p>
<p> 点击stage3可以看到出现了一个长尾task，再次印证stage3是一个倾斜的stage，具体位置是job0的stage3</p>
<p>![image (5)](Flink框架学习笔记&#x2F;image (5).png)</p>
<img src="image (6).png" alt="image (6)" style="zoom:33%;">

<p> 点开sql页面，找到对应job0的DAG图</p>
<p>![image (7)](Flink框架学习笔记&#x2F;image (7).png)</p>
<p> 在DAG页面搜索stage Id为3的阶段，处于哪个算子中，该stage做了什么样的数据操作，从而知道sql语句中倾斜的位置在哪里，做数据探查查看数据内容判断出现哪种倾斜，进行有针对性的优化。</p>
<h1 id="第五章-广播变量"><a href="#第五章-广播变量" class="headerlink" title="第五章 广播变量"></a>第五章 广播变量</h1><p>广播变量：分布式共享只读变量。</p>
<p>广播变量用来高效分发较大的对象。向所有工作节点发送一个较大的只读值，以供一个或多个Spark Task操作使用。比如，如果你的应用需要向所有节点发送一个较大的只读查询表，广播变量用起来会很顺手。在多个Task并行操作中使用同一个变量，但是Spark会为每个Task任务分别发送。</p>
<h2 id="5-1-使用广播变量的步骤"><a href="#5-1-使用广播变量的步骤" class="headerlink" title="5.1 使用广播变量的步骤"></a>5.1 使用广播变量的步骤</h2><p>（1）调用SparkContext.broadcast（广播变量）创建出一个广播对象，任何可序列化的类型都可以这么实现。</p>
<p>（2）通过广播变量.value，访问该对象的值。</p>
<p>（3）广播变量只会被发到各个节点一次，作为只读值处理（修改这个值不会影响到别的节点）。</p>
<h2 id="5-2-例子"><a href="#5-2-例子" class="headerlink" title="5.2 例子"></a>5.2 例子</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BC_1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkCore&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        JavaRDD&lt;String&gt; rdd = jsc.parallelize(Arrays.asList(<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>, <span class="string">&quot;Flink&quot;</span>, <span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>));</span><br><span class="line">        List&lt;String&gt; okList = Arrays.asList(<span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;Hadoop&quot;</span>);</span><br><span class="line">        <span class="comment">//TODO 默认数据传输以Task为单位进行传输，如果想要以Executor为单位进行传输，需要进行包装</span></span><br><span class="line">        Broadcast&lt;List&lt;String&gt;&gt; broadcast = jsc.broadcast(okList);</span><br><span class="line">        JavaRDD&lt;String&gt; filterRDD = rdd.filter(</span><br><span class="line">                s -&gt; broadcast.value().contains(s)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        filterRDD.collect().forEach(System.out::println);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Spark</span><br><span class="line">Hadoop</span><br><span class="line">Spark</span><br><span class="line">Hadoop</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-16_23-12-38.png" alt="Snipaste_2024-06-16_23-12-38" style="zoom:50%;">

<h1 id="第六章-SparkCore实战"><a href="#第六章-SparkCore实战" class="headerlink" title="第六章 SparkCore实战"></a>第六章 SparkCore实战</h1><h2 id="6-1-数据准备"><a href="#6-1-数据准备" class="headerlink" title="6.1 数据准备"></a>6.1 数据准备</h2><p>（1）数据格式</p>
<p><img src="Snipaste_2024-06-11_15-37-56.png" alt="Snipaste_2024-06-11_15-37-56"></p>
<p>（2）数据详细字段说明</p>
<table>
<thead>
<tr>
<th>编号</th>
<th>字段名称</th>
<th>字段类型</th>
<th>字段含义</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>date</td>
<td>String</td>
<td>用户点击行为的日期</td>
</tr>
<tr>
<td>2</td>
<td>user_id</td>
<td>Long</td>
<td>用户的ID</td>
</tr>
<tr>
<td>3</td>
<td>session_id</td>
<td>String</td>
<td>Session的ID（会话ID）</td>
</tr>
<tr>
<td>4</td>
<td>page_id</td>
<td>Long</td>
<td>某个页面的ID</td>
</tr>
<tr>
<td>5</td>
<td>action_time</td>
<td>String</td>
<td>动作的时间点</td>
</tr>
<tr>
<td>6</td>
<td>search_keyword</td>
<td>String</td>
<td>用户搜索的关键词</td>
</tr>
<tr>
<td>7</td>
<td>click_category_id</td>
<td>Long</td>
<td>点击某一个商品品类的ID</td>
</tr>
<tr>
<td>8</td>
<td>click_product_id</td>
<td>Long</td>
<td>某一个商品的ID</td>
</tr>
<tr>
<td>9</td>
<td>order_category_ids</td>
<td>String</td>
<td>一次订单中所有品类的ID集合</td>
</tr>
<tr>
<td>10</td>
<td>order_product_ids</td>
<td>String</td>
<td>一次订单中所有商品的ID集合</td>
</tr>
<tr>
<td>11</td>
<td>pay_category_ids</td>
<td>String</td>
<td>一次支付中所有品类的ID集合</td>
</tr>
<tr>
<td>12</td>
<td>pay_product_ids</td>
<td>String</td>
<td>一次支付中所有商品的ID集合</td>
</tr>
<tr>
<td>13</td>
<td>city_id</td>
<td>Long</td>
<td>城市 id</td>
</tr>
</tbody></table>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tmp <span class="keyword">as</span> (</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span>,</span><br><span class="line">	<span class="keyword">case</span> <span class="keyword">when</span> search_keyword <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="string">&#x27;搜索&#x27;</span></span><br><span class="line">     	 <span class="keyword">when</span> click_category_id <span class="operator">!=</span> <span class="number">-1</span> <span class="keyword">or</span> click_product_id <span class="operator">!=</span> <span class="number">-1</span> <span class="keyword">then</span> <span class="string">&#x27;点击&#x27;</span></span><br><span class="line">         <span class="keyword">when</span> order_category_ids <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">or</span> order_product_ids <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="string">&#x27;下单&#x27;</span></span><br><span class="line">         <span class="keyword">when</span> pay_category_ids <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">or</span> pay_product_ids <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span> <span class="keyword">then</span> <span class="string">&#x27;支付&#x27;</span></span><br><span class="line">         <span class="keyword">else</span> <span class="string">&#x27;其他&#x27;</span></span><br><span class="line">    <span class="keyword">end</span> <span class="keyword">as</span> action_type</span><br><span class="line"><span class="keyword">from</span> t</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">select</span> click_category_id,</span><br><span class="line">       <span class="built_in">sum</span>(<span class="keyword">case</span> <span class="keyword">when</span> action_type <span class="keyword">in</span> (<span class="string">&#x27;点击&#x27;</span>) <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) <span class="keyword">as</span> click_num,</span><br><span class="line">       <span class="built_in">sum</span>(<span class="keyword">case</span> <span class="keyword">when</span> action_type <span class="keyword">in</span> (<span class="string">&#x27;下单&#x27;</span>) <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) <span class="keyword">as</span> order_num,</span><br><span class="line">       <span class="built_in">sum</span>(<span class="keyword">case</span> <span class="keyword">when</span> action_type <span class="keyword">in</span> (<span class="string">&#x27;支付&#x27;</span>) <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span>) <span class="keyword">as</span> pay_num</span><br><span class="line"><span class="keyword">from</span> t</span><br><span class="line"><span class="keyword">where</span> action_type <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&#x27;搜索&#x27;</span>)</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> click_category_id</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> click_num,order_num,pay_num <span class="keyword">desc</span></span><br><span class="line">limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

<h2 id="6-2-需求：Top10热门品类"><a href="#6-2-需求：Top10热门品类" class="headerlink" title="6.2 需求：Top10热门品类"></a>6.2 需求：Top10热门品类</h2><p>需求说明：品类是指产品的分类，大型电商网站品类分多级，咱们的项目中品类只有一级，不同的公司可能对热门的定义不一样。我们按照每个品类的点击、下单、支付的量（次数）来统计热门品类。</p>
<p>鞋			点击数 下单数  支付数</p>
<p>衣服		点击数 下单数  支付数</p>
<p>电脑		点击数 下单数  支付数</p>
<p>例如，综合排名 &#x3D; 点击数*20% + 下单数*30% + 支付数*50%</p>
<p>为了更好的泛用性，当前案例按照点击次数进行排序，如果点击相同，按照下单数，如果下单还是相同，按照支付数。</p>
<h3 id="6-2-1-需求分析"><a href="#6-2-1-需求分析" class="headerlink" title="6.2.1 需求分析"></a>6.2.1 需求分析</h3><p><img src="Snipaste_2024-06-11_16-38-37.png" alt="Snipaste_2024-06-11_16-38-37"></p>
<h3 id="6-2-2-需求实现"><a href="#6-2-2-需求实现" class="headerlink" title="6.2.2 需求实现"></a>6.2.2 需求实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HotCategoryTop10</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;HotCategoryTop10&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建sparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//TODO 将文件作为数据源，对接RDD</span></span><br><span class="line">        <span class="comment">//     如果当前环境是Tarn，那么相对路径指向的是HDFS</span></span><br><span class="line">        JavaRDD&lt;String&gt; dataRDD = jsc.textFile(<span class="string">&quot;src/main/data/user_visit_action.txt&quot;</span>);</span><br><span class="line">        <span class="comment">//TODO 需求分析</span></span><br><span class="line">        <span class="comment">//  热门（点击数量、下单数量、支付数量）品类Top10</span></span><br><span class="line">        <span class="comment">//  1.对同一个品类的不同行为进行统计，对同一个品类的数据进行分组（点击、下单、支付）</span></span><br><span class="line">        <span class="comment">//  2.对统计结果进行排序</span></span><br><span class="line">        <span class="comment">//  3.对排序后的结果取前10条</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 开发</span></span><br><span class="line">        <span class="comment">//TODO 1.将多余的数据进行过滤处理</span></span><br><span class="line">        JavaRDD&lt;String&gt; filterRDD = dataRDD.filter(</span><br><span class="line">                line -&gt; &#123;</span><br><span class="line">                    String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">                    <span class="keyword">return</span> <span class="string">&quot;null&quot;</span>.equals(s[<span class="number">5</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        <span class="comment">//TODO 2.将过滤后的数据进行分组统计</span></span><br><span class="line">        <span class="comment">//       将过滤后的数据进行结构的转变：（品类,（品类,0,1,0））</span></span><br><span class="line">        <span class="comment">//       flatMap方法要求：传递一个参数，返回一个迭代器</span></span><br><span class="line">        JavaPairRDD&lt;String, HotCategory&gt; kvRDD = filterRDD.flatMap(</span><br><span class="line">                line -&gt; &#123;</span><br><span class="line">                    String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">                    <span class="keyword">if</span> (!<span class="string">&quot;-1&quot;</span>.equals(s[<span class="number">6</span>])) &#123;</span><br><span class="line">                        <span class="comment">//TODO 点击数据</span></span><br><span class="line">                        <span class="keyword">return</span> Arrays.asList(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(s[<span class="number">6</span>], <span class="number">1L</span>, <span class="number">0L</span>, <span class="number">0L</span>)).iterator();</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="string">&quot;null&quot;</span>.equals(s[<span class="number">8</span>])) &#123;</span><br><span class="line">                        <span class="comment">//TODO 下单数据</span></span><br><span class="line">                        String[] ids = s[<span class="number">8</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                        List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                        <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                            objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">1L</span>, <span class="number">0L</span>));</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> objs.iterator();</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">//TODO 支付数据</span></span><br><span class="line">                        String[] ids = s[<span class="number">10</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                        List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                        <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                            objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">0L</span>, <span class="number">1L</span>));</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">return</span> objs.iterator();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">        ).mapToPair(</span><br><span class="line">                obj -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(obj.getId(), obj)</span><br><span class="line">        );</span><br><span class="line">        <span class="comment">//TODO 对统计数据进行统计，获取统计结果</span></span><br><span class="line">        JavaPairRDD&lt;String, HotCategory&gt; objCountRDD = kvRDD.reduceByKey(</span><br><span class="line">                (obj1, obj2) -&gt; &#123;</span><br><span class="line">                    obj1.setClickCount(obj1.getClickCount() + obj2.getClickCount());</span><br><span class="line">                    obj1.setOrderCount(obj1.getOrderCount() + obj2.getOrderCount());</span><br><span class="line">                    obj1.setPayCount(obj1.getPayCount() + obj2.getPayCount());</span><br><span class="line">                    <span class="keyword">return</span> obj1;</span><br><span class="line">                &#125;</span><br><span class="line">        );</span><br><span class="line">        <span class="comment">//TODO 对统计的结果进行排序，取前十个，打印出来</span></span><br><span class="line">        <span class="comment">//     如果对象需要排序，那么必须实现可比较的接口，重写方法</span></span><br><span class="line">        objCountRDD</span><br><span class="line">                .map(kv -&gt; kv._2)</span><br><span class="line">                .sortBy(obj -&gt; obj,<span class="literal">true</span>,<span class="number">2</span>)</span><br><span class="line">                .take(<span class="number">10</span>).forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sc</span></span><br><span class="line">        jsc.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//TODO 自定义数据对象</span></span><br><span class="line"><span class="comment">//   1.实现可序列化接口</span></span><br><span class="line"><span class="comment">//   2.遵循bean规范</span></span><br><span class="line"><span class="comment">//   3.提供无参和全参的两种构造方法</span></span><br><span class="line"><span class="comment">//   4.重写toString方法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HotCategory</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span>, Comparable&lt;HotCategory&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">    <span class="keyword">private</span> Long clickCount;</span><br><span class="line">    <span class="keyword">private</span> Long orderCount;</span><br><span class="line">    <span class="keyword">private</span> Long payCount;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">HotCategory</span><span class="params">(String id, Long clickCount, Long orderCount, Long payCount)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">        <span class="built_in">this</span>.clickCount = clickCount;</span><br><span class="line">        <span class="built_in">this</span>.orderCount = orderCount;</span><br><span class="line">        <span class="built_in">this</span>.payCount = payCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">HotCategory</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(String id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">getClickCount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> clickCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setClickCount</span><span class="params">(Long clickCount)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.clickCount = clickCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">getOrderCount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> orderCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setOrderCount</span><span class="params">(Long orderCount)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.orderCount = orderCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">getPayCount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> payCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPayCount</span><span class="params">(Long payCount)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.payCount = payCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;HotCategory&#123;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;id=&#x27;&quot;</span> + id + <span class="string">&#x27;\&#x27;&#x27;</span> +</span><br><span class="line">                <span class="string">&quot;, clickCount=&quot;</span> + clickCount +</span><br><span class="line">                <span class="string">&quot;, orderCount=&quot;</span> + orderCount +</span><br><span class="line">                <span class="string">&quot;, payCount=&quot;</span> + payCount +</span><br><span class="line">                <span class="string">&#x27;&#125;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(HotCategory other)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.clickCount &gt; other.clickCount)&#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.clickCount &lt; other.clickCount)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">this</span>.orderCount &gt; other.orderCount) &#123;</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.orderCount &lt; other.orderCount) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> (<span class="type">int</span>) (other.payCount - <span class="built_in">this</span>.payCount);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>简化版</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">jsc</span><br><span class="line">    .textFile(<span class="string">&quot;src/main/data/user_visit_action.txt&quot;</span>)</span><br><span class="line">    .filter(</span><br><span class="line">        line -&gt; &#123;</span><br><span class="line">            String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;null&quot;</span>.equals(s[<span class="number">5</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    .flatMap(</span><br><span class="line">        line -&gt; &#123;</span><br><span class="line">            String[] s = line.split(<span class="string">&quot;_&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (!<span class="string">&quot;-1&quot;</span>.equals(s[<span class="number">6</span>])) &#123;</span><br><span class="line">                <span class="comment">//TODO 点击数据</span></span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(s[<span class="number">6</span>], <span class="number">1L</span>, <span class="number">0L</span>, <span class="number">0L</span>)).iterator();</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="string">&quot;null&quot;</span>.equals(s[<span class="number">8</span>])) &#123;</span><br><span class="line">                <span class="comment">//TODO 下单数据</span></span><br><span class="line">                String[] ids = s[<span class="number">8</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                    objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">1L</span>, <span class="number">0L</span>));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> objs.iterator();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//TODO 支付数据</span></span><br><span class="line">                String[] ids = s[<span class="number">10</span>].split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">                List&lt;HotCategory&gt; objs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">                <span class="keyword">for</span> (String id : ids) &#123;</span><br><span class="line">                    objs.add(<span class="keyword">new</span> <span class="title class_">HotCategory</span>(id, <span class="number">0L</span>, <span class="number">0L</span>, <span class="number">1L</span>));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> objs.iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    .mapToPair(</span><br><span class="line">        obj -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(obj.getId(), obj)</span><br><span class="line">    )</span><br><span class="line">    .reduceByKey(</span><br><span class="line">        (obj1, obj2) -&gt; &#123;</span><br><span class="line">            obj1.setClickCount(obj1.getClickCount() + obj2.getClickCount());</span><br><span class="line">            obj1.setOrderCount(obj1.getOrderCount() + obj2.getOrderCount());</span><br><span class="line">            obj1.setPayCount(obj1.getPayCount() + obj2.getPayCount());</span><br><span class="line">            <span class="keyword">return</span> obj1;</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    .map(kv -&gt; kv._2)</span><br><span class="line">    .sortBy(obj -&gt; obj,<span class="literal">true</span>,<span class="number">2</span>)</span><br><span class="line">    .take(<span class="number">10</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">HotCategory&#123;id=&#x27;15&#x27;, clickCount=6120, orderCount=1672, payCount=1259&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;2&#x27;, clickCount=6119, orderCount=1767, payCount=1196&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;20&#x27;, clickCount=6098, orderCount=1776, payCount=1244&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;12&#x27;, clickCount=6095, orderCount=1740, payCount=1218&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;11&#x27;, clickCount=6093, orderCount=1781, payCount=1202&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;17&#x27;, clickCount=6079, orderCount=1752, payCount=1231&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;7&#x27;, clickCount=6074, orderCount=1796, payCount=1252&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;9&#x27;, clickCount=6045, orderCount=1736, payCount=1230&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;19&#x27;, clickCount=6044, orderCount=1722, payCount=1158&#125;</span><br><span class="line">HotCategory&#123;id=&#x27;13&#x27;, clickCount=6036, orderCount=1781, payCount=1161&#125;</span><br></pre></td></tr></table></figure>

<h1 id="第七章-SparkSQL概述"><a href="#第七章-SparkSQL概述" class="headerlink" title="第七章 SparkSQL概述"></a>第七章 SparkSQL概述</h1><h2 id="7-1-什么是SparkSQL"><a href="#7-1-什么是SparkSQL" class="headerlink" title="7.1 什么是SparkSQL"></a>7.1 什么是SparkSQL</h2><p>Spark SQL是用于结构化数据处理的Spark模块。与基本的Spark RDD API不同，Spark SQL提供的接口为Spark提供了有关数据结构和正在执行的计算的更多信息。在内部，Spark SQL使用这些额外的信息来执行额外的优化。与Spark SQL交互的方式有多种，包括SQL和Dataset API。计算结果时，使用相同的执行引擎，与您用于表达计算的API&#x2F;语言无关。</p>
<h2 id="7-2-为什么要有Spark-SQL"><a href="#7-2-为什么要有Spark-SQL" class="headerlink" title="7.2 为什么要有Spark SQL"></a>7.2 为什么要有Spark SQL</h2><p><img src="Snipaste_2024-06-18_16-02-09.png" alt="Snipaste_2024-06-18_16-02-09"></p>
<h2 id="7-3-SparkSQL的发展"><a href="#7-3-SparkSQL的发展" class="headerlink" title="7.3 SparkSQL的发展"></a>7.3 SparkSQL的发展</h2><p>1）发展历史</p>
<p>RDD（Spark1.0）&#x3D;》Dataframe（Spark1.3）&#x3D;》Dataset（Spark1.6）</p>
<p>如果同样的数据都给到这三个数据结构，他们分别计算之后，都会给出相同的结果。不同的是他们的执行效率和执行方式。在现在的版本中，dataSet性能最好，已经成为了唯一使用的接口。其中Dataframe已经在底层被看做是特殊泛型的DataSet<Row>。</Row></p>
<p>2）三者的共性</p>
<p>（1）RDD、DataFrame、DataSet全都是Spark平台下的分布式弹性数据集，为处理超大型数据提供便利。</p>
<p>（2）三者都有惰性机制，在进行创建、转换，如map方法时，不会立即执行，只有在遇到Action行动算子如foreach时，三者才会开始遍历运算。</p>
<p>（3）三者有许多共同的函数，如filter，排序等。</p>
<p>（4）三者都会根据Spark的内存情况自动缓存运算。</p>
<p>（5）三者都有分区的概念。</p>
<h1 id="第八章-SparkSQL编程"><a href="#第八章-SparkSQL编程" class="headerlink" title="第八章 SparkSQL编程"></a>第八章 SparkSQL编程</h1><h2 id="8-1-SparkSession新的起始点"><a href="#8-1-SparkSession新的起始点" class="headerlink" title="8.1 SparkSession新的起始点"></a>8.1 SparkSession新的起始点</h2><p>在老的版本中，SparkSQL提供两种SQL查询起始点：</p>
<ul>
<li>一个叫SQLContext，用于Spark自己提供的SQL查询；</li>
<li>一个叫HiveContext，用于连接Hive的查询。</li>
</ul>
<p>SparkSession是Spark最新的SQL查询起始点，实质上是SQLContext和HiveContext的组合，所以在SQLContext和HiveContext上可用的API在SparkSession上同样是可以使用的。</p>
<p>SparkSession内部封装了SparkContext，所以计算实际上是由SparkContext完成的。当我们使用spark-shell的时候，Spark框架会自动的创建一个名称叫做Spark的SparkSession，就像我们以前可以自动获取到一个sc来表示SparkContext。</p>
<h2 id="8-2-常用方法"><a href="#8-2-常用方法" class="headerlink" title="8.2 常用方法"></a>8.2 常用方法</h2><h3 id="8-2-1-SparkSQL的环境转换"><a href="#8-2-1-SparkSQL的环境转换" class="headerlink" title="8.2.1 SparkSQL的环境转换"></a>8.2.1 SparkSQL的环境转换</h3><p>user.json</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">20</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;qiaofeng&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">19</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;xuzhu&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">18</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;duanyu&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">22</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;qiaofeng&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">11</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;xuzhu&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;age&quot;</span><span class="punctuation">:</span><span class="number">12</span><span class="punctuation">,</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;duanyu&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>添加依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.18.22<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkSQL01_Env2</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//TODO 环境之间的转换</span></span><br><span class="line">        <span class="comment">//  Core:SparkContext -&gt; SQL:SparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">sparkSession</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkSession</span>(<span class="keyword">new</span> <span class="title class_">SparkContext</span>(conf));</span><br><span class="line">        <span class="comment">//  SQL:SparkSession -&gt; Core:SparkContext</span></span><br><span class="line">        <span class="type">SparkContext</span> <span class="variable">sparkContext</span> <span class="operator">=</span> spark.sparkContext();</span><br><span class="line">        <span class="comment">//  Core:SparkContext -&gt; Core:JavaSparkContext</span></span><br><span class="line">        <span class="type">JavaSparkContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(sparkContext);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="8-2-2-Row对象转换为自定义对象"><a href="#8-2-2-Row对象转换为自定义对象" class="headerlink" title="8.2.2 Row对象转换为自定义对象"></a>8.2.2 Row对象转换为自定义对象</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkSQL01_Model_1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        Dataset&lt;Row&gt; ds = spark.read().json(<span class="string">&quot;src/main/data/user.json&quot;</span>);</span><br><span class="line">        <span class="comment">// 可以将Dataset转换为RDD</span></span><br><span class="line"><span class="comment">//        RDD&lt;Row&gt; rdd = ds.rdd();</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 将数据模型中的数据类型进行转换，将Row转换成其他对象进行处理</span></span><br><span class="line">        Dataset&lt;User&gt; uerDS = ds.as(Encoders.bean(User.class));</span><br><span class="line">        uerDS.show();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> age;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getAge</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(<span class="type">long</span> age)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">User</span><span class="params">(<span class="type">long</span> age, String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.age = age;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">User</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+---+--------+</span><br><span class="line">|age|    name|</span><br><span class="line">+---+--------+</span><br><span class="line">| 20|qiaofeng|</span><br><span class="line">| 19|   xuzhu|</span><br><span class="line">| 18|  duanyu|</span><br><span class="line">| 22|qiaofeng|</span><br><span class="line">| 11|   xuzhu|</span><br><span class="line">| 12|  duanyu|</span><br><span class="line">+---+--------+</span><br></pre></td></tr></table></figure>

<h3 id="8-2-3-SQL方法的使用"><a href="#8-2-3-SQL方法的使用" class="headerlink" title="8.2.3 SQL方法的使用"></a>8.2.3 SQL方法的使用</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkSQL01_Model_2</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        Dataset&lt;Row&gt; ds = spark.read().json(<span class="string">&quot;src/main/data/user.json&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 模型对象的访问1</span></span><br><span class="line">        <span class="comment">//    将数据模型转换为二维结构（行，列），可以通过SQL语句进行访问</span></span><br><span class="line">        <span class="comment">//    视图：是表的查询结果集。表可以增删改查，视图不能增删改查，只能查询</span></span><br><span class="line">        ds.createOrReplaceTempView(<span class="string">&quot;User_tmp&quot;</span>);<span class="comment">//User_tmp为表名</span></span><br><span class="line">        spark.sql(<span class="string">&quot;select * from User_tmp&quot;</span>).show();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 模型对象的访问2</span></span><br><span class="line">        <span class="comment">//     采用DSL语法进行访问（了解，开发成本高，不常使用）</span></span><br><span class="line">        ds.select(<span class="string">&quot;*&quot;</span>).show();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+---+--------+</span><br><span class="line">|age|    name|</span><br><span class="line">+---+--------+</span><br><span class="line">| 20|qiaofeng|</span><br><span class="line">| 19|   xuzhu|</span><br><span class="line">| 18|  duanyu|</span><br><span class="line">| 22|qiaofeng|</span><br><span class="line">| 11|   xuzhu|</span><br><span class="line">| 12|  duanyu|</span><br><span class="line">+---+--------+</span><br></pre></td></tr></table></figure>

<h2 id="8-3-SQL以及用户自定义函数的使用"><a href="#8-3-SQL以及用户自定义函数的使用" class="headerlink" title="8.3 SQL以及用户自定义函数的使用"></a>8.3 SQL以及用户自定义函数的使用</h2><h3 id="8-3-1-SQL使用方法概述"><a href="#8-3-1-SQL使用方法概述" class="headerlink" title="8.3.1 SQL使用方法概述"></a>8.3.1 SQL使用方法概述</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkSQL01_SQL</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//TODO Spark SQL中对数据模型也进行了封装：RDD -&gt; Dataset</span></span><br><span class="line">        <span class="comment">//    对接文件数据源时，会将文件中的一行数据封装为ROW对象</span></span><br><span class="line">        Dataset&lt;Row&gt; ds = spark.read().json(<span class="string">&quot;src/main/data/user.json&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 将数据模型转换成表，方便SQL语言操作</span></span><br><span class="line">        ds.createOrReplaceTempView(<span class="string">&quot;user&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 使用SQL的方式操作数据</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">sql</span> <span class="operator">=</span> <span class="string">&quot;select avg(age) from user&quot;</span>;</span><br><span class="line">        Dataset&lt;Row&gt; sqlDS = spark.sql(sql);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 展示数据模型的效果</span></span><br><span class="line">        sqlDS.show();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+--------+</span><br><span class="line">|avg(age)|</span><br><span class="line">+--------+</span><br><span class="line">|    17.0|</span><br><span class="line">+--------+</span><br></pre></td></tr></table></figure>

<h3 id="8-3-2-UDF"><a href="#8-3-2-UDF" class="headerlink" title="8.3.2 UDF"></a>8.3.2 UDF</h3><p>UDF：一行进入，一行出</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkSQL01_SQL_UDF</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        Dataset&lt;Row&gt; ds = spark.read().json(<span class="string">&quot;src/main/data/user.json&quot;</span>);</span><br><span class="line">        ds.createOrReplaceTempView(<span class="string">&quot;User_tmp&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO SparkSQL提供了一种特殊的方法，可以在SQL中增加自定义方法来实现复杂的逻辑</span></span><br><span class="line">        <span class="comment">//   UDF:一行输入、一行输出</span></span><br><span class="line">        <span class="comment">//  自定义函数prefixName(x)，逻辑为将x列的每一个数据都加上前缀&#x27;Name:&#x27;</span></span><br><span class="line">        <span class="comment">//  如果想要自定义的方法能够在SQL中使用，那么必须在Spark中进行声明和注册</span></span><br><span class="line">        <span class="comment">//   register()方法需要传递3个参数，</span></span><br><span class="line">        <span class="comment">//   第一个参数表示SQL中使用的方法名，</span></span><br><span class="line">        <span class="comment">//   第二个参数表示逻辑功能,UDFn:表示传递n个参数 In -&gt; Out</span></span><br><span class="line">        <span class="comment">//   第三个参数表示返回的数据类型</span></span><br><span class="line">        spark.udf().register(<span class="string">&quot;prefixName&quot;</span>, <span class="keyword">new</span> <span class="title class_">UDF1</span>&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> String <span class="title function_">call</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="string">&quot;Name:&quot;</span> + s;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, DataTypes.StringType);</span><br><span class="line">        <span class="type">String</span> <span class="variable">sql</span> <span class="operator">=</span> <span class="string">&quot;select age, prefixName(name) as name from User_tmp&quot;</span>;</span><br><span class="line">        spark.sql(sql).show();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">+---+-------------+</span><br><span class="line">|age|         name|</span><br><span class="line">+---+-------------+</span><br><span class="line">| 20|Name:qiaofeng|</span><br><span class="line">| 19|   Name:xuzhu|</span><br><span class="line">| 18|  Name:duanyu|</span><br><span class="line">| 22|Name:qiaofeng|</span><br><span class="line">| 11|   Name:xuzhu|</span><br><span class="line">| 12|  Name:duanyu|</span><br><span class="line">+---+-------------+</span><br></pre></td></tr></table></figure>

<h3 id="8-3-3-UDAF"><a href="#8-3-3-UDAF" class="headerlink" title="8.3.3 UDAF"></a>8.3.3 UDAF</h3><p>UDAF：输入多行，返回一行。通常和groupBy一起使用，如果直接使用UDAF函数，默认将所有的数据合并在一起。</p>
<p>Spark3.x推荐使用extends Aggregator自定义UDAF，属于强类型的Dataset方式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkSQL01_SQL_UDAF</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        Dataset&lt;Row&gt; ds = spark.read().json(<span class="string">&quot;src/main/data/user.json&quot;</span>);</span><br><span class="line">        ds.createOrReplaceTempView(<span class="string">&quot;User_tmp&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//TODO 自定义UDAF函数</span></span><br><span class="line">        <span class="comment">//TODO SparkSQL采用特殊的方式将UDAF转换为UDF使用，functions.udaf()</span></span><br><span class="line">        <span class="comment">//   functions.udaf()使用时需要创建自定义聚合对象</span></span><br><span class="line">        <span class="comment">//   udaf()方法需要传递两个参数</span></span><br><span class="line">        <span class="comment">//     第一个参数表示UDAF对象</span></span><br><span class="line">        <span class="comment">//     第二个参数表示输入数据类型</span></span><br><span class="line">        spark.udf().register(<span class="string">&quot;avgAge&quot;</span>, functions.udaf(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">MyAvgAgeUDAF</span>(),Encoders.LONG()</span><br><span class="line">        ));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">sql</span> <span class="operator">=</span> <span class="string">&quot;select avgAge(age) as avg_age from User_tmp&quot;</span>;</span><br><span class="line">        spark.sql(sql).show();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//TODO 自定义UDAF函数，实现年龄的平均值</span></span><br><span class="line"><span class="comment">//    1.创建自定义的公共类</span></span><br><span class="line"><span class="comment">//    2.继承org.apache.spark.sql.expressions.Aggregator类</span></span><br><span class="line"><span class="comment">//    3.设定泛型</span></span><br><span class="line"><span class="comment">//       IN:输入数据的类型</span></span><br><span class="line"><span class="comment">//       BUFF: 缓冲区的数据类型</span></span><br><span class="line"><span class="comment">//       OUT:输出数据的类型</span></span><br><span class="line"><span class="comment">//   4.重写方法（4计算+2状态）</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyAvgAgeUDAF</span> <span class="keyword">extends</span> <span class="title class_">Aggregator</span>&lt;Long,AvgAgeBuffer,Long&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//TODO 缓冲区的初始化操作</span></span><br><span class="line">    <span class="keyword">public</span> AvgAgeBuffer <span class="title function_">zero</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">AvgAgeBuffer</span>(<span class="number">0L</span>,<span class="number">0L</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//TODO 将输入的年龄和缓冲区的数据进行聚合操作</span></span><br><span class="line">    <span class="keyword">public</span> AvgAgeBuffer <span class="title function_">reduce</span><span class="params">(AvgAgeBuffer buffer, Long in)</span> &#123;</span><br><span class="line">        buffer.setTotal(buffer.getTotal() + in);</span><br><span class="line">        buffer.setCnt(buffer.getCnt() + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span> buffer;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//TODO 合并缓冲区的数据，多个缓冲区最终合并成一个</span></span><br><span class="line">    <span class="keyword">public</span> AvgAgeBuffer <span class="title function_">merge</span><span class="params">(AvgAgeBuffer b1, AvgAgeBuffer b2)</span> &#123;</span><br><span class="line">        b1.setTotal(b1.getTotal() + b2.getTotal());</span><br><span class="line">        b1.setCnt(b1.getCnt() + b2.getCnt());</span><br><span class="line">        <span class="keyword">return</span> b1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//TODO 计算最终结果</span></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">finish</span><span class="params">(AvgAgeBuffer buffer)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> buffer.getTotal()/buffer.getCnt();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//TODO buffer的状态</span></span><br><span class="line">    <span class="keyword">public</span> Encoder&lt;AvgAgeBuffer&gt; <span class="title function_">bufferEncoder</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Encoders.bean(AvgAgeBuffer.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//TODO 输出的状态</span></span><br><span class="line">    <span class="keyword">public</span> Encoder&lt;Long&gt; <span class="title function_">outputEncoder</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Encoders.LONG();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AvgAgeBuffer</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Long total;</span><br><span class="line">    <span class="keyword">private</span> Long cnt;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">AvgAgeBuffer</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">AvgAgeBuffer</span><span class="params">(Long total, Long cnt)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.total = total;</span><br><span class="line">        <span class="built_in">this</span>.cnt = cnt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">getTotal</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> total;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setTotal</span><span class="params">(Long total)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.total = total;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">getCnt</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> cnt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setCnt</span><span class="params">(Long cnt)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.cnt = cnt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+-------+</span><br><span class="line">|avg_age|</span><br><span class="line">+-------+</span><br><span class="line">|     17|</span><br><span class="line">+-------+</span><br></pre></td></tr></table></figure>

<h3 id="8-3-4-UDTF（没有）"><a href="#8-3-4-UDTF（没有）" class="headerlink" title="8.3.4 UDTF（没有）"></a>8.3.4 UDTF（没有）</h3><p>输入一行，返回多行（Hive）。</p>
<p>SparkSQL中没有UDTF，需要使用算子类型的flatMap先完成拆分。</p>
<h1 id="第九章-SparkSQL数据的加载与保存"><a href="#第九章-SparkSQL数据的加载与保存" class="headerlink" title="第九章 SparkSQL数据的加载与保存"></a>第九章 SparkSQL数据的加载与保存</h1><h2 id="9-1-读取和保存文件"><a href="#9-1-读取和保存文件" class="headerlink" title="9.1 读取和保存文件"></a>9.1 读取和保存文件</h2><p>SparkSQL读取和保存的文件一般为三种，JSON文件、CSV文件和列式存储的文件，同时可以通过添加参数，来识别不同的存储和压缩格式。</p>
<h3 id="9-1-1-CSV文件"><a href="#9-1-1-CSV文件" class="headerlink" title="9.1.1 CSV文件"></a>9.1.1 CSV文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Source_CSV</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">//TODO CSV文件就是将数据采用逗号分隔的数据文件</span></span><br><span class="line">        Dataset&lt;Row&gt; csv = spark.read()</span><br><span class="line">                .option(<span class="string">&quot;header&quot;</span>,<span class="string">&quot;true&quot;</span>) <span class="comment">//配置表头</span></span><br><span class="line">                .option(<span class="string">&quot;sep&quot;</span>,<span class="string">&quot;,&quot;</span>) <span class="comment">//配置逗号为分隔符</span></span><br><span class="line">                .csv(<span class="string">&quot;src/main/data/user.csv&quot;</span>);</span><br><span class="line">        csv.write()</span><br><span class="line">                .mode(<span class="string">&quot;append&quot;</span>) <span class="comment">//追加</span></span><br><span class="line">                .option(<span class="string">&quot;header&quot;</span>,<span class="string">&quot;true&quot;</span>) <span class="comment">//配置表头</span></span><br><span class="line">                .csv(<span class="string">&quot;output12&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="9-1-2-JSON文件"><a href="#9-1-2-JSON文件" class="headerlink" title="9.1.2 JSON文件"></a>9.1.2 JSON文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Source_JSON</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="comment">// JSON :JavaScript Object Notation</span></span><br><span class="line">        <span class="comment">//      对象：&#123;&#125;</span></span><br><span class="line">        <span class="comment">//      数组：[]</span></span><br><span class="line">        <span class="comment">//      JSON文件：整个文件的数据格式符合JSON格式</span></span><br><span class="line">        <span class="comment">//TODO SparkSQL其实就是对Spark Core RDD的封装，RDD读取文件采用的是Hadoop。</span></span><br><span class="line">        <span class="comment">//  Hadoop是按行读取的；SparkSQL只需要保证JSON文件中一行数据符合JSON格式即可，无需整个文件符合JSON格式</span></span><br><span class="line">        Dataset&lt;Row&gt; json = spark.read().json(<span class="string">&quot;src/main/data/user.json&quot;</span>);</span><br><span class="line">        json.write().json(<span class="string">&quot;output_json_json&quot;</span>);</span><br><span class="line">        json.show();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="9-1-3-Parquet文件"><a href="#9-1-3-Parquet文件" class="headerlink" title="9.1.3 Parquet文件"></a>9.1.3 Parquet文件</h3><p>列式存储的数据自带分割</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Source_Parquet</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        Dataset&lt;Row&gt; parquet = spark.read().parquet(<span class="string">&quot;src/main/data/users.parquet&quot;</span>);</span><br><span class="line">        parquet.write().parquet(<span class="string">&quot;output_parquet&quot;</span>);</span><br><span class="line">        parquet.show();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="9-2-与MySQL交互"><a href="#9-2-与MySQL交互" class="headerlink" title="9.2 与MySQL交互"></a>9.2 与MySQL交互</h2><p>（1）导入依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 5.8(8.0)MySQL版本 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>8.0.18<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Source_MySQL</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.setProperty(<span class="string">&quot;user&quot;</span>,<span class="string">&quot;root&quot;</span>);</span><br><span class="line">        properties.setProperty(<span class="string">&quot;password&quot;</span>,<span class="string">&quot;wyhdhr19980418&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; jdbc = spark.read().jdbc(<span class="string">&quot;jdbc:mysql://localhost:3306?&amp;serverTimezone=Asia/Shanghai&quot;</span>, <span class="string">&quot;dbtest11.employee&quot;</span>, properties);</span><br><span class="line">        jdbc.write().jdbc(<span class="string">&quot;jdbc:mysql://localhost:3306?&amp;serverTimezone=Asia/Shanghai&quot;</span>, <span class="string">&quot;dbtest11.employee_test&quot;</span>, properties);</span><br><span class="line">        jdbc.show();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+-----+------+---+------------+--------+-------+</span><br><span class="line">|   id|  name|sex|         tel|    addr| salary|</span><br><span class="line">+-----+------+---+------------+--------+-------+</span><br><span class="line">|10001|张一一| 男| 13456789000|山东青岛|1001.58|</span><br><span class="line">|10002|刘小红| 女| 13454319000|河北保定|1201.21|</span><br><span class="line">|10003|  李四| 男|0751-1234567|广东韶关|1004.11|</span><br><span class="line">|10004|刘小强| 男|0755-5555555|广东深圳|1501.23|</span><br><span class="line">|10005|  王艳| 男| 020-1232133|广东广州|1405.16|</span><br><span class="line">+-----+------+---+------------+--------+-------+</span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-24_13-58-27.png" alt="Snipaste_2024-06-24_13-58-27" style="zoom: 67%;">

<h2 id="9-3-与Hive交互"><a href="#9-3-与Hive交互" class="headerlink" title="9.3 与Hive交互"></a>9.3 与Hive交互</h2><p>SparkSQL可以采用内嵌Hive（spark开箱即用的hive），也可以采用外部Hive。企业开发中，通常采用外部Hive。</p>
<p>（1）添加依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-hive_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）拷贝hive-site.xml到resources目录（如果需要操作Hadoop，需要拷贝hdfs-site.xml、core-site.xml、yarn-site.xml）</p>
<img src="Snipaste_2024-06-24_15-52-49.png" alt="Snipaste_2024-06-24_15-52-49" style="zoom:50%;">

<p>（3）代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Source_Hive</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">//TODO 在编码前设置Hadoop的访问用户</span></span><br><span class="line">        System.setProperty(<span class="string">&quot;HADOOP_USER_NAME&quot;</span>,<span class="string">&quot;root&quot;</span>);</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;sparkSql&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取sparkSession</span></span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder().enableHiveSupport()  <span class="comment">//TODO 启用Hive的支持</span></span><br><span class="line">                .config(conf).getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写代码，和Hive对接</span></span><br><span class="line">        spark.sql(<span class="string">&quot;show tables&quot;</span>).show();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 关闭sparkSession</span></span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">+---------+---------------+-----------+</span><br><span class="line">|namespace|      tableName|isTemporary|</span><br><span class="line">+---------+---------------+-----------+</span><br><span class="line">|  default|           dept|      false|</span><br><span class="line">|  default|            emp|      false|</span><br><span class="line">|  default|       location|      false|</span><br><span class="line">|  default|           stu1|      false|</span><br><span class="line">|  default|        student|      false|</span><br><span class="line">|  default|       student1|      false|</span><br><span class="line">|  default|       student2|      false|</span><br><span class="line">|  default|     studentlll|      false|</span><br><span class="line">|  default|     studentqqq|      false|</span><br><span class="line">|  default|studenttesttest|      false|</span><br><span class="line">|  default|        teacher|      false|</span><br><span class="line">|  default|       teacher1|      false|</span><br><span class="line">|  default|       teacher2|      false|</span><br><span class="line">|  default|           test|      false|</span><br><span class="line">+---------+---------------+-----------+</span><br></pre></td></tr></table></figure>

<h1 id="第十章-SparkSQL项目实战"><a href="#第十章-SparkSQL项目实战" class="headerlink" title="第十章 SparkSQL项目实战"></a>第十章 SparkSQL项目实战</h1><h1 id="第十一章-SparkStreaming概述"><a href="#第十一章-SparkStreaming概述" class="headerlink" title="第十一章 SparkStreaming概述"></a>第十一章 SparkStreaming概述</h1><h2 id="11-1-Spark-Streaming概述"><a href="#11-1-Spark-Streaming概述" class="headerlink" title="11.1 Spark Streaming概述"></a>11.1 Spark Streaming概述</h2><p>官方文档: <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/streaming-programming-guide.html">https://spark.apache.org/docs/latest/streaming-programming-guide.html</a></p>
<img src="Snipaste_2024-06-24_19-42-36.png" alt="Snipaste_2024-06-24_19-42-36" style="zoom:50%;">

<p><img src="Snipaste_2024-06-24_21-49-45.png" alt="Snipaste_2024-06-24_21-49-45"></p>
<p>无界数据流是无法计算的，但是有界数据流可以计算的。Spark Streaming底层还是Spark Core,就是在流式数据处理中进行的封装。</p>
<p><img src="Snipaste_2024-06-25_10-44-43.png" alt="Snipaste_2024-06-25_10-44-43"></p>
<h2 id="11-2-Spark-Streaming架构原理"><a href="#11-2-Spark-Streaming架构原理" class="headerlink" title="11.2 Spark Streaming架构原理"></a>11.2 Spark Streaming架构原理</h2><h3 id="11-2-1-什么是DStream"><a href="#11-2-1-什么是DStream" class="headerlink" title="11.2.1 什么是DStream"></a>11.2.1 什么是DStream</h3><p><img src="Snipaste_2024-06-25_11-03-19.png" alt="Snipaste_2024-06-25_11-03-19"></p>
<h3 id="11-2-2-架构图"><a href="#11-2-2-架构图" class="headerlink" title="11.2.2 架构图"></a>11.2.2 架构图</h3><p>整体架构图</p>
<img src="Snipaste_2024-06-25_11-07-16.png" alt="Snipaste_2024-06-25_11-07-16" style="zoom:50%;">

<p>SparkStreaming架构图</p>
<img src="Snipaste_2024-06-25_11-07-49.png" alt="Snipaste_2024-06-25_11-07-49" style="zoom:50%;">

<h1 id="第十二章-SparkStreaming-HelloWorld"><a href="#第十二章-SparkStreaming-HelloWorld" class="headerlink" title="第十二章 SparkStreaming-HelloWorld"></a>第十二章 SparkStreaming-HelloWorld</h1><h2 id="12-1-HelloWorld实现"><a href="#12-1-HelloWorld实现" class="headerlink" title="12.1 HelloWorld实现"></a>12.1 HelloWorld实现</h2><p>需求：通过SparkStreaming读取kafka某个主题的数据并打印输出到控制台。</p>
<p>（1）添加依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-10_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">version</span>&gt;</span>3.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"> 	<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>（2）在hadoop102，103，104上启动zookeeper和kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# xcall.sh jps</span><br><span class="line">-----------hadoop102---------------</span><br><span class="line">2150 QuorumPeerMain</span><br><span class="line">2697 Jps</span><br><span class="line">2603 Kafka</span><br><span class="line">-----------hadoop103---------------</span><br><span class="line">2484 Kafka</span><br><span class="line">2586 Jps</span><br><span class="line">2043 QuorumPeerMain</span><br><span class="line">-----------hadoop104---------------</span><br><span class="line">2593 Jps</span><br><span class="line">2045 QuorumPeerMain</span><br><span class="line">2477 Kafka</span><br></pre></td></tr></table></figure>

<p>（3）编写代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkStreaming03_kafka</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;SparkStreaming&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取JavaStreamingContext</span></span><br><span class="line">        <span class="type">JavaStreamingContext</span> <span class="variable">stream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaStreamingContext</span>(conf, <span class="keyword">new</span> <span class="title class_">Duration</span>(<span class="number">3000</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写业务代码</span></span><br><span class="line">        <span class="comment">// 创建配置参数</span></span><br><span class="line">        HashMap&lt;String, Object&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        map.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;hadoop102:9092,hadoop103:9092,hadoop104:9092&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">&quot;atguigu&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,<span class="string">&quot;latest&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 需要消费的主题</span></span><br><span class="line">        ArrayList&lt;String&gt; strings = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        strings.add(<span class="string">&quot;topicA&quot;</span>);</span><br><span class="line"></span><br><span class="line">        JavaInputDStream&lt;ConsumerRecord&lt;String, String&gt;&gt; directStream = KafkaUtils.createDirectStream(stream, LocationStrategies.PreferBrokers(), ConsumerStrategies.&lt;String, String&gt;Subscribe(strings,map));</span><br><span class="line"></span><br><span class="line">        directStream.map(<span class="keyword">new</span> <span class="title class_">Function</span>&lt;ConsumerRecord&lt;String, String&gt;, Object&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Object <span class="title function_">call</span><span class="params">(ConsumerRecord&lt;String, String&gt; v1)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> v1.value();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).print(<span class="number">100</span>);<span class="comment">//print()函数是根据时间间隔输出时间戳，是DStream中的行动算子，必须加上</span></span><br><span class="line"><span class="comment">//        -------------------------------------------</span></span><br><span class="line"><span class="comment">//                Time: 1719318009000 ms</span></span><br><span class="line"><span class="comment">//        -------------------------------------------</span></span><br><span class="line">        <span class="comment">// 4. 启动数据采集器，并等待数据采集器的结束，如果采集器停止运行，那么main线程会继续执行</span></span><br><span class="line">        stream.start();</span><br><span class="line">        stream.awaitTermination();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>执行后出现以下状态说明对接kafka成功：</p>
<img src="Snipaste_2024-06-25_20-12-44.png" alt="Snipaste_2024-06-25_20-12-44" style="zoom: 33%;">

<p>（4）启动生产者生产数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# kafka-console-producer.sh --broker-list hadoop102:9092 --topic topicA</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">spark</span></span><br></pre></td></tr></table></figure>

<p>（5）在Idea控制台输出如下内容</p>
<img src="Snipaste_2024-06-25_20-20-04.png" alt="Snipaste_2024-06-25_20-20-04" style="zoom: 33%;">

<h2 id="12-2-HelloWorld解析"><a href="#12-2-HelloWorld解析" class="headerlink" title="12.2 HelloWorld解析"></a>12.2 HelloWorld解析</h2><p>DStream是Spark Streaming的基础抽象，代表持续性的数据流和经过各种Spark算子操作后的结果数据流。</p>
<p>在内部实现上，每一批次的数据封装成一个RDD，一系列连续的RDD组成了DStream。对这些RDD的转换是由Spark引擎来计算。</p>
<p>说明：DStream中批次与批次之间计算相互独立。如果批次设置时间小于计算时间会出现计算任务叠加情况，需要多分配资源。通常情况，批次设置时间要大于计算时间。</p>
<p><img src="Snipaste_2024-06-25_20-26-12.png" alt="Snipaste_2024-06-25_20-26-12"></p>
<h2 id="12-3-DStream方法"><a href="#12-3-DStream方法" class="headerlink" title="12.3 DStream方法"></a>12.3 DStream方法</h2><p>直接作用在DStream对象上的方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkStreaming04_DStream</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;SparkStreaming&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取JavaStreamingContext</span></span><br><span class="line">        <span class="type">JavaStreamingContext</span> <span class="variable">stream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaStreamingContext</span>(conf, <span class="keyword">new</span> <span class="title class_">Duration</span>(<span class="number">3000</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写业务代码</span></span><br><span class="line">        <span class="comment">// 创建配置参数</span></span><br><span class="line">        HashMap&lt;String, Object&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        map.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;hadoop102:9092,hadoop103:9092,hadoop104:9092&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">&quot;atguigu&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,<span class="string">&quot;latest&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 需要消费的主题</span></span><br><span class="line">        ArrayList&lt;String&gt; strings = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        strings.add(<span class="string">&quot;topicA&quot;</span>);</span><br><span class="line"></span><br><span class="line">        JavaInputDStream&lt;ConsumerRecord&lt;String, String&gt;&gt; directStream = KafkaUtils.createDirectStream(stream, LocationStrategies.PreferBrokers(), ConsumerStrategies.&lt;String, String&gt;Subscribe(strings,map));</span><br><span class="line"></span><br><span class="line">        directStream.map(</span><br><span class="line">                v1 -&gt; <span class="string">&quot;Kafka&quot;</span> + v1.value()</span><br><span class="line">        ).print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 启动数据采集器，并等待数据采集器的结束，如果采集器停止运行，那么main线程会继续执行</span></span><br><span class="line">        stream.start();</span><br><span class="line">        stream.awaitTermination();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# kafka-console-producer.sh --broker-list hadoop102:9092 --topic topicA</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">2300</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-25_20-42-43.png" alt="Snipaste_2024-06-25_20-42-43" style="zoom:33%;">

<h1 id="第十三章-SparkStreaming-DStream转换"><a href="#第十三章-SparkStreaming-DStream转换" class="headerlink" title="第十三章 SparkStreaming-DStream转换"></a>第十三章 SparkStreaming-DStream转换</h1><p>DStream上的操作与RDD的类似，分为转换和输出两种，此外转换操作中还有一些比较特殊的原语，如：transform()以及各种Window相关的原语。</p>
<img src="Snipaste_2024-06-27_09-58-27.png" alt="Snipaste_2024-06-27_09-58-27" style="zoom: 50%;">

<p>如下代码中，foreachRDD()叫做原语，map()和collect()叫做算子</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//将DStream对象转换为RDD对象</span></span><br><span class="line"><span class="comment">//TODO code =&gt;</span></span><br><span class="line"><span class="comment">//int i = 10;(此处代码在Driver端执行，只执行一次)</span></span><br><span class="line">directStream.foreachRDD(</span><br><span class="line">        rdd -&gt; &#123;</span><br><span class="line">            <span class="comment">//TODO code =&gt;</span></span><br><span class="line">            <span class="comment">//int j = 20;(此处代码在Driver端执行，执行次数和窗口长度、间断时间有关)</span></span><br><span class="line">            rdd.map(</span><br><span class="line">                    v1 -&gt; &#123;</span><br><span class="line">                        <span class="comment">//TODO code =&gt;</span></span><br><span class="line">                        <span class="comment">//int k = 30;(此处代码在Executor端执行，有几个rdd执行几次)</span></span><br><span class="line">                        <span class="keyword">return</span> <span class="string">&quot;RDD&quot;</span> + v1.value();</span><br><span class="line">                    &#125;</span><br><span class="line">            ).collect().forEach(System.out::println);</span><br><span class="line">        &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<h2 id="13-1-无状态转化操作"><a href="#13-1-无状态转化操作" class="headerlink" title="13.1 无状态转化操作"></a>13.1 无状态转化操作</h2><p>无状态转化操作：就是把RDD转化操作应用到DStream每个批次上，每个批次相互独立，自己算自己的。</p>
<p>DStream的部分无状态转化操作列在了下表中，都是DStream自己的API。</p>
<p>注意，只有JavaPairDStream&lt;Key, Value&gt;才能使用xxxByKey()类型的转换算子。</p>
<p><img src="Snipaste_2024-06-25_20-48-48.png" alt="Snipaste_2024-06-25_20-48-48"></p>
<p>需要记住的是，尽管这些函数看起来像作用在整个流上一样，但事实上每个DStream在内部是由许多RDD批次组成，且无状态转化操作是分别应用到每个RDD(一个批次的数据)上的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkStreaming04_Function</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;SparkStreaming&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取JavaStreamingContext</span></span><br><span class="line">        <span class="type">JavaStreamingContext</span> <span class="variable">stream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaStreamingContext</span>(conf, <span class="keyword">new</span> <span class="title class_">Duration</span>(<span class="number">3000</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写业务代码</span></span><br><span class="line">        <span class="comment">// 创建配置参数</span></span><br><span class="line">        HashMap&lt;String, Object&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        map.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;hadoop102:9092,hadoop103:9092,hadoop104:9092&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">&quot;atguigu&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,<span class="string">&quot;latest&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 需要消费的主题</span></span><br><span class="line">        ArrayList&lt;String&gt; strings = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        strings.add(<span class="string">&quot;topicA&quot;</span>);</span><br><span class="line"></span><br><span class="line">        JavaInputDStream&lt;ConsumerRecord&lt;String, String&gt;&gt; directStream = KafkaUtils.createDirectStream(stream, LocationStrategies.PreferBrokers(), ConsumerStrategies.&lt;String, String&gt;Subscribe(strings,map));</span><br><span class="line"></span><br><span class="line">        directStream.map(</span><br><span class="line">                v1 -&gt; <span class="string">&quot;Kafka&quot;</span> + v1.value()</span><br><span class="line">        ).print();</span><br><span class="line">        <span class="comment">//将DStream对象转换为RDD对象</span></span><br><span class="line">        directStream.foreachRDD(</span><br><span class="line">                rdd -&gt; rdd.map(v1 -&gt; <span class="string">&quot;RDD&quot;</span> + v1.value()).collect().forEach(System.out::println)</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 启动数据采集器，并等待数据采集器的结束，如果采集器停止运行，那么main线程会继续执行</span></span><br><span class="line">        stream.start();</span><br><span class="line">        stream.awaitTermination();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# kafka-console-producer.sh --broker-list hadoop102:9092 --topic topicA</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">dddd</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-25_20-54-21.png" alt="Snipaste_2024-06-25_20-54-21" style="zoom:33%;">

<h2 id="13-2-窗口操作"><a href="#13-2-窗口操作" class="headerlink" title="13.2 窗口操作"></a>13.2 窗口操作</h2><h3 id="13-2-1-WindowOperations"><a href="#13-2-1-WindowOperations" class="headerlink" title="13.2.1 WindowOperations"></a>13.2.1 WindowOperations</h3><p>Window Operations可以设置窗口的大小和滑动窗口的间隔来动态的获取当前Streaming的允许状态。所有基于窗口的操作都需要两个参数，分别为窗口时长以及滑动步长。</p>
<ul>
<li>窗口时长：计算内容的时间范围；</li>
<li>滑动步长：隔多久触发一次计算。</li>
</ul>
<p>注意：这两者都必须为采集批次大小的整数倍。</p>
<p>如下图所示WordCount案例：窗口大小为批次的2倍，滑动步等于批次大小。</p>
<p><img src="Snipaste_2024-06-25_22-25-51.png" alt="Snipaste_2024-06-25_22-25-51"></p>
<h3 id="13-2-2-Window"><a href="#13-2-2-Window" class="headerlink" title="13.2.2 Window"></a>13.2.2 Window</h3><p><strong>1）基本语法：</strong></p>
<p>window(windowLength, slideInterval): 基于对源DStream窗口的批次进行计算返回一个新的DStream。</p>
<ul>
<li>windowLength大于slideInterval，数据可能会有重复</li>
<li>windowLength小于slideInterval，数据可能会丢失</li>
<li>windowLength等于slideInterval，数据不会有重复</li>
</ul>
<p><strong>2）需求：</strong></p>
<p>统计WordCount：3秒一个批次，窗口12秒，滑步6秒。</p>
<p><strong>3）代码编写：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkStreaming_06_Window</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1.创建配置对象</span></span><br><span class="line">        <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local[*]&quot;</span>).setAppName(<span class="string">&quot;SparkStreaming&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取JavaStreamingContext</span></span><br><span class="line">        <span class="type">JavaStreamingContext</span> <span class="variable">stream</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaStreamingContext</span>(conf, <span class="keyword">new</span> <span class="title class_">Duration</span>(<span class="number">3000</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 编写业务代码</span></span><br><span class="line">        <span class="comment">// 创建配置参数</span></span><br><span class="line">        HashMap&lt;String, Object&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        map.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;hadoop102:9092,hadoop103:9092,hadoop104:9092&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">&quot;atguigu&quot;</span>);</span><br><span class="line">        map.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,<span class="string">&quot;latest&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 需要消费的主题</span></span><br><span class="line">        ArrayList&lt;String&gt; strings = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        strings.add(<span class="string">&quot;topicA&quot;</span>);</span><br><span class="line"></span><br><span class="line">        JavaInputDStream&lt;ConsumerRecord&lt;String, String&gt;&gt; directStream = KafkaUtils.createDirectStream(stream, LocationStrategies.PreferBrokers(), ConsumerStrategies.&lt;String, String&gt;Subscribe(strings,map));</span><br><span class="line">        <span class="comment">//对从kafka监听的数据进行处理后，划分窗口</span></span><br><span class="line">        JavaDStream&lt;String&gt; stringJavaDStream = directStream.flatMap(</span><br><span class="line">            kv -&gt; &#123;</span><br><span class="line">                String[] split = kv.value().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(split).iterator();</span><br><span class="line">            &#125;</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        JavaPairDStream&lt;String, Integer&gt; javaPairDStream = stringJavaDStream.mapToPair(</span><br><span class="line">            v1 -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(v1,<span class="number">1</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="comment">//TODO 窗口：其实就是数据的范围（时间）</span></span><br><span class="line">        <span class="comment">//    window方法可以改变窗口的数据范围（默认数据范围为采集周期）</span></span><br><span class="line">        <span class="comment">//    window方法可以传递两个参数</span></span><br><span class="line">        <span class="comment">//         第一个参数表示窗口的数据范围（时间）</span></span><br><span class="line">        <span class="comment">//         第二个参数表示窗口的移动幅度（时间），可以不用传递，默认使用的就是采集周期</span></span><br><span class="line">        JavaPairDStream&lt;String, Integer&gt; window = javaPairDStream.window(Duration.apply(<span class="number">12000</span>), Duration.apply(<span class="number">6000</span>));</span><br><span class="line"></span><br><span class="line">        window.reduceByKey(Integer::sum).print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 启动数据采集器，并等待数据采集器的结束，如果采集器停止运行，那么main线程会继续执行</span></span><br><span class="line">        stream.start();</span><br><span class="line">        stream.awaitTermination();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# kafka-console-producer.sh --broker-list hadoop102:9092 --topic topicA</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hadoop spark spark flink flink</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">hadoop hadoop</span></span><br></pre></td></tr></table></figure>

<img src="Snipaste_2024-06-25_23-05-55.png" alt="Snipaste_2024-06-25_23-05-55" style="zoom:33%;">

<h3 id="13-2-3-reduceByKeyAndWindow"><a href="#13-2-3-reduceByKeyAndWindow" class="headerlink" title="13.2.3 reduceByKeyAndWindow"></a>13.2.3 reduceByKeyAndWindow</h3><p>reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks])：当在一个(K,V)对的DStream上调用此函数，会返回一个新(K,V)对的DStream，此处通过对滑动窗口中批次数据使用reduce函数来整合每个key的value值。</p>
<p><strong>实际上就是reduceByKey和Window两个原语的结合</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">JavaInputDStream&lt;ConsumerRecord&lt;String, String&gt;&gt; directStream = KafkaUtils.createDirectStream(stream, LocationStrategies.PreferBrokers(), ConsumerStrategies.&lt;String, String&gt;Subscribe(strings,map));</span><br><span class="line"><span class="comment">//对从kafka监听的数据进行处理后，划分窗口</span></span><br><span class="line">JavaDStream&lt;String&gt; stringJavaDStream = directStream.flatMap(</span><br><span class="line">        kv -&gt; &#123;</span><br><span class="line">            String[] split = kv.value().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> Arrays.asList(split).iterator();</span><br><span class="line">        &#125;</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">JavaPairDStream&lt;String, Integer&gt; javaPairDStream = stringJavaDStream.mapToPair(</span><br><span class="line">        v1 -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(v1,<span class="number">1</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">//TODO reduceByKeyAndWindow</span></span><br><span class="line">javaPairDStream.reduceByKeyAndWindow(</span><br><span class="line">        Integer::sum,Duration.apply(<span class="number">12000L</span>),Duration.apply(<span class="number">6000L</span>)</span><br><span class="line">).print();</span><br></pre></td></tr></table></figure>

<h1 id="第十四章-DStream输出"><a href="#第十四章-DStream输出" class="headerlink" title="第十四章 DStream输出"></a>第十四章 DStream输出</h1><p>DStream通常将数据输出到，外部数据库或屏幕上。</p>
<p>DStream与RDD中的惰性求值类似，如果一个DStream及其派生出的DStream都没有被执行输出操作，那么这些DStream就都不会被求值。如果StreamingContext中没有设定输出操作，整个Context就都不会启动。</p>
<p>（1）saveAsTextFiles(prefix, [suffix])：以text文件形式存储这个DStream的内容。每一批次的存储文件名基于参数中的prefix和suffix。“prefix-Time_IN_MS[.suffix]”。</p>
<p>注意：以上操作都是每一批次写出一次，会产生大量小文件，在生产环境，很少使用。</p>
<p>（2）print()：在运行流程序的驱动结点上打印DStream中每一批次数据的最开始10个元素。这用于开发和调试。</p>
<p>（3）foreachRDD(func)：这是最通用的输出操作，即将函数func用于产生DStream的每一个RDD。其中参数传入的函数func应该实现将每一个RDD中数据推送到外部系统，如将RDD存入文件或者写入数据库。</p>
<p>在企业开发中通常采用foreachRDD()，它用来对DStream中的RDD进行任意计算。这和transform()有些类似，都可以让我们访问任意RDD。在foreachRDD()中，可以重用我们在Spark中实现的所有行动操作(action算子)。</p>
<h1 id="第十五章-DStream关闭"><a href="#第十五章-DStream关闭" class="headerlink" title="第十五章 DStream关闭"></a>第十五章 DStream关闭</h1><p>流式任务需要7*24小时执行，但是有时涉及到升级代码需要主动停止程序，但是分布式程序，没办法做到一个个进程去杀死，所以配置优雅的关闭就显得至关重要了。</p>
<p>关闭方式：使用外部文件系统来控制内部程序关闭。</p>
<p>具体方式略</p>
<h1 id="第十六章-Spark内核"><a href="#第十六章-Spark内核" class="headerlink" title="第十六章 Spark内核"></a>第十六章 Spark内核</h1>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">Linux</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2024/05/25/spark%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Hivesql题库" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2024/01/01/Hivesql%E9%A2%98%E5%BA%93/">Hivesql题库</a>
    </h1>
  

        
        <a href="/2024/01/01/Hivesql%E9%A2%98%E5%BA%93/" class="archive-article-date">
  	<time datetime="2024-01-01T03:13:22.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2024-01-01</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="第一部分-初级题目"><a href="#第一部分-初级题目" class="headerlink" title="第一部分 初级题目"></a>第一部分 初级题目</h1><h1 id="第二部分-中级题目"><a href="#第二部分-中级题目" class="headerlink" title="第二部分 中级题目"></a>第二部分 中级题目</h1>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">面试</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/大数据//" class="article-tag-list-link color4">大数据</a>
        		</li>
      		
		</ul>
	</div>


      
        <p class="article-more-link">
          <a class="article-more-a" href="/2024/01/01/Hivesql%E9%A2%98%E5%BA%93/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2025 John Doe
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">随笔</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">常用算法</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据科学</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">面试</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">聚宽</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">项目</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">推荐系统</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">数据仓库</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">贝叶斯</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">因子投资</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">NLP基础</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">考试</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://www.csdn.net/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>CSDN</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.zhihu.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>知乎</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.huaweicloud.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>华为云</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.aliyun.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>阿里云</a>
            </li>
          
            <li class="search-li">
              <a href="https://leetcode.cn/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>力扣</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.joinquant.com/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>聚宽</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">我叫王宇涵，东北人，本科和硕士分别毕业于哈尔滨工程大学和大连理工大学，2024年秋招拿到快手、百度、京东、科大讯飞、度小满、华为、荣耀、360等十余家企业offer，目前就职于快手数据平台部，担任数据研发工程师，专注于商业化广告业务。热爱大数据平台开发与数仓开发，技术栈包括但不限于Java、数仓建模、Hadoop、Hive、Spark、Flink、Clickhouse、Doris、数据湖、数据治理等。会不定期分享一些技术文章、业务知识、面试心得和读书笔记。</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>